<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Mon 12 Feb 24  to  Tue 13 Feb 24, announced Wed, 14 Feb 24</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item341">Cross-lists</a></li>
<li><a href="#item387">Replacements</a></li>
</ul>
<small>[ total of 636 entries:  <b>1-636</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Wed, 14 Feb 24</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07905" title="Abstract">arXiv:2402.07905</a> [<a href="/pdf/2402.07905" title="Download PDF">pdf</a>, <a href="/ps/2402.07905" title="Download PostScript">ps</a>, <a href="/format/2402.07905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data protection psychology using game theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nkongolo%2C+M">Mike Nkongolo</a>, 
<a href="/search/cs?searchtype=author&query=Sewnath%2C+J">Jahrad Sewnath</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and to be presented at the 19th International Conference on Cyber Warfare and Security (ICCWS), 26 - 27 March 2024, Johannesburg, South Africa. Title of Paper: Infusing Morabaraba Game Design to Develop a Cybersecurity Awareness Game. (CyberMoraba)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The research aims to explore how individuals perceive and interact with data
protection practices in an era of increasing reliance on technology and the
widespread availability of personal data. The study employs a game theoretical
approach to investigate the psychological factors that influence individuals'
awareness and comprehension of data protection measures. This involves using
strategies, moves, rewards, and observations within the game to gain
comprehensive insights into these psychological factors. Through the analysis
of player strategies and moves within the game, the research identifies several
psychological factors that impact awareness of data protection. These factors
include levels of knowledge, attitudes, perceived risks, and individual
differences among participants. The findings highlight the intricate nature of
human cognition and behavior concerning data protection, offering insights
crucial for developing effective awareness games and educational initiatives in
this domain.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07907" title="Abstract">arXiv:2402.07907</a> [<a href="/pdf/2402.07907" title="Download PDF">pdf</a>, <a href="/ps/2402.07907" title="Download PostScript">ps</a>, <a href="/format/2402.07907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applications, challenges and ethical issues of AI and ChatGPT in  education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sidiropoulos%2C+D">Dimitrios Sidiropoulos</a>, 
<a href="/search/cs?searchtype=author&query=Anagnostopoulos%2C+C">Christos-Nikolaos Anagnostopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Artificial Intelligence (AI) in recent years has shown an unprecedentedly
impressive development, tending to play a catalytic role in all aspects of
life. The interest of the academic community, but also of governments, is huge
in the dynamics of AI and is reflected by the truly explosive amount of
investment and research that is underway. Enthusiastic opinions and statements
about AI are made every day, but at the same time they also bring to the fore
alarming predictions about its effects. This paper aims to describe the
opportunities emerging from the use of artificial intelligence and ChatGPT to
improve education, but also to identify the challenges and ethical issues that
arise.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07909" title="Abstract">arXiv:2402.07909</a> [<a href="/pdf/2402.07909" title="Download PDF">pdf</a>, <a href="/format/2402.07909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt4Vis: Prompting Large Language Models with Example Mining and  Schema Filtering for Tabular Data Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuaimin Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuanang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yuanfeng Song</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yunze Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chen Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Databases (cs.DB)

</div>
<p class="mathjax">Data visualization (DV) systems are increasingly recognized for their
profound capability to uncover insights from vast datasets, gaining attention
across both industry and academia. Crafting data queries is an essential
process within certain declarative visualization languages (DVLs, e.g.,
Vega-Lite, EChart.). The evolution of natural language processing (NLP)
technologies has streamlined the use of natural language interfaces to
visualize tabular data, offering a more accessible and intuitive user
experience. However, current methods for converting natural language questions
into data visualization queries, such as Seq2Vis, ncNet, and RGVisNet, despite
utilizing complex neural network architectures, still fall short of
expectations and have great room for improvement.
<br />Large language models (LLMs) such as ChatGPT and GPT-4, have established new
benchmarks in a variety of NLP tasks, fundamentally altering the landscape of
the field. Inspired by these advancements, we introduce a novel framework,
Prompt4Vis, leveraging LLMs and in-context learning to enhance the performance
of generating data visualization from natural language. Prompt4Vis comprises
two key components: (1) a multi-objective example mining module, designed to
find out the truly effective examples that strengthen the LLM's in-context
learning capabilities for text-to-vis; (2) a schema filtering module, which is
proposed to simplify the schema of the database. Extensive experiments through
5-fold cross-validation on the NVBench dataset demonstrate the superiority of
Prompt4Vis, which notably surpasses the state-of-the-art (SOTA) RGVisNet by
approximately 35.9% and 71.3% on dev and test sets, respectively. To the best
of our knowledge, Prompt4Vis is the first work that introduces in-context
learning into the text-to-vis for generating data visualization queries.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07910" title="Abstract">arXiv:2402.07910</a> [<a href="/pdf/2402.07910" title="Download PDF">pdf</a>, <a href="/format/2402.07910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental Interface for Multimodal and Large Language Model Based  Explanations of Educational Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abu-Rasheed%2C+H">Hasan Abu-Rasheed</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+C">Christian Weber</a>, 
<a href="/search/cs?searchtype=author&query=Fathi%2C+M">Madjid Fathi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In the age of artificial intelligence (AI), providing learners with suitable
and sufficient explanations of AI-based recommendation algorithm's output
becomes essential to enable them to make an informed decision about it.
However, the rapid development of AI approaches for educational recommendations
and their explainability is not accompanied by an equal level of evidence-based
experimentation to evaluate the learning effect of those explanations. To
address this issue, we propose an experimental web-based tool for evaluating
multimodal and large language model (LLM) based explainability approaches. Our
tool provides a comprehensive set of modular, interactive, and customizable
explainability elements, which researchers and educators can utilize to study
the role of individual and hybrid explainability methods. We design a two-stage
evaluation of the proposed tool, with learners and with educators. Our
preliminary results from the first stage show high acceptance of the tool's
components, user-friendliness, and an induced motivation to use the
explanations for exploring more information about the recommendation.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07911" title="Abstract">arXiv:2402.07911</a> [<a href="/pdf/2402.07911" title="Download PDF">pdf</a>, <a href="/format/2402.07911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does mapping elites illuminate search spaces? A large-scale user study  of MAP--Elites applied to human--AI collaborative design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Walton%2C+S+P">Sean P. Walton</a>, 
<a href="/search/cs?searchtype=author&query=Evans%2C+B+J">Ben J. Evans</a>, 
<a href="/search/cs?searchtype=author&query=Rahat%2C+A+A+M">Alma A. M. Rahat</a>, 
<a href="/search/cs?searchtype=author&query=Stovold%2C+J">James Stovold</a>, 
<a href="/search/cs?searchtype=author&query=Vincalek%2C+J">Jakub Vincalek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Two studies of a human-AI collaborative design tool were carried out in order
to understand the influence design recommendations have on the design process.
The tool investigated is based on an evolutionary algorithm attempting to
design a virtual car to travel as far as possible in a fixed time. Participants
were able to design their own cars, make recommendations to the algorithm and
view sets of recommendations from the algorithm. The algorithm-recommended sets
were designs which had been previously tested; some sets were simply randomly
picked and other sets were picked using MAP-Elites. In the first study 808
design sessions were recorded as part of a science outreach program, each with
analytical data of how each participant used the tool. To provide context to
this quantitative data, a smaller double-blind lab study was also carried out
with 12 participants. In the lab study the same quantitative data from the
large scale study was collected alongside responses to interview questions.
Although there is some evidence that the MAP-Elites provide higher-quality
individual recommendations, neither study provides convincing evidence that
these recommendations have a more positive influence on the design process than
simply a random selection of designs. In fact, it seems that providing a
combination of MAP-Elites and randomly selected recommendations is beneficial
to the process. Furthermore, simply viewing recommendations from the MAP-Elites
had a positive influence on engagement in the design task and the quality of
the final design produced. Our findings are significant both for researchers
designing new mixed-initiative tools, and those who wish to evaluate existing
tools. Most significantly, we found that metrics researchers currently use to
evaluate the success of human-AI collaborative algorithms do not measure the
full influence these algorithms have on the design process.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07912" title="Abstract">arXiv:2402.07912</a> [<a href="/pdf/2402.07912" title="Download PDF">pdf</a>, <a href="/format/2402.07912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial Computing: Concept, Applications, Challenges and Future  Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yenduri%2C+G">Gokul Yenduri</a>, 
<a href="/search/cs?searchtype=author&query=M%2C+R">Ramalingam M</a>, 
<a href="/search/cs?searchtype=author&query=Maddikunta%2C+P+K+R">Praveen Kumar Reddy Maddikunta</a>, 
<a href="/search/cs?searchtype=author&query=Gadekallu%2C+T+R">Thippa Reddy Gadekallu</a>, 
<a href="/search/cs?searchtype=author&query=Jhaveri%2C+R+H">Rutvij H Jhaveri</a>, 
<a href="/search/cs?searchtype=author&query=Bandi%2C+A">Ajay Bandi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shirawalmath%2C+A+A">Adarsh Arunkumar Shirawalmath</a>, 
<a href="/search/cs?searchtype=author&query=Ravishankar%2C+R">Raghav Ravishankar</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weizheng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to peer reviewe
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Spatial computing is a technological advancement that facilitates the
seamless integration of devices into the physical environment, resulting in a
more natural and intuitive digital world user experience. Spatial computing has
the potential to become a significant advancement in the field of computing.
From GPS and location-based services to healthcare, spatial computing
technologies have influenced and improved our interactions with the digital
world. The use of spatial computing in creating interactive digital
environments has become increasingly popular and effective. This is explained
by its increasing significance among researchers and industrial organisations,
which motivated us to conduct this review. This review provides a detailed
overview of spatial computing, including its enabling technologies and its
impact on various applications. Projects related to spatial computing are also
discussed. In this review, we also explored the potential challenges and
limitations of spatial computing. Furthermore, we discuss potential solutions
and future directions. Overall, this paper aims to provide a comprehensive
understanding of spatial computing, its enabling technologies, their impact on
various applications, emerging challenges, and potential solutions.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07913" title="Abstract">arXiv:2402.07913</a> [<a href="/pdf/2402.07913" title="Download PDF">pdf</a>, <a href="/format/2402.07913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QACP: An Annotated Question Answering Dataset for Assisting Chinese  Python Programming Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+R">Rui Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Lu Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaoying Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+N">Na Zong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengyu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In online learning platforms, particularly in rapidly growing computer
programming courses, addressing the thousands of students' learning queries
requires considerable human cost. The creation of intelligent assistant large
language models (LLMs) tailored for programming education necessitates distinct
data support. However, in real application scenarios, the data resources for
training such LLMs are relatively scarce. Therefore, to address the data
scarcity in intelligent educational systems for programming, this paper
proposes a new Chinese question-and-answer dataset for Python learners. To
ensure the authenticity and reliability of the sources of the questions, we
collected questions from actual student questions and categorized them
according to various dimensions such as the type of questions and the type of
learners. This annotation principle is designed to enhance the effectiveness
and quality of online programming education, providing a solid data foundation
for developing the programming teaching assists (TA). Furthermore, we conducted
comprehensive evaluations of various LLMs proficient in processing and
generating Chinese content, highlighting the potential limitations of general
LLMs as intelligent teaching assistants in computer programming courses.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07914" title="Abstract">arXiv:2402.07914</a> [<a href="/pdf/2402.07914" title="Download PDF">pdf</a>, <a href="/format/2402.07914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Requirements-Driven Visualizations for Big Data Analytics: a  Model-Driven approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lavalle%2C+A">Ana Lavalle</a>, 
<a href="/search/cs?searchtype=author&query=Mat%C3%A9%2C+A">Alejandro Mat&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Trujillo%2C+J">Juan Trujillo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 38th International Conference on Conceptual Modeling (ER 2019)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Choosing the right Visualization techniques is critical in Big Data
Analytics. However, decision makers are not experts on visualization and they
face up with enormous difficulties in doing so. There are currently many
different (i) Big Data sources and also (ii) many different visual analytics to
be chosen. Every visualization technique is not valid for every Big Data source
and is not adequate for every context. In order to tackle this problem, we
propose an approach, based on the Model Driven Architecture (MDA) to facilitate
the selection of the right visual analytics to non-expert users. The approach
is based on three different models: (i) a requirements model based on
goal-oriented modeling for representing information requirements, (ii) a data
representation model for representing data which will be connected to
visualizations and, (iii) a visualization model for representing visualization
details regardless of their implementation technology. Together with these
models, a set of transformations allow us to semi-automatically obtain the
corresponding implementation avoiding the intervention of the non-expert users.
In this way, the great advantage of our proposal is that users no longer need
to focus on the characteristics of the visualization, but rather, they focus on
their information requirements and obtain the visualization that is better
suited for their needs. We show the applicability of our proposal through a
case study focused on a tax collection organization from a real project
developed by the Spin-off company Lucentia Lab.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07915" title="Abstract">arXiv:2402.07915</a> [<a href="/pdf/2402.07915" title="Download PDF">pdf</a>, <a href="/ps/2402.07915" title="Download PostScript">ps</a>, <a href="/format/2402.07915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Research on Older Adults&#x27; Interaction with E-Health Interface Based on  Explainable Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xueting Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhibo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+F">Fusen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xianghao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+K">Kun Chi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kexin Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper proposed a comprehensive mixed-methods framework with varied
samples of older adults, including user experience, usability assessments, and
in-depth interviews with the integration of Explainable Artificial Intelligence
(XAI) methods. The experience of older adults' interaction with the Ehealth
interface is collected through interviews and transformed into operatable
databases whereas XAI methods are utilized to explain the collected interview
results in this research work. The results show that XAI-infused e-health
interfaces could play an important role in bridging the age-related digital
divide by investigating elders' preferences when interacting with E-health
interfaces. Furthermore, the study identifies important design factors, such as
intuitive visualization and straightforward explanations, that are critical for
creating efficient Human Computer Interaction (HCI) tools among older users.
Furthermore, this study emphasizes the revolutionary potential of XAI in
e-health interfaces for older users, emphasizing the importance of transparency
and understandability in HCI-driven healthcare solutions. This study's findings
have far-reaching implications for the design and development of user-centric
e-health technologies, intending to increase the overall well-being of older
adults.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07916" title="Abstract">arXiv:2402.07916</a> [<a href="/pdf/2402.07916" title="Download PDF">pdf</a>, <a href="/format/2402.07916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perceptual Thresholds for Radial Optic Flow Distortion in Near-Eye  Stereoscopic Displays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saeedpour-Parizi%2C+M+R">Mohammad R. Saeedpour-Parizi</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+N+L">Niall L. Williams</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+T">Tim Wong</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+P">Phillip Guan</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>, 
<a href="/search/cs?searchtype=author&query=Erkelens%2C+I+M">Ian M. Erkelens</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We provide the first perceptual quantification of user's sensitivity to
radial optic flow artifacts and demonstrate a promising approach for masking
this optic flow artifact via blink suppression. Near-eye HMDs allow users to
feel immersed in virtual environments by providing visual cues, like motion
parallax and stereoscopy, that mimic how we view the physical world. However,
these systems exhibit a variety of perceptual artifacts that can limit their
usability and the user's sense of presence in VR. One well-known artifact is
the vergence-accommodation conflict (VAC). Varifocal displays can mitigate VAC,
but bring with them other artifacts such as a change in virtual image size
(radial optic flow) when the focal plane changes. We conducted a set of
psychophysical studies to measure users' ability to perceive this radial flow
artifact before, during, and after self-initiated blinks. Our results showed
that visual sensitivity was reduced by a factor of 10 at the start and for ~70
ms after a blink was detected. Pre- and post-blink sensitivity was, on average,
~0.15% image size change during normal viewing and increased to ~1.5-2.0%
during blinks. Our results imply that a rapid (under 70 ms) radial optic flow
distortion can go unnoticed during a blink. Furthermore, our results provide
empirical data that can be used to inform engineering requirements for both
hardware design and software-based graphical correction algorithms for future
varifocal near-eye displays. Our project website is available at
https://gamma.umd.edu/RoF/.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07917" title="Abstract">arXiv:2402.07917</a> [<a href="/pdf/2402.07917" title="Download PDF">pdf</a>, <a href="/ps/2402.07917" title="Download PostScript">ps</a>, <a href="/format/2402.07917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smart Water Irrigation for Rice Farming through the Internet of Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Binayao%2C+R+P">Regie Porras Binayao</a>, 
<a href="/search/cs?searchtype=author&query=Mantua%2C+P+V+L">Paul Vincent Lagapa Mantua</a>, 
<a href="/search/cs?searchtype=author&query=Namocatcat%2C+H+R+M+P">Holy Rose May Pardillo Namocatcat</a>, 
<a href="/search/cs?searchtype=author&query=Seroy%2C+J+K+K+B">Jade Kachel Klient Bocboc Seroy</a>, 
<a href="/search/cs?searchtype=author&query=Sudaria%2C+P+R+A+B">Phoebe Ruth Alithea Bacotot Sudaria</a>, 
<a href="/search/cs?searchtype=author&query=Gumonan%2C+K+M+V+C">Kenn Migan Vincent Casicas Gumonan</a>, 
<a href="/search/cs?searchtype=author&query=Orozco%2C+S+M+M">Shiela Mae Malbas Orozco</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures, 1 table
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Computing Sciences Research, 8, 2550-2563
  (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This study intends to build smart water irrigation for rice farming using IoT
and microcontroller devices with solar panel support. The system demonstrates
the capabilities of automated irrigation by reducing physical labor through
smart monitoring of the temperature, soil moisture, and humidity using multiple
sensors. This study uses an agile methodology as it is suitable for reiterative
operation for the development of the prototype. The mean result for the
interpretation of data gathered for the systems' adaptability and flexibility
is 4.32. The researchers were able to develop smart water irrigation for rice
farming using IoT and microcontroller devices with solar panel support and the
respondents also agreed that Smart water irrigation for rice farming using IoT
and microcontroller devices with solar panel support is practical and valuable.
A decision support system is recommended that can analyze data collected from
IoT sensors and provide further recommendations. Based on the results, it is
also suggested that future researchers use drip irrigation, instead of flood
irrigation. Smart water irrigation has the potential to revolutionize
agriculture, enhance environmental sustainability, and address pressing global
challenges related to water resources and food security. These implications
highlight the importance of continued research and innovation in this field.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07919" title="Abstract">arXiv:2402.07919</a> [<a href="/pdf/2402.07919" title="Download PDF">pdf</a>, <a href="/ps/2402.07919" title="Download PostScript">ps</a>, <a href="/format/2402.07919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Can Generative AI Enhance the Well-being of Blind?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bendel%2C+O">Oliver Bendel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper examines the question of how generative AI can improve the
well-being of blind or visually impaired people. It refers to a current
example, the Be My Eyes app, in which the Be My AI feature was integrated in
2023, which is based on GPT-4 from OpenAI. The author's tests are described and
evaluated. There is also an ethical and social discussion. The power of the
tool, which can analyze still images in an amazing way, is demonstrated. Those
affected gain a new independence and a new perception of their environment. At
the same time, they are dependent on the world view and morality of the
provider or developer, who prescribe or deny them certain descriptions. An
outlook makes it clear that the analysis of moving images will mean a further
leap forward. It is fair to say that generative AI can fundamentally improve
the well-being of blind and visually impaired people and will change it in
various ways.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07920" title="Abstract">arXiv:2402.07920</a> [<a href="/pdf/2402.07920" title="Download PDF">pdf</a>, <a href="/ps/2402.07920" title="Download PostScript">ps</a>, <a href="/format/2402.07920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring patient trust in clinical advice from AI-driven LLMs like  ChatGPT for self-diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+D">Delong Du</a>, 
<a href="/search/cs?searchtype=author&query=Paluch%2C+R">Richard Paluch</a>, 
<a href="/search/cs?searchtype=author&query=Stevens%2C+G">Gunnar Stevens</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+C">Claudia M&#xfc;ller</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference Trusting in Care Technology, February
  15/16, 2024, Delmenhorst, Germany
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Trustworthy clinical advice is crucial but burdensome when seeking health
support from professionals. Inaccessibility and financial burdens present
obstacles to obtaining professional clinical advice, even when healthcare is
available. Consequently, individuals often resort to self-diagnosis, utilizing
medical materials to validate the health conditions of their families and
friends. However, the convenient method of self-diagnosis requires a commitment
to learning and is often not effective, presenting risks when individuals seek
self-care approaches or treatment strategies without professional guidance.
Artificial Intelligence (AI), supported by Large Language Models (LLM), may
become a powerful yet risky self-diagnosis tool for clinical advice due to the
hallucination of LLM, where it produces inaccurate yet deceiving information.
Thus, can we trust the clinical advice from AI-driven LLMs like ChatGPT like
ChatGPT4 for self-diagnosis? We examined this issue through a think-aloud
observation: a patient uses GPT4 for self-diagnosis and clinical advice while a
doctor assesses ChatGPT responses with their own expertise. After that, we
conducted a semi-structured interview with the patient to understand their
trust in AI-driven LLMs for clinical advice. we have concluded that the
confounding factors influencing a patient's trust revolve around their
competency-evaluation. Essentially, trust is equated with efficacy, which is
determined by whether decisions made based on the AI agent's clinical advice
and suggestion will effectively achieve the patient health goals. Patients tend
to trust doctors more than AI agents due to this strategy, believing that
educated, authorized doctors can provide effective medical guidance. This
competency-based trust also explains why patients often perceive more
experienced doctors as more trustworthy compared to less experienced ones.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07922" title="Abstract">arXiv:2402.07922</a> [<a href="/pdf/2402.07922" title="Download PDF">pdf</a>, <a href="/format/2402.07922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards the Human Digital Twin: Definition and Design -- A survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lauer-Schmaltz%2C+M+W">Martin Wolfgang Lauer-Schmaltz</a>, 
<a href="/search/cs?searchtype=author&query=Cash%2C+P">Philip Cash</a>, 
<a href="/search/cs?searchtype=author&query=Hansen%2C+J+P">John Paulin Hansen</a>, 
<a href="/search/cs?searchtype=author&query=Maier%2C+A">Anja Maier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is an extension of the following paper: Lauer-Schmaltz MW, Cash P, Hansen JP, Maier A. Designing Human Digital Twins for Behaviour-Changing Therapy and Rehabilitation: A Systematic Review. Proceedings of the Design Society. 2022;2:1303-1312. doi:10.1017/pds.2022.132
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB)

</div>
<p class="mathjax">Human Digital Twins (HDTs) are a fast-emerging technology with significant
potential in fields ranging from healthcare to sports. HDTs extend the
traditional understanding of Digital Twins by representing humans as the
underlying physical entity. This has introduced several significant challenges,
including ambiguity in the definition of HDTs and a lack of guidance for their
design. This survey brings together the recent advances in the field of HDTs to
guide future developers by proposing a first cross-domain definition of HDTs
based on their characteristics, as well as eleven key design considerations
that emerge from the associated challenges.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07923" title="Abstract">arXiv:2402.07923</a> [<a href="/pdf/2402.07923" title="Download PDF">pdf</a>, <a href="/ps/2402.07923" title="Download PostScript">ps</a>, <a href="/format/2402.07923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> eHealth Intervention to Improve Health Habits in the Adolescent  Population: Mixed Methods Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Benavides%2C+C">Carmen Benavides</a>, 
<a href="/search/cs?searchtype=author&query=Ben%C3%ADtez-Andrades%2C+J+A">Jos&#xe9; Alberto Ben&#xed;tez-Andrades</a>, 
<a href="/search/cs?searchtype=author&query=Marqu%C3%A9s-S%C3%A1nchez%2C+P">Pilar Marqu&#xe9;s-S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Arias%2C+N">Natalia Arias</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> JMIR mHealth and uHealth, Volume 9, Issue 2, February 2021, e20217
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Background: Technology has provided a new way of life for adolescents.
Strategies aimed at improving health behaviors through digital platforms can
offer promising results. However, since peers can modify behaviors related to
food and exercise, studying digital interventions based on peer influence to
improve weight status of adolescents is important.
<br />Objective: To assess an eHealth app's effectiveness in adolescent population
improvements in age- and sex-adjusted BMI percentiles. The study also examined
social relationships of adolescents pre- and postintervention, identifying
group leaders to study their profiles, eating, physical activity habits, and
app usage.
<br />Methods: BMI percentiles were calculated following World Health Organization
guidelines. Participants' diets and physical activity levels were assessed
using the KIDMED questionnaire and PAQ-A. Social network variables were
analyzed using SNA methodology, with reciprocal friendships used to compute the
"degree" measure for centrality.
<br />Results: The sample included 210 individuals in the intervention group and 91
in the control group, with a 60.1% participation rate. Adolescents in the
intervention group modified their BMI toward the 50th percentile, improving
diet and increasing social network postintervention. Group leaders were also
leaders in physical activity and app usage.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07924" title="Abstract">arXiv:2402.07924</a> [<a href="/pdf/2402.07924" title="Download PDF">pdf</a>, <a href="/format/2402.07924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IllusionX: An LLM-powered mixed reality personal companion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yousri%2C+R">Ramez Yousri</a>, 
<a href="/search/cs?searchtype=author&query=Essam%2C+Z">Zeyad Essam</a>, 
<a href="/search/cs?searchtype=author&query=Kareem%2C+Y">Yehia Kareem</a>, 
<a href="/search/cs?searchtype=author&query=Sherief%2C+Y">Youstina Sherief</a>, 
<a href="/search/cs?searchtype=author&query=Gamil%2C+S">Sherry Gamil</a>, 
<a href="/search/cs?searchtype=author&query=Safwat%2C+S">Soha Safwat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Mixed Reality (MR) and Artificial Intelligence (AI) are increasingly becoming
integral parts of our daily lives. Their applications range in fields from
healthcare to education to entertainment. MR has opened a new frontier for such
fields as well as new methods of enhancing user engagement. In this paper, We
propose a new system one that combines the power of Large Language Models
(LLMs) and mixed reality (MR) to provide a personalized companion for
educational purposes. We present an overview of its structure and components as
well tests to measure its performance. We found that our system is better in
generating coherent information, however it's rather limited by the documents
provided to it. This interdisciplinary approach aims to provide a better user
experience and enhance user engagement. The user can interact with the system
through a custom-design smart watch, smart glasses and a mobile app.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07925" title="Abstract">arXiv:2402.07925</a> [<a href="/pdf/2402.07925" title="Download PDF">pdf</a>, <a href="/format/2402.07925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point and Instruct: Enabling Precise Image Editing by Unifying Direct  Manipulation and Text Instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Helbling%2C+A">Alec Helbling</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seongmin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Chau%2C+P">Polo Chau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Machine learning has enabled the development of powerful systems capable of
editing images from natural language instructions. However, in many common
scenarios it is difficult for users to specify precise image transformations
with text alone. For example, in an image with several dogs, it is difficult to
select a particular dog and move it to a precise location. Doing this with text
alone would require a complex prompt that disambiguates the target dog and
describes the destination. However, direct manipulation is well suited to
visual tasks like selecting objects and specifying locations. We introduce
Point and Instruct, a system for seamlessly combining familiar direct
manipulation and textual instructions to enable precise image manipulation.
With our system, a user can visually mark objects and locations, and reference
them in textual instructions. This allows users to benefit from both the visual
descriptiveness of natural language and the spatial precision of direct
manipulation.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07926" title="Abstract">arXiv:2402.07926</a> [<a href="/pdf/2402.07926" title="Download PDF">pdf</a>, <a href="/ps/2402.07926" title="Download PostScript">ps</a>, <a href="/format/2402.07926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Data Creator to Data Reuser: Distance Matters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borgman%2C+C+L">Christine L. Borgman</a>, 
<a href="/search/cs?searchtype=author&query=Groth%2C+P+T">Paul T. Groth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, consisting of Table of Contents, Abstract, 20 page narrative, 1 box, 10 pages references. Original work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY); Digital Libraries (cs.DL); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Sharing research data is complex, labor-intensive, expensive, and requires
infrastructure investments by multiple stakeholders. Open science policies
focus on data release rather than on data reuse, yet reuse is also difficult,
expensive, and may never occur. Investments in data management could be made
more wisely by considering who might reuse data, how, why, for what purposes,
and when. Data creators cannot anticipate all possible reuses or reusers; our
goal is to identify factors that may aid stakeholders in deciding how to invest
in research data, how to identify potential reuses and reusers, and how to
improve data exchange processes. Drawing upon empirical studies of data sharing
and reuse, we develop the theoretical construct of distance between data
creator and data reuser, identifying six distance dimensions that influence the
ability to transfer knowledge effectively: domain, methods, collaboration,
curation, purposes, and time and temporality. These dimensions are primarily
social in character, with associated technical aspects that can decrease - or
increase - distances between creators and reusers. We identify the order of
expected influence on data reuse and ways in which the six dimensions are
interdependent. Our theoretical framing of the distance between data creators
and prospective reusers leads to recommendations to four categories of
stakeholders on how to make data sharing and reuse more effective: data
creators, data reusers, data archivists, and funding agencies.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07927" title="Abstract">arXiv:2402.07927</a> [<a href="/pdf/2402.07927" title="Download PDF">pdf</a>, <a href="/format/2402.07927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Systematic Survey of Prompt Engineering in Large Language Models:  Techniques and Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahoo%2C+P">Pranab Sahoo</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A+K">Ayush Kumar Singh</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Sriparna Saha</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+V">Vinija Jain</a>, 
<a href="/search/cs?searchtype=author&query=Mondal%2C+S">Samrat Mondal</a>, 
<a href="/search/cs?searchtype=author&query=Chadha%2C+A">Aman Chadha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Prompt engineering has emerged as an indispensable technique for extending
the capabilities of large language models (LLMs) and vision-language models
(VLMs). This approach leverages task-specific instructions, known as prompts,
to enhance model efficacy without modifying the core model parameters. Rather
than updating the model parameters, prompts allow seamless integration of
pre-trained models into downstream tasks by eliciting desired model behaviors
solely based on the given prompt. Prompts can be natural language instructions
that provide context to guide the model or learned vector representations that
activate relevant knowledge. This burgeoning field has enabled success across
various applications, from question-answering to commonsense reasoning.
However, there remains a lack of systematic organization and understanding of
the diverse prompt engineering methods and techniques. This survey paper
addresses the gap by providing a structured overview of recent advancements in
prompt engineering, categorized by application area. For each prompting
approach, we provide a summary detailing the prompting methodology, its
applications, the models involved, and the datasets utilized. We also delve
into the strengths and limitations of each approach and include a taxonomy
diagram and table summarizing datasets, models, and critical points of each
prompting technique. This systematic analysis enables a better understanding of
this rapidly developing field and facilitates future research by illuminating
open challenges and opportunities for prompt engineering.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07928" title="Abstract">arXiv:2402.07928</a> [<a href="/pdf/2402.07928" title="Download PDF">pdf</a>, <a href="/format/2402.07928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Abstracted Trajectory Visualization for Explainability in Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Takagi%2C+Y">Yoshiki Takagi</a>, 
<a href="/search/cs?searchtype=author&query=Tabalba%2C+R">Roderick Tabalba</a>, 
<a href="/search/cs?searchtype=author&query=Kirshenbaum%2C+N">Nurit Kirshenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Leigh%2C+J">Jason Leigh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14pages, 11figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Explainable AI (XAI) has demonstrated the potential to help reinforcement
learning (RL) practitioners to understand how RL models work. However, XAI for
users who do not have RL expertise (non-RL experts), has not been studied
sufficiently. This results in a difficulty for the non-RL experts to
participate in the fundamental discussion of how RL models should be designed
for an incoming society where humans and AI coexist. Solving such a problem
would enable RL experts to communicate with the non-RL experts in producing
machine learning solutions that better fit our society. We argue that
abstracted trajectories, that depicts transitions between the major states of
the RL model, will be useful for non-RL experts to build a mental model of the
agents. Our early results suggest that by leveraging a visualization of the
abstracted trajectories, users without RL expertise are able to infer the
behavior patterns of RL.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07932" title="Abstract">arXiv:2402.07932</a> [<a href="/pdf/2402.07932" title="Download PDF">pdf</a>, <a href="/ps/2402.07932" title="Download PostScript">ps</a>, <a href="/format/2402.07932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Human-Machine Collaboration Framework for the Development of Schemas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Isaak%2C+N">Nicos Isaak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">The Winograd Schema Challenge (WSC), a seemingly well-thought-out test for
machine intelligence, has been proposed to shed light on developing systems
that exhibit human behavior. Since its introduction, it aimed to pivot the
focus of the AI community from the technology to the science of AI. While
common and trivial for humans, studies show that it is still challenging for
machines, especially when they have to deal with novel schemas, that is,
well-designed sentences that require the resolving of definite pronouns. As
researchers have become increasingly interested in the challenge itself, this
presumably necessitates the availability of an extensive collection of Winograd
schemas, which goes beyond what human experts can reasonably develop
themselves, especially after proposed ways of utilizing them as novel forms of
CAPTCHAs.
<br />To address this necessity, we propose a novel framework that explicitly
focuses on how humans and machines can collaborate as teammates to design novel
schemas from scratch. This is being accomplished by combining two recent
studies from the literature: i) Winventor, a machine-driven approach for the
development of large amounts of Winograd schemas, albeit not of high quality,
and ii) WinoFlexi, an online crowdsourcing system that allows crowd workers to
develop a limited number of schemas often of similar quality to that of
experts. Our proposal crafts a new road map toward developing a novel
collaborative platform that amplifies human and machine intelligence by
combining their complementary strengths.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07933" title="Abstract">arXiv:2402.07933</a> [<a href="/pdf/2402.07933" title="Download PDF">pdf</a>, <a href="/ps/2402.07933" title="Download PostScript">ps</a>, <a href="/format/2402.07933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-Centered AI Product Prototyping with No-Code AutoML: Conceptual  Framework, Potentials and Limitations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Truss%2C+M">Mario Truss</a>, 
<a href="/search/cs?searchtype=author&query=Schmitt%2C+M">Marc Schmitt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
<p class="mathjax">This paper evaluates No-Code AutoML as a solution for challenges in AI
product prototyping, characterized by unpredictability and inaccessibility to
non-experts, and proposes a conceptual framework. This complexity of AI
products hinders seamless execution and interdisciplinary collaboration crucial
for human-centered AI products. Relevant to industry and innovation, it affects
strategic decision-making and investment risk mitigation. Current approaches
provide limited insights into the potential and feasibility of AI product
ideas. Employing Design Science Research, the study identifies challenges and
integrates no-code AutoML as a solution by presenting a framework for AI
product prototyping with No-code AutoML. A case study confirms its potential in
supporting non-experts, offering a structured approach to AI product
development. The framework facilitates accessible and interpretable
prototyping, benefiting academia, managers, and decision-makers. Strategic
integration of no-code AutoML enhances efficiency, empowers non-experts, and
informs early-stage decisions, albeit with acknowledged limitations.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07936" title="Abstract">arXiv:2402.07936</a> [<a href="/pdf/2402.07936" title="Download PDF">pdf</a>, <a href="/format/2402.07936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Design and Organization of Educational Competitions with Anonymous  and Real-Time Leaderboards in Academic and Industrial Settings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kad%C4%B1o%C4%9Flu%2C+S">Serdar Kad&#x131;o&#x11f;lu</a>, 
<a href="/search/cs?searchtype=author&query=Kleynhans%2C+B">Bernard Kleynhans</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI-EAAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The goal of this paper is to share our experience in designing and organizing
educational competitions with anonymous and (near) real-time leaderboards in
both academic and industrial settings. While such competitions serve as a great
educational tool and provide participants with hands-on experience, they
require significant planning, technical setup, and administration from
organizers. In this paper, we first outline several important areas including
team registration, data access, submission systems, rules and conditions that
organizers should consider when planning such events. We then present a
high-level system design that can support (near) real-time evaluation of
submissions to power anonymous leaderboards and provide immediate feedback for
participants. Finally, we share our experience applying this abstract system in
academic and industrial settings. We hope the set of guidelines and the
high-level system design proposed here help others in their organization of
similar educational events.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07937" title="Abstract">arXiv:2402.07937</a> [<a href="/pdf/2402.07937" title="Download PDF">pdf</a>, <a href="/ps/2402.07937" title="Download PostScript">ps</a>, <a href="/format/2402.07937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Physiological Sensor-Based Android Application Synchronized with a  Driving Simulator for Driver Monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez-Ortega%2C+D">David Gonz&#xe1;lez-Ortega</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Pernas%2C+F+J">Francisco Javier D&#xed;az-Pernas</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez-Zarzuela%2C+M">Mario Mart&#xed;nez-Zarzuela</a>, 
<a href="/search/cs?searchtype=author&query=Ant%C3%B3n-Rodr%C3%ADguez%2C+M">M&#xed;riam Ant&#xf3;n-Rodr&#xed;guez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sensors 2019, 19, 399
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we present an Android application to control and monitor the
physiological sensors from the Shimmer platform and its synchronized working
with a driving simulator. The Android app can monitor drivers and their
parameters can be used to analyze the relation between their physiological
states and driving performance. The app can configure, select, receive,
process, represent graphically, and store the signals from electrocardiogram
(ECG), electromyogram (EMG) and galvanic skin response (GSR) modules and
accelerometers, a magnetometer and a gyroscope. The Android app is synchronized
in two steps with a driving simulator that we previously developed using the
Unity game engine to analyze driving security and efficiency. The Android app
was tested with different sensors working simultaneously at various sampling
rates and in different Android devices. We also tested the synchronized working
of the driving simulator and the Android app with 25 people and analyzed the
relation between data from the ECG, EMG, GSR, and gyroscope sensors and from
the simulator. Among others, some significant correlations between a
gyroscope-based feature calculated by the Android app and vehicle data and
particular traffic offences were found. The Android app can be applied with
minor adaptations to other different users such as patients with chronic
diseases or athletes.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07938" title="Abstract">arXiv:2402.07938</a> [<a href="/pdf/2402.07938" title="Download PDF">pdf</a>, <a href="/format/2402.07938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language User Interfaces: Voice Interactive User Interfaces  powered by LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wasti%2C+S+M">Syed Mekael Wasti</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+K+Q">Ken Q. Pu</a>, 
<a href="/search/cs?searchtype=author&query=Neshati%2C+A">Ali Neshati</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to peer review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">The recent meteoric advancements in large language models have showcased a
remarkable capacity for logical reasoning and comprehension. These newfound
capabilities have opened the door to a new generation of software, as has been
made obvious through the innumerable ways they are being applied in the
industry. This research focuses on harnessing and guiding the upgraded power of
LLMs to construct a framework that can serve as an intermediary between a user
and their user interface. By comprehending a user's needs through a thorough
analysis of natural textual inputs, an effectively crafted LLM engine can
classify the most likely available application, identify the desired UI
component and subsequently execute the user's expected actions. This
integration can evolve static UI systems into highly dynamic and adaptable
solutions, introducing a new frontier of intelligent and responsive user
experiences. Such a framework can fundamentally shift how users accomplish
daily tasks, skyrocket efficiency, and greatly reduce cognitive load.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07939" title="Abstract">arXiv:2402.07939</a> [<a href="/pdf/2402.07939" title="Download PDF">pdf</a>, <a href="/format/2402.07939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UFO: A UI-Focused Agent for Windows OS Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoyun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liqun Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shilin He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+B">Bo Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+S">Si Qin</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+M">Minghua Ma</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yu Kang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qingwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Rajmohan%2C+S">Saravan Rajmohan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">We introduce UFO, an innovative UI-Focused agent to fulfill user requests
tailored to applications on Windows OS, harnessing the capabilities of
GPT-Vision. UFO employs a dual-agent framework to meticulously observe and
analyze the graphical user interface (GUI) and control information of Windows
applications. This enables the agent to seamlessly navigate and operate within
individual applications and across them to fulfill user requests, even when
spanning multiple applications. The framework incorporates a control
interaction module, facilitating action grounding without human intervention
and enabling fully automated execution. Consequently, UFO transforms arduous
and time-consuming processes into simple tasks achievable solely through
natural language commands. We conducted testing of UFO across 9 popular Windows
applications, encompassing a variety of scenarios reflective of users' daily
usage. The results, derived from both quantitative metrics and real-case
studies, underscore the superior effectiveness of UFO in fulfilling user
requests. To the best of our knowledge, UFO stands as the first UI agent
specifically tailored for task completion within the Windows OS environment.
The open-source code for UFO is available on https://github.com/microsoft/UFO.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07940" title="Abstract">arXiv:2402.07940</a> [<a href="/pdf/2402.07940" title="Download PDF">pdf</a>, <a href="/ps/2402.07940" title="Download PostScript">ps</a>, <a href="/format/2402.07940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMs Among Us: Generative AI Participating in Digital Discourse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Radivojevic%2C+K">Kristina Radivojevic</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+N">Nicholas Clark</a>, 
<a href="/search/cs?searchtype=author&query=Brenner%2C+P">Paul Brenner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The emergence of Large Language Models (LLMs) has great potential to reshape
the landscape of many social media platforms. While this can bring promising
opportunities, it also raises many threats, such as biases and privacy
concerns, and may contribute to the spread of propaganda by malicious actors.
We developed the "LLMs Among Us" experimental framework on top of the Mastodon
social media platform for bot and human participants to communicate without
knowing the ratio or nature of bot and human participants. We built 10 personas
with three different LLMs, GPT-4, LLama 2 Chat, and Claude. We conducted three
rounds of the experiment and surveyed participants after each round to measure
the ability of LLMs to pose as human participants without human detection. We
found that participants correctly identified the nature of other users in the
experiment only 42% of the time despite knowing the presence of both bots and
humans. We also found that the choice of persona had substantially more impact
on human perception than the choice of mainstream LLMs.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07945" title="Abstract">arXiv:2402.07945</a> [<a href="/pdf/2402.07945" title="Download PDF">pdf</a>, <a href="/format/2402.07945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ScreenAgent: A Vision Language Model-driven Computer Control Agent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+R">Runliang Niu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jindong Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yali Fu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiyu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Leng%2C+X">Xueyuan Leng</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+H">He Kong</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yi Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Existing Large Language Models (LLM) can invoke a variety of tools and APIs
to complete complex tasks. The computer, as the most powerful and universal
tool, could potentially be controlled directly by a trained LLM agent. Powered
by the computer, we can hopefully build a more generalized agent to assist
humans in various daily digital works. In this paper, we construct an
environment for a Vision Language Model (VLM) agent to interact with a real
computer screen. Within this environment, the agent can observe screenshots and
manipulate the Graphics User Interface (GUI) by outputting mouse and keyboard
actions. We also design an automated control pipeline that includes planning,
acting, and reflecting phases, guiding the agent to continuously interact with
the environment and complete multi-step tasks. Additionally, we construct the
ScreenAgent Dataset, which collects screenshots and action sequences when
completing a variety of daily computer tasks. Finally, we trained a model,
ScreenAgent, which achieved computer control capabilities comparable to GPT-4V
and demonstrated more precise UI positioning capabilities. Our attempts could
inspire further research on building a generalist LLM agent. The code is
available at \url{https://github.com/niuzaisheng/ScreenAgent}.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07946" title="Abstract">arXiv:2402.07946</a> [<a href="/pdf/2402.07946" title="Download PDF">pdf</a>, <a href="/ps/2402.07946" title="Download PostScript">ps</a>, <a href="/format/2402.07946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Re-Envisioning Command and Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McDowell%2C+K">Kaleb McDowell</a>, 
<a href="/search/cs?searchtype=author&query=Novoseller%2C+E">Ellen Novoseller</a>, 
<a href="/search/cs?searchtype=author&query=Madison%2C+A">Anna Madison</a>, 
<a href="/search/cs?searchtype=author&query=Goecks%2C+V+G">Vinicius G. Goecks</a>, 
<a href="/search/cs?searchtype=author&query=Kelshaw%2C+C">Christopher Kelshaw</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the NATO Science and Technology Organization Symposium (ICMCIS) organized by the Information Systems Technology (IST) Panel, IST-205-RSY - the ICMCIS, held in Koblenz, Germany, 23-24 April 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Future warfare will require Command and Control (C2) decision-making to occur
in more complex, fast-paced, ill-structured, and demanding conditions. C2 will
be further complicated by operational challenges such as Denied, Degraded,
Intermittent, and Limited (DDIL) communications and the need to account for
many data streams, potentially across multiple domains of operation. Yet,
current C2 practices -- which stem from the industrial era rather than the
emerging intelligence era -- are linear and time-consuming. Critically, these
approaches may fail to maintain overmatch against adversaries on the future
battlefield. To address these challenges, we propose a vision for future C2
based on robust partnerships between humans and artificial intelligence (AI)
systems. This future vision is encapsulated in three operational impacts:
streamlining the C2 operations process, maintaining unity of effort, and
developing adaptive collective knowledge systems. This paper illustrates the
envisaged future C2 capabilities, discusses the assumptions that shaped them,
and describes how the proposed developments could transform C2 in future
warfare.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07950" title="Abstract">arXiv:2402.07950</a> [<a href="/pdf/2402.07950" title="Download PDF">pdf</a>, <a href="/format/2402.07950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sentinels of the Stream: Unleashing Large Language Models for Dynamic  Packet Classification in Software Defined Networks -- Position Paper
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murtuza%2C+S">Shariq Murtuza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">With the release of OpenAI's ChatGPT, the field of large language models
(LLM) saw an increase of academic interest in GPT based chat assistants. In the
next few months multiple accesible large language models were released that
included Meta's LLama models and Mistral AI's Mistral and Mixtral MoE models.
These models are available openly for a wide array of purposes with a wide
spectrum of licenses. These LLMs have found their use in a different number of
fields like code development, SQL generation etc. In this work we propose our
plan to explore the applicability of large language model in the domain of
network security. We plan to create Sentinel, a LLM, to analyse network packet
contents and pass a judgment on it's threat level. This work is a preliminary
report that will lay our plan for our future endeavors.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07954" title="Abstract">arXiv:2402.07954</a> [<a href="/pdf/2402.07954" title="Download PDF">pdf</a>, <a href="/format/2402.07954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Leaky-Integrate-and Fire as Spike-Train-Quantization Operator on  Dirac-Superimposed Continuous-Time Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moser%2C+B+A">Bernhard A. Moser</a>, 
<a href="/search/cs?searchtype=author&query=Lunglmayr%2C+M">Michael Lunglmayr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2305.08012">arXiv:2305.08012</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Leaky-integrate-and-fire (LIF) is studied as a non-linear operator that maps
an integrable signal $f$ to a sequence $\eta_f$ of discrete events, the spikes.
In the case without any Dirac pulses in the input, it makes no difference
whether to set the neuron's potential to zero or to subtract the threshold
$\vartheta$ immediately after a spike triggering event. However, in the case of
superimpose Dirac pulses the situation is different which raises the question
of a mathematical justification of each of the proposed reset variants. In the
limit case of zero refractory time the standard reset scheme based on threshold
subtraction results in a modulo-based reset scheme which allows to characterize
LIF as a quantization operator based on a weighted Alexiewicz norm $\|.\|_{A,
\alpha}$ with leaky parameter $\alpha$. We prove the quantization formula
$\|\eta_f - f\|_{A, \alpha} &lt; \vartheta$ under the general condition of local
integrability, almost everywhere boundedness and locally finitely many
superimposed weighted Dirac pulses which provides a much larger signal space
and more flexible sparse signal representation than manageable by classical
signal processing.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07956" title="Abstract">arXiv:2402.07956</a> [<a href="/pdf/2402.07956" title="Download PDF">pdf</a>, <a href="/ps/2402.07956" title="Download PostScript">ps</a>, <a href="/format/2402.07956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Educational data mining and learning analytics: An updated survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Romero%2C+C">C. Romero</a>, 
<a href="/search/cs?searchtype=author&query=Ventura%2C+S">S. Ventura</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Wiley interdisciplinary reviews: Data mining and knowledge
  discovery;2020; 10(3):e1355
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This survey is an updated and improved version of the previous one published
in 2013 in this journal with the title data mining in education. It reviews in
a comprehensible and very general way how Educational Data Mining and Learning
Analytics have been applied over educational data. In the last decade, this
research area has evolved enormously and a wide range of related terms are now
used in the bibliography such as Academic Analytics, Institutional Analytics,
Teaching Analytics, Data-Driven Education, Data-Driven Decision-Making in
Education, Big Data in Education, and Educational Data Science. This paper
provides the current state of the art by reviewing the main publications, the
key milestones, the knowledge discovery cycle, the main educational
environments, the specific tools, the free available datasets, the most used
methods, the main objectives, and the future trends in this research area.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07963" title="Abstract">arXiv:2402.07963</a> [<a href="/pdf/2402.07963" title="Download PDF">pdf</a>, <a href="/format/2402.07963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SMX: Sequential Monte Carlo Planning for Expert Iteration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Macfarlane%2C+M+V">Matthew V Macfarlane</a>, 
<a href="/search/cs?searchtype=author&query=Toledo%2C+E">Edan Toledo</a>, 
<a href="/search/cs?searchtype=author&query=Byrne%2C+D">Donal Byrne</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Siddarth Singh</a>, 
<a href="/search/cs?searchtype=author&query=Duckworth%2C+P">Paul Duckworth</a>, 
<a href="/search/cs?searchtype=author&query=Laterre%2C+A">Alexandre Laterre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 5 main figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Developing agents that can leverage planning abilities during their decision
and learning processes is critical to the advancement of Artificial
Intelligence. Recent works have demonstrated the effectiveness of combining
tree-based search methods and self-play learning mechanisms. Yet, these methods
typically face scaling challenges due to the sequential nature of their search.
While practical engineering solutions can partly overcome this, they still
demand extensive computational resources, which hinders their applicability. In
this paper, we introduce SMX, a model-based planning algorithm that utilises
scalable Sequential Monte Carlo methods to create an effective self-learning
mechanism. Grounded in the theoretical framework of control as inference, SMX
benefits from robust theoretical underpinnings. Its sampling-based search
approach makes it adaptable to environments with both discrete and continuous
action spaces. Furthermore, SMX allows for high parallelisation and can run on
hardware accelerators to optimise computing efficiency. SMX demonstrates a
statistically significant improvement in performance compared to AlphaZero, as
well as demonstrating its performance as an improvement operator for a
model-free policy, matching or exceeding top model-free methods across both
continuous and discrete environments.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07967" title="Abstract">arXiv:2402.07967</a> [<a href="/pdf/2402.07967" title="Download PDF">pdf</a>, <a href="/ps/2402.07967" title="Download PostScript">ps</a>, <a href="/format/2402.07967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating MLSecOps in the Biotechnology Industry 5.0
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pervez%2C+N">Naseela Pervez</a>, 
<a href="/search/cs?searchtype=author&query=Titus%2C+A+J">Alexander J. Titus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Biotechnology Industry 5.0 is advancing with the integration of cutting-edge
technologies like Machine Learning (ML), the Internet Of Things (IoT), and
cloud computing. It is no surprise that an industry that utilizes data from
customers and can alter their lives is a target of a variety of attacks. This
chapter provides a perspective of how Machine Learning Security Operations
(MLSecOps) can help secure the biotechnology Industry 5.0. The chapter provides
an analysis of the threats in the biotechnology Industry 5.0 and how ML
algorithms can help secure with industry best practices. This chapter explores
the scope of MLSecOps in the biotechnology Industry 5.0, highlighting how
crucial it is to comply with current regulatory frameworks. With biotechnology
Industry 5.0 developing innovative solutions in healthcare, supply chain
management, biomanufacturing, pharmaceuticals sectors, and more, the chapter
also discusses the MLSecOps best practices that industry and enterprises should
follow while also considering ethical responsibilities. Overall, the chapter
provides a discussion of how to integrate MLSecOps into the design, deployment,
and regulation of the processes in biotechnology Industry 5.0.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07970" title="Abstract">arXiv:2402.07970</a> [<a href="/pdf/2402.07970" title="Download PDF">pdf</a>, <a href="/format/2402.07970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utilizing Low-Dimensional Molecular Embeddings for Rapid Chemical  Similarity Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kirchoff%2C+K+E">Kathryn E. Kirchoff</a>, 
<a href="/search/cs?searchtype=author&query=Wellnitz%2C+J">James Wellnitz</a>, 
<a href="/search/cs?searchtype=author&query=Hochuli%2C+J+E">Joshua E. Hochuli</a>, 
<a href="/search/cs?searchtype=author&query=Maxfield%2C+T">Travis Maxfield</a>, 
<a href="/search/cs?searchtype=author&query=Popov%2C+K+I">Konstantin I. Popov</a>, 
<a href="/search/cs?searchtype=author&query=Gomez%2C+S">Shawn Gomez</a>, 
<a href="/search/cs?searchtype=author&query=Tropsha%2C+A">Alexander Tropsha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Nearest neighbor-based similarity searching is a common task in chemistry,
with notable use cases in drug discovery. Yet, some of the most commonly used
approaches for this task still leverage a brute-force approach. In practice
this can be computationally costly and overly time-consuming, due in part to
the sheer size of modern chemical databases. Previous computational
advancements for this task have generally relied on improvements to hardware or
dataset-specific tricks that lack generalizability. Approaches that leverage
lower-complexity searching algorithms remain relatively underexplored. However,
many of these algorithms are approximate solutions and/or struggle with typical
high-dimensional chemical embeddings. Here we evaluate whether a combination of
low-dimensional chemical embeddings and a k-d tree data structure can achieve
fast nearest neighbor queries while maintaining performance on standard
chemical similarity search benchmarks. We examine different dimensionality
reductions of standard chemical embeddings as well as a learned,
structurally-aware embedding -- SmallSA -- for this task. With this framework,
searches on over one billion chemicals execute in less than a second on a
single CPU core, five orders of magnitude faster than the brute-force approach.
We also demonstrate that SmallSA achieves competitive performance on chemical
similarity benchmarks.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07997" title="Abstract">arXiv:2402.07997</a> [<a href="/pdf/2402.07997" title="Download PDF">pdf</a>, <a href="/format/2402.07997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Compression in the Era of Machine Learning: A Review of  Recent Advances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ozyilkan%2C+E">Ezgi Ozyilkan</a>, 
<a href="/search/cs?searchtype=author&query=Erkip%2C+E">Elza Erkip</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to be appearing at CISS 2024 (invited paper)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Many applications from camera arrays to sensor networks require efficient
compression and processing of correlated data, which in general is collected in
a distributed fashion. While information-theoretic foundations of distributed
compression are well investigated, the impact of theory in practice-oriented
applications to this day has been somewhat limited. As the field of data
compression is undergoing a transformation with the emergence of learning-based
techniques, machine learning is becoming an important tool to reap the
long-promised benefits of distributed compression. In this paper, we review the
recent contributions in the broad area of learned distributed compression
techniques for abstract sources and images. In particular, we discuss
approaches that provide interpretable results operating close to
information-theoretic bounds. We also highlight unresolved research challenges,
aiming to inspire fresh interest and advancements in the field of learned
distributed compression.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07999" title="Abstract">arXiv:2402.07999</a> [<a href="/pdf/2402.07999" title="Download PDF">pdf</a>, <a href="/format/2402.07999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NetInfoF Framework: Measuring and Exploiting Network Usable Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Meng-Chieh Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haiyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ioannidis%2C+V+N">Vassilis N. Ioannidis</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiang Song</a>, 
<a href="/search/cs?searchtype=author&query=Adeshina%2C+S">Soji Adeshina</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Da Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Faloutsos%2C+C">Christos Faloutsos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICLR 2024 (Spotlight)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Given a node-attributed graph, and a graph task (link prediction or node
classification), can we tell if a graph neural network (GNN) will perform well?
More specifically, do the graph structure and the node features carry enough
usable information for the task? Our goals are (1) to develop a fast tool to
measure how much information is in the graph structure and in the node
features, and (2) to exploit the information to solve the task, if there is
enough. We propose NetInfoF, a framework including NetInfoF_Probe and
NetInfoF_Act, for the measurement and the exploitation of network usable
information (NUI), respectively. Given a graph data, NetInfoF_Probe measures
NUI without any model training, and NetInfoF_Act solves link prediction and
node classification, while two modules share the same backbone. In summary,
NetInfoF has following notable advantages: (a) General, handling both link
prediction and node classification; (b) Principled, with theoretical guarantee
and closed-form solution; (c) Effective, thanks to the proposed adjustment to
node similarity; (d) Scalable, scaling linearly with the input size. In our
carefully designed synthetic datasets, NetInfoF correctly identifies the ground
truth of NUI and is the only method being robust to all graph scenarios.
Applied on real-world datasets, NetInfoF wins in 11 out of 12 times on link
prediction compared to general GNN baselines.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08005" title="Abstract">arXiv:2402.08005</a> [<a href="/pdf/2402.08005" title="Download PDF">pdf</a>, <a href="/format/2402.08005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Refined Direct Preference Optimization with Synthetic Data for  Behavioral Alignment of LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gallego%2C+V">V&#xed;ctor Gallego</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-print. Submitted to the ICLR 2024 Workshop on Representational Alignment (Re-Align)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we introduce \emph{refined Direct Preference Optimization}
(rDPO), a method for improving the behavioral alignment of Large Language
Models (LLMs) without the need for human-annotated data. The method involves
creating synthetic data using self-critique prompting by a teacher LLM and then
utilising a generalized DPO loss function to distil to a student LLM. The loss
function incorporates an additional external reward model to improve the
quality of synthetic data, making rDPO robust to potential noise in the
synthetic dataset. rDPO is shown to be effective in a diverse set of
behavioural alignment tasks, such as improved safety, robustness against
role-playing, and reduced sycophancy. Code to be released at
https://github.com/vicgalle/refined-dpo.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08006" title="Abstract">arXiv:2402.08006</a> [<a href="/pdf/2402.08006" title="Download PDF">pdf</a>, <a href="/format/2402.08006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extending 3D body pose estimation for robotic-assistive therapies of  autistic children
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santos%2C+L">Laura Santos</a>, 
<a href="/search/cs?searchtype=author&query=Carvalho%2C+B">Bernardo Carvalho</a>, 
<a href="/search/cs?searchtype=author&query=Barata%2C+C">Catarina Barata</a>, 
<a href="/search/cs?searchtype=author&query=Santos-Victor%2C+J">Jos&#xe9; Santos-Victor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Robotic-assistive therapy has demonstrated very encouraging results for
children with Autism. Accurate estimation of the child's pose is essential both
for human-robot interaction and for therapy assessment purposes. Non-intrusive
methods are the sole viable option since these children are sensitive to touch.
<br />While depth cameras have been used extensively, existing methods face two
major limitations: (i) they are usually trained with adult-only data and do not
correctly estimate a child's pose, and (ii) they fail in scenarios with a high
number of occlusions. Therefore, our goal was to develop a 3D pose estimator
for children, by adapting an existing state-of-the-art 3D body modelling method
and incorporating a linear regression model to fine-tune one of its inputs,
thereby correcting the pose of children's 3D meshes.
<br />In controlled settings, our method has an error below $0.3m$, which is
considered acceptable for this kind of application and lower than current
state-of-the-art methods. In real-world settings, the proposed model performs
similarly to a Kinect depth camera and manages to successfully estimate the 3D
body poses in a much higher number of frames.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08010" title="Abstract">arXiv:2402.08010</a> [<a href="/pdf/2402.08010" title="Download PDF">pdf</a>, <a href="/format/2402.08010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Which Frequencies do CNNs Need? Emergent Bottleneck Structure in Feature  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yuxiao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Jacot%2C+A">Arthur Jacot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">We describe the emergence of a Convolution Bottleneck (CBN) structure in
CNNs, where the network uses its first few layers to transform the input
representation into a representation that is supported only along a few
frequencies and channels, before using the last few layers to map back to the
outputs. We define the CBN rank, which describes the number and type of
frequencies that are kept inside the bottleneck, and partially prove that the
parameter norm required to represent a function $f$ scales as depth times the
CBN rank $f$. We also show that the parameter norm depends at next order on the
regularity of $f$. We show that any network with almost optimal parameter norm
will exhibit a CBN structure in both the weights and - under the assumption
that the network is stable under large learning rate - the activations, which
motivates the common practice of down-sampling; and we verify that the CBN
results still hold with down-sampling. Finally we use the CBN structure to
interpret the functions learned by CNNs on a number of tasks.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08011" title="Abstract">arXiv:2402.08011</a> [<a href="/pdf/2402.08011" title="Download PDF">pdf</a>, <a href="/format/2402.08011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On The Nature Of The Phenotype In Tree Genetic Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banzhaf%2C+W">Wolfgang Banzhaf</a>, 
<a href="/search/cs?searchtype=author&query=Bakurov%2C+I">Illya Bakurov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">In this contribution, we discuss the basic concepts of genotypes and
phenotypes in tree-based GP (TGP), and then analyze their behavior using five
benchmark datasets. We show that TGP exhibits the same behavior that we can
observe in other GP representations: At the genotypic level trees show
frequently unchecked growth with seemingly ineffective code, but on the
phenotypic level, much smaller trees can be observed. To generate phenotypes,
we provide a unique technique for removing semantically ineffective code from
GP trees. The approach extracts considerably simpler phenotypes while not being
limited to local operations in the genotype. We generalize this transformation
based on a problem-independent parameter that enables a further simplification
of the exact phenotype by coarse-graining to produce approximate phenotypes.
The concept of these phenotypes (exact and approximate) allows us to clarify
what evolved solutions truly predict, making GP models considered at the
phenotypic level much better interpretable.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08015" title="Abstract">arXiv:2402.08015</a> [<a href="/pdf/2402.08015" title="Download PDF">pdf</a>, <a href="/format/2402.08015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Amharic-LLaMA: Integrating Task Specific and Generative  Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azime%2C+I+A">Israel Abebe Azime</a>, 
<a href="/search/cs?searchtype=author&query=Fuge%2C+M+Y">Mitiku Yohannes Fuge</a>, 
<a href="/search/cs?searchtype=author&query=Tonja%2C+A+L">Atnafu Lambebo Tonja</a>, 
<a href="/search/cs?searchtype=author&query=Belay%2C+T+D">Tadesse Destaw Belay</a>, 
<a href="/search/cs?searchtype=author&query=Wassie%2C+A+K">Aman Kassahun Wassie</a>, 
<a href="/search/cs?searchtype=author&query=Jada%2C+E+S">Eyasu Shiferaw Jada</a>, 
<a href="/search/cs?searchtype=author&query=Chanie%2C+Y">Yonas Chanie</a>, 
<a href="/search/cs?searchtype=author&query=Sewunetie%2C+W+T">Walelign Tewabe Sewunetie</a>, 
<a href="/search/cs?searchtype=author&query=Yimam%2C+S+M">Seid Muhie Yimam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have received a lot of attention in natural
language processing (NLP) research because of their exceptional performance in
understanding and generating human languages. However, low-resource languages
are left behind due to the unavailability of resources. In this work, we focus
on enhancing the LLaMA-2-Amharic model by integrating task-specific and
generative datasets to improve language model performance for Amharic. We
compile an Amharic instruction fine-tuning dataset and fine-tuned
LLaMA-2-Amharic model. The fine-tuned model shows promising results in
different NLP tasks. We open-source our dataset creation pipeline, instruction
datasets, trained models, and evaluation outputs to promote language-specific
studies on these models.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08017" title="Abstract">arXiv:2402.08017</a> [<a href="/pdf/2402.08017" title="Download PDF">pdf</a>, <a href="/format/2402.08017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lumos : Empowering Multimodal LLMs with Scene Text Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shenoy%2C+A">Ashish Shenoy</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yichao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Jayakumar%2C+S">Srihari Jayakumar</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+D">Debojeet Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Moslehpour%2C+M">Mohsen Moslehpour</a>, 
<a href="/search/cs?searchtype=author&query=Chuang%2C+P">Pierce Chuang</a>, 
<a href="/search/cs?searchtype=author&query=Harpale%2C+A">Abhay Harpale</a>, 
<a href="/search/cs?searchtype=author&query=Bhardwaj%2C+V">Vikas Bhardwaj</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Di Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shicong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Longfang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ramchandani%2C+A">Ankit Ramchandani</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X+L">Xin Luna Dong</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Anuj Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to KDD 2024 (ADS Track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce Lumos, the first end-to-end multimodal question-answering system
with text understanding capabilities. At the core of Lumos is a Scene Text
Recognition (STR) component that extracts text from first person point-of-view
images, the output of which is used to augment input to a Multimodal Large
Language Model (MM-LLM). While building Lumos, we encountered numerous
challenges related to STR quality, overall latency, and model inference. In
this paper, we delve into those challenges, and discuss the system
architecture, design choices, and modeling techniques employed to overcome
these obstacles. We also provide a comprehensive evaluation for each component,
showcasing high quality and efficiency.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08018" title="Abstract">arXiv:2402.08018</a> [<a href="/pdf/2402.08018" title="Download PDF">pdf</a>, <a href="/format/2402.08018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nearest Neighbour Score Estimators for Diffusion Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niedoba%2C+M">Matthew Niedoba</a>, 
<a href="/search/cs?searchtype=author&query=Green%2C+D">Dylan Green</a>, 
<a href="/search/cs?searchtype=author&query=Naderiparizi%2C+S">Saeid Naderiparizi</a>, 
<a href="/search/cs?searchtype=author&query=Lioutas%2C+V">Vasileios Lioutas</a>, 
<a href="/search/cs?searchtype=author&query=Lavington%2C+J+W">Jonathan Wilder Lavington</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaoxuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunpeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Ke Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dabiri%2C+S">Setareh Dabiri</a>, 
<a href="/search/cs?searchtype=author&query=%C5%9Acibior%2C+A">Adam &#x15a;cibior</a>, 
<a href="/search/cs?searchtype=author&query=Zwartsenberg%2C+B">Berend Zwartsenberg</a>, 
<a href="/search/cs?searchtype=author&query=Wood%2C+F">Frank Wood</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
<p class="mathjax">Score function estimation is the cornerstone of both training and sampling
from diffusion generative models. Despite this fact, the most commonly used
estimators are either biased neural network approximations or high variance
Monte Carlo estimators based on the conditional score. We introduce a novel
nearest neighbour score function estimator which utilizes multiple samples from
the training set to dramatically decrease estimator variance. We leverage our
low variance estimator in two compelling applications. Training consistency
models with our estimator, we report a significant increase in both convergence
speed and sample quality. In diffusion models, we show that our estimator can
replace a learned network for probability-flow ODE integration, opening
promising new avenues of future research.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08019" title="Abstract">arXiv:2402.08019</a> [<a href="/pdf/2402.08019" title="Download PDF">pdf</a>, <a href="/format/2402.08019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Volitional Control of the Paretic Hand Post-Stroke Increases Finger  Stiffness and Resistance to Robot-Assisted Movement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Ava Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Katelyn Lee</a>, 
<a href="/search/cs?searchtype=author&query=Winterbottom%2C+L">Lauren Winterbottom</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jingxi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Connor Lee</a>, 
<a href="/search/cs?searchtype=author&query=Munger%2C+G">Grace Munger</a>, 
<a href="/search/cs?searchtype=author&query=Deli-Ivanov%2C+A">Alexandra Deli-Ivanov</a>, 
<a href="/search/cs?searchtype=author&query=Nilsen%2C+D+M">Dawn M. Nilsen</a>, 
<a href="/search/cs?searchtype=author&query=Stein%2C+J">Joel Stein</a>, 
<a href="/search/cs?searchtype=author&query=Ciocarlie%2C+M">Matei Ciocarlie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Increased effort during use of the paretic arm and hand can provoke
involuntary abnormal synergy patterns and amplify stiffness effects of muscle
tone for individuals after stroke, which can add difficulty for user-controlled
devices to assist hand movement during functional tasks. We study how
volitional effort, exerted in an attempt to open or close the hand, affects
resistance to robot-assisted movement at the finger level. We perform
experiments with three chronic stroke survivors to measure changes in stiffness
when the user is actively exerting effort to activate ipsilateral
EMG-controlled robot-assisted hand movements, compared with when the fingers
are passively stretched, as well as overall effects from sustained active
engagement and use. Our results suggest that active engagement of the upper
extremity increases muscle tone in the finger to a much greater degree than
through passive-stretch or sustained exertion over time. Potential design
implications of this work suggest that developers should anticipate higher
levels of finger stiffness when relying on user-driven ipsilateral control
methods for assistive or rehabilitative devices for stroke.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08020" title="Abstract">arXiv:2402.08020</a> [<a href="/pdf/2402.08020" title="Download PDF">pdf</a>, <a href="/format/2402.08020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grasp Force Assistance via Throttle-based Wrist Angle Control on a  Robotic Hand Orthosis for C6-C7 Spinal Cord Injury
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Palacios%2C+J">Joaquin Palacios</a>, 
<a href="/search/cs?searchtype=author&query=Deli-Ivanov%2C+A">Alexandra Deli-Ivanov</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Ava Chen</a>, 
<a href="/search/cs?searchtype=author&query=Winterbottom%2C+L">Lauren Winterbottom</a>, 
<a href="/search/cs?searchtype=author&query=Nilsen%2C+D+M">Dawn M. Nilsen</a>, 
<a href="/search/cs?searchtype=author&query=Stein%2C+J">Joel Stein</a>, 
<a href="/search/cs?searchtype=author&query=Ciocarlie%2C+M">Matei Ciocarlie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Individuals with hand paralysis resulting from C6-C7 spinal cord injuries
frequently rely on tenodesis for grasping. However, tenodesis generates limited
grasping force and demands constant exertion to maintain a grasp, leading to
fatigue and sometimes pain. We introduce the MyHand-SCI, a wearable robot that
provides grasping assistance through motorized exotendons. Our user-driven
device enables independent, ipsilateral operation via a novel Throttle-based
Wrist Angle control method, which allows users to maintain grasps without
continued wrist extension. A pilot case study with a person with C6 spinal cord
injury shows an improvement in functional grasping and grasping force, as well
as a preserved ability to modulate grasping force while using our device, thus
improving their ability to manipulate everyday objects. This research is a step
towards developing effective and intuitive wearable assistive devices for
individuals with spinal cord injury.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08021" title="Abstract">arXiv:2402.08021</a> [<a href="/pdf/2402.08021" title="Download PDF">pdf</a>, <a href="/format/2402.08021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Careless Whisper: Speech-to-Text Hallucination Harms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koenecke%2C+A">Allison Koenecke</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+A+S+G">Anna Seo Gyeong Choi</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+K">Katelyn Mei</a>, 
<a href="/search/cs?searchtype=author&query=Schellmann%2C+H">Hilke Schellmann</a>, 
<a href="/search/cs?searchtype=author&query=Sloane%2C+M">Mona Sloane</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Speech-to-text services aim to transcribe input audio as accurately as
possible. They increasingly play a role in everyday life, for example in
personal voice assistants or in customer-company interactions. We evaluate Open
AI's Whisper, a state-of-the-art service outperforming industry competitors.
While many of Whisper's transcriptions were highly accurate, we found that
roughly 1% of audio transcriptions contained entire hallucinated phrases or
sentences, which did not exist in any form in the underlying audio. We
thematically analyze the Whisper-hallucinated content, finding that 38% of
hallucinations include explicit harms such as violence, made up personal
information, or false video-based authority. We further provide hypotheses on
why hallucinations occur, uncovering potential disparities due to speech type
by health status. We call on industry practitioners to ameliorate these
language-model-based hallucinations in Whisper, and to raise awareness of
potential biases in downstream applications of speech-to-text models.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08022" title="Abstract">arXiv:2402.08022</a> [<a href="/pdf/2402.08022" title="Download PDF">pdf</a>, <a href="/format/2402.08022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Digital Cousins for Ensemble Q-Learning in Large-Scale  Wireless Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bozkus%2C+T">Talha Bozkus</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+U">Urbashi Mitra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Optimizing large-scale wireless networks, including optimal resource
management, power allocation, and throughput maximization, is inherently
challenging due to their non-observable system dynamics and heterogeneous and
complex nature. Herein, a novel ensemble Q-learning algorithm that addresses
the performance and complexity challenges of the traditional Q-learning
algorithm for optimizing wireless networks is presented. Ensemble learning with
synthetic Markov Decision Processes is tailored to wireless networks via new
models for approximating large state-space observable wireless networks. In
particular, digital cousins are proposed as an extension of the traditional
digital twin concept wherein multiple Q-learning algorithms on multiple
synthetic Markovian environments are run in parallel and their outputs are
fused into a single Q-function. Convergence analyses of key statistics and
Q-functions and derivations of upper bounds on the estimation bias and variance
are provided. Numerical results across a variety of real-world wireless
networks show that the proposed algorithm can achieve up to 50% less average
policy error with up to 40% less runtime complexity than the state-of-the-art
reinforcement learning algorithms. It is also shown that theoretical results
properly predict trends in the experimental results.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08023" title="Abstract">arXiv:2402.08023</a> [<a href="/pdf/2402.08023" title="Download PDF">pdf</a>, <a href="/format/2402.08023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UGMAE: A Unified Framework for Graph Masked Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yijun Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chuxu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kou%2C+Z">Ziyi Kou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zheyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chawla%2C+N+V">Nitesh V. Chawla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generative self-supervised learning on graphs, particularly graph masked
autoencoders, has emerged as a popular learning paradigm and demonstrated its
efficacy in handling non-Euclidean data. However, several remaining issues
limit the capability of existing methods: 1) the disregard of uneven node
significance in masking, 2) the underutilization of holistic graph information,
3) the ignorance of semantic knowledge in the representation space due to the
exclusive use of reconstruction loss in the output space, and 4) the unstable
reconstructions caused by the large volume of masked contents. In light of
this, we propose UGMAE, a unified framework for graph masked autoencoders to
address these issues from the perspectives of adaptivity, integrity,
complementarity, and consistency. Specifically, we first develop an adaptive
feature mask generator to account for the unique significance of nodes and
sample informative masks (adaptivity). We then design a ranking-based structure
reconstruction objective joint with feature reconstruction to capture holistic
graph information and emphasize the topological proximity between neighbors
(integrity). After that, we present a bootstrapping-based similarity module to
encode the high-level semantic knowledge in the representation space,
complementary to the low-level reconstruction in the output space
(complementarity). Finally, we build a consistency assurance module to provide
reconstruction objectives with extra stabilized consistency targets
(consistency). Extensive experiments demonstrate that UGMAE outperforms both
contrastive and generative state-of-the-art baselines on several tasks across
multiple datasets.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08025" title="Abstract">arXiv:2402.08025</a> [<a href="/pdf/2402.08025" title="Download PDF">pdf</a>, <a href="/format/2402.08025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond the Mud: Datasets and Benchmarks for Computer Vision in Off-Road  Racing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tyo%2C+J">Jacob Tyo</a>, 
<a href="/search/cs?searchtype=author&query=Olarinre%2C+M">Motolani Olarinre</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+Y">Youngseog Chung</a>, 
<a href="/search/cs?searchtype=author&query=Lipton%2C+Z+C">Zachary C. Lipton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2311.09256">arXiv:2311.09256</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite significant progress in optical character recognition (OCR) and
computer vision systems, robustly recognizing text and identifying people in
images taken in unconstrained \emph{in-the-wild} environments remain an ongoing
challenge. However, such obstacles must be overcome in practical applications
of vision systems, such as identifying racers in photos taken during off-road
racing events. To this end, we introduce two new challenging real-world
datasets - the off-road motorcycle Racer Number Dataset (RND) and the Muddy
Racer re-iDentification Dataset (MUDD) - to highlight the shortcomings of
current methods and drive advances in OCR and person re-identification (ReID)
under extreme conditions. These two datasets feature over 6,300 images taken
during off-road competitions which exhibit a variety of factors that undermine
even modern vision systems, namely mud, complex poses, and motion blur. We
establish benchmark performance on both datasets using state-of-the-art models.
Off-the-shelf models transfer poorly, reaching only 15% end-to-end (E2E) F1
score on text spotting, and 33% rank-1 accuracy on ReID. Fine-tuning yields
major improvements, bringing model performance to 53% F1 score for E2E text
spotting and 79% rank-1 accuracy on ReID, but still falls short of good
performance. Our analysis exposes open problems in real-world OCR and ReID that
necessitate domain-targeted techniques. With these datasets and analysis of
model limitations, we aim to foster innovations in handling real-world
conditions like mud and complex poses to drive progress in robust computer
vision. All data was sourced from PerformancePhoto.co, a website used by
professional motorsports photographers, racers, and fans. The top-performing
text spotting and ReID models are deployed on this platform to power real-time
race photo search.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08027" title="Abstract">arXiv:2402.08027</a> [<a href="/pdf/2402.08027" title="Download PDF">pdf</a>, <a href="/format/2402.08027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Stability of Undesirable Equilibria in the Quadratic Program  Framework for Safety-Critical Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Reis%2C+M+F">Matheus F. Reis</a>, 
<a href="/search/eess?searchtype=author&query=Aguiar%2C+A+P">A. Pedro Aguiar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IFAC Automatica. Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Control Lyapunov functions (CLFs) and Control Barrier Functions (CBFs) have
been used to develop provably safe controllers by means of quadratic programs
(QPs). This framework guarantees safety in the form of trajectory invariance
with respect to a given set, but it can introduce undesirable equilibrium
points to the closed loop system, which can be asymptotically stable. In this
work, we present a detailed study of the formation and stability of equilibrium
points with the QP framework for a class of nonlinear systems. We introduce the
useful concept of compatibility between a CLF and a family of CBFs, regarding
the number of stable equilibrium points other than the CLF minimum. Using this
concept, we derive a set of compatibility conditions on the parameters of a
quadratic CLF and a family of quadratic CBFs that guarantee that all
undesirable equilibrium points are not attractive. Furthermore, we propose an
extension to the QP-based controller that dynamically modifies the CLF geometry
in order to satisfy the compatibility conditions, guaranteeing safety and
quasi-global convergence of the system state to the CLF minimum. Numeric
simulations illustrate the applicability of the proposed method for
safety-critical, deadlock-free robotic navigation tasks.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08030" title="Abstract">arXiv:2402.08030</a> [<a href="/pdf/2402.08030" title="Download PDF">pdf</a>, <a href="/format/2402.08030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why and When LLM-Based Assistants Can Go Wrong: Investigating the  Effectiveness of Prompt-Based Interactions for Software Help-Seeking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khurana%2C+A">Anjali Khurana</a>, 
<a href="/search/cs?searchtype=author&query=Subramonyam%2C+H">Hari Subramonyam</a>, 
<a href="/search/cs?searchtype=author&query=Chilana%2C+P+K">Parmit K Chilana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the Proceedings of the 29th International Conference on Intelligent User Interfaces (IUI'24), March 18--21, 2024, in Greenville, SC, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Model (LLM) assistants, such as ChatGPT, have emerged as
potential alternatives to search methods for helping users navigate complex,
feature-rich software. LLMs use vast training data from domain-specific texts,
software manuals, and code repositories to mimic human-like interactions,
offering tailored assistance, including step-by-step instructions. In this
work, we investigated LLM-generated software guidance through a within-subject
experiment with 16 participants and follow-up interviews. We compared a
baseline LLM assistant with an LLM optimized for particular software contexts,
SoftAIBot, which also offered guidelines for constructing appropriate prompts.
We assessed task completion, perceived accuracy, relevance, and trust.
Surprisingly, although SoftAIBot outperformed the baseline LLM, our results
revealed no significant difference in LLM usage and user perceptions with or
without prompt guidelines and the integration of domain context. Most users
struggled to understand how the prompt's text related to the LLM's responses
and often followed the LLM's suggestions verbatim, even if they were incorrect.
This resulted in difficulties when using the LLM's advice for software tasks,
leading to low task completion rates. Our detailed analysis also revealed that
users remained unaware of inaccuracies in the LLM's responses, indicating a gap
between their lack of software expertise and their ability to evaluate the
LLM's assistance. With the growing push for designing domain-specific LLM
assistants, we emphasize the importance of incorporating explainable,
context-aware cues into LLMs to help users understand prompt-based
interactions, identify biases, and maximize the utility of LLM assistants.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08031" title="Abstract">arXiv:2402.08031</a> [<a href="/pdf/2402.08031" title="Download PDF">pdf</a>, <a href="/format/2402.08031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dumviri: Detecting Trackers and Mixed Trackers with a Breakage Detector
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shuang%2C+H">He Shuang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lianying Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lie%2C+D">David Lie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Previous automatic tracker detection work lacks features to recognize web
page breakage and often resort to manual analysis to assess the breakage caused
by blocking trackers.
<br />We introduce Dumviri, which incorporates a breakage detector that can
automatically detect web page breakage caused by erroneously blocking a
resource that is needed by the page to function properly. This addition allows
Dumviri to prevent functional resources from being misclassified as trackers
and increases overall detection accuracy. We designed Dumviri to take
differential features. We further find that these features are agnostic to
analysis granularity and enable Dumviri to predict tracking resources at the
request field granularity, allowing Dumviri to handle some mixed trackers.
<br />Evaluating Dumviri on 15K pages shows its ability to replicate the labels of
human-generated filter lists with an accuracy of 97.44%. Through a manual
analysis, we found that Dumviri identified previously unreported trackers and
its breakage detector can identify rules that cause web page breakage in
commonly used filter lists like EasyPrivacy. In the case of mixed trackers,
Dumviri, being the first automated mixed tracker detector, achieves a 79.09%
accuracy. We have confirmed 22 previously unreported unique trackers and 26
unique mixed trackers. We promptly reported these findings to privacy
developers, and we will publish our filter lists in uBlock Origin's extended
syntax.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08035" title="Abstract">arXiv:2402.08035</a> [<a href="/pdf/2402.08035" title="Download PDF">pdf</a>, <a href="/format/2402.08035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple Random Masking Autoencoder Ensembles for Robust Multimodal  Semi-supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Todoran%2C+A">Alexandru-Raul Todoran</a>, 
<a href="/search/cs?searchtype=author&query=Leordeanu%2C+M">Marius Leordeanu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">There is an increasing number of real-world problems in computer vision and
machine learning requiring to take into consideration multiple interpretation
layers (modalities or views) of the world and learn how they relate to each
other. For example, in the case of Earth Observations from satellite data, it
is important to be able to predict one observation layer (e.g. vegetation
index) from other layers (e.g. water vapor, snow cover, temperature etc), in
order to best understand how the Earth System functions and also be able to
reliably predict information for one layer when the data is missing (e.g. due
to measurement failure or error).
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08046" title="Abstract">arXiv:2402.08046</a> [<a href="/pdf/2402.08046" title="Download PDF">pdf</a>, <a href="/format/2402.08046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tight Algorithm for Connected Odd Cycle Transversal Parameterized by  Clique-width
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bojikian%2C+N">Narek Bojikian</a>, 
<a href="/search/cs?searchtype=author&query=Kratsch%2C+S">Stefan Kratsch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Recently, Bojikian and Kratsch [2023] have presented a novel approach to
tackle connectivity problems parameterized by clique-width
($\operatorname{cw}$), based on counting small representations of partial
solutions (modulo two). Using this technique, they were able to get a tight
bound for the Steiner Tree problem, answering an open question posed by
Hegerfeld and Kratsch [ESA, 2023]. We use the same technique to solve the
Connected Odd Cycle Transversal problem in time
$\mathcal{O}^*(12^{\operatorname{cw}})$. We define a new representation of
partial solutions by separating the connectivity requirement from the
2-colorability requirement of this problem. Moreover, we prove that our result
is tight by providing SETH-based lower bound excluding algorithms with running
time $\mathcal{O}^*((12-\epsilon)^{\operatorname{lcw}})$ even when
parameterized by linear clique-width. This answers the second question posed by
Hegerfeld and Kratsch in the same paper.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08049" title="Abstract">arXiv:2402.08049</a> [<a href="/pdf/2402.08049" title="Download PDF">pdf</a>, <a href="/format/2402.08049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An algorithm for dynamic vehicle-track-structure interaction analysis  for high-speed trains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fedorova%2C+M">Maria Fedorova</a>, 
<a href="/search/math?searchtype=author&query=Sivaselvan%2C+M+V">M. V. Sivaselvan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 28 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Engineering Structures, 2017, 148 (October): 857-77
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The objective of the present work is to develop a robust, yet
simple-to-implement algorithm for dynamic vehicle-track-structure-interaction
(VTSI) analysis, applicable to trains passing over bridges. The algorithm can
be readily implemented in existing bridge analysis software with minimal code
modifications. It is based on modeling the bridge and train separately, and
coupling them together by means of kinematic constraints. The contact forces
between the wheels and the track become Lagrange multipliers in this approach.
A direct implementation of such an approach results in spurious oscillations in
the contact forces. Two approaches are presented to mitigate these spurious
oscillations - (a) a cubic B-spline interpolation of the kinematic constraints
in time, and (b) an adaptation of an alternate time-integration scheme
originally developed by Bathe. Solutions obtained using this algorithm are
verified using a generic differential algebraic equation (DAE) solver. Due to
high train speeds and possible track irregularities, wheels can momentarily
lose contact with the track. This contact separation is formulated as a Linear
Complementarity Problem (LCP). With this formulation, including contact
separation in the analysis amounts to replacing a call to a linear equation
solver by a call to an LCP solver, a modification of only two steps of the
procedure. The focus of this paper is on the computational procedure of VTSI
analysis. The main contribution of this paper is recognizing computational
issues associated with time-varying kinematic constraints, clearly identifying
their cause and developing remedies.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08056" title="Abstract">arXiv:2402.08056</a> [<a href="/pdf/2402.08056" title="Download PDF">pdf</a>, <a href="/format/2402.08056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MIML library: a Modular and Flexible Library for Multi-instance  Multi-label Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belmonte%2C+%C3%81">&#xc1;lvaro Belmonte</a>, 
<a href="/search/cs?searchtype=author&query=Zafra%2C+A">Amelia Zafra</a>, 
<a href="/search/cs?searchtype=author&query=Gibaja%2C+E">Eva Gibaja</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">MIML library is a Java software tool to develop, test, and compare
classification algorithms for multi-instance multi-label (MIML) learning. The
library includes 43 algorithms and provides a specific format and facilities
for data managing and partitioning, holdout and cross-validation methods,
standard metrics for performance evaluation, and generation of reports. In
addition, algorithms can be executed through $xml$ configuration files without
needing to program. It is platform-independent, extensible, free, open-source,
and available on GitHub under the GNU General Public License.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08061" title="Abstract">arXiv:2402.08061</a> [<a href="/pdf/2402.08061" title="Download PDF">pdf</a>, <a href="/format/2402.08061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Portobello: Extending Driving Simulation from the Lab to the Road
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bu%2C+F">Fanjun Bu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Stacey Li</a>, 
<a href="/search/cs?searchtype=author&query=Goedicke%2C+D">David Goedicke</a>, 
<a href="/search/cs?searchtype=author&query=Colley%2C+M">Mark Colley</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+G">Gyanendra Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Yasuda%2C+H">Hiroshi Yasuda</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+W">Wendy Ju</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In automotive user interface design, testing often starts with lab-based
driving simulators and migrates toward on-road studies to mitigate risks. Mixed
reality (XR) helps translate virtual study designs to the real road to increase
ecological validity. However, researchers rarely run the same study in both
in-lab and on-road simulators due to the challenges of replicating studies in
both physical and virtual worlds. To provide a common infrastructure to port
in-lab study designs on-road, we built a platform-portable infrastructure,
Portobello, to enable us to run twinned physical-virtual studies. As a
proof-of-concept, we extended the on-road simulator XR-OOM with Portobello. We
ran a within-subjects, autonomous-vehicle crosswalk cooperation study (N=32)
both in-lab and on-road to investigate study design portability and
platform-driven influences on study outcomes. To our knowledge, this is the
first system that enables the twinning of studies originally designed for
in-lab simulators to be carried out in an on-road platform.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08062" title="Abstract">arXiv:2402.08062</a> [<a href="/pdf/2402.08062" title="Download PDF">pdf</a>, <a href="/ps/2402.08062" title="Download PostScript">ps</a>, <a href="/format/2402.08062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Avoiding Catastrophe in Continuous Spaces by Asking for Help
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Plaut%2C+B">Benjamin Plaut</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hanlin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Russell%2C+S">Stuart Russell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Most reinforcement learning algorithms with formal regret guarantees assume
all mistakes are reversible and rely on essentially trying all possible
options. This approach leads to poor outcomes when some mistakes are
irreparable or even catastrophic. We propose a variant of the contextual bandit
problem where the goal is to minimize the chance of catastrophe. Specifically,
we assume that the payoff each round represents the chance of avoiding
catastrophe that round, and try to maximize the product of payoffs (the overall
chance of avoiding catastrophe). To give the agent some chance of success, we
allow a limited number of queries to a mentor and assume a Lipschitz continuous
payoff function. We present an algorithm whose regret and rate of querying the
mentor both approach 0 as the time horizon grows, assuming a continuous 1D
state space and a relatively "simple" payoff function. We also provide a
matching lower bound: without the simplicity assumption: any algorithm either
constantly asks for help or is nearly guaranteed to cause catastrophe. Finally,
we identify the key obstacle to generalizing our algorithm to a
multi-dimensional state space.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08063" title="Abstract">arXiv:2402.08063</a> [<a href="/pdf/2402.08063" title="Download PDF">pdf</a>, <a href="/format/2402.08063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Locality Sensitive Hashing for Network Traffic Fingerprinting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mashnoor%2C+N">Nowfel Mashnoor</a>, 
<a href="/search/cs?searchtype=author&query=Thom%2C+J">Jay Thom</a>, 
<a href="/search/cs?searchtype=author&query=Rouf%2C+A">Abdur Rouf</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+S">Shamik Sengupta</a>, 
<a href="/search/cs?searchtype=author&query=Charyyev%2C+B">Batyr Charyyev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference Name: 2023 IEEE 29th International Symposium on Local and Metropolitan Area Networks (LANMAN) Date of Conference: 10-11 July 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">The advent of the Internet of Things (IoT) has brought forth additional
intricacies and difficulties to computer networks. These gadgets are
particularly susceptible to cyber-attacks because of their simplistic design.
Therefore, it is crucial to recognise these devices inside a network for the
purpose of network administration and to identify any harmful actions. Network
traffic fingerprinting is a crucial technique for identifying devices and
detecting anomalies. Currently, the predominant methods for this depend heavily
on machine learning (ML). Nevertheless, machine learning (ML) methods need the
selection of features, adjustment of hyperparameters, and retraining of models
to attain optimal outcomes and provide resilience to concept drifts detected in
a network. In this research, we suggest using locality-sensitive hashing (LSH)
for network traffic fingerprinting as a solution to these difficulties. Our
study focuses on examining several design options for the Nilsimsa LSH
function. We then use this function to create unique fingerprints for network
data, which may be used to identify devices. We also compared it with ML-based
traffic fingerprinting and observed that our method increases the accuracy of
state-of-the-art by 12% achieving around 94% accuracy in identifying devices in
a network.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08064" title="Abstract">arXiv:2402.08064</a> [<a href="/pdf/2402.08064" title="Download PDF">pdf</a>, <a href="/ps/2402.08064" title="Download PostScript">ps</a>, <a href="/format/2402.08064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond LLMs: Advancing the Landscape of Complex Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu-Carroll%2C+J">Jennifer Chu-Carroll</a>, 
<a href="/search/cs?searchtype=author&query=Beck%2C+A">Andrew Beck</a>, 
<a href="/search/cs?searchtype=author&query=Burnham%2C+G">Greg Burnham</a>, 
<a href="/search/cs?searchtype=author&query=Melville%2C+D+O">David OS Melville</a>, 
<a href="/search/cs?searchtype=author&query=Nachman%2C+D">David Nachman</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96zcan%2C+A+E">A. Erdem &#xd6;zcan</a>, 
<a href="/search/cs?searchtype=author&query=Ferrucci%2C+D">David Ferrucci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Since the advent of Large Language Models a few years ago, they have often
been considered the de facto solution for many AI problems. However, in
addition to the many deficiencies of LLMs that prevent them from broad industry
adoption, such as reliability, cost, and speed, there is a whole class of
common real world problems that Large Language Models perform poorly on,
namely, constraint satisfaction and optimization problems. These problems are
ubiquitous and current solutions are highly specialized and expensive to
implement. At Elemental Cognition, we developed our EC AI platform which takes
a neuro-symbolic approach to solving constraint satisfaction and optimization
problems. The platform employs, at its core, a precise and high performance
logical reasoning engine, and leverages LLMs for knowledge acquisition and user
interaction. This platform supports developers in specifying application logic
in natural and concise language while generating application user interfaces to
interact with users effectively. We evaluated LLMs against systems built on the
EC AI platform in three domains and found the EC AI systems to significantly
outperform LLMs on constructing valid and optimal solutions, on validating
proposed solutions, and on repairing invalid solutions.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08068" title="Abstract">arXiv:2402.08068</a> [<a href="/pdf/2402.08068" title="Download PDF">pdf</a>, <a href="/ps/2402.08068" title="Download PostScript">ps</a>, <a href="/format/2402.08068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Blocklace: A Universal, Byzantine Fault-Tolerant, Conflict-free  Replicated Data Type
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almeida%2C+P+S">Paulo S&#xe9;rgio Almeida</a>, 
<a href="/search/cs?searchtype=author&query=Shapiro%2C+E">Ehud Shapiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Conflict-free Replicated Data Types (CRDTs) are designed for replica
convergence without global coordination or consensus. Recent work has achieves
the same in a Byzantine environment, through DAG-like structures based on
cryptographic hashes of content.
<br />The blocklace is a partially-ordered generalization of the blockchain in
which each block has any finite number of signed hash pointers to preceding
blocks. We show that the blocklace datatype, with the sole operation of adding
a single block, is a CRDT: it is both a pure operation-based CRDT, with
self-tagging; and a delta-state CRDT, under a slight generalization of the
delta framework. Allowing arbitrary values as payload, the blocklace can also
be seen as a universal Byzantine fault-tolerant implementation for arbitrary
CRDTs, under the operation-based approach.
<br />Current approaches only care about CRDT convergence, being
equivocation-tolerant (they do not detect or prevent equivocations), allowing a
Byzantine node to cause an arbitrary amount of harm by polluting the CRDT state
with an infinite number of equivocations.
<br />We show that a blocklace can be used not only in an equivocation-tolerant
way, but also so as to detect and eventually exclude Byzantine behavior, namely
equivocations, even under the presence of collusion. The blocklace CRDT
protocol ensures that the Byzantine nodes may harm only a finite prefix of the
computation.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08070" title="Abstract">arXiv:2402.08070</a> [<a href="/pdf/2402.08070" title="Download PDF">pdf</a>, <a href="/format/2402.08070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Attribute Vision Transformers are Efficient and Robust Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gani%2C+H">Hanan Gani</a>, 
<a href="/search/cs?searchtype=author&query=Saadi%2C+N">Nada Saadi</a>, 
<a href="/search/cs?searchtype=author&query=Hussein%2C+N">Noor Hussein</a>, 
<a href="/search/cs?searchtype=author&query=Nandakumar%2C+K">Karthik Nandakumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/hananshafi/MTL-ViT.">this https URL</a> arXiv admin note: text overlap with <a href="/abs/2207.08677">arXiv:2207.08677</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Since their inception, Vision Transformers (ViTs) have emerged as a
compelling alternative to Convolutional Neural Networks (CNNs) across a wide
spectrum of tasks. ViTs exhibit notable characteristics, including global
attention, resilience against occlusions, and adaptability to distribution
shifts. One underexplored aspect of ViTs is their potential for multi-attribute
learning, referring to their ability to simultaneously grasp multiple
attribute-related tasks. In this paper, we delve into the multi-attribute
learning capability of ViTs, presenting a straightforward yet effective
strategy for training various attributes through a single ViT network as
distinct tasks. We assess the resilience of multi-attribute ViTs against
adversarial attacks and compare their performance against ViTs designed for
single attributes. Moreover, we further evaluate the robustness of
multi-attribute ViTs against a recent transformer based attack called
Patch-Fool. Our empirical findings on the CelebA dataset provide validation for
our assertion.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08072" title="Abstract">arXiv:2402.08072</a> [<a href="/pdf/2402.08072" title="Download PDF">pdf</a>, <a href="/format/2402.08072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Programming Error Messages in Real Time with Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kimmel%2C+B">Bailey Kimmel</a>, 
<a href="/search/cs?searchtype=author&query=Geisert%2C+A">Austin Geisert</a>, 
<a href="/search/cs?searchtype=author&query=Yaro%2C+L">Lily Yaro</a>, 
<a href="/search/cs?searchtype=author&query=Gipson%2C+B">Brendan Gipson</a>, 
<a href="/search/cs?searchtype=author&query=Hotchkiss%2C+T">Taylor Hotchkiss</a>, 
<a href="/search/cs?searchtype=author&query=Osae-Asante%2C+S">Sidney Osae-Asante</a>, 
<a href="/search/cs?searchtype=author&query=Vaught%2C+H">Hunter Vaught</a>, 
<a href="/search/cs?searchtype=author&query=Wininger%2C+G">Grant Wininger</a>, 
<a href="/search/cs?searchtype=author&query=Yamaguchi%2C+C">Chase Yamaguchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generative AI is changing the way that many disciplines are taught, including
computer science. Researchers have shown that generative AI tools are capable
of solving programming problems, writing extensive blocks of code, and
explaining complex code in simple terms. Particular promise has been shown in
using generative AI to enhance programming error messages. Both students and
instructors have complained for decades that these messages are often cryptic
and difficult to understand. Yet recent work has shown that students make fewer
repeated errors when enhanced via GPT-4. We extend this work by implementing
feedback from ChatGPT for all programs submitted to our automated assessment
tool, Athene, providing help for compiler, run-time, and logic errors. Our
results indicate that adding generative AI to an automated assessment tool does
not necessarily make it better and that design of the interface matters greatly
to the usability of the feedback that GPT-4 provided.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08073" title="Abstract">arXiv:2402.08073</a> [<a href="/pdf/2402.08073" title="Download PDF">pdf</a>, <a href="/format/2402.08073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grounding Data Science Code Generation with Input-Output Specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yeming Wen</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+P">Pengcheng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+K">Kensen Shi</a>, 
<a href="/search/cs?searchtype=author&query=Michalewski%2C+H">Henryk Michalewski</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhuri%2C+S">Swarat Chaudhuri</a>, 
<a href="/search/cs?searchtype=author&query=Polozov%2C+A">Alex Polozov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Programming Languages (cs.PL); Software Engineering (cs.SE)

</div>
<p class="mathjax">Large language models (LLMs) have recently demonstrated a remarkable ability
to generate code from natural language (NL) prompts. However, in the real
world, NL is often too ambiguous to capture the true intent behind programming
problems, requiring additional input-output (I/O) specifications.
Unfortunately, LLMs can have difficulty aligning their outputs with both the NL
prompt and the I/O specification. In this paper, we give a way to mitigate this
issue in the context of data science programming, where tasks require explicit
I/O specifications for clarity. Specifically, we propose GIFT4Code, a novel
approach for the instruction fine-tuning of LLMs with respect to I/O
specifications. Our method leverages synthetic data produced by the LLM itself
and utilizes execution-derived feedback as a key learning signal. This
feedback, in the form of program I/O specifications, is provided to the LLM to
facilitate instruction fine-tuning. We evaluated our approach on two
challenging data science benchmarks, Arcade and DS-1000. The results
demonstrate a significant improvement in the LLM's ability to generate code
that is not only executable but also accurately aligned with user
specifications, substantially improving the quality of code generation for
complex data science tasks.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08078" title="Abstract">arXiv:2402.08078</a> [<a href="/pdf/2402.08078" title="Download PDF">pdf</a>, <a href="/format/2402.08078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models as Agents in Two-Player Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+P">Peng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">By formally defining the training processes of large language models (LLMs),
which usually encompasses pre-training, supervised fine-tuning, and
reinforcement learning with human feedback, within a single and unified machine
learning paradigm, we can glean pivotal insights for advancing LLM
technologies. This position paper delineates the parallels between the training
methods of LLMs and the strategies employed for the development of agents in
two-player games, as studied in game theory, reinforcement learning, and
multi-agent systems. We propose a re-conceptualization of LLM learning
processes in terms of agent learning in language-based games. This framework
unveils innovative perspectives on the successes and challenges in LLM
development, offering a fresh understanding of addressing alignment issues
among other strategic considerations. Furthermore, our two-player game approach
sheds light on novel data preparation and machine learning techniques for
training LLMs.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08079" title="Abstract">arXiv:2402.08079</a> [<a href="/pdf/2402.08079" title="Download PDF">pdf</a>, <a href="/format/2402.08079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReNeLiB: Real-time Neural Listening Behavior Generation for Socially  Interactive Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Don%2C+D+W">Daksitha Withanage Don</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+P">Philipp M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Nunnari%2C+F">Fabrizio Nunnari</a>, 
<a href="/search/cs?searchtype=author&query=Andr%C3%A9%2C+E">Elisabeth Andr&#xe9;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 11 figures, ICMI conference, project page <a href="https://daksitha.github.io/ReNeLib/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Flexible and natural nonverbal reactions to human behavior remain a challenge
for socially interactive agents (SIAs) that are predominantly animated using
hand-crafted rules. While recently proposed machine learning based approaches
to conversational behavior generation are a promising way to address this
challenge, they have not yet been employed in SIAs. The primary reason for this
is the lack of a software toolkit integrating such approaches with SIA
frameworks that conforms to the challenging real-time requirements of
human-agent interaction scenarios. In our work, we for the first time present
such a toolkit consisting of three main components: (1) real-time feature
extraction capturing multi-modal social cues from the user; (2) behavior
generation based on a recent state-of-the-art neural network approach; (3)
visualization of the generated behavior supporting both FLAME-based and Apple
ARKit-based interactive agents. We comprehensively evaluate the real-time
performance of the whole framework and its components. In addition, we
introduce pre-trained behavioral generation models derived from psychotherapy
sessions for domain-specific listening behaviors. Our software toolkit, pivotal
for deploying and assessing SIAs' listening behavior in real-time, is publicly
available. Resources, including code, behavioural multi-modal features
extracted from therapeutic interactions, are hosted at
\url{https://daksitha.github.io/ReNeLib}
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08080" title="Abstract">arXiv:2402.08080</a> [<a href="/pdf/2402.08080" title="Download PDF">pdf</a>, <a href="/ps/2402.08080" title="Download PostScript">ps</a>, <a href="/format/2402.08080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User Perception of Partially Automated Driving Systems: A Meaningful  Human Control Perspective on the Perception among Tesla Users
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suryana%2C+L+E">Lucas Elbert Suryana</a>, 
<a href="/search/cs?searchtype=author&query=Nordhoff%2C+S">Sina Nordhoff</a>, 
<a href="/search/cs?searchtype=author&query=Calvert%2C+S+C">Simeon C. Calvert</a>, 
<a href="/search/cs?searchtype=author&query=Zgonnikov%2C+A">Arkady Zgonnikov</a>, 
<a href="/search/cs?searchtype=author&query=van+Arem%2C+B">Bart van Arem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The use of partially automated driving systems raises concerns about
potential responsibility issues, posing risk to the system safety, acceptance,
and adoption of these technologies. The concept of meaningful human control has
emerged in response to the responsibility gap problem, requiring the
fulfillment of two conditions, tracking and tracing. While this concept has
provided important philosophical and design insights on automated driving
systems, there is currently little knowledge on how meaningful human control
relates to subjective experiences of actual users of these systems. To address
this gap, our study aimed to investigate the alignment between the degree of
meaningful human control and drivers' perceptions of safety and trust in a
real-world partially automated driving system. We utilized previously collected
data from interviews with Tesla "Full Self-Driving" (FSD) Beta users,
investigating the alignment between the user perception and how well the system
was tracking the users' reasons. We found that tracking of users' reasons for
driving tasks (such as safe maneuvers) correlated with perceived safety and
trust, albeit with notable exceptions. Surprisingly, failure to track lane
changing and braking reasons was not necessarily associated with negative
perceptions of safety. However, the failure of the system to track expected
maneuvers in dangerous situations always resulted in low trust and perceived
lack of safety. Overall, our analyses highlight alignment points but also
possible discrepancies between perceived safety and trust on the one hand, and
meaningful human control on the other hand. Our results can help the developers
of automated driving technology to design systems under meaningful human
control and are perceived as safe and trustworthy.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08084" title="Abstract">arXiv:2402.08084</a> [<a href="/pdf/2402.08084" title="Download PDF">pdf</a>, <a href="/format/2402.08084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CycPUF: Cyclic Physical Unclonable Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dominguez%2C+M">Michael Dominguez</a>, 
<a href="/search/cs?searchtype=author&query=Rezaei%2C+A">Amin Rezaei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of 27th Design, Automation &amp; Test in Europe Conference &amp; Exhibition (DATE 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Physical Unclonable Functions (PUFs) leverage manufacturing process
imperfections that cause propagation delay discrepancies for the signals
traveling along these paths. While PUFs can be used for device authentication
and chip-specific key generation, strong PUFs have been shown to be vulnerable
to machine learning modeling attacks. Although there is an impression that
combinational circuits must be designed without any loops, cyclic combinational
circuits have been shown to increase design security against hardware
intellectual property theft. In this paper, we introduce feedback signals into
traditional delay-based PUF designs such as arbiter PUF, ring oscillator PUF,
and butterfly PUF to give them a wider range of possible output behaviors and
thus an edge against modeling attacks. Based on our analysis, cyclic PUFs
produce responses that can be binary, steady-state, oscillating, or
pseudo-random under fixed challenges. The proposed cyclic PUFs are implemented
in field programmable gate arrays, and their power and area overhead, in
addition to functional metrics, are reported compared with their traditional
counterparts. The security gain of the proposed cyclic PUFs is also shown
against state-of-the-art attacks.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08085" title="Abstract">arXiv:2402.08085</a> [<a href="/pdf/2402.08085" title="Download PDF">pdf</a>, <a href="/format/2402.08085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Message Detouring: A Simple Yet Effective Cycle Representation for  Expressive Graph Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Ziquan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Dan%2C+T">Tingting Dan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Guorong Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Geometry (cs.CG)

</div>
<p class="mathjax">Graph learning is crucial in the fields of bioinformatics, social networks,
and chemicals. Although high-order graphlets, such as cycles, are critical to
achieving an informative graph representation for node classification, edge
prediction, and graph recognition, modeling high-order topological
characteristics poses significant computational challenges, restricting its
widespread applications in machine learning. To address this limitation, we
introduce the concept of \textit{message detouring} to hierarchically
characterize cycle representation throughout the entire graph, which
capitalizes on the contrast between the shortest and longest pathways within a
range of local topologies associated with each graph node. The topological
feature representations derived from our message detouring landscape
demonstrate comparable expressive power to high-order
\textit{Weisfeiler-Lehman} (WL) tests but much less computational demands. In
addition to the integration with graph kernel and message passing neural
networks, we present a novel message detouring neural network, which uses
Transformer backbone to integrate cycle representations across nodes and edges.
Aside from theoretical results, experimental results on expressiveness, graph
classification, and node classification show message detouring can
significantly outperform current counterpart approaches on various benchmark
datasets.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08086" title="Abstract">arXiv:2402.08086</a> [<a href="/pdf/2402.08086" title="Download PDF">pdf</a>, <a href="/format/2402.08086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text-centric Alignment for Multi-Modality Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y">Yun-Da Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Yen%2C+T">Ting-Yu Yen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+P">Pei-Fu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhe-Yan Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shou-De Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This research paper addresses the challenge of modality mismatch in
multimodal learning, where the modalities available during inference differ
from those available at training. We propose the Text-centric Alignment for
Multi-Modality Learning (TAMML) approach, an innovative method that utilizes
Large Language Models (LLMs) with in-context learning and foundation models to
enhance the generalizability of multimodal systems under these conditions. By
leveraging the unique properties of text as a unified semantic space, TAMML
demonstrates significant improvements in handling unseen, diverse, and
unpredictable modality combinations. TAMML not only adapts to varying
modalities but also maintains robust performance, showcasing the potential of
foundation models in overcoming the limitations of traditional fixed-modality
frameworks in embedding representations. This study contributes to the field by
offering a flexible, effective solution for real-world applications where
modality availability is dynamic and uncertain.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08088" title="Abstract">arXiv:2402.08088</a> [<a href="/pdf/2402.08088" title="Download PDF">pdf</a>, <a href="/format/2402.08088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Out-of-Distribution Detection and Data Drift Monitoring using  Statistical Process Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zamzmi%2C+G">Ghada Zamzmi</a>, 
<a href="/search/cs?searchtype=author&query=Venkatesh%2C+K">Kesavan Venkatesh</a>, 
<a href="/search/cs?searchtype=author&query=Nelson%2C+B">Brandon Nelson</a>, 
<a href="/search/cs?searchtype=author&query=Prathapan%2C+S">Smriti Prathapan</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+P+H">Paul H. Yi</a>, 
<a href="/search/cs?searchtype=author&query=Sahiner%2C+B">Berkman Sahiner</a>, 
<a href="/search/cs?searchtype=author&query=Delfino%2C+J+G">Jana G. Delfino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Background: Machine learning (ML) methods often fail with data that deviates
from their training distribution. This is a significant concern for ML-enabled
devices in clinical settings, where data drift may cause unexpected performance
that jeopardizes patient safety.
<br />Method: We propose a ML-enabled Statistical Process Control (SPC) framework
for out-of-distribution (OOD) detection and drift monitoring. SPC is
advantageous as it visually and statistically highlights deviations from the
expected distribution. To demonstrate the utility of the proposed framework for
monitoring data drift in radiological images, we investigated different design
choices, including methods for extracting feature representations, drift
quantification, and SPC parameter selection.
<br />Results: We demonstrate the effectiveness of our framework for two tasks: 1)
differentiating axial vs. non-axial computed tomography (CT) images and 2)
separating chest x-ray (CXR) from other modalities. For both tasks, we achieved
high accuracy in detecting OOD inputs, with 0.913 in CT and 0.995 in CXR, and
sensitivity of 0.980 in CT and 0.984 in CXR. Our framework was also adept at
monitoring data streams and identifying the time a drift occurred. In a
simulation with 100 daily CXR cases, we detected a drift in OOD input
percentage from 0-1% to 3-5% within two days, maintaining a low false-positive
rate. Through additional experimental results, we demonstrate the framework's
data-agnostic nature and independence from the underlying model's structure.
<br />Conclusion: We propose a framework for OOD detection and drift monitoring
that is agnostic to data, modality, and model. The framework is customizable
and can be adapted for specific applications.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08090" title="Abstract">arXiv:2402.08090</a> [<a href="/pdf/2402.08090" title="Download PDF">pdf</a>, <a href="/format/2402.08090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Neural Contracting Dynamics: Extended Linearization and Global  Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jaffe%2C+S">Sean Jaffe</a>, 
<a href="/search/cs?searchtype=author&query=Davydov%2C+A">Alexander Davydov</a>, 
<a href="/search/cs?searchtype=author&query=Lapsekili%2C+D">Deniz Lapsekili</a>, 
<a href="/search/cs?searchtype=author&query=singh%2C+A">Ambuj singh</a>, 
<a href="/search/cs?searchtype=author&query=Bullo%2C+F">Francesco Bullo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures. Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Global stability and robustness guarantees in learned dynamical systems are
essential to ensure well-behavedness of the systems in the face of uncertainty.
We present Extended Linearized Contracting Dynamics (ELCD), the first neural
network-based dynamical system with global contractivity guarantees in
arbitrary metrics. The key feature of ELCD is a parametrization of the extended
linearization of the nonlinear vector field. In its most basic form, ELCD is
guaranteed to be (i) globally exponentially stable, (ii) equilibrium
contracting, and (iii) globally contracting with respect to some metric. To
allow for contraction with respect to more general metrics in the data space,
we train diffeomorphisms between the data space and a latent space and enforce
contractivity in the latent space, which ensures global contractivity in the
data space. We demonstrate the performance of ELCD on the $2$D, $4$D, and $8$D
LASA datasets.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08093" title="Abstract">arXiv:2402.08093</a> [<a href="/pdf/2402.08093" title="Download PDF">pdf</a>, <a href="/format/2402.08093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BASE TTS: Lessons from building a billion-parameter Text-to-Speech model  on 100K hours of data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C5%81ajszczak%2C+M">Mateusz &#x141;ajszczak</a>, 
<a href="/search/cs?searchtype=author&query=C%C3%A1mbara%2C+G">Guillermo C&#xe1;mbara</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Beyhan%2C+F">Fatih Beyhan</a>, 
<a href="/search/cs?searchtype=author&query=van+Korlaar%2C+A">Arent van Korlaar</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Joly%2C+A">Arnaud Joly</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADn-Cortinas%2C+%C3%81">&#xc1;lvaro Mart&#xed;n-Cortinas</a>, 
<a href="/search/cs?searchtype=author&query=Abbas%2C+A">Ammar Abbas</a>, 
<a href="/search/cs?searchtype=author&query=Michalski%2C+A">Adam Michalski</a>, 
<a href="/search/cs?searchtype=author&query=Moinet%2C+A">Alexis Moinet</a>, 
<a href="/search/cs?searchtype=author&query=Karlapati%2C+S">Sri Karlapati</a>, 
<a href="/search/cs?searchtype=author&query=Muszy%C5%84ska%2C+E">Ewa Muszy&#x144;ska</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Haohan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Putrycz%2C+B">Bartosz Putrycz</a>, 
<a href="/search/cs?searchtype=author&query=Gambino%2C+S+L">Soledad L&#xf3;pez Gambino</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+K">Kayeon Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Sokolova%2C+E">Elena Sokolova</a>, 
<a href="/search/cs?searchtype=author&query=Drugman%2C+T">Thomas Drugman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We introduce a text-to-speech (TTS) model called BASE TTS, which stands for
$\textbf{B}$ig $\textbf{A}$daptive $\textbf{S}$treamable TTS with
$\textbf{E}$mergent abilities. BASE TTS is the largest TTS model to-date,
trained on 100K hours of public domain speech data, achieving a new
state-of-the-art in speech naturalness. It deploys a 1-billion-parameter
autoregressive Transformer that converts raw texts into discrete codes
("speechcodes") followed by a convolution-based decoder which converts these
speechcodes into waveforms in an incremental, streamable manner. Further, our
speechcodes are built using a novel speech tokenization technique that features
speaker ID disentanglement and compression with byte-pair encoding. Echoing the
widely-reported "emergent abilities" of large language models when trained on
increasing volume of data, we show that BASE TTS variants built with 10K+ hours
and 500M+ parameters begin to demonstrate natural prosody on textually complex
sentences. We design and share a specialized dataset to measure these emergent
abilities for text-to-speech. We showcase state-of-the-art naturalness of BASE
TTS by evaluating against baselines that include publicly available large-scale
text-to-speech systems: YourTTS, Bark and TortoiseTTS. Audio samples generated
by the model can be heard at https://amazon-ltts-paper.com/.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08096" title="Abstract">arXiv:2402.08096</a> [<a href="/pdf/2402.08096" title="Download PDF">pdf</a>, <a href="/format/2402.08096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Which Pretrain Samples to Rehearse when Finetuning Pretrained Models?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+A">Andrew Bai</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+C">Chih-Kuan Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+C">Cho-Jui Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Taly%2C+A">Ankur Taly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Fine-tuning pretrained foundational models on specific tasks is now the de
facto approach for text and vision tasks. A known pitfall of this approach is
the forgetting of pretraining knowledge that happens during finetuning.
Rehearsing samples randomly from the pretrain dataset is a common approach to
alleviate such forgetting. However, we find that random mixing unintentionally
includes samples which are not (yet) forgotten or unlearnable by the model. We
propose a novel sampling scheme, mix-cd, that identifies and prioritizes
samples that actually face forgetting, which we call collateral damage. Since
directly identifying collateral damage samples is computationally expensive, we
propose a procedure to estimate the distribution of such samples by tracking
the statistics of finetuned samples. Our approach is lightweight, easy to
implement, and can be seamlessly integrated into existing models, offering an
effective means to retain pretrain performance without additional computational
costs.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08100" title="Abstract">arXiv:2402.08100</a> [<a href="/pdf/2402.08100" title="Download PDF">pdf</a>, <a href="/format/2402.08100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the Impact of Data Contamination of Large Language Models  in Text-to-SQL Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ranaldi%2C+F">Federico Ranaldi</a>, 
<a href="/search/cs?searchtype=author&query=Ruzzetti%2C+E+S">Elena Sofia Ruzzetti</a>, 
<a href="/search/cs?searchtype=author&query=Onorati%2C+D">Dario Onorati</a>, 
<a href="/search/cs?searchtype=author&query=Ranaldi%2C+L">Leonardo Ranaldi</a>, 
<a href="/search/cs?searchtype=author&query=Giannone%2C+C">Cristina Giannone</a>, 
<a href="/search/cs?searchtype=author&query=Favalli%2C+A">Andrea Favalli</a>, 
<a href="/search/cs?searchtype=author&query=Romagnoli%2C+R">Raniero Romagnoli</a>, 
<a href="/search/cs?searchtype=author&query=Zanzotto%2C+F+M">Fabio Massimo Zanzotto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Understanding textual description to generate code seems to be an achieved
capability of instruction-following Large Language Models (LLMs) in zero-shot
scenario. However, there is a severe possibility that this translation ability
may be influenced by having seen target textual descriptions and the related
code. This effect is known as Data Contamination.
<br />In this study, we investigate the impact of Data Contamination on the
performance of GPT-3.5 in the Text-to-SQL code-generating tasks. Hence, we
introduce a novel method to detect Data Contamination in GPTs and examine
GPT-3.5's Text-to-SQL performances using the known Spider Dataset and our new
unfamiliar dataset Termite. Furthermore, we analyze GPT-3.5's efficacy on
databases with modified information via an adversarial table disconnection
(ATD) approach, complicating Text-to-SQL tasks by removing structural pieces of
information from the database. Our results indicate a significant performance
drop in GPT-3.5 on the unfamiliar Termite dataset, even with ATD modifications,
highlighting the effect of Data Contamination on LLMs in Text-to-SQL
translation tasks.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08101" title="Abstract">arXiv:2402.08101</a> [<a href="/pdf/2402.08101" title="Download PDF">pdf</a>, <a href="/format/2402.08101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auditing Work: Exploring the New York City algorithmic bias audit regime
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Groves%2C+L">Lara Groves</a>, 
<a href="/search/cs?searchtype=author&query=Metcalf%2C+J">Jacob Metcalf</a>, 
<a href="/search/cs?searchtype=author&query=Kennedy%2C+A">Alayna Kennedy</a>, 
<a href="/search/cs?searchtype=author&query=Vecchione%2C+B">Briana Vecchione</a>, 
<a href="/search/cs?searchtype=author&query=Strait%2C+A">Andrew Strait</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">In July 2023, New York City (NYC) initiated the first algorithm auditing
system for commercial machine-learning systems. Local Law 144 (LL 144) mandates
NYC-based employers using automated employment decision-making tools (AEDTs) in
hiring to undergo annual bias audits conducted by an independent auditor. This
paper examines lessons from LL 144 for other national algorithm auditing
attempts. Through qualitative interviews with 16 experts and practitioners
within the regime, we find that LL 144 has not effectively established an
auditing regime. The law fails to clearly define key aspects, such as AEDTs and
independent auditors, leading auditors, AEDT vendors, and companies using AEDTs
to define the law's practical implementation in ways that failed to protect job
applicants. Contributing factors include the law's flawed transparency-driven
theory of change, industry lobbying narrowing the definition of AEDTs,
practical and cultural challenges faced by auditors in accessing data, and wide
disagreement over what constitutes a legitimate auditor, resulting in four
distinct 'auditor roles.' We conclude with four recommendations for
policymakers seeking to create similar bias auditing regimes, emphasizing
clearer definitions, metrics, and increased accountability. By exploring LL 144
through the lens of auditors, our paper advances the evidence base around audit
as an accountability mechanism, providing guidance for policymakers seeking to
create similar regimes.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08105" title="Abstract">arXiv:2402.08105</a> [<a href="/pdf/2402.08105" title="Download PDF">pdf</a>, <a href="/format/2402.08105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Cartesian Product Graphs with Laplacian Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Changhao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Mishne%2C+G">Gal Mishne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Graph Laplacian learning, also known as network topology inference, is a
problem of great interest to multiple communities. In Gaussian graphical models
(GM), graph learning amounts to endowing covariance selection with the
Laplacian structure. In graph signal processing (GSP), it is essential to infer
the unobserved graph from the outputs of a filtering system. In this paper, we
study the problem of learning Cartesian product graphs under Laplacian
constraints. The Cartesian graph product is a natural way for modeling
higher-order conditional dependencies and is also the key for generalizing GSP
to multi-way tensors. We establish statistical consistency for the penalized
maximum likelihood estimation (MLE) of a Cartesian product Laplacian, and
propose an efficient algorithm to solve the problem. We also extend our method
for efficient joint graph learning and imputation in the presence of structural
missing values. Experiments on synthetic and real-world datasets demonstrate
that our method is superior to previous GSP and GM methods.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08109" title="Abstract">arXiv:2402.08109</a> [<a href="/pdf/2402.08109" title="Download PDF">pdf</a>, <a href="/ps/2402.08109" title="Download PostScript">ps</a>, <a href="/format/2402.08109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Data to Decisions: The Transformational Power of Machine Learning  in Business Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gangadharan%2C+K">Kapilya Gangadharan</a>, 
<a href="/search/cs?searchtype=author&query=Malathi%2C+K">K. Malathi</a>, 
<a href="/search/cs?searchtype=author&query=Purandaran%2C+A">Anoop Purandaran</a>, 
<a href="/search/cs?searchtype=author&query=Subramanian%2C+B">Barathi Subramanian</a>, 
<a href="/search/cs?searchtype=author&query=Jeyaraj%2C+R">Rathinaraja Jeyaraj</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 55 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">This research aims to explore the impact of Machine Learning (ML) on the
evolution and efficacy of Recommendation Systems (RS), particularly in the
context of their growing significance in commercial business environments.
Methodologically, the study delves into the role of ML in crafting and refining
these systems, focusing on aspects such as data sourcing, feature engineering,
and the importance of evaluation metrics, thereby highlighting the iterative
nature of enhancing recommendation algorithms. The deployment of Recommendation
Engines (RE), driven by advanced algorithms and data analytics, is explored
across various domains, showcasing their significant impact on user experience
and decision-making processes. These engines not only streamline information
discovery and enhance collaboration but also accelerate knowledge acquisition,
proving vital in navigating the digital landscape for businesses. They
contribute significantly to sales, revenue, and the competitive edge of
enterprises by offering improved recommendations that align with individual
customer needs. The research identifies the increasing expectation of users for
a seamless, intuitive online experience, where content is personalized and
dynamically adapted to changing preferences. Future research directions include
exploring advancements in deep learning models, ethical considerations in the
deployment of RS, and addressing scalability challenges. This study emphasizes
the indispensability of comprehending and leveraging ML in RS for researchers
and practitioners, to tap into the full potential of personalized
recommendation in commercial business prospects.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08112" title="Abstract">arXiv:2402.08112</a> [<a href="/pdf/2402.08112" title="Download PDF">pdf</a>, <a href="/format/2402.08112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Competition Winning Deep Reinforcement Learning Agent in microRTS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goodfriend%2C+S">Scott Goodfriend</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Scripted agents have predominantly won the five previous iterations of the
IEEE microRTS ($\mu$RTS) competitions hosted at CIG and CoG. Despite Deep
Reinforcement Learning (DRL) algorithms making significant strides in real-time
strategy (RTS) games, their adoption in this primarily academic competition has
been limited due to the considerable training resources required and the
complexity inherent in creating and debugging such agents. RAISocketAI is the
first DRL agent to win the IEEE microRTS competition. In a benchmark without
performance constraints, RAISocketAI regularly defeated the two prior
competition winners. This first competition-winning DRL submission can be a
benchmark for future microRTS competitions and a starting point for future DRL
research. Iteratively fine-tuning the base policy and transfer learning to
specific maps were critical to RAISocketAI's winning performance. These
strategies can be used to economically train future DRL agents. Further work in
Imitation Learning using Behavior Cloning and fine-tuning these models with DRL
has proven promising as an efficient way to bootstrap models with demonstrated,
competitive behaviors.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08113" title="Abstract">arXiv:2402.08113</a> [<a href="/pdf/2402.08113" title="Download PDF">pdf</a>, <a href="/format/2402.08113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Addressing cognitive bias in medical language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmidgall%2C+S">Samuel Schmidgall</a>, 
<a href="/search/cs?searchtype=author&query=Harris%2C+C">Carl Harris</a>, 
<a href="/search/cs?searchtype=author&query=Essien%2C+I">Ime Essien</a>, 
<a href="/search/cs?searchtype=author&query=Olshvang%2C+D">Daniel Olshvang</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+T">Tawsifur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J+W">Ji Woong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ziaei%2C+R">Rojin Ziaei</a>, 
<a href="/search/cs?searchtype=author&query=Eshraghian%2C+J">Jason Eshraghian</a>, 
<a href="/search/cs?searchtype=author&query=Abadir%2C+P">Peter Abadir</a>, 
<a href="/search/cs?searchtype=author&query=Chellappa%2C+R">Rama Chellappa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">The integration of large language models (LLMs) into the medical field has
gained significant attention due to their promising accuracy in simulated
clinical decision-making settings. However, clinical decision-making is more
complex than simulations because physicians' decisions are shaped by many
factors, including the presence of cognitive bias. However, the degree to which
LLMs are susceptible to the same cognitive biases that affect human clinicians
remains unexplored. Our hypothesis posits that when LLMs are confronted with
clinical questions containing cognitive biases, they will yield significantly
less accurate responses compared to the same questions presented without such
biases.In this study, we developed BiasMedQA, a novel benchmark for evaluating
cognitive biases in LLMs applied to medical tasks. Using BiasMedQA we evaluated
six LLMs, namely GPT-4, Mixtral-8x70B, GPT-3.5, PaLM-2, Llama 2 70B-chat, and
the medically specialized PMC Llama 13B. We tested these models on 1,273
questions from the US Medical Licensing Exam (USMLE) Steps 1, 2, and 3,
modified to replicate common clinically-relevant cognitive biases. Our analysis
revealed varying effects for biases on these LLMs, with GPT-4 standing out for
its resilience to bias, in contrast to Llama 2 70B-chat and PMC Llama 13B,
which were disproportionately affected by cognitive bias. Our findings
highlight the critical need for bias mitigation in the development of medical
LLMs, pointing towards safer and more reliable applications in healthcare.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08114" title="Abstract">arXiv:2402.08114</a> [<a href="/pdf/2402.08114" title="Download PDF">pdf</a>, <a href="/format/2402.08114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Preference Learning for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muldrew%2C+W">William Muldrew</a>, 
<a href="/search/cs?searchtype=author&query=Hayes%2C+P">Peter Hayes</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingtian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Barber%2C+D">David Barber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">As large language models (LLMs) become more capable, fine-tuning techniques
for aligning with human intent are increasingly important. A key consideration
for aligning these models is how to most effectively use human resources, or
model resources in the case where LLMs themselves are used as oracles.
Reinforcement learning from Human or AI preferences (RLHF/RLAIF) is the most
prominent example of such a technique, but is complex and often unstable.
Direct Preference Optimization (DPO) has recently been proposed as a simpler
and more stable alternative. In this work, we develop an active learning
strategy for DPO to make better use of preference labels. We propose a
practical acquisition function for prompt/completion pairs based on the
predictive entropy of the language model and a measure of certainty of the
implicit preference model optimized by DPO. We demonstrate how our approach
improves both the rate of learning and final performance of fine-tuning on
pairwise preference data.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08115" title="Abstract">arXiv:2402.08115</a> [<a href="/pdf/2402.08115" title="Download PDF">pdf</a>, <a href="/format/2402.08115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Self-Verification Limitations of Large Language Models on  Reasoning and Planning Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stechly%2C+K">Kaya Stechly</a>, 
<a href="/search/cs?searchtype=author&query=Valmeekam%2C+K">Karthik Valmeekam</a>, 
<a href="/search/cs?searchtype=author&query=Kambhampati%2C+S">Subbarao Kambhampati</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2310.12397">arXiv:2310.12397</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">There has been considerable divergence of opinion on the reasoning abilities
of Large Language Models (LLMs). While the initial optimism that reasoning
might emerge automatically with scale has been tempered thanks to a slew of
counterexamples--ranging from multiplication to simple planning--there persists
a wide spread belief that LLMs can self-critique and improve their own
solutions in an iterative fashion. This belief seemingly rests on the
assumption that verification of correctness should be easier than generation--a
rather classical argument from computational complexity--which should be
irrelevant to LLMs to the extent that what they are doing is approximate
retrieval. In this paper, we set out to systematically investigate the
effectiveness of iterative prompting in the context of reasoning and planning.
We present a principled empirical study of the performance of GPT-4 in three
domains: Game of 24, Graph Coloring, and STRIPS planning. We experiment both
with the model critiquing its own answers and with an external correct reasoner
verifying proposed solutions. In each case, we analyze whether the content of
criticisms actually affects bottom line performance, and whether we can ablate
elements of the augmented system without losing performance. We observe
significant performance collapse with self-critique, significant performance
gains with sound external verification, but that the content of critique
doesn't matter to the performance of the system. In fact, merely re-prompting
with a sound verifier maintains most of the benefits of more involved setups.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08117" title="Abstract">arXiv:2402.08117</a> [<a href="/pdf/2402.08117" title="Download PDF">pdf</a>, <a href="/format/2402.08117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Universal Non-Parametric Approach For Improved Molecular Sequence  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+S">Sarwan Ali</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+T+E">Tamkanat E Ali</a>, 
<a href="/search/cs?searchtype=author&query=Chourasia%2C+P">Prakash Chourasia</a>, 
<a href="/search/cs?searchtype=author&query=Patterson%2C+M">Murray Patterson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at The Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">In the field of biological research, it is essential to comprehend the
characteristics and functions of molecular sequences. The classification of
molecular sequences has seen widespread use of neural network-based techniques.
Despite their astounding accuracy, these models often require a substantial
number of parameters and more data collection. In this work, we present a novel
approach based on the compression-based Model, motivated from
\cite{jiang2023low}, which combines the simplicity of basic compression
algorithms like Gzip and Bz2, with Normalized Compression Distance (NCD)
algorithm to achieve better performance on classification tasks without relying
on handcrafted features or pre-trained models. Firstly, we compress the
molecular sequence using well-known compression algorithms, such as Gzip and
Bz2. By leveraging the latent structure encoded in compressed files, we compute
the Normalized Compression Distance between each pair of molecular sequences,
which is derived from the Kolmogorov complexity. This gives us a distance
matrix, which is the input for generating a kernel matrix using a Gaussian
kernel. Next, we employ kernel Principal Component Analysis (PCA) to get the
vector representations for the corresponding molecular sequence, capturing
important structural and functional information. The resulting vector
representations provide an efficient yet effective solution for molecular
sequence analysis and can be used in ML-based downstream tasks. The proposed
approach eliminates the need for computationally intensive Deep Neural Networks
(DNNs), with their large parameter counts and data requirements. Instead, it
leverages a lightweight and universally accessible compression-based model.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08122" title="Abstract">arXiv:2402.08122</a> [<a href="/pdf/2402.08122" title="Download PDF">pdf</a>, <a href="/ps/2402.08122" title="Download PostScript">ps</a>, <a href="/format/2402.08122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unmasking honey adulteration : a breakthrough in quality assurance  through cutting-edge convolutional neural network analysis of thermal images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boulbarj%2C+I">Ilias Boulbarj</a>, 
<a href="/search/cs?searchtype=author&query=Abdelaziz%2C+B">Bouklouze Abdelaziz</a>, 
<a href="/search/cs?searchtype=author&query=Alami%2C+Y+E">Yousra El Alami</a>, 
<a href="/search/cs?searchtype=author&query=Samira%2C+D">Douzi Samira</a>, 
<a href="/search/cs?searchtype=author&query=Hassan%2C+D">Douzi Hassan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4th International Conference on AI, Machine Learning and Applications (AIMLA 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Honey, a natural product generated from organic sources, is widely recognized
for its revered reputation. Nevertheless, honey is susceptible to adulteration,
a situation that has substantial consequences for both the well-being of the
general population and the financial well-being of a country. Conventional
approaches for detecting honey adulteration are often associated with extensive
time requirements and restricted sensitivity. This paper presents a novel
approach to address the aforementioned issue by employing Convolutional Neural
Networks (CNNs) for the classification of honey samples based on thermal
images. The use of thermal imaging technique offers a significant advantage in
detecting adulterants, as it can reveal differences in temperature in honey
samples caused by variations in sugar composition, moisture levels, and other
substances used for adulteration. To establish a meticulous approach to
categorizing honey, a thorough dataset comprising thermal images of authentic
and tainted honey samples was collected. Several state-of-the-art Convolutional
Neural Network (CNN) models were trained and optimized using the dataset that
was gathered. Within this set of models, there exist pre-trained models such as
InceptionV3, Xception, VGG19, and ResNet that have exhibited exceptional
performance, achieving classification accuracies ranging from 88% to 98%.
Furthermore, we have implemented a more streamlined and less complex
convolutional neural network (CNN) model, outperforming comparable models with
an outstanding accuracy rate of 99%. This simplification offers not only the
sole advantage of the model, but it also concurrently offers a more efficient
solution in terms of resources and time. This approach offers a viable way to
implement quality control measures in the honey business, so guaranteeing the
genuineness and safety of this valuable organic commodity.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08125" title="Abstract">arXiv:2402.08125</a> [<a href="/pdf/2402.08125" title="Download PDF">pdf</a>, <a href="/format/2402.08125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Customizable Perturbation Synthesis for Robust SLAM Benchmarking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaohao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yongqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Ye Li</a>, 
<a href="/search/cs?searchtype=author&query=Raj%2C+B">Bhiksha Raj</a>, 
<a href="/search/cs?searchtype=author&query=Johnson-Roberson%2C+M">Matthew Johnson-Roberson</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaonan Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)

</div>
<p class="mathjax">Robustness is a crucial factor for the successful deployment of robots in
unstructured environments, particularly in the domain of Simultaneous
Localization and Mapping (SLAM). Simulation-based benchmarks have emerged as a
highly scalable approach for robustness evaluation compared to real-world data
collection. However, crafting a challenging and controllable noisy world with
diverse perturbations remains relatively under-explored. To this end, we
propose a novel, customizable pipeline for noisy data synthesis, aimed at
assessing the resilience of multi-modal SLAM models against various
perturbations. This pipeline incorporates customizable hardware setups,
software components, and perturbed environments. In particular, we introduce
comprehensive perturbation taxonomy along with a perturbation composition
toolbox, allowing the transformation of clean simulations into challenging
noisy environments. Utilizing the pipeline, we instantiate the Robust-SLAM
benchmark, which includes diverse perturbation types, to evaluate the risk
tolerance of existing advanced multi-modal SLAM models. Our extensive analysis
uncovers the susceptibilities of existing SLAM models to real-world
disturbance, despite their demonstrated accuracy in standard benchmarks. Our
perturbation synthesis toolbox, SLAM robustness evaluation pipeline, and
Robust-SLAM benchmark will be made publicly available at
https://github.com/Xiaohao-Xu/SLAM-under-Perturbation/.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08126" title="Abstract">arXiv:2402.08126</a> [<a href="/pdf/2402.08126" title="Download PDF">pdf</a>, <a href="/ps/2402.08126" title="Download PostScript">ps</a>, <a href="/format/2402.08126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextual Multinomial Logit Bandits with General Value Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengxiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haipeng Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Contextual multinomial logit (MNL) bandits capture many real-world assortment
recommendation problems such as online retailing/advertising. However, prior
work has only considered (generalized) linear value functions, which greatly
limits its applicability. Motivated by this fact, in this work, we consider
contextual MNL bandits with a general value function class that contains the
ground truth, borrowing ideas from a recent trend of studies on contextual
bandits. Specifically, we consider both the stochastic and the adversarial
settings, and propose a suite of algorithms, each with different
computation-regret trade-off. When applied to the linear case, our results not
only are the first ones with no dependence on a certain problem-dependent
constant that can be exponentially large, but also enjoy other advantages such
as computational efficiency, dimension-free regret bounds, or the ability to
handle completely adversarial contexts and rewards.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08127" title="Abstract">arXiv:2402.08127</a> [<a href="/pdf/2402.08127" title="Download PDF">pdf</a>, <a href="/format/2402.08127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Contextual Bandits with Uninformed Feedback Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengxiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haipeng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Mineiro%2C+P">Paul Mineiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Bandits with feedback graphs are powerful online learning models that
interpolate between the full information and classic bandit problems, capturing
many real-life applications. A recent work by Zhang et al. (2023) studies the
contextual version of this problem and proposes an efficient and optimal
algorithm via a reduction to online regression. However, their algorithm
crucially relies on seeing the feedback graph before making each decision,
while in many applications, the feedback graph is uninformed, meaning that it
is either only revealed after the learner makes her decision or even never
fully revealed at all. This work develops the first contextual algorithm for
such uninformed settings, via an efficient reduction to online regression over
both the losses and the graphs. Importantly, we show that it is critical to
learn the graphs using log loss instead of squared loss to obtain favorable
regret guarantees. We also demonstrate the empirical effectiveness of our
algorithm on a bidding application using both synthetic and real-world data.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08128" title="Abstract">arXiv:2402.08128</a> [<a href="/pdf/2402.08128" title="Download PDF">pdf</a>, <a href="/format/2402.08128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursive Joint Simulation in Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kovarik%2C+V">Vojtech Kovarik</a>, 
<a href="/search/cs?searchtype=author&query=Oesterheld%2C+C">Caspar Oesterheld</a>, 
<a href="/search/cs?searchtype=author&query=Conitzer%2C+V">Vincent Conitzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Game-theoretic dynamics between AI agents could differ from traditional
human-human interactions in various ways. One such difference is that it may be
possible to accurately simulate an AI agent, for example because its source
code is known. Our aim is to explore ways of leveraging this possibility to
achieve more cooperative outcomes in strategic settings. In this paper, we
study an interaction between AI agents where the agents run a recursive joint
simulation. That is, the agents first jointly observe a simulation of the
situation they face. This simulation in turn recursively includes additional
simulations (with a small chance of failure, to avoid infinite recursion), and
the results of all these nested simulations are observed before an action is
chosen. We show that the resulting interaction is strategically equivalent to
an infinitely repeated version of the original game, allowing a direct transfer
of existing results such as the various folk theorems.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08129" title="Abstract">arXiv:2402.08129</a> [<a href="/pdf/2402.08129" title="Download PDF">pdf</a>, <a href="/ps/2402.08129" title="Download PostScript">ps</a>, <a href="/format/2402.08129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Design of Affine Maximizer Mechanisms in Dynamic Settings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Curry%2C+M">Michael Curry</a>, 
<a href="/search/cs?searchtype=author&query=Thoma%2C+V">Vinzenz Thoma</a>, 
<a href="/search/cs?searchtype=author&query=Chakrabarti%2C+D">Darshan Chakrabarti</a>, 
<a href="/search/cs?searchtype=author&query=McAleer%2C+S">Stephen McAleer</a>, 
<a href="/search/cs?searchtype=author&query=Kroer%2C+C">Christian Kroer</a>, 
<a href="/search/cs?searchtype=author&query=Sandholm%2C+T">Tuomas Sandholm</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+N">Niao He</a>, 
<a href="/search/cs?searchtype=author&query=Seuken%2C+S">Sven Seuken</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the Thirty-Eighth Proceedings of the AAAI Conference on Artificial Intelligence 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Dynamic mechanism design is a challenging extension to ordinary mechanism
design in which the mechanism designer must make a sequence of decisions over
time in the face of possibly untruthful reports of participating agents.
Optimizing dynamic mechanisms for welfare is relatively well understood.
However, there has been less work on optimizing for other goals (e.g. revenue),
and without restrictive assumptions on valuations, it is remarkably challenging
to characterize good mechanisms. Instead, we turn to automated mechanism design
to find mechanisms with good performance in specific problem instances. In
fact, the situation is similar even in static mechanism design. However, in the
static case, optimization/machine learning-based automated mechanism design
techniques have been successful in finding high-revenue mechanisms in cases
beyond the reach of analytical results. We extend the class of affine maximizer
mechanisms to MDPs where agents may untruthfully report their rewards. This
extension results in a challenging bilevel optimization problem in which the
upper problem involves choosing optimal mechanism parameters, and the lower
problem involves solving the resulting MDP. Our approach can find truthful
dynamic mechanisms that achieve strong performance on goals other than welfare,
and can be applied to essentially any problem setting-without restrictions on
valuations-for which RL can learn optimal policies.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08132" title="Abstract">arXiv:2402.08132</a> [<a href="/pdf/2402.08132" title="Download PDF">pdf</a>, <a href="/ps/2402.08132" title="Download PostScript">ps</a>, <a href="/format/2402.08132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Resurgence of Recurrent Models for Long Sequences: Survey and  Research Opportunities in the Transformer Era
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tiezzi%2C+M">Matteo Tiezzi</a>, 
<a href="/search/cs?searchtype=author&query=Casoni%2C+M">Michele Casoni</a>, 
<a href="/search/cs?searchtype=author&query=Betti%2C+A">Alessandro Betti</a>, 
<a href="/search/cs?searchtype=author&query=Guidi%2C+T">Tommaso Guidi</a>, 
<a href="/search/cs?searchtype=author&query=Gori%2C+M">Marco Gori</a>, 
<a href="/search/cs?searchtype=author&query=Melacci%2C+S">Stefano Melacci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">A longstanding challenge for the Machine Learning community is the one of
developing models that are capable of processing and learning from very long
sequences of data. The outstanding results of Transformers-based networks
(e.g., Large Language Models) promotes the idea of parallel attention as the
key to succeed in such a challenge, obfuscating the role of classic sequential
processing of Recurrent Models. However, in the last few years, researchers who
were concerned by the quadratic complexity of self-attention have been
proposing a novel wave of neural models, which gets the best from the two
worlds, i.e., Transformers and Recurrent Nets. Meanwhile, Deep Space-State
Models emerged as robust approaches to function approximation over time, thus
opening a new perspective in learning from sequential data, followed by many
people in the field and exploited to implement a special class of (linear)
Recurrent Neural Networks. This survey is aimed at providing an overview of
these trends framed under the unifying umbrella of Recurrence. Moreover, it
emphasizes novel research opportunities that become prominent when abandoning
the idea of processing long sequences whose length is known-in-advance for the
more realistic setting of potentially infinite-length sequences, thus
intersecting the field of lifelong-online learning from streamed data.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08133" title="Abstract">arXiv:2402.08133</a> [<a href="/pdf/2402.08133" title="Download PDF">pdf</a>, <a href="/ps/2402.08133" title="Download PostScript">ps</a>, <a href="/format/2402.08133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Low-Degree Truncation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De%2C+A">Anindya De</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huan Li</a>, 
<a href="/search/cs?searchtype=author&query=Nadimpalli%2C+S">Shivam Nadimpalli</a>, 
<a href="/search/cs?searchtype=author&query=Servedio%2C+R+A">Rocco A. Servedio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We consider the following basic, and very broad, statistical problem: Given a
known high-dimensional distribution ${\cal D}$ over $\mathbb{R}^n$ and a
collection of data points in $\mathbb{R}^n$, distinguish between the two
possibilities that (i) the data was drawn from ${\cal D}$, versus (ii) the data
was drawn from ${\cal D}|_S$, i.e. from ${\cal D}$ subject to truncation by an
unknown truncation set $S \subseteq \mathbb{R}^n$.
<br />We study this problem in the setting where ${\cal D}$ is a high-dimensional
i.i.d. product distribution and $S$ is an unknown degree-$d$ polynomial
threshold function (one of the most well-studied types of Boolean-valued
function over $\mathbb{R}^n$). Our main results are an efficient algorithm when
${\cal D}$ is a hypercontractive distribution, and a matching lower bound:
<br />$\bullet$ For any constant $d$, we give a polynomial-time algorithm which
successfully distinguishes ${\cal D}$ from ${\cal D}|_S$ using $O(n^{d/2})$
samples (subject to mild technical conditions on ${\cal D}$ and $S$);
<br />$\bullet$ Even for the simplest case of ${\cal D}$ being the uniform
distribution over $\{+1, -1\}^n$, we show that for any constant $d$, any
distinguishing algorithm for degree-$d$ polynomial threshold functions must use
$\Omega(n^{d/2})$ samples.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08134" title="Abstract">arXiv:2402.08134</a> [<a href="/pdf/2402.08134" title="Download PDF">pdf</a>, <a href="/format/2402.08134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Randomized Algorithms for Symmetric Nonnegative Matrix Factorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hayashi%2C+K">Koby Hayashi</a>, 
<a href="/search/cs?searchtype=author&query=Aksoy%2C+S+G">Sinan G. Aksoy</a>, 
<a href="/search/cs?searchtype=author&query=Ballard%2C+G">Grey Ballard</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Haesun Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Optimization and Control (math.OC)

</div>
<p class="mathjax">Symmetric Nonnegative Matrix Factorization (SymNMF) is a technique in data
analysis and machine learning that approximates a symmetric matrix with a
product of a nonnegative, low-rank matrix and its transpose. To design faster
and more scalable algorithms for SymNMF we develop two randomized algorithms
for its computation. The first algorithm uses randomized matrix sketching to
compute an initial low-rank input matrix and proceeds to use this input to
rapidly compute a SymNMF. The second algorithm uses randomized leverage score
sampling to approximately solve constrained least squares problems. Many
successful methods for SymNMF rely on (approximately) solving sequences of
constrained least squares problems. We prove theoretically that leverage score
sampling can approximately solve nonnegative least squares problems to a chosen
accuracy with high probability. Finally we demonstrate that both methods work
well in practice by applying them to graph clustering tasks on large real world
data sets. These experiments show that our methods approximately maintain
solution quality and achieve significant speed ups for both large dense and
large sparse problems.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08135" title="Abstract">arXiv:2402.08135</a> [<a href="/pdf/2402.08135" title="Download PDF">pdf</a>, <a href="/format/2402.08135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A scalable, synergy-first backbone decomposition of higher-order  structures in complex systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Varley%2C+T+F">Thomas F. Varley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Other Statistics (stat.OT)

</div>
<p class="mathjax">Since its introduction in 2011, the partial information decomposition (PID)
has triggered an explosion of interest in the field of multivariate information
theory and the study of emergent, higher-order ("synergistic") interactions in
complex systems. Despite its power, however, the PID has a number of
limitations that restrict its general applicability: it scales poorly with
system size and the standard approach to decomposition hinges on a definition
of "redundancy", leaving synergy only vaguely defined as "that information not
redundant." Other heuristic measures, such as the O-information, have been
introduced, although these measures typically only provided a summary statistic
of redundancy/synergy dominance, rather than direct insight into the synergy
itself. To address this issue, we present an alternative decomposition that is
synergy-first, scales much more gracefully than the PID, and has a
straightforward interpretation. Our approach defines synergy as that
information in a set that would be lost following the minimally invasive
perturbation on any single element. By generalizing this idea to sets of
elements, we construct a totally ordered "backbone" of partial synergy atoms
that sweeps systems scales. Our approach starts with entropy, but can be
generalized to the Kullback-Leibler divergence, and by extension, to the total
correlation and the single-target mutual information. Finally, we show that
this approach can be used to decompose higher-order interactions beyond just
information theory: we demonstrate this by showing how synergistic combinations
of pairwise edges in a complex network supports signal communicability and
global integration. We conclude by discussing how this perspective on
synergistic structure (information-based or otherwise) can deepen our
understanding of part-whole relationships in complex systems.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08138" title="Abstract">arXiv:2402.08138</a> [<a href="/pdf/2402.08138" title="Download PDF">pdf</a>, <a href="/format/2402.08138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> H2O-SDF: Two-phase Learning for 3D Indoor Reconstruction using Object  Surface Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+M">Minyoung Park</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+M">Mirae Do</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+Y">YeonJae Shin</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+J">Jaeseok Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Jongkwang Hong</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Joongrock Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chul Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Advanced techniques using Neural Radiance Fields (NeRF), Signed Distance
Fields (SDF), and Occupancy Fields have recently emerged as solutions for 3D
indoor scene reconstruction. We introduce a novel two-phase learning approach,
H2O-SDF, that discriminates between object and non-object regions within indoor
environments. This method achieves a nuanced balance, carefully preserving the
geometric integrity of room layouts while also capturing intricate surface
details of specific objects. A cornerstone of our two-phase learning framework
is the introduction of the Object Surface Field (OSF), a novel concept designed
to mitigate the persistent vanishing gradient problem that has previously
hindered the capture of high-frequency details in other methods. Our proposed
approach is validated through several experiments that include ablation
studies.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08139" title="Abstract">arXiv:2402.08139</a> [<a href="/pdf/2402.08139" title="Download PDF">pdf</a>, <a href="/format/2402.08139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Consistently Oriented Basis for Eigenanalysis: Improved Directional  Statistics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Damask%2C+J">Jay Damask</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 11 figures, refer to <a href="/abs/1912.12983">arXiv:1912.12983</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The algorithm derived in this article, which builds upon the original paper,
takes a holistic view of the handedness of an orthonormal eigenvector matrix so
as to transfer what would have been labeled as a reflection in the original
algorithm into a rotation through a major arc in the new algorithm. In so
doing, the angular wrap-around on the interval {\pi} that exists in the
original is extended to a 2{\pi} interval for primary rotations, which in turn
provides clean directional statistics. The modified algorithm is detailed in
this article and an empirical example is shown. The empirical example is
analyzed in the context of random matrix theory, after which two methods are
discussed to stabilize eigenvector pointing directions as they evolve in time.
The thucyd Python package and source code, reported in the original paper, has
been updated to include the new algorithm and is freely available.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08144" title="Abstract">arXiv:2402.08144</a> [<a href="/pdf/2402.08144" title="Download PDF">pdf</a>, <a href="/format/2402.08144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Average-Case Analysis of Iterative Voting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kavner%2C+J">Joshua Kavner</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Lirong Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 63 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Iterative voting is a natural model of repeated strategic decision-making in
social choice when agents have the opportunity to update their votes prior to
finalizing the group decision. Prior work has analyzed the efficacy of
iterative plurality on the welfare of the chosen outcome at equilibrium,
relative to the truthful vote profile, via an adaptation of the price of
anarchy. However, prior analyses have only studied the worst-case and
average-case performances when agents' preferences are distributed by the
impartial culture. This work extends average-case analyses to a wider class of
distributions and distinguishes when iterative plurality improves or degrades
asymptotic welfare.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08145" title="Abstract">arXiv:2402.08145</a> [<a href="/pdf/2402.08145" title="Download PDF">pdf</a>, <a href="/format/2402.08145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Epistemic Exploration for Generalizable Planning and Learning in  Non-Stationary Settings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karia%2C+R">Rushang Karia</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+P">Pulkit Verma</a>, 
<a href="/search/cs?searchtype=author&query=Speranzon%2C+A">Alberto Speranzon</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+S">Siddharth Srivastava</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at ICAPS-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This paper introduces a new approach for continual planning and model
learning in non-stationary stochastic environments expressed using relational
representations. Such capabilities are essential for the deployment of
sequential decision-making systems in the uncertain, constantly evolving real
world. Working in such practical settings with unknown (and non-stationary)
transition systems and changing tasks, the proposed framework models gaps in
the agent's current state of knowledge and uses them to conduct focused,
investigative explorations. Data collected using these explorations is used for
learning generalizable probabilistic models for solving the current task
despite continual changes in the environment dynamics. Empirical evaluations on
several benchmark domains show that this approach significantly outperforms
planning and RL baselines in terms of sample complexity in non-stationary
settings. Theoretical results show that the system reverts to exhibit desirable
convergence properties when stationarity holds.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08147" title="Abstract">arXiv:2402.08147</a> [<a href="/pdf/2402.08147" title="Download PDF">pdf</a>, <a href="/format/2402.08147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verified Multi-Step Synthesis using Large Language Models and Monte  Carlo Tree Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brandfonbrener%2C+D">David Brandfonbrener</a>, 
<a href="/search/cs?searchtype=author&query=Raja%2C+S">Sibi Raja</a>, 
<a href="/search/cs?searchtype=author&query=Prasad%2C+T">Tarun Prasad</a>, 
<a href="/search/cs?searchtype=author&query=Loughridge%2C+C">Chloe Loughridge</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Henniger%2C+S">Simon Henniger</a>, 
<a href="/search/cs?searchtype=author&query=Byrd%2C+W+E">William E. Byrd</a>, 
<a href="/search/cs?searchtype=author&query=Zinkov%2C+R">Robert Zinkov</a>, 
<a href="/search/cs?searchtype=author&query=Amin%2C+N">Nada Amin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">We present an approach using Monte Carlo Tree Search (MCTS) to guide Large
Language Models (LLMs) to generate verified programs in Dafny, Lean and Coq.
Our method, which we call VMCTS, leverages the verifier inside the search
algorithm by checking partial programs at each step. In combination with the
LLM prior, the verifier feedback raises the synthesis capabilities of open
source models. On a set of five verified programming problems, we find that in
four problems where the base model cannot solve the question even when
re-sampling solutions for one hour, VMCTS can solve the problems within 6
minutes. The base model with VMCTS is even competitive with ChatGPT4 augmented
with plugins and multiple re-tries on these problems. Our code and benchmarks
are available at
https://github.com/namin/llm-verified-with-monte-carlo-tree-search .
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08155" title="Abstract">arXiv:2402.08155</a> [<a href="/pdf/2402.08155" title="Download PDF">pdf</a>, <a href="/format/2402.08155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CMA-R:Causal Mediation Analysis for Explaining Rumour Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+L">Lin Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiuzhen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+J+H">Jey Han Lau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures, Accepted by EACL 2024 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We apply causal mediation analysis to explain the decision-making process of
neural models for rumour detection on Twitter. Interventions at the input and
network level reveal the causal impacts of tweets and words in the model
output. We find that our approach CMA-R -- Causal Mediation Analysis for Rumour
detection -- identifies salient tweets that explain model predictions and show
strong agreement with human judgements for critical tweets determining the
truthfulness of stories. CMA-R can further highlight causally impactful words
in the salient tweets, providing another layer of interpretability and
transparency into these blackbox rumour detection systems. Code is available
at: https://github.com/ltian678/cma-r.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08156" title="Abstract">arXiv:2402.08156</a> [<a href="/pdf/2402.08156" title="Download PDF">pdf</a>, <a href="/ps/2402.08156" title="Download PostScript">ps</a>, <a href="/format/2402.08156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Group Decision-Making among Privacy-Aware Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papachristou%2C+M">Marios Papachristou</a>, 
<a href="/search/cs?searchtype=author&query=Rahimian%2C+M+A">M. Amin Rahimian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Multiagent Systems (cs.MA); Machine Learning (stat.ML)

</div>
<p class="mathjax">How can individuals exchange information to learn from each other despite
their privacy needs and security concerns? For example, consider individuals
deliberating a contentious topic and being concerned about divulging their
private experiences. Preserving individual privacy and enabling efficient
social learning are both important desiderata but seem fundamentally at odds
with each other and very hard to reconcile. We do so by controlling information
leakage using rigorous statistical guarantees that are based on differential
privacy (DP). Our agents use log-linear rules to update their beliefs after
communicating with their neighbors. Adding DP randomization noise to beliefs
provides communicating agents with plausible deniability with regard to their
private information and their network neighborhoods. We consider two learning
environments one for distributed maximum-likelihood estimation given a finite
number of private signals and another for online learning from an infinite,
intermittent signal stream. Noisy information aggregation in the finite case
leads to interesting tradeoffs between rejecting low-quality states and making
sure all high-quality states are accepted in the algorithm output. Our results
flesh out the nature of the trade-offs in both cases between the quality of the
group decision outcomes, learning accuracy, communication cost, and the level
of privacy protections that the agents are afforded.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08165" title="Abstract">arXiv:2402.08165</a> [<a href="/pdf/2402.08165" title="Download PDF">pdf</a>, <a href="/ps/2402.08165" title="Download PostScript">ps</a>, <a href="/format/2402.08165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What is a &quot;bug&quot;? On subjectivity, epistemic power, and implications for  software research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Widder%2C+D+G">David Gray Widder</a>, 
<a href="/search/cs?searchtype=author&query=Goues%2C+C+L">Claire Le Goues</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Considerable effort in software research and practice is spent on bugs.
Finding, reporting, tracking, triaging, attempting to fix them automatically,
detecting "bug smells" -these comprise a substantial portion of large projects'
time and development cost, and are of significant interest to researchers in
Software Engineering, Programming Languages, and beyond.
<br />But, what is a bug, exactly? While segmentation faults rarely spark joy, most
bugs are not so clear cut. Per the Oxford English Dictionary, the word "bug"
has been a colloquialism for an engineering "defect" at least since the 1870s.
Most modern software-oriented definitions speak to a disconnect between what a
developer intended and what a program actually does. Formal verification, from
its inception, has developed means to identify deviations from a formal
specification, expected to more or less fully encode desired behavior. However,
software is rarely accompanied by full and formal specifications, and this
intention is instead treated as implicit or partially-documented at best. The
International Software Testing Qualifications board writes: "A human being can
make an error (mistake), which produces a defect (fault, bug) in the program
code, or in a document. If a defect in code is executed, the system may fail to
do what it should do (or do something it shouldn't), causing a failure. Defects
may result in failures, but not all [do]". Most sources forsake this precision.
The influential paper "Finding bugs is easy" begins by saying "bug patterns are
code idioms that are often errors"-with no particular elaboration. Other work
relies on imperfect practical proxies for specifications. For example, in
automatic program repair research, a bug corresponds to a failing test case:
when the test passes, the bug is considered fixed.
<br />However, when we interrogate fairly straightforward definitions, they start
to break down...
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08170" title="Abstract">arXiv:2402.08170</a> [<a href="/pdf/2402.08170" title="Download PDF">pdf</a>, <a href="/format/2402.08170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLaGA: Large Language and Graph Assistant
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Runjin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jaiswal%2C+A">Ajay Jaiswal</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+N">Neil Shah</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph Neural Networks (GNNs) have empowered the advance in graph-structured
data analysis. Recently, the rise of Large Language Models (LLMs) like GPT-4
has heralded a new era in deep learning. However, their application to graph
data poses distinct challenges due to the inherent difficulty of translating
graph structures to language. To this end, we introduce the \textbf{L}arge
\textbf{L}anguage \textbf{a}nd \textbf{G}raph \textbf{A}ssistant
(\textbf{LLaGA}), an innovative model that effectively integrates LLM
capabilities to handle the complexities of graph-structured data. LLaGA retains
the general-purpose nature of LLMs while adapting graph data into a format
compatible with LLM input. LLaGA achieves this by reorganizing graph nodes to
structure-aware sequences and then mapping these into the token embedding space
through a versatile projector. LLaGA excels in versatility, generalizability
and interpretability, allowing it to perform consistently well across different
datasets and tasks, extend its ability to unseen datasets or tasks, and provide
explanations for graphs. Our extensive experiments across popular graph
benchmarks show that LLaGA delivers outstanding performance across four
datasets and three tasks using one single model, surpassing state-of-the-art
graph models in both supervised and zero-shot scenarios. Our code is available
at \url{https://github.com/ChenRunjin/LLaGA}
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08171" title="Abstract">arXiv:2402.08171</a> [<a href="/pdf/2402.08171" title="Download PDF">pdf</a>, <a href="/ps/2402.08171" title="Download PostScript">ps</a>, <a href="/format/2402.08171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Epistemic Power, Objectivity and Gender in AI Ethics Labor: Legitimizing  Located Complaints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Widder%2C+D+G">David Gray Widder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">What counts as legitimate AI ethics labor, and consequently, what are the
epistemic terms on which AI ethics claims are rendered legitimate? Based on 75
interviews with technologists including researchers, developers, open source
contributors, artists, and activists, this paper explores various epistemic
bases from which AI ethics is practiced. In the context of outside attacks on
AI ethics as an impediment to "progress," I show how some AI ethics practices
have reached toward scholarly authority, automation and quantification and
achieved some legitimacy, while those based on richly embodied and situated
lived experience have not. This paper draws the works of feminist Anthropology
and Science and Technology Studies (STS) scholars Diana Forsythe and Lucy
Suchman together with the works of postcolonial feminist theorist Sara Ahmed
and Black feminist theorist Kristie Dotson to examine the implications of
dominant AI ethics practices. I argue that by entrenching the epistemic power
of quantification, dominant AI ethics practices risk legitimizing AI ethics as
a project in equal and opposite measure to the extent that they delegitimize
and marginalize embodied and lived experiences as legitimate parts of the same
project. In response, I propose and sketch the idea of humble technical
practices: quantified or technical practices which specifically seek to make
their epistemic limits clear, with a view to flattening hierarchies of
epistemic power.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08172" title="Abstract">arXiv:2402.08172</a> [<a href="/pdf/2402.08172" title="Download PDF">pdf</a>, <a href="/format/2402.08172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Projection-Based Time-Divided Reduced Order Model for Fluid-Structure  Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Q">Qijia Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiquan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+P">Pengtao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaoping Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this paper, a type of novel projection-based, time-divided reduced order
model (ROM) is proposed for dynamic fluid-structure interaction (FSI) problems,
where spatial and temporal dimensions are partitioned as follows: spatially,
each kind of variable is separated from others in terms of its attribution
(fluid/structure), its category (velocity/pressure) and its component
(horizontal/vertical); temporally, basis functions are deliberately adopted in
small time windows tailored through extensive numerical trials. By the
combination of space and time decompositions, the proposed ROM enables
prolonged simulations under prescribed accuracy thresholds. Numerical
experiments are carried out by means of a numerical comparison between the
proposed ROM and corresponding full-order model (FOM) on solving a benchmark
problem of FSI with a vibrating elastic beam in the fluid flow, where the
representation of basis function sets on perturbation parameters is
investigated as well. Extensive numerical results demonstrate the accuracy and
efficiency of the proposed ROM. The developed numerical techniques are
dimension-independent, which can be seamlessly extended to high dimensional FSI
problems.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08174" title="Abstract">arXiv:2402.08174</a> [<a href="/pdf/2402.08174" title="Download PDF">pdf</a>, <a href="/format/2402.08174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Position Embedding of Graphs with Landmarks and Clustering  for Link Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsang Kim</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+S">Seungjun Baek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The International World Wide Web Conference (WWW) 2024, Accepted paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Learning positional information of nodes in a graph is important for link
prediction tasks. We propose a representation of positional information using
representative nodes called landmarks. A small number of nodes with high degree
centrality are selected as landmarks, which serve as reference points for the
nodes' positions. We justify this selection strategy for well-known random
graph models and derive closed-form bounds on the average path lengths
involving landmarks. In a model for power-law graphs, we prove that landmarks
provide asymptotically exact information on inter-node distances. We apply
theoretical insights to practical networks and propose Hierarchical Position
embedding with Landmarks and Clustering (HPLC). HPLC combines landmark
selection and graph clustering, where the graph is partitioned into densely
connected clusters in which nodes with the highest degree are selected as
landmarks. HPLC leverages the positional information of nodes based on
landmarks at various levels of hierarchy such as nodes' distances to landmarks,
inter-landmark distances and hierarchical grouping of clusters. Experiments
show that HPLC achieves state-of-the-art performances of link prediction on
various datasets in terms of HIT@K, MRR, and AUC. The code is available at
\url{https://github.com/kmswin1/HPLC}.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08178" title="Abstract">arXiv:2402.08178</a> [<a href="/pdf/2402.08178" title="Download PDF">pdf</a>, <a href="/format/2402.08178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LoTa-Bench: Benchmarking Language-oriented Task Planners for Embodied  Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jae-Woo Choi</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+Y">Youngwoo Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Ong%2C+H">Hyobin Ong</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jaehong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+M">Minsu Jang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024. Code: <a href="https://github.com/lbaa2022/LLMTaskPlanning">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Large language models (LLMs) have recently received considerable attention as
alternative solutions for task planning. However, comparing the performance of
language-oriented task planners becomes difficult, and there exists a dearth of
detailed exploration regarding the effects of various factors such as
pre-trained model selection and prompt construction. To address this, we
propose a benchmark system for automatically quantifying performance of task
planning for home-service embodied agents. Task planners are tested on two
pairs of datasets and simulators: 1) ALFRED and AI2-THOR, 2) an extension of
Watch-And-Help and VirtualHome. Using the proposed benchmark system, we perform
extensive experiments with LLMs and prompts, and explore several enhancements
of the baseline planner. We expect that the proposed benchmark tool would
accelerate the development of language-oriented task planners.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08180" title="Abstract">arXiv:2402.08180</a> [<a href="/pdf/2402.08180" title="Download PDF">pdf</a>, <a href="/ps/2402.08180" title="Download PostScript">ps</a>, <a href="/format/2402.08180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Structured Prediction with Fenchel--Young Losses and Improved  Surrogate Regret for Online Multiclass Classification with Logistic Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sakaue%2C+S">Shinsaku Sakaue</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+H">Han Bao</a>, 
<a href="/search/cs?searchtype=author&query=Tsuchiya%2C+T">Taira Tsuchiya</a>, 
<a href="/search/cs?searchtype=author&query=Oki%2C+T">Taihei Oki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper studies online structured prediction with full-information
feedback. For online multiclass classification, van der Hoeven (2020) has
obtained surrogate regret bounds independent of the time horizon, or
\emph{finite}, by introducing an elegant \emph{exploit-the-surrogate-gap}
framework. However, this framework has been limited to multiclass
classification primarily because it relies on a classification-specific
procedure for converting estimated scores to outputs. We extend the
exploit-the-surrogate-gap framework to online structured prediction with
\emph{Fenchel--Young losses}, a large family of surrogate losses including the
logistic loss for multiclass classification, obtaining finite surrogate regret
bounds in various structured prediction problems. To this end, we propose and
analyze \emph{randomized decoding}, which converts estimated scores to general
structured outputs. Moreover, by applying our decoding to online multiclass
classification with the logistic loss, we obtain a surrogate regret bound of
$O(B^2)$, where $B$ is the $\ell_2$-diameter of the domain. This bound is tight
up to logarithmic factors and improves the previous bound of $O(dB^2)$ due to
van der Hoeven (2020) by a factor of $d$, the number of classes.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08182" title="Abstract">arXiv:2402.08182</a> [<a href="/pdf/2402.08182" title="Download PDF">pdf</a>, <a href="/format/2402.08182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Continual Test-Time Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+F">Fan Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+K">Kaile Du</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hanyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guangcan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The prior drift is crucial in Continual Test-Time Adaptation (CTTA) methods
that only use unlabeled test data, as it can cause significant error
propagation. In this paper, we introduce VCoTTA, a variational Bayesian
approach to measure uncertainties in CTTA. At the source stage, we transform a
pre-trained deterministic model into a Bayesian Neural Network (BNN) via a
variational warm-up strategy, injecting uncertainties into the model. During
the testing time, we employ a mean-teacher update strategy using variational
inference for the student model and exponential moving average for the teacher
model. Our novel approach updates the student model by combining priors from
both the source and teacher models. The evidence lower bound is formulated as
the cross-entropy between the student and teacher models, along with the
Kullback-Leibler (KL) divergence of the prior mixture. Experimental results on
three datasets demonstrate the method's effectiveness in mitigating prior drift
within the CTTA framework.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08183" title="Abstract">arXiv:2402.08183</a> [<a href="/pdf/2402.08183" title="Download PDF">pdf</a>, <a href="/format/2402.08183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pixel Sentence Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chenghao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhuoxu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Danlu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hudson%2C+G+T">G Thomas Hudson</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yizhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+H">Haoran Duan</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenghua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jungong Han</a>, 
<a href="/search/cs?searchtype=author&query=Moubayed%2C+N+A">Noura Al Moubayed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Pretrained language models are long known to be subpar in capturing sentence
and document-level semantics. Though heavily investigated, transferring
perturbation-based methods from unsupervised visual representation learning to
NLP remains an unsolved problem. This is largely due to the discreteness of
subword units brought by tokenization of language models, limiting small
perturbations of inputs to form semantics-preserved positive pairs. In this
work, we conceptualize the learning of sentence-level textual semantics as a
visual representation learning process. Drawing from cognitive and linguistic
sciences, we introduce an unsupervised visual sentence representation learning
framework, employing visually-grounded text perturbation methods like typos and
word order shuffling, resonating with human cognitive patterns, and enabling
perturbation to texts to be perceived as continuous. Our approach is further
bolstered by large-scale unsupervised topical alignment training and natural
language inference supervision, achieving comparable performance in semantic
textual similarity (STS) to existing state-of-the-art NLP methods.
Additionally, we unveil our method's inherent zero-shot cross-lingual
transferability and a unique leapfrogging pattern across languages during
iterative training. To our knowledge, this is the first representation learning
method devoid of traditional language models for understanding sentence and
document semantics, marking a stride closer to human-like textual
comprehension. Our code is available at
https://github.com/gowitheflow-1998/Pixel-Linguist
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08184" title="Abstract">arXiv:2402.08184</a> [<a href="/pdf/2402.08184" title="Download PDF">pdf</a>, <a href="/format/2402.08184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling Multi-Agent Transfer Reinforcement Learning via Scenario  Independent Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nipu%2C+A+S">Ayesha Siddika Nipu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Siming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Harris%2C+A">Anthony Harris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE Conference on Games (CoG)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Multi-Agent Reinforcement Learning (MARL) algorithms are widely adopted in
tackling complex tasks that require collaboration and competition among agents
in dynamic Multi-Agent Systems (MAS). However, learning such tasks from scratch
is arduous and may not always be feasible, particularly for MASs with a large
number of interactive agents due to the extensive sample complexity. Therefore,
reusing knowledge gained from past experiences or other agents could
efficiently accelerate the learning process and upscale MARL algorithms. In
this study, we introduce a novel framework that enables transfer learning for
MARL through unifying various state spaces into fixed-size inputs that allow
one unified deep-learning policy viable in different scenarios within a MAS. We
evaluated our approach in a range of scenarios within the StarCraft Multi-Agent
Challenge (SMAC) environment, and the findings show significant enhancements in
multi-agent learning performance using maneuvering skills learned from other
scenarios compared to agents learning from scratch. Furthermore, we adopted
Curriculum Transfer Learning (CTL), enabling our deep learning policy to
progressively acquire knowledge and skills across pre-designed homogeneous
learning scenarios organized by difficulty levels. This process promotes inter-
and intra-agent knowledge transfer, leading to high multi-agent learning
performance in more complicated heterogeneous scenarios.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08185" title="Abstract">arXiv:2402.08185</a> [<a href="/pdf/2402.08185" title="Download PDF">pdf</a>, <a href="/format/2402.08185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Data-driven Weather Forecasting: Time-Sliding Data  Augmentation of ERA5
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheon%2C+M">Minjong Cheon</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+D">Daehyun Kang</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yo-Hwan Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Seon-Yu Kang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">Modern deep learning techniques, which mimic traditional numerical weather
prediction (NWP) models and are derived from global atmospheric reanalysis
data, have caused a significant revolution within a few years. In this new
paradigm, our research introduces a novel strategy that deviates from the
common dependence on high-resolution data, which is often constrained by
computational resources, and instead utilizes low-resolution data (2.5 degrees)
for global weather prediction and climate data analysis. Our main focus is
evaluating data-driven weather prediction (DDWP) frameworks, specifically
addressing sample size adequacy, structural improvements to the model, and the
ability of climate data to represent current climatic trends. By using the
Adaptive Fourier Neural Operator (AFNO) model via FourCastNet and a proposed
time-sliding method to inflate the dataset of the ECMWF Reanalysis v5 (ERA5),
this paper improves on conventional approaches by adding more variables and a
novel approach to data augmentation and processing. Our findings reveal that
despite the lower resolution, the proposed approach demonstrates considerable
accuracy in predicting atmospheric conditions, effectively rivaling
higher-resolution models. Furthermore, the study confirms the model's
proficiency in reflecting current climate trends and its potential in
predicting future climatic events, underscoring its utility in climate change
strategies. This research marks a pivotal step in the realm of meteorological
forecasting, showcasing the feasibility of lower-resolution data in producing
reliable predictions and opening avenues for more accessible and inclusive
climate modeling. The insights gleaned from this study not only contribute to
the advancement of climate science but also lay the groundwork for future
innovations in the field.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08187" title="Abstract">arXiv:2402.08187</a> [<a href="/pdf/2402.08187" title="Download PDF">pdf</a>, <a href="/format/2402.08187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning time-dependent PDE via graph neural networks and deep operator  network for robust accuracy on irregular grids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+S+W">Sung Woong Cho</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+Y">Jae Yong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+H+J">Hyung Ju Hwang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Scientific computing using deep learning has seen significant advancements in
recent years. There has been growing interest in models that learn the operator
from the parameters of a partial differential equation (PDE) to the
corresponding solutions. Deep Operator Network (DeepONet) and Fourier Neural
operator, among other models, have been designed with structures suitable for
handling functions as inputs and outputs, enabling real-time predictions as
surrogate models for solution operators. There has also been significant
progress in the research on surrogate models based on graph neural networks
(GNNs), specifically targeting the dynamics in time-dependent PDEs. In this
paper, we propose GraphDeepONet, an autoregressive model based on GNNs, to
effectively adapt DeepONet, which is well-known for successful operator
learning. GraphDeepONet exhibits robust accuracy in predicting solutions
compared to existing GNN-based PDE solver models. It maintains consistent
performance even on irregular grids, leveraging the advantages inherited from
DeepONet and enabling predictions on arbitrary grids. Additionally, unlike
traditional DeepONet and its variants, GraphDeepONet enables time extrapolation
for time-dependent PDE solutions. We also provide theoretical analysis of the
universal approximation capability of GraphDeepONet in approximating continuous
operators across arbitrary time intervals.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08189" title="Abstract">arXiv:2402.08189</a> [<a href="/pdf/2402.08189" title="Download PDF">pdf</a>, <a href="/format/2402.08189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulating Human Strategic Behavior: Comparing Single and Multi-agent  LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sreedhar%2C+K">Karthik Sreedhar</a>, 
<a href="/search/cs?searchtype=author&query=Chilton%2C+L">Lydia Chilton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">When creating plans, policies, or applications for people, it is challenging
for designers to think through the strategic ways that different people will
behave. Recently, Large Language Models (LLMs) have been shown to create
realistic simulations of human-like behavior based on personas. We build on
this to investigate whether LLMs can simulate human strategic behavior. Human
strategies are complex because they take into account social norms in addition
to aiming to maximize personal gain. The ultimatum game is a classic economics
experiment used to understand human strategic behavior in a social setting. It
shows that people will often choose to "punish" other players to enforce social
norms rather than to maximize personal profits. We test whether LLMs can
replicate this complex behavior in simulations. We compare two architectures:
single- and multi-agent LLMs. We compare their abilities to (1) simulate
human-like actions in the ultimatum game, (2) simulate two player
personalities, greedy and fair, and (3) create robust strategies that are
logically complete and consistent with personality. Our evaluation shows the
multi-agent architecture is much more accurate than single LLMs (88% vs. 50%)
in simulating human strategy creation and actions for personality pairs. Thus
there is potential to use LLMs to simulate human strategic behavior to help
designers, planners, and policymakers perform preliminary exploration of how
people behave in systems.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08191" title="Abstract">arXiv:2402.08191</a> [<a href="/pdf/2402.08191" title="Download PDF">pdf</a>, <a href="/format/2402.08191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> THE COLOSSEUM: A Benchmark for Evaluating Generalization for Robotic  Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pumacay%2C+W">Wilbert Pumacay</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+I">Ishika Singh</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Jiafei Duan</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+R">Ranjay Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Thomason%2C+J">Jesse Thomason</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+D">Dieter Fox</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">To realize effective large-scale, real-world robotic applications, we must
evaluate how well our robot policies adapt to changes in environmental
conditions. Unfortunately, a majority of studies evaluate robot performance in
environments closely resembling or even identical to the training setup. We
present THE COLOSSEUM, a novel simulation benchmark, with 20 diverse
manipulation tasks, that enables systematical evaluation of models across 12
axes of environmental perturbations. These perturbations include changes in
color, texture, and size of objects, table-tops, and backgrounds; we also vary
lighting, distractors, and camera pose. Using THE COLOSSEUM, we compare 4
state-of-the-art manipulation models to reveal that their success rate degrades
between 30-50% across these perturbation factors. When multiple perturbations
are applied in unison, the success rate degrades $\geq$75%. We identify that
changing the number of distractor objects, target object color, or lighting
conditions are the perturbations that reduce model performance the most. To
verify the ecological validity of our results, we show that our results in
simulation are correlated ($\bar{R}^2 = 0.614$) to similar perturbations in
real-world experiments. We open source code for others to use THE COLOSSEUM,
and also release code to 3D print the objects used to replicate the real-world
perturbations. Ultimately, we hope that THE COLOSSEUM will serve as a benchmark
to identify modeling decisions that systematically improve generalization for
manipulation. See https://robot-colosseum.github.io/ for more details.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08192" title="Abstract">arXiv:2402.08192</a> [<a href="/pdf/2402.08192" title="Download PDF">pdf</a>, <a href="/ps/2402.08192" title="Download PostScript">ps</a>, <a href="/format/2402.08192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monolithic Silicon-Photonics Linear-Algebra Accelerators Enabling  Next-Gen Massive MIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hsueh%2C+T">Tzu-Chien Hsueh</a>, 
<a href="/search/eess?searchtype=author&query=Fainman%2C+Y">Yeshaiahu Fainman</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+B">Bill Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures, 2 tables, 17 equations. arXiv admin note: substantial text overlap with <a href="/abs/2311.11224">arXiv:2311.11224</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP); Optics (physics.optics)

</div>
<p class="mathjax">A system-on-chip (SoC) photonic-electronic linear-algebra accelerator with
the features of wavelength-division-multiplexing (WDM) based broadband
photodetections and high-dimensional matrix-inversion operations fabricated in
advanced monolithic silicon-photonics (M-SiPh) semiconductor process technology
is proposed to achieve substantial leaps in computation density and energy
efficiency, including realistic considerations of energy/area overhead due to
electronic/photonic on-chip conversions, integrations, and calibrations through
holistic co-design methodologies to support linear-detection based massive
multiple-input multiple-output (MIMO) decoding technology requiring the
inversion of channel matrices and other emergent applications limited by
linear-algebra computation capacities.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08193" title="Abstract">arXiv:2402.08193</a> [<a href="/pdf/2402.08193" title="Download PDF">pdf</a>, <a href="/format/2402.08193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Ensemble Belief Propagation for Efficient Inference in  High-Dimensional Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=MacKinlay%2C+D">Dan MacKinlay</a>, 
<a href="/search/cs?searchtype=author&query=Tsuchida%2C+R">Russell Tsuchida</a>, 
<a href="/search/cs?searchtype=author&query=Pagendam%2C+D">Dan Pagendam</a>, 
<a href="/search/cs?searchtype=author&query=Kuhnert%2C+P">Petra Kuhnert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under conference submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Efficient inference in high-dimensional models remains a central challenge in
machine learning. This paper introduces the Gaussian Ensemble Belief
Propagation (GEnBP) algorithm, a fusion of the Ensemble Kalman filter and
Gaussian belief propagation (GaBP) methods. GEnBP updates ensembles by passing
low-rank local messages in a graphical model structure. This combination
inherits favourable qualities from each method. Ensemble techniques allow GEnBP
to handle high-dimensional states, parameters and intricate, noisy, black-box
generation processes. The use of local messages in a graphical model structure
ensures that the approach is suited to distributed computing and can
efficiently handle complex dependence structures. GEnBP is particularly
advantageous when the ensemble size is considerably smaller than the inference
dimension. This scenario often arises in fields such as spatiotemporal
modelling, image processing and physical model inversion. GEnBP can be applied
to general problem structures, including jointly learning system parameters,
observation parameters, and latent state variables.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08195" title="Abstract">arXiv:2402.08195</a> [<a href="/pdf/2402.08195" title="Download PDF">pdf</a>, <a href="/format/2402.08195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimized Information Flow for Transformer Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kugarajeevan%2C+J">Janani Kugarajeevan</a>, 
<a href="/search/cs?searchtype=author&query=Kokul%2C+T">Thanikasalam Kokul</a>, 
<a href="/search/cs?searchtype=author&query=Ramanan%2C+A">Amirthalingam Ramanan</a>, 
<a href="/search/cs?searchtype=author&query=Fernando%2C+S">Subha Fernando</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">One-stream Transformer trackers have shown outstanding performance in
challenging benchmark datasets over the last three years, as they enable
interaction between the target template and search region tokens to extract
target-oriented features with mutual guidance. Previous approaches allow free
bidirectional information flow between template and search tokens without
investigating their influence on the tracker's discriminative capability. In
this study, we conducted a detailed study on the information flow of the tokens
and based on the findings, we propose a novel Optimized Information Flow
Tracking (OIFTrack) framework to enhance the discriminative capability of the
tracker. The proposed OIFTrack blocks the interaction from all search tokens to
target template tokens in early encoder layers, as the large number of
non-target tokens in the search region diminishes the importance of
target-specific features. In the deeper encoder layers of the proposed tracker,
search tokens are partitioned into target search tokens and non-target search
tokens, allowing bidirectional flow from target search tokens to template
tokens to capture the appearance changes of the target. In addition, since the
proposed tracker incorporates dynamic background cues, distractor objects are
successfully avoided by capturing the surrounding information of the target.
The OIFTrack demonstrated outstanding performance in challenging benchmarks,
particularly excelling in the one-shot tracking benchmark GOT-10k, achieving an
average overlap of 74.6\%. The code, models, and results of this work are
available at \url{https://github.com/JananiKugaa/OIFTrack}
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08200" title="Abstract">arXiv:2402.08200</a> [<a href="/pdf/2402.08200" title="Download PDF">pdf</a>, <a href="/format/2402.08200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Tuning Text-To-Image Diffusion Models for Class-Wise Spurious  Feature Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=MaungMaung%2C+A">AprilPyone MaungMaung</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+H">Huy H. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Kiya%2C+H">Hitoshi Kiya</a>, 
<a href="/search/cs?searchtype=author&query=Echizen%2C+I">Isao Echizen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose a method for generating spurious features by leveraging
large-scale text-to-image diffusion models. Although the previous work detects
spurious features in a large-scale dataset like ImageNet and introduces
Spurious ImageNet, we found that not all spurious images are spurious across
different classifiers. Although spurious images help measure the reliance of a
classifier, filtering many images from the Internet to find more spurious
features is time-consuming. To this end, we utilize an existing approach of
personalizing large-scale text-to-image diffusion models with available
discovered spurious images and propose a new spurious feature similarity loss
based on neural features of an adversarially robust model. Precisely, we
fine-tune Stable Diffusion with several reference images from Spurious ImageNet
with a modified objective incorporating the proposed spurious-feature
similarity loss. Experiment results show that our method can generate spurious
images that are consistently spurious across different classifiers. Moreover,
the generated spurious images are visually similar to reference images from
Spurious ImageNet.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08202" title="Abstract">arXiv:2402.08202</a> [<a href="/pdf/2402.08202" title="Download PDF">pdf</a>, <a href="/format/2402.08202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Confronting Discrimination in Classification: Smote Based on  Marginalized Minorities in the Kernel Space for Imbalanced Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+L">Lingyun Zhong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Financial fraud detection poses a typical challenge characterized by class
imbalance, where instances of fraud are extremely rare but can lead to
unpredictable economic losses if misidentified. Precisely classifying these
critical minority samples represents a challenging task within the
classification. The primary difficulty arises from mainstream classifiers,
which often exhibit "implicit discrimination" against minority samples in
evaluation metrics, which results in frequent misclassifications, and the key
to the problem lies in the overlap of feature spaces between majority and
minority samples. To address these challenges, oversampling is a feasible
solution, yet current classical oversampling methods often lack the necessary
caution in sample selection, exacerbating feature space overlap. In response,
we propose a novel classification oversampling approach based on the decision
boundary and sample proximity relationships. This method carefully considers
the distance between critical samples and the decision hyperplane, as well as
the density of surrounding samples, resulting in an adaptive oversampling
strategy in the kernel space. Finally, we test the proposed method on a classic
financial fraud dataset, and the results show that our proposed method provides
an effective and robust solution that can improve the classification accuracy
of minorities.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08205" title="Abstract">arXiv:2402.08205</a> [<a href="/pdf/2402.08205" title="Download PDF">pdf</a>, <a href="/format/2402.08205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TurtleRabbit 2024 SSL Team Description Paper
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trinh%2C+L">Linh Trinh</a>, 
<a href="/search/cs?searchtype=author&query=Anzuman%2C+A">Alif Anzuman</a>, 
<a href="/search/cs?searchtype=author&query=Batkhuu%2C+E">Eric Batkhuu</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+D">Dychen Chan</a>, 
<a href="/search/cs?searchtype=author&query=Graf%2C+L">Lisa Graf</a>, 
<a href="/search/cs?searchtype=author&query=Gurung%2C+D">Darpan Gurung</a>, 
<a href="/search/cs?searchtype=author&query=Jamal%2C+T">Tharunimm Jamal</a>, 
<a href="/search/cs?searchtype=author&query=Namgyal%2C+J">Jigme Namgyal</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+J">Jason Ng</a>, 
<a href="/search/cs?searchtype=author&query=Tsang%2C+W+L">Wing Lam Tsang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X+R">X. Rosalind Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yilmaz%2C+E">Eren Yilmaz</a>, 
<a href="/search/cs?searchtype=author&query=Obst%2C+O">Oliver Obst</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted paper as part of the qualification for RoboCup 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">TurtleRabbit is a new RoboCup SSL team from Western Sydney University. This
team description paper presents our approach in navigating some of the
challenges in developing a new SSL team from scratch. SSL is dominated by teams
with extensive experience and customised equipment that has been developed over
many years. Here, we outline our approach in overcoming some of the
complexities associated with replicating advanced open-sourced designs and
managing the high costs of custom components. Opting for simplicity and
cost-effectiveness, our strategy primarily employs off-the-shelf electronics
components and ``hobby'' brushless direct current (BLDC) motors, complemented
by 3D printing and CNC milling. This approach helped us to streamline the
development process and, with our open-sourced hardware design, hopefully will
also lower the bar for other teams to enter RoboCup SSL in the future. The
paper details the specific hardware choices, their approximate costs, the
integration of electronics and mechanics, and the initial steps taken in
software development, for our entry into SSL that aims to be simple yet
competitive.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08207" title="Abstract">arXiv:2402.08207</a> [<a href="/pdf/2402.08207" title="Download PDF">pdf</a>, <a href="/format/2402.08207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Translating Images to Road Network:A Non-Autoregressive  Sequence-to-Sequence Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiachen Lu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+R">Renyuan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xinyue Cai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+F">Feng Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 Oral Presentation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The extraction of road network is essential for the generation of
high-definition maps since it enables the precise localization of road
landmarks and their interconnections. However, generating road network poses a
significant challenge due to the conflicting underlying combination of
Euclidean (e.g., road landmarks location) and non-Euclidean (e.g., road
topological connectivity) structures. Existing methods struggle to merge the
two types of data domains effectively, but few of them address it properly.
Instead, our work establishes a unified representation of both types of data
domain by projecting both Euclidean and non-Euclidean data into an integer
series called RoadNet Sequence. Further than modeling an auto-regressive
sequence-to-sequence Transformer model to understand RoadNet Sequence, we
decouple the dependency of RoadNet Sequence into a mixture of auto-regressive
and non-autoregressive dependency. Building on this, our proposed
non-autoregressive sequence-to-sequence approach leverages non-autoregressive
dependencies while fixing the gap towards auto-regressive dependencies,
resulting in success on both efficiency and accuracy. Extensive experiments on
nuScenes dataset demonstrate the superiority of RoadNet Sequence representation
and the non-autoregressive approach compared to existing state-of-the-art
alternatives. The code is open-source on
https://github.com/fudan-zvg/RoadNetworkTRansformer.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08208" title="Abstract">arXiv:2402.08208</a> [<a href="/pdf/2402.08208" title="Download PDF">pdf</a>, <a href="/format/2402.08208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inherent Diverse Redundant Safety Mechanisms for AI-based Software  Elements in Automotive Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pitale%2C+M">Mandar Pitale</a>, 
<a href="/search/cs?searchtype=author&query=Abbaspour%2C+A">Alireza Abbaspour</a>, 
<a href="/search/cs?searchtype=author&query=Upadhyay%2C+D">Devesh Upadhyay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article is accepted for the SAE WCX 2024 conference proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This paper explores the role and challenges of Artificial Intelligence (AI)
algorithms, specifically AI-based software elements, in autonomous driving
systems. These AI systems are fundamental in executing real-time critical
functions in complex and high-dimensional environments. They handle vital tasks
like multi-modal perception, cognition, and decision-making tasks such as
motion planning, lane keeping, and emergency braking. A primary concern relates
to the ability (and necessity) of AI models to generalize beyond their initial
training data. This generalization issue becomes evident in real-time
scenarios, where models frequently encounter inputs not represented in their
training or validation data. In such cases, AI systems must still function
effectively despite facing distributional or domain shifts. This paper
investigates the risk associated with overconfident AI models in
safety-critical applications like autonomous driving. To mitigate these risks,
methods for training AI models that help maintain performance without
overconfidence are proposed. This involves implementing certainty reporting
architectures and ensuring diverse training data. While various
distribution-based methods exist to provide safety mechanisms for AI models,
there is a noted lack of systematic assessment of these methods, especially in
the context of safety-critical automotive applications. Many methods in the
literature do not adapt well to the quick response times required in
safety-critical edge applications. This paper reviews these methods, discusses
their suitability for safety-critical applications, and highlights their
strengths and limitations. The paper also proposes potential improvements to
enhance the safety and reliability of AI algorithms in autonomous vehicles in
the context of rapid and accurate decision-making processes.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08209" title="Abstract">arXiv:2402.08209</a> [<a href="/pdf/2402.08209" title="Download PDF">pdf</a>, <a href="/format/2402.08209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Thresholding Data Shapley for Data Cleansing Using Multi-Armed Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Namba%2C+H">Hiroyuki Namba</a>, 
<a href="/search/cs?searchtype=author&query=Horiguchi%2C+S">Shota Horiguchi</a>, 
<a href="/search/cs?searchtype=author&query=Hamamoto%2C+M">Masaki Hamamoto</a>, 
<a href="/search/cs?searchtype=author&query=Egi%2C+M">Masashi Egi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Data cleansing aims to improve model performance by removing a set of harmful
instances from the training dataset. Data Shapley is a common theoretically
guaranteed method to evaluate the contribution of each instance to model
performance; however, it requires training on all subsets of the training data,
which is computationally expensive. In this paper, we propose an
iterativemethod to fast identify a subset of instances with low data Shapley
values by using the thresholding bandit algorithm. We provide a theoretical
guarantee that the proposed method can accurately select harmful instances if a
sufficiently large number of iterations is conducted. Empirical evaluation
using various models and datasets demonstrated that the proposed method
efficiently improved the computational speed while maintaining the model
performance.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08211" title="Abstract">arXiv:2402.08211</a> [<a href="/pdf/2402.08211" title="Download PDF">pdf</a>, <a href="/format/2402.08211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer Mechanisms Mimic Frontostriatal Gating Operations When  Trained on Human Working Memory Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Traylor%2C+A">Aaron Traylor</a>, 
<a href="/search/cs?searchtype=author&query=Merullo%2C+J">Jack Merullo</a>, 
<a href="/search/cs?searchtype=author&query=Frank%2C+M+J">Michael J. Frank</a>, 
<a href="/search/cs?searchtype=author&query=Pavlick%2C+E">Ellie Pavlick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Models based on the Transformer neural network architecture have seen success
on a wide variety of tasks that appear to require complex "cognitive branching"
-- or the ability to maintain pursuit of one goal while accomplishing others.
In cognitive neuroscience, success on such tasks is thought to rely on
sophisticated frontostriatal mechanisms for selective \textit{gating}, which
enable role-addressable updating -- and later readout -- of information to and
from distinct "addresses" of memory, in the form of clusters of neurons.
However, Transformer models have no such mechanisms intentionally built-in. It
is thus an open question how Transformers solve such tasks, and whether the
mechanisms that emerge to help them to do so bear any resemblance to the gating
mechanisms in the human brain. In this work, we analyze the mechanisms that
emerge within a vanilla attention-only Transformer trained on a simple sequence
modeling task inspired by a task explicitly designed to study working memory
gating in computational cognitive neuroscience. We find that, as a result of
training, the self-attention mechanism within the Transformer specializes in a
way that mirrors the input and output gating mechanisms which were explicitly
incorporated into earlier, more biologically-inspired architectures. These
results suggest opportunities for future research on computational similarities
between modern AI architectures and models of the human brain.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08212" title="Abstract">arXiv:2402.08212</a> [<a href="/pdf/2402.08212" title="Download PDF">pdf</a>, <a href="/format/2402.08212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BBSEA: An Exploration of Brain-Body Synchronization for Embodied Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sizhe Yang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Q">Qian Luo</a>, 
<a href="/search/cs?searchtype=author&query=Pani%2C+A">Anumpam Pani</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yanchao Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Embodied agents capable of complex physical skills can improve productivity,
elevate life quality, and reshape human-machine collaboration. We aim at
autonomous training of embodied agents for various tasks involving mainly large
foundation models. It is believed that these models could act as a brain for
embodied agents; however, existing methods heavily rely on humans for task
proposal and scene customization, limiting the learning autonomy, training
efficiency, and generalization of the learned policies. In contrast, we
introduce a brain-body synchronization ({\it BBSEA}) scheme to promote embodied
learning in unknown environments without human involvement. The proposed
combines the wisdom of foundation models (``brain'') with the physical
capabilities of embodied agents (``body''). Specifically, it leverages the
``brain'' to propose learnable physical tasks and success metrics, enabling the
``body'' to automatically acquire various skills by continuously interacting
with the scene. We carry out an exploration of the proposed autonomous learning
scheme in a table-top setting, and we demonstrate that the proposed
synchronization can generate diverse tasks and develop multi-task policies with
promising adaptability to new tasks and configurations. We will release our
data, code, and trained models to facilitate future studies in building
autonomously learning agents with large foundation models in more complex
scenarios. More visualizations are available at
\href{https://bbsea-embodied-ai.github.io}{https://bbsea-embodied-ai.github.io}
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08216" title="Abstract">arXiv:2402.08216</a> [<a href="/pdf/2402.08216" title="Download PDF">pdf</a>, <a href="/ps/2402.08216" title="Download PostScript">ps</a>, <a href="/format/2402.08216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Improved Approximation Algorithm for Metric Triangle Packing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jingyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Mingyu Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in TAMC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Given an edge-weighted metric complete graph with $n$ vertices, the maximum
weight metric triangle packing problem is to find a set of $n/3$
vertex-disjoint triangles with the total weight of all triangles in the packing
maximized. Several simple methods can lead to a 2/3-approximation ratio.
However, this barrier is not easy to break. Chen et al. proposed a randomized
approximation algorithm with an expected ratio of $(0.66768-\varepsilon)$ for
any constant $\varepsilon&gt;0$. In this paper, we improve the approximation ratio
to $(0.66835-\varepsilon)$. Furthermore, we can derandomize our algorithm.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08217" title="Abstract">arXiv:2402.08217</a> [<a href="/pdf/2402.08217" title="Download PDF">pdf</a>, <a href="/format/2402.08217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Springboard, Roadblock or &quot;Crutch&quot;?: How Transgender Users Leverage  Voice Changers for Gender Presentation in Social Virtual Reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Povinelli%2C+K">Kassie Povinelli</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuhang Zhao</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE VR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Social virtual reality (VR) serves as a vital platform for transgender
individuals to explore their identities through avatars and foster personal
connections within online communities. However, it presents a challenge: the
disconnect between avatar embodiment and voice representation, often leading to
misgendering and harassment. Prior research acknowledges this issue but
overlooks the potential solution of voice changers. We interviewed 13
transgender and gender-nonconforming users of social VR platforms, focusing on
their experiences with and without voice changers. We found that using a voice
changer not only reduces voice-related harassment, but also allows them to
experience gender euphoria through both hearing their modified voice and the
reactions of others to their modified voice, motivating them to pursue voice
training and medication to achieve desired voices. Furthermore, we identified
the technical barriers to current voice changer technology and potential
improvements to alleviate the problems that transgender and
gender-nonconforming users face.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08219" title="Abstract">arXiv:2402.08219</a> [<a href="/pdf/2402.08219" title="Download PDF">pdf</a>, <a href="/format/2402.08219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BBox-Adapter: Lightweight Adapting for Black-Box Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haotian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yuchen Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bo Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Adapting state-of-the-art Large Language Models (LLMs) like GPT-4 and Gemini
for specific tasks is challenging. Due to the opacity in their parameters,
embeddings, and even output probabilities, existing fine-tuning adaptation
methods are inapplicable. Consequently, adapting these black-box LLMs is only
possible through their API services, raising concerns about transparency,
privacy, and cost. To address these challenges, we introduce BBox-Adapter, a
novel lightweight adapter for black-box LLMs. BBox-Adapter distinguishes target
and source domain data by treating target data as positive and source data as
negative. It employs a ranking-based Noise Contrastive Estimation (NCE) loss to
promote the likelihood of target domain data while penalizing that of the
source domain. Furthermore, it features an online adaptation mechanism, which
incorporates real-time positive data sampling from ground-truth, human, or AI
feedback, coupled with negative data from previous adaptations. Extensive
experiments demonstrate BBox-Adapter's effectiveness and cost efficiency. It
improves model performance by up to 6.77% across diverse tasks and domains,
while reducing training and inference costs by 31.30x and 1.84x, respectively.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08221" title="Abstract">arXiv:2402.08221</a> [<a href="/pdf/2402.08221" title="Download PDF">pdf</a>, <a href="/format/2402.08221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MetaTra: Meta-Learning for Generalized Trajectory Prediction in Unseen  Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaohe Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Feilong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zide Fan</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+F">Fangli Mou</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yingyan Hou</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+L">Lijie Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Trajectory prediction has garnered widespread attention in different fields,
such as autonomous driving and robotic navigation. However, due to the
significant variations in trajectory patterns across different scenarios,
models trained in known environments often falter in unseen ones. To learn a
generalized model that can directly handle unseen domains without requiring any
model updating, we propose a novel meta-learning-based trajectory prediction
method called MetaTra. This approach incorporates a Dual Trajectory Transformer
(Dual-TT), which enables a thorough exploration of the individual intention and
the interactions within group motion patterns in diverse scenarios. Building on
this, we propose a meta-learning framework to simulate the generalization
process between source and target domains. Furthermore, to enhance the
stability of our prediction outcomes, we propose a Serial and Parallel Training
(SPT) strategy along with a feature augmentation method named MetaMix.
Experimental results on several real-world datasets confirm that MetaTra not
only surpasses other state-of-the-art methods but also exhibits plug-and-play
capabilities, particularly in the realm of domain generalization.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08224" title="Abstract">arXiv:2402.08224</a> [<a href="/pdf/2402.08224" title="Download PDF">pdf</a>, <a href="/ps/2402.08224" title="Download PostScript">ps</a>, <a href="/format/2402.08224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-Dimensional Direction-of-Arrival Estimation Using Stacked  Intelligent Metasurfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+J">Jiancheng An</a>, 
<a href="/search/cs?searchtype=author&query=Yuen%2C+C">Chau Yuen</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Y+L">Yong Liang Guan</a>, 
<a href="/search/cs?searchtype=author&query=Di+Renzo%2C+M">Marco Di Renzo</a>, 
<a href="/search/cs?searchtype=author&query=Debbah%2C+M">M&#xe9;rouane Debbah</a>, 
<a href="/search/cs?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>, 
<a href="/search/cs?searchtype=author&query=Hanzo%2C+L">Lajos Hanzo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 12 figures, and 2 tables. arXiv admin note: text overlap with <a href="/abs/2310.09861">arXiv:2310.09861</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Stacked intelligent metasurfaces (SIM) are capable of emulating
reconfigurable physical neural networks by relying on electromagnetic (EM)
waves as carriers. They can also perform various complex computational and
signal processing tasks. A SIM is fabricated by densely integrating multiple
metasurface layers, each consisting of a large number of small meta-atoms that
can control the EM waves passing through it. In this paper, we harness a SIM
for two-dimensional (2D) direction-of-arrival (DOA) estimation. In contrast to
the conventional designs, an advanced SIM in front of the receiver array
automatically carries out the 2D discrete Fourier transform (DFT) as the
incident waves propagate through it. As a result, the receiver array directly
observes the angular spectrum of the incoming signal. In this context, the DOA
estimates can be readily obtained by using probes to detect the energy
distribution on the receiver array. This avoids the need for power-thirsty
radio frequency (RF) chains. To enable SIM to perform the 2D DFT, we formulate
the optimization problem of minimizing the fitting error between the SIM's EM
response and the 2D DFT matrix. Furthermore, a gradient descent algorithm is
customized for iteratively updating the phase shift of each meta-atom in SIM.
To further improve the DOA estimation accuracy, we configure the phase shift
pattern in the zeroth layer of the SIM to generate a set of 2D DFT matrices
associated with orthogonal spatial frequency bins. Additionally, we
analytically evaluate the performance of the proposed SIM-based DOA estimator
by deriving a tight upper bound for the mean square error (MSE). Our numerical
simulations verify the capability of a well-trained SIM to perform DOA
estimation and corroborate our theoretical analysis. It is demonstrated that a
SIM having an optical computational speed achieves an MSE of $10^{-4}$ for DOA
estimation.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08225" title="Abstract">arXiv:2402.08225</a> [<a href="/pdf/2402.08225" title="Download PDF">pdf</a>, <a href="/format/2402.08225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Black-box Robustness with In-Context Rewriting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=O%27Brien%2C+K">Kyle O&#x27;Brien</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+N">Nathan Ng</a>, 
<a href="/search/cs?searchtype=author&query=Puri%2C+I">Isha Puri</a>, 
<a href="/search/cs?searchtype=author&query=Mendez%2C+J">Jorge Mendez</a>, 
<a href="/search/cs?searchtype=author&query=Palangi%2C+H">Hamid Palangi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ghassemi%2C+M">Marzyeh Ghassemi</a>, 
<a href="/search/cs?searchtype=author&query=Hartvigsen%2C+T">Thomas Hartvigsen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Machine learning models often excel on in-distribution (ID) data but struggle
with unseen out-of-distribution (OOD) inputs. Most techniques for improving OOD
robustness are not applicable to settings where the model is effectively a
black box, such as when the weights are frozen, retraining is costly, or the
model is leveraged via an API. Test-time augmentation (TTA) is a simple
post-hoc technique for improving robustness that sidesteps black-box
constraints by aggregating predictions across multiple augmentations of the
test input. TTA has seen limited use in NLP due to the challenge of generating
effective natural language augmentations. In this work, we propose LLM-TTA,
which uses LLM-generated augmentations as TTA's augmentation function. LLM-TTA
outperforms conventional augmentation functions across sentiment, toxicity, and
news classification tasks for BERT and T5 models, with BERT's OOD robustness
improving by an average of 4.30 percentage points without regressing average ID
performance. We explore selectively augmenting inputs based on prediction
entropy to reduce the rate of expensive LLM augmentations, allowing us to
maintain performance gains while reducing the average number of generated
augmentations by 57.76%. LLM-TTA is agnostic to the task model architecture,
does not require OOD labels, and is effective across low and high-resource
settings. We share our data, models, and code for reproducibility.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08227" title="Abstract">arXiv:2402.08227</a> [<a href="/pdf/2402.08227" title="Download PDF">pdf</a>, <a href="/format/2402.08227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Preserving Language Model Inference with Instance Obfuscation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yixiang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ravi%2C+S">Srivatsan Ravi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Muhao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Language Models as a Service (LMaaS) offers convenient access for developers
and researchers to perform inference using pre-trained language models.
Nonetheless, the input data and the inference results containing private
information are exposed as plaintext during the service call, leading to
privacy issues. Recent studies have started tackling the privacy issue by
transforming input data into privacy-preserving representation from the
user-end with the techniques such as noise addition and content perturbation,
while the exploration of inference result protection, namely decision privacy,
is still a blank page. In order to maintain the black-box manner of LMaaS,
conducting data privacy protection, especially for the decision, is a
challenging task because the process has to be seamless to the models and
accompanied by limited communication and computation overhead. We thus propose
Instance-Obfuscated Inference (IOI) method, which focuses on addressing the
decision privacy issue of natural language understanding tasks in their
complete life-cycle. Besides, we conduct comprehensive experiments to evaluate
the performance as well as the privacy-protection strength of the proposed
method on various benchmarking tasks.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08228" title="Abstract">arXiv:2402.08228</a> [<a href="/pdf/2402.08228" title="Download PDF">pdf</a>, <a href="/format/2402.08228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Out-of-Distribution Generalization of GNNs: An  Architecture Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+K">Kai Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Hongzhi Wen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+W">Wei Jin</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yaming Guo</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiliang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yi Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph neural networks (GNNs) have exhibited remarkable performance under the
assumption that test data comes from the same distribution of training data.
However, in real-world scenarios, this assumption may not always be valid.
Consequently, there is a growing focus on exploring the Out-of-Distribution
(OOD) problem in the context of graphs. Most existing efforts have primarily
concentrated on improving graph OOD generalization from two
\textbf{model-agnostic} perspectives: data-driven methods and strategy-based
learning. However, there has been limited attention dedicated to investigating
the impact of well-known \textbf{GNN model architectures} on graph OOD
generalization, which is orthogonal to existing research. In this work, we
provide the first comprehensive investigation of OOD generalization on graphs
from an architecture perspective, by examining the common building blocks of
modern GNNs. Through extensive experiments, we reveal that both the graph
self-attention mechanism and the decoupled architecture contribute positively
to graph OOD generalization. In contrast, we observe that the linear
classification layer tends to compromise graph OOD generalization capability.
Furthermore, we provide in-depth theoretical insights and discussions to
underpin these discoveries. These insights have empowered us to develop a novel
GNN backbone model, DGAT, designed to harness the robust properties of both
graph self-attention mechanism and the decoupled architecture. Extensive
experimental results demonstrate the effectiveness of our model under graph
OOD, exhibiting substantial and consistent enhancements across various training
strategies.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08229" title="Abstract">arXiv:2402.08229</a> [<a href="/pdf/2402.08229" title="Download PDF">pdf</a>, <a href="/format/2402.08229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Discovery under Off-Target Interventions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choo%2C+D">Davin Choo</a>, 
<a href="/search/cs?searchtype=author&query=Shiragur%2C+K">Kirankumar Shiragur</a>, 
<a href="/search/cs?searchtype=author&query=Uhler%2C+C">Caroline Uhler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted into AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">Causal graph discovery is a significant problem with applications across
various disciplines. However, with observational data alone, the underlying
causal graph can only be recovered up to its Markov equivalence class, and
further assumptions or interventions are necessary to narrow down the true
graph. This work addresses the causal discovery problem under the setting of
stochastic interventions with the natural goal of minimizing the number of
interventions performed. We propose the following stochastic intervention model
which subsumes existing adaptive noiseless interventions in the literature
while capturing scenarios such as fat-hand interventions and CRISPR gene
knockouts: any intervention attempt results in an actual intervention on a
random subset of vertices, drawn from a distribution dependent on attempted
action. Under this model, we study the two fundamental problems in causal
discovery of verification and search and provide approximation algorithms with
polylogarithmic competitive ratios and provide some preliminary experimental
results.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08230" title="Abstract">arXiv:2402.08230</a> [<a href="/pdf/2402.08230" title="Download PDF">pdf</a>, <a href="/format/2402.08230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Modulus RF Beamforming for Enhanced Self-Interference  Suppression in Full-Duplex Massive MIMO Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahmood%2C+M">Mobeen Mahmood</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuanxing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Morawski%2C+R">Robert Morawski</a>, 
<a href="/search/cs?searchtype=author&query=Le-Ngoc%2C+T">Tho Le-Ngoc</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication in IEEE WCNC 2024. arXiv admin note: text overlap with <a href="/abs/2309.03317">arXiv:2309.03317</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This study employs a uniform rectangular array (URA) sub-connected hybrid
beamforming (SC-HBF) architecture to provide a novel self-interference (SI)
suppression scheme in a full-duplex (FD) massive multiple-input multiple-output
(mMIMO) system. Our primary objective is to mitigate the strong SI through the
design of RF beamforming stages for uplink and downlink transmissions that
utilize the spatial degrees of freedom provided due to the use of large array
structures. We propose a non-constant modulus RF beamforming (NCM-BF-SIS)
scheme that incorporates the gain controllers for both transmit (Tx) and
receive (Rx) RF beamforming stages and optimizes the uplink and downlink beam
directions jointly with gain controller coefficients. To solve this challenging
non-convex optimization problem, we propose a swarm intelligence-based
algorithmic solution that finds the optimal beam perturbations while also
adjusting the Tx/Rx gain controllers to alleviate SI subject to the directivity
degradation constraints for the beams. The data-driven analysis based on the
measured SI channel in an anechoic chamber shows that the proposed NCM-BF-SIS
scheme can suppress SI by around 80 dB in FD mMIMO systems.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08231" title="Abstract">arXiv:2402.08231</a> [<a href="/pdf/2402.08231" title="Download PDF">pdf</a>, <a href="/ps/2402.08231" title="Download PostScript">ps</a>, <a href="/format/2402.08231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asynchronous Distributed Coordinated Hybrid Precoding in Multi-cell  mmWave Wireless Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jafri%2C+M">Meesam Jafri</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+S">Suraj Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sunil Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Jagannatham%2C+A+K">Aditya K. Jagannatham</a>, 
<a href="/search/cs?searchtype=author&query=Hanzo%2C+L">Lajos Hanzo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Open Journal of Vehicular Technology, vol. 5, pp. 200-218,
  2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Asynchronous distributed hybrid beamformers (ADBF) are conceived for
minimizing the total transmit power subject to
signal-to-interference-plus-noise ratio (SINR) constraints at the users. Our
design requires only limited information exchange between the base stations
(BSs) of the mmWave multi-cell coordinated (MCC) networks considered. To begin
with, a semidefinite relaxation (SDR)-based fully-digital (FD) beamformer is
designed for a centralized MCC system. Subsequently, a Bayesian learning (BL)
technique is harnessed for decomposing the FD beamformer into its analog and
baseband components and construct a hybrid transmit precoder (TPC). However,
the centralized TPC design requires global channel state information (CSI),
hence it results in a high signaling overhead. An alternating direction based
method of multipliers (ADMM) technique is developed for a synchronous
distributed beamformer (SDBF) design, which relies only on limited information
exchange among the BSs, thus reducing the signaling overheads required by the
centralized TPC design procedure.
<br />However, the SDBF design is challenging, since it requires the updates from
the BSs to be strictly synchronized. As a remedy, an ADBF framework is
developed that mitigates the inter-cell interference (ICI) and also control the
asynchrony in the system.
<br />Furthermore, the above ADBF framework is also extended to the robust ADBF
(R-ADBF) algorithm that incorporates the CSI uncertainty into the design
procedure for minimizing the the worst-case transmit power. Our simulation
results illustrate both the enhanced performance and the improved convergence
properties of the ADMM-based ADBF and R-ADBF schemes.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08232" title="Abstract">arXiv:2402.08232</a> [<a href="/pdf/2402.08232" title="Download PDF">pdf</a>, <a href="/ps/2402.08232" title="Download PostScript">ps</a>, <a href="/format/2402.08232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating High-Dimensional Functions Deterministically
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gamarnik%2C+D">David Gamarnik</a>, 
<a href="/search/cs?searchtype=author&query=Smedira%2C+D">Devin Smedira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO); Probability (math.PR)

</div>
<p class="mathjax">We design a Quasi-Polynomial time deterministic approximation algorithm for
computing the integral of a multi-dimensional separable function, supported by
some underlying hyper-graph structure, appropriately defined. Equivalently, our
integral is the partition function of a graphical model with continuous
potentials. While randomized algorithms for high-dimensional integration are
widely known, deterministic counterparts generally do not exist. We use the
correlation decay method applied to the Riemann sum of the function to produce
our algorithm. For our method to work, we require that the domain is bounded
and the hyper-edge potentials are positive and bounded on the domain. We
further assume that upper and lower bounds on the potentials separated by a
multiplicative factor of $1 + O(1/\Delta^2)$, where $\Delta$ is the maximum
degree of the graph. When $\Delta = 3$, our method works provided the upper and
lower bounds are separated by a factor of at most $1.0479$. To the best of our
knowledge, our algorithm is the first deterministic algorithm for
high-dimensional integration of a continuous function, apart from the case of
trivial product form distributions.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08236" title="Abstract">arXiv:2402.08236</a> [<a href="/pdf/2402.08236" title="Download PDF">pdf</a>, <a href="/format/2402.08236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BERT4FCA: A Method for Bipartite Link Prediction using Formal Concept  Analysis and BERT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Siqi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yamamoto%2C+A">Akihiro Yamamoto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">We propose BERT4FCA, a novel method for link prediction in bipartite
networks, using formal concept analysis (FCA) and BERT. Link prediction in
bipartite networks is an important task that can solve various practical
problems like friend recommendation in social networks and co-authorship
prediction in author-paper networks. Recent research has found that in
bipartite networks, maximal bi-cliques provide important information for link
prediction, and they can be extracted by FCA. Some FCA-based bipartite link
prediction methods have achieved good performance. However, we figured out that
their performance could be further improved because these methods did not fully
capture the rich information of the extracted maximal bi-cliques. To address
this limitation, we propose an approach using BERT, which can learn more
information from the maximal bi-cliques extracted by FCA and use them to make
link prediction. We conduct experiments on three real-world bipartite networks
and demonstrate that our method outperforms previous FCA-based methods, and
some classic methods such as matrix-factorization and node2vec.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08238" title="Abstract">arXiv:2402.08238</a> [<a href="/pdf/2402.08238" title="Download PDF">pdf</a>, <a href="/format/2402.08238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Opportunistic Scheduling Using Statistical Information of Wireless  Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Z">Zhouyou Gu</a>, 
<a href="/search/cs?searchtype=author&query=Hardjawana%2C+W">Wibowo Hardjawana</a>, 
<a href="/search/cs?searchtype=author&query=Vucetic%2C+B">Branka Vucetic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been accepted in the IEEE Transactions on Wireless Communications. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper considers opportunistic scheduler (OS) design using statistical
channel state information~(CSI). We apply max-weight schedulers (MWSs) to
maximize a utility function of users' average data rates. MWSs schedule the
user with the highest weighted instantaneous data rate every time slot.
Existing methods require hundreds of time slots to adjust the MWS's weights
according to the instantaneous CSI before finding the optimal weights that
maximize the utility function. In contrast, our MWS design requires few slots
for estimating the statistical CSI. Specifically, we formulate a weight
optimization problem using the mean and variance of users' signal-to-noise
ratios (SNRs) to construct constraints bounding users' feasible average rates.
Here, the utility function is the formulated objective, and the MWS's weights
are optimization variables. We develop an iterative solver for the problem and
prove that it finds the optimal weights. We also design an online architecture
where the solver adaptively generates optimal weights for networks with varying
mean and variance of the SNRs. Simulations show that our methods effectively
require $4\sim10$ times fewer slots to find the optimal weights and achieve
$5\sim15\%$ better average rates than the existing methods.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08241" title="Abstract">arXiv:2402.08241</a> [<a href="/pdf/2402.08241" title="Download PDF">pdf</a>, <a href="/format/2402.08241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Learning for Trustworthy Recommender Systems: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jin Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shoujin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Longbing Cao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiuzhen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jannach%2C+D">Dietmar Jannach</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+C+C">Charu C. Aggarwal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Recommender Systems (RS) have significantly advanced online content discovery
and personalized decision-making. However, emerging vulnerabilities in RS have
catalyzed a paradigm shift towards Trustworthy RS (TRS). Despite numerous
progress on TRS, most of them focus on data correlations while overlooking the
fundamental causal nature in recommendation. This drawback hinders TRS from
identifying the cause in addressing trustworthiness issues, leading to limited
fairness, robustness, and explainability. To bridge this gap, causal learning
emerges as a class of promising methods to augment TRS. These methods, grounded
in reliable causality, excel in mitigating various biases and noises while
offering insightful explanations for TRS. However, there lacks a timely survey
in this vibrant area. This paper creates an overview of TRS from the
perspective of causal learning. We begin by presenting the advantages and
common procedures of Causality-oriented TRS (CTRS). Then, we identify potential
trustworthiness challenges at each stage and link them to viable causal
solutions, followed by a classification of CTRS methods. Finally, we discuss
several future directions for advancing this field.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08242" title="Abstract">arXiv:2402.08242</a> [<a href="/pdf/2402.08242" title="Download PDF">pdf</a>, <a href="/format/2402.08242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Equitable Agile Research and Development of AI and Robotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hundt%2C+A">Andrew Hundt</a>, 
<a href="/search/cs?searchtype=author&query=Schuller%2C+J">Julia Schuller</a>, 
<a href="/search/cs?searchtype=author&query=Kacianka%2C+S">Severin Kacianka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages (32 with refs + appendix), 2 figures, 1 table (7 with appendix), incorporates changes based on WeRobot 2023 Draft feedback
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG); Robotics (cs.RO); Software Engineering (cs.SE)

</div>
<p class="mathjax">Machine Learning (ML) and 'Artificial Intelligence' ('AI') methods tend to
replicate and amplify existing biases and prejudices, as do Robots with AI. For
example, robots with facial recognition have failed to identify Black Women as
human, while others have categorized people, such as Black Men, as criminals
based on appearance alone. A 'culture of modularity' means harms are perceived
as 'out of scope', or someone else's responsibility, throughout employment
positions in the 'AI supply chain'. Incidents are routine enough
(incidentdatabase.ai lists over 2000 examples) to indicate that few
organizations are capable of completely respecting peoples' rights; meeting
claimed equity, diversity, and inclusion (EDI or DEI) goals; or recognizing and
then addressing such failures in their organizations and artifacts. We propose
a framework for adapting widely practiced Research and Development (R&amp;D)
project management methodologies to build organizational equity capabilities
and better integrate known evidence-based best practices. We describe how
project teams can organize and operationalize the most promising practices,
skill sets, organizational cultures, and methods to detect and address
rights-based fairness, equity, accountability, and ethical problems as early as
possible when they are often less harmful and easier to mitigate; then monitor
for unforeseen incidents to adaptively and constructively address them. Our
primary example adapts an Agile development process based on Scrum, one of the
most widely adopted approaches to organizing R&amp;D teams. We also discuss
limitations of our proposed framework and future research directions.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08244" title="Abstract">arXiv:2402.08244</a> [<a href="/pdf/2402.08244" title="Download PDF">pdf</a>, <a href="/ps/2402.08244" title="Download PostScript">ps</a>, <a href="/format/2402.08244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> APALU: A Trainable, Adaptive Activation Function for Deep Learning  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Subramanian%2C+B">Barathi Subramanian</a>, 
<a href="/search/cs?searchtype=author&query=Jeyaraj%2C+R">Rathinaraja Jeyaraj</a>, 
<a href="/search/cs?searchtype=author&query=Ugli%2C+R+A+A">Rakhmonov Akhrorjon Akhmadjon Ugli</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jeonghong Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, Submitted at IJCAI 2024 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Activation function is a pivotal component of deep learning, facilitating the
extraction of intricate data patterns. While classical activation functions
like ReLU and its variants are extensively utilized, their static nature and
simplicity, despite being advantageous, often limit their effectiveness in
specialized tasks. The trainable activation functions also struggle sometimes
to adapt to the unique characteristics of the data. Addressing these
limitations, we introduce a novel trainable activation function, adaptive
piecewise approximated activation linear unit (APALU), to enhance the learning
performance of deep learning across a broad range of tasks. It presents a
unique set of features that enable it to maintain stability and efficiency in
the learning process while adapting to complex data representations.
Experiments reveal significant improvements over widely used activation
functions for different tasks. In image classification, APALU increases
MobileNet and GoogleNet accuracy by 0.37% and 0.04%, respectively, on the
CIFAR10 dataset. In anomaly detection, it improves the average area under the
curve of One-CLASS Deep SVDD by 0.8% on the MNIST dataset, 1.81% and 1.11%
improvements with DifferNet, and knowledge distillation, respectively, on the
MVTech dataset. Notably, APALU achieves 100% accuracy on a sign language
recognition task with a limited dataset. For regression tasks, APALU enhances
the performance of deep neural networks and recurrent neural networks on
different datasets. These improvements highlight the robustness and
adaptability of APALU across diverse deep-learning applications.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08245" title="Abstract">arXiv:2402.08245</a> [<a href="/pdf/2402.08245" title="Download PDF">pdf</a>, <a href="/format/2402.08245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Reconfigurable V-shape Formation of Multiple UAVs in Narrow Space  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bui%2C+D+N">Duy Nam Bui</a>, 
<a href="/search/cs?searchtype=author&query=Phung%2C+M+D">Manh Duong Phung</a>, 
<a href="/search/cs?searchtype=author&query=Duy%2C+H+P">Hung Pham Duy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in: 2024 IEEE/SICE International Symposium on System Integration (SII)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents the design and implementation of a self-reconfigurable
V-shape formation controller for multiple unmanned aerial vehicles (UAVs)
navigating through narrow spaces in a dense obstacle environment. The selection
of the V-shape formation is motivated by its maneuverability and visibility
advantages. The main objective is to develop an effective formation control
strategy that allows UAVs to autonomously adjust their positions to form the
desired formation while navigating through obstacles. To achieve this, we
propose a distributed behavior-based control algorithm that combines the
behaviors designed for individual UAVs so that they together navigate the UAVs
to their desired positions. The reconfiguration process is automatic, utilizing
individual UAV sensing within the formation, allowing for dynamic adaptations
such as opening/closing wings or merging into a straight line. Simulation
results show that the self-reconfigurable V-shape formation offers adaptability
and effectiveness for UAV formations in complex operational scenarios.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08246" title="Abstract">arXiv:2402.08246</a> [<a href="/pdf/2402.08246" title="Download PDF">pdf</a>, <a href="/format/2402.08246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ant Colony Optimization for Cooperative Inspection Path Planning Using  Multiple Unmanned Aerial Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bui%2C+D+N">Duy Nam Bui</a>, 
<a href="/search/eess?searchtype=author&query=Duong%2C+T+N">Thuy Ngan Duong</a>, 
<a href="/search/eess?searchtype=author&query=Phung%2C+M+D">Manh Duong Phung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in: 2024 IEEE/SICE International Symposium on System Integration (SII)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents a new swarm intelligence-based approach to deal with the
cooperative path planning problem of unmanned aerial vehicles (UAVs), which is
essential for the automatic inspection of infrastructure. The approach uses a
3D model of the structure to generate viewpoints for the UAVs. The calculation
of the viewpoints considers the constraints related to the UAV formation model,
camera parameters, and requirements for data post-processing. The viewpoints
are then used as input to formulate the path planning as an extended traveling
salesman problem and the definition of a new cost function. Ant colony
optimization is finally used to solve the problem to yield optimal inspection
paths. Experiments with 3D models of real structures have been conducted to
evaluate the performance of the proposed approach. The results show that our
system is not only capable of generating feasible inspection paths for UAVs but
also reducing the path length by 29.47\% for complex structures when compared
with another heuristic approach. The source code of the algorithm can be found
at https://github.com/duynamrcv/aco_3d_ipp.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08249" title="Abstract">arXiv:2402.08249</a> [<a href="/pdf/2402.08249" title="Download PDF">pdf</a>, <a href="/format/2402.08249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SepRep-Net: Multi-source Free Domain Adaptation via Model Separation And  Reparameterization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Ying Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We consider multi-source free domain adaptation, the problem of adapting
multiple existing models to a new domain without accessing the source data.
Among existing approaches, methods based on model ensemble are effective in
both the source and target domains, but incur significantly increased
computational costs. Towards this dilemma, in this work, we propose a novel
framework called SepRep-Net, which tackles multi-source free domain adaptation
via model Separation and Reparameterization.Concretely, SepRep-Net reassembled
multiple existing models to a unified network, while maintaining separate
pathways (Separation). During training, separate pathways are optimized in
parallel with the information exchange regularly performed via an additional
feature merging unit. With our specific design, these pathways can be further
reparameterized into a single one to facilitate inference (Reparameterization).
SepRep-Net is characterized by 1) effectiveness: competitive performance on the
target domain, 2) efficiency: low computational costs, and 3) generalizability:
maintaining more source knowledge than existing solutions. As a general
approach, SepRep-Net can be seamlessly plugged into various methods. Extensive
experiments validate the performance of SepRep-Net on mainstream benchmarks.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08250" title="Abstract">arXiv:2402.08250</a> [<a href="/pdf/2402.08250" title="Download PDF">pdf</a>, <a href="/ps/2402.08250" title="Download PostScript">ps</a>, <a href="/format/2402.08250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A survey of recent methods for addressing AI fairness and bias in  biomedicine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yifan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Mingquan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Han Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yifan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Furong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhiyong Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Artificial intelligence (AI) systems have the potential to revolutionize
clinical practices, including improving diagnostic accuracy and surgical
decision-making, while also reducing costs and manpower. However, it is
important to recognize that these systems may perpetuate social inequities or
demonstrate biases, such as those based on race or gender. Such biases can
occur before, during, or after the development of AI models, making it critical
to understand and address potential biases to enable the accurate and reliable
application of AI models in clinical settings. To mitigate bias concerns during
model development, we surveyed recent publications on different debiasing
methods in the fields of biomedical natural language processing (NLP) or
computer vision (CV). Then we discussed the methods that have been applied in
the biomedical domain to address bias. We performed our literature search on
PubMed, ACM digital library, and IEEE Xplore of relevant articles published
between January 2018 and December 2023 using multiple combinations of keywords.
We then filtered the result of 10,041 articles automatically with loose
constraints, and manually inspected the abstracts of the remaining 890 articles
to identify the 55 articles included in this review. Additional articles in the
references are also included in this review. We discuss each method and compare
its strengths and weaknesses. Finally, we review other potential methods from
the general domain that could be applied to biomedicine to address bias and
improve fairness.The bias of AIs in biomedicine can originate from multiple
sources. Existing debiasing methods that focus on algorithms can be categorized
into distributional or algorithmic.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08251" title="Abstract">arXiv:2402.08251</a> [<a href="/pdf/2402.08251" title="Download PDF">pdf</a>, <a href="/format/2402.08251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object Detection in Thermal Images Using Deep Learning for Unmanned  Aerial Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tu%2C+M+D">Minh Dang Tu</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+K+T">Kieu Trang Le</a>, 
<a href="/search/cs?searchtype=author&query=Phung%2C+M+D">Manh Duong Phung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in: 2024 IEEE/SICE International Symposium on System Integration (SII)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This work presents a neural network model capable of recognizing small and
tiny objects in thermal images collected by unmanned aerial vehicles. Our model
consists of three parts, the backbone, the neck, and the prediction head. The
backbone is developed based on the structure of YOLOv5 combined with the use of
a transformer encoder at the end. The neck includes a BI-FPN block combined
with the use of a sliding window and a transformer to increase the information
fed into the prediction head. The prediction head carries out the detection by
evaluating feature maps with the Sigmoid function. The use of transformers with
attention and sliding windows increases recognition accuracy while keeping the
model at a reasonable number of parameters and computation requirements for
embedded systems. Experiments conducted on public dataset VEDAI and our
collected datasets show that our model has a higher accuracy than
state-of-the-art methods such as ResNet, Faster RCNN, ComNet, ViT, YOLOv5,
SMPNet, and DPNetV3. Experiments on the embedded computer Jetson AGX show that
our model achieves a real-time computation speed with a stability rate of over
90%.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08255" title="Abstract">arXiv:2402.08255</a> [<a href="/pdf/2402.08255" title="Download PDF">pdf</a>, <a href="/format/2402.08255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distal Interference: Exploring the Limits of Model-Based Continual  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Deventer%2C+H">Heinrich van Deventer</a>, 
<a href="/search/cs?searchtype=author&query=Bosman%2C+A+S">Anna Sergeevna Bosman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Continual learning is the sequential learning of different tasks by a machine
learning model. Continual learning is known to be hindered by catastrophic
interference or forgetting, i.e. rapid unlearning of earlier learned tasks when
new tasks are learned. Despite their practical success, artificial neural
networks (ANNs) are prone to catastrophic interference. This study analyses how
gradient descent and overlapping representations between distant input points
lead to distal interference and catastrophic interference. Distal interference
refers to the phenomenon where training a model on a subset of the domain leads
to non-local changes on other subsets of the domain. This study shows that
uniformly trainable models without distal interference must be exponentially
large. A novel antisymmetric bounded exponential layer B-spline ANN
architecture named ABEL-Spline is proposed that can approximate any continuous
function, is uniformly trainable, has polynomial computational complexity, and
provides some guarantees for distal interference. Experiments are presented to
demonstrate the theoretical properties of ABEL-Splines. ABEL-Splines are also
evaluated on benchmark regression problems. It is concluded that the weaker
distal interference guarantees in ABEL-Splines are insufficient for model-only
continual learning. It is conjectured that continual learning with polynomial
complexity models requires augmentation of the training data or algorithm.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08256" title="Abstract">arXiv:2402.08256</a> [<a href="/pdf/2402.08256" title="Download PDF">pdf</a>, <a href="/format/2402.08256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Balanced Explicit and Implicit Relations with Contrastive  Learning for Knowledge Concept Recommendation in MOOCs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hengnian Gu</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Z">Zhiyi Duan</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+P">Pan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Dongdai Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WWW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The knowledge concept recommendation in Massive Open Online Courses (MOOCs)
is a significant issue that has garnered widespread attention. Existing methods
primarily rely on the explicit relations between users and knowledge concepts
on the MOOC platforms for recommendation. However, there are numerous implicit
relations (e.g., shared interests or same knowledge levels between users)
generated within the users' learning activities on the MOOC platforms. Existing
methods fail to consider these implicit relations, and these relations
themselves are difficult to learn and represent, causing poor performance in
knowledge concept recommendation and an inability to meet users' personalized
needs. To address this issue, we propose a novel framework based on contrastive
learning, which can represent and balance the explicit and implicit relations
for knowledge concept recommendation in MOOCs (CL-KCRec). Specifically, we
first construct a MOOCs heterogeneous information network (HIN) by modeling the
data from the MOOC platforms. Then, we utilize a relation-updated graph
convolutional network and stacked multi-channel graph neural network to
represent the explicit and implicit relations in the HIN, respectively.
Considering that the quantity of explicit relations is relatively fewer
compared to implicit relations in MOOCs, we propose a contrastive learning with
prototypical graph to enhance the representations of both relations to capture
their fruitful inherent relational knowledge, which can guide the propagation
of students' preferences within the HIN. Based on these enhanced
representations, to ensure the balanced contribution of both towards the final
recommendation, we propose a dual-head attention mechanism for balanced fusion.
Experimental results demonstrate that CL-KCRec outperforms several
state-of-the-art baselines on real-world datasets in terms of HR, NDCG and MRR.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08259" title="Abstract">arXiv:2402.08259</a> [<a href="/pdf/2402.08259" title="Download PDF">pdf</a>, <a href="/format/2402.08259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Table Reasoning with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuanliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dingzirui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+L">Longxu Dou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qingfu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+W">Wanxiang Che</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Table reasoning, which aims to generate the corresponding answer to the
question following the user requirement according to the provided table, and
optionally a text description of the table, effectively improving the
efficiency of obtaining information. Recently, using Large Language Models
(LLMs) has become the mainstream method for table reasoning, because it not
only significantly reduces the annotation cost but also exceeds the performance
of previous methods. However, existing research still lacks a summary of
LLM-based table reasoning works. Due to the existing lack of research,
questions about which techniques can improve table reasoning performance in the
era of LLMs, why LLMs excel at table reasoning, and how to enhance table
reasoning abilities in the future, remain largely unexplored. This gap
significantly limits progress in research. To answer the above questions and
advance table reasoning research with LLMs, we present this survey to analyze
existing research, inspiring future work. In this paper, we analyze the
mainstream techniques used to improve table reasoning performance in the LLM
era, and the advantages of LLMs compared to pre-LLMs for solving table
reasoning. We provide research directions from both the improvement of existing
methods and the expansion of practical applications to inspire future research.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08264" title="Abstract">arXiv:2402.08264</a> [<a href="/pdf/2402.08264" title="Download PDF">pdf</a>, <a href="/format/2402.08264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iiro Honkala&#x27;s contributions to identifying codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hudry%2C+O">Olivier Hudry</a>, 
<a href="/search/cs?searchtype=author&query=Junnila%2C+V">Ville Junnila</a>, 
<a href="/search/cs?searchtype=author&query=Lobstein%2C+A">Antoine Lobstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">A set $C$ of vertices in a graph $G=(V,E)$ is an identifying code if it is
dominating and any two vertices of $V$ are dominated by distinct sets of
codewords. This paper presents a survey of Iiro Honkala's contributions to the
study of identifying codes with respect to several aspects: complexity of
computing an identifying code, combinatorics in binary Hamming spaces, infinite
grids, relationships between identifying codes and usual parameters in graphs,
structural properties of graphs admitting identifying codes, and number of
optimal identifying codes.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08265" title="Abstract">arXiv:2402.08265</a> [<a href="/pdf/2402.08265" title="Download PDF">pdf</a>, <a href="/format/2402.08265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Dense Reward View on Aligning Text-to-Image Diffusion with Preference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shentao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mingyuan Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Aligning text-to-image diffusion model (T2I) with preference has been gaining
increasing research attention. While prior works exist on directly optimizing
T2I by preference data, these methods are developed under the bandit assumption
of a latent reward on the entire diffusion reverse chain, while ignoring the
sequential nature of the generation process. From literature, this may harm the
efficacy and efficiency of alignment. In this paper, we take on a finer dense
reward perspective and derive a tractable alignment objective that emphasizes
the initial steps of the T2I reverse chain. In particular, we introduce
temporal discounting into the DPO-style explicit-reward-free loss, to break the
temporal symmetry therein and suit the T2I generation hierarchy. In experiments
on single and multiple prompt generation, our method is competitive with strong
relevant baselines, both quantitatively and qualitatively. Further studies are
conducted to illustrate the insight of our approach.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08267" title="Abstract">arXiv:2402.08267</a> [<a href="/pdf/2402.08267" title="Download PDF">pdf</a>, <a href="/ps/2402.08267" title="Download PostScript">ps</a>, <a href="/format/2402.08267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Image Coding for Machines through Optimizing Encoder via  Auxiliary Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Iino%2C+K">Kei Iino</a>, 
<a href="/search/cs?searchtype=author&query=Akamatsu%2C+S">Shunsuke Akamatsu</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+H">Hiroshi Watanabe</a>, 
<a href="/search/cs?searchtype=author&query=Enomoto%2C+S">Shohei Enomoto</a>, 
<a href="/search/cs?searchtype=author&query=Sakamoto%2C+A">Akira Sakamoto</a>, 
<a href="/search/cs?searchtype=author&query=Eda%2C+T">Takeharu Eda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> copyright 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Image coding for machines (ICM) aims to compress images for machine analysis
using recognition models rather than human vision. Hence, in ICM, it is
important for the encoder to recognize and compress the information necessary
for the machine recognition task. There are two main approaches in learned ICM;
optimization of the compression model based on task loss, and Region of
Interest (ROI) based bit allocation. These approaches provide the encoder with
the recognition capability. However, optimization with task loss becomes
difficult when the recognition model is deep, and ROI-based methods often
involve extra overhead during evaluation. In this study, we propose a novel
training method for learned ICM models that applies auxiliary loss to the
encoder to improve its recognition capability and rate-distortion performance.
Our method achieves Bjontegaard Delta rate improvements of 27.7% and 20.3% in
object detection and semantic segmentation tasks, compared to the conventional
training method.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08268" title="Abstract">arXiv:2402.08268</a> [<a href="/pdf/2402.08268" title="Download PDF">pdf</a>, <a href="/format/2402.08268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> World Model on Million-Length Video And Language With RingAttention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+W">Wilson Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zaharia%2C+M">Matei Zaharia</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Current language models fall short in understanding aspects of the world not
easily described in words, and struggle with complex, long-form tasks. Video
sequences offer valuable temporal information absent in language and static
images, making them attractive for joint modeling with language. Such models
could develop a understanding of both human textual knowledge and the physical
world, enabling broader AI capabilities for assisting humans. However, learning
from millions of tokens of video and language sequences poses challenges due to
memory constraints, computational complexity, and limited datasets. To address
these challenges, we curate a large dataset of diverse videos and books,
utilize the RingAttention technique to scalably train on long sequences, and
gradually increase context size from 4K to 1M tokens. This paper makes the
following contributions: (a) Largest context size neural network: We train one
of the largest context size transformers on long video and language sequences,
setting new benchmarks in difficult retrieval tasks and long video
understanding. (b) Solutions for overcoming vision-language training
challenges, including using masked sequence packing for mixing different
sequence lengths, loss weighting to balance language and vision, and
model-generated QA dataset for long sequence chat. (c) A highly-optimized
implementation with RingAttention, masked sequence packing, and other key
features for training on millions-length multimodal sequences. (d) Fully
open-sourced a family of 7B parameter models capable of processing long text
documents (LWM-Text, LWM-Text-Chat) and videos (LWM, LWM-Chat) of over 1M
tokens. This work paves the way for training on massive datasets of long video
and language to develop understanding of both human knowledge and the
multimodal world, and broader capabilities.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08269" title="Abstract">arXiv:2402.08269</a> [<a href="/pdf/2402.08269" title="Download PDF">pdf</a>, <a href="/format/2402.08269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometry-induced Implicit Regularization in Deep ReLU Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bona-Pellissier%2C+J">Joachim Bona-Pellissier</a> (IMT), 
<a href="/search/cs?searchtype=author&query=Malgouyres%2C+F+%C3%A7">Fran &#xe7;ois Malgouyres</a> (IMT), 
<a href="/search/cs?searchtype=author&query=Bachoc%2C+F+%C3%A7">Fran &#xe7;ois Bachoc</a> (IMT)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Optimization and Control (math.OC); Statistics Theory (math.ST)

</div>
<p class="mathjax">It is well known that neural networks with many more parameters than training
examples do not overfit. Implicit regularization phenomena, which are still not
well understood, occur during optimization and 'good' networks are favored.
Thus the number of parameters is not an adequate measure of complexity if we do
not consider all possible networks but only the 'good' ones. To better
understand which networks are favored during optimization, we study the
geometry of the output set as parameters vary. When the inputs are fixed, we
prove that the dimension of this set changes and that the local dimension,
called batch functional dimension, is almost surely determined by the
activation patterns in the hidden layers. We prove that the batch functional
dimension is invariant to the symmetries of the network parameterization:
neuron permutations and positive rescalings. Empirically, we establish that the
batch functional dimension decreases during optimization. As a consequence,
optimization leads to parameters with low batch functional dimensions. We call
this phenomenon geometry-induced implicit regularization.The batch functional
dimension depends on both the network parameters and inputs. To understand the
impact of the inputs, we study, for fixed parameters, the largest attainable
batch functional dimension when the inputs vary. We prove that this quantity,
called computable full functional dimension, is also invariant to the
symmetries of the network's parameterization, and is determined by the
achievable activation patterns. We also provide a sampling theorem, showing a
fast convergence of the estimation of the computable full functional dimension
for a random input of increasing size. Empirically we find that the computable
full functional dimension remains close to the number of parameters, which is
related to the notion of local identifiability. This differs from the observed
values for the batch functional dimension computed on training inputs and test
inputs. The latter are influenced by geometry-induced implicit regularization.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08270" title="Abstract">arXiv:2402.08270</a> [<a href="/pdf/2402.08270" title="Download PDF">pdf</a>, <a href="/format/2402.08270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What the Fix? A Study of ASATs Rule Documentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Latappy%2C+C">Corentin Latappy</a>, 
<a href="/search/cs?searchtype=author&query=Degueule%2C+T">Thomas Degueule</a>, 
<a href="/search/cs?searchtype=author&query=Falleri%2C+J">Jean-R&#xe9;my Falleri</a> (LaBRI), 
<a href="/search/cs?searchtype=author&query=Robbes%2C+R">Romain Robbes</a> (CNRS, LaBRI, UB, Bordeaux INP), 
<a href="/search/cs?searchtype=author&query=Blanc%2C+X">Xavier Blanc</a>, 
<a href="/search/cs?searchtype=author&query=Teyton%2C+C">C&#xe9;dric Teyton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32nd IEEE/ACM International Conference on Program Comprehension (ICPC 2024), Apr 2024, Lisboa, Portugal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Automatic Static Analysis Tools (ASATs) are widely used by software
developers to diffuse and enforce coding practices. Yet, we know little about
the documentation of ASATs, despite it being critical to learn about the coding
practices in the first place. We shed light on this through several
contributions. First, we analyze the documentation of more than 100 rules of 16
ASATs for multiple programming languages, and distill a taxonomy of the
purposes of the documentation-What triggers a rule; Why it is important; and
how to Fix an issue-and its types of contents. Then, we conduct a survey to
assess the effectiveness of the documentation in terms of its goals and types
of content. We highlight opportunities for improvement in ASAT documentation.
In particular, we find that the Why purpose is missing in half of the rules we
survey; moreover, when the Why is present, it is more likely to have quality
issues than the What and the Fix.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08273" title="Abstract">arXiv:2402.08273</a> [<a href="/pdf/2402.08273" title="Download PDF">pdf</a>, <a href="/format/2402.08273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regional Adaptive Metropolis Light Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Otsu%2C+H">Hisanari Otsu</a>, 
<a href="/search/cs?searchtype=author&query=Herveau%2C+K">Killian Herveau</a>, 
<a href="/search/cs?searchtype=author&query=Hanika%2C+J">Johannes Hanika</a>, 
<a href="/search/cs?searchtype=author&query=Nowrouzezahrai%2C+D">Derek Nowrouzezahrai</a>, 
<a href="/search/cs?searchtype=author&query=Dachsbacher%2C+C">Carsten Dachsbacher</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">The design of the proposal distributions, and most notably the kernel
parameters, are crucial for the performance of Markov chain Monte Carlo (MCMC)
rendering. A poor selection of parameters can increase the correlation of the
Markov chain and result in bad rendering performance. We approach this problem
by a novel path perturbation strategy for online-learning of state-dependent
kernel parameters. We base our approach on the theoretical framework of
regional adaptive MCMC which enables the adaptation of parameters depending on
the region of the state space which contains the current sample, and on
information collected from previous samples. For this, we define a partitioning
of the path space on a low-dimensional canonical space to capture the
characteristics of paths, with a focus on path segments closer to the sensor.
Fast convergence is achieved by adaptive refinement of the partitions.
Exemplarily, we present two novel regional adaptive path perturbation
techniques akin to lens and multi-chain perturbations. Our approach can easily
be used on top of existing path space MLT methods to improve rendering
efficiency, while being agnostic to the initial choice of kernel parameters.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08274" title="Abstract">arXiv:2402.08274</a> [<a href="/pdf/2402.08274" title="Download PDF">pdf</a>, <a href="/ps/2402.08274" title="Download PostScript">ps</a>, <a href="/format/2402.08274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nearly Orthogonal Sets over Finite Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chawin%2C+D">Dror Chawin</a>, 
<a href="/search/cs?searchtype=author&query=Haviv%2C+I">Ishay Haviv</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Discrete Mathematics (cs.DM); Information Theory (cs.IT); Combinatorics (math.CO)

</div>
<p class="mathjax">For a field $\mathbb{F}$ and integers $d$ and $k$, a set of vectors of
$\mathbb{F}^d$ is called $k$-nearly orthogonal if its members are
non-self-orthogonal and every $k+1$ of them include an orthogonal pair. We
prove that for every prime $p$ there exists a positive constant $\delta =
\delta (p)$, such that for every field $\mathbb{F}$ of characteristic $p$ and
for all integers $k \geq 2$ and $d \geq k^{1/(p-1)}$, there exists a $k$-nearly
orthogonal set of at least $d^{\delta \cdot k^{1/(p-1)}/ \log k}$ vectors of
$\mathbb{F}^d$. In particular, for the binary field we obtain a set of
$d^{\Omega( k /\log k)}$ vectors, and this is tight up to the $\log k$ term in
the exponent. For comparison, the best known lower bound over the reals is
$d^{\Omega( \log k / \log \log k)}$ (Alon and Szegedy, Graphs and Combin.,
1999). The proof combines probabilistic and spectral arguments.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08275" title="Abstract">arXiv:2402.08275</a> [<a href="/pdf/2402.08275" title="Download PDF">pdf</a>, <a href="/ps/2402.08275" title="Download PostScript">ps</a>, <a href="/format/2402.08275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implementation of Recommendation Algorithm based on Recommendation  Sessions in E-commerce IT System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malinowski%2C+M">Micha&#x142; Malinowski</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Management and Business Research Quarterly, 19, 2021, 14-32
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">This paper presents a study on the implementation of the author's Algorithm
of Recommendation Sessions (ARS) in an operational e-commerce information
system and analyses the basic parameters of the resulting recommendation
system. It begins with a synthetic overview of recommendation systems, followed
by a presentation of the proprietary ARS algorithm, which is based on
recommendation sessions. A mathematical model of the recommendation session,
constructed using graph and network theory, serves as the input for the ARS
algorithm. This paper also explores graph structure representation methods and
the implementation of a G graph (representing a set of recommendation sessions)
in a relational database using the SQL standard. The ARS algorithm was
implemented in a working e-commerce information system, leading to the
development of a fully functional recommendation system adaptable to various
e-commerce IT systems. The effectiveness of the algorithm is demonstrated by
research on the recommendation system's parameters presented in the final
section of the paper.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08277" title="Abstract">arXiv:2402.08277</a> [<a href="/pdf/2402.08277" title="Download PDF">pdf</a>, <a href="/format/2402.08277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Faithful and Robust LLM Specialists for Evidence-Based  Question-Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schimanski%2C+T">Tobias Schimanski</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+J">Jingwei Ni</a>, 
<a href="/search/cs?searchtype=author&query=Kraus%2C+M">Mathias Kraus</a>, 
<a href="/search/cs?searchtype=author&query=Ash%2C+E">Elliott Ash</a>, 
<a href="/search/cs?searchtype=author&query=Leippold%2C+M">Markus Leippold</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Advances towards more faithful and traceable answers of Large Language Models
(LLMs) are crucial for various research and practical endeavors. One avenue in
reaching this goal is basing the answers on reliable sources. However, this
Evidence-Based QA has proven to work insufficiently with LLMs in terms of
citing the correct sources (source quality) and truthfully representing the
information within sources (answer attributability). In this work, we
systematically investigate how to robustly fine-tune LLMs for better source
quality and answer attributability. Specifically, we introduce a data
generation pipeline with automated data quality filters, which can synthesize
diversified high-quality training and testing data at scale. We further
introduce four test sets to benchmark the robustness of fine-tuned specialist
models. Extensive evaluation shows that fine-tuning on synthetic data improves
performance on both in- and out-of-distribution. %Evidence-Based QA cases.
Furthermore, we show that data quality, which can be drastically improved by
proposed quality filters, matters more than quantity in improving
Evidence-Based QA.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08280" title="Abstract">arXiv:2402.08280</a> [<a href="/pdf/2402.08280" title="Download PDF">pdf</a>, <a href="/format/2402.08280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pix2Code: Learning to Compose Neural Visual Concepts as Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=W%C3%BCst%2C+A">Antonia W&#xfc;st</a>, 
<a href="/search/cs?searchtype=author&query=Stammer%2C+W">Wolfgang Stammer</a>, 
<a href="/search/cs?searchtype=author&query=Delfosse%2C+Q">Quentin Delfosse</a>, 
<a href="/search/cs?searchtype=author&query=Dhami%2C+D+S">Devendra Singh Dhami</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The challenge in learning abstract concepts from images in an unsupervised
fashion lies in the required integration of visual perception and generalizable
relational reasoning. Moreover, the unsupervised nature of this task makes it
necessary for human users to be able to understand a model's learnt concepts
and potentially revise false behaviours. To tackle both the generalizability
and interpretability constraints of visual concept learning, we propose
Pix2Code, a framework that extends program synthesis to visual relational
reasoning by utilizing the abilities of both explicit, compositional symbolic
and implicit neural representations. This is achieved by retrieving object
representations from images and synthesizing relational concepts as
lambda-calculus programs. We evaluate the diverse properties of Pix2Code on the
challenging reasoning domains, Kandinsky Patterns and CURI, thereby testing its
ability to identify compositional visual concepts that generalize to novel data
and concept configurations. Particularly, in stark contrast to neural
approaches, we show that Pix2Code's representations remain human interpretable
and can be easily revised for improved performance.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08282" title="Abstract">arXiv:2402.08282</a> [<a href="/pdf/2402.08282" title="Download PDF">pdf</a>, <a href="/format/2402.08282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Logic of Awareness for Nested Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kubono%2C+Y">Yudai Kubono</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, This is an author's original manuscript
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Reasoning abilities of human beings are limited. Logics that treat logical
inference for human knowledge should reflect these limited abilities. Logic of
awareness is one of those logics. In the logic, what an agent with a limited
reasoning ability actually knows at a given moment (explicit knowledge) is
distinguished from the ideal knowledge that an agent obtains by performing all
possible inferences with what she already knows (implicit knowledge). This
paper proposes a logic for explicit knowledge. In particular, we focus more on
nested explicit knowledge, which means another agent's knowledge that an agent
actually knows at a given moment. We develope a new formalization of two ideas
and propose Kripke-style semantics. The first idea is the effect on an agent's
reasoning ability by a state of an agent's awareness. We incorporate a relation
on possible worlds called an indistinguishable relation to represent ignorance
due to lack of awareness. The second idea is a state of each agent's awareness
in the other agent's mind. We incorporate a non-empty finite sequence of agents
called \textit{a chain of belief for awareness}. Our logic is called Awareness
Logic with Partitions and Chains (ALPC). Employing an example, we show how
nested explicit knowledge is formalized with our logic. Thereafter, we propose
the proof system and prove the completeness. Finally, we discuss directions for
extending and applying our logic and conclude. Our logic offers a foundation
for a formal representation of human knowledge. We expect that the logic can be
applied to computer science and game theory by describing and analyzing
strategic behavior in a game and practical agent communication.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08284" title="Abstract">arXiv:2402.08284</a> [<a href="/pdf/2402.08284" title="Download PDF">pdf</a>, <a href="/ps/2402.08284" title="Download PostScript">ps</a>, <a href="/format/2402.08284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Logical Approach to Criminal Case Investigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ugai%2C+T">Takanori Ugai</a>, 
<a href="/search/cs?searchtype=author&query=Koyanagi%2C+Y">Yusuke Koyanagi</a>, 
<a href="/search/cs?searchtype=author&query=Nishino%2C+F">Fumihito Nishino</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">XAI (eXplanable AI) techniques that have the property of explaining the
reasons for their conclusions, i.e. explainability or interpretability, are
attracting attention. XAI is expected to be used in the development of forensic
science and the justice system. In today's forensic and criminal investigation
environment, experts face many challenges due to large amounts of data, small
pieces of evidence in a chaotic and complex environment, traditional laboratory
structures and sometimes inadequate knowledge. All these can lead to failed
investigations and miscarriages of justice. In this paper, we describe the
application of one logical approach to crime scene investigation. The subject
of the application is ``The Adventure of the Speckled Band'' from the Sherlock
Holmes short stories. The applied data is the knowledge graph created for the
Knowledge Graph Reasoning Challenge. We tried to find the murderer by inferring
each person with the motive, opportunity, and method. We created an ontology of
motives and methods of murder from dictionaries and dictionaries, added it to
the knowledge graph of ``The Adventure of the Speckled Band'', and applied
scripts to determine motives, opportunities, and methods.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08286" title="Abstract">arXiv:2402.08286</a> [<a href="/pdf/2402.08286" title="Download PDF">pdf</a>, <a href="/format/2402.08286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MetaVRadar: Measuring Metaverse Virtual Reality Network Activity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+M">Minzhao Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Tripathi%2C+R+D">Rahul Dev Tripathi</a>, 
<a href="/search/cs?searchtype=author&query=Sivaraman%2C+V">Vijay Sivaraman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted at ACM SIGMETRICS/IFIP PERFORMANCE 2024 and is published by the Proceedings of the ACM on Measurement and Analysis of Computing Systems (POMACS)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc. ACM Meas. Anal. Comput. Syst. 7, 3, Article 55 (December
  2023), 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The "metaverse", wherein users can enter virtual worlds to work, study, play,
shop, socialize, and entertain, is fast becoming a reality, attracting billions
of dollars in investment from companies such as Meta, Microsoft, and Clipo
Labs. Further, virtual reality (VR) headsets from entities like Oculus, HTC,
and Microsoft are rapidly maturing to provide fully immersive experiences to
metaverse users. However, little is known about the network dynamics of
metaverse VR applications in terms of service domains, flow counts, traffic
rates and volumes, content location and latency, etc., which are needed to make
telecommunications network infrastructure "metaverse ready". This paper is an
empirical measurement study of metaverse VR network behavior aimed at helping
telecommunications network operators better provision and manage the network to
ensure good user experience. Using illustrative hour-long network traces of
metaverse sessions on the Oculus VR headset, we first develop a categorization
of user activity into distinct states ranging from login home to streetwalking
and event attendance to asset trading, and undertake a detailed analysis of
network traffic per state, identifying unique service domains, protocols, flow
profiles, and volumetric patterns, thereby highlighting the vastly more complex
nature of a metaverse session compared to streaming video or gaming. Armed with
the network behavioral profiles, our second contribution develops a real-time
method MetaVRadar to detect metaverse session and classify the user activity
state leveraging formalized flow signatures and volumetric attributes. Our
third contribution practically implements MetaVRadar, evaluates its accuracy in
our lab environment, and demonstrates its usability in a large university
network so operators can better monitor and plan resources to support requisite
metaverse user experience.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08289" title="Abstract">arXiv:2402.08289</a> [<a href="/pdf/2402.08289" title="Download PDF">pdf</a>, <a href="/ps/2402.08289" title="Download PostScript">ps</a>, <a href="/format/2402.08289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why Studying Cut-ins? Comparing Cut-ins and Other Lane Changes Based on  Naturalistic Driving Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lu%2C+Y">Yun Lu</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+D">Dejiang Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Su%2C+R">Rong Su</a>, 
<a href="/search/eess?searchtype=author&query=Brar%2C+A+S">Avalpreet Singh Brar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Extensive research has been conducted to explore vehicle lane changes, while
the study on cut-ins has not received sufficient attention. The existing
studies have not addressed the fundamental question of why studying cut-ins is
crucial, despite the extensive investigation into lane changes. To tackle this
issue, it is important to demonstrate how cut-ins, as a special type of lane
change, differ from other lane changes. In this paper, we explore to compare
driving characteristics of cut-ins and other lane changes based on naturalistic
driving data. The highD dataset is employed to conduct the comparison. We
extract all lane-change events from the dataset and exclude events that are not
suitable for our comparison. Lane-change events are then categorized into the
cut-in events and other lane-change events based on various gap-based rules.
Several performance metrics are designed to measure the driving characteristics
of the two types of events. We prove the significant differences between the
cut-in behavior and other lane-change behavior by using the Wilcoxon rank-sum
test. The results suggest the necessity of conducting specialized studies on
cut-ins, offering valuable insights for future research in this field.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08290" title="Abstract">arXiv:2402.08290</a> [<a href="/pdf/2402.08290" title="Download PDF">pdf</a>, <a href="/format/2402.08290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Effect of Data Poisoning on Counterfactual Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Artelt%2C+A">Andr&#xe9; Artelt</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S">Shubham Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Lecu%C3%A9%2C+F">Freddy Lecu&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Hammer%2C+B">Barbara Hammer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Counterfactual explanations provide a popular method for analyzing the
predictions of black-box systems, and they can offer the opportunity for
computational recourse by suggesting actionable changes on how to change the
input to obtain a different (i.e. more favorable) system output. However,
recent work highlighted their vulnerability to different types of
manipulations. This work studies the vulnerability of counterfactual
explanations to data poisoning. We formalize data poisoning in the context of
counterfactual explanations for increasing the cost of recourse on three
different levels: locally for a single instance, or a sub-group of instances,
or globally for all instances. We demonstrate that state-of-the-art
counterfactual generation methods \&amp; toolboxes are vulnerable to such data
poisoning.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08291" title="Abstract">arXiv:2402.08291</a> [<a href="/pdf/2402.08291" title="Download PDF">pdf</a>, <a href="/format/2402.08291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On a modified Hilbert transformation, the discrete inf-sup condition,  and error estimates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=L%C3%B6scher%2C+R">Richard L&#xf6;scher</a>, 
<a href="/search/math?searchtype=author&query=Steinbach%2C+O">Olaf Steinbach</a>, 
<a href="/search/math?searchtype=author&query=Zank%2C+M">Marco Zank</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we analyze the discrete inf-sup condition and related error
estimates for a modified Hilbert transformation as used in the space-time
discretization of time-dependent partial differential equations. It turns out
that the stability constant depends linearly on the finite element mesh
parameter, but in most cases, we can show optimal convergence. We present a
series of numerical experiments which illustrate the theoretical findings.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08294" title="Abstract">arXiv:2402.08294</a> [<a href="/pdf/2402.08294" title="Download PDF">pdf</a>, <a href="/format/2402.08294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning semantic image quality for fetal ultrasound from noisy ranking  annotation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Manxi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ambsdorf%2C+J">Jakob Ambsdorf</a>, 
<a href="/search/cs?searchtype=author&query=Sejer%2C+E+P+F">Emilie Pi Fogtmann Sejer</a>, 
<a href="/search/cs?searchtype=author&query=Bashir%2C+Z">Zahra Bashir</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+C+K">Chun Kit Wong</a>, 
<a href="/search/cs?searchtype=author&query=Pegios%2C+P">Paraskevas Pegios</a>, 
<a href="/search/cs?searchtype=author&query=Raheli%2C+A">Alberto Raheli</a>, 
<a href="/search/cs?searchtype=author&query=Svendsen%2C+M+B+S">Morten Bo S&#xf8;ndergaard Svendsen</a>, 
<a href="/search/cs?searchtype=author&query=Nielsen%2C+M">Mads Nielsen</a>, 
<a href="/search/cs?searchtype=author&query=Tolsgaard%2C+M+G">Martin Gr&#xf8;nneb&#xe6;k Tolsgaard</a>, 
<a href="/search/cs?searchtype=author&query=Christensen%2C+A+N">Anders Nymark Christensen</a>, 
<a href="/search/cs?searchtype=author&query=Feragen%2C+A">Aasa Feragen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of the accepted paper at ISBI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce the notion of semantic image quality for applications where
image quality relies on semantic requirements. Working in fetal ultrasound,
where ranking is challenging and annotations are noisy, we design a robust
coarse-to-fine model that ranks images based on their semantic image quality
and endow our predicted rankings with an uncertainty estimate. To annotate
rankings on training data, we design an efficient ranking annotation scheme
based on the merge sort algorithm. Finally, we compare our ranking algorithm to
a number of state-of-the-art ranking algorithms on a challenging fetal
ultrasound quality assessment task, showing the superior performance of our
method on the majority of rank correlation metrics.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08296" title="Abstract">arXiv:2402.08296</a> [<a href="/pdf/2402.08296" title="Download PDF">pdf</a>, <a href="/format/2402.08296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Level GNN Preconditioner for Solving Large Scale Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nastorg%2C+M">Matthieu Nastorg</a> (TAU, IFPEN), 
<a href="/search/cs?searchtype=author&query=Gratien%2C+J">Jean-Marc Gratien</a> (IFPEN), 
<a href="/search/cs?searchtype=author&query=Faney%2C+T">Thibault Faney</a> (IFPEN), 
<a href="/search/cs?searchtype=author&query=Bucci%2C+M+A">Michele Alessandro Bucci</a> (TAU), 
<a href="/search/cs?searchtype=author&query=Charpiat%2C+G">Guillaume Charpiat</a> (TAU), 
<a href="/search/cs?searchtype=author&query=Schoenauer%2C+M">Marc Schoenauer</a> (TAU)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Large-scale numerical simulations often come at the expense of daunting
computations. High-Performance Computing has enhanced the process, but adapting
legacy codes to leverage parallel GPU computations remains challenging.
Meanwhile, Machine Learning models can harness GPU computations effectively but
often struggle with generalization and accuracy. Graph Neural Networks (GNNs),
in particular, are great for learning from unstructured data like meshes but
are often limited to small-scale problems. Moreover, the capabilities of the
trained model usually restrict the accuracy of the data-driven solution. To
benefit from both worlds, this paper introduces a novel preconditioner
integrating a GNN model within a multi-level Domain Decomposition framework.
The proposed GNN-based preconditioner is used to enhance the efficiency of a
Krylov method, resulting in a hybrid solver that can converge with any desired
level of accuracy. The efficiency of the Krylov method greatly benefits from
the GNN preconditioner, which is adaptable to meshes of any size and shape, is
executed on GPUs, and features a multi-level approach to enforce the
scalability of the entire process. Several experiments are conducted to
validate the numerical behavior of the hybrid solver, and an in-depth analysis
of its performance is proposed to assess its competitiveness against a C++
legacy solver.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08298" title="Abstract">arXiv:2402.08298</a> [<a href="/pdf/2402.08298" title="Download PDF">pdf</a>, <a href="/ps/2402.08298" title="Download PostScript">ps</a>, <a href="/format/2402.08298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time to Stop and Think: What kind of research do we want to do?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ceberio%2C+J">Josu Ceberio</a>, 
<a href="/search/cs?searchtype=author&query=Calvo%2C+B">Borja Calvo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Experimentation is an intrinsic part of research in artificial intelligence
since it allows for collecting quantitative observations, validating
hypotheses, and providing evidence for their reformulation. For that reason,
experimentation must be coherent with the purposes of the research, properly
addressing the relevant questions in each case. Unfortunately, the literature
is full of works whose experimentation is neither rigorous nor convincing,
oftentimes designed to support prior beliefs rather than answering the relevant
research questions.
<br />In this paper, we focus on the field of metaheuristic optimization, since it
is our main field of work, and it is where we have observed the misconduct that
has motivated this letter. Even if we limit the focus of this manuscript to the
experimental part of the research, our main goal is to sew the seed of sincere
critical assessment of our work, sparking a reflection process both at the
individual and the community level. Such a reflection process is too complex
and extensive to be tackled as a whole. Therefore, to bring our feet to the
ground, we will include in this document our reflections about the role of
experimentation in our work, discussing topics such as the use of benchmark
instances vs instance generators, or the statistical assessment of empirical
results. That is, all the statements included in this document are personal
views and opinions, which can be shared by others or not. Certainly, having
different points of view is the basis to establish a good discussion process.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08299" title="Abstract">arXiv:2402.08299</a> [<a href="/pdf/2402.08299" title="Download PDF">pdf</a>, <a href="/format/2402.08299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero Trust Score-based Network-level Access Control in Enterprise  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bradatsch%2C+L">Leonard Bradatsch</a>, 
<a href="/search/cs?searchtype=author&query=Miroshkin%2C+O">Oleksandr Miroshkin</a>, 
<a href="/search/cs?searchtype=author&query=Trkulja%2C+N">Natasa Trkulja</a>, 
<a href="/search/cs?searchtype=author&query=Kargl%2C+F">Frank Kargl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is to be published in the Proceedings of 2023 IEEE 22nd International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Zero Trust security has recently gained attention in enterprise network
security. One of its key ideas is making network-level access decisions based
on trust scores. However, score-based access control in the enterprise domain
still lacks essential elements in our understanding, and in this paper, we
contribute with respect to three crucial aspects. First, we provide a
comprehensive list of 29 trust attributes that can be used to calculate a trust
score. By introducing a novel mathematical approach, we demonstrate how to
quantify these attributes. Second, we describe a dynamic risk-based method to
calculate the trust threshold the trust score must meet for permitted access.
Third, we introduce a novel trust algorithm based on Subjective Logic that
incorporates the first two contributions and offers fine-grained decision
possibilities. We discuss how this algorithm shows a higher expressiveness
compared to a lightweight additive trust algorithm. Performance-wise, a
prototype of the Subjective Logic-based approach showed similar calculation
times for making an access decision as the additive approach. In addition, the
dynamic threshold calculation showed only 7% increased decision-making times
compared to a static threshold.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08300" title="Abstract">arXiv:2402.08300</a> [<a href="/pdf/2402.08300" title="Download PDF">pdf</a>, <a href="/format/2402.08300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Order-Complexity Aesthetic Assessment Model for Aesthetic-aware Music  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Duo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yongsen Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Computational aesthetic evaluation has made remarkable contribution to visual
art works, but its application to music is still rare. Currently, subjective
evaluation is still the most effective form of evaluating artistic works.
However, subjective evaluation of artistic works will consume a lot of human
and material resources. The popular AI generated content (AIGC) tasks nowadays
have flooded all industries, and music is no exception. While compared to music
produced by humans, AI generated music still sounds mechanical, monotonous, and
lacks aesthetic appeal. Due to the lack of music datasets with rating
annotations, we have to choose traditional aesthetic equations to objectively
measure the beauty of music. In order to improve the quality of AI music
generation and further guide computer music production, synthesis,
recommendation and other tasks, we use Birkhoff's aesthetic measure to design a
aesthetic model, objectively measuring the aesthetic beauty of music, and form
a recommendation list according to the aesthetic feeling of music. Experiments
show that our objective aesthetic model and recommendation method are
effective.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08303" title="Abstract">arXiv:2402.08303</a> [<a href="/pdf/2402.08303" title="Download PDF">pdf</a>, <a href="/format/2402.08303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatCell: Facilitating Single-Cell Analysis with Natural Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kangwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ningyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+X">Xinle Deng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+P">Penghui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiangru Tang</a>, 
<a href="/search/cs?searchtype=author&query=Gerstein%2C+M">Mark Gerstein</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiaohui Fan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huajun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Ongoing work; 15 pages, 6 Tables, 9 Figures; Project homepage: <a href="https://zjunlp.github.io/project/ChatCell">this https URL</a>; Code: <a href="https://github.com/zjunlp/ChatCell">this https URL</a>; Dataset: <a href="https://huggingface.co/datasets/zjunlp/ChatCell-Instructions">this https URL</a>; Demo: <a href="https://huggingface.co/spaces/zjunlp/Chatcell">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">As Large Language Models (LLMs) rapidly evolve, their influence in science is
becoming increasingly prominent. The emerging capabilities of LLMs in task
generalization and free-form dialogue can significantly advance fields like
chemistry and biology. However, the field of single-cell biology, which forms
the foundational building blocks of living organisms, still faces several
challenges. High knowledge barriers and limited scalability in current methods
restrict the full exploitation of LLMs in mastering single-cell data, impeding
direct accessibility and rapid iteration. To this end, we introduce ChatCell,
which signifies a paradigm shift by facilitating single-cell analysis with
natural language. Leveraging vocabulary adaptation and unified sequence
generation, ChatCell has acquired profound expertise in single-cell biology and
the capability to accommodate a diverse range of analysis tasks. Extensive
experiments further demonstrate ChatCell's robust performance and potential to
deepen single-cell insights, paving the way for more accessible and intuitive
exploration in this pivotal field. Our project homepage is available at
https://zjunlp.github.io/project/ChatCell.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08309" title="Abstract">arXiv:2402.08309</a> [<a href="/pdf/2402.08309" title="Download PDF">pdf</a>, <a href="/format/2402.08309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompted Contextual Vectors for Spear-Phishing Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nahmias%2C+D">Daniel Nahmias</a>, 
<a href="/search/cs?searchtype=author&query=Engelberg%2C+G">Gal Engelberg</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+D">Dan Klein</a>, 
<a href="/search/cs?searchtype=author&query=Shabtai%2C+A">Asaf Shabtai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Spear-phishing attacks present a significant security challenge, with large
language models (LLMs) escalating the threat by generating convincing emails
and facilitating target reconnaissance. To address this, we propose a detection
approach based on a novel document vectorization method that utilizes an
ensemble of LLMs to create representation vectors. By prompting LLMs to reason
and respond to human-crafted questions, we quantify the presence of common
persuasion principles in the email's content, producing prompted contextual
document vectors for a downstream supervised machine learning model. We
evaluate our method using a unique dataset generated by a proprietary system
that automates target reconnaissance and spear-phishing email creation. Our
method achieves a 91% F1 score in identifying LLM-generated spear-phishing
emails, with the training set comprising only traditional phishing and benign
emails. Key contributions include an innovative document vectorization method
utilizing LLM reasoning, a publicly available dataset of high-quality
spear-phishing emails, and the demonstrated effectiveness of our method in
detecting such emails. This methodology can be utilized for various document
classification tasks, particularly in adversarial problem domains.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08310" title="Abstract">arXiv:2402.08310</a> [<a href="/pdf/2402.08310" title="Download PDF">pdf</a>, <a href="/format/2402.08310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-to-many Reconstruction of 3D Geometry of cultural Artifacts using a  synthetically trained Generative Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=P%C3%B6llabauer%2C+T">Thomas P&#xf6;llabauer</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BChn%2C+J">Julius K&#xfc;hn</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiayi Li</a>, 
<a href="/search/cs?searchtype=author&query=Kuijper%2C+A">Arjan Kuijper</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 21st Eurographics Workshop on Graphics and Cultural Heritage (GCH
  2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Estimating the 3D shape of an object using a single image is a difficult
problem. Modern approaches achieve good results for general objects, based on
real photographs, but worse results on less expressive representations such as
historic sketches. Our automated approach generates a variety of detailed 3D
representation from a single sketch, depicting a medieval statue, and can be
guided by multi-modal inputs, such as text prompts. It relies solely on
synthetic data for training, making it adoptable even in cases of only small
numbers of training examples. Our solution allows domain experts such as a
curators to interactively reconstruct potential appearances of lost artifacts.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08313" title="Abstract">arXiv:2402.08313</a> [<a href="/pdf/2402.08313" title="Download PDF">pdf</a>, <a href="/format/2402.08313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximating Families of Sharp Solutions to Fisher&#x27;s Equation with  Physics-Informed Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rohrhofer%2C+F+M">Franz M. Rohrhofer</a>, 
<a href="/search/cs?searchtype=author&query=Posch%2C+S">Stefan Posch</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B6%C3%9Fnitzer%2C+C">Clemens G&#xf6;&#xdf;nitzer</a>, 
<a href="/search/cs?searchtype=author&query=Geiger%2C+B+C">Bernhard C. Geiger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper employs physics-informed neural networks (PINNs) to solve Fisher's
equation, a fundamental representation of a reaction-diffusion system with both
simplicity and significance. The focus lies specifically in investigating
Fisher's equation under conditions of large reaction rate coefficients, wherein
solutions manifest as traveling waves, posing a challenge for numerical methods
due to the occurring steepness of the wave front. To address optimization
challenges associated with the standard PINN approach, a residual weighting
scheme is introduced. This scheme is designed to enhance the tracking of
propagating wave fronts by considering the reaction term in the
reaction-diffusion equation. Furthermore, a specific network architecture is
studied which is tailored for solutions in the form of traveling waves. Lastly,
the capacity of PINNs to approximate an entire family of solutions is assessed
by incorporating the reaction rate coefficient as an additional input to the
network architecture. This modification enables the approximation of the
solution across a broad and continuous range of reaction rate coefficients,
thus solving a class of reaction-diffusion systems using a single PINN
instance.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08314" title="Abstract">arXiv:2402.08314</a> [<a href="/pdf/2402.08314" title="Download PDF">pdf</a>, <a href="/ps/2402.08314" title="Download PostScript">ps</a>, <a href="/format/2402.08314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Willy Wonka Mechanisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Archbold%2C+T">Thomas Archbold</a>, 
<a href="/search/cs?searchtype=author&query=de+Keijzer%2C+B">Bart de Keijzer</a>, 
<a href="/search/cs?searchtype=author&query=Ventre%2C+C">Carmine Ventre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Bounded rationality in mechanism design aims to ensure
incentive-compatibility for agents who are cognitively limited. These agents
lack the contingent reasoning skills that traditional mechanism design assumes,
and depending on how these cognitive limitations are modelled this alters the
class of incentive-compatible mechanisms. In this work we design mechanisms
without any "obvious" manipulations for several auction settings that aim to
either maximise revenue or minimise the compensation paid to the agents. A
mechanism without obvious manipulations is said to be "not obviously
manipulable" (NOM), and assumes agents act truthfully as long as the maximum
and minimum utilities from doing so are no worse than the maximum and minimum
utilities from lying, with the extremes taken over all possible actions of the
other agents. We exploit the definition of NOM by introducing the concept of
"golden tickets" and "wooden spoons", which designate bid profiles ensuring the
mechanism's incentive-compatibility for each agent. We then characterise these
"Willy Wonka" mechanisms, and by carefully choosing the golden tickets and
wooden spoons we use this to design revenue-maximising auctions and frugal
procurement auctions.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08316" title="Abstract">arXiv:2402.08316</a> [<a href="/pdf/2402.08316" title="Download PDF">pdf</a>, <a href="/format/2402.08316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CrossGaze: A Strong Method for 3D Gaze Estimation in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=C%C4%83trun%C4%83%2C+A">Andy C&#x103;trun&#x103;</a>, 
<a href="/search/cs?searchtype=author&query=Cosma%2C+A">Adrian Cosma</a>, 
<a href="/search/cs?searchtype=author&query=R%C4%83doi%2C+E">Emilian R&#x103;doi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Gaze estimation, the task of predicting where an individual is looking, is a
critical task with direct applications in areas such as human-computer
interaction and virtual reality. Estimating the direction of looking in
unconstrained environments is difficult, due to the many factors that can
obscure the face and eye regions. In this work we propose CrossGaze, a strong
baseline for gaze estimation, that leverages recent developments in computer
vision architectures and attention-based modules. Unlike previous approaches,
our method does not require a specialised architecture, utilizing already
established models that we integrate in our architecture and adapt for the task
of 3D gaze estimation. This approach allows for seamless updates to the
architecture as any module can be replaced with more powerful feature
extractors. On the Gaze360 benchmark, our model surpasses several
state-of-the-art methods, achieving a mean angular error of 9.94 degrees. Our
proposed model serves as a strong foundation for future research and
development in gaze estimation, paving the way for practical and accurate gaze
prediction in real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08318" title="Abstract">arXiv:2402.08318</a> [<a href="/pdf/2402.08318" title="Download PDF">pdf</a>, <a href="/format/2402.08318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explicit References to Social Values in Fairy Tales: A Comparison  between Three European Cultures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diaz-Faes%2C+A+M">Alba Morollon Diaz-Faes</a>, 
<a href="/search/cs?searchtype=author&query=Murteira%2C+C+S+R">Carla Sofia Ribeiro Murteira</a>, 
<a href="/search/cs?searchtype=author&query=Ruskov%2C+M">Martin Ruskov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of the Joint 3rd International Conference on Natural Language Processing for Digital Humanities and 8th International Workshop on Computational Linguistics for Uralic Languages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The study of social values in fairy tales opens the possibility to learn
about the communication of values across space and time. We propose to study
the communication of values in fairy tales from Portugal, Italy and Germany
using a technique called word embedding with a compass to quantify vocabulary
differences and commonalities. We study how these three national traditions of
fairy tales differ in their explicit references to values. To do this, we
specify a list of value-charged tokens, consider their word stems and analyse
the distance between these in a bespoke pre-trained Word2Vec model. We
triangulate and critically discuss the validity of the resulting hypotheses
emerging from this quantitative model. Our claim is that this is a reusable and
reproducible method for the study of the values explicitly referenced in
historical corpora. Finally, our preliminary findings hint at a shared cultural
understanding and the expression of values such as Benevolence, Conformity, and
Universalism across European societies, suggesting the existence of a
pan-European cultural memory.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08320" title="Abstract">arXiv:2402.08320</a> [<a href="/pdf/2402.08320" title="Download PDF">pdf</a>, <a href="/format/2402.08320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Paradox of Motion: Evidence for Spurious Correlations in  Skeleton-based Gait Recognition Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=C%C4%83trun%C4%83%2C+A">Andy C&#x103;trun&#x103;</a>, 
<a href="/search/cs?searchtype=author&query=Cosma%2C+A">Adrian Cosma</a>, 
<a href="/search/cs?searchtype=author&query=R%C4%83doi%2C+E">Emilian R&#x103;doi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Gait, an unobtrusive biometric, is valued for its capability to identify
individuals at a distance, across external outfits and environmental
conditions. This study challenges the prevailing assumption that vision-based
gait recognition, in particular skeleton-based gait recognition, relies
primarily on motion patterns, revealing a significant role of the implicit
anthropometric information encoded in the walking sequence. We show through a
comparative analysis that removing height information leads to notable
performance degradation across three models and two benchmarks (CASIA-B and
GREW). Furthermore, we propose a spatial transformer model processing
individual poses, disregarding any temporal information, which achieves
unreasonably good accuracy, emphasizing the bias towards appearance information
and indicating spurious correlations in existing benchmarks. These findings
underscore the need for a nuanced understanding of the interplay between motion
and appearance in vision-based gait recognition, prompting a reevaluation of
the methodological assumptions in this field. Our experiments indicate that
"in-the-wild" datasets are less prone to spurious correlations, prompting the
need for more diverse and large scale datasets for advancing the field.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08321" title="Abstract">arXiv:2402.08321</a> [<a href="/pdf/2402.08321" title="Download PDF">pdf</a>, <a href="/ps/2402.08321" title="Download PostScript">ps</a>, <a href="/format/2402.08321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploration by Optimization with Hybrid Regularizers: Logarithmic Regret  with Adversarial Robustness in Partial Monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsuchiya%2C+T">Taira Tsuchiya</a>, 
<a href="/search/cs?searchtype=author&query=Ito%2C+S">Shinji Ito</a>, 
<a href="/search/cs?searchtype=author&query=Honda%2C+J">Junya Honda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Partial monitoring is a generic framework of online decision-making problems
with limited observations. To make decisions from such limited observations, it
is necessary to find an appropriate distribution for exploration. Recently, a
powerful approach for this purpose, exploration by optimization (ExO), was
proposed, which achieves the optimal bounds in adversarial environments with
follow-the-regularized-leader for a wide range of online decision-making
problems. However, a naive application of ExO in stochastic environments
significantly degrades regret bounds. To resolve this problem in locally
observable games, we first establish a novel framework and analysis for ExO
with a hybrid regularizer. This development allows us to significantly improve
the existing regret bounds of best-of-both-worlds (BOBW) algorithms, which
achieves nearly optimal bounds both in stochastic and adversarial environments.
In particular, we derive a stochastic regret bound of $O(\sum_{a \neq a^*} k^2
m^2 \log T / \Delta_a)$, where $k$, $m$, and $T$ are the numbers of actions,
observations and rounds, $a^*$ is an optimal action, and $\Delta_a$ is the
suboptimality gap for action $a$. This bound is roughly $\Theta(k^2 \log T)$
times smaller than existing BOBW bounds. In addition, for globally observable
games, we provide a new BOBW algorithm with the first $O(\log T)$ stochastic
bound.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08322" title="Abstract">arXiv:2402.08322</a> [<a href="/pdf/2402.08322" title="Download PDF">pdf</a>, <a href="/format/2402.08322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> zk-IoT: Securing the Internet of Things with Zero-Knowledge Proofs on  Blockchain Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramezan%2C+G">Gholamreza Ramezan</a>, 
<a href="/search/cs?searchtype=author&query=Meamari%2C+E">Ehsan Meamari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">This paper introduces the zk-IoT framework, a novel approach to enhancing the
security of Internet of Things (IoT) ecosystems through the use of
Zero-Knowledge Proofs (ZKPs) on blockchain platforms. Our framework ensures the
integrity of firmware execution and data processing in potentially compromised
IoT devices. By leveraging the concept of ZKP, we establish a trust layer that
facilitates secure, autonomous communication between IoT devices in
environments where devices may not inherently trust each other. The framework
comprises zk-Devices, which utilize functional commitment to generate proofs
for executed programs, and service contracts for encoding interaction logic
among devices. It also provides for IoT device automation using proof-carrying
data (PCD) and a blockchain layer for transparent and verifiable data
processing. We conduct experiments, the results of which show that proof
generation, publication, and verification timings meet the practical
requirements of IoT device communication, demonstrating the feasibility and
efficiency of our solution. The zk-IoT framework represents a significant
advancement in the realm of IoT security, paving the way for reliable and
scalable IoT networks across various applications, such as smart city
infrastructures, healthcare systems, and industrial automation.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08323" title="Abstract">arXiv:2402.08323</a> [<a href="/pdf/2402.08323" title="Download PDF">pdf</a>, <a href="/ps/2402.08323" title="Download PostScript">ps</a>, <a href="/format/2402.08323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mapping the Ethics of Generative AI: A Comprehensive Scoping Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hagendorff%2C+T">Thilo Hagendorff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The advent of generative artificial intelligence and the widespread adoption
of it in society engendered intensive debates about its ethical implications
and risks. These risks often differ from those associated with traditional
discriminative machine learning. To synthesize the recent discourse and map its
normative concepts, we conducted a scoping review on the ethics of generative
artificial intelligence, including especially large language models and
text-to-image models. Our analysis provides a taxonomy of 378 normative issues
in 19 topic areas and ranks them according to their prevalence in the
literature. The study offers a comprehensive overview for scholars,
practitioners, or policymakers, condensing the ethical debates surrounding
fairness, safety, harmful content, hallucinations, privacy, interaction risks,
security, alignment, societal impacts, and others. We discuss the results,
evaluate imbalances in the literature, and explore unsubstantiated risk
scenarios.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08324" title="Abstract">arXiv:2402.08324</a> [<a href="/pdf/2402.08324" title="Download PDF">pdf</a>, <a href="/format/2402.08324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Quantification via Stable Distribution Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Petersen%2C+F">Felix Petersen</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+A">Aashwin Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Kuehne%2C+H">Hilde Kuehne</a>, 
<a href="/search/cs?searchtype=author&query=Borgelt%2C+C">Christian Borgelt</a>, 
<a href="/search/cs?searchtype=author&query=Deussen%2C+O">Oliver Deussen</a>, 
<a href="/search/cs?searchtype=author&query=Yurochkin%2C+M">Mikhail Yurochkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ICLR 2024, Code @ <a href="https://github.com/Felix-Petersen/distprop">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We propose a new approach for propagating stable probability distributions
through neural networks. Our method is based on local linearization, which we
show to be an optimal approximation in terms of total variation distance for
the ReLU non-linearity. This allows propagating Gaussian and Cauchy input
uncertainties through neural networks to quantify their output uncertainties.
To demonstrate the utility of propagating distributions, we apply the proposed
method to predicting calibrated confidence intervals and selective prediction
on out-of-distribution data. The results demonstrate a broad applicability of
propagating distributions and show the advantages of our method over other
approaches such as moment matching.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08327" title="Abstract">arXiv:2402.08327</a> [<a href="/pdf/2402.08327" title="Download PDF">pdf</a>, <a href="/format/2402.08327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PreFLMR: Scaling Up Fine-Grained Late-Interaction Multi-modal Retrievers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weizhe Lin</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+J">Jingbiao Mei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinghong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Byrne%2C+B">Bill Byrne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Multimodal Models (LMMs) excel in natural language and visual
understanding but are challenged by exacting tasks such as Knowledge-based
Visual Question Answering (KB-VQA) which involve the retrieval of relevant
information from document collections to use in shaping answers to questions.
We present an extensive training and evaluation framework, M2KR, for KB-VQA.
M2KR contains a collection of vision and language tasks which we have
incorporated into a single suite of benchmark tasks for training and evaluating
general-purpose multi-modal retrievers. We use M2KR to develop PreFLMR, a
pre-trained version of the recently developed Fine-grained Late-interaction
Multi-modal Retriever (FLMR) approach to KB-VQA, and we report new
state-of-the-art results across a range of tasks. We also present
investigations into the scaling behaviors of PreFLMR intended to be useful in
future developments in general-purpose multi-modal retrievers.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08333" title="Abstract">arXiv:2402.08333</a> [<a href="/pdf/2402.08333" title="Download PDF">pdf</a>, <a href="/format/2402.08333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scribble-based fast weak-supervision and interactive corrections for  segmenting whole slide images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Habis%2C+A">Antoine Habis</a>, 
<a href="/search/cs?searchtype=author&query=Nathanson%2C+R+R">Roy Rosman Nathanson</a>, 
<a href="/search/cs?searchtype=author&query=Meas-Yedid%2C+V">Vannary Meas-Yedid</a>, 
<a href="/search/cs?searchtype=author&query=Angelini%2C+E+D">Elsa D. Angelini</a>, 
<a href="/search/cs?searchtype=author&query=Olivo-Marin%2C+J">Jean-Christophe Olivo-Marin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper proposes a dynamic interactive and weakly supervised segmentation
method with minimal user interactions to address two major challenges in the
segmentation of whole slide histopathology images. First, the lack of
hand-annotated datasets to train algorithms. Second, the lack of interactive
paradigms to enable a dialogue between the pathologist and the machine, which
can be a major obstacle for use in clinical routine.
<br />We therefore propose a fast and user oriented method to bridge this gap by
giving the pathologist control over the final result while limiting the number
of interactions needed to achieve a good result (over 90\% on all our metrics
with only 4 correction scribbles).
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08334" title="Abstract">arXiv:2402.08334</a> [<a href="/pdf/2402.08334" title="Download PDF">pdf</a>, <a href="/ps/2402.08334" title="Download PostScript">ps</a>, <a href="/format/2402.08334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Executable Specification of Oncology Dose-Escalation Protocols with  Prolog
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Norris%2C+D+C">David C. Norris</a>, 
<a href="/search/cs?searchtype=author&query=Triska%2C+M">Markus Triska</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 2 figures, 1 appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">We present, as a pure Prolog program, the first executable specification of
the 3 + 3 dose-escalation protocol commonly used in early-phase oncology drug
development. In this program, the imperative operations of the protocol emerge
as consequences of clinically meaningful anticipatory-regret scenarios that are
declared as CLP(Z) constraints. This 'regret-constrained' (RC) specification
yields a robust formulation which can be used to prove clinically meaningful
safety and liveness properties of the protocol before incorporating it into a
trial, and then as an on-line decision support system while the trial is
underway. Our RC specification also readily accommodates certain pragmatic
modifications to trial enrollment which severely strain traditionally
imperative formulations. The features of modern Prolog systems let us describe
the 3 + 3 protocol with a short and general program that has desirable
algebraic properties and can therefore be used, tested and reasoned about in
several different ways.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08339" title="Abstract">arXiv:2402.08339</a> [<a href="/pdf/2402.08339" title="Download PDF">pdf</a>, <a href="/ps/2402.08339" title="Download PostScript">ps</a>, <a href="/format/2402.08339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interleaved snowballing: Reducing the workload of literature curators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stephan%2C+R">Ralf Stephan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">We formally define the literature (reference) snowballing method and present
a refined version of it. We show that the improved algorithm can substantially
reduce curator work, even before application of text classification, by
reducing the number of candidates to classify. We also present a desktop
application named LitBall that implements this and other literature collection
methods, through access to the Semantic Scholar academic graph (S2AG).
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08341" title="Abstract">arXiv:2402.08341</a> [<a href="/pdf/2402.08341" title="Download PDF">pdf</a>, <a href="/format/2402.08341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eliciting Big Five Personality Traits in Large Language Models: A  Textual Analysis with Classifier-Driven Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hilliard%2C+A">Airlie Hilliard</a>, 
<a href="/search/cs?searchtype=author&query=Munoz%2C+C">Cristian Munoz</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zekun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Koshiyama%2C+A+S">Adriano Soares Koshiyama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Manuscript submitted to ACM Facct. Authors One and Two contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) are increasingly being utilized by both
candidates and employers in the recruitment context. However, with this comes
numerous ethical concerns, particularly related to the lack of transparency in
these "black-box" models. Although previous studies have sought to increase the
transparency of these models by investigating the personality traits of LLMs,
many of the previous studies have provided them with personality assessments to
complete. On the other hand, this study seeks to obtain a better understanding
of such models by examining their output variations based on different input
prompts. Specifically, we use a novel elicitation approach using prompts
derived from common interview questions, as well as prompts designed to elicit
particular Big Five personality traits to examine whether the models were
susceptible to trait-activation like humans are, to measure their personality
based on the language used in their outputs. To do so, we repeatedly prompted
multiple LMs with different parameter sizes, including Llama-2, Falcon,
Mistral, Bloom, GPT, OPT, and XLNet (base and fine tuned versions) and examined
their personality using classifiers trained on the myPersonality dataset. Our
results reveal that, generally, all LLMs demonstrate high openness and low
extraversion. However, whereas LMs with fewer parameters exhibit similar
behaviour in personality traits, newer and LMs with more parameters exhibit a
broader range of personality traits, with increased agreeableness, emotional
stability, and openness. Furthermore, a greater number of parameters is
positively associated with openness and conscientiousness. Moreover, fine-tuned
models exhibit minor modulations in their personality traits, contingent on the
dataset. Implications and directions for future research are discussed.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08343" title="Abstract">arXiv:2402.08343</a> [<a href="/pdf/2402.08343" title="Download PDF">pdf</a>, <a href="/format/2402.08343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Hybrid Approach for Identifying Obsolescence Features: Applied to  Railway Signaling Infrastructure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Saad%2C+E">Elie Saad</a>, 
<a href="/search/eess?searchtype=author&query=Besbes%2C+M">Mariem Besbes</a>, 
<a href="/search/eess?searchtype=author&query=Zolghadri%2C+M">Marc Zolghadri</a>, 
<a href="/search/eess?searchtype=author&query=Czmil%2C+V">Victor Czmil</a>, 
<a href="/search/eess?searchtype=author&query=Bourgeois%2C+V">Vincent Bourgeois</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Electrical component obsolescence poses a major issue especially within
systems with large life cycles. Thus, finding the optimal management solution
for each obsolescence case is as crucial as knowing what to consider when faced
with an obsolescence case. In this paper, a novel hybrid approach for
identifying features affecting electrical component obsolescence management is
introduced, which combines features engineering techniques and expert
knowledge. The method then uses machine learning to predict obsolescence
resolution techniques in order to find the optimal resolution. The motivation
behind this research is driven by the imperative need for SNCF RESEAU to
optimally address and mitigate the challenges posed by electrical component
obsolescence in railway infrastructure.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08345" title="Abstract">arXiv:2402.08345</a> [<a href="/pdf/2402.08345" title="Download PDF">pdf</a>, <a href="/format/2402.08345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditional Information Gain Trellis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bicici%2C+U+C">Ufuk Can Bicici</a>, 
<a href="/search/cs?searchtype=author&query=Meral%2C+T+H+S">Tuna Han Salih Meral</a>, 
<a href="/search/cs?searchtype=author&query=Akarun%2C+L">Lale Akarun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review in Pattern Recognition Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Conditional computing processes an input using only part of the neural
network's computational units. Learning to execute parts of a deep
convolutional network by routing individual samples has several advantages:
Reducing the computational burden is an obvious advantage. Furthermore, if
similar classes are routed to the same path, that part of the network learns to
discriminate between finer differences and better classification accuracies can
be attained with fewer parameters. Recently, several papers have exploited this
idea to take a particular child of a node in a tree-shaped network or to skip
parts of a network. In this work, we follow a Trellis-based approach for
generating specific execution paths in a deep convolutional neural network. We
have designed routing mechanisms that use differentiable information gain-based
cost functions to determine which subset of features in a convolutional layer
will be executed. We call our method Conditional Information Gain Trellis
(CIGT). We show that our conditional execution mechanism achieves comparable or
better model performance compared to unconditional baselines, using only a
fraction of the computational resources.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08346" title="Abstract">arXiv:2402.08346</a> [<a href="/pdf/2402.08346" title="Download PDF">pdf</a>, <a href="/format/2402.08346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tight (Double) Exponential Bounds for Identification Problems:  Locating-Dominating Set and Test Cover
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+D">Dipayan Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Foucaud%2C+F">Florent Foucaud</a>, 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+D">Diptapriyo Majumdar</a>, 
<a href="/search/cs?searchtype=author&query=Tale%2C+P">Prafullkumar Tale</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Abstract shortened to fit the requirements
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We investigate fine-grained algorithmic aspects of identification problems in
graphs and set systems, with a focus on Locating-Dominating Set and Test Cover.
We prove, among other things, the following three (tight) conditional lower
bounds. \begin{enumerate} \item \textsc{Locating-Dominating Set} does not admit
an algorithm running in time $2^{o(k^2)} \cdot poly(n)$, nor a polynomial time
kernelization algorithm that reduces the solution size and outputs a kernel
with $2^{o(k)}$ vertices, unless the \ETH\ fails. \end{enumerate} To the best
of our knowledge, \textsc{Locating-Dominating Set} is the first problem that
admits such an algorithmic lower-bound (with a quadratic function in the
exponent) when parameterized by the solution size. \begin{enumerate}[resume]
\item \textsc{Test Cover} does not admit an algorithm running in time
$2^{2^{o(k)}} \cdot poly(|U| + |\calF|)$. \end{enumerate} After \textsc{Edge
Clique Cover} and \textsc{BiClique Cover}, this is the only example that we
know of that admits a double exponential lower bound when parameterized by the
solution size. \begin{enumerate}[resume] \item \textsc{Locating-Dominating Set}
(respectively, \textsc{Test Cover}) parameterized by the treewidth of the input
graph (respectively, of the natural auxiliary graph) does not admit an
algorithm running in time $2^{2^{o(\tw)}} \cdot poly(n)$ (respectively,
$2^{2^{o(\tw)}} \cdot poly(|U| + |\calF|))$. \end{enumerate} This result
augments the small list of NP-Complete problems that admit double exponential
lower bounds when parameterized by treewidth. We also present algorithms whose
running times match the above lower bounds. We also investigate the
parameterizations by several other structural graph parameters, answering some
open problems from the literature.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08348" title="Abstract">arXiv:2402.08348</a> [<a href="/pdf/2402.08348" title="Download PDF">pdf</a>, <a href="/format/2402.08348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visually Dehallucinative Instruction Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cha%2C+S">Sungguk Cha</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jusung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Younghyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheoljong Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, synthetic visual instructions by generative language model
have demonstrated plausible text generation performance on the visual
question-answering tasks. However, challenges persist in the hallucination of
generative language models, i.e., the generated image-text data contains
unintended contents. This paper presents a novel and scalable method for
generating visually dehallucinative instructions, dubbed CAP2QA, that
constrains the scope to only image contents. Our key contributions lie in
introducing image-aligned instructive QA dataset CAP2QA-COCO and its scalable
recipe. In our experiments, we compare synthetic visual instruction datasets
that share the same source data by visual instruction tuning and conduct
general visual recognition tasks. It shows that our proposed method
significantly reduces visual hallucination while consistently improving visual
recognition ability and expressiveness.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08349" title="Abstract">arXiv:2402.08349</a> [<a href="/pdf/2402.08349" title="Download PDF">pdf</a>, <a href="/format/2402.08349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Data Model Robustness of Text-to-SQL Systems Based on  Real User Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=F%C3%BCrst%2C+J">Jonathan F&#xfc;rst</a>, 
<a href="/search/cs?searchtype=author&query=Kosten%2C+C">Catherine Kosten</a>, 
<a href="/search/cs?searchtype=author&query=Nooralahzadeh%2C+F">Farhard Nooralahzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Stockinger%2C+K">Kurt Stockinger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Text-to-SQL systems (also known as NL-to-SQL systems) have become an
increasingly popular solution for bridging the gap between user capabilities
and SQL-based data access. These systems translate user requests in natural
language to valid SQL statements for a specific database. Recent Text-to-SQL
systems have benefited from the rapid improvement of transformer-based language
models. However, while Text-to-SQL systems that incorporate such models
continuously reach new high scores on -- often synthetic -- benchmark datasets,
a systematic exploration of their robustness towards different data models in a
real-world, realistic scenario is notably missing. This paper provides the
first in-depth evaluation of the data model robustness of Text-to-SQL systems
in practice based on a multi-year international project focused on Text-to-SQL
interfaces. Our evaluation is based on a real-world deployment of FootballDB, a
system that was deployed over a 9 month period in the context of the FIFA World
Cup 2022, during which about 6K natural language questions were asked and
executed. All of our data is based on real user questions that were asked live
to the system. We manually labeled and translated a subset of these questions
for three different data models. For each data model, we explore the
performance of representative Text-to-SQL systems and language models. We
further quantify the impact of training data size, pre-, and post-processing
steps as well as language model inference time. Our comprehensive evaluation
sheds light on the design choices of real-world Text-to-SQL systems and their
impact on moving from research prototypes to real deployments. Last, we provide
a new benchmark dataset to the community, which is the first to enable the
evaluation of different data models for the same dataset and is substantially
more challenging than most previous datasets in terms of query complexity.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08358" title="Abstract">arXiv:2402.08358</a> [<a href="/pdf/2402.08358" title="Download PDF">pdf</a>, <a href="/ps/2402.08358" title="Download PostScript">ps</a>, <a href="/format/2402.08358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> De la Vall&#xe9;e Poussin filtered polynomial approximation on the half  line
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Donatella%2C+O">Occorsio Donatella</a>, 
<a href="/search/math?searchtype=author&query=Themistoclakis%2C+W">Woula Themistoclakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">On the half line we introduce a new sequence of near--best uniform
approximation polynomials, easily computable by the values of the approximated
function at a truncated number of Laguerre zeros. Such approximation
polynomials come from a discretization of filtered Fourier--Laguerre partial
sums, which are filtered by using a de la Vall\'ee Poussin (VP) filter. They
have the peculiarity of depending on two parameters: a truncation parameter
that determines how many of the $n$ Laguerre zeros are considered, and a
localization parameter, which determines the range of action of the VP filter
that we are going to apply. As $n\to\infty$, under simple assumptions on such
parameters and on the Laguerre exponents of the involved weights, we prove that
the new VP filtered approximation polynomials have uniformly bounded Lebesgue
constants and uniformly convergence at a near--best approximation rate, for any
locally continuous function on the semiaxis. \newline The theoretical results
have been validated by the numerical experiments. In particular, they show a
better performance of the proposed VP filtered approximation versus the
truncated Lagrange interpolation at the same nodes, especially for functions
a.e. very smooth with isolated singularities. In such cases we see a more
localized approximation as well as a good reduction of the Gibbs phenomenon.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08359" title="Abstract">arXiv:2402.08359</a> [<a href="/pdf/2402.08359" title="Download PDF">pdf</a>, <a href="/format/2402.08359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Produce Semi-dense Correspondences for Visual Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giang%2C+K+T">Khang Truong Giang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Soohwan Song</a>, 
<a href="/search/cs?searchtype=author&query=Jo%2C+S">Sungho Jo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 9 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This study addresses the challenge of performing visual localization in
demanding conditions such as night-time scenarios, adverse weather, and
seasonal changes. While many prior studies have focused on improving
image-matching performance to facilitate reliable dense keypoint matching
between images, existing methods often heavily rely on predefined feature
points on a reconstructed 3D model. Consequently, they tend to overlook
unobserved keypoints during the matching process. Therefore, dense keypoint
matches are not fully exploited, leading to a notable reduction in accuracy,
particularly in noisy scenes. To tackle this issue, we propose a novel
localization method that extracts reliable semi-dense 2D-3D matching points
based on dense keypoint matches. This approach involves regressing semi-dense
2D keypoints into 3D scene coordinates using a point inference network. The
network utilizes both geometric and visual cues to effectively infer 3D
coordinates for unobserved keypoints from the observed ones. The abundance of
matching information significantly enhances the accuracy of camera pose
estimation, even in scenarios involving noisy or sparse 3D models.
Comprehensive evaluations demonstrate that the proposed method outperforms
other methods in challenging scenes and achieves competitive results in
large-scale visual localization benchmarks. The code will be available.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08360" title="Abstract">arXiv:2402.08360</a> [<a href="/pdf/2402.08360" title="Download PDF">pdf</a>, <a href="/format/2402.08360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Question Answering Instruction: Unlocking Multimodal Large  Language Model To Domain-Specific Visual Multitasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jusung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cha%2C+S">Sungguk Cha</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Younghyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheoljong Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Having revolutionized natural language processing (NLP) applications, large
language models (LLMs) are expanding into the realm of multimodal inputs. Owing
to their ability to interpret images, multimodal LLMs (MLLMs) have been
primarily used for vision-language tasks. Currently, MLLMs have not yet been
extended for domain-specific visual tasks, which require a more explicit
understanding of visual information. We developed a method to transform
domain-specific visual and vision-language datasets into a unified question
answering format called Visual Question Answering Instruction (VQA-IN), thereby
extending MLLM to domain-specific tasks. The VQA-IN was applied to train
multiple MLLM architectures using smaller versions of LLMs (sLLMs). The
experimental results indicated that the proposed method achieved a high score
metric on domainspecific visual tasks while also maintaining its performance on
vision-language tasks in a multitask manner.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08365" title="Abstract">arXiv:2402.08365</a> [<a href="/pdf/2402.08365" title="Download PDF">pdf</a>, <a href="/format/2402.08365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuRes: Learning Proofs of Propositional Satisfiability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+M">Mohamed Ghanem</a>, 
<a href="/search/cs?searchtype=author&query=Schmitt%2C+F">Frederik Schmitt</a>, 
<a href="/search/cs?searchtype=author&query=Siber%2C+J">Julian Siber</a>, 
<a href="/search/cs?searchtype=author&query=Finkbeiner%2C+B">Bernd Finkbeiner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">We introduce NeuRes, a neuro-symbolic proof-based SAT solver. Unlike other
neural SAT solving methods, NeuRes is capable of proving unsatisfiability as
opposed to merely predicting it. By design, NeuRes operates in a
certificate-driven fashion by employing propositional resolution to prove
unsatisfiability and to accelerate the process of finding satisfying truth
assignments in case of unsat and sat formulas, respectively. To realize this,
we propose a novel architecture that adapts elements from Graph Neural Networks
and Pointer Networks to autoregressively select pairs of nodes from a dynamic
graph structure, which is essential to the generation of resolution proofs. Our
model is trained and evaluated on a dataset of teacher proofs and truth
assignments that we compiled with the same random formula distribution used by
NeuroSAT. In our experiments, we show that NeuRes solves more test formulas
than NeuroSAT by a rather wide margin on different distributions while being
much more data-efficient. Furthermore, we show that NeuRes is capable of
largely shortening teacher proofs by notable proportions. We use this feature
to devise a bootstrapped training procedure that manages to reduce a dataset of
proofs generated by an advanced solver by ~23% after training on it with no
extra guidance.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08367" title="Abstract">arXiv:2402.08367</a> [<a href="/pdf/2402.08367" title="Download PDF">pdf</a>, <a href="/format/2402.08367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RBF-PINN: Non-Fourier Positional Embedding in Physics-Informed Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+C">Chengxi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Burghardt%2C+T">Tilo Burghardt</a>, 
<a href="/search/cs?searchtype=author&query=Gambaruto%2C+A+M">Alberto M Gambaruto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2402.06955">arXiv:2402.06955</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">While many recent Physics-Informed Neural Networks (PINNs) variants have had
considerable success in solving Partial Differential Equations, the empirical
benefits of feature mapping drawn from the broader Neural Representations
research have been largely overlooked. We highlight the limitations of widely
used Fourier-based feature mapping in certain situations and suggest the use of
the conditionally positive definite Radial Basis Function. The empirical
findings demonstrate the effectiveness of our approach across a variety of
forward and inverse problem cases. Our method can be seamlessly integrated into
coordinate-based input neural networks and contribute to the wider field of
PINNs research.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08369" title="Abstract">arXiv:2402.08369</a> [<a href="/pdf/2402.08369" title="Download PDF">pdf</a>, <a href="/format/2402.08369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-shot Imitation in a Non-Stationary Environment via Multi-Modal Skill
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shin%2C+S">Sangwoo Shin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Daehee Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+M">Minjong Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+W+K">Woo Kyung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+H">Honguk Woo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICML-2023 Camera Ready Version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">One-shot imitation is to learn a new task from a single demonstration, yet it
is a challenging problem to adopt it for complex tasks with the high domain
diversity inherent in a non-stationary environment. To tackle the problem, we
explore the compositionality of complex tasks, and present a novel skill-based
imitation learning framework enabling one-shot imitation and zero-shot
adaptation; from a single demonstration for a complex unseen task, a semantic
skill sequence is inferred and then each skill in the sequence is converted
into an action sequence optimized for environmental hidden dynamics that can
vary over time. Specifically, we leverage a vision-language model to learn a
semantic skill set from offline video datasets, where each skill is represented
on the vision-language embedding space, and adapt meta-learning with dynamics
inference to enable zero-shot skill adaptation. We evaluate our framework with
various one-shot imitation scenarios for extended multi-stage Meta-world tasks,
showing its superiority in learning complex tasks, generalizing to dynamics
changes, and extending to different demonstration conditions and modalities,
compared to other baselines.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08371" title="Abstract">arXiv:2402.08371</a> [<a href="/pdf/2402.08371" title="Download PDF">pdf</a>, <a href="/ps/2402.08371" title="Download PostScript">ps</a>, <a href="/format/2402.08371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Helping university students to choose elective courses by using a hybrid  multi-criteria recommendation system with genetic optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esteban%2C+A">A. Esteban</a>, 
<a href="/search/cs?searchtype=author&query=Zafra%2C+A">A. Zafra</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+C">C. Romero</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Knowledge-Based Systems, (2020):194, 105385
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The wide availability of specific courses together with the flexibility of
academic plans in university studies reveal the importance of Recommendation
Systems (RSs) in this area. These systems appear as tools that help students to
choose courses that suit to their personal interests and their academic
performance. This paper presents a hybrid RS that combines Collaborative
Filtering (CF) and Content-based Filtering (CBF) using multiple criteria
related both to student and course information to recommend the most suitable
courses to the students. A Genetic Algorithm (GA) has been developed to
automatically discover the optimal RS configuration which include both the most
relevant criteria and the configuration of the rest of parameters. The
experimental study has used real information of Computer Science Degree of
University of Cordoba (Spain) including information gathered from students
during three academic years, counting on 2500 entries of 95 students and 63
courses. Experimental results show a study of the most relevant criteria for
the course recommendation, the importance of using a hybrid model that combines
both student information and course information to increase the reliability of
the recommendations as well as an excellent performance compared to previous
models.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08373" title="Abstract">arXiv:2402.08373</a> [<a href="/pdf/2402.08373" title="Download PDF">pdf</a>, <a href="/format/2402.08373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Series Classification for Dynamic Strategies in Multi-Step  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Green%2C+R">Riku Green</a>, 
<a href="/search/cs?searchtype=author&query=Stevens%2C+G">Grant Stevens</a>, 
<a href="/search/cs?searchtype=author&query=de+Menezes+e+Silva+Filho%2C+T">Telmo de Menezes e Silva Filho</a>, 
<a href="/search/cs?searchtype=author&query=Abdallah%2C+Z">Zahraa Abdallah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multi-step forecasting (MSF) in time-series, the ability to make predictions
multiple time steps into the future, is fundamental to almost all temporal
domains. To make such forecasts, one must assume the recursive complexity of
the temporal dynamics. Such assumptions are referred to as the forecasting
strategy used to train a predictive model. Previous work shows that it is not
clear which forecasting strategy is optimal a priori to evaluating on unseen
data. Furthermore, current approaches to MSF use a single (fixed) forecasting
strategy.
<br />In this paper, we characterise the instance-level variance of optimal
forecasting strategies and propose Dynamic Strategies (DyStrat) for MSF. We
experiment using 10 datasets from different scales, domains, and lengths of
multi-step horizons. When using a random-forest-based classifier, DyStrat
outperforms the best fixed strategy, which is not knowable a priori, 94% of the
time, with an average reduction in mean-squared error of 11%. Our approach
typically triples the top-1 accuracy compared to current approaches. Notably,
we show DyStrat generalises well for any MSF task.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08379" title="Abstract">arXiv:2402.08379</a> [<a href="/pdf/2402.08379" title="Download PDF">pdf</a>, <a href="/format/2402.08379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Duet of Representations and How Explanations Exacerbate It
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+C">Charles Wan</a>, 
<a href="/search/cs?searchtype=author&query=Belo%2C+R">Rodrigo Belo</a>, 
<a href="/search/cs?searchtype=author&query=Zejnilovi%C4%87%2C+L">Leid Zejnilovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Lavado%2C+S">Susana Lavado</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In World Conference on Explainable Artificial Intelligence (pp.
  181-197). Cham: Springer Nature Switzerland (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">An algorithm effects a causal representation of relations between features
and labels in the human's perception. Such a representation might conflict with
the human's prior belief. Explanations can direct the human's attention to the
conflicting feature and away from other relevant features. This leads to causal
overattribution and may adversely affect the human's information processing. In
a field experiment we implemented an XGBoost-trained model as a decision-making
aid for counselors at a public employment service to predict candidates' risk
of long-term unemployment. The treatment group of counselors was also provided
with SHAP. The results show that the quality of the human's decision-making is
worse when a feature on which the human holds a conflicting prior belief is
displayed as part of the explanation.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08381" title="Abstract">arXiv:2402.08381</a> [<a href="/pdf/2402.08381" title="Download PDF">pdf</a>, <a href="/format/2402.08381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAVRL: Learn to Fly in Cluttered Environments with Varying Speed
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hang Yu</a>, 
<a href="/search/cs?searchtype=author&query=De+Wagter%2C+C">Christophe De Wagter</a>, 
<a href="/search/cs?searchtype=author&query=de+Croon%2C+G+C+H+E">Guido C. H. E de Croon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Many existing obstacle avoidance algorithms overlook the crucial balance
between safety and agility, especially in environments of varying complexity.
In our study, we introduce an obstacle avoidance pipeline based on
reinforcement learning. This pipeline enables drones to adapt their flying
speed according to the environmental complexity. Moreover, to improve the
obstacle avoidance performance in cluttered environments, we propose a novel
latent space. The latent space in this representation is explicitly trained to
retain memory of previous depth map observations. Our findings confirm that
varying speed leads to a superior balance of success rate and agility in
cluttered environments. Additionally, our memory-augmented latent
representation outperforms the latent representation commonly used in
reinforcement learning. Finally, after minimal fine-tuning, we successfully
deployed our network on a real drone for enhanced obstacle avoidance.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08382" title="Abstract">arXiv:2402.08382</a> [<a href="/pdf/2402.08382" title="Download PDF">pdf</a>, <a href="/format/2402.08382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Punctuation Restoration Improves Structure Understanding without  Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Min%2C+J">Junghyun Min</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Minho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Woochul Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yeonsoo Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Unsupervised learning objectives like language modeling and de-noising
constitute a significant part in producing pre-trained models that perform
various downstream applications from natural language understanding to
conversational tasks. However, despite impressive conversational capabilities
of recent large language model, their abilities to capture syntactic or
semantic structure within text lag behind. We hypothesize that the mismatch
between linguistic performance and competence in machines is attributable to
insufficient transfer of linguistic structure knowledge to computational
systems with currently popular pre-training objectives. We show that
punctuation restoration transfers to improvements in in- and
out-of-distribution performance on structure-related tasks like named entity
recognition, open information extraction, chunking, and part-of-speech tagging.
Punctuation restoration is an effective learning objective that can improve
structure understanding and yield a more robust structure-aware representations
of natural language.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08383" title="Abstract">arXiv:2402.08383</a> [<a href="/pdf/2402.08383" title="Download PDF">pdf</a>, <a href="/format/2402.08383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Quantification for Forward and Inverse Problems of PDEs via  Latent Global Evolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tailin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Neiswanger%2C+W">Willie Neiswanger</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hongtao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Ermon%2C+S">Stefano Ermon</a>, 
<a href="/search/cs?searchtype=author&query=Leskovec%2C+J">Jure Leskovec</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep learning-based surrogate models have demonstrated remarkable advantages
over classical solvers in terms of speed, often achieving speedups of 10 to
1000 times over traditional partial differential equation (PDE) solvers.
However, a significant challenge hindering their widespread adoption in both
scientific and industrial domains is the lack of understanding about their
prediction uncertainties, particularly in scenarios that involve critical
decision making. To address this limitation, we propose a method that
integrates efficient and precise uncertainty quantification into a deep
learning-based surrogate model. Our method, termed Latent Evolution of PDEs
with Uncertainty Quantification (LE-PDE-UQ), endows deep learning-based
surrogate models with robust and efficient uncertainty quantification
capabilities for both forward and inverse problems. LE-PDE-UQ leverages latent
vectors within a latent space to evolve both the system's state and its
corresponding uncertainty estimation. The latent vectors are decoded to provide
predictions for the system's state as well as estimates of its uncertainty. In
extensive experiments, we demonstrate the accurate uncertainty quantification
performance of our approach, surpassing that of strong baselines including deep
ensembles, Bayesian neural network layers, and dropout. Our method excels at
propagating uncertainty over extended auto-regressive rollouts, making it
suitable for scenarios involving long-term predictions. Our code is available
at: https://github.com/AI4Science-WestlakeU/le-pde-uq.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08384" title="Abstract">arXiv:2402.08384</a> [<a href="/pdf/2402.08384" title="Download PDF">pdf</a>, <a href="/format/2402.08384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Selective Learning: Towards Robust Calibration with Dynamic  Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zongbo Han</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yifeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Changqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Linjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J+T">Joey Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qinghua Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Huaxiu Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Miscalibration in deep learning refers to there is a discrepancy between the
predicted confidence and performance. This problem usually arises due to the
overfitting problem, which is characterized by learning everything presented in
the training set, resulting in overconfident predictions during testing.
Existing methods typically address overfitting and mitigate the miscalibration
by adding a maximum-entropy regularizer to the objective function. The
objective can be understood as seeking a model that fits the ground-truth
labels by increasing the confidence while also maximizing the entropy of
predicted probabilities by decreasing the confidence. However, previous methods
lack clear guidance on confidence adjustment, leading to conflicting objectives
(increasing but also decreasing confidence). Therefore, we introduce a method
called Dynamic Regularization (DReg), which aims to learn what should be
learned during training thereby circumventing the confidence adjusting
trade-off. At a high level, DReg aims to obtain a more reliable model capable
of acknowledging what it knows and does not know. Specifically, DReg
effectively fits the labels for in-distribution samples (samples that should be
learned) while applying regularization dynamically to samples beyond model
capabilities (e.g., outliers), thereby obtaining a robust calibrated model
especially on the samples beyond model capabilities. Both theoretical and
empirical analyses sufficiently demonstrate the superiority of DReg compared
with previous methods.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08392" title="Abstract">arXiv:2402.08392</a> [<a href="/pdf/2402.08392" title="Download PDF">pdf</a>, <a href="/format/2402.08392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models as Minecraft Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madge%2C+C">Chris Madge</a>, 
<a href="/search/cs?searchtype=author&query=Poesio%2C+M">Massimo Poesio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this work we examine the use of Large Language Models (LLMs) in the
challenging setting of acting as a Minecraft agent. We apply and evaluate LLMs
in the builder and architect settings, introduce clarification questions and
examining the challenges and opportunities for improvement. In addition, we
present a platform for online interaction with the agents and an evaluation
against previous works.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08393" title="Abstract">arXiv:2402.08393</a> [<a href="/pdf/2402.08393" title="Download PDF">pdf</a>, <a href="/format/2402.08393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NfgTransformer: Equivariant Representation Learning for Normal-form  Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Siqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Marris%2C+L">Luke Marris</a>, 
<a href="/search/cs?searchtype=author&query=Piliouras%2C+G">Georgios Piliouras</a>, 
<a href="/search/cs?searchtype=author&query=Gemp%2C+I">Ian Gemp</a>, 
<a href="/search/cs?searchtype=author&query=Heess%2C+N">Nicolas Heess</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ICLR 2024. Open-sourced at <a href="https://github.com/google-deepmind/nfg_transformer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Normal-form games (NFGs) are the fundamental model of strategic interaction.
We study their representation using neural networks. We describe the inherent
equivariance of NFGs -- any permutation of strategies describes an equivalent
game -- as well as the challenges this poses for representation learning. We
then propose the NfgTransformer architecture that leverages this equivariance,
leading to state-of-the-art performance in a range of game-theoretic tasks
including equilibrium-solving, deviation gain estimation and ranking, with a
common approach to NFG representation. We show that the resulting model is
interpretable and versatile, paving the way towards deep learning systems
capable of game-theoretic reasoning when interacting with humans and with each
other.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08395" title="Abstract">arXiv:2402.08395</a> [<a href="/pdf/2402.08395" title="Download PDF">pdf</a>, <a href="/format/2402.08395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New limiter regions for multidimensional flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Woodfield%2C+J">James Woodfield</a>, 
<a href="/search/math?searchtype=author&query=Weller%2C+H">Hilary Weller</a>, 
<a href="/search/math?searchtype=author&query=Cotter%2C+C+J">Colin J Cotter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Accurate transport algorithms are crucial for computational fluid dynamics
and more accurate and efficient schemes are always in development. One
dimensional limiting is a commonly employed technique used to suppress
nonphysical oscillations. However, the application of such limiters can reduce
accuracy. It is important to identify the weakest set of sufficient conditions
required on the limiter as to allow the development of successful numerical
algorithms.
<br />The main goal of this paper is to identify new less restrictive sufficient
conditions for flux form in-compressible advection to remain monotonic. First,
we identify conditions in which the Spekreijse limiter region can fail to be
monotonic for incompressible flux form advection and demonstrate this
numerically. Then a convex combination argument is used to derive new
sufficient conditions that are less restrictive than the Sweby region for a
discrete maximum principle. This allows the introduction of two new more
general limiter regions suitable for flux form incompressible advection.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08397" title="Abstract">arXiv:2402.08397</a> [<a href="/pdf/2402.08397" title="Download PDF">pdf</a>, <a href="/format/2402.08397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Neural-network Enhanced Video Coding Framework beyond ECM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yanchen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wenxuan He</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+C">Chuanmin Jia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qizhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junru Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yue Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chaoyi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Siwei Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, a hybrid video compression framework is proposed that serves
as a demonstrative showcase of deep learning-based approaches extending beyond
the confines of traditional coding methodologies. The proposed hybrid framework
is founded upon the Enhanced Compression Model (ECM), which is a further
enhancement of the Versatile Video Coding (VVC) standard. We have augmented the
latest ECM reference software with well-designed coding techniques, including
block partitioning, deep learning-based loop filter, and the activation of
block importance mapping (BIM) which was integrated but previously inactive
within ECM, further enhancing coding performance. Compared with ECM-10.0, our
method achieves 6.26, 13.33, and 12.33 BD-rate savings for the Y, U, and V
components under random access (RA) configuration, respectively.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08400" title="Abstract">arXiv:2402.08400</a> [<a href="/pdf/2402.08400" title="Download PDF">pdf</a>, <a href="/format/2402.08400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Hierarchical Certification for Segmentation using Randomized  Smoothing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anani%2C+A">Alaa Anani</a>, 
<a href="/search/cs?searchtype=author&query=Lorenz%2C+T">Tobias Lorenz</a>, 
<a href="/search/cs?searchtype=author&query=Schiele%2C+B">Bernt Schiele</a>, 
<a href="/search/cs?searchtype=author&query=Fritz%2C+M">Mario Fritz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Common certification methods operate on a flat pre-defined set of
fine-grained classes. In this paper, however, we propose a novel, more general,
and practical setting, namely adaptive hierarchical certification for image
semantic segmentation. In this setting, the certification can be within a
multi-level hierarchical label space composed of fine to coarse levels. Unlike
classic methods where the certification would abstain for unstable components,
our approach adaptively relaxes the certification to a coarser level within the
hierarchy. This relaxation lowers the abstain rate whilst providing more
certified semantically meaningful information. We mathematically formulate the
problem setup and introduce, for the first time, an adaptive hierarchical
certification algorithm for image semantic segmentation, that certifies image
pixels within a hierarchy and prove the correctness of its guarantees. Since
certified accuracy does not take the loss of information into account when
traversing into a coarser hierarchy level, we introduce a novel evaluation
paradigm for adaptive hierarchical certification, namely the certified
information gain metric, which is proportional to the class granularity level.
Our evaluation experiments on real-world challenging datasets such as
Cityscapes and ACDC demonstrate that our adaptive algorithm achieves a higher
certified information gain and a lower abstain rate compared to the current
state-of-the-art certification method, as well as other non-adaptive versions
of it.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08401" title="Abstract">arXiv:2402.08401</a> [<a href="/pdf/2402.08401" title="Download PDF">pdf</a>, <a href="/format/2402.08401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LOSS-GAT: Label Propagation and One-Class Semi-Supervised Graph  Attention Network for Fake News Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lakzaei%2C+B">Batool Lakzaei</a>, 
<a href="/search/cs?searchtype=author&query=Chehreghani%2C+M+H">Mostafa Haghir Chehreghani</a>, 
<a href="/search/cs?searchtype=author&query=Bagheri%2C+A">Alireza Bagheri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In the era of widespread social networks, the rapid dissemination of fake
news has emerged as a significant threat, inflicting detrimental consequences
across various dimensions of people's lives. Machine learning and deep learning
approaches have been extensively employed for identifying fake news. However, a
significant challenge in identifying fake news is the limited availability of
labeled news datasets. Therefore, the One-Class Learning (OCL) approach,
utilizing only a small set of labeled data from the interest class, can be a
suitable approach to address this challenge. On the other hand, representing
data as a graph enables access to diverse content and structural information,
and label propagation methods on graphs can be effective in predicting node
labels. In this paper, we adopt a graph-based model for data representation and
introduce a semi-supervised and one-class approach for fake news detection,
called LOSS-GAT. Initially, we employ a two-step label propagation algorithm,
utilizing Graph Neural Networks (GNNs) as an initial classifier to categorize
news into two groups: interest (fake) and non-interest (real). Subsequently, we
enhance the graph structure using structural augmentation techniques.
Ultimately, we predict the final labels for all unlabeled data using a GNN that
induces randomness within the local neighborhood of nodes through the
aggregation function. We evaluate our proposed method on five common datasets
and compare the results against a set of baseline models, including both OCL
and binary labeled models. The results demonstrate that LOSS-GAT achieves a
notable improvement, surpassing 10%, with the advantage of utilizing only a
limited set of labeled fake news. Noteworthy, LOSS-GAT even outperforms binary
labeled models.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08403" title="Abstract">arXiv:2402.08403</a> [<a href="/pdf/2402.08403" title="Download PDF">pdf</a>, <a href="/format/2402.08403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMs and the Human Condition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wallis%2C+P">Peter Wallis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A draft paper for circulation. target is CUI or IVA in 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper presents three established theories of human decision-making and
describes how they can be integrated to provide a model of purposive human
action. Taking seriously the idea of language as action the model is then
applied to the conversational user interfaces. Theory based AI research has had
a hard time recently and the aim here is to revitalise interest in
understanding what LLMs are actually doing other than running poorly understood
machine learning routines over all the data the relevant Big Tech company can
hoover up. When a raspberry pi computer for under 50USD is up to 400 times
faster than the first commercial Cray super computer~\cite{crayVpi}, Big Tech
can get really close to having an infinite number of monkeys typing at random
and producing text, some of which will make sense. By understanding where
ChatGPT's apparent intelligence comes from, perhaps we can perform the magic
with fewer resources and at the same time gain some understanding about our
relationship with our world.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08405" title="Abstract">arXiv:2402.08405</a> [<a href="/pdf/2402.08405" title="Download PDF">pdf</a>, <a href="/format/2402.08405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Approach to Regularising 1NN classifier for Improved  Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Challa%2C+A">Aditya Challa</a>, 
<a href="/search/cs?searchtype=author&query=Danda%2C+S">Sravan Danda</a>, 
<a href="/search/cs?searchtype=author&query=Najman%2C+L">Laurent Najman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we propose a class of non-parametric classifiers, that learn
arbitrary boundaries and generalize well.
<br />Our approach is based on a novel way to regularize 1NN classifiers using a
greedy approach. We refer to this class of classifiers as Watershed
Classifiers. 1NN classifiers are known to trivially over-fit but have very
large VC dimension, hence do not generalize well. We show that watershed
classifiers can find arbitrary boundaries on any dense enough dataset, and, at
the same time, have very small VC dimension; hence a watershed classifier leads
to good generalization.
<br />Traditional approaches to regularize 1NN classifiers are to consider $K$
nearest neighbours. Neighbourhood component analysis (NCA) proposes a way to
learn representations consistent with ($n-1$) nearest neighbour classifier,
where $n$ denotes the size of the dataset. In this article, we propose a loss
function which can learn representations consistent with watershed classifiers,
and show that it outperforms the NCA baseline.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08406" title="Abstract">arXiv:2402.08406</a> [<a href="/pdf/2402.08406" title="Download PDF">pdf</a>, <a href="/format/2402.08406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transition Constrained Bayesian Optimization via Markov Decision  Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Folch%2C+J+P">Jose Pablo Folch</a>, 
<a href="/search/cs?searchtype=author&query=Tsay%2C+C">Calvin Tsay</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+R+M">Robert M Lee</a>, 
<a href="/search/cs?searchtype=author&query=Shafei%2C+B">Behrang Shafei</a>, 
<a href="/search/cs?searchtype=author&query=Ormaniec%2C+W">Weronika Ormaniec</a>, 
<a href="/search/cs?searchtype=author&query=Krause%2C+A">Andreas Krause</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Wilk%2C+M">Mark van der Wilk</a>, 
<a href="/search/cs?searchtype=author&query=Misener%2C+R">Ruth Misener</a>, 
<a href="/search/cs?searchtype=author&query=Mutn%C3%BD%2C+M">Mojm&#xed;r Mutn&#xfd;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages main, 24 pages total, 13 figures, 1 table, preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Bayesian optimization is a methodology to optimize black-box functions.
Traditionally, it focuses on the setting where you can arbitrarily query the
search space. However, many real-life problems do not offer this flexibility;
in particular, the search space of the next query may depend on previous ones.
Example challenges arise in the physical sciences in the form of local movement
constraints, required monotonicity in certain variables, and transitions
influencing the accuracy of measurements. Altogether, such transition
constraints necessitate a form of planning. This work extends Bayesian
optimization via the framework of Markov Decision Processes, iteratively
solving a tractable linearization of our objective using reinforcement learning
to obtain a policy that plans ahead over long horizons. The resulting policy is
potentially history-dependent and non-Markovian. We showcase applications in
chemical reactor optimization, informative path planning, machine calibration,
and other synthetic examples.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08407" title="Abstract">arXiv:2402.08407</a> [<a href="/pdf/2402.08407" title="Download PDF">pdf</a>, <a href="/format/2402.08407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coding-Based Hybrid Post-Quantum Cryptosystem for Non-Uniform  Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tarnopolsky%2C+S">Saar Tarnopolsky</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+A">Alejandro Cohen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">We introduce for non-uniform messages a novel hybrid universal network coding
cryptosystem (NU-HUNCC) in the finite blocklength regime that provides
Post-Quantum (PQ) security at high communication rates. Recently, hybrid
cryptosystems offered PQ security by premixing the data using secure coding
schemes and encrypting only a small portion of it, assuming the data is
uniformly distributed. An assumption that is often challenging to enforce.
Standard fixed-length lossless source coding and compression schemes guarantee
a uniform output in normalized divergence. Yet, his is not sufficient to
guarantee security. We consider an efficient almost uniform compression scheme
in non-normalized variational distance for the proposed hybrid cryptosystem,
that by utilizing uniform sub-linear shared seed, guarantees PQ security.
Specifically, for the proposed PQ cryptosystem, first, we provide an end-to-end
coding scheme, NU-HUNCC, for non-uniform messages. Second, we show that
NU-HUNCC is information-theoretic individually secured (IS) against an
eavesdropper with access to any subset of the links. Third, we introduce a
modified security definition, individually semantically secure under a chosen
ciphertext attack (ISS-CCA1), and show that against an all-observing
eavesdropper, NU-HUNCC satisfies its conditions. Finally, we provide an
analysis that shows the high communication rate of NU-HUNCC and the
negligibility of the shared seed size.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08409" title="Abstract">arXiv:2402.08409</a> [<a href="/pdf/2402.08409" title="Download PDF">pdf</a>, <a href="/format/2402.08409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transferring Ultrahigh-Field Representations for Intensity-Guided Brain  Segmentation of Low-Field Magnetic Resonance Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+K">Kwanseok Oh</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jieun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+D">Da-Woon Heo</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+D">Dinggang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Suk%2C+H">Heung-Il Suk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 9 figures, and 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Ultrahigh-field (UHF) magnetic resonance imaging (MRI), i.e., 7T MRI,
provides superior anatomical details of internal brain structures owing to its
enhanced signal-to-noise ratio and susceptibility-induced contrast. However,
the widespread use of 7T MRI is limited by its high cost and lower
accessibility compared to low-field (LF) MRI. This study proposes a
deep-learning framework that systematically fuses the input LF magnetic
resonance feature representations with the inferred 7T-like feature
representations for brain image segmentation tasks in a 7T-absent environment.
Specifically, our adaptive fusion module aggregates 7T-like features derived
from the LF image by a pre-trained network and then refines them to be
effectively assimilable UHF guidance into LF image features. Using
intensity-guided features obtained from such aggregation and assimilation,
segmentation models can recognize subtle structural representations that are
usually difficult to recognize when relying only on LF features. Beyond such
advantages, this strategy can seamlessly be utilized by modulating the contrast
of LF features in alignment with UHF guidance, even when employing arbitrary
segmentation models. Exhaustive experiments demonstrated that the proposed
method significantly outperformed all baseline models on both brain tissue and
whole-brain segmentation tasks; further, it exhibited remarkable adaptability
and scalability by successfully integrating diverse segmentation models and
tasks. These improvements were not only quantifiable but also visible in the
superlative visual quality of segmentation masks.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08411" title="Abstract">arXiv:2402.08411</a> [<a href="/pdf/2402.08411" title="Download PDF">pdf</a>, <a href="/ps/2402.08411" title="Download PostScript">ps</a>, <a href="/format/2402.08411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Insights Towards Better Case Study Reporting in Software Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rico%2C+S">Sergio Rico</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the International Workshop on Methodological Issues in Empirical Software Engineering (WSESE2024), ICSE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Case studies are a popular and noteworthy type of research study in software
engineering, offering significant potential to impact industry practices by
investigating phenomena in their natural contexts. This potential to reach a
broad audience beyond the academic community is often undermined by
deficiencies in reporting, particularly in the context description, study
classification, generalizability, and the handling of validity threats. This
paper presents a reflective analysis aiming to share insights that can enhance
the quality and impact of case study reporting.
<br />We emphasize the need to follow established guidelines, accurate
classification, and detailed context descriptions in case studies.
Additionally, particular focus is placed on articulating generalizable findings
and thoroughly discussing generalizability threats. We aim to encourage
researchers to adopt more rigorous and communicative strategies, ensuring that
case studies are methodologically sound, resonate with, and apply to software
engineering practitioners and the broader academic community. The reflections
and recommendations offered in this paper aim to ensure that insights from case
studies are transparent, understandable, and tailored to meet the needs of both
academic researchers and industry practitioners. In doing so, we seek to
enhance the real-world applicability of academic research, bridging the gap
between theoretical research and practical implementation in industry.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08413" title="Abstract">arXiv:2402.08413</a> [<a href="/pdf/2402.08413" title="Download PDF">pdf</a>, <a href="/format/2402.08413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mood as a Contextual Cue for Improved Emotion Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Narayana%2C+S">Soujanya Narayana</a>, 
<a href="/search/cs?searchtype=author&query=Radwan%2C+I">Ibrahim Radwan</a>, 
<a href="/search/cs?searchtype=author&query=Subramanian%2C+R">Ramanathan Subramanian</a>, 
<a href="/search/cs?searchtype=author&query=Goecke%2C+R">Roland Goecke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Psychological studies observe that emotions are rarely expressed in isolation
and are typically influenced by the surrounding context. While recent studies
effectively harness uni- and multimodal cues for emotion inference, hardly any
study has considered the effect of long-term affect, or \emph{mood}, on
short-term \emph{emotion} inference. This study (a) proposes time-continuous
\emph{valence} prediction from videos, fusing multimodal cues including
\emph{mood} and \emph{emotion-change} ($\Delta$) labels, (b) serially
integrates spatial and channel attention for improved inference, and (c)
demonstrates algorithmic generalisability with experiments on the \emph{EMMA}
and \emph{AffWild2} datasets. Empirical results affirm that utilising mood
labels is highly beneficial for dynamic valence prediction. Comparing
\emph{unimodal} (training only with mood labels) vs \emph{multimodal} (training
with mood and $\Delta$ labels) results, inference performance improves for the
latter, conveying that both long and short-term contextual cues are critical
for time-continuous emotion inference.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08416" title="Abstract">arXiv:2402.08416</a> [<a href="/pdf/2402.08416" title="Download PDF">pdf</a>, <a href="/format/2402.08416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pandora: Jailbreak GPTs by Retrieval Augmented Generation Poisoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+G">Gelei Deng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kailong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuekang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Large Language Models~(LLMs) have gained immense popularity and are being
increasingly applied in various domains. Consequently, ensuring the security of
these models is of paramount importance. Jailbreak attacks, which manipulate
LLMs to generate malicious content, are recognized as a significant
vulnerability. While existing research has predominantly focused on direct
jailbreak attacks on LLMs, there has been limited exploration of indirect
methods. The integration of various plugins into LLMs, notably Retrieval
Augmented Generation~(RAG), which enables LLMs to incorporate external
knowledge bases into their response generation such as GPTs, introduces new
avenues for indirect jailbreak attacks.
<br />To fill this gap, we investigate indirect jailbreak attacks on LLMs,
particularly GPTs, introducing a novel attack vector named Retrieval Augmented
Generation Poisoning. This method, Pandora, exploits the synergy between LLMs
and RAG through prompt manipulation to generate unexpected responses. Pandora
uses maliciously crafted content to influence the RAG process, effectively
initiating jailbreak attacks. Our preliminary tests show that Pandora
successfully conducts jailbreak attacks in four different scenarios, achieving
higher success rates than direct attacks, with 64.3\% for GPT-3.5 and 34.8\%
for GPT-4.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08420" title="Abstract">arXiv:2402.08420</a> [<a href="/pdf/2402.08420" title="Download PDF">pdf</a>, <a href="/format/2402.08420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision-Based Hand Gesture Customization from a Single Demonstration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahi%2C+S">Soroush Shahi</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+C+T">Cori Tymoszek Park</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+R">Richard Kang</a>, 
<a href="/search/cs?searchtype=author&query=Liberman%2C+A">Asaf Liberman</a>, 
<a href="/search/cs?searchtype=author&query=Levy%2C+O">Oron Levy</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+J">Jun Gong</a>, 
<a href="/search/cs?searchtype=author&query=Bedri%2C+A">Abdelkareem Bedri</a>, 
<a href="/search/cs?searchtype=author&query=Laput%2C+G">Gierad Laput</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Hand gesture recognition is becoming a more prevalent mode of human-computer
interaction, especially as cameras proliferate across everyday devices. Despite
continued progress in this field, gesture customization is often underexplored.
Customization is crucial since it enables users to define and demonstrate
gestures that are more natural, memorable, and accessible. However,
customization requires efficient usage of user-provided data. We introduce a
method that enables users to easily design bespoke gestures with a monocular
camera from one demonstration. We employ transformers and meta-learning
techniques to address few-shot learning challenges. Unlike prior work, our
method supports any combination of one-handed, two-handed, static, and dynamic
gestures, including different viewpoints. We evaluated our customization method
through a user study with 20 gestures collected from 21 participants, achieving
up to 97% average recognition accuracy from one demonstration. Our work
provides a viable path for vision-based gesture customization, laying the
foundation for future advancements in this domain.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08421" title="Abstract">arXiv:2402.08421</a> [<a href="/pdf/2402.08421" title="Download PDF">pdf</a>, <a href="/format/2402.08421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conservative and Risk-Aware Offline Multi-Agent Reinforcement Learning  for Digital Twins
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eldeeb%2C+E">Eslam Eldeeb</a>, 
<a href="/search/cs?searchtype=author&query=Sifaou%2C+H">Houssem Sifaou</a>, 
<a href="/search/cs?searchtype=author&query=Simeone%2C+O">Osvaldo Simeone</a>, 
<a href="/search/cs?searchtype=author&query=Shehab%2C+M">Mohammad Shehab</a>, 
<a href="/search/cs?searchtype=author&query=Alves%2C+H">Hirley Alves</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Digital twin (DT) platforms are increasingly regarded as a promising
technology for controlling, optimizing, and monitoring complex engineering
systems such as next-generation wireless networks. An important challenge in
adopting DT solutions is their reliance on data collected offline, lacking
direct access to the physical environment. This limitation is particularly
severe in multi-agent systems, for which conventional multi-agent reinforcement
(MARL) requires online interactions with the environment. A direct application
of online MARL schemes to an offline setting would generally fail due to the
epistemic uncertainty entailed by the limited availability of data. In this
work, we propose an offline MARL scheme for DT-based wireless networks that
integrates distributional RL and conservative Q-learning to address the
environment's inherent aleatoric uncertainty and the epistemic uncertainty
arising from limited data. To further exploit the offline data, we adapt the
proposed scheme to the centralized training decentralized execution framework,
allowing joint training of the agents' policies. The proposed MARL scheme,
referred to as multi-agent conservative quantile regression (MA-CQR) addresses
general risk-sensitive design criteria and is applied to the trajectory
planning problem in drone networks, showcasing its advantages.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08423" title="Abstract">arXiv:2402.08423</a> [<a href="/pdf/2402.08423" title="Download PDF">pdf</a>, <a href="/format/2402.08423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vehicle Behavior Prediction by Episodic-Memory Implanted NDT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+P">Peining Shen</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jianwu Fang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hongkai Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Jianru Xue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICRA2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In autonomous driving, predicting the behavior (turning left, stopping, etc.)
of target vehicles is crucial for the self-driving vehicle to make safe
decisions and avoid accidents. Existing deep learning-based methods have shown
excellent and accurate performance, but the black-box nature makes it
untrustworthy to apply them in practical use. In this work, we explore the
interpretability of behavior prediction of target vehicles by an Episodic
Memory implanted Neural Decision Tree (abbrev. eMem-NDT). The structure of
eMem-NDT is constructed by hierarchically clustering the text embedding of
vehicle behavior descriptions. eMem-NDT is a neural-backed part of a
pre-trained deep learning model by changing the soft-max layer of the deep
model to eMem-NDT, for grouping and aligning the memory prototypes of the
historical vehicle behavior features in training data on a neural decision
tree. Each leaf node of eMem-NDT is modeled by a neural network for aligning
the behavior memory prototypes. By eMem-NDT, we infer each instance in behavior
prediction of vehicles by bottom-up Memory Prototype Matching (MPM) (searching
the appropriate leaf node and the links to the root node) and top-down Leaf
Link Aggregation (LLA) (obtaining the probability of future behaviors of
vehicles for certain instances). We validate eMem-NDT on BLVD and LOKI
datasets, and the results show that our model can obtain a superior performance
to other methods with clear explainability. The code is available at
https://github.com/JWFangit/eMem-NDT.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08424" title="Abstract">arXiv:2402.08424</a> [<a href="/pdf/2402.08424" title="Download PDF">pdf</a>, <a href="/format/2402.08424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditional Neural Expert Processes for Learning from Demonstration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yildirim%2C+Y">Yigit Yildirim</a>, 
<a href="/search/cs?searchtype=author&query=Ugur%2C+E">Emre Ugur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. Submitted to Robotics and Automation Letters on February 13, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Learning from Demonstration (LfD) is a widely used technique for skill
acquisition in robotics. However, demonstrations of the same skill may exhibit
significant variances, or learning systems may attempt to acquire different
means of the same skill simultaneously, making it challenging to encode these
motions into movement primitives. To address these challenges, we propose an
LfD framework, namely the Conditional Neural Expert Processes (CNEP), that
learns to assign demonstrations from different modes to distinct expert
networks utilizing the inherent information within the latent space to match
experts with the encoded representations. CNEP does not require supervision on
which mode the trajectories belong to. Provided experiments on artificially
generated datasets demonstrate the efficacy of CNEP. Furthermore, we compare
the performance of CNEP with another LfD framework, namely Conditional Neural
Movement Primitives (CNMP), on a range of tasks, including experiments on a
real robot. The results reveal enhanced modeling performance for movement
primitives, leading to the synthesis of trajectories that more accurately
reflect those demonstrated by experts, particularly when the model inputs
include intersection points from various trajectories. Additionally, CNEP
offers improved interpretability and faster convergence by promoting expert
specialization. Furthermore, we show that the CNEP model accomplishes obstacle
avoidance tasks with a real manipulator when provided with novel start and
destination points, in contrast to the CNMP model, which leads to collisions
with the obstacle.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08426" title="Abstract">arXiv:2402.08426</a> [<a href="/pdf/2402.08426" title="Download PDF">pdf</a>, <a href="/format/2402.08426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frequency-aware Graph Signal Processing for Collaborative Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+J">Jiafeng Xia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hansu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tun Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+L">Li Shang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+N">Ning Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Graph Signal Processing (GSP) based recommendation algorithms have recently
attracted lots of attention due to its high efficiency. However, these methods
failed to consider the importance of various interactions that reflect unique
user/item characteristics and failed to utilize user and item high-order
neighborhood information to model user preference, thus leading to sub-optimal
performance. To address the above issues, we propose a frequency-aware graph
signal processing method (FaGSP) for collaborative filtering. Firstly, we
design a Cascaded Filter Module, consisting of an ideal high-pass filter and an
ideal low-pass filter that work in a successive manner, to capture both unique
and common user/item characteristics to more accurately model user preference.
Then, we devise a Parallel Filter Module, consisting of two low-pass filters
that can easily capture the hierarchy of neighborhood, to fully utilize
high-order neighborhood information of users/items for more accurate user
preference modeling. Finally, we combine these two modules via a linear model
to further improve recommendation accuracy. Extensive experiments on six public
datasets demonstrate the superiority of our method from the perspectives of
prediction accuracy and training efficiency compared with state-of-the-art
GCN-based recommendation methods and GSP-based recommendation methods.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08427" title="Abstract">arXiv:2402.08427</a> [<a href="/pdf/2402.08427" title="Download PDF">pdf</a>, <a href="/format/2402.08427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Self-Supervised Instance Contrastive Learning for Radar  Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Decourt%2C+C">Colin Decourt</a>, 
<a href="/search/cs?searchtype=author&query=VanRullen%2C+R">Rufin VanRullen</a>, 
<a href="/search/cs?searchtype=author&query=Salle%2C+D">Didier Salle</a>, 
<a href="/search/cs?searchtype=author&query=Oberlin%2C+T">Thomas Oberlin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, driven by the need for safer and more autonomous transport
systems, the automotive industry has shifted toward integrating a growing
number of Advanced Driver Assistance Systems (ADAS). Among the array of sensors
employed for object recognition tasks, radar sensors have emerged as a
formidable contender due to their abilities in adverse weather conditions or
low-light scenarios and their robustness in maintaining consistent performance
across diverse environments. However, the small size of radar datasets and the
complexity of the labelling of those data limit the performance of radar object
detectors. Driven by the promising results of self-supervised learning in
computer vision, this paper presents RiCL, an instance contrastive learning
framework to pre-train radar object detectors. We propose to exploit the
detection from the radar and the temporal information to pre-train the radar
object detection model in a self-supervised way using contrastive learning. We
aim to pre-train an object detector's backbone, head and neck to learn with
fewer data. Experiments on the CARRADA and the RADDet datasets show the
effectiveness of our approach in learning generic representations of objects in
range-Doppler maps. Notably, our pre-training strategy allows us to use only
20% of the labelled data to reach a similar mAP@0.5 than a supervised approach
using the whole training set.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08429" title="Abstract">arXiv:2402.08429</a> [<a href="/pdf/2402.08429" title="Download PDF">pdf</a>, <a href="/format/2402.08429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is 3-(F)WL Enough to Distinguish All 3D Graphs?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wanghan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Other Computer Science (cs.OH)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The problem of graph isomorphism is an important but challenging problem in
the field of graph analysis, for example: analyzing the similarity of two
chemical molecules, or studying the expressive ability of graph neural
networks. WL test is a method to judge whether two graphs are isomorphic, but
it cannot distinguish all non-isomorphic graphs. As an improvement of WL, k-WL
has stronger isomorphism discrimination ability, and as k increases, its
discrimination ability is strictly increasing. However, whether the isomorphic
discrimination power of k-WL is strictly increasing for more complex 3D graphs,
or whether there exists k that can discriminate all 3D graphs, remains
unexplored. This paper attempts to explore this problem from the perspective of
graph generation.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08430" title="Abstract">arXiv:2402.08430</a> [<a href="/pdf/2402.08430" title="Download PDF">pdf</a>, <a href="/format/2402.08430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Prompt Influence on Automated Method Generation: An Empirical  Study with Copilot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fagadau%2C+I+D">Ionut Daniel Fagadau</a>, 
<a href="/search/cs?searchtype=author&query=Mariani%2C+L">Leonardo Mariani</a>, 
<a href="/search/cs?searchtype=author&query=Micucci%2C+D">Daniela Micucci</a>, 
<a href="/search/cs?searchtype=author&query=Riganelli%2C+O">Oliviero Riganelli</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 32nd IEEE/ACM International Conference on
  Program Comprehension (ICPC 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Generative AI is changing the way developers interact with software systems,
providing services that can produce and deliver new content, crafted to satisfy
the actual needs of developers. For instance, developers can ask for new code
directly from within their IDEs by writing natural language prompts, and
integrated services based on generative AI, such as Copilot, immediately
respond to prompts by providing ready-to-use code snippets. Formulating the
prompt appropriately, and incorporating the useful information while avoiding
any information overload, can be an important factor in obtaining the right
piece of code. The task of designing good prompts is known as prompt
engineering. In this paper, we systematically investigate the influence of
eight prompt features on the style and the content of prompts, on the level of
correctness, complexity, size, and similarity to the developers' code of the
generated code. We specifically consider the task of using Copilot with 124,800
prompts obtained by systematically combining the eight considered prompt
features to generate the implementation of 200 Java methods. Results show how
some prompt features, such as the presence of examples and the summary of the
purpose of the method, can significantly influence the quality of the result.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08431" title="Abstract">arXiv:2402.08431</a> [<a href="/pdf/2402.08431" title="Download PDF">pdf</a>, <a href="/format/2402.08431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Java Methods: An Empirical Assessment of Four AI-Based Code  Assistants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Corso%2C+V">Vincenzo Corso</a>, 
<a href="/search/cs?searchtype=author&query=Mariani%2C+L">Leonardo Mariani</a>, 
<a href="/search/cs?searchtype=author&query=Micucci%2C+D">Daniela Micucci</a>, 
<a href="/search/cs?searchtype=author&query=Riganelli%2C+O">Oliviero Riganelli</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of 32nd IEEE/ACM International Conference on Program
  Comprehension (ICPC 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">AI-based code assistants are promising tools that can facilitate and speed up
code development. They exploit machine learning algorithms and natural language
processing to interact with developers, suggesting code snippets (e.g., method
implementations) that can be incorporated into projects. Recent studies
empirically investigated the effectiveness of code assistants using simple
exemplary problems (e.g., the re-implementation of well-known algorithms),
which fail to capture the spectrum and nature of the tasks actually faced by
developers. In this paper, we expand the knowledge in the area by comparatively
assessing four popular AI-based code assistants, namely GitHub Copilot,
Tabnine, ChatGPT, and Google Bard, with a dataset of 100 methods that we
constructed from real-life open-source Java projects, considering a variety of
cases for complexity and dependency from contextual elements. Results show that
Copilot is often more accurate than other techniques, yet none of the
assistants is completely subsumed by the rest of the approaches. Interestingly,
the effectiveness of these solutions dramatically decreases when dealing with
dependencies outside the boundaries of single classes.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08434" title="Abstract">arXiv:2402.08434</a> [<a href="/pdf/2402.08434" title="Download PDF">pdf</a>, <a href="/format/2402.08434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving promise equations over monoids and groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Larrauri%2C+A">Alberto Larrauri</a>, 
<a href="/search/cs?searchtype=author&query=%C5%BDivn%C3%BD%2C+S">Stanislav &#x17d;ivn&#xfd;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">We give a complete complexity classification for the problem of finding a
solution to a given system of equations over a fixed finite monoid, given that
a solut ion over a more restricted monoid exists. As a corollary, we obtain a
complexity classification for the same problem over groups.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08436" title="Abstract">arXiv:2402.08436</a> [<a href="/pdf/2402.08436" title="Download PDF">pdf</a>, <a href="/ps/2402.08436" title="Download PostScript">ps</a>, <a href="/format/2402.08436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The current state of security -- Insights from the German software  industry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Langstrof%2C+T">Timo Langstrof</a>, 
<a href="/search/cs?searchtype=author&query=Sabau%2C+A+R">Alex R. Sabau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">These days, software development and security go hand in hand. Numerous
techniques and strategies are discussed in the literature that can be applied
to guarantee the incorporation of security into the software development
process. In this paper the main ideas of secure software development that have
been discussed in the literature are outlined. Next, a dataset on
implementation in practice is gathered through a qualitative interview research
involving 20 companies. Trends and correlations in this dataset are found and
contrasted with theoretical ideas from the literature. The results show that
the organizations that were polled are placing an increasing focus on security.
Although the techniques covered in the literature are being used in the real
world, they are frequently not fully integrated into formal, standardized
processes. The insights gained from our research lay the groundwork for future
research, which can delve deeper into specific elements of these methods to
enhance our understanding of their application in real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08437" title="Abstract">arXiv:2402.08437</a> [<a href="/pdf/2402.08437" title="Download PDF">pdf</a>, <a href="/format/2402.08437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Camera Calibration through Geometric Constraints from Rotation and  Projection Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Waleed%2C+M">Muhammad Waleed</a>, 
<a href="/search/cs?searchtype=author&query=Rauf%2C+A">Abdul Rauf</a>, 
<a href="/search/cs?searchtype=author&query=Taj%2C+M">Murtaza Taj</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The process of camera calibration involves estimating the intrinsic and
extrinsic parameters, which are essential for accurately performing tasks such
as 3D reconstruction, object tracking and augmented reality. In this work, we
propose a novel constraints-based loss for measuring the intrinsic (focal
length: $(f_x, f_y)$ and principal point: $(p_x, p_y)$) and extrinsic
(baseline: ($b$), disparity: ($d$), translation: $(t_x, t_y, t_z)$, and
rotation specifically pitch: $(\theta_p)$) camera parameters. Our novel
constraints are based on geometric properties inherent in the camera model,
including the anatomy of the projection matrix (vanishing points, image of
world origin, axis planes) and the orthonormality of the rotation matrix. Thus
we proposed a novel Unsupervised Geometric Constraint Loss (UGCL) via a
multitask learning framework. Our methodology is a hybrid approach that employs
the learning power of a neural network to estimate the desired parameters along
with the underlying mathematical properties inherent in the camera projection
matrix. This distinctive approach not only enhances the interpretability of the
model but also facilitates a more informed learning process. Additionally, we
introduce a new CVGL Camera Calibration dataset, featuring over 900
configurations of camera parameters, incorporating 63,600 image pairs that
closely mirror real-world conditions. By training and testing on both synthetic
and real-world datasets, our proposed approach demonstrates improvements across
all parameters when compared to the state-of-the-art (SOTA) benchmarks. The
code and the updated dataset can be found here:
https://github.com/CVLABLUMS/CVGL-Camera-Calibration
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08439" title="Abstract">arXiv:2402.08439</a> [<a href="/pdf/2402.08439" title="Download PDF">pdf</a>, <a href="/format/2402.08439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JeFaPaTo -- A joint toolbox for blinking analysis and facial features  extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%BCchner%2C+T">Tim B&#xfc;chner</a>, 
<a href="/search/cs?searchtype=author&query=Mothes%2C+O">Oliver Mothes</a>, 
<a href="/search/cs?searchtype=author&query=Guntinas-Lichius%2C+O">Orlando Guntinas-Lichius</a>, 
<a href="/search/cs?searchtype=author&query=Denzler%2C+J">Joachim Denzler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A Preprint - Submitted to the Journal of Open Source Software; 6 pages, 3 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Analyzing facial features and expressions is a complex task in computer
vision. The human face is intricate, with significant shape, texture, and
appearance variations. In medical contexts, facial structures that differ from
the norm, such as those affected by paralysis, are particularly important to
study and require precise analysis. One area of interest is the subtle
movements involved in blinking, a process that is not yet fully understood and
needs high-resolution, time-specific analysis for detailed understanding.
However, a significant challenge is that many advanced computer vision
techniques demand programming skills, making them less accessible to medical
professionals who may not have these skills. The Jena Facial Palsy Toolbox
(JeFaPaTo) has been developed to bridge this gap. It utilizes cutting-edge
computer vision algorithms and offers a user-friendly interface for those
without programming expertise. This toolbox is designed to make advanced facial
analysis more accessible to medical experts, simplifying integration into their
workflow.
<br />The state of the eye closure is of high interest to medical experts, e.g., in
the context of facial palsy or Parkinson's disease. Due to facial nerve damage,
the eye-closing process might be impaired and could lead to many undesirable
side effects. Hence, more than a simple distinction between open and closed
eyes is required for a detailed analysis. Factors such as duration,
synchronicity, velocity, complete closure, the time between blinks, and
frequency over time are highly relevant. Such detailed analysis could help
medical experts better understand the blinking process, its deviations, and
possible treatments for better eye care.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08441" title="Abstract">arXiv:2402.08441</a> [<a href="/pdf/2402.08441" title="Download PDF">pdf</a>, <a href="/format/2402.08441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent space configuration for improved generalization in supervised  autoencoder neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gabdullin%2C+N">Nikita Gabdullin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages,18 figures, 2 tables, 15 equations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Autoencoders (AE) are simple yet powerful class of neural networks that
compress data by projecting input into low-dimensional latent space (LS).
Whereas LS is formed according to the loss function minimization during
training, its properties and topology are not controlled directly. In this
paper we focus on AE LS properties and propose two methods for obtaining LS
with desired topology, called LS configuration. The proposed methods include
loss configuration using a geometric loss term that acts directly in LS, and
encoder configuration. We show that the former allows to reliably obtain LS
with desired configuration by defining the positions and shapes of LS clusters
for supervised AE (SAE). Knowing LS configuration allows to define similarity
measure in LS to predict labels or estimate similarity for multiple inputs
without using decoders or classifiers. We also show that this leads to more
stable and interpretable training. We show that SAE trained for clothes texture
classification using the proposed method generalizes well to unseen data from
LIP, Market1501, and WildTrack datasets without fine-tuning, and even allows to
evaluate similarity for unseen classes. We further illustrate the advantages of
pre-configured LS similarity estimation with cross-dataset searches and
text-based search using a text query without language models.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08443" title="Abstract">arXiv:2402.08443</a> [<a href="/pdf/2402.08443" title="Download PDF">pdf</a>, <a href="/format/2402.08443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-aware Dynamic Resource Allocation in Virtual Sensor Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delgado%2C+C">Carmen Delgado</a>, 
<a href="/search/cs?searchtype=author&query=Canales%2C+M">Mar&#xed;a Canales</a>, 
<a href="/search/cs?searchtype=author&query=Ort%C3%ADn%2C+J">Jorge Ort&#xed;n</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%A1llego%2C+J+R">Jos&#xe9; Ram&#xf3;n G&#xe1;llego</a>, 
<a href="/search/cs?searchtype=author&query=Redondi%2C+A">Alessandro Redondi</a>, 
<a href="/search/cs?searchtype=author&query=Bousnina%2C+S">Sonda Bousnina</a>, 
<a href="/search/cs?searchtype=author&query=Cesana%2C+M">Matteo Cesana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference Version: 5 pages, 2 figures, 10 references. arXiv admin note: text overlap with <a href="/abs/2402.06281">arXiv:2402.06281</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2017 14th IEEE Annual Consumer Communications &amp; Networking
  Conference (CCNC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Sensor network virtualization enables the possibility of sharing common
physical resources to multiple stakeholder applications. This paper focuses on
addressing the dynamic adaptation of already assigned virtual sensor network
resources to respond to time varying application demands. We propose an
optimization framework that dynamically allocate applications into sensor nodes
while accounting for the characteristics and limitations of the wireless sensor
environment. It takes also into account the additional energy consumption
related to activating new nodes and/or moving already active applications.
Different objective functions related to the available energy in the nodes are
analyzed. The proposed framework is evaluated by simulation considering
realistic parameters from actual sensor nodes and deployed applications to
assess the efficiency of the proposals.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08446" title="Abstract">arXiv:2402.08446</a> [<a href="/pdf/2402.08446" title="Download PDF">pdf</a>, <a href="/format/2402.08446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inevitability of Polarization in Geometric Opinion Exchange
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alidou%2C+A+M">Abdou Majeed Alidou</a>, 
<a href="/search/cs?searchtype=author&query=Balig%C3%A1cs%2C+J">J&#xfa;lia Balig&#xe1;cs</a>, 
<a href="/search/cs?searchtype=author&query=Hahn-Klimroth%2C+M">Max Hahn-Klimroth</a>, 
<a href="/search/cs?searchtype=author&query=H%C4%85z%C5%82a%2C+J">Jan H&#x105;z&#x142;a</a>, 
<a href="/search/cs?searchtype=author&query=Hintze%2C+L">Lukas Hintze</a>, 
<a href="/search/cs?searchtype=author&query=Scheftelowitsch%2C+O">Olga Scheftelowitsch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Theoretical Economics (econ.TH)

</div>
<p class="mathjax">Polarization and unexpected correlations between opinions on diverse topics
(including in politics, culture and consumer choices) are an object of
sustained attention. However, numerous theoretical models do not seem to
convincingly explain these phenomena.
<br />This paper is motivated by a recent line of work, studying models where
polarization can be explained in terms of biased assimilation and geometric
interplay between opinions on various topics. The agent opinions are
represented as unit vectors on a multidimensional sphere and updated according
to geometric rules. In contrast to previous work, we focus on the classical
opinion exchange setting, where the agents update their opinions in discrete
time steps, with a pair of agents interacting randomly at every step. The
opinions are updated according to an update rule belonging to a general class.
<br />Our findings are twofold. First, polarization appears to be ubiquitous in the
class of models we study, requiring only relatively modest assumptions
reflecting biased assimilation. Second, there is a qualitative difference
between two-dimensional dynamics on the one hand, and three or more dimensions
on the other. Accordingly, we prove almost sure polarization for a large class
of update rules in two dimensions. Then, we prove polarization in three and
more dimensions in more limited cases and try to shed light on central
difficulties that are absent in two dimensions.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08450" title="Abstract">arXiv:2402.08450</a> [<a href="/pdf/2402.08450" title="Download PDF">pdf</a>, <a href="/format/2402.08450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subgraphormer: Unifying Subgraph GNNs and Graph Transformers via Graph  Products
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bar-Shalom%2C+G">Guy Bar-Shalom</a>, 
<a href="/search/cs?searchtype=author&query=Bevilacqua%2C+B">Beatrice Bevilacqua</a>, 
<a href="/search/cs?searchtype=author&query=Maron%2C+H">Haggai Maron</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In the realm of Graph Neural Networks (GNNs), two exciting research
directions have recently emerged: Subgraph GNNs and Graph Transformers. In this
paper, we propose an architecture that integrates both approaches, dubbed
Subgraphormer, which combines the enhanced expressive power, message-passing
mechanisms, and aggregation schemes from Subgraph GNNs with attention and
positional encodings, arguably the most important components in Graph
Transformers. Our method is based on an intriguing new connection we reveal
between Subgraph GNNs and product graphs, suggesting that Subgraph GNNs can be
formulated as Message Passing Neural Networks (MPNNs) operating on a product of
the graph with itself. We use this formulation to design our architecture:
first, we devise an attention mechanism based on the connectivity of the
product graph. Following this, we propose a novel and efficient positional
encoding scheme for Subgraph GNNs, which we derive as a positional encoding for
the product graph. Our experimental results demonstrate significant performance
improvements over both Subgraph GNNs and Graph Transformers on a wide range of
datasets.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08451" title="Abstract">arXiv:2402.08451</a> [<a href="/pdf/2402.08451" title="Download PDF">pdf</a>, <a href="/format/2402.08451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Moonwalk: Advancing Gait-Based User Recognition on Wearable Devices with  Metric Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liberman%2C+A">Asaf Liberman</a>, 
<a href="/search/cs?searchtype=author&query=Levy%2C+O">Oron Levy</a>, 
<a href="/search/cs?searchtype=author&query=Shahi%2C+S">Soroush Shahi</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+C+T">Cori Tymoszek Park</a>, 
<a href="/search/cs?searchtype=author&query=Ralph%2C+M">Mike Ralph</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+R">Richard Kang</a>, 
<a href="/search/cs?searchtype=author&query=Bedri%2C+A">Abdelkareem Bedri</a>, 
<a href="/search/cs?searchtype=author&query=Laput%2C+G">Gierad Laput</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Personal devices have adopted diverse authentication methods, including
biometric recognition and passcodes. In contrast, headphones have limited input
mechanisms, depending solely on the authentication of connected devices. We
present Moonwalk, a novel method for passive user recognition utilizing the
built-in headphone accelerometer. Our approach centers on gait recognition;
enabling users to establish their identity simply by walking for a brief
interval, despite the sensor's placement away from the feet. We employ
self-supervised metric learning to train a model that yields a highly
discriminative representation of a user's 3D acceleration, with no retraining
required. We tested our method in a study involving 50 participants, achieving
an average F1 score of 92.9% and equal error rate of 2.3%. We extend our
evaluation by assessing performance under various conditions (e.g. shoe types
and surfaces). We discuss the opportunities and challenges these variations
introduce and propose new directions for advancing passive authentication for
wearable devices.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08462" title="Abstract">arXiv:2402.08462</a> [<a href="/pdf/2402.08462" title="Download PDF">pdf</a>, <a href="/format/2402.08462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Indicators for characterising online hate speech and its automatic  detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Forzinetti%2C+E">Erica Forzinetti</a>, 
<a href="/search/cs?searchtype=author&query=Della+Vedova%2C+M+L">Marco L. Della Vedova</a>, 
<a href="/search/cs?searchtype=author&query=Pasta%2C+S">Stefano Pasta</a>, 
<a href="/search/cs?searchtype=author&query=Santerini%2C+M">Milena Santerini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">We examined four case studies in the context of hate speech on Twitter in
Italian from 2019 to 2020, aiming at comparing the classification of the 3,600
tweets made by expert pedagogists with the automatic classification made by
machine learning algorithms. Pedagogists used a novel classification scheme
based on seven indicators that characterize hate. These indicators are: the
content is public, it affects a target group, it contains hate speech in
explicit verbal form, it will not redeem, it has intention to harm, it can have
a possible violent response, it incites hatred and violence. The case studies
refer to Jews, Muslims, Roma, and immigrants target groups. We find that not
all the types of hateful content are equally detectable by the machine learning
algorithms that we considered. In particular, algorithms perform better in
identifying tweets that incite hatred and violence, and those that can have
possible violent response.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08466" title="Abstract">arXiv:2402.08466</a> [<a href="/pdf/2402.08466" title="Download PDF">pdf</a>, <a href="/format/2402.08466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taking Training Seriously: Human Guidance and Management-Based  Regulation of Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coglianese%2C+C">Cary Coglianese</a>, 
<a href="/search/cs?searchtype=author&query=Crum%2C+C+R">Colton R. Crum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Fervent calls for more robust governance of the harms associated with
artificial intelligence (AI) are leading to the adoption around the world of
what regulatory scholars have called a management-based approach to regulation.
Recent initiatives in the United States and Europe, as well as the adoption of
major self-regulatory standards by the International Organization for
Standardization, share in common a core management-based paradigm. These
management-based initiatives seek to motivate an increase in human oversight of
how AI tools are trained and developed. Refinements and systematization of
human-guided training techniques will thus be needed to fit within this
emerging era of management-based regulatory paradigm. If taken seriously,
human-guided training can alleviate some of the technical and ethical pressures
on AI, boosting AI performance with human intuition as well as better
addressing the needs for fairness and effective explainability. In this paper,
we discuss the connection between the emerging management-based regulatory
frameworks governing AI and the need for human oversight during training. We
broadly cover some of the technical components involved in human-guided
training and then argue that the kinds of high-stakes use cases for AI that
appear of most concern to regulators should lean more on human-guided training
than on data-only training. We hope to foster a discussion between legal
scholars and computer scientists involving how to govern a domain of technology
that is vast, heterogenous, and dynamic in its applications and risks.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08467" title="Abstract">arXiv:2402.08467</a> [<a href="/pdf/2402.08467" title="Download PDF">pdf</a>, <a href="/format/2402.08467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lying Blindly: Bypassing ChatGPT&#x27;s Safeguards to Generate Hard-to-Detect  Disinformation Claims at Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heppell%2C+F">Freddy Heppell</a>, 
<a href="/search/cs?searchtype=author&query=Bakir%2C+M+E">Mehmet E. Bakir</a>, 
<a href="/search/cs?searchtype=author&query=Bontcheva%2C+K">Kalina Bontcheva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">As Large Language Models (LLMs) become more proficient, their misuse in
large-scale viral disinformation campaigns is a growing concern. This study
explores the capability of ChatGPT to generate unconditioned claims about the
war in Ukraine, an event beyond its knowledge cutoff, and evaluates whether
such claims can be differentiated by human readers and automated tools from
human-written ones. We compare war-related claims from ClaimReview, authored by
IFCN-registered fact-checkers, and similar short-form content generated by
ChatGPT. We demonstrate that ChatGPT can produce realistic, target-specific
disinformation cheaply, fast, and at scale, and that these claims cannot be
reliably distinguished by humans or existing automated tools.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08468" title="Abstract">arXiv:2402.08468</a> [<a href="/pdf/2402.08468" title="Download PDF">pdf</a>, <a href="/ps/2402.08468" title="Download PostScript">ps</a>, <a href="/format/2402.08468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ROSpace: Intrusion Detection Dataset for a ROS2-Based Cyber-Physical  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Puccetti%2C+T">Tommaso Puccetti</a>, 
<a href="/search/cs?searchtype=author&query=Nardi%2C+S">Simone Nardi</a>, 
<a href="/search/cs?searchtype=author&query=Cinquilli%2C+C">Cosimo Cinquilli</a>, 
<a href="/search/cs?searchtype=author&query=Zoppi%2C+T">Tommaso Zoppi</a>, 
<a href="/search/cs?searchtype=author&query=Ceccarelli%2C+A">Andrea Ceccarelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Most of the intrusion detection datasets to research machine learning-based
intrusion detection systems (IDSs) are devoted to cyber-only systems, and they
typically collect data from one architectural layer. Additionally, often the
attacks are generated in dedicated attack sessions, without reproducing the
realistic alternation and overlap of normal and attack actions. We present a
dataset for intrusion detection by performing penetration testing on an
embedded cyber-physical system built over Robot Operating System 2 (ROS2).
Features are monitored from three architectural layers: the Linux operating
system, the network, and the ROS2 services. The dataset is structured as a time
series and describes the expected behavior of the system and its response to
ROS2-specific attacks: it repeatedly alternates periods of attack-free
operation with periods when a specific attack is being performed. Noteworthy,
this allows measuring the time to detect an attacker and the number of
malicious activities performed before detection. Also, it allows training an
intrusion detector to minimize both, by taking advantage of the numerous
alternating periods of normal and attack operations.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08470" title="Abstract">arXiv:2402.08470</a> [<a href="/pdf/2402.08470" title="Download PDF">pdf</a>, <a href="/format/2402.08470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel-friendly Spatio-Temporal Graph Learning for Photovoltaic  Degradation Analysis at Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yangxin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wieser%2C+R">Raymond Wieser</a>, 
<a href="/search/cs?searchtype=author&query=Bruckman%2C+L">Laura Bruckman</a>, 
<a href="/search/cs?searchtype=author&query=French%2C+R">Roger French</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yinghui Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">We propose a novel Spatio-Temporal Graph Neural Network empowered trend
analysis approach (ST-GTrend) to perform fleet-level performance degradation
analysis for Photovoltaic (PV) power networks. PV power stations have become an
integral component to the global sustainable energy production landscape.
Accurately estimating the performance of PV systems is critical to their
feasibility as a power generation technology and as a financial asset. One of
the most challenging problems in assessing the Levelized Cost of Energy (LCOE)
of a PV system is to understand and estimate the long-term Performance Loss
Rate (PLR) for large fleets of PV inverters. ST-GTrend integrates
spatio-temporal coherence and graph attention to separate PLR as a long-term
"aging" trend from multiple fluctuation terms in the PV input data. To cope
with diverse degradation patterns in timeseries, ST-GTrend adopts a paralleled
graph autoencoder array to extract aging and fluctuation terms simultaneously.
ST-GTrend imposes flatness and smoothness regularization to ensure the
disentanglement between aging and fluctuation. To scale the analysis to large
PV systems, we also introduce Para-GTrend, a parallel algorithm to accelerate
the training and inference of ST-GTrend. We have evaluated ST-GTrend on three
large-scale PV datasets, spanning a time period of 10 years. Our results show
that ST-GTrend reduces Mean Absolute Percent Error (MAPE) and Euclidean
Distances by 34.74% and 33.66% compared to the SOTA methods. Our results
demonstrate that Para-GTrend can speed up ST-GTrend by up to 7.92 times. We
further verify the generality and effectiveness of ST-GTrend for trend analysis
using financial and economic datasets.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08472" title="Abstract">arXiv:2402.08472</a> [<a href="/pdf/2402.08472" title="Download PDF">pdf</a>, <a href="/format/2402.08472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for the Automated Analysis of Optimization  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sartori%2C+C+C">Camilo Chac&#xf3;n Sartori</a>, 
<a href="/search/cs?searchtype=author&query=Blum%2C+C">Christian Blum</a>, 
<a href="/search/cs?searchtype=author&query=Ochoa%2C+G">Gabriela Ochoa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the GECCO 2024 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The ability of Large Language Models (LLMs) to generate high-quality text and
code has fuelled their rise in popularity. In this paper, we aim to demonstrate
the potential of LLMs within the realm of optimization algorithms by
integrating them into STNWeb. This is a web-based tool for the generation of
Search Trajectory Networks (STNs), which are visualizations of optimization
algorithm behavior. Although visualizations produced by STNWeb can be very
informative for algorithm designers, they often require a certain level of
prior knowledge to be interpreted. In an attempt to bridge this knowledge gap,
we have incorporated LLMs, specifically GPT-4, into STNWeb to produce extensive
written reports, complemented by automatically generated plots, thereby
enhancing the user experience and reducing the barriers to the adoption of this
tool by the research community. Moreover, our approach can be expanded to other
tools from the optimization community, showcasing the versatility and potential
of LLMs in this field.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08473" title="Abstract">arXiv:2402.08473</a> [<a href="/pdf/2402.08473" title="Download PDF">pdf</a>, <a href="/format/2402.08473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intriguing Differences Between Zero-Shot and Systematic Evaluations of  Vision-Language Transformer Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salman%2C+S">Shaeke Salman</a>, 
<a href="/search/cs?searchtype=author&query=Shams%2C+M+M+B">Md Montasir Bin Shams</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiuwen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lingjiong Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 30 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Transformer-based models have dominated natural language processing and other
areas in the last few years due to their superior (zero-shot) performance on
benchmark datasets. However, these models are poorly understood due to their
complexity and size. While probing-based methods are widely used to understand
specific properties, the structures of the representation space are not
systematically characterized; consequently, it is unclear how such models
generalize and overgeneralize to new inputs beyond datasets. In this paper,
based on a new gradient descent optimization method, we are able to explore the
embedding space of a commonly used vision-language model. Using the Imagenette
dataset, we show that while the model achieves over 99\% zero-shot
classification performance, it fails systematic evaluations completely. Using a
linear approximation, we provide a framework to explain the striking
differences. We have also obtained similar results using a different model to
support that our results are applicable to other transformer models with
continuous inputs. We also propose a robust way to detect the modified images.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08478" title="Abstract">arXiv:2402.08478</a> [<a href="/pdf/2402.08478" title="Download PDF">pdf</a>, <a href="/ps/2402.08478" title="Download PostScript">ps</a>, <a href="/format/2402.08478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A precise bare simulation approach to the minimization of some  distances. II. Further Foundations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Broniatowski%2C+M">Michel Broniatowski</a>, 
<a href="/search/cs?searchtype=author&query=Stummer%2C+W">Wolfgang Stummer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The constrained minimization (respectively maximization) of directed
distances and of related generalized entropies is a fundamental task in
information theory as well as in the adjacent fields of statistics, machine
learning, artificial intelligence, signal processing and pattern recognition.
In our previous paper "A precise bare simulation approach to the minimization
of some distances. I. Foundations", we obtained such kind of constrained optima
by a new dimension-free precise bare (pure) simulation method, provided
basically that (i) the underlying directed distance is of f-divergence type,
and that (ii) this can be connected to a light-tailed probability distribution
in a certain manner. In the present paper, we extend this approach such that
constrained optimization problems of a very huge amount of directed distances
and generalized entropies -- and beyond -- can be tackled by a newly developed
dimension-free extended bare simulation method, for obtaining both optima as
well as optimizers. Almost no assumptions (like convexity) on the set of
constraints are needed, within our discrete setup of arbitrary dimension, and
our method is precise (i.e., converges in the limit). For instance, we cover
constrained optimizations of arbitrary f-divergences, Bregman distances, scaled
Bregman distances and weighted Euclidean distances. The potential for
wide-spread applicability is indicated, too; in particular, we deliver many
recent references for uses of the involved distances/divergences in various
different research fields (which may also serve as an interdisciplinary
interface).
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08479" title="Abstract">arXiv:2402.08479</a> [<a href="/pdf/2402.08479" title="Download PDF">pdf</a>, <a href="/format/2402.08479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Plausible Extractive Rationalization through Semi-Supervised Entailment  Signal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jie%2C+Y+W">Yeo Wei Jie</a>, 
<a href="/search/cs?searchtype=author&query=Satapathy%2C+R">Ranjan Satapathy</a>, 
<a href="/search/cs?searchtype=author&query=Cambria%2C+E">Erik Cambria</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The increasing use of complex and opaque black box models requires the
adoption of interpretable measures, one such option is extractive rationalizing
models, which serve as a more interpretable alternative. These models, also
known as Explain-Then-Predict models, employ an explainer model to extract
rationales and subsequently condition the predictor with the extracted
information. Their primary objective is to provide precise and faithful
explanations, represented by the extracted rationales. In this paper, we take a
semi-supervised approach to optimize for the plausibility of extracted
rationales. We adopt a pre-trained natural language inference (NLI) model and
further fine-tune it on a small set of supervised rationales ($10\%$). The NLI
predictor is leveraged as a source of supervisory signals to the explainer via
entailment alignment. We show that, by enforcing the alignment agreement
between the explanation and answer in a question-answering task, the
performance can be improved without access to ground truth labels. We evaluate
our approach on the ERASER dataset and show that our approach achieves
comparable results with supervised extractive models and outperforms
unsupervised approaches by $&gt; 100\%$.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08480" title="Abstract">arXiv:2402.08480</a> [<a href="/pdf/2402.08480" title="Download PDF">pdf</a>, <a href="/format/2402.08480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revealing Decurve Flows for Generalized Graph Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Liheng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Bronstein%2C+M+M">Michael M. Bronstein</a>, 
<a href="/search/cs?searchtype=author&query=Torr%2C+P+H+S">Philip H.S. Torr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Differential Geometry (math.DG)

</div>
<p class="mathjax">This study addresses the limitations of the traditional analysis of
message-passing, central to graph learning, by defining {\em
\textbf{generalized propagation}} with directed and weighted graphs. The
significance manifest in two ways. \textbf{Firstly}, we propose {\em
Generalized Propagation Neural Networks} (\textbf{GPNNs}), a framework that
unifies most propagation-based graph neural networks. By generating
directed-weighted propagation graphs with adjacency function and connectivity
function, GPNNs offer enhanced insights into attention mechanisms across
various graph models. We delve into the trade-offs within the design space with
empirical experiments and emphasize the crucial role of the adjacency function
for model expressivity via theoretical analysis. \textbf{Secondly}, we propose
the {\em Continuous Unified Ricci Curvature} (\textbf{CURC}), an extension of
celebrated {\em Ollivier-Ricci Curvature} for directed and weighted graphs.
Theoretically, we demonstrate that CURC possesses continuity, scale invariance,
and a lower bound connection with the Dirichlet isoperimetric constant
validating bottleneck analysis for GPNNs. We include a preliminary exploration
of learned propagation patterns in datasets, a first in the field. We observe
an intriguing ``{\em \textbf{decurve flow}}'' - a curvature reduction during
training for models with learnable propagation, revealing the evolution of
propagation over time and a deeper connection to over-smoothing and bottleneck
trade-off.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08481" title="Abstract">arXiv:2402.08481</a> [<a href="/pdf/2402.08481" title="Download PDF">pdf</a>, <a href="/format/2402.08481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Migration to Microservices: A Comparative Study of Decomposition  Strategies and Analysis Metrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=chaieb%2C+M">Meryam chaieb</a>, 
<a href="/search/cs?searchtype=author&query=Saied%2C+M+A">Mohamed Aymen Saied</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IST journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The microservices architectural style is widely favored for its scalability,
reusability, and easy maintainability, prompting increased adoption by
developers. However, transitioning from a monolithic to a microservices-based
architecture is intricate and costly. In response, we present a novel method
utilizing clustering to identify potential microservices in a given monolithic
application. Our approach employs a density-based clustering algorithm
considering static analysis, structural, and semantic relationships between
classes, ensuring a functionally and contextually coherent partitioning. To
assess the reliability of our microservice suggestion approach, we conducted an
in-depth analysis of hyperparameter sensitivity and compared it with two
established clustering algorithms. A comprehensive comparative analysis
involved seven applications, evaluating against six baselines, utilizing a
dataset of four open-source Java projects. Metrics assessed the quality of
generated microservices. Furthermore, we meticulously compared our suggested
microservices with manually identified ones in three microservices-based
applications. This comparison provided a nuanced understanding of our
approach's efficacy and reliability. Our methodology demonstrated promising
outcomes, showcasing remarkable effectiveness and commendable stability.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08484" title="Abstract">arXiv:2402.08484</a> [<a href="/pdf/2402.08484" title="Download PDF">pdf</a>, <a href="/ps/2402.08484" title="Download PostScript">ps</a>, <a href="/format/2402.08484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Computational Complexity of the Housing Market
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lock%2C+E">Edwin Lock</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Z">Zephyr Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Teytelboym%2C+A">Alexander Teytelboym</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">We prove that the classic problem of finding a competitive equilibrium in an
exchange economy with indivisible goods, money, and unit-demand agents is
PPAD-complete. In this "housing market", agents have preferences over the house
and amount of money they end up with, but can experience income effects. Our
results contrast with the existence of polynomial-time algorithms for related
problems: Top Trading Cycles for the "housing exchange" problem in which there
are no transfers and the Hungarian algorithm for the "housing assignment"
problem in which agents' utilities are linear in money. Along the way, we prove
that the Rainbow-KKM problem, a total search problem based on a generalization
by Gale of the Knaster-Kuratowski-Mazurkiewicz lemma, is PPAD-complete. Our
reductions also imply bounds on the query complexity of finding competitive
equilibrium.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08491" title="Abstract">arXiv:2402.08491</a> [<a href="/pdf/2402.08491" title="Download PDF">pdf</a>, <a href="/format/2402.08491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning for Controlled Traversing of the Attractor  Landscape of Boolean Models in the Context of Cellular Reprogramming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mizera%2C+A">Andrzej Mizera</a>, 
<a href="/search/cs?searchtype=author&query=Zarzycki%2C+J">Jakub Zarzycki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Molecular Networks (q-bio.MN); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Cellular reprogramming can be used for both the prevention and cure of
different diseases. However, the efficiency of discovering reprogramming
strategies with classical wet-lab experiments is hindered by lengthy time
commitments and high costs. In this study, we develop a~novel computational
framework based on deep reinforcement learning that facilitates the
identification of reprogramming strategies. For this aim, we formulate
a~control problem in the context of cellular reprogramming for the frameworks
of BNs and PBNs under the asynchronous update mode. Furthermore, we introduce
the notion of a~pseudo-attractor and a~procedure for identification of
pseudo-attractor state during training. Finally, we devise a~computational
framework for solving the control problem, which we test on a~number of
different models.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08492" title="Abstract">arXiv:2402.08492</a> [<a href="/pdf/2402.08492" title="Download PDF">pdf</a>, <a href="/ps/2402.08492" title="Download PostScript">ps</a>, <a href="/format/2402.08492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Application of ChatGPT in Responding to Questions Related to the  Boston Bowel Preparation Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoqiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yubin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zicheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Boming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yilin Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+E">Enning Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+X">Xiaoxuan Lei</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yisen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaobo Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Background: Colonoscopy, a crucial diagnostic tool in gastroenterology,
depends heavily on superior bowel preparation. ChatGPT, a large language model
with emergent intelligence which also exhibits potential in medical
applications. This study aims to assess the accuracy and consistency of ChatGPT
in using the Boston Bowel Preparation Scale (BBPS) for colonoscopy assessment.
Methods: We retrospectively collected 233 colonoscopy images from 2020 to 2023.
These images were evaluated using the BBPS by 3 senior endoscopists and 3
novice endoscopists. Additionally, ChatGPT also assessed these images, having
been divided into three groups and undergone specific Fine-tuning. Consistency
was evaluated through two rounds of testing. Results: In the initial round,
ChatGPT's accuracy varied between 48.93% and 62.66%, trailing the endoscopists'
accuracy of 76.68% to 77.83%. Kappa values for ChatGPT was between 0.52 and
0.53, compared to 0.75 to 0.87 for the endoscopists. Conclusion: While ChatGPT
shows promise in bowel preparation scoring, it currently does not match the
accuracy and consistency of experienced endoscopists. Future research should
focus on in-depth Fine-tuning.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08493" title="Abstract">arXiv:2402.08493</a> [<a href="/pdf/2402.08493" title="Download PDF">pdf</a>, <a href="/format/2402.08493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparsity via Sparse Group $k$-max Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+Q">Qinghua Tao</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+X">Xiangming Xi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Suykens%2C+J+A+K">Johan A.K. Suykens</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, accepted to American Control Conference 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">For the linear inverse problem with sparsity constraints, the $l_0$
regularized problem is NP-hard, and existing approaches either utilize greedy
algorithms to find almost-optimal solutions or to approximate the $l_0$
regularization with its convex counterparts. In this paper, we propose a novel
and concise regularization, namely the sparse group $k$-max regularization,
which can not only simultaneously enhance the group-wise and in-group sparsity,
but also casts no additional restraints on the magnitude of variables in each
group, which is especially important for variables at different scales, so that
it approximate the $l_0$ norm more closely. We also establish an iterative soft
thresholding algorithm with local optimality conditions and complexity analysis
provided. Through numerical experiments on both synthetic and real-world
datasets, we verify the effectiveness and flexibility of the proposed method.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08494" title="Abstract">arXiv:2402.08494</a> [<a href="/pdf/2402.08494" title="Download PDF">pdf</a>, <a href="/format/2402.08494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep learning enhanced cost-aware multi-fidelity uncertainty  quantification of a computational model for radiotherapy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Vitullo%2C+P">Piermario Vitullo</a>, 
<a href="/search/math?searchtype=author&query=Franco%2C+N+R">Nicola Rares Franco</a>, 
<a href="/search/math?searchtype=author&query=Zunino%2C+P">Paolo Zunino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Forward uncertainty quantification (UQ) for partial differential equations is
a many-query task that requires a significant number of model evaluations. The
objective of this work is to mitigate the computational cost of UQ for a 3D-1D
multiscale computational model of microcirculation. To this purpose, we present
a deep learning enhanced multi-fidelity Monte Carlo (DL-MFMC) method that
integrates the information of a multiscale full-order model (FOM) with that
coming from a deep learning enhanced non-intrusive projection-based reduced
order model (ROM). The latter is constructed by leveraging on proper orthogonal
decomposition (POD) and mesh-informed neural networks (previously developed by
the authors and co-workers), integrating diverse architectures that approximate
POD coefficients while introducing fine-scale corrections for the
microstructures. The DL-MFMC approach provides a robust estimator of specific
quantities of interest and their associated uncertainties, with optimal
management of computational resources. In particular, the computational budget
is efficiently divided between training and sampling, ensuring a reliable
estimation process suitably exploiting the ROM speed-up. Here, we apply the
DL-MFMC technique to accelerate the estimation of biophysical quantities
regarding oxygen transfer and radiotherapy outcomes. Compared to classical
Monte Carlo methods, the proposed approach shows remarkable speed-ups and a
substantial reduction of the overall computational cost.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08496" title="Abstract">arXiv:2402.08496</a> [<a href="/pdf/2402.08496" title="Download PDF">pdf</a>, <a href="/format/2402.08496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Systematic Review of Data-to-Text NLG
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Osuji%2C+C+C">Chinonso Cynthia Osuji</a>, 
<a href="/search/cs?searchtype=author&query=Ferreira%2C+T+C">Thiago Castro Ferreira</a>, 
<a href="/search/cs?searchtype=author&query=Davis%2C+B">Brian Davis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This systematic review aims to provide a comprehensive analysis of the state
of data-to-text generation research, focusing on identifying research gaps,
offering future directions, and addressing challenges found during the review.
We thoroughly examined the literature, including approaches, datasets,
evaluation metrics, applications, multilingualism, and hallucination mitigation
measures. Our review provides a roadmap for future research in this rapidly
evolving field.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08498" title="Abstract">arXiv:2402.08498</a> [<a href="/pdf/2402.08498" title="Download PDF">pdf</a>, <a href="/ps/2402.08498" title="Download PostScript">ps</a>, <a href="/format/2402.08498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auditing Counterfire: Evaluating Advanced Counterargument Generation  with Evidence and Style
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verma%2C+P">Preetika Verma</a>, 
<a href="/search/cs?searchtype=author&query=Jaidka%2C+K">Kokil Jaidka</a>, 
<a href="/search/cs?searchtype=author&query=Churina%2C+S">Svetlana Churina</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 10 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present a novel dataset for the controlled composition of counterarguments
designed for further applications in argument refining, mining, and evaluation.
Our dataset constitutes enriched counter-arguments to posts in the Reddit
ChangeMyView dataset that are integrated with evidence retrieved from
high-quality sources and generated based on user preferences, adjusting the
critical attributes of evidence and argument style. The resultant Counterfire
corpus comprises arguments generated from GPT-3.5 turbo, Koala, and PaLM 2
models and two of their finetuned variants (N = 32,000). Model evaluation
indicates strong paraphrasing abilities with evidence, albeit limited word
overlap, while demonstrating high style integration (0.9682 for 'reciprocity'),
showing the ability of LLM to assimilate diverse styles. Of all models, GPT-3.5
turbo showed the highest scores in argument quality evaluation, showing
consistent accuracy (score &gt;0.8). In further analyses, reciprocity-style
counterarguments display higher counts in most categories, possibly indicating
a more creatively persuasive use of evidence. In contrast, human-written
counterarguments exhibited greater argumentative richness and diversity across
categories. Despite human-written arguments being favored as the most
persuasive in human evaluation, the 'No Style' generated text surprisingly
exhibited the highest score, prompting further exploration and investigation on
the trade-offs in generation for facts and style.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08502" title="Abstract">arXiv:2402.08502</a> [<a href="/pdf/2402.08502" title="Download PDF">pdf</a>, <a href="/format/2402.08502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provable Traffic Rule Compliance in Safe Reinforcement Learning on the  Open Sea
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krasowski%2C+H">Hanna Krasowski</a>, 
<a href="/search/cs?searchtype=author&query=Althoff%2C+M">Matthias Althoff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Autonomous vehicles have to obey traffic rules. These rules are often
formalized using temporal logic, resulting in constraints that are hard to
solve using optimization-based motion planners. Reinforcement Learning (RL) is
a promising method to find motion plans adhering to temporal logic
specifications. However, vanilla RL algorithms are based on random exploration,
which is inherently unsafe. To address this issue, we propose a provably safe
RL approach that always complies with traffic rules. As a specific application
area, we consider vessels on the open sea, which must adhere to the Convention
on the International Regulations for Preventing Collisions at Sea (COLREGS). We
introduce an efficient verification approach that determines the compliance of
actions with respect to the COLREGS formalized using temporal logic. Our action
verification is integrated into the RL process so that the agent only selects
verified actions. In contrast to agents that only integrate the traffic rule
information in the reward function, our provably safe agent always complies
with the formalized rules in critical maritime traffic situations and, thus,
never causes a collision.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08506" title="Abstract">arXiv:2402.08506</a> [<a href="/pdf/2402.08506" title="Download PDF">pdf</a>, <a href="/format/2402.08506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> P-Mamba: Marrying Perona Malik Diffusion with Mamba for Efficient  Pediatric Echocardiographic Left Ventricular Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zi Ye</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianxiang Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In pediatric cardiology, the accurate and immediate assessment of cardiac
function through echocardiography is important since it can determine whether
urgent intervention is required in many emergencies. However, echocardiography
is characterized by ambiguity and heavy background noise interference, bringing
more difficulty to accurate segmentation. Present methods lack efficiency and
are also prone to mistakenly segmenting some background noise areas as the left
ventricular area due to noise disturbance. To relieve the two issues, we
introduce P-Mamba for efficient pediatric echocardiographic left ventricular
segmentation. Specifically, we turn to the recently proposed vision mamba
layers in our vision mamba encoder branch to improve the computing and memory
efficiency of our model while modeling global dependencies. In the other
DWT-based PMD encoder branch, we devise DWT-based Perona-Malik Diffusion (PMD)
Blocks that utilize PMD for noise suppression, while simultaneously preserving
the local shape cues of the left ventricle. Leveraging the strengths of both
the two encoder branches, P-Mamba achieves superior accuracy and efficiency to
established models, such as vision transformers with quadratic and linear
computational complexity. This innovative approach promises significant
advancements in pediatric cardiac imaging and beyond.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08509" title="Abstract">arXiv:2402.08509</a> [<a href="/pdf/2402.08509" title="Download PDF">pdf</a>, <a href="/format/2402.08509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Shapes to Shapes: Inferring SHACL Shapes for Results of SPARQL  CONSTRUCT Queries (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seifer%2C+P">Philipp Seifer</a>, 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez%2C+D">Daniel Hern&#xe1;ndez</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%A4mmel%2C+R">Ralf L&#xe4;mmel</a>, 
<a href="/search/cs?searchtype=author&query=Staab%2C+S">Steffen Staab</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">SPARQL CONSTRUCT queries allow for the specification of data processing
pipelines that transform given input graphs into new output graphs. It is now
common to constrain graphs through SHACL shapes allowing users to understand
which data they can expect and which not. However, it becomes challenging to
understand what graph data can be expected at the end of a data processing
pipeline without knowing the particular input data: Shape constraints on the
input graph may affect the output graph, but may no longer apply literally, and
new shapes may be imposed by the query template. In this paper, we study the
derivation of shape constraints that hold on all possible output graphs of a
given SPARQL CONSTRUCT query. We assume that the SPARQL CONSTRUCT query is
fixed, e.g., being part of a program, whereas the input graphs adhere to input
shape constraints but may otherwise vary over time and, thus, are mostly
unknown. We study a fragment of SPARQL CONSTRUCT queries (SCCQ) and a fragment
of SHACL (Simple SHACL). We formally define the problem of deriving the most
restrictive set of Simple SHACL shapes that constrain the results from
evaluating a SCCQ over any input graph restricted by a given set of Simple
SHACL shapes. We propose and implement an algorithm that statically analyses
input SHACL shapes and CONSTRUCT queries and prove its soundness and
complexity.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08511" title="Abstract">arXiv:2402.08511</a> [<a href="/pdf/2402.08511" title="Download PDF">pdf</a>, <a href="/format/2402.08511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Amplifying Exploration in Monte-Carlo Tree Search by Focusing on the  Unknown
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Derstroff%2C+C">Cedric Derstroff</a>, 
<a href="/search/cs?searchtype=author&query=Brugger%2C+J">Jannis Brugger</a>, 
<a href="/search/cs?searchtype=author&query=Bl%C3%BCml%2C+J">Jannis Bl&#xfc;ml</a>, 
<a href="/search/cs?searchtype=author&query=Mezini%2C+M">Mira Mezini</a>, 
<a href="/search/cs?searchtype=author&query=Kramer%2C+S">Stefan Kramer</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Monte-Carlo tree search (MCTS) is an effective anytime algorithm with a vast
amount of applications. It strategically allocates computational resources to
focus on promising segments of the search tree, making it a very attractive
search algorithm in large search spaces. However, it often expends its limited
resources on reevaluating previously explored regions when they remain the most
promising path. Our proposed methodology, denoted as AmEx-MCTS, solves this
problem by introducing a novel MCTS formulation. Central to AmEx-MCTS is the
decoupling of value updates, visit count updates, and the selected path during
the tree search, thereby enabling the exclusion of already explored subtrees or
leaves. This segregation preserves the utility of visit counts for both
exploration-exploitation balancing and quality metrics within MCTS. The
resultant augmentation facilitates in a considerably broader search using
identical computational resources, preserving the essential characteristics of
MCTS. The expanded coverage not only yields more precise estimations but also
proves instrumental in larger and more complex problems. Our empirical
evaluation demonstrates the superior performance of AmEx-MCTS, surpassing
classical MCTS and related approaches by a substantial margin.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08514" title="Abstract">arXiv:2402.08514</a> [<a href="/pdf/2402.08514" title="Download PDF">pdf</a>, <a href="/format/2402.08514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counterfactual Influence in Markov Decision Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kazemi%2C+M">Milad Kazemi</a>, 
<a href="/search/cs?searchtype=author&query=Lally%2C+J">Jessica Lally</a>, 
<a href="/search/cs?searchtype=author&query=Tishchenko%2C+E">Ekaterina Tishchenko</a>, 
<a href="/search/cs?searchtype=author&query=Chockler%2C+H">Hana Chockler</a>, 
<a href="/search/cs?searchtype=author&query=Paoletti%2C+N">Nicola Paoletti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Our work addresses a fundamental problem in the context of counterfactual
inference for Markov Decision Processes (MDPs). Given an MDP path $\tau$, this
kind of inference allows us to derive counterfactual paths $\tau'$ describing
what-if versions of $\tau$ obtained under different action sequences than those
observed in $\tau$. However, as the counterfactual states and actions deviate
from the observed ones over time, the observation $\tau$ may no longer
influence the counterfactual world, meaning that the analysis is no longer
tailored to the individual observation, resulting in interventional outcomes
rather than counterfactual ones. Even though this issue specifically affects
the popular Gumbel-max structural causal model used for MDP counterfactuals, it
has remained overlooked until now. In this work, we introduce a formal
characterisation of influence based on comparing counterfactual and
interventional distributions. We devise an algorithm to construct
counterfactual models that automatically satisfy influence constraints.
Leveraging such models, we derive counterfactual policies that are not just
optimal for a given reward structure but also remain tailored to the observed
path. Even though there is an unavoidable trade-off between policy optimality
and strength of influence constraints, our experiments demonstrate that it is
possible to derive (near-)optimal policies while remaining under the influence
of the observation.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08515" title="Abstract">arXiv:2402.08515</a> [<a href="/pdf/2402.08515" title="Download PDF">pdf</a>, <a href="/format/2402.08515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Krylov Eigenvalue Solver Based on Filtered Time Domain Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Nannen%2C+L">Lothar Nannen</a>, 
<a href="/search/math?searchtype=author&query=Wess%2C+M">Markus Wess</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper introduces a method for computing eigenvalues and eigenvectors of
a generalized Hermitian, matrix eigenvalue problem. The work is focused on
large scale eigenvalue problems, where the application of a direct inverse is
out of reach. Instead, an explicit time-domain integrator for the corresponding
wave problem is combined with a proper filtering and a Krylov iteration in
order to solve for eigenvalues within a given region of interest. We report
results of small scale model problems to confirm the reliability of the method,
as well as the computation of acoustic resonances in a three dimensional model
of a hunting horn to demonstrate the efficiency.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08522" title="Abstract">arXiv:2402.08522</a> [<a href="/pdf/2402.08522" title="Download PDF">pdf</a>, <a href="/format/2402.08522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fairness Auditing with Multi-Agent Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Vos%2C+M">Martijn de Vos</a>, 
<a href="/search/cs?searchtype=author&query=Dhasade%2C+A">Akash Dhasade</a>, 
<a href="/search/cs?searchtype=author&query=Bourr%C3%A9e%2C+J+G">Jade Garcia Bourr&#xe9;e</a>, 
<a href="/search/cs?searchtype=author&query=Kermarrec%2C+A">Anne-Marie Kermarrec</a>, 
<a href="/search/cs?searchtype=author&query=Merrer%2C+E+L">Erwan Le Merrer</a>, 
<a href="/search/cs?searchtype=author&query=Rottembourg%2C+B">Benoit Rottembourg</a>, 
<a href="/search/cs?searchtype=author&query=Tredan%2C+G">Gilles Tredan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Existing work in fairness audits assumes that agents operate independently.
In this paper, we consider the case of multiple agents auditing the same
platform for different tasks. Agents have two levers: their collaboration
strategy, with or without coordination beforehand, and their sampling method.
We theoretically study their interplay when agents operate independently or
collaborate. We prove that, surprisingly, coordination can sometimes be
detrimental to audit accuracy, whereas uncoordinated collaboration generally
yields good results. Experimentation on real-world datasets confirms this
observation, as the audit accuracy of uncoordinated collaboration matches that
of collaborative optimal sampling.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08524" title="Abstract">arXiv:2402.08524</a> [<a href="/pdf/2402.08524" title="Download PDF">pdf</a>, <a href="/ps/2402.08524" title="Download PostScript">ps</a>, <a href="/format/2402.08524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new framework for calibrating COVID-19 SEIR models with  spatial-/time-varying coefficients using genetic and sliding window  algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Huan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+R">Ralf Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Kl%C3%BCsener%2C+S">Sebastian Kl&#xfc;sener</a>, 
<a href="/search/cs?searchtype=author&query=Backhaus%2C+A">Andreas Backhaus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Software Engineering (cs.SE); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">A susceptible-exposed-infected-removed (SEIR) model assumes
spatial-/time-varying coefficients to model the effect of non-pharmaceutical
interventions (NPIs) on the regional and temporal distribution of COVID-19
disease epidemics. A significant challenge in using such model is their fast
and accurate calibration to observed data from geo-referenced hospitalized
data, i.e., efficient estimation of the spatial-/time-varying parameters. In
this work, a new calibration framework is proposed towards optimizing the
spatial-/time-varying parameters of the SEIR model. We also devise a method for
combing the overlapping sliding window technique (OSW) with a genetic algorithm
(GA) calibration routine to automatically search the segmented parameter space.
Parallelized GA is used to reduce the computational burden. Our framework
abstracts the implementation complexity of the method away from the user. It
provides high-level APIs for setting up a customized calibration system and
consuming the optimized values of parameters. We evaluated the application of
our method on the calibration of a spatial age-structured microsimulation model
using a single objective function that comprises observed COVID-19-related ICU
demand. The results reflect the effectiveness of the proposed method towards
estimating the parameters in a changing environment.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08526" title="Abstract">arXiv:2402.08526</a> [<a href="/pdf/2402.08526" title="Download PDF">pdf</a>, <a href="/format/2402.08526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concept-1K: A Novel Benchmark for Instance Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Junhao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+S">Shengjie Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qianli Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Incremental learning (IL) is essential to realize the human-level
intelligence in the neural network. However, existing IL scenarios and datasets
are unqualified for assessing forgetting in PLMs, giving an illusion that PLMs
do not suffer from catastrophic forgetting. To this end, we propose a
challenging IL scenario called instance-incremental learning (IIL) and a novel
dataset called Concept-1K, which supports an order of magnitude larger IL
steps. Based on the experiments on Concept-1K, we reveal that billion-parameter
PLMs still suffer from catastrophic forgetting, and the forgetting is affected
by both model scale, pretraining, and buffer size. Furthermore, existing IL
methods and a popular finetuning technique, LoRA, fail to achieve satisfactory
performance. Our study provides a novel scenario for future studies to explore
the catastrophic forgetting of PLMs and encourage more powerful techniques to
be designed for alleviating the forgetting in PLMs. The data, code and scripts
are publicly available at
https://github.com/zzz47zzz/pretrained-lm-for-incremental-learning.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08529" title="Abstract">arXiv:2402.08529</a> [<a href="/pdf/2402.08529" title="Download PDF">pdf</a>, <a href="/format/2402.08529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximately Piecewise E(3) Equivariant Point Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atzmon%2C+M">Matan Atzmon</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiahui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+F">Francis Williams</a>, 
<a href="/search/cs?searchtype=author&query=Litany%2C+O">Or Litany</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Integrating a notion of symmetry into point cloud neural networks is a
provably effective way to improve their generalization capability. Of
particular interest are $E(3)$ equivariant point cloud networks where Euclidean
transformations applied to the inputs are preserved in the outputs. Recent
efforts aim to extend networks that are $E(3)$ equivariant, to accommodate
inputs made of multiple parts, each of which exhibits local $E(3)$ symmetry. In
practical settings, however, the partitioning into individually transforming
regions is unknown a priori. Errors in the partition prediction would
unavoidably map to errors in respecting the true input symmetry. Past works
have proposed different ways to predict the partition, which may exhibit
uncontrolled errors in their ability to maintain equivariance to the actual
partition. To this end, we introduce APEN: a general framework for constructing
approximate piecewise-$E(3)$ equivariant point networks. Our primary insight is
that functions that are equivariant with respect to a finer partition will also
maintain equivariance in relation to the true partition. Leveraging this
observation, we propose a design where the equivariance approximation error at
each layers can be bounded solely in terms of (i) uncertainty quantification of
the partition prediction, and (ii) bounds on the probability of failing to
suggest a proper subpartition of the ground truth one. We demonstrate the
effectiveness of APEN using two data types exemplifying part-based symmetry:
(i) real-world scans of room scenes containing multiple furniture-type objects;
and, (ii) human motions, characterized by articulated parts exhibiting rigid
movement. Our empirical results demonstrate the advantage of integrating
piecewise $E(3)$ symmetry into network design, showing a distinct improvement
in generalization compared to prior works for both classification and
segmentation tasks.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08530" title="Abstract">arXiv:2402.08530</a> [<a href="/pdf/2402.08530" title="Download PDF">pdf</a>, <a href="/format/2402.08530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Distributional Analogue to the Successor Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wiltzer%2C+H">Harley Wiltzer</a>, 
<a href="/search/cs?searchtype=author&query=Farebrother%2C+J">Jesse Farebrother</a>, 
<a href="/search/cs?searchtype=author&query=Gretton%2C+A">Arthur Gretton</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yunhao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Barreto%2C+A">Andr&#xe9; Barreto</a>, 
<a href="/search/cs?searchtype=author&query=Dabney%2C+W">Will Dabney</a>, 
<a href="/search/cs?searchtype=author&query=Bellemare%2C+M+G">Marc G. Bellemare</a>, 
<a href="/search/cs?searchtype=author&query=Rowland%2C+M">Mark Rowland</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper contributes a new approach for distributional reinforcement
learning which elucidates a clean separation of transition structure and reward
in the learning process. Analogous to how the successor representation (SR)
describes the expected consequences of behaving according to a given policy,
our distributional successor measure (SM) describes the distributional
consequences of this behaviour. We formulate the distributional SM as a
distribution over distributions and provide theory connecting it with
distributional and model-based reinforcement learning. Moreover, we propose an
algorithm that learns the distributional SM from data by minimizing a two-level
maximum mean discrepancy. Key to our method are a number of algorithmic
techniques that are independently valuable for learning generative models of
state. As an illustration of the usefulness of the distributional SM, we show
that it enables zero-shot risk-sensitive policy evaluation in a way that was
not previously possible.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08532" title="Abstract">arXiv:2402.08532</a> [<a href="/pdf/2402.08532" title="Download PDF">pdf</a>, <a href="/ps/2402.08532" title="Download PostScript">ps</a>, <a href="/format/2402.08532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Captions Are Worth a Thousand Words: Enhancing Product Retrieval with  Pretrained Image-to-Text Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jason Tang</a>, 
<a href="/search/cs?searchtype=author&query=McGoldrick%2C+G">Garrin McGoldrick</a>, 
<a href="/search/cs?searchtype=author&query=Al-Ghossein%2C+M">Marie Al-Ghossein</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Ching-Wei Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 3rd International Workshop on Interactive and Scalable Information Retrieval Methods for E-Commerce (ISIR-eCom 2024) Held in conjunction with ACM WSDM - March 8th, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">This paper explores the usage of multimodal image-to-text models to enhance
text-based item retrieval. We propose utilizing pre-trained image captioning
and tagging models, such as instructBLIP and CLIP, to generate text-based
product descriptions which are combined with existing text descriptions. Our
work is particularly impactful for smaller eCommerce businesses who are unable
to maintain the high-quality text descriptions necessary to effectively perform
item retrieval for search and recommendation use cases. We evaluate the
searchability of ground-truth text, image-generated text, and combinations of
both texts on several subsets of Amazon's publicly available ESCI dataset. The
results demonstrate the dual capability of our proposed models to enhance the
retrieval of existing text and generate highly-searchable standalone
descriptions.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08533" title="Abstract">arXiv:2402.08533</a> [<a href="/pdf/2402.08533" title="Download PDF">pdf</a>, <a href="/format/2402.08533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grace Period is All You Need: Individual Fairness without Revenue Loss  in Revenue Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jaillet%2C+P">Patrick Jaillet</a>, 
<a href="/search/cs?searchtype=author&query=Podimata%2C+C">Chara Podimata</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zijie Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Imagine you and a friend purchase identical items at a store, yet only your
friend received a discount. Would your friend's discount make you feel unfairly
treated by the store? And would you be less willing to purchase from that store
again in the future? Based on a large-scale online survey that we ran on
Prolific, it turns out that the answers to the above questions are positive.
Motivated by these findings, in this work we propose a notion of individual
fairness in online revenue management and an algorithmic module (called ``Grace
Period'') that can be embedded in traditional revenue management algorithms and
guarantee individual fairness. Specifically, we show how to embed the Grace
Period in five common revenue management algorithms including Deterministic
Linear Programming with Probabilistic Assignment, Resolving Deterministic
Linear Programming with Probabilistic Assignment, Static Bid Price Control,
Booking Limit, and Nesting, thus covering both stochastic and adversarial
customer arrival settings. Embedding the Grace Period does not incur additional
regret for any of these algorithms. This finding indicates that there is no
tradeoff between a seller maximizing their revenue and guaranteeing that each
customer feels fairly treated.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08539" title="Abstract">arXiv:2402.08539</a> [<a href="/pdf/2402.08539" title="Download PDF">pdf</a>, <a href="/ps/2402.08539" title="Download PostScript">ps</a>, <a href="/format/2402.08539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent Diagnosis of Alzheimer&#x27;s Disease Based on Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yixuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zejun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Honglin Dai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP)

</div>
<p class="mathjax">This study is based on the Alzheimer's Disease Neuroimaging Initiative (ADNI)
dataset and aims to explore early detection and disease progression in
Alzheimer's disease (AD). We employ innovative data preprocessing strategies,
including the use of the random forest algorithm to fill missing data and the
handling of outliers and invalid data, thereby fully mining and utilizing these
limited data resources. Through Spearman correlation coefficient analysis, we
identify some features strongly correlated with AD diagnosis. We build and test
three machine learning models using these features: random forest, XGBoost, and
support vector machine (SVM). Among them, the XGBoost model performs the best
in terms of diagnostic performance, achieving an accuracy of 91%. Overall, this
study successfully overcomes the challenge of missing data and provides
valuable insights into early detection of Alzheimer's disease, demonstrating
its unique research value and practical significance.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08540" title="Abstract">arXiv:2402.08540</a> [<a href="/pdf/2402.08540" title="Download PDF">pdf</a>, <a href="/format/2402.08540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative VS non-Generative Models in Engineering Shape Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Usama%2C+M">Muhammad Usama</a>, 
<a href="/search/cs?searchtype=author&query=Masood%2C+Z">Zahid Masood</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Shahroz Khan</a>, 
<a href="/search/cs?searchtype=author&query=Kostas%2C+K">Konstantinos Kostas</a>, 
<a href="/search/cs?searchtype=author&query=Kaklis%2C+P">Panagiotis Kaklis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this work, we perform a systematic comparison of the effectiveness and
efficiency of generative and non-generative models in constructing design
spaces for novel and efficient design exploration and shape optimization. We
apply these models in the case of airfoil/hydrofoil design and conduct the
comparison on the resulting design spaces. A conventional Generative
Adversarial Network (GAN) and a state-of-the-art generative model, the
Performance-Augmented Diverse Generative Adversarial Network (PaDGAN), are
juxtaposed with a linear non-generative model based on the coupling of the
Karhunen-Lo\`eve Expansion and a physics-informed Shape Signature Vector
(SSV-KLE). The comparison demonstrates that, with an appropriate shape encoding
and a physics-augmented design space, non-generative models have the potential
to cost-effectively generate high-performing valid designs with enhanced
coverage of the design space. In this work, both approaches are applied to two
large foil profile datasets comprising real-world and artificial designs
generated through either a profile-generating parametric model or deep-learning
approach. These datasets are further enriched with integral properties of their
members' shapes as well as physics-informed parameters. Our results illustrate
that the design spaces constructed by the non-generative model outperform the
generative model in terms of design validity, generating robust latent spaces
with none or significantly fewer invalid designs when compared to generative
models. We aspire that these findings will aid the engineering design community
in making informed decisions when constructing designs spaces for shape
optimization, as we have show that under certain conditions computationally
inexpensive approaches can closely match or even outperform state-of-the art
generative models.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08541" title="Abstract">arXiv:2402.08541</a> [<a href="/pdf/2402.08541" title="Download PDF">pdf</a>, <a href="/format/2402.08541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous-Time Best-Response and Related Dynamics in Tullock Contests  with Convex Costs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elkind%2C+E">Edith Elkind</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+A">Abheek Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Goldberg%2C+P+W">Paul W. Goldberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
<p class="mathjax">Tullock contests model real-life scenarios that range from competition among
proof-of-work blockchain miners to rent-seeking and lobbying activities. We
show that continuous-time best-response dynamics in Tullock contests with
convex costs converges to the unique equilibrium using Lyapunov-style
arguments. We then use this result to provide an algorithm for computing an
approximate equilibrium. We also establish convergence of related discrete-time
dynamics, e.g., when the agents best-respond to the empirical average action of
other agents. These results indicate that the equilibrium is a reliable
predictor of the agents' behavior in these games.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08545" title="Abstract">arXiv:2402.08545</a> [<a href="/pdf/2402.08545" title="Download PDF">pdf</a>, <a href="/ps/2402.08545" title="Download PostScript">ps</a>, <a href="/format/2402.08545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial-Time Algorithms for Weaver&#x27;s Discrepancy Problem in a Dense  Regime
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jourdan%2C+B">Ben Jourdan</a>, 
<a href="/search/cs?searchtype=author&query=Macgregor%2C+P">Peter Macgregor</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">He Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Given $v_1,\ldots, v_m\in\mathbb{C}^d$ with $\|v_i\|^2= \alpha$ for all
$i\in[m]$ as input and suppose $\sum_{i=1}^m | \langle u, v_i \rangle |^2 = 1$
for every unit vector $u\in\mathbb{C}^d$, Weaver's discrepancy problem asks for
a partition $S_1, S_2$ of $[m]$, such that $\sum_{i\in S_{j}} |\langle u, v_i
\rangle|^2 \leq 1 -\theta$ for some universal constant $\theta$, every unit
vector $u\in\mathbb{C}^d$ and every $j\in\{1,2\}$. We prove that this problem
can be solved deterministically in polynomial time when $m\geq 49 d^2$.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08546" title="Abstract">arXiv:2402.08546</a> [<a href="/pdf/2402.08546" title="Download PDF">pdf</a>, <a href="/format/2402.08546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grounding LLMs For Robot Task Planning Using Closed-loop State Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhat%2C+V">Vineet Bhat</a>, 
<a href="/search/cs?searchtype=author&query=Kaypak%2C+A+U">Ali Umut Kaypak</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+P">Prashanth Krishnamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Karri%2C+R">Ramesh Karri</a>, 
<a href="/search/cs?searchtype=author&query=Khorrami%2C+F">Farshad Khorrami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robotic planning algorithms direct agents to perform actions within diverse
environments to accomplish a task. Large Language Models (LLMs) like PaLM 2,
GPT-3.5, and GPT-4 have revolutionized this domain, using their embedded
real-world knowledge to tackle complex tasks involving multiple agents and
objects. This paper introduces an innovative planning algorithm that integrates
LLMs into the robotics context, enhancing task-focused execution and success
rates. Key to our algorithm is a closed-loop feedback which provides real-time
environmental states and error messages, crucial for refining plans when
discrepancies arise. The algorithm draws inspiration from the human neural
system, emulating its brain-body architecture by dividing planning across two
LLMs in a structured, hierarchical fashion. Our method not only surpasses
baselines within the VirtualHome Environment, registering a notable 35% average
increase in task-oriented success rates, but achieves an impressive execution
score of 85%, approaching the human-level benchmark of 94%. Moreover,
effectiveness of the algorithm in real robot scenarios is shown using a
realistic physics simulator and the Franka Research 3 Arm.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08547" title="Abstract">arXiv:2402.08547</a> [<a href="/pdf/2402.08547" title="Download PDF">pdf</a>, <a href="/format/2402.08547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dueling Over Dessert, Mastering the Art of Repeated Cake Cutting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Br%C3%A2nzei%2C+S">Simina Br&#xe2;nzei</a>, 
<a href="/search/cs?searchtype=author&query=Hajiaghayi%2C+M">MohammadTaghi Hajiaghayi</a>, 
<a href="/search/cs?searchtype=author&query=Phillips%2C+R">Reed Phillips</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+S">Suho Shin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Theoretical Economics (econ.TH)

</div>
<p class="mathjax">We consider the setting of repeated fair division between two players,
denoted Alice and Bob, with private valuations over a cake. In each round, a
new cake arrives, which is identical to the ones in previous rounds. Alice cuts
the cake at a point of her choice, while Bob chooses the left piece or the
right piece, leaving the remainder for Alice. We consider two versions:
sequential, where Bob observes Alice's cut point before choosing left/right,
and simultaneous, where he only observes her cut point after making his choice.
The simultaneous version was first considered by Aumann and Maschler (1995).
<br />We observe that if Bob is almost myopic and chooses his favorite piece too
often, then he can be systematically exploited by Alice through a strategy akin
to a binary search. This strategy allows Alice to approximate Bob's preferences
with increasing precision, thereby securing a disproportionate share of the
resource over time.
<br />We analyze the limits of how much a player can exploit the other one and show
that fair utility profiles are in fact achievable. Specifically, the players
can enforce the equitable utility profile of $(1/2, 1/2)$ in the limit on every
trajectory of play, by keeping the other player's utility to approximately
$1/2$ on average while guaranteeing they themselves get at least approximately
$1/2$ on average. We show this theorem using a connection with Blackwell
approachability.
<br />Finally, we analyze a natural dynamic known as fictitious play, where players
best respond to the empirical distribution of the other player. We show that
fictitious play converges to the equitable utility profile of $(1/2, 1/2)$ at a
rate of $O(1/\sqrt{T})$.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08549" title="Abstract">arXiv:2402.08549</a> [<a href="/pdf/2402.08549" title="Download PDF">pdf</a>, <a href="/format/2402.08549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Competitive Revenue Extraction from Time-Discounted Transactions in the  Semi-Myopic Regime
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gafni%2C+Y">Yotam Gafni</a>, 
<a href="/search/cs?searchtype=author&query=Yaish%2C+A">Aviv Yaish</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
<p class="mathjax">Decentralized cryptocurrencies are payment systems that rely on aligning the
incentives of users and miners to operate correctly and offer a high quality of
service to users. Recent literature studies the mechanism design problem of the
auction serving as a cryptocurrency's transaction fee mechanism (TFM). We find
that a non-myopic modelling of miners falls close to another well-known
problem: that of online buffer management for packet switching. The main
difference is that unlike packets which are of a fixed size throughout their
lifetime, in a financial environment, user preferences (and therefore revenue
extraction) may be time-dependent. We study the competitive ratio guarantees
given a certain discount rate, and show how existing methods from packet
scheduling, which we call "the undiscounted case", perform suboptimally in the
more general discounted setting. Most notably, we find a novel, simple,
memoryless, and optimal deterministic algorithm for the semi-myopic case, when
the discount factor is up to ~0.770018. We also present a randomized algorithm
that achieves better performance than the best possible deterministic
algorithm, for any discount rate.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08552" title="Abstract">arXiv:2402.08552</a> [<a href="/pdf/2402.08552" title="Download PDF">pdf</a>, <a href="/format/2402.08552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Confronting Reward Overoptimization for Diffusion Models: A Perspective  of Inductive and Primacy Biases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Y">Yibing Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yonggang Wen</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Bridging the gap between diffusion models and human preferences is crucial
for their integration into practical generative workflows. While optimizing
downstream reward models has emerged as a promising alignment strategy,
concerns arise regarding the risk of excessive optimization with learned reward
models, which potentially compromises ground-truth performance. In this work,
we confront the reward overoptimization problem in diffusion model alignment
through the lenses of both inductive and primacy biases. We first identify the
divergence of current methods from the temporal inductive bias inherent in the
multi-step denoising process of diffusion models as a potential source of
overoptimization. Then, we surprisingly discover that dormant neurons in our
critic model act as a regularization against overoptimization, while active
neurons reflect primacy bias in this setting. Motivated by these observations,
we propose Temporal Diffusion Policy Optimization with critic active neuron
Reset (TDPO-R), a policy gradient algorithm that exploits the temporal
inductive bias of intermediate timesteps, along with a novel reset strategy
that targets active neurons to counteract the primacy bias. Empirical results
demonstrate the superior efficacy of our algorithms in mitigating reward
overoptimization.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08558" title="Abstract">arXiv:2402.08558</a> [<a href="/pdf/2402.08558" title="Download PDF">pdf</a>, <a href="/ps/2402.08558" title="Download PostScript">ps</a>, <a href="/format/2402.08558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring diversity perceptions in a community through a Q&amp;A chatbot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kun%2C+P">Peter Kun</a>, 
<a href="/search/cs?searchtype=author&query=De+G%C3%B6tzen%2C+A">Amalia De G&#xf6;tzen</a>, 
<a href="/search/cs?searchtype=author&query=Bidoglia%2C+M">Miriam Bidoglia</a>, 
<a href="/search/cs?searchtype=author&query=Gommesen%2C+N+J">Niels J&#xf8;rgen Gommesen</a>, 
<a href="/search/cs?searchtype=author&query=Gaskell%2C+G">George Gaskell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Design Research Society conference 2022, Bilbao, 25 June - 3 July, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">While diversity has become a debated issue in design, very little research
exists on positive use-cases for diversity beyond scholarly criticism. The
current work addresses this gap through the case of a diversity-aware chatbot,
exploring what benefits a diversity-aware chatbot could bring to people and how
do people interpret diversity when being presented with it. In this paper, we
motivate a Q&amp;A chatbot as a technology probe and deploy it in two student
communities within a study. During the study, we collected contextual data on
people's expectations and perceptions when presented with diversity during the
study. Our key findings show that people seek out others with shared niche
interests, or their search is driven by exploration and inspiration when
presented with diversity. Although interacting with chatbots is limited,
participants found the engagement novel and interesting to motivate future
research.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08562" title="Abstract">arXiv:2402.08562</a> [<a href="/pdf/2402.08562" title="Download PDF">pdf</a>, <a href="/format/2402.08562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Higher Layers Need More LoRA Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chongyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kezhen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+J">Jinmeng Rao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Baochen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruibo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+D">Daiyi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yawen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiaoyuan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Subrahmanian%2C+V">VS Subrahmanian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code is available at <a href="https://github.com/GCYZSL/MoLA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Parameter-efficient tuning (PEFT) techniques like low-rank adaptation (LoRA)
offer training efficiency on Large Language Models, but their impact on model
performance remains limited. Recent efforts integrate LoRA and
Mixture-of-Experts (MoE) to improve the performance of PEFT methods. Despite
promising results, research on improving the efficiency of LoRA with MoE is
still in its early stages. Recent studies have shown that experts in the MoE
architecture have different strengths and also exhibit some redundancy. Does
this statement also apply to parameter-efficient MoE? In this paper, we
introduce a novel parameter-efficient MoE method,
\textit{\textbf{M}oE-L\textbf{o}RA with \textbf{L}ayer-wise Expert
\textbf{A}llocation (MoLA)} for Transformer-based models, where each model
layer has the flexibility to employ a varying number of LoRA experts. We
investigate several architectures with varying layer-wise expert
configurations. Experiments on six well-known NLP and commonsense QA benchmarks
demonstrate that MoLA achieves equal or superior performance compared to all
baselines. We find that allocating more LoRA experts to higher layers further
enhances the effectiveness of models with a certain number of experts in total.
With much fewer parameters, this allocation strategy outperforms the setting
with the same number of experts in every layer. This work can be widely used as
a plug-and-play parameter-efficient tuning approach for various applications.
The code is available at https://github.com/GCYZSL/MoLA.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08563" title="Abstract">arXiv:2402.08563</a> [<a href="/pdf/2402.08563" title="Download PDF">pdf</a>, <a href="/format/2402.08563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Denoising Diffusion Restoration Tackles Forward and Inverse Problems for  the Laplace Operator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+A">Amartya Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Stadt%2C+M+M">Melissa M. Stadt</a>, 
<a href="/search/cs?searchtype=author&query=Podina%2C+L">Lena Podina</a>, 
<a href="/search/cs?searchtype=author&query=Kohandel%2C+M">Mohammad Kohandel</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Analysis of PDEs (math.AP)

</div>
<p class="mathjax">Diffusion models have emerged as a promising class of generative models that
map noisy inputs to realistic images. More recently, they have been employed to
generate solutions to partial differential equations (PDEs). However, they
still struggle with inverse problems in the Laplacian operator, for instance,
the Poisson equation, because the eigenvalues that are large in magnitude
amplify the measurement noise. This paper presents a novel approach for the
inverse and forward solution of PDEs through the use of denoising diffusion
restoration models (DDRM). DDRMs were used in linear inverse problems to
restore original clean signals by exploiting the singular value decomposition
(SVD) of the linear operator. Equivalently, we present an approach to restore
the solution and the parameters in the Poisson equation by exploiting the
eigenvalues and the eigenfunctions of the Laplacian operator. Our results show
that using denoising diffusion restoration significantly improves the
estimation of the solution and parameters. Our research, as a result, pioneers
the integration of diffusion models with the principles of underlying physics
to solve PDEs.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08564" title="Abstract">arXiv:2402.08564</a> [<a href="/pdf/2402.08564" title="Download PDF">pdf</a>, <a href="/format/2402.08564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Barriers to Collusion-resistant Transaction Fee Mechanisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gafni%2C+Y">Yotam Gafni</a>, 
<a href="/search/cs?searchtype=author&query=Yaish%2C+A">Aviv Yaish</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
<p class="mathjax">To allocate transactions to blocks, cryptocurrencies use an auction-like
transaction fee mechanism (TFM). A conjecture of Roughgarden [44] asks whether
there is a TFM that is incentive compatible for both the users and the miner,
and is also resistant to off-chain agreements (OCAs) between these parties, a
collusion notion that captures the ability of users and the miner to jointly
deviate for profit. The work of Chung and Shi [12] tackles the problem using
the different collusion resistance notion of side-channel proofness (SCP), and
shows an impossibility given this notion. We show that OCA-proofness and SCP
are different, with SCP being strictly stronger. We then fully characterize the
intersection of deterministic dominant strategy incentive-compatible (DSIC) and
OCA-proof mechanisms, as well as deterministic MMIC and OCA-proof ones, and use
this characterization to show that only the trivial mechanism is DSIC, myopic
miner incentive-compatible (MMIC) and OCA-proof. We also show that a randomized
mechanism can be at most 0.842-efficient in the worst case, and that the
impossibility of a non-trivial DSIC, MMIC and OCA-proof extends to a couple of
natural classes of randomized mechanisms.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08565" title="Abstract">arXiv:2402.08565</a> [<a href="/pdf/2402.08565" title="Download PDF">pdf</a>, <a href="/format/2402.08565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artificial Intelligence for Literature Reviews: Opportunities and  Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bolanos%2C+F">Francisco Bolanos</a>, 
<a href="/search/cs?searchtype=author&query=Salatino%2C+A">Angelo Salatino</a>, 
<a href="/search/cs?searchtype=author&query=Osborne%2C+F">Francesco Osborne</a>, 
<a href="/search/cs?searchtype=author&query=Motta%2C+E">Enrico Motta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC); Information Retrieval (cs.IR)

</div>
<p class="mathjax">This manuscript presents a comprehensive review of the use of Artificial
Intelligence (AI) in Systematic Literature Reviews (SLRs). A SLR is a rigorous
and organised methodology that assesses and integrates previous research on a
given topic. Numerous tools have been developed to assist and partially
automate the SLR process. The increasing role of AI in this field shows great
potential in providing more effective support for researchers, moving towards
the semi-automatic creation of literature reviews. Our study focuses on how AI
techniques are applied in the semi-automation of SLRs, specifically in the
screening and extraction phases. We examine 21 leading SLR tools using a
framework that combines 23 traditional features with 11 AI features. We also
analyse 11 recent tools that leverage large language models for searching the
literature and assisting academic writing. Finally, the paper discusses current
trends in the field, outlines key research challenges, and suggests directions
for future research.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08566" title="Abstract">arXiv:2402.08566</a> [<a href="/pdf/2402.08566" title="Download PDF">pdf</a>, <a href="/format/2402.08566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian-Sum Filter for Range-based 3D Relative Pose Estimation in the  Presence of Ambiguities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S+S">Syed S. Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Shalaby%2C+M+A">Mohammed A. Shalaby</a>, 
<a href="/search/cs?searchtype=author&query=Cossette%2C+C+C">Charles C. Cossette</a>, 
<a href="/search/cs?searchtype=author&query=Ny%2C+J+L">Jerome Le Ny</a>, 
<a href="/search/cs?searchtype=author&query=Forbes%2C+J+R">James R. Forbes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 9 figures, submitted to IEEE Conference on Control Technology and Applications 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Multi-robot systems must have the ability to accurately estimate relative
states between robots in order to perform collaborative tasks, possibly with no
external aiding. Three-dimensional relative pose estimation using range
measurements oftentimes suffers from a finite number of non-unique solutions,
or ambiguities. This paper: 1) identifies and accurately estimates all possible
ambiguities in 2D; 2) treats them as components of a Gaussian mixture model;
and 3) presents a computationally-efficient estimator, in the form of a
Gaussian-sum filter (GSF), to realize range-based relative pose estimation in
an infrastructure-free, 3D, setup. This estimator is evaluated in simulation
and experiment and is shown to avoid divergence to local minima induced by the
ambiguous poses. Furthermore, the proposed GSF outperforms an extended Kalman
filter, demonstrates similar performance to the computationally-demanding
particle filter, and is shown to be consistent.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08567" title="Abstract">arXiv:2402.08567</a> [<a href="/pdf/2402.08567" title="Download PDF">pdf</a>, <a href="/format/2402.08567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM  Agents Exponentially Fast
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xiangming Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiaosen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+T">Tianyu Pang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+C">Chao Du</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ye Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jing Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Min Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">A multimodal large language model (MLLM) agent can receive instructions,
capture images, retrieve histories from memory, and decide which tools to use.
Nonetheless, red-teaming efforts have revealed that adversarial images/prompts
can jailbreak an MLLM and cause unaligned behaviors. In this work, we report an
even more severe safety issue in multi-agent environments, referred to as
infectious jailbreak. It entails the adversary simply jailbreaking a single
agent, and without any further intervention from the adversary, (almost) all
agents will become infected exponentially fast and exhibit harmful behaviors.
To validate the feasibility of infectious jailbreak, we simulate multi-agent
environments containing up to one million LLaVA-1.5 agents, and employ
randomized pair-wise chat as a proof-of-concept instantiation for multi-agent
interaction. Our results show that feeding an (infectious) adversarial image
into the memory of any randomly chosen agent is sufficient to achieve
infectious jailbreak. Finally, we derive a simple principle for determining
whether a defense mechanism can provably restrain the spread of infectious
jailbreak, but how to design a practical defense that meets this principle
remains an open question to investigate. Our project page is available at
https://sail-sg.github.io/Agent-Smith/.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08568" title="Abstract">arXiv:2402.08568</a> [<a href="/pdf/2402.08568" title="Download PDF">pdf</a>, <a href="/format/2402.08568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence Analysis of a Variable Projection Method for Regularized  Separable Nonlinear Inverse Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Espa%C3%B1ol%2C+M+I">Malena I. Espa&#xf1;ol</a>, 
<a href="/search/math?searchtype=author&query=Jeronimo%2C+G">Gabriela Jeronimo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Variable projection methods prove highly efficient in solving separable
nonlinear least squares problems by transforming them into a reduced nonlinear
least squares problem, typically solvable via the Gauss-Newton method. When
solving large-scale separable nonlinear inverse problems with general-form
Tikhonov regularization, the computational demand for computing Jacobians in
the Gauss-Newton method becomes very challenging. To mitigate this, iterative
methods, specifically LSQR, can be used as inner solvers to compute approximate
Jacobians. This article analyzes the impact of these approximate Jacobians
within the variable projection method and introduces stopping criteria to
ensure convergence. We also present numerical experiments where we apply the
proposed method to solve a blind deconvolution problem to illustrate and
confirm our theoretical results.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08570" title="Abstract">arXiv:2402.08570</a> [<a href="/pdf/2402.08570" title="Download PDF">pdf</a>, <a href="/format/2402.08570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Foundation Model Selection in Robotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Po-han Li</a>, 
<a href="/search/cs?searchtype=author&query=Toprak%2C+O+S">Oyku Selin Toprak</a>, 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+A">Aditya Narayanan</a>, 
<a href="/search/cs?searchtype=author&query=Topcu%2C+U">Ufuk Topcu</a>, 
<a href="/search/cs?searchtype=author&query=Chinchali%2C+S">Sandeep Chinchali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Foundation models have recently expanded into robotics after excelling in
computer vision and natural language processing. The models are accessible in
two ways: open-source or paid, closed-source options. Users with access to both
face a problem when deciding between effective yet costly closed-source models
and free but less powerful open-source alternatives. We call it the model
selection problem. Existing supervised-learning methods are impractical due to
the high cost of collecting extensive training data from closed-source models.
Hence, we focus on the online learning setting where algorithms learn while
collecting data, eliminating the need for large pre-collected datasets. We thus
formulate a user-centric online model selection problem and propose a novel
solution that combines an open-source encoder to output context and an online
learning algorithm that processes this context. The encoder distills vast data
distributions into low-dimensional features, i.e., the context, without
additional training. The online learning algorithm aims to maximize a composite
reward that includes model performance, execution time, and costs based on the
context extracted from the data. It results in an improved trade-off between
selecting open-source and closed-source models compared to non-contextual
methods, as validated by our theoretical analysis. Experiments across
language-based robotic tasks such as Waymo Open Dataset, ALFRED, and Open
X-Embodiment demonstrate real-world applications of the solution. The results
show that the solution significantly improves the task success rate by up to
14%.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08571" title="Abstract">arXiv:2402.08571</a> [<a href="/pdf/2402.08571" title="Download PDF">pdf</a>, <a href="/format/2402.08571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Glass Segmentation with Multi Scales and Primary Prediction Guiding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qingliang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Glass-like objects can be seen everywhere in our daily life which are very
hard for existing methods to segment them. The properties of transparencies
pose great challenges of detecting them from the chaotic background and the
vague separation boundaries further impede the acquisition of their exact
contours. Moving machines which ignore glasses have great risks of crashing
into transparent barriers or difficulties in analysing objects reflected in the
mirror, thus it is of substantial significance to accurately locate glass-like
objects and completely figure out their contours. In this paper, inspired by
the scale integration strategy and the refinement method, we proposed a
brand-new network, named as MGNet, which consists of a Fine-Rescaling and
Merging module (FRM) to improve the ability to extract spatially relationship
and a Primary Prediction Guiding module (PPG) to better mine the leftover
semantics from the fused features. Moreover, we supervise the model with a
novel loss function with the uncertainty-aware loss to produce high-confidence
segmentation maps. Unlike the existing glass segmentation models that must be
trained on different settings with respect to varied datasets, our model are
trained under consistent settings and has achieved superior performance on
three popular public datasets. Code is available at
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08573" title="Abstract">arXiv:2402.08573</a> [<a href="/pdf/2402.08573" title="Download PDF">pdf</a>, <a href="/format/2402.08573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two Tales of Single-Phase Contrastive Hebbian Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=H%C3%B8ier%2C+R+K">Rasmus Kj&#xe6;r H&#xf8;ier</a>, 
<a href="/search/cs?searchtype=author&query=Zach%2C+C">Christopher Zach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">The search for "biologically plausible" learning algorithms has converged on
the idea of representing gradients as activity differences. However, most
approaches require a high degree of synchronization (distinct phases during
learning) and introduce substantial computational overhead, which raises doubts
regarding their biological plausibility as well as their potential utility for
neuromorphic computing. Furthermore, they commonly rely on applying
infinitesimal perturbations (nudges) to output units, which is impractical in
noisy environments. Recently it has been shown that by modelling artificial
neurons as dyads with two oppositely nudged compartments, it is possible for a
fully local learning algorithm named ``dual propagation'' to bridge the
performance gap to backpropagation, without requiring separate learning phases
or infinitesimal nudging. However, the algorithm has the drawback that its
numerical stability relies on symmetric nudging, which may be restrictive in
biological and analog implementations. In this work we first provide a solid
foundation for the objective underlying the dual propagation method, which also
reveals a surprising connection with adversarial robustness. Second, we
demonstrate how dual propagation is related to a particular adjoint state
method, which is stable regardless of asymmetric nudging.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08576" title="Abstract">arXiv:2402.08576</a> [<a href="/pdf/2402.08576" title="Download PDF">pdf</a>, <a href="/format/2402.08576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regret Minimization in Stackelberg Games with Side Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harris%2C+K">Keegan Harris</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z+S">Zhiwei Steven Wu</a>, 
<a href="/search/cs?searchtype=author&query=Balcan%2C+M">Maria-Florina Balcan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In its most basic form, a Stackelberg game is a two-player game in which a
leader commits to a (mixed) strategy, and a follower best-responds. Stackelberg
games are perhaps one of the biggest success stories of algorithmic game theory
over the last decade, as algorithms for playing in Stackelberg games have been
deployed in many real-world domains including airport security, anti-poaching
efforts, and cyber-crime prevention. However, these algorithms often fail to
take into consideration the additional information available to each player
(e.g. traffic patterns, weather conditions, network congestion), a salient
feature of reality which may significantly affect both players' optimal
strategies. We formalize such settings as Stackelberg games with side
information, in which both players observe an external context before playing.
The leader then commits to a (possibly context-dependent) strategy, and the
follower best-responds to both the leader's strategy and the context. We focus
on the online setting in which a sequence of followers arrive over time, and
the context may change from round-to-round. In sharp contrast to the
non-contextual version, we show that it is impossible for the leader to achieve
good performance (measured by regret) in the full adversarial setting (i.e.,
when both the context and the follower are chosen by an adversary). However, it
turns out that a little bit of randomness goes a long way. Motivated by our
impossibility result, we show that no-regret learning is possible in two
natural relaxations: the setting in which the sequence of followers is chosen
stochastically and the sequence of contexts is adversarial, and the setting in
which the sequence of contexts is stochastic and the sequence of followers is
chosen by an adversary.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08577" title="Abstract">arXiv:2402.08577</a> [<a href="/pdf/2402.08577" title="Download PDF">pdf</a>, <a href="/format/2402.08577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Test-Time Backdoor Attacks on Multimodal Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+D">Dong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+T">Tianyu Pang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+C">Chao Du</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xianjun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Min Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">Backdoor attacks are commonly executed by contaminating training data, such
that a trigger can activate predetermined harmful effects during the test
phase. In this work, we present AnyDoor, a test-time backdoor attack against
multimodal large language models (MLLMs), which involves injecting the backdoor
into the textual modality using adversarial test images (sharing the same
universal perturbation), without requiring access to or modification of the
training data. AnyDoor employs similar techniques used in universal adversarial
attacks, but distinguishes itself by its ability to decouple the timing of
setup and activation of harmful effects. In our experiments, we validate the
effectiveness of AnyDoor against popular MLLMs such as LLaVA-1.5, MiniGPT-4,
InstructBLIP, and BLIP-2, as well as provide comprehensive ablation studies.
Notably, because the backdoor is injected by a universal perturbation, AnyDoor
can dynamically change its backdoor trigger prompts/harmful effects, exposing a
new challenge for defending against backdoor attacks. Our project page is
available at https://sail-sg.github.io/AnyDoor/.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08578" title="Abstract">arXiv:2402.08578</a> [<a href="/pdf/2402.08578" title="Download PDF">pdf</a>, <a href="/format/2402.08578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedLPS: Heterogeneous Federated Learning for Multiple Tasks with Local  Parameter Sharing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yongzhe Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuyun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Beheshti%2C+A">Amin Beheshti</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+W">Wanchun Dou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated Learning (FL) has emerged as a promising solution in Edge Computing
(EC) environments to process the proliferation of data generated by edge
devices. By collaboratively optimizing the global machine learning models on
distributed edge devices, FL circumvents the need for transmitting raw data and
enhances user privacy. Despite practical successes, FL still confronts
significant challenges including constrained edge device resources, multiple
tasks deployment, and data heterogeneity. However, existing studies focus on
mitigating the FL training costs of each single task whereas neglecting the
resource consumption across multiple tasks in heterogeneous FL scenarios. In
this paper, we propose Heterogeneous Federated Learning with Local Parameter
Sharing (FedLPS) to fill this gap. FedLPS leverages principles from transfer
learning to facilitate the deployment of multiple tasks on a single device by
dividing the local model into a shareable encoder and task-specific encoders.
To further reduce resource consumption, a channel-wise model pruning algorithm
that shrinks the footprint of local models while accounting for both data and
system heterogeneity is employed in FedLPS. Additionally, a novel heterogeneous
model aggregation algorithm is proposed to aggregate the heterogeneous
predictors in FedLPS. We implemented the proposed FedLPS on a real FL platform
and compared it with state-of-the-art (SOTA) FL frameworks. The experimental
results on five popular datasets and two modern DNN models illustrate that the
proposed FedLPS significantly outperforms the SOTA FL frameworks by up to 4.88%
and reduces the computational resource consumption by 21.3%. Our code is
available at:https://github.com/jyzgh/FedLPS.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08579" title="Abstract">arXiv:2402.08579</a> [<a href="/pdf/2402.08579" title="Download PDF">pdf</a>, <a href="/format/2402.08579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Coupled Phase Oscillators as a Neuromorphic Platform using  Equilibrium Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qingshan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wanjura%2C+C+C">Clara C. Wanjura</a>, 
<a href="/search/cs?searchtype=author&query=Marquardt%2C+F">Florian Marquardt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures, comments welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Mesoscale and Nanoscale Physics (cond-mat.mes-hall); Neural and Evolutionary Computing (cs.NE); Optics (physics.optics)

</div>
<p class="mathjax">Given the rapidly growing scale and resource requirements of machine learning
applications, the idea of building more efficient learning machines much closer
to the laws of physics is an attractive proposition. One central question for
identifying promising candidates for such neuromorphic platforms is whether not
only inference but also training can exploit the physical dynamics. In this
work, we show that it is possible to successfully train a system of coupled
phase oscillators - one of the most widely investigated nonlinear dynamical
systems with a multitude of physical implementations, comprising laser arrays,
coupled mechanical limit cycles, superfluids, and exciton-polaritons. To this
end, we apply the approach of equilibrium propagation, which permits to extract
training gradients via a physical realization of backpropagation, based only on
local interactions. The complex energy landscape of the XY/ Kuramoto model
leads to multistability, and we show how to address this challenge. Our study
identifies coupled phase oscillators as a new general-purpose neuromorphic
platform and opens the door towards future experimental implementations.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08581" title="Abstract">arXiv:2402.08581</a> [<a href="/pdf/2402.08581" title="Download PDF">pdf</a>, <a href="/format/2402.08581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Factual Error Correction for Abstractive Summarization via  Data Distillation and Conditional-generation Cloze
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+D">Dingxin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+X">Xueyi Hao</a>, 
<a href="/search/cs?searchtype=author&query=Litvak%2C+M">Marina Litvak</a>, 
<a href="/search/cs?searchtype=author&query=Vanetik%2C+N">Natalia Vanetik</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yanquan Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> manuscript
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Improving factual consistency in abstractive summarization has been a focus
of current research. One promising approach is the post-editing method.
However, previous works have yet to make sufficient use of factual factors in
summaries and suffers from the negative effect of the training datasets. In
this paper, we first propose a novel factual error correction model FactCloze
based on a conditional-generation cloze task. FactCloze can construct the
causality among factual factors while being able to determine whether the blank
can be answered or not. Then, we propose a data distillation method to generate
a more faithful summarization dataset SummDSC via multiple-dimensional
evaluation. We experimentally validate the effectiveness of our approach, which
leads to an improvement in multiple factual consistency metrics compared to
baselines.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08582" title="Abstract">arXiv:2402.08582</a> [<a href="/pdf/2402.08582" title="Download PDF">pdf</a>, <a href="/format/2402.08582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FESS Loss: Feature-Enhanced Spatial Segmentation Loss for Optimizing  Medical Image Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chodvadiya%2C+C">Charulkumar Chodvadiya</a>, 
<a href="/search/cs?searchtype=author&query=Mahla%2C+N">Navyansh Mahla</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+K+G">Kinshuk Gaurav Singh</a>, 
<a href="/search/cs?searchtype=author&query=Jadhav%2C+K+S">Kshitij Sharad Jadhav</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 Pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Medical image segmentation is a critical process in the field of medical
imaging, playing a pivotal role in diagnosis, treatment, and research. It
involves partitioning of an image into multiple regions, representing distinct
anatomical or pathological structures. Conventional methods often grapple with
the challenge of balancing spatial precision and comprehensive feature
representation due to their reliance on traditional loss functions. To overcome
this, we propose Feature-Enhanced Spatial Segmentation Loss (FESS Loss), that
integrates the benefits of contrastive learning (which extracts intricate
features, particularly in the nuanced domain of medical imaging) with the
spatial accuracy inherent in the Dice loss. The objective is to augment both
spatial precision and feature-based representation in the segmentation of
medical images. FESS Loss signifies a notable advancement, offering a more
accurate and refined segmentation process, ultimately contributing to
heightened precision in the analysis of medical images. Further, FESS loss
demonstrates superior performance in limited annotated data availability
scenarios often present in the medical domain.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08583" title="Abstract">arXiv:2402.08583</a> [<a href="/pdf/2402.08583" title="Download PDF">pdf</a>, <a href="/format/2402.08583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixture of Link Predictors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Li Ma</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+H">Haoyu Han</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juanhui Li</a>, 
<a href="/search/cs?searchtype=author&query=Shomer%2C+H">Harry Shomer</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiaofeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiliang Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Link prediction, which aims to forecast unseen connections in graphs, is a
fundamental task in graph machine learning. Heuristic methods, leveraging a
range of different pairwise measures such as common neighbors and shortest
paths, often rival the performance of vanilla Graph Neural Networks (GNNs).
Therefore, recent advancements in GNNs for link prediction (GNN4LP) have
primarily focused on integrating one or a few types of pairwise information. In
this work, we reveal that different node pairs within the same dataset
necessitate varied pairwise information for accurate prediction and models that
only apply the same pairwise information uniformly could achieve suboptimal
performance. As a result, we propose a simple mixture of experts model Link-MoE
for link prediction. Link-MoE utilizes various GNNs as experts and
strategically selects the appropriate expert for each node pair based on
various types of pairwise information. Experimental results across diverse
real-world datasets demonstrate substantial performance improvement from
Link-MoE. Notably, Link-MoE achieves a relative improvement of 18.82\% on the
MRR metric for the Pubmed dataset and 10.8\% on the Hits@100 metric for the
ogbl-ppa dataset, compared to the best baselines.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08586" title="Abstract">arXiv:2402.08586</a> [<a href="/pdf/2402.08586" title="Download PDF">pdf</a>, <a href="/format/2402.08586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Repeated Evasion Attacks in Tree Ensembles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cascioli%2C+L">Lorenzo Cascioli</a>, 
<a href="/search/cs?searchtype=author&query=Devos%2C+L">Laurens Devos</a>, 
<a href="/search/cs?searchtype=author&query=Ku%C5%BEelka%2C+O">Ond&#x159;ej Ku&#x17e;elka</a>, 
<a href="/search/cs?searchtype=author&query=Davis%2C+J">Jesse Davis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Tree ensembles are one of the most widely used model classes. However, these
models are susceptible to adversarial examples, i.e., slightly perturbed
examples that elicit a misprediction. There has been significant research on
designing approaches to construct such examples for tree ensembles. But this is
a computationally challenging problem that often must be solved a large number
of times (e.g., for all examples in a training set). This is compounded by the
fact that current approaches attempt to find such examples from scratch. In
contrast, we exploit the fact that multiple similar problems are being solved.
Specifically, our approach exploits the insight that adversarial examples for
tree ensembles tend to perturb a consistent but relatively small set of
features. We show that we can quickly identify this set of features and use
this knowledge to speedup constructing adversarial examples.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08593" title="Abstract">arXiv:2402.08593</a> [<a href="/pdf/2402.08593" title="Download PDF">pdf</a>, <a href="/format/2402.08593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Feature Preprocessor: Real-time Extraction of Subgraph-based  Features from Transaction Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blanu%C5%A1a%2C+J">Jovan Blanu&#x161;a</a>, 
<a href="/search/cs?searchtype=author&query=Baraja%2C+M+C">Maximo Cravero Baraja</a>, 
<a href="/search/cs?searchtype=author&query=Anghel%2C+A">Andreea Anghel</a>, 
<a href="/search/cs?searchtype=author&query=von+Niederh%C3%A4usern%2C+L">Luc von Niederh&#xe4;usern</a>, 
<a href="/search/cs?searchtype=author&query=Altman%2C+E">Erik Altman</a>, 
<a href="/search/cs?searchtype=author&query=Pozidis%2C+H">Haris Pozidis</a>, 
<a href="/search/cs?searchtype=author&query=Atasu%2C+K">Kubilay Atasu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we present "Graph Feature Preprocessor", a software library
for detecting typical money laundering and fraud patterns in financial
transaction graphs in real time. These patterns are used to produce a rich set
of transaction features for downstream machine learning training and inference
tasks such as money laundering detection. We show that our enriched transaction
features dramatically improve the prediction accuracy of
gradient-boosting-based machine learning models. Our library exploits multicore
parallelism, maintains a dynamic in-memory graph, and efficiently mines
subgraph patterns in the incoming transaction stream, which enables it to be
operated in a streaming manner. We evaluate our library using highly-imbalanced
synthetic anti-money laundering (AML) and real-life Ethereum phishing datasets.
In these datasets, the proportion of illicit transactions is very small, which
makes the learning process challenging. Our solution, which combines our Graph
Feature Preprocessor and gradient-boosting-based machine learning models, is
able to detect these illicit transactions with higher minority-class F1 scores
than standard graph neural networks. In addition, the end-to-end throughput
rate of our solution executed on a multicore CPU outperforms the graph neural
network baselines executed on a powerful V100 GPU. Overall, the combination of
high accuracy, a high throughput rate, and low latency of our solution
demonstrates the practical value of our library in real-world applications.
Graph Feature Preprocessor has been integrated into IBM mainframe software
products, namely "IBM Cloud Pak for Data on Z" and "AI Toolkit for IBM Z and
LinuxONE".
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08594" title="Abstract">arXiv:2402.08594</a> [<a href="/pdf/2402.08594" title="Download PDF">pdf</a>, <a href="/format/2402.08594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Multi-Task Transfer Learning for Soft Prompt Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Haeju Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+M">Minchan Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Se-Young Yun</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kee-Eung Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors equally contributed to this work. Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Prompt tuning, in which prompts are optimized to adapt large-scale
pre-trained language models to downstream tasks instead of fine-tuning the full
model parameters, has been shown to be particularly effective when the prompts
are trained in a multi-task transfer learning setting. These methods generally
involve individually training prompts for each source task and then aggregating
them to provide the initialization of the prompt for the target task. However,
this approach critically ignores the fact that some of the source tasks could
be negatively or positively interfering with each other. We argue that when we
extract knowledge from source tasks via training source prompts, we need to
consider this correlation among source tasks for better transfer to target
tasks. To this end, we propose a Bayesian approach where we work with the
posterior distribution of prompts across source tasks. We obtain representative
source prompts corresponding to the samples from the posterior utilizing Stein
Variational Gradient Descent, which are then aggregated to constitute the
initial target prompt. We show extensive experimental results on the standard
benchmark NLP tasks, where our Bayesian multi-task transfer learning approach
outperforms the state-of-the-art methods in many settings. Furthermore, our
approach requires no auxiliary models other than the prompt itself, achieving a
high degree of parameter efficiency.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08595" title="Abstract">arXiv:2402.08595</a> [<a href="/pdf/2402.08595" title="Download PDF">pdf</a>, <a href="/format/2402.08595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Homomorphism Counts for Graph Neural Networks: All About That Basis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+E">Emily Jin</a>, 
<a href="/search/cs?searchtype=author&query=Bronstein%2C+M">Michael Bronstein</a>, 
<a href="/search/cs?searchtype=author&query=Ceylan%2C+I+I">Ismail Ilkan Ceylan</a>, 
<a href="/search/cs?searchtype=author&query=Lanzinger%2C+M">Matthias Lanzinger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph neural networks are architectures for learning invariant functions over
graphs. A large body of work has investigated the properties of graph neural
networks and identified several limitations, particularly pertaining to their
expressive power. Their inability to count certain patterns (e.g., cycles) in a
graph lies at the heart of such limitations, since many functions to be learned
rely on the ability of counting such patterns. Two prominent paradigms aim to
address this limitation by enriching the graph features with subgraph or
homomorphism pattern counts. In this work, we show that both of these
approaches are sub-optimal in a certain sense and argue for a more fine-grained
approach, which incorporates the homomorphism counts of all structures in the
"basis" of the target pattern. This yields strictly more expressive
architectures without incurring any additional overhead in terms of
computational complexity compared to existing approaches. We prove a series of
theoretical results on node-level and graph-level motif parameters and
empirically validate them on standard benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08601" title="Abstract">arXiv:2402.08601</a> [<a href="/pdf/2402.08601" title="Download PDF">pdf</a>, <a href="/format/2402.08601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Inversion with Timestep-aware Sampling for Training-free  Non-rigid Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jung%2C+Y">Yunji Jung</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seokju Lee</a>, 
<a href="/search/cs?searchtype=author&query=Djanibekov%2C+T">Tair Djanibekov</a>, 
<a href="/search/cs?searchtype=author&query=Shim%2C+H">Hyunjung Shim</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jongchul Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-guided non-rigid editing involves complex edits for input images, such
as changing motion or compositions within their surroundings. Since it requires
manipulating the input structure, existing methods often struggle with
preserving object identity and background, particularly when combined with
Stable Diffusion. In this work, we propose a training-free approach for
non-rigid editing with Stable Diffusion, aimed at improving the identity
preservation quality without compromising editability. Our approach comprises
three stages: text optimization, latent inversion, and timestep-aware text
injection sampling. Inspired by the recent success of Imagic, we employ their
text optimization for smooth editing. Then, we introduce latent inversion to
preserve the input image's identity without additional model fine-tuning. To
fully utilize the input reconstruction ability of latent inversion, we suggest
timestep-aware text inject sampling. This effectively retains the structure of
the input image by injecting the source text prompt in early sampling steps and
then transitioning to the target prompt in subsequent sampling steps. This
strategic approach seamlessly harmonizes with text optimization, facilitating
complex non-rigid edits to the input without losing the original identity. We
demonstrate the effectiveness of our method in terms of identity preservation,
editability, and aesthetic quality through extensive experiments.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08604" title="Abstract">arXiv:2402.08604</a> [<a href="/pdf/2402.08604" title="Download PDF">pdf</a>, <a href="/format/2402.08604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling Space-Saving Set Sketches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H+K">Homin K. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Masson%2C+C">Charles Masson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Large, distributed data streams are now ubiquitous. High-accuracy sketches
with low memory overhead have become the de facto method for analyzing this
data. For instance, if we wish to group data by some label and report the
largest counts using fixed memory, we need to turn to mergeable heavy hitter
sketches that can provide highly accurate approximate counts. Similarly, if we
wish to keep track of the number of distinct items in a single set spread
across several streams using fixed memory, we can turn to mergeable count
distinct sketches that can provide highly accurate set cardinalities.
<br />If we were to try to keep track of the cardinality of multiple sets and
report only on the largest ones, maintaining individual count distinct sketches
for each set can grow unwieldy, especially if the number of sets is not known
in advance. We consider the natural combination of the heavy hitters problem
with the count distinct problem, the heavy distinct hitters problem: given a
stream of $(\ell, x)$ pairs, find all the labels $\ell$ that are paired with a
large number of distinct items $x$ using only constant memory.
<br />No previous work on heavy distinct hitters has managed to be of practical use
in the large, distributed data stream setting. We propose a new algorithm, the
Sampling Space-Saving Set Sketch, which combines sketching and sampling
techniques and has all the desired properties for size, speed, accuracy,
mergeability, and invertibility. We compare our algorithm to several existing
solutions to the heavy distinct hitters problem, and provide experimental
results across several data sets showing the superiority of the new sketch.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08607" title="Abstract">arXiv:2402.08607</a> [<a href="/pdf/2402.08607" title="Download PDF">pdf</a>, <a href="/ps/2402.08607" title="Download PostScript">ps</a>, <a href="/format/2402.08607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A robust second-order low-rank BUG integrator based on the midpoint rule
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ceruti%2C+G">Gianluca Ceruti</a>, 
<a href="/search/math?searchtype=author&query=Einkemmer%2C+L">Lukas Einkemmer</a>, 
<a href="/search/math?searchtype=author&query=Kusch%2C+J">Jonas Kusch</a>, 
<a href="/search/math?searchtype=author&query=Lubich%2C+C">Christian Lubich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Dynamical low-rank approximation has become a valuable tool to perform an
on-the-fly model order reduction for prohibitively large matrix differential
equations. A core ingredient is the construction of integrators that are robust
to the presence of small singular values and the resulting large time
derivatives of the orthogonal factors in the low-rank matrix representation.
Recently, the robust basis-update &amp; Galerkin (BUG) class of integrators has
been introduced. These methods require no steps that evolve the solution
backward in time, often have favourable structure-preserving properties, and
allow for parallel time-updates of the low-rank factors. The BUG framework is
flexible enough to allow for adaptations to these and further requirements.
However, the BUG methods presented so far have only first-order robust error
bounds. This work proposes a second-order BUG integrator for dynamical low-rank
approximation based on the midpoint rule. The integrator first performs a
half-step with a first-order BUG integrator, followed by a Galerkin update with
a suitably augmented basis. We prove a robust second-order error bound which in
addition shows an improved dependence on the normal component of the vector
field. These rigorous results are illustrated and complemented by a number of
numerical experiments.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08608" title="Abstract">arXiv:2402.08608</a> [<a href="/pdf/2402.08608" title="Download PDF">pdf</a>, <a href="/ps/2402.08608" title="Download PostScript">ps</a>, <a href="/format/2402.08608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evidence Tetris in the Pixelated World of Validity Threats
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wyrich%2C+M">Marvin Wyrich</a>, 
<a href="/search/cs?searchtype=author&query=Apel%2C+S">Sven Apel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WSESE 2024, an ICSE co-located workshop on methodological issues with empirical studies in software engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Valid empirical studies build confidence in scientific findings. Fortunately,
it is now common for software engineering researchers to consider threats to
validity when designing their studies and to discuss them as part of their
publication. Yet, in complex experiments with human participants, there is
often an overwhelming number of intuitively plausible threats to validity --
more than a researcher can feasibly cover. Therefore, prioritizing potential
threats to validity becomes crucial. We suggest moving away from relying solely
on intuition for prioritizing validity threats, and propose that evidence on
the actual impact of suspected threats to validity should complement intuition.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08609" title="Abstract">arXiv:2402.08609</a> [<a href="/pdf/2402.08609" title="Download PDF">pdf</a>, <a href="/format/2402.08609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixtures of Experts Unlock Parameter Scaling for Deep RL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Obando-Ceron%2C+J">Johan Obando-Ceron</a>, 
<a href="/search/cs?searchtype=author&query=Sokar%2C+G">Ghada Sokar</a>, 
<a href="/search/cs?searchtype=author&query=Willi%2C+T">Timon Willi</a>, 
<a href="/search/cs?searchtype=author&query=Lyle%2C+C">Clare Lyle</a>, 
<a href="/search/cs?searchtype=author&query=Farebrother%2C+J">Jesse Farebrother</a>, 
<a href="/search/cs?searchtype=author&query=Foerster%2C+J">Jakob Foerster</a>, 
<a href="/search/cs?searchtype=author&query=Dziugaite%2C+G+K">Gintare Karolina Dziugaite</a>, 
<a href="/search/cs?searchtype=author&query=Precup%2C+D">Doina Precup</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+P+S">Pablo Samuel Castro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The recent rapid progress in (self) supervised learning models is in large
part predicted by empirical scaling laws: a model's performance scales
proportionally to its size. Analogous scaling laws remain elusive for
reinforcement learning domains, however, where increasing the parameter count
of a model often hurts its final performance. In this paper, we demonstrate
that incorporating Mixture-of-Expert (MoE) modules, and in particular Soft MoEs
(Puigcerver et al., 2023), into value-based networks results in more
parameter-scalable models, evidenced by substantial performance increases
across a variety of training regimes and model sizes. This work thus provides
strong empirical evidence towards developing scaling laws for reinforcement
learning.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08611" title="Abstract">arXiv:2402.08611</a> [<a href="/pdf/2402.08611" title="Download PDF">pdf</a>, <a href="/format/2402.08611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Cost-Sensitive Transformer Model for Prognostics Under Highly  Imbalanced Industrial Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beikmohammadi%2C+A">Ali Beikmohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Hamian%2C+M+H">Mohammad Hosein Hamian</a>, 
<a href="/search/cs?searchtype=author&query=Khoeyniha%2C+N">Neda Khoeyniha</a>, 
<a href="/search/cs?searchtype=author&query=Lindgren%2C+T">Tony Lindgren</a>, 
<a href="/search/cs?searchtype=author&query=Steinert%2C+O">Olof Steinert</a>, 
<a href="/search/cs?searchtype=author&query=Magn%C3%BAsson%2C+S">Sindri Magn&#xfa;sson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The rapid influx of data-driven models into the industrial sector has been
facilitated by the proliferation of sensor technology, enabling the collection
of vast quantities of data. However, leveraging these models for failure
detection and prognosis poses significant challenges, including issues like
missing values and class imbalances. Moreover, the cost sensitivity associated
with industrial operations further complicates the application of conventional
models in this context. This paper introduces a novel cost-sensitive
transformer model developed as part of a systematic workflow, which also
integrates a hybrid resampler and a regression-based imputer. After subjecting
our approach to rigorous testing using the APS failure dataset from Scania
trucks and the SECOM dataset, we observed a substantial enhancement in
performance compared to state-of-the-art methods. Moreover, we conduct an
ablation study to analyze the contributions of different components in our
proposed method. Our findings highlight the potential of our method in
addressing the unique challenges of failure prediction in industrial settings,
thereby contributing to enhanced reliability and efficiency in industrial
operations.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08614" title="Abstract">arXiv:2402.08614</a> [<a href="/pdf/2402.08614" title="Download PDF">pdf</a>, <a href="/format/2402.08614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CaPS: Collaborative and Private Synthetic Data Generation from  Distributed Sources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pentyala%2C+S">Sikha Pentyala</a>, 
<a href="/search/cs?searchtype=author&query=Pereira%2C+M">Mayana Pereira</a>, 
<a href="/search/cs?searchtype=author&query=De+Cock%2C+M">Martine De Cock</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Data is the lifeblood of the modern world, forming a fundamental part of AI,
decision-making, and research advances. With increase in interest in data,
governments have taken important steps towards a regulated data world,
drastically impacting data sharing and data usability and resulting in massive
amounts of data confined within the walls of organizations. While synthetic
data generation (SDG) is an appealing solution to break down these walls and
enable data sharing, the main drawback of existing solutions is the assumption
of a trusted aggregator for generative model training. Given that many data
holders may not want to, or be legally allowed to, entrust a central entity
with their raw data, we propose a framework for the collaborative and private
generation of synthetic tabular data from distributed data holders. Our
solution is general, applicable to any marginal-based SDG, and provides input
privacy by replacing the trusted aggregator with secure multi-party computation
(MPC) protocols and output privacy via differential privacy (DP). We
demonstrate the applicability and scalability of our approach for the
state-of-the-art select-measure-generate SDG algorithms MWEM+PGM and AIM.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08621" title="Abstract">arXiv:2402.08621</a> [<a href="/pdf/2402.08621" title="Download PDF">pdf</a>, <a href="/format/2402.08621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generalized Approach to Online Convex Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pedramfar%2C+M">Mohammad Pedramfar</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+V">Vaneet Aggarwal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we analyze the problem of online convex optimization in
different settings. We show that any algorithm for online linear optimization
with fully adaptive adversaries is an algorithm for online convex optimization.
We also show that any such algorithm that requires full-information feedback
may be transformed to an algorithm with semi-bandit feedback with comparable
regret bound. We further show that algorithms that are designed for fully
adaptive adversaries using deterministic semi-bandit feedback can obtain
similar bounds using only stochastic semi-bandit feedback when facing oblivious
adversaries. We use this to describe general meta-algorithms to convert first
order algorithms to zeroth order algorithms with comparable regret bounds. Our
framework allows us to analyze online optimization in various settings, such
full-information feedback, bandit feedback, stochastic regret, adversarial
regret and various forms of non-stationary regret. Using our analysis, we
provide the first efficient projection-free online convex optimization
algorithm using linear optimization oracles.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08622" title="Abstract">arXiv:2402.08622</a> [<a href="/pdf/2402.08622" title="Download PDF">pdf</a>, <a href="/format/2402.08622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeRF Analogies: Example-Based Visual Attribute Transfer for NeRFs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fischer%2C+M">Michael Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhengqin Li</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen-Phuoc%2C+T">Thu Nguyen-Phuoc</a>, 
<a href="/search/cs?searchtype=author&query=Bozic%2C+A">Aljaz Bozic</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Marshall%2C+C">Carl Marshall</a>, 
<a href="/search/cs?searchtype=author&query=Ritschel%2C+T">Tobias Ritschel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://mfischer-ucl.github.io/nerf_analogies/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">A Neural Radiance Field (NeRF) encodes the specific relation of 3D geometry
and appearance of a scene. We here ask the question whether we can transfer the
appearance from a source NeRF onto a target 3D geometry in a semantically
meaningful way, such that the resulting new NeRF retains the target geometry
but has an appearance that is an analogy to the source NeRF. To this end, we
generalize classic image analogies from 2D images to NeRFs. We leverage
correspondence transfer along semantic affinity that is driven by semantic
features from large, pre-trained 2D image models to achieve multi-view
consistent appearance transfer. Our method allows exploring the mix-and-match
product space of 3D geometry and appearance. We show that our method
outperforms traditional stylization-based methods and that a large majority of
users prefer our method over several typical baselines.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08631" title="Abstract">arXiv:2402.08631</a> [<a href="/pdf/2402.08631" title="Download PDF">pdf</a>, <a href="/format/2402.08631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Editing on Black-box Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiaoshuai Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhengyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+K">Keqing He</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+G">Guanting Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jinxu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weiran Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Knowledge editing (KE) aims to efficiently and precisely modify the behavior
of large language models (LLMs) to update specific knowledge without negatively
influencing other knowledge. Current research primarily focuses on white-box
LLMs editing, overlooking an important scenario: black-box LLMs editing, where
LLMs are accessed through interfaces and only textual output is available. To
address the limitations of existing evaluations that are not inapplicable to
black-box LLM editing and lack comprehensiveness, we propose a
multi-perspective evaluation framework, incorporating the assessment of style
retention for the first time. To tackle privacy leaks of editing data and style
over-editing in current methods, we introduce a novel postEdit framework,
resolving privacy concerns through downstream post-processing and maintaining
textual style consistency via fine-grained editing to original responses.
Experiments and analysis on two benchmarks demonstrate that postEdit
outperforms all baselines and achieves strong generalization, especially with
huge improvements on style retention (average $+20.82\%\uparrow$).
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08635" title="Abstract">arXiv:2402.08635</a> [<a href="/pdf/2402.08635" title="Download PDF">pdf</a>, <a href="/ps/2402.08635" title="Download PostScript">ps</a>, <a href="/format/2402.08635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BdSLW60: A Word-Level Bangla Sign Language Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rubaiyeat%2C+H+A">Husne Ara Rubaiyeat</a>, 
<a href="/search/cs?searchtype=author&query=Mahmud%2C+H">Hasan Mahmud</a>, 
<a href="/search/cs?searchtype=author&query=Habib%2C+A">Ahsan Habib</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+M+K">Md. Kamrul Hasan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Sign language discourse is an essential mode of daily communication for the
deaf and hard-of-hearing people. However, research on Bangla Sign Language
(BdSL) faces notable limitations, primarily due to the lack of datasets.
Recognizing wordlevel signs in BdSL (WL-BdSL) presents a multitude of
challenges, including the need for well-annotated datasets, capturing the
dynamic nature of sign gestures from facial or hand landmarks, developing
suitable machine learning or deep learning-based models with substantial video
samples, and so on. In this paper, we address these challenges by creating a
comprehensive BdSL word-level dataset named BdSLW60 in an unconstrained and
natural setting, allowing positional and temporal variations and allowing sign
users to change hand dominance freely. The dataset encompasses 60 Bangla sign
words, with a significant scale of 9307 video trials provided by 18 signers
under the supervision of a sign language professional. The dataset was
rigorously annotated and cross-checked by 60 annotators. We also introduced a
unique approach of a relative quantization-based key frame encoding technique
for landmark based sign gesture recognition. We report the benchmarking of our
BdSLW60 dataset using the Support Vector Machine (SVM) with testing accuracy up
to 67.6% and an attention-based bi-LSTM with testing accuracy up to 75.1%. The
dataset is available at https://www.kaggle.com/datasets/hasaniut/bdslw60 and
the code base is accessible from https://github.com/hasanssl/BdSLW60_Code.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08637" title="Abstract">arXiv:2402.08637</a> [<a href="/pdf/2402.08637" title="Download PDF">pdf</a>, <a href="/format/2402.08637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strategizing against No-Regret Learners in First-Price Auctions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rubinstein%2C+A">Aviad Rubinstein</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Junyao Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG)

</div>
<p class="mathjax">We study repeated first-price auctions and general repeated Bayesian games
between two players, where one player, the learner, employs a no-regret
learning algorithm, and the other player, the optimizer, knowing the learner's
algorithm, strategizes to maximize its own utility. For a commonly used class
of no-regret learning algorithms called mean-based algorithms, we show that (i)
in standard (i.e., full-information) first-price auctions, the optimizer cannot
get more than the Stackelberg utility -- a standard benchmark in the
literature, but (ii) in Bayesian first-price auctions, there are instances
where the optimizer can achieve much higher than the Stackelberg utility.
<br />On the other hand, Mansour et al. (2022) showed that a more sophisticated
class of algorithms called no-polytope-swap-regret algorithms are sufficient to
cap the optimizer's utility at the Stackelberg utility in any repeated Bayesian
game (including Bayesian first-price auctions), and they pose the open question
whether no-polytope-swap-regret algorithms are necessary to cap the optimizer's
utility. For general Bayesian games, under a reasonable and necessary
condition, we prove that no-polytope-swap-regret algorithms are indeed
necessary to cap the optimizer's utility and thus answer their open question.
For Bayesian first-price auctions, we give a simple improvement of the standard
algorithm for minimizing the polytope swap regret by exploiting the structure
of Bayesian first-price auctions.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08638" title="Abstract">arXiv:2402.08638</a> [<a href="/pdf/2402.08638" title="Download PDF">pdf</a>, <a href="/format/2402.08638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SemRel2024: A Collection of Semantic Textual Relatedness Datasets for 14  Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ousidhoum%2C+N">Nedjma Ousidhoum</a>, 
<a href="/search/cs?searchtype=author&query=Muhammad%2C+S+H">Shamsuddeen Hassan Muhammad</a>, 
<a href="/search/cs?searchtype=author&query=Abdalla%2C+M">Mohamed Abdalla</a>, 
<a href="/search/cs?searchtype=author&query=Abdulmumin%2C+I">Idris Abdulmumin</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+I+S">Ibrahim Said Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Ahuja%2C+S">Sanchit Ahuja</a>, 
<a href="/search/cs?searchtype=author&query=Aji%2C+A+F">Alham Fikri Aji</a>, 
<a href="/search/cs?searchtype=author&query=Araujo%2C+V">Vladimir Araujo</a>, 
<a href="/search/cs?searchtype=author&query=Ayele%2C+A+A">Abinew Ali Ayele</a>, 
<a href="/search/cs?searchtype=author&query=Baswani%2C+P">Pavan Baswani</a>, 
<a href="/search/cs?searchtype=author&query=Beloucif%2C+M">Meriem Beloucif</a>, 
<a href="/search/cs?searchtype=author&query=Biemann%2C+C">Chris Biemann</a>, 
<a href="/search/cs?searchtype=author&query=Bourhim%2C+S">Sofia Bourhim</a>, 
<a href="/search/cs?searchtype=author&query=De+Kock%2C+C">Christine De Kock</a>, 
<a href="/search/cs?searchtype=author&query=Dekebo%2C+G+S">Genet Shanko Dekebo</a>, 
<a href="/search/cs?searchtype=author&query=Hourrane%2C+O">Oumaima Hourrane</a>, 
<a href="/search/cs?searchtype=author&query=Kanumolu%2C+G">Gopichand Kanumolu</a>, 
<a href="/search/cs?searchtype=author&query=Madasu%2C+L">Lokesh Madasu</a>, 
<a href="/search/cs?searchtype=author&query=Rutunda%2C+S">Samuel Rutunda</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+M">Manish Shrivastava</a>, 
<a href="/search/cs?searchtype=author&query=Solorio%2C+T">Thamar Solorio</a>, 
<a href="/search/cs?searchtype=author&query=Surange%2C+N">Nirmal Surange</a>, 
<a href="/search/cs?searchtype=author&query=Tilaye%2C+H+G">Hailegnaw Getaneh Tilaye</a>, 
<a href="/search/cs?searchtype=author&query=Vishnubhotla%2C+K">Krishnapriya Vishnubhotla</a>, 
<a href="/search/cs?searchtype=author&query=Winata%2C+G">Genta Winata</a>, 
<a href="/search/cs?searchtype=author&query=Yimam%2C+S+M">Seid Muhie Yimam</a>, 
<a href="/search/cs?searchtype=author&query=Mohammad%2C+S+M">Saif M. Mohammad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Exploring and quantifying semantic relatedness is central to representing
language. It holds significant implications across various NLP tasks, including
offering insights into the capabilities and performance of Large Language
Models (LLMs). While earlier NLP research primarily focused on semantic
similarity, often within the English language context, we instead investigate
the broader phenomenon of semantic relatedness. In this paper, we present
SemRel, a new semantic relatedness dataset collection annotated by native
speakers across 14 languages:Afrikaans, Algerian Arabic, Amharic, English,
Hausa, Hindi, Indonesian, Kinyarwanda, Marathi, Moroccan Arabic, Modern
Standard Arabic, Punjabi, Spanish, and Telugu. These languages originate from
five distinct language families and are predominantly spoken in Africa and Asia
-- regions characterised by a relatively limited availability of NLP resources.
Each instance in the SemRel datasets is a sentence pair associated with a score
that represents the degree of semantic textual relatedness between the two
sentences. The scores are obtained using a comparative annotation framework. We
describe the data collection and annotation processes, related challenges when
building the datasets, and their impact and utility in NLP. We further report
experiments for each language and across the different languages.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08640" title="Abstract">arXiv:2402.08640</a> [<a href="/pdf/2402.08640" title="Download PDF">pdf</a>, <a href="/format/2402.08640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forecasting high-impact research topics via machine learning on evolving  knowledge graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xuemei Gu</a>, 
<a href="/search/cs?searchtype=author&query=Krenn%2C+M">Mario Krenn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, Comments welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The exponential growth in scientific publications poses a severe challenge
for human researchers. It forces attention to more narrow sub-fields, which
makes it challenging to discover new impactful research ideas and
collaborations outside one's own field. While there are ways to predict a
scientific paper's future citation counts, they need the research to be
finished and the paper written, usually assessing impact long after the idea
was conceived. Here we show how to predict the impact of onsets of ideas that
have never been published by researchers. For that, we developed a large
evolving knowledge graph built from more than 21 million scientific papers. It
combines a semantic network created from the content of the papers and an
impact network created from the historic citations of papers. Using machine
learning, we can predict the dynamic of the evolving network into the future
with high accuracy, and thereby the impact of new research directions. We
envision that the ability to predict the impact of new ideas will be a crucial
component of future artificial muses that can inspire new impactful and
interesting scientific ideas.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08643" title="Abstract">arXiv:2402.08643</a> [<a href="/pdf/2402.08643" title="Download PDF">pdf</a>, <a href="/format/2402.08643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learned Image Compression with Text Quality Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+C">Chih-Yu Lai</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+D">Dung Tran</a>, 
<a href="/search/cs?searchtype=author&query=Koishida%2C+K">Kazuhito Koishida</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICIP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Learned image compression has gained widespread popularity for their
efficiency in achieving ultra-low bit-rates. Yet, images containing substantial
textual content, particularly screen-content images (SCI), often suffers from
text distortion at such compressed levels. To address this, we propose to
minimize a novel text logit loss designed to quantify the disparity in text
between the original and reconstructed images, thereby improving the perceptual
quality of the reconstructed text. Through rigorous experimentation across
diverse datasets and employing state-of-the-art algorithms, our findings reveal
significant enhancements in the quality of reconstructed text upon integration
of the proposed loss function with appropriate weighting. Notably, we achieve a
Bjontegaard delta (BD) rate of -32.64% for Character Error Rate (CER) and
-28.03% for Word Error Rate (WER) on average by applying the text logit loss
for two screenshot datasets. Additionally, we present quantitative metrics
tailored for evaluating text quality in image compression tasks. Our findings
underscore the efficacy and potential applicability of our proposed text logit
loss function across various text-aware image compression contexts.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08644" title="Abstract">arXiv:2402.08644</a> [<a href="/pdf/2402.08644" title="Download PDF">pdf</a>, <a href="/format/2402.08644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tandem Transformers for Inference Efficient LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%2C+A+P">Aishwarya P S</a>, 
<a href="/search/cs?searchtype=author&query=Nair%2C+P+A">Pranav Ajit Nair</a>, 
<a href="/search/cs?searchtype=author&query=Samaga%2C+Y">Yashas Samaga</a>, 
<a href="/search/cs?searchtype=author&query=Boyd%2C+T">Toby Boyd</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sanjiv Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+P">Prateek Jain</a>, 
<a href="/search/cs?searchtype=author&query=Netrapalli%2C+P">Praneeth Netrapalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The autoregressive nature of conventional large language models (LLMs)
inherently limits inference speed, as tokens are generated sequentially. While
speculative and parallel decoding techniques attempt to mitigate this, they
face limitations: either relying on less accurate smaller models for generation
or failing to fully leverage the base LLM's representations.
<br />We introduce a novel architecture, Tandem transformers, to address these
issues. This architecture uniquely combines (1) a small autoregressive model
and (2) a large model operating in block mode (processing multiple tokens
simultaneously). The small model's predictive accuracy is substantially
enhanced by granting it attention to the large model's richer representations.
On the PaLM2 pretraining dataset, a tandem of PaLM2-Bison and PaLM2-Gecko
demonstrates a 3.3% improvement in next-token prediction accuracy over a
standalone PaLM2-Gecko, offering a 1.16x speedup compared to a PaLM2-Otter
model with comparable downstream performance. We further incorporate the tandem
model within the speculative decoding (SPEED) framework where the large model
validates tokens from the small model. This ensures that the Tandem of
PaLM2-Bison and PaLM2-Gecko achieves substantial speedup (around 1.14x faster
than using vanilla PaLM2-Gecko in SPEED) while maintaining identical downstream
task accuracy.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08645" title="Abstract">arXiv:2402.08645</a> [<a href="/pdf/2402.08645" title="Download PDF">pdf</a>, <a href="/format/2402.08645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Peeking Behind the Curtains of Residual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tunhou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+F">Feng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hai Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiran Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Arxiv Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The utilization of residual learning has become widespread in deep and
scalable neural nets. However, the fundamental principles that contribute to
the success of residual learning remain elusive, thus hindering effective
training of plain nets with depth scalability. In this paper, we peek behind
the curtains of residual learning by uncovering the "dissipating inputs"
phenomenon that leads to convergence failure in plain neural nets: the input is
gradually compromised through plain layers due to non-linearities, resulting in
challenges of learning feature representations. We theoretically demonstrate
how plain neural nets degenerate the input to random noise and emphasize the
significance of a residual connection that maintains a better lower bound of
surviving neurons as a solution. With our theoretical discoveries, we propose
"The Plain Neural Net Hypothesis" (PNNH) that identifies the internal path
across non-linear layers as the most critical part in residual learning, and
establishes a paradigm to support the training of deep plain neural nets devoid
of residual connections. We thoroughly evaluate PNNH-enabled CNN architectures
and Transformers on popular vision benchmarks, showing on-par accuracy, up to
0.3% higher training throughput, and 2x better parameter efficiency compared to
ResNets and vision Transformers.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08646" title="Abstract">arXiv:2402.08646</a> [<a href="/pdf/2402.08646" title="Download PDF">pdf</a>, <a href="/format/2402.08646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inference of Abstraction for a Unified Account of Symbolic Reasoning  from Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kido%2C+H">Hiroyuki Kido</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Inspired by empirical work in neuroscience for Bayesian approaches to brain
function, we give a unified probabilistic account of various types of symbolic
reasoning from data. We characterise them in terms of formal logic using the
classical consequence relation, an empirical consequence relation, maximal
consistent sets, maximal possible sets and maximum likelihood estimation. The
theory gives new insights into reasoning towards human-like machine
intelligence.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08648" title="Abstract">arXiv:2402.08648</a> [<a href="/pdf/2402.08648" title="Download PDF">pdf</a>, <a href="/format/2402.08648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Universal Adversarial Perturbations for Quantum Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anil%2C+G">Gautham Anil</a>, 
<a href="/search/cs?searchtype=author&query=Vinod%2C+V">Vishnu Vinod</a>, 
<a href="/search/cs?searchtype=author&query=Narayan%2C+A">Apurva Narayan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Quantum Machine Learning (QML) has emerged as a promising field of research,
aiming to leverage the capabilities of quantum computing to enhance existing
machine learning methodologies. Recent studies have revealed that, like their
classical counterparts, QML models based on Parametrized Quantum Circuits
(PQCs) are also vulnerable to adversarial attacks. Moreover, the existence of
Universal Adversarial Perturbations (UAPs) in the quantum domain has been
demonstrated theoretically in the context of quantum classifiers. In this work,
we introduce QuGAP: a novel framework for generating UAPs for quantum
classifiers. We conceptualize the notion of additive UAPs for PQC-based
classifiers and theoretically demonstrate their existence. We then utilize
generative models (QuGAP-A) to craft additive UAPs and experimentally show that
quantum classifiers are susceptible to such attacks. Moreover, we formulate a
new method for generating unitary UAPs (QuGAP-U) using quantum generative
models and a novel loss function based on fidelity constraints. We evaluate the
performance of the proposed framework and show that our method achieves
state-of-the-art misclassification rates, while maintaining high fidelity
between legitimate and adversarial samples.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08649" title="Abstract">arXiv:2402.08649</a> [<a href="/pdf/2402.08649" title="Download PDF">pdf</a>, <a href="/format/2402.08649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sharing Spectrum and Services in the 7-24 GHz Upper Midband
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Testolina%2C+P">Paolo Testolina</a>, 
<a href="/search/cs?searchtype=author&query=Polese%2C+M">Michele Polese</a>, 
<a href="/search/cs?searchtype=author&query=Melodia%2C+T">Tommaso Melodia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, 0 tables. This paper has been submitted to IEEE Communications Magazine. Copyright may change without notice
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The upper midband, spanning 7 to 24 GHz, strikes a good balance between large
bandwidths and favorable propagation environments for future 6th Generation
(6G) networks. Wireless networks in the upper midband, however, will need to
share the spectrum and safely coexist with a variety of incumbents, ranging
from radiolocation to fixed satellite services, as well as Earth exploration
and sensing. In this paper, we take the first step toward understanding the
potential and challenges associated with cellular systems between 7 and 24 GHz.
Our focus is on the enabling technologies and policies for coexistence with
established incumbents. We consider dynamic spectrum sharing solutions enabled
by programmable and adaptive cellular networks, but also the possibility of
leveraging the cellular infrastructure for incumbent services. Our
comprehensive analysis employs ray tracing and examines real-world urban
scenarios to evaluate throughput, coverage tradeoffs, and the potential impact
on incumbent services. Our findings highlight the advantages of FR-3 over FR-2
and FR-1 in terms of coverage and bandwidth, respectively. We conclude by
discussing a network architecture based on Open RAN, aimed at enabling dynamic
spectrum and service sharing.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08653" title="Abstract">arXiv:2402.08653</a> [<a href="/pdf/2402.08653" title="Download PDF">pdf</a>, <a href="/format/2402.08653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAGMAN: Stability Analysis of Graph Neural Networks on the Manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+W">Wuxinlin Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Chenhui Deng</a>, 
<a href="/search/cs?searchtype=author&query=Aghdaei%2C+A">Ali Aghdaei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiru Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhuo Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Modern graph neural networks (GNNs) can be sensitive to changes in the input
graph structure and node features, potentially resulting in unpredictable
behavior and degraded performance. In this work, we introduce a spectral
framework known as SAGMAN for examining the stability of GNNs. This framework
assesses the distance distortions that arise from the nonlinear mappings of
GNNs between the input and output manifolds: when two nearby nodes on the input
manifold are mapped (through a GNN model) to two distant ones on the output
manifold, it implies a large distance distortion and thus a poor GNN stability.
We propose a distance-preserving graph dimension reduction (GDR) approach that
utilizes spectral graph embedding and probabilistic graphical models (PGMs) to
create low-dimensional input/output graph-based manifolds for meaningful
stability analysis. Our empirical evaluations show that SAGMAN effectively
assesses the stability of each node when subjected to various edge or feature
perturbations, offering a scalable approach for evaluating the stability of
GNNs, extending to applications within recommendation systems. Furthermore, we
illustrate its utility in downstream tasks, notably in enhancing GNN stability
and facilitating adversarial targeted attacks.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08654" title="Abstract">arXiv:2402.08654</a> [<a href="/pdf/2402.08654" title="Download PDF">pdf</a>, <a href="/format/2402.08654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Continuous 3D Words for Text-to-Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+T">Ta-Ying Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Gadelha%2C+M">Matheus Gadelha</a>, 
<a href="/search/cs?searchtype=author&query=Groueix%2C+T">Thibault Groueix</a>, 
<a href="/search/cs?searchtype=author&query=Fisher%2C+M">Matthew Fisher</a>, 
<a href="/search/cs?searchtype=author&query=Mech%2C+R">Radomir Mech</a>, 
<a href="/search/cs?searchtype=author&query=Markham%2C+A">Andrew Markham</a>, 
<a href="/search/cs?searchtype=author&query=Trigoni%2C+N">Niki Trigoni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://ttchengab.github.io/continuous_3d_words">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current controls over diffusion models (e.g., through text or ControlNet) for
image generation fall short in recognizing abstract, continuous attributes like
illumination direction or non-rigid shape change. In this paper, we present an
approach for allowing users of text-to-image models to have fine-grained
control of several attributes in an image. We do this by engineering special
sets of input tokens that can be transformed in a continuous manner -- we call
them Continuous 3D Words. These attributes can, for example, be represented as
sliders and applied jointly with text prompts for fine-grained control over
image generation. Given only a single mesh and a rendering engine, we show that
our approach can be adopted to provide continuous user control over several
3D-aware attributes, including time-of-day illumination, bird wing orientation,
dollyzoom effect, and object poses. Our method is capable of conditioning image
creation with multiple Continuous 3D Words and text descriptions simultaneously
while adding no overhead to the generative process. Project Page:
https://ttchengab.github.io/continuous_3d_words
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08655" title="Abstract">arXiv:2402.08655</a> [<a href="/pdf/2402.08655" title="Download PDF">pdf</a>, <a href="/format/2402.08655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the Privacy Risk of Cross-Platform Identity Linkage using Eye  Movement Biometrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aziz%2C+S">Samantha Aziz</a>, 
<a href="/search/cs?searchtype=author&query=Komogortsev%2C+O">Oleg Komogortsev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures. This paper is set to appear in the 2023 proceedings of the IEEE International Joint Conference on Biometrics (IEEE 2023) as an accepted paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The recent emergence of ubiquitous, multi-platform eye tracking has raised
user privacy concerns over re-identification across platforms, where a person
is re-identified across multiple eye tracking-enabled platforms using
personally identifying information that is implicitly expressed through their
eye movement. We present an empirical investigation quantifying a modern eye
movement biometric model's ability to link subject identities across three
different eye tracking devices using eye movement signals from each device. We
show that a state-of-the art eye movement biometrics model demonstrates
above-chance levels of biometric performance (34.99% equal error rate, 15%
rank-1 identification rate) when linking user identities across one pair of
devices, but not for the other. Considering these findings, we also discuss the
impact that eye tracking signal quality has on the model's ability to
meaningfully associate a subject's identity between two substantially different
eye tracking devices. Our investigation advances a fundamental understanding of
the privacy risks for identity linkage across platforms by employing both
quantitative and qualitative measures of biometric performance, including a
visualization of the model's ability to distinguish genuine and imposter
authentication attempts across platforms.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08656" title="Abstract">arXiv:2402.08656</a> [<a href="/pdf/2402.08656" title="Download PDF">pdf</a>, <a href="/format/2402.08656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuroBench: An Open-Source Benchmark Framework for the Standardization  of Methodology in Brainwave-based Authentication Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaurasia%2C+A+K">Avinash Kumar Chaurasia</a> (a), 
<a href="/search/cs?searchtype=author&query=Fallahi%2C+M">Matin Fallahi</a> (b), 
<a href="/search/cs?searchtype=author&query=Strufe%2C+T">Thorsten Strufe</a> (b), 
<a href="/search/cs?searchtype=author&query=Terh%C3%B6rst%2C+P">Philipp Terh&#xf6;rst</a> (a), 
<a href="/search/cs?searchtype=author&query=Cabarcos%2C+P+A">Patricia Arias Cabarcos</a> (a and b) ((a) University of Paderborn, (b) KASTEL Security Research Labs - KIT)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 5 Figures, 3 tables, Submitted to the Journal of Information Security and Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Biometric systems based on brain activity have been proposed as an
alternative to passwords or to complement current authentication techniques. By
leveraging the unique brainwave patterns of individuals, these systems offer
the possibility of creating authentication solutions that are resistant to
theft, hands-free, accessible, and potentially even revocable. However, despite
the growing stream of research in this area, faster advance is hindered by
reproducibility problems. Issues such as the lack of standard reporting schemes
for performance results and system configuration, or the absence of common
evaluation benchmarks, make comparability and proper assessment of different
biometric solutions challenging. Further, barriers are erected to future work
when, as so often, source code is not published open access. To bridge this
gap, we introduce NeuroBench, a flexible open source tool to benchmark
brainwave-based authentication models. It incorporates nine diverse datasets,
implements a comprehensive set of pre-processing parameters and machine
learning algorithms, enables testing under two common adversary models (known
vs unknown attacker), and allows researchers to generate full performance
reports and visualizations. We use NeuroBench to investigate the shallow
classifiers and deep learning-based approaches proposed in the literature, and
to test robustness across multiple sessions. We observe a 37.6\% reduction in
Equal Error Rate (EER) for unknown attacker scenarios (typically not tested in
the literature), and we highlight the importance of session variability to
brainwave authentication. All in all, our results demonstrate the viability and
relevance of NeuroBench in streamlining fair comparisons of algorithms, thereby
furthering the advancement of brainwave-based authentication through robust
methodological practices.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08657" title="Abstract">arXiv:2402.08657</a> [<a href="/pdf/2402.08657" title="Download PDF">pdf</a>, <a href="/format/2402.08657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PIN: Positional Insert Unlocks Object Localisation Abilities in VLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dorkenwald%2C+M">Michael Dorkenwald</a>, 
<a href="/search/cs?searchtype=author&query=Barazani%2C+N">Nimrod Barazani</a>, 
<a href="/search/cs?searchtype=author&query=Snoek%2C+C+G+M">Cees G. M. Snoek</a>, 
<a href="/search/cs?searchtype=author&query=Asano%2C+Y+M">Yuki M. Asano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision-Language Models (VLMs), such as Flamingo and GPT-4V, have shown
immense potential by integrating large language models with vision systems.
Nevertheless, these models face challenges in the fundamental computer vision
task of object localisation, due to their training on multimodal data
containing mostly captions without explicit spatial grounding. While it is
possible to construct custom, supervised training pipelines with bounding box
annotations that integrate with VLMs, these result in specialized and
hard-to-scale models. In this paper, we aim to explore the limits of
caption-based VLMs and instead propose to tackle the challenge in a simpler
manner by i) keeping the weights of a caption-based VLM frozen and ii) not
using any supervised detection data. To this end, we introduce an
input-agnostic Positional Insert (PIN), a learnable spatial prompt, containing
a minimal set of parameters that are slid inside the frozen VLM, unlocking
object localisation capabilities. Our PIN module is trained with a simple
next-token prediction task on synthetic data without requiring the introduction
of new output heads. Our experiments demonstrate strong zero-shot localisation
performances on a variety of images, including Pascal VOC, COCO, LVIS, and
diverse images like paintings or cartoons.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08658" title="Abstract">arXiv:2402.08658</a> [<a href="/pdf/2402.08658" title="Download PDF">pdf</a>, <a href="/ps/2402.08658" title="Download PostScript">ps</a>, <a href="/format/2402.08658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Last JITAI? The Unreasonable Effectiveness of Large Language Models  in Issuing Just-in-Time Adaptive Interventions: Fostering Physical Activity  in a Prospective Cardiac Rehabilitation Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haag%2C+D">David Haag</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+D">Devender Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Gruber%2C+S">Sebastian Gruber</a>, 
<a href="/search/cs?searchtype=author&query=Sareban%2C+M">Mahdi Sareban</a>, 
<a href="/search/cs?searchtype=author&query=Treff%2C+G">Gunnar Treff</a>, 
<a href="/search/cs?searchtype=author&query=Niebauer%2C+J">Josef Niebauer</a>, 
<a href="/search/cs?searchtype=author&query=Bull%2C+C">Christopher Bull</a>, 
<a href="/search/cs?searchtype=author&query=Smeddinck%2C+J+D">Jan David Smeddinck</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We explored the viability of Large Language Models (LLMs) for triggering and
personalizing content for Just-in-Time Adaptive Interventions (JITAIs) in
digital health. JITAIs are being explored as a key mechanism for sustainable
behavior change, adapting interventions to an individual's current context and
needs. However, traditional rule-based and machine learning models for JITAI
implementation face scalability and reliability limitations, such as lack of
personalization, difficulty in managing multi-parametric systems, and issues
with data sparsity. To investigate JITAI implementation via LLMs, we tested the
contemporary overall performance-leading model 'GPT-4' with examples grounded
in the use case of fostering heart-healthy physical activity in outpatient
cardiac rehabilitation. Three personas and five sets of context information per
persona were used as a basis of triggering and personalizing JITAIs.
Subsequently, we generated a total of 450 proposed JITAI decisions and message
content, divided equally into JITAIs generated by 10 iterations with GPT-4, a
baseline provided by 10 laypersons (LayPs), and a gold standard set by 10
healthcare professionals (HCPs). Ratings from 27 LayPs indicated that JITAIs
generated by GPT-4 were superior to those by HCPs and LayPs over all assessed
scales: i.e., appropriateness, engagement, effectiveness, and professionality.
This study indicates that LLMs have significant potential for implementing
JITAIs as a building block of personalized or "precision" health, offering
scalability, effective personalization based on opportunistically sampled
information, and good acceptability.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08661" title="Abstract">arXiv:2402.08661</a> [<a href="/pdf/2402.08661" title="Download PDF">pdf</a>, <a href="/ps/2402.08661" title="Download PostScript">ps</a>, <a href="/format/2402.08661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multidimensional Blockchain Fees are (Essentially) Optimal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Angeris%2C+G">Guillermo Angeris</a>, 
<a href="/search/cs?searchtype=author&query=Diamandis%2C+T">Theo Diamandis</a>, 
<a href="/search/cs?searchtype=author&query=Moallemi%2C+C">Ciamac Moallemi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper we show that, using only mild assumptions, previously proposed
multidimensional blockchain fee markets are essentially optimal, even against
worst-case adversaries. In particular, we show that the average welfare gap
between the following two scenarios is at most $O(1/\sqrt{T})$, where $T$ is
the length of the time horizon considered. In the first scenario, the designer
knows all future actions by users and is allowed to fix the optimal prices of
resources ahead of time, based on the designer's oracular knowledge of those
actions. In the second, the prices are updated by a very simple algorithm that
does not have this oracular knowledge, a special case of which is similar to
EIP-1559, the base fee mechanism used by the Ethereum blockchain. Roughly
speaking, this means that, on average, over a reasonable timescale, there is no
difference in welfare between 'correctly' fixing the prices, with oracular
knowledge of the future, when compared to the proposed algorithm. We show a
matching lower bound of $\Omega(1/\sqrt{T})$ for any implementable algorithm
and also separately consider the case where the adversary is known to be
stochastic.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08662" title="Abstract">arXiv:2402.08662</a> [<a href="/pdf/2402.08662" title="Download PDF">pdf</a>, <a href="/format/2402.08662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Emergent Gaits with Decentralized Phase Oscillators: on the  role of Observations, Rewards, and Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jenny Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Heim%2C+S">Steve Heim</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+S+H">Se Hwan Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sangbae Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA 2024, 8 pages 7 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a minimal phase oscillator model for learning quadrupedal
locomotion. Each of the four oscillators is coupled only to itself and its
corresponding leg through local feedback of the ground reaction force, which
can be interpreted as an observer feedback gain. We interpret the oscillator
itself as a latent contact state-estimator. Through a systematic ablation
study, we show that the combination of phase observations, simple phase-based
rewards, and the local feedback dynamics induces policies that exhibit emergent
gait preferences, while using a reduced set of simple rewards, and without
prescribing a specific gait. The code is open-source, and a video synopsis
available at https://youtu.be/1NKQ0rSV3jU.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08666" title="Abstract">arXiv:2402.08666</a> [<a href="/pdf/2402.08666" title="Download PDF">pdf</a>, <a href="/format/2402.08666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Generalization in Semantic Parsing by Increasing Natural  Language Variation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saparina%2C+I">Irina Saparina</a>, 
<a href="/search/cs?searchtype=author&query=Lapata%2C+M">Mirella Lapata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Text-to-SQL semantic parsing has made significant progress in recent years,
with various models demonstrating impressive performance on the challenging
Spider benchmark. However, it has also been shown that these models often
struggle to generalize even when faced with small perturbations of previously
(accurately) parsed expressions. This is mainly due to the linguistic form of
questions in Spider which are overly specific, unnatural, and display limited
variation. In this work, we use data augmentation to enhance the robustness of
text-to-SQL parsers against natural language variations. Existing approaches
generate question reformulations either via models trained on Spider or only
introduce local changes. In contrast, we leverage the capabilities of large
language models to generate more realistic and diverse questions. Using only a
few prompts, we achieve a two-fold increase in the number of questions in
Spider. Training on this augmented dataset yields substantial improvements on a
range of evaluation sets, including robustness benchmarks and out-of-domain
data.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08667" title="Abstract">arXiv:2402.08667</a> [<a href="/pdf/2402.08667" title="Download PDF">pdf</a>, <a href="/format/2402.08667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Target Score Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Bortoli%2C+V">Valentin De Bortoli</a>, 
<a href="/search/cs?searchtype=author&query=Hutchinson%2C+M">Michael Hutchinson</a>, 
<a href="/search/cs?searchtype=author&query=Wirnsberger%2C+P">Peter Wirnsberger</a>, 
<a href="/search/cs?searchtype=author&query=Doucet%2C+A">Arnaud Doucet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation (stat.CO); Machine Learning (stat.ML)

</div>
<p class="mathjax">Denoising Score Matching estimates the score of a noised version of a target
distribution by minimizing a regression loss and is widely used to train the
popular class of Denoising Diffusion Models. A well known limitation of
Denoising Score Matching, however, is that it yields poor estimates of the
score at low noise levels. This issue is particularly unfavourable for problems
in the physical sciences and for Monte Carlo sampling tasks for which the score
of the clean original target is known. Intuitively, estimating the score of a
slightly noised version of the target should be a simple task in such cases. In
this paper, we address this shortcoming and show that it is indeed possible to
leverage knowledge of the target score. We present a Target Score Identity and
corresponding Target Score Matching regression loss which allows us to obtain
score estimates admitting favourable properties at low noise levels.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08670" title="Abstract">arXiv:2402.08670</a> [<a href="/pdf/2402.08670" title="Download PDF">pdf</a>, <a href="/format/2402.08670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rec-GPT4V: Multimodal Recommendation with Large Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuqing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The development of large vision-language models (LVLMs) offers the potential
to address challenges faced by traditional multimodal recommendations thanks to
their proficient understanding of static images and textual dynamics. However,
the application of LVLMs in this field is still limited due to the following
complexities: First, LVLMs lack user preference knowledge as they are trained
from vast general datasets. Second, LVLMs suffer setbacks in addressing
multiple image dynamics in scenarios involving discrete, noisy, and redundant
image sequences. To overcome these issues, we propose the novel reasoning
scheme named Rec-GPT4V: Visual-Summary Thought (VST) of leveraging large
vision-language models for multimodal recommendation. We utilize user history
as in-context user preferences to address the first challenge. Next, we prompt
LVLMs to generate item image summaries and utilize image comprehension in
natural language space combined with item titles to query the user preferences
over candidate items. We conduct comprehensive experiments across four datasets
with three LVLMs: GPT4-V, LLaVa-7b, and LLaVa-13b. The numerical results
indicate the efficacy of VST.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08671" title="Abstract">arXiv:2402.08671</a> [<a href="/pdf/2402.08671" title="Download PDF">pdf</a>, <a href="/format/2402.08671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Semi-Dense Detector-Free Methods Good at Matching Local Features?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vilain%2C+M">Matthieu Vilain</a>, 
<a href="/search/cs?searchtype=author&query=Giraud%2C+R">R&#xe9;mi Giraud</a>, 
<a href="/search/cs?searchtype=author&query=Germain%2C+H">Hugo Germain</a>, 
<a href="/search/cs?searchtype=author&query=Bourmaud%2C+G">Guillaume Bourmaud</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Semi-dense detector-free approaches (SDF), such as LoFTR, are currently among
the most popular image matching methods. While SDF methods are trained to
establish correspondences between two images, their performances are almost
exclusively evaluated using relative pose estimation metrics. Thus, the link
between their ability to establish correspondences and the quality of the
resulting estimated pose has thus far received little attention. This paper is
a first attempt to study this link. We start with proposing a novel structured
attention-based image matching architecture (SAM). It allows us to show a
counter-intuitive result on two datasets (MegaDepth and HPatches): on the one
hand SAM either outperforms or is on par with SDF methods in terms of
pose/homography estimation metrics, but on the other hand SDF approaches are
significantly better than SAM in terms of matching accuracy. We then propose to
limit the computation of the matching accuracy to textured regions, and show
that in this case SAM often surpasses SDF methods. Our findings highlight a
strong correlation between the ability to establish accurate correspondences in
textured regions and the accuracy of the resulting estimated pose/homography.
Our code will be made available.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08672" title="Abstract">arXiv:2402.08672</a> [<a href="/pdf/2402.08672" title="Download PDF">pdf</a>, <a href="/format/2402.08672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Assessment and Selection under Temporal Distribution Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+E">Elise Han</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chengpiao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kaizheng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">We investigate model assessment and selection in a changing environment, by
synthesizing datasets from both the current time period and historical epochs.
To tackle unknown and potentially arbitrary temporal distribution shift, we
develop an adaptive rolling window approach to estimate the generalization
error of a given model. This strategy also facilitates the comparison between
any two candidate models by estimating the difference of their generalization
errors. We further integrate pairwise comparisons into a single-elimination
tournament, achieving near-optimal model selection from a collection of
candidates. Theoretical analyses and numerical experiments demonstrate the
adaptivity of our proposed methods to the non-stationarity in data.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08674" title="Abstract">arXiv:2402.08674</a> [<a href="/pdf/2402.08674" title="Download PDF">pdf</a>, <a href="/format/2402.08674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Curriculum Effects Emerge with In-Context Learning in Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Russin%2C+J">Jacob Russin</a>, 
<a href="/search/cs?searchtype=author&query=Pavlick%2C+E">Ellie Pavlick</a>, 
<a href="/search/cs?searchtype=author&query=Frank%2C+M+J">Michael J. Frank</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, under review at CogSci 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Human learning is sensitive to rule-like structure and the curriculum of
examples used for training. In tasks governed by succinct rules, learning is
more robust when related examples are blocked across trials, but in the absence
of such rules, interleaving is more effective. To date, no neural model has
simultaneously captured these seemingly contradictory effects. Here we show
that this same tradeoff spontaneously emerges with "in-context learning" (ICL)
both in neural networks trained with metalearning and in large language models
(LLMs). ICL is the ability to learn new tasks "in context" - without weight
changes - via an inner-loop algorithm implemented in activation dynamics.
Experiments with pretrained LLMs and metalearning transformers show that ICL
exhibits the blocking advantage demonstrated in humans on a task involving
rule-like structure, and conversely, that concurrent in-weight learning
reproduces the interleaving advantage observed in humans on tasks lacking such
structure.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08676" title="Abstract">arXiv:2402.08676</a> [<a href="/pdf/2402.08676" title="Download PDF">pdf</a>, <a href="/format/2402.08676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Convergence Analysis of Approximate Message Passing with Non-Separable  Functions and Applications to Multi-Class Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%87akmak%2C+B">Burak &#xc7;akmak</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y+M">Yue M. Lu</a>, 
<a href="/search/cs?searchtype=author&query=Opper%2C+M">Manfred Opper</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Motivated by the recent application of approximate message passing (AMP) to
the analysis of convex optimizations in multi-class classifications [Loureiro,
et. al., 2021], we present a convergence analysis of AMP dynamics with
non-separable multivariate nonlinearities. As an application, we present a
complete (and independent) analysis of the motivated convex optimization
problem.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08678" title="Abstract">arXiv:2402.08678</a> [<a href="/pdf/2402.08678" title="Download PDF">pdf</a>, <a href="/format/2402.08678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Mamba: Towards Learning on Graphs with State Space Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Behrouz%2C+A">Ali Behrouz</a>, 
<a href="/search/cs?searchtype=author&query=Hashemi%2C+F">Farnoosh Hashemi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph Neural Networks (GNNs) have shown promising potential in graph
representation learning. The majority of GNNs define a local message-passing
mechanism, propagating information over the graph by stacking multiple layers.
These methods, however, are known to suffer from two major limitations:
over-squashing and poor capturing of long-range dependencies. Recently, Graph
Transformers (GTs) emerged as a powerful alternative to Message-Passing Neural
Networks (MPNNs). GTs, however, have quadratic computational cost, lack
inductive biases on graph structures, and rely on complex Positional/Structural
Encodings (SE/PE). In this paper, we show that while Transformers, complex
message-passing, and SE/PE are sufficient for good performance in practice,
neither is necessary. Motivated by the recent success of State Space Models
(SSMs), such as Mamba, we present Graph Mamba Networks (GMNs), a general
framework for a new class of GNNs based on selective SSMs. We discuss and
categorize the new challenges when adopting SSMs to graph-structured data, and
present four required and one optional steps to design GMNs, where we choose
(1) Neighborhood Tokenization, (2) Token Ordering, (3) Architecture of
Bidirectional Selective SSM Encoder, (4) Local Encoding, and dispensable (5) PE
and SE. We further provide theoretical justification for the power of GMNs.
Experiments demonstrate that despite much less computational cost, GMNs attain
an outstanding performance in long-range, small-scale, large-scale, and
heterophilic benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08679" title="Abstract">arXiv:2402.08679</a> [<a href="/pdf/2402.08679" title="Download PDF">pdf</a>, <a href="/format/2402.08679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xingang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Fangxu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+L">Lianhui Qin</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Bin Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Jailbreaks on Large language models (LLMs) have recently received increasing
attention. For a comprehensive assessment of LLM safety, it is essential to
consider jailbreaks with diverse attributes, such as contextual coherence and
sentiment/stylistic variations, and hence it is beneficial to study
controllable jailbreaking, i.e. how to enforce control on LLM attacks. In this
paper, we formally formulate the controllable attack generation problem, and
build a novel connection between this problem and controllable text generation,
a well-explored topic of natural language processing. Based on this connection,
we adapt the Energy-based Constrained Decoding with Langevin Dynamics (COLD), a
state-of-the-art, highly efficient algorithm in controllable text generation,
and introduce the COLD-Attack framework which unifies and automates the search
of adversarial LLM attacks under a variety of control requirements such as
fluency, stealthiness, sentiment, and left-right-coherence. The controllability
enabled by COLD-Attack leads to diverse new jailbreak scenarios which not only
cover the standard setting of generating fluent suffix attacks, but also allow
us to address new controllable attack settings such as revising a user query
adversarially with minimal paraphrasing, and inserting stealthy attacks in
context with left-right-coherence. Our extensive experiments on various LLMs
(Llama-2, Mistral, Vicuna, Guanaco, GPT-3.5) show COLD-Attack's broad
applicability, strong controllability, high success rate, and attack
transferability. Our code is available at
https://github.com/Yu-Fangxu/COLD-Attack.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08680" title="Abstract">arXiv:2402.08680</a> [<a href="/pdf/2402.08680" title="Download PDF">pdf</a>, <a href="/format/2402.08680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Object Hallucination in Large Vision-Language Models via  Classifier-Free Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Linxi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yihe Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weitong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Quanquan Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 20 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The advancement of Large Vision-Language Models (LVLMs) has increasingly
highlighted the critical issue of their tendency to hallucinate non-existing
objects in the images. To address this issue, previous works focused on using
specially curated datasets or powerful LLMs (e.g., GPT-3.5) to rectify the
outputs of LVLMs. However, these approaches require either expensive
training/fine-tuning or API access to advanced LLMs to correct the model's
output post-generation. In this paper, we tackle this challenge by introducing
a framework called Mitigating hallucinAtion via classifieR-Free guIdaNcE
(MARINE), which is both training-free and API-free, and can effectively and
efficiently reduce object hallucinations during the generation process.
Specifically, MARINE enriches the visual context of LVLMs by integrating
existing open-source vision models, and employs classifier-free guidance to
incorporate the additional object grounding features to improve the precision
of LVLMs' generations. Through comprehensive evaluations across $6$ popular
LVLMs with diverse evaluation metrics, we demonstrate the effectiveness of
MARINE, which even outperforms existing fine-tuning-based methods. Remarkably,
it not only reduces hallucinations but also improves the detailedness of LVLMs'
generations, as assessed by GPT-4V.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08682" title="Abstract">arXiv:2402.08682</a> [<a href="/pdf/2402.08682" title="Download PDF">pdf</a>, <a href="/format/2402.08682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IM-3D: Iterative Multiview Diffusion and Reconstruction for High-Quality  3D Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Melas-Kyriazi%2C+L">Luke Melas-Kyriazi</a>, 
<a href="/search/cs?searchtype=author&query=Laina%2C+I">Iro Laina</a>, 
<a href="/search/cs?searchtype=author&query=Rupprecht%2C+C">Christian Rupprecht</a>, 
<a href="/search/cs?searchtype=author&query=Neverova%2C+N">Natalia Neverova</a>, 
<a href="/search/cs?searchtype=author&query=Vedaldi%2C+A">Andrea Vedaldi</a>, 
<a href="/search/cs?searchtype=author&query=Gafni%2C+O">Oran Gafni</a>, 
<a href="/search/cs?searchtype=author&query=Kokkinos%2C+F">Filippos Kokkinos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Most text-to-3D generators build upon off-the-shelf text-to-image models
trained on billions of images. They use variants of Score Distillation Sampling
(SDS), which is slow, somewhat unstable, and prone to artifacts. A mitigation
is to fine-tune the 2D generator to be multi-view aware, which can help
distillation or can be combined with reconstruction networks to output 3D
objects directly. In this paper, we further explore the design space of
text-to-3D models. We significantly improve multi-view generation by
considering video instead of image generators. Combined with a 3D
reconstruction algorithm which, by using Gaussian splatting, can optimize a
robust image-based loss, we directly produce high-quality 3D outputs from the
generated views. Our new method, IM-3D, reduces the number of evaluations of
the 2D generator network 10-100x, resulting in a much more efficient pipeline,
better quality, fewer geometric inconsistencies, and higher yield of usable 3D
assets.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Wed, 14 Feb 24</h3>
<dl>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07948" title="Abstract">arXiv:2402.07948</a> (cross-list from q-bio.QM) [<a href="/pdf/2402.07948" title="Download PDF">pdf</a>, <a href="/ps/2402.07948" title="Download PostScript">ps</a>, <a href="/format/2402.07948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> evolSOM: an R Package for evolutionary conservation analysis with SOMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Prochetto%2C+S">Santiago Prochetto</a>, 
<a href="/search/q-bio?searchtype=author&query=Reinheimer%2C+R">Renata Reinheimer</a>, 
<a href="/search/q-bio?searchtype=author&query=Stegmayer%2C+G">Georgina Stegmayer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Populations and Evolution (q-bio.PE)

</div>
<p class="mathjax">Motivation: Unraveling the connection between genes and traits is crucial for
solving many biological puzzles. Genes provide instructions for building
cellular machinery, directing the processes that sustain life. RNA molecules
and proteins, derived from these genetic instructions, play crucial roles in
shaping cell structures, influencing reactions, and guiding behavior. This
fundamental biological principle links genetic makeup to observable traits, but
integrating and extracting meaningful relationships from this complex,
multimodal data presents a significant challenge. Results: We introduce
evolSOM, a novel R package that utilizes Self-Organizing Maps (SOMs) to explore
and visualize the conservation of biological variables, easing the integration
of phenotypic and genotypic attributes. By constructing species-specific or
condition-specific SOMs that capture non-redundant patterns, evolSOM allows the
analysis of displacement of biological variables between species or conditions.
Variables displaced together suggest membership in the same regulatory network,
and the nature of the displacement may hold biological significance. The
package automatically calculates and graphically presents these displacements,
enabling efficient comparison and revealing conserved and displaced variables.
The package facilitates the integration of diverse phenotypic data types,
enabling the exploration of potential gene drivers underlying observed
phenotypic changes. Its user-friendly interface and visualization capabilities
enhance the accessibility of complex network analyses. Illustratively, we
employed evolSOM to study the displacement of genes and phenotypic traits,
successfully identifying potential drivers of phenotypic differentiation in
grass leaves. Availability: The package is open-source and is available at
https://github.com/sanprochetto/evolSOM.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07949" title="Abstract">arXiv:2402.07949</a> (cross-list from q-bio.QM) [<a href="/pdf/2402.07949" title="Download PDF">pdf</a>, <a href="/format/2402.07949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing the Design of an Artificial Pancreas to Improve Diabetes  Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Khanna%2C+A">Ashok Khanna</a>, 
<a href="/search/q-bio?searchtype=author&query=Francon%2C+O">Olivier Francon</a>, 
<a href="/search/q-bio?searchtype=author&query=Miikkulainen%2C+R">Risto Miikkulainen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Diabetes, a chronic condition that impairs how the body turns food into
energy, i.e. blood glucose, affects 38 million people in the US alone. The
standard treatment is to supplement carbohydrate intake with an artificial
pancreas, i.e. a continuous insulin pump (basal shots), as well as occasional
insulin injections (bolus shots). The goal of the treatment is to keep blood
glucose at the center of an acceptable range, as measured through a continuous
glucose meter. A secondary goal is to minimize injections, which are unpleasant
and difficult for some patients to implement. In this study, neuroevolution was
used to discover an optimal strategy for the treatment. Based on a dataset of
30 days of treatment and measurements of a single patient, a random forest was
first trained to predict future glucose levels. A neural network was then
evolved to prescribe carbohydrates, basal pumping levels, and bolus injections.
Evolution discovered a Pareto front that reduced deviation from the target and
number of injections compared to the original data, thus improving patients'
quality of life. To make the system easier to adopt, a language interface was
developed with a large language model. Thus, these technologies not only
improve patient care but also adoption in a broader population.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07955" title="Abstract">arXiv:2402.07955</a> (cross-list from q-bio.BM) [<a href="/pdf/2402.07955" title="Download PDF">pdf</a>, <a href="/format/2402.07955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProtIR: Iterative Refinement between Retrievers and Predictors for  Protein Function Annotation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+Z">Zuobai Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Lu%2C+J">Jiarui Lu</a>, 
<a href="/search/q-bio?searchtype=author&query=Chenthamarakshan%2C+V">Vijil Chenthamarakshan</a>, 
<a href="/search/q-bio?searchtype=author&query=Lozano%2C+A">Aur&#xe9;lie Lozano</a>, 
<a href="/search/q-bio?searchtype=author&query=Das%2C+P">Payel Das</a>, 
<a href="/search/q-bio?searchtype=author&query=Tang%2C+J">Jian Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Protein function annotation is an important yet challenging task in biology.
Recent deep learning advancements show significant potential for accurate
function prediction by learning from protein sequences and structures.
Nevertheless, these predictor-based methods often overlook the modeling of
protein similarity, an idea commonly employed in traditional approaches using
sequence or structure retrieval tools. To fill this gap, we first study the
effect of inter-protein similarity modeling by benchmarking retriever-based
methods against predictors on protein function annotation tasks. Our results
show that retrievers can match or outperform predictors without large-scale
pre-training. Building on these insights, we introduce a novel variational
pseudo-likelihood framework, ProtIR, designed to improve function predictors by
incorporating inter-protein similarity modeling. This framework iteratively
refines knowledge between a function predictor and retriever, thereby combining
the strengths of both predictors and retrievers. ProtIR showcases around 10%
improvement over vanilla predictor-based methods. Besides, it achieves
performance on par with protein language model-based methods, yet without the
need for massive pre-training, highlighting the efficacy of our framework. Code
will be released upon acceptance.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07975" title="Abstract">arXiv:2402.07975</a> (cross-list from quant-ph) [<a href="/pdf/2402.07975" title="Download PDF">pdf</a>, <a href="/ps/2402.07975" title="Download PostScript">ps</a>, <a href="/format/2402.07975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational complexity of isometric tensor network states
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Malz%2C+D">Daniel Malz</a>, 
<a href="/search/quant-ph?searchtype=author&query=Trivedi%2C+R">Rahul Trivedi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Comments welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">We determine the computational power of isometric tensor network states
(isoTNS), a variational ansatz originally developed to numerically find and
compute properties of gapped ground states and topological states in two
dimensions. By mapping 2D isoTNS to 1+1D unitary quantum circuits, we find that
computing local expectation values in isoTNS is $\textsf{BQP}$-complete. We
then introduce injective isoTNS, which are those isoTNS that are the unique
ground states of frustration-free Hamiltonians, and which are characterized by
an injectivity parameter $\delta\in(0,1/D]$, where $D$ is the bond dimension of
the isoTNS. We show that injectivity necessarily adds depolarizing noise to the
circuit at a rate $\eta=\delta^2D^2$. We show that weakly injective isoTNS
(small $\delta$) are still $\textsf{BQP}$-complete, but that there exists an
efficient classical algorithm to compute local expectation values in strongly
injective isoTNS ($\eta\geq0.41$). Sampling from isoTNS corresponds to
monitored quantum dynamics and we exhibit a family of isoTNS that undergo a
phase transition from a hard regime to an easy phase where the monitored
circuit can be sampled efficiently. Our results can be used to design provable
algorithms to contract isoTNS. Our mapping between ground states of certain
frustration-free Hamiltonians to open circuit dynamics in one dimension fewer
may be of independent interest.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08001" title="Abstract">arXiv:2402.08001</a> (cross-list from hep-ph) [<a href="/pdf/2402.08001" title="Download PDF">pdf</a>, <a href="/format/2402.08001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improvement and generalization of ABCD method with Bayesian inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ph?searchtype=author&query=Alvarez%2C+E">Ezequiel Alvarez</a>, 
<a href="/search/hep-ph?searchtype=author&query=Da+Rold%2C+L">Leandro Da Rold</a>, 
<a href="/search/hep-ph?searchtype=author&query=Szewc%2C+M">Manuel Szewc</a>, 
<a href="/search/hep-ph?searchtype=author&query=Szynkman%2C+A">Alejandro Szynkman</a>, 
<a href="/search/hep-ph?searchtype=author&query=Tanco%2C+S+A">Santiago A. Tanco</a>, 
<a href="/search/hep-ph?searchtype=author&query=Tarutina%2C+T">Tatiana Tarutina</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Phenomenology (hep-ph)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex)

</div>
<p class="mathjax">To find New Physics or to refine our knowledge of the Standard Model at the
LHC is an enterprise that involves many factors. We focus on taking advantage
of available information and pour our effort in re-thinking the usual
data-driven ABCD method to improve it and to generalize it using Bayesian
Machine Learning tools. We propose that a dataset consisting of a signal and
many backgrounds is well described through a mixture model. Signal, backgrounds
and their relative fractions in the sample can be well extracted by exploiting
the prior knowledge and the dependence between the different observables at the
event-by-event level with Bayesian tools. We show how, in contrast to the ABCD
method, one can take advantage of understanding some properties of the
different backgrounds and of having more than two independent observables to
measure in each event. In addition, instead of regions defined through hard
cuts, the Bayesian framework uses the information of continuous distribution to
obtain soft-assignments of the events which are statistically more robust. To
compare both methods we use a toy problem inspired by $pp\to hh\to b\bar b b
\bar b$, selecting a reduced and simplified number of processes and analysing
the flavor of the four jets and the invariant mass of the jet-pairs, modeled
with simplified distributions. Taking advantage of all this information, and
starting from a combination of biased and agnostic priors, leads us to a very
good posterior once we use the Bayesian framework to exploit the data and the
mutual information of the observables at the event-by-event level. We show how,
in this simplified model, the Bayesian framework outperforms the ABCD method
sensitivity in obtaining the signal fraction in scenarios with $1\%$ and
$0.5\%$ true signal fractions in the dataset. We also show that the method is
robust against the absence of signal.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08012" title="Abstract">arXiv:2402.08012</a> (cross-list from math.ST) [<a href="/pdf/2402.08012" title="Download PDF">pdf</a>, <a href="/ps/2402.08012" title="Download PostScript">ps</a>, <a href="/format/2402.08012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Differentially Private Synthetic Data Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=He%2C+Y">Yiyun He</a>, 
<a href="/search/math?searchtype=author&query=Vershynin%2C+R">Roman Vershynin</a>, 
<a href="/search/math?searchtype=author&query=Zhu%2C+Y">Yizhe Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG); Probability (math.PR)

</div>
<p class="mathjax">We present a polynomial-time algorithm for online differentially private
synthetic data generation. For a data stream within the hypercube $[0,1]^d$ and
an infinite time horizon, we develop an online algorithm that generates a
differentially private synthetic dataset at each time $t$. This algorithm
achieves a near-optimal accuracy bound of $O(t^{-1/d}\log(t))$ for $d\geq 2$
and $O(t^{-1}\log^{4.5}(t))$ for $d=1$ in the 1-Wasserstein distance. This
result generalizes the previous work on the continual release model for
counting queries to include Lipschitz queries. Compared to the offline case,
where the entire dataset is available at once, our approach requires only an
extra polylog factor in the accuracy bound.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08055" title="Abstract">arXiv:2402.08055</a> (cross-list from quant-ph) [<a href="/pdf/2402.08055" title="Download PDF">pdf</a>, <a href="/format/2402.08055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Quantum Algorithm Based Heuristic to Hide Sensitive Itemsets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ghoshal%2C+A">Abhijeet Ghoshal</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+Y">Yan Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Menon%2C+S">Syam Menon</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sarkar%2C+S">Sumit Sarkar</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Workshop on Information Technologies and Systems WITS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Quantum devices use qubits to represent information, which allows them to
exploit important properties from quantum physics, specifically superposition
and entanglement. As a result, quantum computers have the potential to
outperform the most advanced classical computers. In recent years, quantum
algorithms have shown hints of this promise, and many algorithms have been
proposed for the quantum domain. There are two key hurdles to solving difficult
real-world problems on quantum computers. The first is on the hardware front --
the number of qubits in the most advanced quantum systems is too small to make
the solution of large problems practical. The second involves the algorithms
themselves -- as quantum computers use qubits, the algorithms that work there
are fundamentally different from those that work on traditional computers. As a
result of these constraints, research has focused on developing approaches to
solve small versions of problems as proofs of concept -- recognizing that it
would be possible to scale these up once quantum devices with enough qubits
become available. Our objective in this paper is along the same lines. We
present a quantum approach to solve a well-studied problem in the context of
data sharing. This heuristic uses the well-known Quantum Approximate
Optimization Algorithm (QAOA). We present results on experiments involving
small datasets to illustrate how the problem could be solved using quantum
algorithms. The results show that the method has potential and provide answers
close to optimal. At the same time, we realize there are opportunities for
improving the method further.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08075" title="Abstract">arXiv:2402.08075</a> (cross-list from q-bio.GN) [<a href="/pdf/2402.08075" title="Download PDF">pdf</a>, <a href="/format/2402.08075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient and Scalable Fine-Tune of Language Models for Genome  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Zhan%2C+H">Huixin Zhan</a>, 
<a href="/search/q-bio?searchtype=author&query=Wu%2C+Y+N">Ying Nian Wu</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+Z">Zijun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Although DNA foundation models have advanced the understanding of genomes,
they still face significant challenges in the limited scale and diversity of
genomic data. This limitation starkly contrasts with the success of natural
language foundation models, which thrive on substantially larger scales.
Furthermore, genome understanding involves numerous downstream genome
annotation tasks with inherent data heterogeneity, thereby necessitating more
efficient and robust fine-tuning methods tailored for genomics. Here, we
present \textsc{Lingo}: \textsc{L}anguage prefix f\textsc{In}e-tuning for
\textsc{G}en\textsc{O}mes. Unlike DNA foundation models, \textsc{Lingo}
strategically leverages natural language foundation models' contextual cues,
recalibrating their linguistic knowledge to genomic sequences. \textsc{Lingo}
further accommodates numerous, heterogeneous downstream fine-tune tasks by an
adaptive rank sampling method that prunes and stochastically reintroduces
pruned singular vectors within small computational budgets. Adaptive rank
sampling outperformed existing fine-tuning methods on all benchmarked 14 genome
understanding tasks, while requiring fewer than 2\% of trainable parameters as
genomic-specific adapters. Impressively, applying these adapters on natural
language foundation models matched or even exceeded the performance of DNA
foundation models. \textsc{Lingo} presents a new paradigm of efficient and
scalable genome understanding via genomic-specific adapters on language models.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08077" title="Abstract">arXiv:2402.08077</a> (cross-list from stat.ML) [<a href="/pdf/2402.08077" title="Download PDF">pdf</a>, <a href="/format/2402.08077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffeomorphic Measure Matching with Kernels for Generative Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Pandey%2C+B">Biraj Pandey</a>, 
<a href="/search/stat?searchtype=author&query=Hosseini%2C+B">Bamdad Hosseini</a>, 
<a href="/search/stat?searchtype=author&query=Batlle%2C+P">Pau Batlle</a>, 
<a href="/search/stat?searchtype=author&query=Owhadi%2C+H">Houman Owhadi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS); Computation (stat.CO)

</div>
<p class="mathjax">This article presents a general framework for the transport of probability
measures towards minimum divergence generative modeling and sampling using
ordinary differential equations (ODEs) and Reproducing Kernel Hilbert Spaces
(RKHSs), inspired by ideas from diffeomorphic matching and image registration.
A theoretical analysis of the proposed method is presented, giving a priori
error bounds in terms of the complexity of the model, the number of samples in
the training set, and model misspecification. An extensive suite of numerical
experiments further highlights the properties, strengths, and weaknesses of the
method and extends its applicability to other tasks, such as conditional
simulation and inference.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08082" title="Abstract">arXiv:2402.08082</a> (cross-list from stat.ML) [<a href="/pdf/2402.08082" title="Download PDF">pdf</a>, <a href="/ps/2402.08082" title="Download PostScript">ps</a>, <a href="/format/2402.08082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Score-based generative models break the curse of dimensionality in  learning a family of sub-Gaussian probability distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cole%2C+F">Frank Cole</a>, 
<a href="/search/stat?searchtype=author&query=Lu%2C+Y">Yulong Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, to appear in the proceedings of 12th International Conference on Learning Representations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">While score-based generative models (SGMs) have achieved remarkable success
in enormous image generation tasks, their mathematical foundations are still
limited. In this paper, we analyze the approximation and generalization of SGMs
in learning a family of sub-Gaussian probability distributions. We introduce a
notion of complexity for probability distributions in terms of their relative
density with respect to the standard Gaussian measure. We prove that if the
log-relative density can be locally approximated by a neural network whose
parameters can be suitably bounded, then the distribution generated by
empirical score matching approximates the target distribution in total
variation with a dimension-independent rate. We illustrate our theory through
examples, which include certain mixtures of Gaussians. An essential ingredient
of our proof is to derive a dimension-free deep neural network approximation
rate for the true score function associated with the forward process, which is
interesting in its own right.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08095" title="Abstract">arXiv:2402.08095</a> (cross-list from stat.ML) [<a href="/pdf/2402.08095" title="Download PDF">pdf</a>, <a href="/ps/2402.08095" title="Download PostScript">ps</a>, <a href="/format/2402.08095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence Analysis of Discrete Diffusion Model: Exact Implementation  through Uniformization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chen%2C+H">Hongrui Chen</a>, 
<a href="/search/stat?searchtype=author&query=Ying%2C+L">Lexing Ying</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion models have achieved huge empirical success in data generation
tasks. Recently, some efforts have been made to adapt the framework of
diffusion models to discrete state space, providing a more natural approach for
modeling intrinsically discrete data, such as language and graphs. This is
achieved by formulating both the forward noising process and the corresponding
reversed process as Continuous Time Markov Chains (CTMCs). In this paper, we
investigate the theoretical properties of the discrete diffusion model.
Specifically, we introduce an algorithm leveraging the uniformization of
continuous Markov chains, implementing transitions on random time points. Under
reasonable assumptions on the learning of the discrete score function, we
derive Total Variation distance and KL divergence guarantees for sampling from
any distribution on a hypercube. Our results align with state-of-the-art
achievements for diffusion models in $\mathbb{R}^d$ and further underscore the
advantages of discrete diffusion models in comparison to the $\mathbb{R}^d$
setting.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08097" title="Abstract">arXiv:2402.08097</a> (cross-list from math.OC) [<a href="/pdf/2402.08097" title="Download PDF">pdf</a>, <a href="/ps/2402.08097" title="Download PostScript">ps</a>, <a href="/format/2402.08097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Accelerated Gradient Method for Simple Bilevel Optimization with  Convex Lower-level Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cao%2C+J">Jincheng Cao</a>, 
<a href="/search/math?searchtype=author&query=Jiang%2C+R">Ruichen Jiang</a>, 
<a href="/search/math?searchtype=author&query=Hamedani%2C+E+Y">Erfan Yazdandoost Hamedani</a>, 
<a href="/search/math?searchtype=author&query=Mokhtari%2C+A">Aryan Mokhtari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we focus on simple bilevel optimization problems, where we
minimize a convex smooth objective function over the optimal solution set of
another convex smooth constrained optimization problem. We present a novel
bilevel optimization method that locally approximates the solution set of the
lower-level problem using a cutting plane approach and employs an accelerated
gradient-based update to reduce the upper-level objective function over the
approximated solution set. We measure the performance of our method in terms of
suboptimality and infeasibility errors and provide non-asymptotic convergence
guarantees for both error criteria. Specifically, when the feasible set is
compact, we show that our method requires at most
$\mathcal{O}(\max\{1/\sqrt{\epsilon_{f}}, 1/\epsilon_g\})$ iterations to find a
solution that is $\epsilon_f$-suboptimal and $\epsilon_g$-infeasible. Moreover,
under the additional assumption that the lower-level objective satisfies the
$r$-th H\"olderian error bound, we show that our method achieves an iteration
complexity of
$\mathcal{O}(\max\{\epsilon_{f}^{-\frac{2r-1}{2r}},\epsilon_{g}^{-\frac{2r-1}{2r}}\})$,
which matches the optimal complexity of single-level convex constrained
optimization when $r=1$.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08098" title="Abstract">arXiv:2402.08098</a> (cross-list from eess.IV) [<a href="/pdf/2402.08098" title="Download PDF">pdf</a>, <a href="/format/2402.08098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Classification of Body MRI Sequence Type Using Convolutional  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Helm%2C+K">Kimberly Helm</a>, 
<a href="/search/eess?searchtype=author&query=Mathai%2C+T+S">Tejas Sudharshan Mathai</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+B">Boah Kim</a>, 
<a href="/search/eess?searchtype=author&query=Mukherjee%2C+P">Pritam Mukherjee</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jianfei Liu</a>, 
<a href="/search/eess?searchtype=author&query=Summers%2C+R+M">Ronald M. Summers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at SPIE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Multi-parametric MRI of the body is routinely acquired for the identification
of abnormalities and diagnosis of diseases. However, a standard naming
convention for the MRI protocols and associated sequences does not exist due to
wide variations in imaging practice at institutions and myriad MRI scanners
from various manufacturers being used for imaging. The intensity distributions
of MRI sequences differ widely as a result, and there also exists information
conflicts related to the sequence type in the DICOM headers. At present,
clinician oversight is necessary to ensure that the correct sequence is being
read and used for diagnosis. This poses a challenge when specific series need
to be considered for building a cohort for a large clinical study or for
developing AI algorithms. In order to reduce clinician oversight and ensure the
validity of the DICOM headers, we propose an automated method to classify the
3D MRI sequence acquired at the levels of the chest, abdomen, and pelvis. In
our pilot work, our 3D DenseNet-121 model achieved an F1 score of 99.5% at
differentiating 5 common MRI sequences obtained by three Siemens scanners
(Aera, Verio, Biograph mMR). To the best of our knowledge, we are the first to
develop an automated method for the 3D classification of MRI sequences in the
chest, abdomen, and pelvis, and our work has outperformed the previous
state-of-the-art MRI series classifiers.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08106" title="Abstract">arXiv:2402.08106</a> (cross-list from math.OC) [<a href="/pdf/2402.08106" title="Download PDF">pdf</a>, <a href="/ps/2402.08106" title="Download PostScript">ps</a>, <a href="/format/2402.08106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mirror Descent-Ascent for mean-field min-max problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lascu%2C+R">Razvan-Andrei Lascu</a>, 
<a href="/search/math?searchtype=author&query=Majka%2C+M+B">Mateusz B. Majka</a>, 
<a href="/search/math?searchtype=author&query=Szpruch%2C+%C5%81">&#x141;ukasz Szpruch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Probability (math.PR)

</div>
<p class="mathjax">We study two variants of the mirror descent-ascent algorithm for solving
min-max problems on the space of measures: simultaneous and sequential. We work
under assumptions of convexity-concavity and relative smoothness of the payoff
function with respect to a suitable Bregman divergence, defined on the space of
measures via flat derivatives. We show that the convergence rates to mixed Nash
equilibria, measured in the Nikaid\`o-Isoda error, are of order
$\mathcal{O}\left(N^{-1/2}\right)$ and $\mathcal{O}\left(N^{-2/3}\right)$ for
the simultaneous and sequential schemes, respectively, which is in line with
the state-of-the-art results for related finite-dimensional algorithms.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08108" title="Abstract">arXiv:2402.08108</a> (cross-list from econ.EM) [<a href="/pdf/2402.08108" title="Download PDF">pdf</a>, <a href="/format/2402.08108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Moving-Band Statistical Arbitrages via Convex-Concave  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Johansson%2C+K">Kasper Johansson</a>, 
<a href="/search/econ?searchtype=author&query=Schmelzer%2C+T">Thomas Schmelzer</a>, 
<a href="/search/econ?searchtype=author&query=Boyd%2C+S">Stephen Boyd</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Machine Learning (cs.LG); Portfolio Management (q-fin.PM)

</div>
<p class="mathjax">We propose a new method for finding statistical arbitrages that can contain
more assets than just the traditional pair. We formulate the problem as seeking
a portfolio with the highest volatility, subject to its price remaining in a
band and a leverage limit. This optimization problem is not convex, but can be
approximately solved using the convex-concave procedure, a specific sequential
convex programming method. We show how the method generalizes to finding
moving-band statistical arbitrages, where the price band midpoint varies over
time.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08142" title="Abstract">arXiv:2402.08142</a> (cross-list from math.OC) [<a href="/pdf/2402.08142" title="Download PDF">pdf</a>, <a href="/format/2402.08142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Size-Aware Dispatching Rules via Value Iteration and Some  Numerical Investigations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hyyti%C3%A4%2C+E">Esa Hyyti&#xe4;</a>, 
<a href="/search/math?searchtype=author&query=Righter%2C+R">Rhonda Righter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Performance (cs.PF)

</div>
<p class="mathjax">This technical report explains how optimal size-aware dispatching policies
can be determined numerically using value iteration. It also contains some
numerical examples that shed light to the nature of the optimal policies
itself. The report complements our ``Towards the Optimal Dynamic Size-aware
Dispatching'' article that will appear in Elsevier's Performance Evaluation in
2024.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08151" title="Abstract">arXiv:2402.08151</a> (cross-list from stat.ME) [<a href="/pdf/2402.08151" title="Download PDF">pdf</a>, <a href="/format/2402.08151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient-flow adaptive importance sampling for Bayesian leave one out  cross-validation for sigmoidal classification models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chang%2C+J+C">Joshua C Chang</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+X">Xiangting Li</a>, 
<a href="/search/stat?searchtype=author&query=Xu%2C+S">Shixin Xu</a>, 
<a href="/search/stat?searchtype=author&query=Yao%2C+H">Hao-Ren Yao</a>, 
<a href="/search/stat?searchtype=author&query=Porcino%2C+J">Julia Porcino</a>, 
<a href="/search/stat?searchtype=author&query=Chow%2C+C">Carson Chow</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Spectral Theory (math.SP); Statistics Theory (math.ST)

</div>
<p class="mathjax">We introduce a set of gradient-flow-guided adaptive importance sampling (IS)
transformations to stabilize Monte-Carlo approximations of point-wise leave one
out cross-validated (LOO) predictions for Bayesian classification models. One
can leverage this methodology for assessing model generalizability by for
instance computing a LOO analogue to the AIC or computing LOO ROC/PRC curves
and derived metrics like the AUROC and AUPRC. By the calculus of variations and
gradient flow, we derive two simple nonlinear single-step transformations that
utilize gradient information to shift a model's pre-trained full-data posterior
closer to the target LOO posterior predictive distributions. In doing so, the
transformations stabilize importance weights. Because the transformations
involve the gradient of the likelihood function, the resulting Monte Carlo
integral depends on Jacobian determinants with respect to the model Hessian. We
derive closed-form exact formulae for these Jacobian determinants in the cases
of logistic regression and shallow ReLU-activated artificial neural networks,
and provide a simple approximation that sidesteps the need to compute full
Hessian matrices and their spectra. We test the methodology on an $n\ll p$
dataset that is known to produce unstable LOO IS weights.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08159" title="Abstract">arXiv:2402.08159</a> (cross-list from eess.IV) [<a href="/pdf/2402.08159" title="Download PDF">pdf</a>, <a href="/format/2402.08159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Poisson flow consistency models for low-dose CT image denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hein%2C+D">Dennis Hein</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+A">Adam Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+G">Ge Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Diffusion and Poisson flow models have demonstrated remarkable success for a
wide range of generative tasks. Nevertheless, their iterative nature results in
computationally expensive sampling and the number of function evaluations (NFE)
required can be orders of magnitude larger than for single-step methods.
Consistency models are a recent class of deep generative models which enable
single-step sampling of high quality data without the need for adversarial
training. In this paper, we introduce a novel image denoising technique which
combines the flexibility afforded in Poisson flow generative models (PFGM)++
with the, high quality, single step sampling of consistency models. The
proposed method first learns a trajectory between a noise distribution and the
posterior distribution of interest by training PFGM++ in a supervised fashion.
These pre-trained PFGM++ are subsequently "distilled" into Poisson flow
consistency models (PFCM) via an updated version of consistency distillation.
We call this approach posterior sampling Poisson flow consistency models
(PS-PFCM). Our results indicate that the added flexibility of tuning the
hyperparameter D, the dimensionality of the augmentation variables in PFGM++,
allows us to outperform consistency models, a current state-of-the-art
diffusion-style model with NFE=1 on clinical low-dose CT images. Notably, PFCM
is in itself a novel family of deep generative models and we provide initial
results on the CIFAR-10 dataset.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08164" title="Abstract">arXiv:2402.08164</a> (cross-list from stat.ML) [<a href="/pdf/2402.08164" title="Download PDF">pdf</a>, <a href="/ps/2402.08164" title="Download PostScript">ps</a>, <a href="/format/2402.08164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Limitations of the Transformer Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Peng%2C+B">Binghui Peng</a>, 
<a href="/search/stat?searchtype=author&query=Narayanan%2C+S">Srini Narayanan</a>, 
<a href="/search/stat?searchtype=author&query=Papadimitriou%2C+C">Christos Papadimitriou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">What are the root causes of hallucinations in large language models (LLMs)?
We use Communication Complexity to prove that the Transformer layer is
incapable of composing functions (e.g., identify a grandparent of a person in a
genealogy) if the domains of the functions are large enough; we show through
examples that this inability is already empirically present when the domains
are quite small. We also point out that several mathematical tasks that are at
the core of the so-called compositional tasks thought to be hard for LLMs are
unlikely to be solvable by Transformers, for large enough instances and
assuming that certain well accepted conjectures in the field of Computational
Complexity are true.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08194" title="Abstract">arXiv:2402.08194</a> (cross-list from quant-ph) [<a href="/pdf/2402.08194" title="Download PDF">pdf</a>, <a href="/ps/2402.08194" title="Download PostScript">ps</a>, <a href="/format/2402.08194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On black-box separations of quantum digital signatures from pseudorandom  states
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Coladangelo%2C+A">Andrea Coladangelo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mutreja%2C+S">Saachi Mutreja</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">It is well-known that digital signatures can be constructed from one-way
functions in a black-box way. While one-way functions are essentially the
minimal assumption in classical cryptography, this is not the case in the
quantum setting. A variety of qualitatively weaker and inherently quantum
assumptions (e.g. EFI pairs, one-way state generators, and pseudorandom states)
are known to be sufficient for non-trivial quantum cryptography.
<br />While it is known that commitments, zero-knowledge proofs, and even
multiparty computation can be constructed from these assumptions, it has
remained an open question whether the same is true for quantum digital
signatures schemes (QDS). In this work, we show that there $\textit{does not}$
exist a black-box construction of a QDS scheme with classical signatures from
pseudorandom states with linear, or greater, output length. Our result
complements that of Morimae and Yamakawa (2022), who described a
$\textit{one-time}$ secure QDS scheme with classical signatures, but left open
the question of constructing a standard $\textit{multi-time}$ secure one.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08198" title="Abstract">arXiv:2402.08198</a> (cross-list from q-bio.BM) [<a href="/pdf/2402.08198" title="Download PDF">pdf</a>, <a href="/format/2402.08198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PSC-CPI: Multi-Scale Protein Sequence-Structure Contrasting for  Efficient and Generalizable Compound-Protein Interaction Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Wu%2C+L">Lirong Wu</a>, 
<a href="/search/q-bio?searchtype=author&query=Huang%2C+Y">Yufei Huang</a>, 
<a href="/search/q-bio?searchtype=author&query=Tan%2C+C">Cheng Tan</a>, 
<a href="/search/q-bio?searchtype=author&query=Gao%2C+Z">Zhangyang Gao</a>, 
<a href="/search/q-bio?searchtype=author&query=Hu%2C+B">Bozhen Hu</a>, 
<a href="/search/q-bio?searchtype=author&query=Lin%2C+H">Haitao Lin</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+Z">Zicheng Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+S+Z">Stan Z. Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Compound-Protein Interaction (CPI) prediction aims to predict the pattern and
strength of compound-protein interactions for rational drug discovery. Existing
deep learning-based methods utilize only the single modality of protein
sequences or structures and lack the co-modeling of the joint distribution of
the two modalities, which may lead to significant performance drops in complex
real-world scenarios due to various factors, e.g., modality missing and domain
shifting. More importantly, these methods only model protein sequences and
structures at a single fixed scale, neglecting more fine-grained multi-scale
information, such as those embedded in key protein fragments. In this paper, we
propose a novel multi-scale Protein Sequence-structure Contrasting framework
for CPI prediction (PSC-CPI), which captures the dependencies between protein
sequences and structures through both intra-modality and cross-modality
contrasting. We further apply length-variable protein augmentation to allow
contrasting to be performed at different scales, from the amino acid level to
the sequence level. Finally, in order to more fairly evaluate the model
generalizability, we split the test data into four settings based on whether
compounds and proteins have been observed during the training stage. Extensive
experiments have shown that PSC-CPI generalizes well in all four settings,
particularly in the more challenging ``Unseen-Both" setting, where neither
compounds nor proteins have been observed during training. Furthermore, even
when encountering a situation of modality missing, i.e., inference with only
single-modality protein data, PSC-CPI still exhibits comparable or even better
performance than previous approaches.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08201" title="Abstract">arXiv:2402.08201</a> (cross-list from stat.ML) [<a href="/pdf/2402.08201" title="Download PDF">pdf</a>, <a href="/format/2402.08201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Off-Policy Evaluation in Markov Decision Processes under Weak  Distributional Overlap
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Mehrabi%2C+M">Mohammad Mehrabi</a>, 
<a href="/search/stat?searchtype=author&query=Wager%2C+S">Stefan Wager</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 50 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Doubly robust methods hold considerable promise for off-policy evaluation in
Markov decision processes (MDPs) under sequential ignorability: They have been
shown to converge as $1/\sqrt{T}$ with the horizon $T$, to be statistically
efficient in large samples, and to allow for modular implementation where
preliminary estimation tasks can be executed using standard reinforcement
learning techniques. Existing results, however, make heavy use of a strong
distributional overlap assumption whereby the stationary distributions of the
target policy and the data-collection policy are within a bounded factor of
each other -- and this assumption is typically only credible when the state
space of the MDP is bounded. In this paper, we re-visit the task of off-policy
evaluation in MDPs under a weaker notion of distributional overlap, and
introduce a class of truncated doubly robust (TDR) estimators which we find to
perform well in this setting. When the distribution ratio of the target and
data-collection policies is square-integrable (but not necessarily bounded),
our approach recovers the large-sample behavior previously established under
strong distributional overlap. When this ratio is not square-integrable, TDR is
still consistent but with a slower-than-$1/\sqrt{T}$; furthermore, this rate of
convergence is minimax over a class of MDPs defined only using mixing
conditions. We validate our approach numerically and find that, in our
experiments, appropriate truncation plays a major role in enabling accurate
off-policy evaluation when strong distributional overlap does not hold.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08210" title="Abstract">arXiv:2402.08210</a> (cross-list from quant-ph) [<a href="/pdf/2402.08210" title="Download PDF">pdf</a>, <a href="/format/2402.08210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Computing-Enhanced Algorithm Unveils Novel Inhibitors for KRAS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Vakili%2C+M+G">Mohammad Ghazi Vakili</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gorgulla%2C+C">Christoph Gorgulla</a>, 
<a href="/search/quant-ph?searchtype=author&query=Nigam%2C+A">AkshatKumar Nigam</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bezrukov%2C+D">Dmitry Bezrukov</a>, 
<a href="/search/quant-ph?searchtype=author&query=Varoli%2C+D">Daniel Varoli</a>, 
<a href="/search/quant-ph?searchtype=author&query=Aliper%2C+A">Alex Aliper</a>, 
<a href="/search/quant-ph?searchtype=author&query=Polykovsky%2C+D">Daniil Polykovsky</a>, 
<a href="/search/quant-ph?searchtype=author&query=Das%2C+K+M+P">Krishna M. Padmanabha Das</a>, 
<a href="/search/quant-ph?searchtype=author&query=Snider%2C+J">Jamie Snider</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lyakisheva%2C+A">Anna Lyakisheva</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mansob%2C+A+H">Ardalan Hosseini Mansob</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yao%2C+Z">Zhong Yao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bitar%2C+L">Lela Bitar</a>, 
<a href="/search/quant-ph?searchtype=author&query=Radchenko%2C+E">Eugene Radchenko</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ding%2C+X">Xiao Ding</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+J">Jinxin Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Meng%2C+F">Fanye Meng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ren%2C+F">Feng Ren</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cao%2C+Y">Yudong Cao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Stagljar%2C+I">Igor Stagljar</a>, 
<a href="/search/quant-ph?searchtype=author&query=Aspuru-Guzik%2C+A">Al&#xe1;n Aspuru-Guzik</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhavoronkov%2C+A">Alex Zhavoronkov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Engineering, Finance, and Science (cs.CE); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)

</div>
<p class="mathjax">The discovery of small molecules with therapeutic potential is a
long-standing challenge in chemistry and biology. Researchers have increasingly
leveraged novel computational techniques to streamline the drug development
process to increase hit rates and reduce the costs associated with bringing a
drug to market. To this end, we introduce a quantum-classical generative model
that seamlessly integrates the computational power of quantum algorithms
trained on a 16-qubit IBM quantum computer with the established reliability of
classical methods for designing small molecules. Our hybrid generative model
was applied to designing new KRAS inhibitors, a crucial target in cancer
therapy. We synthesized 15 promising molecules during our investigation and
subjected them to experimental testing to assess their ability to engage with
the target. Notably, among these candidates, two molecules, ISM061-018-2 and
ISM061-22, each featuring unique scaffolds, stood out by demonstrating
effective engagement with KRAS. ISM061-018-2 was identified as a broad-spectrum
KRAS inhibitor, exhibiting a binding affinity to KRAS-G12D at $1.4 \mu M$.
Concurrently, ISM061-22 exhibited specific mutant selectivity, displaying
heightened activity against KRAS G12R and Q61H mutants. To our knowledge, this
work shows for the first time the use of a quantum-generative model to yield
experimentally confirmed biological hits, showcasing the practical potential of
quantum-assisted drug discovery to produce viable therapeutics. Moreover, our
findings reveal that the efficacy of distribution learning correlates with the
number of qubits utilized, underlining the scalability potential of quantum
computing resources. Overall, we anticipate our results to be a stepping stone
towards developing more advanced quantum generative models in drug discovery.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08220" title="Abstract">arXiv:2402.08220</a> (cross-list from q-bio.MN) [<a href="/pdf/2402.08220" title="Download PDF">pdf</a>, <a href="/format/2402.08220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Threshold Circuits with Void Reactions in Step Chemical  Reaction Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Anderson%2C+R">Rachel Anderson</a>, 
<a href="/search/q-bio?searchtype=author&query=Avila%2C+A">Alberto Avila</a>, 
<a href="/search/q-bio?searchtype=author&query=Fu%2C+B">Bin Fu</a>, 
<a href="/search/q-bio?searchtype=author&query=Gomez%2C+T">Timothy Gomez</a>, 
<a href="/search/q-bio?searchtype=author&query=Grizzell%2C+E">Elise Grizzell</a>, 
<a href="/search/q-bio?searchtype=author&query=Massie%2C+A">Aiden Massie</a>, 
<a href="/search/q-bio?searchtype=author&query=Mukhopadhyay%2C+G">Gourab Mukhopadhyay</a>, 
<a href="/search/q-bio?searchtype=author&query=Salinas%2C+A">Adrian Salinas</a>, 
<a href="/search/q-bio?searchtype=author&query=Schweller%2C+R">Robert Schweller</a>, 
<a href="/search/q-bio?searchtype=author&query=Tomai%2C+E">Evan Tomai</a>, 
<a href="/search/q-bio?searchtype=author&query=Wylie%2C+T">Tim Wylie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Molecular Networks (q-bio.MN)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">We introduce a new model of \emph{step} Chemical Reaction Networks (step
CRNs), motivated by the step-wise addition of materials in standard lab
procedures. Step CRNs have ordered reactants that transform into products via
reaction rules over a series of steps. We study an important subset of weak
reaction rules, \emph{void} rules, in which chemical species may only be
deleted but never changed. We demonstrate the capabilities of these simple
limited systems to simulate threshold circuits and compute functions using
various configurations of rule sizes and step constructions, and prove that
without steps, void rules are incapable of these computations, which further
motivates the step model. Additionally, we prove the coNP-completeness of
verifying if a given step CRN computes a function, holding even for $O(1)$ step
systems.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08223" title="Abstract">arXiv:2402.08223</a> (cross-list from econ.TH) [<a href="/pdf/2402.08223" title="Download PDF">pdf</a>, <a href="/ps/2402.08223" title="Download PostScript">ps</a>, <a href="/format/2402.08223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Limits of Price Discrimination Under Privacy Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Fallah%2C+A">Alireza Fallah</a>, 
<a href="/search/econ?searchtype=author&query=Jordan%2C+M+I">Michael I. Jordan</a>, 
<a href="/search/econ?searchtype=author&query=Makhdoumi%2C+A">Ali Makhdoumi</a>, 
<a href="/search/econ?searchtype=author&query=Malekian%2C+A">Azarakhsh Malekian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">We consider a producer's problem of selling a product to a continuum of
privacy-conscious consumers, where the producer can implement third-degree
price discrimination, offering different prices to different market segments.
In the absence of privacy constraints, Bergemann, Brooks, and Morris [2015]
characterize the set of all possible consumer-producer utilities, showing that
it is a triangle. We consider a privacy mechanism that provides a degree of
protection by probabilistically masking each market segment, and we establish
that the resultant set of all consumer-producer utilities forms a convex
polygon, characterized explicitly as a linear mapping of a certain
high-dimensional convex polytope into $\mathbb{R}^2$. This characterization
enables us to investigate the impact of the privacy mechanism on both producer
and consumer utilities. In particular, we establish that the privacy constraint
always hurts the producer by reducing both the maximum and minimum utility
achievable. From the consumer's perspective, although the privacy mechanism
ensures an increase in the minimum utility compared to the non-private
scenario, interestingly, it may reduce the maximum utility. Finally, we
demonstrate that increasing the privacy level does not necessarily intensify
these effects. For instance, the maximum utility for the producer or the
minimum utility for the consumer may exhibit nonmonotonic behavior in response
to an increase of the privacy level.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08233" title="Abstract">arXiv:2402.08233</a> (cross-list from q-fin.TR) [<a href="/pdf/2402.08233" title="Download PDF">pdf</a>, <a href="/ps/2402.08233" title="Download PostScript">ps</a>, <a href="/format/2402.08233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-End Policy Learning of a Statistical Arbitrage Autoencoder  Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Krause%2C+F">Fabian Krause</a>, 
<a href="/search/q-fin?searchtype=author&query=Calliess%2C+J">Jan-Peter Calliess</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Trading and Market Microstructure (q-fin.TR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In Statistical Arbitrage (StatArb), classical mean reversion trading
strategies typically hinge on asset-pricing or PCA based models to identify the
mean of a synthetic asset. Once such a (linear) model is identified, a separate
mean reversion strategy is then devised to generate a trading signal. With a
view of generalising such an approach and turning it truly data-driven, we
study the utility of Autoencoder architectures in StatArb. As a first approach,
we employ a standard Autoencoder trained on US stock returns to derive trading
strategies based on the Ornstein-Uhlenbeck (OU) process. To further enhance
this model, we take a policy-learning approach and embed the Autoencoder
network into a neural network representation of a space of portfolio trading
policies. This integration outputs portfolio allocations directly and is
end-to-end trainable by backpropagation of the risk-adjusted returns of the
neural policy. Our findings demonstrate that this innovative end-to-end policy
learning approach not only simplifies the strategy development process, but
also yields superior gross returns over its competitors illustrating the
potential of end-to-end training over classical two-stage approaches.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08235" title="Abstract">arXiv:2402.08235</a> (cross-list from eess.IV) [<a href="/pdf/2402.08235" title="Download PDF">pdf</a>, <a href="/format/2402.08235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Color Image Denoising Using The Green Channel Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kong%2C+Z">Zhaoming Kong</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+X">Xiaowei Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Noise removal in the standard RGB (sRGB) space remains a challenging task, in
that the noise statistics of real-world images can be different in R, G and B
channels. In fact, the green channel usually has twice the sampling rate in raw
data and a higher signal-to-noise ratio than red/blue ones. However, the green
channel prior (GCP) is often understated or ignored in color image denoising
since many existing approaches mainly focus on modeling the relationship among
image patches. In this paper, we propose a simple and effective one step
GCP-based image denoising (GCP-ID) method, which aims to exploit the GCP for
denoising in the sRGB space by integrating it into the classic nonlocal
transform domain denoising framework. Briefly, we first take advantage of the
green channel to guide the search of similar patches, which improves the patch
search quality and encourages sparsity in the transform domain. Then we
reformulate RGB patches into RGGB arrays to explicitly characterize the density
of green samples. The block circulant representation is utilized to capture the
cross-channel correlation and the channel redundancy. Experiments on both
synthetic and real-world datasets demonstrate the competitive performance of
the proposed GCP-ID method for the color image and video denoising tasks. The
code is available at github.com/ZhaomingKong/GCP-ID.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08252" title="Abstract">arXiv:2402.08252</a> (cross-list from eess.AS) [<a href="/pdf/2402.08252" title="Download PDF">pdf</a>, <a href="/format/2402.08252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unrestricted Global Phase Bias-Aware Single-channel Speech Enhancement  with Conformer-based Metric GAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+S">Shiqi Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Qiu%2C+Z">Zheng Qiu</a>, 
<a href="/search/eess?searchtype=author&query=Takeuchi%2C+D">Daiki Takeuchi</a>, 
<a href="/search/eess?searchtype=author&query=Harada%2C+N">Noboru Harada</a>, 
<a href="/search/eess?searchtype=author&query=Makino%2C+S">Shoji Makino</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">With the rapid development of neural networks in recent years, the ability of
various networks to enhance the magnitude spectrum of noisy speech in the
single-channel speech enhancement domain has become exceptionally outstanding.
However, enhancing the phase spectrum using neural networks is often
ineffective, which remains a challenging problem. In this paper, we found that
the human ear cannot sensitively perceive the difference between a precise
phase spectrum and a biased phase (BP) spectrum. Therefore, we propose an
optimization method of phase reconstruction, allowing freedom on the
global-phase bias instead of reconstructing the precise phase spectrum. We
applied it to a Conformer-based Metric Generative Adversarial Networks (CMGAN)
baseline model, which relaxes the existing constraints of precise phase and
gives the neural network a broader learning space. Results show that this
method achieves a new state-of-the-art performance without incurring additional
computational overhead.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08276" title="Abstract">arXiv:2402.08276</a> (cross-list from eess.IV) [<a href="/pdf/2402.08276" title="Download PDF">pdf</a>, <a href="/format/2402.08276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking U-net Skip Connections for Biomedical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wilm%2C+F">Frauke Wilm</a>, 
<a href="/search/eess?searchtype=author&query=Ammeling%2C+J">Jonas Ammeling</a>, 
<a href="/search/eess?searchtype=author&query=%C3%96ttl%2C+M">Mathias &#xd6;ttl</a>, 
<a href="/search/eess?searchtype=author&query=Fick%2C+R+H+J">Rutger H.J. Fick</a>, 
<a href="/search/eess?searchtype=author&query=Aubreville%2C+M">Marc Aubreville</a>, 
<a href="/search/eess?searchtype=author&query=Breininger%2C+K">Katharina Breininger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 9 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The U-net architecture has significantly impacted deep learning-based
segmentation of medical images. Through the integration of long-range skip
connections, it facilitated the preservation of high-resolution features.
Out-of-distribution data can, however, substantially impede the performance of
neural networks. Previous works showed that the trained network layers differ
in their susceptibility to this domain shift, e.g., shallow layers are more
affected than deeper layers. In this work, we investigate the implications of
this observation of layer sensitivity to domain shifts of U-net-style
segmentation networks. By copying features of shallow layers to corresponding
decoder blocks, these bear the risk of re-introducing domain-specific
information. We used a synthetic dataset to model different levels of data
distribution shifts and evaluated the impact on downstream segmentation
performance. We quantified the inherent domain susceptibility of each network
layer, using the Hellinger distance. These experiments confirmed the higher
domain susceptibility of earlier network layers. When gradually removing skip
connections, a decrease in domain susceptibility of deeper layers could be
observed. For downstream segmentation performance, the original U-net
outperformed the variant without any skip connections. The best performance,
however, was achieved when removing the uppermost skip connection - not only in
the presence of domain shifts but also for in-domain test data. We validated
our results on three clinical datasets - two histopathology datasets and one
magnetic resonance dataset - with performance increases of up to 10% in-domain
and 13% cross-domain when removing the uppermost skip connection.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08312" title="Abstract">arXiv:2402.08312</a> (cross-list from eess.AS) [<a href="/pdf/2402.08312" title="Download PDF">pdf</a>, <a href="/format/2402.08312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Channel-Combination Algorithms for Robust Distant Voice Activity and  Overlapped Speech Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mariotte%2C+T">Th&#xe9;o Mariotte</a>, 
<a href="/search/eess?searchtype=author&query=Larcher%2C+A">Anthony Larcher</a>, 
<a href="/search/eess?searchtype=author&query=Montr%C3%A9sor%2C+S">Silvio Montr&#xe9;sor</a>, 
<a href="/search/eess?searchtype=author&query=Thomas%2C+J">Jean-Hugh Thomas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures, accepted at IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Voice Activity Detection (VAD) and Overlapped Speech Detection (OSD) are key
pre-processing tasks for speaker diarization. In the meeting context, it is
often easier to capture speech with a distant device. This consideration
however leads to severe performance degradation. We study a unified supervised
learning framework to solve distant multi-microphone joint VAD and OSD
(VAD+OSD). This paper investigates various multi-channel VAD+OSD front-ends
that weight and combine incoming channels. We propose three algorithms based on
the Self-Attention Channel Combinator (SACC), previously proposed in the
literature. Experiments conducted on the AMI meeting corpus exhibit that
channel combination approaches bring significant VAD+OSD improvements in the
distant speech scenario. Specifically, we explore the use of learned complex
combination weights and demonstrate the benefits of such an approach in terms
of explainability. Channel combination-based VAD+OSD systems are evaluated on
the final back-end task, i.e. speaker diarization, and show significant
improvements. Finally, since multi-channel systems are trained given a fixed
array configuration, they may fail in generalizing to other array set-ups, e.g.
mismatched number of microphones. A channel-number invariant loss is proposed
to learn a unique feature representation regardless of the number of available
microphones. The evaluation conducted on mismatched array configurations
highlights the robustness of this training strategy.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08331" title="Abstract">arXiv:2402.08331</a> (cross-list from math.NT) [<a href="/pdf/2402.08331" title="Download PDF">pdf</a>, <a href="/format/2402.08331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beatty Sequences for a Quadratic Irrational: Decidability and  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Schaeffer%2C+L">Luke Schaeffer</a>, 
<a href="/search/math?searchtype=author&query=Shallit%2C+J">Jeffrey Shallit</a>, 
<a href="/search/math?searchtype=author&query=Zorcic%2C+S">Stefan Zorcic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Number Theory (math.NT)</span>; Discrete Mathematics (cs.DM); Formal Languages and Automata Theory (cs.FL); Combinatorics (math.CO); Logic (math.LO)

</div>
<p class="mathjax">Let $\alpha$ and $\beta$ belong to the same quadratic field. We show that the
inhomogeneous Beatty sequence $(\lfloor n \alpha + \beta \rfloor)_{n \geq 1}$
is synchronized, in the sense that there is a finite automaton that takes as
input the Ostrowski representations of $n$ and $y$ in parallel, and accepts if
and only if $y = \lfloor n \alpha + \beta \rfloor$. Since it is already known
that the addition relation is computable for Ostrowski representations based on
a quadratic number, a consequence is a new and rather simple proof that the
first-order logical theory of these sequences with addition is decidable. The
decision procedure is easily implemented in the free software Walnut.
<br />As an application, we show that for each $r \geq 1$ it is decidable whether
the set $\{ \lfloor n \alpha + \beta \rfloor \, : \, n \geq 1 \}$ forms an
additive basis (or asymptotic additive basis) of order $r$. Using our
techniques, we also solve some open problems of Reble and Kimberling, and give
an explicit characterization of a sequence of Hildebrand et al.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08332" title="Abstract">arXiv:2402.08332</a> (cross-list from math.CO) [<a href="/pdf/2402.08332" title="Download PDF">pdf</a>, <a href="/format/2402.08332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting $K_{2,3}$ as an induced minor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dallard%2C+C">Cl&#xe9;ment Dallard</a>, 
<a href="/search/math?searchtype=author&query=Dumas%2C+M">Ma&#xeb;l Dumas</a>, 
<a href="/search/math?searchtype=author&query=Hilaire%2C+C">Claire Hilaire</a>, 
<a href="/search/math?searchtype=author&query=Milani%C4%8D%2C+M">Martin Milani&#x10d;</a>, 
<a href="/search/math?searchtype=author&query=Perez%2C+A">Anthony Perez</a>, 
<a href="/search/math?searchtype=author&query=Trotignon%2C+N">Nicolas Trotignon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We consider a natural generalization of chordal graphs, in which every
minimal separator induces a subgraph with independence number at most $2$. Such
graphs can be equivalently defined as graphs that do not contain the complete
bipartite graph $K_{2,3}$ as an induced minor, that is, graphs from which
$K_{2,3}$ cannot be obtained by a sequence of edge contractions and vertex
deletions.
<br />We develop a polynomial-time algorithm for recognizing these graphs. Our
algorithm relies on a characterization of $K_{2,3}$-induced minor-free graphs
in terms of excluding particular induced subgraphs, called Truemper
configurations.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08344" title="Abstract">arXiv:2402.08344</a> (cross-list from stat.ML) [<a href="/pdf/2402.08344" title="Download PDF">pdf</a>, <a href="/format/2402.08344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Bias in Noisy-SGD: With Applications to Differentially Private  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sander%2C+T">Tom Sander</a>, 
<a href="/search/stat?searchtype=author&query=Sylvestre%2C+M">Maxime Sylvestre</a>, 
<a href="/search/stat?searchtype=author&query=Durmus%2C+A">Alain Durmus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Training Deep Neural Networks (DNNs) with small batches using Stochastic
Gradient Descent (SGD) yields superior test performance compared to larger
batches. The specific noise structure inherent to SGD is known to be
responsible for this implicit bias. DP-SGD, used to ensure differential privacy
(DP) in DNNs' training, adds Gaussian noise to the clipped gradients.
Surprisingly, large-batch training still results in a significant decrease in
performance, which poses an important challenge because strong DP guarantees
necessitate the use of massive batches. We first show that the phenomenon
extends to Noisy-SGD (DP-SGD without clipping), suggesting that the
stochasticity (and not the clipping) is the cause of this implicit bias, even
with additional isotropic Gaussian noise. We theoretically analyse the
solutions obtained with continuous versions of Noisy-SGD for the Linear Least
Square and Diagonal Linear Network settings, and reveal that the implicit bias
is indeed amplified by the additional noise. Thus, the performance issues of
large-batch DP-SGD training are rooted in the same underlying principles as
SGD, offering hope for potential improvements in large batch training
strategies.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08399" title="Abstract">arXiv:2402.08399</a> (cross-list from eess.SP) [<a href="/pdf/2402.08399" title="Download PDF">pdf</a>, <a href="/format/2402.08399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-based Real-time Smartphone Pose Detection for  Ultra-wideband Tagless Gate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Choi%2C+J">Junyoung Choi</a>, 
<a href="/search/eess?searchtype=author&query=Bhattacharya%2C+S">Sagnik Bhattacharya</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE GLOBECOM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">As commercial interest in proximity services increased, the development of
various wireless localization techniques was promoted. In line with this trend,
Ultra-wideband (UWB) is emerging as a promising solution that can realize
proximity services thanks to centimeter-level localization accuracy. In
addition, since the actual location of the mobile device (MD) on the human
body, called pose, affects the localization accuracy, poses are also important
to provide accurate proximity services, especially for the UWB tagless gate
(UTG). In this paper, a real-time pose detector, termed D3, is proposed to
estimate the pose of MD when users pass through UTG. D3 is based on
line-of-sight (LOS) and non-LOS (NLOS) classification using UWB channel impulse
response and utilizes the inertial measurement unit embedded in the smartphone
to estimate the pose. D3 is implemented on Samsung Galaxy Note20 Ultra (i.e.,
SMN986B) and Qorvo UWB board to show the feasibility and applicability. D3
achieved an LOS/NLOS classification accuracy of 0.984, and ultimately detected
four different poses of MD with an accuracy of 0.961 in real-time.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08412" title="Abstract">arXiv:2402.08412</a> (cross-list from stat.ML) [<a href="/pdf/2402.08412" title="Download PDF">pdf</a>, <a href="/format/2402.08412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interacting Particle Systems on Networks: joint inference of the network  and the interaction kernel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Lang%2C+Q">Quanjun Lang</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+X">Xiong Wang</a>, 
<a href="/search/stat?searchtype=author&query=Lu%2C+F">Fei Lu</a>, 
<a href="/search/stat?searchtype=author&query=Maggioni%2C+M">Mauro Maggioni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 53 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS); Statistics Theory (math.ST)

</div>
<p class="mathjax">Modeling multi-agent systems on networks is a fundamental challenge in a wide
variety of disciplines. We jointly infer the weight matrix of the network and
the interaction kernel, which determine respectively which agents interact with
which others and the rules of such interactions from data consisting of
multiple trajectories. The estimator we propose leads naturally to a non-convex
optimization problem, and we investigate two approaches for its solution: one
is based on the alternating least squares (ALS) algorithm; another is based on
a new algorithm named operator regression with alternating least squares
(ORALS). Both algorithms are scalable to large ensembles of data trajectories.
We establish coercivity conditions guaranteeing identifiability and
well-posedness. The ALS algorithm appears statistically efficient and robust
even in the small data regime but lacks performance and convergence guarantees.
The ORALS estimator is consistent and asymptotically normal under a coercivity
condition. We conduct several numerical experiments ranging from Kuramoto
particle systems on networks to opinion dynamics in leader-follower models.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08422" title="Abstract">arXiv:2402.08422</a> (cross-list from math.ST) [<a href="/pdf/2402.08422" title="Download PDF">pdf</a>, <a href="/format/2402.08422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distribution Estimation under the Infinity Norm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kontorovich%2C+A">Aryeh Kontorovich</a>, 
<a href="/search/math?searchtype=author&query=Painsky%2C+A">Amichai Painsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Distribution Estimation, Probability Estimation, Infinity Norm
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present novel bounds for estimating discrete probability distributions
under the $\ell_\infty$ norm. These are nearly optimal in various precise
senses, including a kind of instance-optimality. Our data-dependent convergence
guarantees for the maximum likelihood estimator significantly improve upon the
currently known results. A variety of techniques are utilized and innovated
upon, including Chernoff-type inequalities and empirical Bernstein bounds. We
illustrate our results in synthetic and real-world experiments. Finally, we
apply our proposed framework to a basic selective inference problem, where we
estimate the most frequent probabilities in a sample.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08425" title="Abstract">arXiv:2402.08425</a> (cross-list from stat.ML) [<a href="/pdf/2402.08425" title="Download PDF">pdf</a>, <a href="/format/2402.08425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer Operators from Batches of Unpaired Points via Entropic  Transport Kernels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Beier%2C+F">Florian Beier</a>, 
<a href="/search/stat?searchtype=author&query=Bi%2C+H">Hancheng Bi</a>, 
<a href="/search/stat?searchtype=author&query=Sarrazin%2C+C">Cl&#xe9;ment Sarrazin</a>, 
<a href="/search/stat?searchtype=author&query=Schmitzer%2C+B">Bernhard Schmitzer</a>, 
<a href="/search/stat?searchtype=author&query=Steidl%2C+G">Gabriele Steidl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS)

</div>
<p class="mathjax">In this paper, we are concerned with estimating the joint probability of
random variables $X$ and $Y$, given $N$ independent observation blocks
$(\boldsymbol{x}^i,\boldsymbol{y}^i)$, $i=1,\ldots,N$, each of $M$ samples
$(\boldsymbol{x}^i,\boldsymbol{y}^i) = \bigl((x^i_j, y^i_{\sigma^i(j)})
\bigr)_{j=1}^M$, where $\sigma^i$ denotes an unknown permutation of i.i.d.
sampled pairs $(x^i_j,y_j^i)$, $j=1,\ldots,M$. This means that the internal
ordering of the $M$ samples within an observation block is not known. We derive
a maximum-likelihood inference functional, propose a computationally tractable
approximation and analyze their properties. In particular, we prove a
$\Gamma$-convergence result showing that we can recover the true density from
empirical approximations as the number $N$ of blocks goes to infinity. Using
entropic optimal transport kernels, we model a class of hypothesis spaces of
density functions over which the inference functional can be minimized. This
hypothesis class is particularly suited for approximate inference of transfer
operators from data. We solve the resulting discrete minimization problem by a
modification of the EMML algorithm to take addional transition probability
constraints into account and prove the convergence of this algorithm.
Proof-of-concept examples demonstrate the potential of our method.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08505" title="Abstract">arXiv:2402.08505</a> (cross-list from quant-ph) [<a href="/pdf/2402.08505" title="Download PDF">pdf</a>, <a href="/format/2402.08505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Q-COSMIC: Quantum Software Metrics Based on COSMIC (ISO/IEC19761)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Valdes-Souto%2C+F">Francisco Valdes-Souto</a>, 
<a href="/search/quant-ph?searchtype=author&query=Perez-Gonzalez%2C+H+G">Hector G. Perez-Gonzalez</a>, 
<a href="/search/quant-ph?searchtype=author&query=Perez-Delgado%2C+C+A">Carlos A. Perez-Delgado</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Quantum engineering seeks to exploit quantum information to build, among
others, computing, cybersecurity, and metrology technologies. Quantum Software
Engineering (QSE) focuses on the information processing side of these
technologies. Historically, quantum (software) engineering has focused on
development in controlled research environments and 'in the small'. As the
field progresses, we should expect to see more large-scale quantum systems to
be deployed as 'real-world' products and services. An essential tool in
(classical) software engineering and development has been software size
metrics. Calculating/estimating the size of a piece of software, to be
developed or pre-existing, is an essential step in its engineering. Quantum
software will be no different. Here we introduce Q-COSMIC, a technique for
measuring the functional size of quantum software, based on the well-regarded
COSMIC standard (ISO/IEC19761) for classical software
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08508" title="Abstract">arXiv:2402.08508</a> (cross-list from stat.ML) [<a href="/pdf/2402.08508" title="Download PDF">pdf</a>, <a href="/format/2402.08508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A PAC-Bayesian Link Between Generalisation and Flat Minima
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Haddouche%2C+M">Maxime Haddouche</a>, 
<a href="/search/stat?searchtype=author&query=Viallard%2C+P">Paul Viallard</a>, 
<a href="/search/stat?searchtype=author&query=Simsekli%2C+U">Umut Simsekli</a>, 
<a href="/search/stat?searchtype=author&query=Guedj%2C+B">Benjamin Guedj</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We provide novel PAC-Bayesian generalisation bounds involving gradient norms and being interpretable under the lens of flat minima
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Modern machine learning usually involves predictors in the overparametrised
setting (number of trained parameters greater than dataset size), and their
training yield not only good performances on training data, but also good
generalisation capacity. This phenomenon challenges many theoretical results,
and remains an open problem. To reach a better understanding, we provide novel
generalisation bounds involving gradient terms. To do so, we combine the
PAC-Bayes toolbox with Poincar\'e and Log-Sobolev inequalities, avoiding an
explicit dependency on dimension of the predictor space. Our results highlight
the positive influence of \emph{flat minima} (being minima with a neighbourhood
nearly minimising the learning problem as well) on generalisation performances,
involving directly the benefits of the optimisation phase.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08521" title="Abstract">arXiv:2402.08521</a> (cross-list from eess.SP) [<a href="/pdf/2402.08521" title="Download PDF">pdf</a>, <a href="/format/2402.08521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking multi-component signal processing methods in the  time-frequency plane
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Miramont%2C+J+M">Juan M. Miramont</a>, 
<a href="/search/eess?searchtype=author&query=Bardenet%2C+R">R&#xe9;mi Bardenet</a>, 
<a href="/search/eess?searchtype=author&query=Chainais%2C+P">Pierre Chainais</a>, 
<a href="/search/eess?searchtype=author&query=Auger%2C+F">Francois Auger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Signal processing in the time-frequency plane has a long history and remains
a field of methodological innovation. For instance, detection and denoising
based on the zeros of the spectrogram have been proposed since 2015,
contrasting with a long history of focusing on larger values of the
spectrogram. Yet, unlike neighboring fields like optimization and machine
learning, time-frequency signal processing lacks widely-adopted benchmarking
tools. In this work, we contribute an open-source, Python-based toolbox termed
MCSM-Benchs for benchmarking multi-component signal analysis methods, and we
demonstrate our toolbox on three time-frequency benchmarks. First, we compare
different methods for signal detection based on the zeros of the spectrogram,
including unexplored variations of previously proposed detection tests. Second,
we compare zero-based denoising methods to both classical and novel methods
based on large values and ridges of the spectrogram. Finally, we compare the
denoising performance of these methods against typical spectrogram thresholding
strategies, in terms of post-processing artifacts commonly referred to as
musical noise. At a low level, the obtained results provide new insight on the
assessed approaches, and in particular research directions to further develop
zero-based methods. At a higher level, our benchmarks exemplify the benefits of
using a public, collaborative, common framework for benchmarking.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08536" title="Abstract">arXiv:2402.08536</a> (cross-list from math.OC) [<a href="/pdf/2402.08536" title="Download PDF">pdf</a>, <a href="/format/2402.08536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retractions on closed sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Olikier%2C+G">Guillaume Olikier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">On a manifold or a closed subset of a Euclidean vector space, a retraction
enables to move in the direction of a tangent vector while staying on the set.
Retractions are a versatile tool to perform computational tasks such as
optimization, interpolation, and numerical integration. This paper studies two
definitions of retraction on a closed subset of a Euclidean vector space, one
being weaker than the other. Specifically, it shows that, in the context of
constrained optimization, the weaker definition should be preferred as it
inherits the main property of the other while being less restrictive.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08591" title="Abstract">arXiv:2402.08591</a> (cross-list from math.FA) [<a href="/pdf/2402.08591" title="Download PDF">pdf</a>, <a href="/ps/2402.08591" title="Download PostScript">ps</a>, <a href="/format/2402.08591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Maccone-Pati Uncertainty Principle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Krishna%2C+K+M">K. Mahesh Krishna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 0 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Functional Analysis (math.FA)</span>; Information Theory (cs.IT); Mathematical Physics (math-ph)

</div>
<p class="mathjax">We show that one of the two important uncertainty principles derived by
Maccone and Pati \textit{[Phys. Rev. Lett., 2014]} can be derived for arbitrary
maps defined on subsets of $\mathcal{L}^p$ spaces for $1&lt; p&lt;\infty$. Our main
tool is the Clarkson inequalities. We also derive a nonlinear uncertainty
principle for weak parallelogram spaces and Type-p Banach spaces.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08592" title="Abstract">arXiv:2402.08592</a> (cross-list from eess.IV) [<a href="/pdf/2402.08592" title="Download PDF">pdf</a>, <a href="/ps/2402.08592" title="Download PostScript">ps</a>, <a href="/format/2402.08592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convolutional Neural Networks Towards Facial Skin Lesions Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sarshar%2C+R">Reza Sarshar</a>, 
<a href="/search/eess?searchtype=author&query=Heydari%2C+M">Mohammad Heydari</a>, 
<a href="/search/eess?searchtype=author&query=Noughabi%2C+E+A">Elham Akhondzadeh Noughabi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Facial analysis has emerged as a prominent area of research with diverse
applications, including cosmetic surgery programs, the beauty industry,
photography, and entertainment. Manipulating patient images often necessitates
professional image processing software. This study contributes by providing a
model that facilitates the detection of blemishes and skin lesions on facial
images through a convolutional neural network and machine learning approach.
The proposed method offers advantages such as simple architecture, speed and
suitability for image processing while avoiding the complexities associated
with traditional methods. The model comprises four main steps: area selection,
scanning the chosen region, lesion diagnosis, and marking the identified
lesion. Raw data for this research were collected from a reputable clinic in
Tehran specializing in skincare and beauty services. The dataset includes
administrative information, clinical data, and facial and profile images. A
total of 2300 patient images were extracted from this raw data. A software tool
was developed to crop and label lesions, with input from two treatment experts.
In the lesion preparation phase, the selected area was standardized to 50 * 50
pixels. Subsequently, a convolutional neural network model was employed for
lesion labeling. The classification model demonstrated high accuracy, with a
measure of 0.98 for healthy skin and 0.97 for lesioned skin specificity.
Internal validation involved performance indicators and cross-validation, while
external validation compared the model's performance indicators with those of
the transfer learning method using the Vgg16 deep network model. Compared to
existing studies, the results of this research showcase the efficacy and
desirability of the proposed model and methodology.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08606" title="Abstract">arXiv:2402.08606</a> (cross-list from quant-ph) [<a href="/pdf/2402.08606" title="Download PDF">pdf</a>, <a href="/format/2402.08606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arbitrary Polynomial Separations in Trainable Quantum Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Anschuetz%2C+E+R">Eric R. Anschuetz</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gao%2C+X">Xun Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent theoretical results in quantum machine learning have demonstrated a
general trade-off between the expressive power of quantum neural networks
(QNNs) and their trainability; as a corollary of these results, practical
exponential separations in expressive power over classical machine learning
models are believed to be infeasible as such QNNs take a time to train that is
exponential in the model size. We here circumvent these negative results by
constructing a hierarchy of efficiently trainable QNNs that exhibit
unconditionally provable, polynomial memory separations of arbitrary constant
degree over classical neural networks in performing a classical sequence
modeling task. Furthermore, each unit cell of the introduced class of QNNs is
computationally efficient, implementable in constant time on a quantum device.
The classical networks we prove a separation over include well-known examples
such as recurrent neural networks and Transformers. We show that quantum
contextuality is the source of the expressivity separation, suggesting that
other classical sequence learning problems with long-time correlations may be a
regime where practical advantages in quantum machine learning may exist.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08616" title="Abstract">arXiv:2402.08616</a> (cross-list from stat.ML) [<a href="/pdf/2402.08616" title="Download PDF">pdf</a>, <a href="/ps/2402.08616" title="Download PostScript">ps</a>, <a href="/format/2402.08616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adjustment Identification Distance: A gadjid for Causal Structure  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Henckel%2C+L">Leonard Henckel</a>, 
<a href="/search/stat?searchtype=author&query=W%C3%BCrtzen%2C+T">Theo W&#xfc;rtzen</a>, 
<a href="/search/stat?searchtype=author&query=Weichwald%2C+S">Sebastian Weichwald</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Evaluating graphs learned by causal discovery algorithms is difficult: The
number of edges that differ between two graphs does not reflect how the graphs
differ with respect to the identifying formulas they suggest for causal
effects. We introduce a framework for developing causal distances between
graphs which includes the structural intervention distance for directed acyclic
graphs as a special case. We use this framework to develop improved
adjustment-based distances as well as extensions to completed partially
directed acyclic graphs and causal orders. We develop polynomial-time
reachability algorithms to compute the distances efficiently. In our package
gadjid (open source at https://github.com/CausalDisco/gadjid), we provide
implementations of our distances; they are orders of magnitude faster than the
structural intervention distance and thereby provide a success metric for
causal discovery that scales to graph sizes that were previously prohibitive.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08617" title="Abstract">arXiv:2402.08617</a> (cross-list from quant-ph) [<a href="/pdf/2402.08617" title="Download PDF">pdf</a>, <a href="/format/2402.08617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demystifying Quantum Power Flow: Unveiling the Limits of Practical  Quantum Advantage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Pareek%2C+P">Parikshit Pareek</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jayakumar%2C+A">Abhijith Jayakumar</a>, 
<a href="/search/quant-ph?searchtype=author&query=Coffrin%2C+C">Carleton Coffrin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Misra%2C+S">Sidhant Misra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Quantum computers hold promise for solving problems intractable for classical
computers, especially those with high time and/or space complexity. The
reduction of the power flow (PF) problem into a linear system of equations,
allows formulation of quantum power flow (QPF) algorithms, based on quantum
linear system solving methods such as the Harrow-Hassidim-Lloyd (HHL)
algorithm. The speedup due to QPF algorithms is claimed to be exponential when
compared to classical PF solved by state-of-the-art algorithms. We investigate
the potential for practical quantum advantage (PQA) in solving QPF compared to
classical methods on gate-based quantum computers. We meticulously scrutinize
the end-to-end complexity of QPF, providing a nuanced evaluation of the
purported quantum speedup in this problem. Our analysis establishes a best-case
bound for the HHL-QPF complexity, conclusively demonstrating the absence of any
PQA in the direct current power flow (DCPF) and fast decoupled load flow (FDLF)
problem. Additionally, we establish that for potential PQA to exist it is
necessary to consider DCPF-type problems with a very narrow range of condition
number values and readout requirements.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Wed, 14 Feb 24</h3>
<dl>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1807.11110" title="Abstract">arXiv:1807.11110</a> (replaced) [<a href="/pdf/1807.11110" title="Download PDF">pdf</a>, <a href="/format/1807.11110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ROPNN: Detection of ROP Payloads Using Deep Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xusheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhisheng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haizhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yiwei Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Ping Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Minghui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peng Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2001.07026" title="Abstract">arXiv:2001.07026</a> (replaced) [<a href="/pdf/2001.07026" title="Download PDF">pdf</a>, <a href="/ps/2001.07026" title="Download PostScript">ps</a>, <a href="/format/2001.07026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging tensor kernels to reduce objective function mismatch in deep  clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Trosten%2C+D+J">Daniel J. Trosten</a>, 
<a href="/search/stat?searchtype=author&query=L%C3%B8kse%2C+S">Sigurd L&#xf8;kse</a>, 
<a href="/search/stat?searchtype=author&query=Jenssen%2C+R">Robert Jenssen</a>, 
<a href="/search/stat?searchtype=author&query=Kampffmeyer%2C+M">Michael Kampffmeyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2002.03339" title="Abstract">arXiv:2002.03339</a> (replaced) [<a href="/pdf/2002.03339" title="Download PDF">pdf</a>, <a href="/ps/2002.03339" title="Download PostScript">ps</a>, <a href="/format/2002.03339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Input Validation for Neural Networks via Runtime Local Robustness  Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiangchao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liqian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mine%2C+A">Antoine Mine</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Ji Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2002.07279" title="Abstract">arXiv:2002.07279</a> (replaced) [<a href="/pdf/2002.07279" title="Download PDF">pdf</a>, <a href="/ps/2002.07279" title="Download PostScript">ps</a>, <a href="/format/2002.07279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formal Methods: From Academia to Industrial Practice. A Travel Guide
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huisman%2C+M">Marieke Huisman</a>, 
<a href="/search/cs?searchtype=author&query=Gurov%2C+D">Dilian Gurov</a>, 
<a href="/search/cs?searchtype=author&query=Malkis%2C+A">Alexander Malkis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 0 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2007.10453" title="Abstract">arXiv:2007.10453</a> (replaced) [<a href="/pdf/2007.10453" title="Download PDF">pdf</a>, <a href="/format/2007.10453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Points2Surf: Learning Implicit Surfaces from Point Cloud Patches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Erler%2C+P">Philipp Erler</a>, 
<a href="/search/cs?searchtype=author&query=Guerrero%2C+P">Paul Guerrero</a>, 
<a href="/search/cs?searchtype=author&query=Ohrhallinger%2C+S">Stefan Ohrhallinger</a>, 
<a href="/search/cs?searchtype=author&query=Wimmer%2C+M">Michael Wimmer</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+N+J">Niloy J. Mitra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published at ECCV 2020 Repository: <a href="https://github.com/ErlerPhilipp/points2surf">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Vision -- ECCV 2020, 108--124
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2007.15788" title="Abstract">arXiv:2007.15788</a> (replaced) [<a href="/pdf/2007.15788" title="Download PDF">pdf</a>, <a href="/format/2007.15788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Low-rank Tensor Bandits for Multi-dimensional Online Decision  Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/stat?searchtype=author&query=Hao%2C+B">Botao Hao</a>, 
<a href="/search/stat?searchtype=author&query=Wen%2C+Z">Zheng Wen</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+J">Jingfei Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Sun%2C+W+W">Will Wei Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Journal of the American Statistical Association
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.04567" title="Abstract">arXiv:2108.04567</a> (replaced) [<a href="/pdf/2108.04567" title="Download PDF">pdf</a>, <a href="/format/2108.04567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust and Dexterous Dual-arm Tele-Cooperation using Adaptable Impedance  Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Babarahmati%2C+K+K">Keyhan Kouhkiloui Babarahmati</a>, 
<a href="/search/cs?searchtype=author&query=Kasaei%2C+M">Mohammadreza Kasaei</a>, 
<a href="/search/cs?searchtype=author&query=Tiseo%2C+C">Carlo Tiseo</a>, 
<a href="/search/cs?searchtype=author&query=Mistry%2C+M">Michael Mistry</a>, 
<a href="/search/cs?searchtype=author&query=Vijayakumar%2C+S">Sethu Vijayakumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.02553" title="Abstract">arXiv:2109.02553</a> (replaced) [<a href="/pdf/2109.02553" title="Download PDF">pdf</a>, <a href="/format/2109.02553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Broken-FEEC discretizations and Hodge Laplace problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Campos-Pinto%2C+M">Martin Campos-Pinto</a>, 
<a href="/search/math?searchtype=author&query=G%C3%BC%C3%A7l%C3%BC%2C+Y">Yaman G&#xfc;&#xe7;l&#xfc;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.08792" title="Abstract">arXiv:2109.08792</a> (replaced) [<a href="/pdf/2109.08792" title="Download PDF">pdf</a>, <a href="/format/2109.08792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to be Fair: A Consequentialist Approach to Equitable  Decision-Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chohlas-Wood%2C+A">Alex Chohlas-Wood</a>, 
<a href="/search/cs?searchtype=author&query=Coots%2C+M">Madison Coots</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Henry Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Brunskill%2C+E">Emma Brunskill</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+S">Sharad Goel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.13335" title="Abstract">arXiv:2109.13335</a> (replaced) [<a href="/pdf/2109.13335" title="Download PDF">pdf</a>, <a href="/ps/2109.13335" title="Download PostScript">ps</a>, <a href="/format/2109.13335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithms for matrix multiplication via sampling and opportunistic  matrix multiplication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harris%2C+D+G">David G. Harris</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ESA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.00076" title="Abstract">arXiv:2111.00076</a> (replaced) [<a href="/pdf/2111.00076" title="Download PDF">pdf</a>, <a href="/format/2111.00076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Game Transformations That Preserve Nash Equilibria or Best-Response Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tewolde%2C+E">Emanuel Tewolde</a>, 
<a href="/search/cs?searchtype=author&query=Conitzer%2C+V">Vincent Conitzer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 1 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.08217" title="Abstract">arXiv:2112.08217</a> (replaced) [<a href="/pdf/2112.08217" title="Download PDF">pdf</a>, <a href="/format/2112.08217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Forecasting with Generative Networks via Scoring Rule  Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Pacchiardi%2C+L">Lorenzo Pacchiardi</a>, 
<a href="/search/stat?searchtype=author&query=Adewoyin%2C+R">Rilwan Adewoyin</a>, 
<a href="/search/stat?searchtype=author&query=Dueben%2C+P">Peter Dueben</a>, 
<a href="/search/stat?searchtype=author&query=Dutta%2C+R">Ritabrata Dutta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.11783" title="Abstract">arXiv:2203.11783</a> (replaced) [<a href="/pdf/2203.11783" title="Download PDF">pdf</a>, <a href="/ps/2203.11783" title="Download PostScript">ps</a>, <a href="/format/2203.11783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Combinatorial Multi-Round Ascending Auction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Kasberger%2C+B">Bernhard Kasberger</a>, 
<a href="/search/econ?searchtype=author&query=Teytelboym%2C+A">Alexander Teytelboym</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.09009" title="Abstract">arXiv:2204.09009</a> (replaced) [<a href="/pdf/2204.09009" title="Download PDF">pdf</a>, <a href="/ps/2204.09009" title="Download PostScript">ps</a>, <a href="/format/2204.09009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fixed-Parameter Algorithms for the Kneser and Schrijver Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haviv%2C+I">Ishay Haviv</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages. This paper includes and extends the content of <a href="/abs/2204.06761">arXiv:2204.06761</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.09442" title="Abstract">arXiv:2205.09442</a> (replaced) [<a href="/pdf/2205.09442" title="Download PDF">pdf</a>, <a href="/format/2205.09442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Oracle-MNIST: a Dataset of Oracle Characters for Benchmarking Machine  Learning Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Weihong Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accept by Scientific Data
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.13340" title="Abstract">arXiv:2205.13340</a> (replaced) [<a href="/pdf/2205.13340" title="Download PDF">pdf</a>, <a href="/format/2205.13340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Active Learning with Noise Stability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingjian Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+P">Pengkun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yangcheng Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xueying Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Min Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chengzhong Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.09256" title="Abstract">arXiv:2206.09256</a> (replaced) [<a href="/pdf/2206.09256" title="Download PDF">pdf</a>, <a href="/format/2206.09256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multistream Gaze Estimation with Anatomical Eye Region Isolation by  Synthetic to Real Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahmud%2C+Z">Zunayed Mahmud</a>, 
<a href="/search/cs?searchtype=author&query=Hungler%2C+P">Paul Hungler</a>, 
<a href="/search/cs?searchtype=author&query=Etemad%2C+A">Ali Etemad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures, 14 tables. This work has been accepted to the IEEE Transactions on Artificial Intelligence $\copyright$ 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.09945" title="Abstract">arXiv:2206.09945</a> (replaced) [<a href="/pdf/2206.09945" title="Download PDF">pdf</a>, <a href="/ps/2206.09945" title="Download PostScript">ps</a>, <a href="/format/2206.09945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Representations of Dynamical Networks: A Coprime Factorization  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sab%C4%83u%2C+%C5%9E">&#x15e;erban Sab&#x103;u</a>, 
<a href="/search/eess?searchtype=author&query=Speril%C4%83%2C+A">Andrei Speril&#x103;</a>, 
<a href="/search/eess?searchtype=author&query=Oar%C4%83%2C+C">Cristian Oar&#x103;</a>, 
<a href="/search/eess?searchtype=author&query=Jadbabaie%2C+A">Ali Jadbabaie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.03886" title="Abstract">arXiv:2208.03886</a> (replaced) [<a href="/pdf/2208.03886" title="Download PDF">pdf</a>, <a href="/ps/2208.03886" title="Download PostScript">ps</a>, <a href="/format/2208.03886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What can we know about that which we cannot even imagine?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Wolpert%2C+D+H">David H. Wolpert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 9 pages are references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">History and Philosophy of Physics (physics.hist-ph)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.12044" title="Abstract">arXiv:2209.12044</a> (replaced) [<a href="/pdf/2209.12044" title="Download PDF">pdf</a>, <a href="/format/2209.12044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterising memory in infinite games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Casares%2C+A">Antonio Casares</a>, 
<a href="/search/cs?searchtype=author&query=Ohlmann%2C+P">Pierre Ohlmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages, 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.10677" title="Abstract">arXiv:2210.10677</a> (replaced) [<a href="/pdf/2210.10677" title="Download PDF">pdf</a>, <a href="/format/2210.10677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> List homomorphisms by deleting edges and vertices: tight complexity  bounds for bounded-treewidth graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esmer%2C+B+C">Bar&#x131;&#x15f; Can Esmer</a>, 
<a href="/search/cs?searchtype=author&query=Focke%2C+J">Jacob Focke</a>, 
<a href="/search/cs?searchtype=author&query=Marx%2C+D">D&#xe1;niel Marx</a>, 
<a href="/search/cs?searchtype=author&query=Rz%C4%85%C5%BCewski%2C+P">Pawe&#x142; Rz&#x105;&#x17c;ewski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.11025" title="Abstract">arXiv:2210.11025</a> (replaced) [<a href="/pdf/2210.11025" title="Download PDF">pdf</a>, <a href="/format/2210.11025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Double precision is not necessary for LSQR for solving discrete linear  ill-posed problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+H">Haibo Li</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Scientific Computing 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.05987" title="Abstract">arXiv:2211.05987</a> (replaced) [<a href="/pdf/2211.05987" title="Download PDF">pdf</a>, <a href="/format/2211.05987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CCPrefix: Counterfactual Contrastive Prefix-Tuning for Many-Class  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Canran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+G">Guodong Long</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+T">Tao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+C">Chongyang Tao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jing Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> has been accepted by EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14310" title="Abstract">arXiv:2211.14310</a> (replaced) [<a href="/pdf/2211.14310" title="Download PDF">pdf</a>, <a href="/format/2211.14310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient 3D Reconstruction, Streaming and Visualization of Static and  Dynamic Scene Parts for Multi-client Live-telepresence in Large-scale  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+Holland%2C+L">Leif Van Holland</a>, 
<a href="/search/cs?searchtype=author&query=Stotko%2C+P">Patrick Stotko</a>, 
<a href="/search/cs?searchtype=author&query=Krumpen%2C+S">Stefan Krumpen</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+R">Reinhard Klein</a>, 
<a href="/search/cs?searchtype=author&query=Weinmann%2C+M">Michael Weinmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The final version of record is available at <a href="https://doi.org/10.1109/ICCVW60793.2023.00460">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV) Workshops, 2023, pp. 4258-4272
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.03553" title="Abstract">arXiv:2212.03553</a> (replaced) [<a href="/pdf/2212.03553" title="Download PDF">pdf</a>, <a href="/format/2212.03553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expressiveness of SHACL Features and Extensions for Full Equality and  Disjointness Tests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bogaerts%2C+B">Bart Bogaerts</a>, 
<a href="/search/cs?searchtype=author&query=Jakubowski%2C+M">Maxime Jakubowski</a>, 
<a href="/search/cs?searchtype=author&query=Van+den+Bussche%2C+J">Jan Van den Bussche</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.06218" title="Abstract">arXiv:2212.06218</a> (replaced) [<a href="/pdf/2212.06218" title="Download PDF">pdf</a>, <a href="/format/2212.06218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparison Of Deep Object Detectors On A New Vulnerable Pedestrian  Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+D">Devansh Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Hade%2C+T">Tihitina Hade</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qing Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08678" title="Abstract">arXiv:2212.08678</a> (replaced) [<a href="/pdf/2212.08678" title="Download PDF">pdf</a>, <a href="/format/2212.08678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An in-principle super-polynomial quantum advantage for approximating  combinatorial optimization problems via computational learning theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Pirnay%2C+N">Niklas Pirnay</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ulitzsch%2C+V">Vincent Ulitzsch</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wilde%2C+F">Frederik Wilde</a>, 
<a href="/search/quant-ph?searchtype=author&query=Eisert%2C+J">Jens Eisert</a>, 
<a href="/search/quant-ph?searchtype=author&query=Seifert%2C+J">Jean-Pierre Seifert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5+15 pages, 6 figures, replaced with final version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Other Condensed Matter (cond-mat.other); Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02749" title="Abstract">arXiv:2301.02749</a> (replaced) [<a href="/pdf/2301.02749" title="Download PDF">pdf</a>, <a href="/format/2301.02749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do You Need a Hand? -- a Bimanual Robotic Dressing Assistance Scheme
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jihong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Gienger%2C+M">Michael Gienger</a>, 
<a href="/search/cs?searchtype=author&query=Franzese%2C+G">Giovanni Franzese</a>, 
<a href="/search/cs?searchtype=author&query=Kober%2C+J">Jens Kober</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03180" title="Abstract">arXiv:2301.03180</a> (replaced) [<a href="/pdf/2301.03180" title="Download PDF">pdf</a>, <a href="/format/2301.03180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subset verification and search algorithms for causal DAGs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choo%2C+D">Davin Choo</a>, 
<a href="/search/cs?searchtype=author&query=Shiragur%2C+K">Kirankumar Shiragur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted into AISTATS 2023 (<a href="https://aistats.org/aistats2023/accepted.html">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03250" title="Abstract">arXiv:2301.03250</a> (replaced) [<a href="/pdf/2301.03250" title="Download PDF">pdf</a>, <a href="/format/2301.03250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the resilience of cellular networks: how can national roaming help?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weedage%2C+L">Lotte Weedage</a>, 
<a href="/search/cs?searchtype=author&query=Rangel%2C+S">Syllas Rangel</a>, 
<a href="/search/cs?searchtype=author&query=Stegehuis%2C+C">Clara Stegehuis</a>, 
<a href="/search/cs?searchtype=author&query=Bayhan%2C+S">Suzan Bayhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 9 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Network and Service Management, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.04634" title="Abstract">arXiv:2301.04634</a> (replaced) [<a href="/pdf/2301.04634" title="Download PDF">pdf</a>, <a href="/format/2301.04634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Street-View Image Generation from a Bird&#x27;s-Eye View Layout
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Swerdlow%2C+A">Alexander Swerdlow</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Runsheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bolei Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.05352" title="Abstract">arXiv:2301.05352</a> (replaced) [<a href="/pdf/2301.05352" title="Download PDF">pdf</a>, <a href="/format/2301.05352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concentration in Gossip Opinion Dynamics over Random Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xing%2C+Y">Yu Xing</a>, 
<a href="/search/eess?searchtype=author&query=Johansson%2C+K+H">Karl Henrik Johansson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11916" title="Abstract">arXiv:2301.11916</a> (replaced) [<a href="/pdf/2301.11916" title="Download PDF">pdf</a>, <a href="/format/2301.11916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models Are Latent Variable Models: Explaining and Finding  Good Demonstrations for In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wanrong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Saxon%2C+M">Michael Saxon</a>, 
<a href="/search/cs?searchtype=author&query=Steyvers%2C+M">Mark Steyvers</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W+Y">William Yang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> code at: <a href="https://github.com/WANGXinyiLinda/concept-based-demonstration-selection">this https URL</a> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11989" title="Abstract">arXiv:2301.11989</a> (replaced) [<a href="/pdf/2301.11989" title="Download PDF">pdf</a>, <a href="/format/2301.11989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical Differentially Private Hyperparameter Tuning with Subsampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koskela%2C+A">Antti Koskela</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+T">Tejas Kulkarni</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13058" title="Abstract">arXiv:2301.13058</a> (replaced) [<a href="/pdf/2301.13058" title="Download PDF">pdf</a>, <a href="/ps/2301.13058" title="Download PostScript">ps</a>, <a href="/format/2301.13058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bilinear optimal control for the fractional Laplacian: analysis and  discretization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bersetche%2C+F">Francisco Bersetche</a>, 
<a href="/search/math?searchtype=author&query=Fuica%2C+F">Francisco Fuica</a>, 
<a href="/search/math?searchtype=author&query=Otarola%2C+E">Enrique Otarola</a>, 
<a href="/search/math?searchtype=author&query=Quero%2C+D">Daniel Quero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13139" title="Abstract">arXiv:2301.13139</a> (replaced) [<a href="/pdf/2301.13139" title="Download PDF">pdf</a>, <a href="/format/2301.13139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Framework for Policy Mirror Descent with General  Parameterization and Linear Convergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Alfano%2C+C">Carlo Alfano</a>, 
<a href="/search/stat?searchtype=author&query=Yuan%2C+R">Rui Yuan</a>, 
<a href="/search/stat?searchtype=author&query=Rebeschini%2C+P">Patrick Rebeschini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Post-conference updates
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00284" title="Abstract">arXiv:2302.00284</a> (replaced) [<a href="/pdf/2302.00284" title="Download PDF">pdf</a>, <a href="/format/2302.00284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Selective Uncertainty Propagation in Offline RL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+S+K">Sanath Kumar Krishnamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Modi%2C+S">Shrey Modi</a>, 
<a href="/search/cs?searchtype=author&query=Gangwani%2C+T">Tanmay Gangwani</a>, 
<a href="/search/cs?searchtype=author&query=Katariya%2C+S">Sumeet Katariya</a>, 
<a href="/search/cs?searchtype=author&query=Kveton%2C+B">Branislav Kveton</a>, 
<a href="/search/cs?searchtype=author&query=Rangi%2C+A">Anshuka Rangi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09631" title="Abstract">arXiv:2302.09631</a> (replaced) [<a href="/pdf/2302.09631" title="Download PDF">pdf</a>, <a href="/format/2302.09631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rewriting Modulo Traced Comonoid Structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghica%2C+D+R">Dan R. Ghica</a>, 
<a href="/search/cs?searchtype=author&query=Kaye%2C+G">George Kaye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version, 32 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Category Theory (math.CT)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10295" title="Abstract">arXiv:2302.10295</a> (replaced) [<a href="/pdf/2302.10295" title="Download PDF">pdf</a>, <a href="/format/2302.10295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correlation Clustering with Active Learning of Pairwise Similarities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aronsson%2C+L">Linus Aronsson</a>, 
<a href="/search/cs?searchtype=author&query=Chehreghani%2C+M+H">Morteza Haghir Chehreghani</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transactions on Machine Learning Research (TMLR) (2024).
  https://openreview.net/forum?id=Ryf1TVCjBz
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11508" title="Abstract">arXiv:2302.11508</a> (replaced) [<a href="/pdf/2302.11508" title="Download PDF">pdf</a>, <a href="/format/2302.11508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> nSimplex Zen: A Novel Dimensionality Reduction for Euclidean and Hilbert  Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Connor%2C+R">Richard Connor</a>, 
<a href="/search/cs?searchtype=author&query=Vadicamo%2C+L">Lucia Vadicamo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13705" title="Abstract">arXiv:2302.13705</a> (replaced) [<a href="/pdf/2302.13705" title="Download PDF">pdf</a>, <a href="/format/2302.13705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter Estimation-Based Extended Observer for Linear Systems with  Polynomial Overparameterization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Glushchenko%2C+A">Anton Glushchenko</a>, 
<a href="/search/eess?searchtype=author&query=Lastochkin%2C+K">Konstantin Lastochkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02566" title="Abstract">arXiv:2303.02566</a> (replaced) [<a href="/pdf/2303.02566" title="Download PDF">pdf</a>, <a href="/format/2303.02566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MFAI: A Scalable Bayesian Matrix Factorization Approach to Leveraging  Auxiliary Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wang%2C+Z">Zhiwei Wang</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+F">Fa Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Zheng%2C+C">Cong Zheng</a>, 
<a href="/search/stat?searchtype=author&query=Hu%2C+X">Xianghong Hu</a>, 
<a href="/search/stat?searchtype=author&query=Cai%2C+M">Mingxuan Cai</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+C">Can Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06530" title="Abstract">arXiv:2303.06530</a> (replaced) [<a href="/pdf/2303.06530" title="Download PDF">pdf</a>, <a href="/format/2303.06530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making Batch Normalization Great in Federated Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+J">Jike Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong-You Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chao%2C+W">Wei-Lun Chao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08083" title="Abstract">arXiv:2303.08083</a> (replaced) [<a href="/pdf/2303.08083" title="Download PDF">pdf</a>, <a href="/ps/2303.08083" title="Download PostScript">ps</a>, <a href="/format/2303.08083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secrecy Gain of Formally Unimodular Lattices from Codes over the  Integers Modulo 4
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bollauf%2C+M+F">Maiara F. Bollauf</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hsuan-Yin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ytrehus%2C+%C3%98">&#xd8;yvind Ytrehus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2202.09236">arXiv:2202.09236</a>; Paper accepted for publication in IEEE Transactions on Information Theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08944" title="Abstract">arXiv:2303.08944</a> (replaced) [<a href="/pdf/2303.08944" title="Download PDF">pdf</a>, <a href="/ps/2303.08944" title="Download PostScript">ps</a>, <a href="/format/2303.08944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agnostic Multi-Robust Learning Using ERM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmadi%2C+S">Saba Ahmadi</a>, 
<a href="/search/cs?searchtype=author&query=Blum%2C+A">Avrim Blum</a>, 
<a href="/search/cs?searchtype=author&query=Montasser%2C+O">Omar Montasser</a>, 
<a href="/search/cs?searchtype=author&query=Stangl%2C+K">Kevin Stangl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10233" title="Abstract">arXiv:2303.10233</a> (replaced) [<a href="/pdf/2303.10233" title="Download PDF">pdf</a>, <a href="/ps/2303.10233" title="Download PostScript">ps</a>, <a href="/format/2303.10233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast solution of incompressible flow problems with two-level pressure  approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pestana%2C+J">Jennifer Pestana</a>, 
<a href="/search/math?searchtype=author&query=Silvester%2C+D+J">David J. Silvester</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11223" title="Abstract">arXiv:2303.11223</a> (replaced) [<a href="/pdf/2303.11223" title="Download PDF">pdf</a>, <a href="/format/2303.11223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monocular Cyclist Detection with Convolutional Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Charles Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11793" title="Abstract">arXiv:2303.11793</a> (replaced) [<a href="/pdf/2303.11793" title="Download PDF">pdf</a>, <a href="/format/2303.11793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Optimal Transport and Jacobian Regularization by Optimal  Trajectory for Enhanced Adversarial Defense
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+B+M">Binh M. Le</a>, 
<a href="/search/cs?searchtype=author&query=Tariq%2C+S">Shahroz Tariq</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+S+S">Simon S. Woo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14732" title="Abstract">arXiv:2303.14732</a> (replaced) [<a href="/pdf/2303.14732" title="Download PDF">pdf</a>, <a href="/ps/2303.14732" title="Download PostScript">ps</a>, <a href="/format/2303.14732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interdisciplinary Papers Supported by Disciplinary Grants Garner Deep  and Broad Scientific Impact
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+M">Minsu Park</a>, 
<a href="/search/cs?searchtype=author&query=Maity%2C+S+K">Suman Kalyan Maity</a>, 
<a href="/search/cs?searchtype=author&query=Wuchty%2C+S">Stefan Wuchty</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dashun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Social and Information Networks (cs.SI); General Economics (econ.GN)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15458" title="Abstract">arXiv:2303.15458</a> (replaced) [<a href="/pdf/2303.15458" title="Download PDF">pdf</a>, <a href="/format/2303.15458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Stochastic Method for Solving Time-Fractional Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guidotti%2C+N+L">Nicolas L. Guidotti</a>, 
<a href="/search/math?searchtype=author&query=Acebr%C3%B3n%2C+J">Juan Acebr&#xf3;n</a>, 
<a href="/search/math?searchtype=author&query=Monteiro%2C+J">Jos&#xe9; Monteiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in Computers and Mathematics with Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16180" title="Abstract">arXiv:2303.16180</a> (replaced) [<a href="/pdf/2303.16180" title="Download PDF">pdf</a>, <a href="/format/2303.16180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Coating by 3D Hybrid Programmable Matter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kostitsyna%2C+I">Irina Kostitsyna</a>, 
<a href="/search/cs?searchtype=author&query=Liedtke%2C+D">David Liedtke</a>, 
<a href="/search/cs?searchtype=author&query=Scheideler%2C+C">Christian Scheideler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01954" title="Abstract">arXiv:2304.01954</a> (replaced) [<a href="/pdf/2304.01954" title="Download PDF">pdf</a>, <a href="/ps/2304.01954" title="Download PostScript">ps</a>, <a href="/format/2304.01954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strong spatial mixing for colorings on trees and its algorithmic  applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zongchen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kuikui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mani%2C+N">Nitya Mani</a>, 
<a href="/search/cs?searchtype=author&query=Moitra%2C+A">Ankur Moitra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 54 pages, 3 page appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08242" title="Abstract">arXiv:2304.08242</a> (replaced) [<a href="/pdf/2304.08242" title="Download PDF">pdf</a>, <a href="/format/2304.08242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Deep Latent Position Topic Model for Clustering and Representation  of Networks with Textual Edges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boutin%2C+R">R&#xe9;mi Boutin</a>, 
<a href="/search/cs?searchtype=author&query=Latouche%2C+P">Pierre Latouche</a>, 
<a href="/search/cs?searchtype=author&query=Bouveyron%2C+C">Charles Bouveyron</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages including the appendix, 13 figures, 6 tables, journal paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Social and Information Networks (cs.SI); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08467" title="Abstract">arXiv:2304.08467</a> (replaced) [<a href="/pdf/2304.08467" title="Download PDF">pdf</a>, <a href="/format/2304.08467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Compress Prompts with Gist Tokens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mu%2C+J">Jesse Mu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X+L">Xiang Lisa Li</a>, 
<a href="/search/cs?searchtype=author&query=Goodman%2C+N">Noah Goodman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023, 26 pages. Version 3 updates preprint to camera-ready version and clarifies some writing in places
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09571" title="Abstract">arXiv:2304.09571</a> (replaced) [<a href="/pdf/2304.09571" title="Download PDF">pdf</a>, <a href="/format/2304.09571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLIC: Large Receptive Field Transform Coding with Adaptive Weights for  Learned Image Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+P">Peirong Ning</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiayu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Y">Yongqi Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+F">Feng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ronggang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fix typos in Fig.8
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12076" title="Abstract">arXiv:2304.12076</a> (replaced) [<a href="/pdf/2304.12076" title="Download PDF">pdf</a>, <a href="/format/2304.12076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Customized Load Profiles Synthesis for Electricity Customers Based on  Conditional Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhenyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongcai Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12606" title="Abstract">arXiv:2304.12606</a> (replaced) [<a href="/pdf/2304.12606" title="Download PDF">pdf</a>, <a href="/ps/2304.12606" title="Download PostScript">ps</a>, <a href="/format/2304.12606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistics of Random Binning Based on Tsallis Divergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kavian%2C+M">Masoud Kavian</a>, 
<a href="/search/cs?searchtype=author&query=Mojahedian%2C+M+M">Mohammad Mahdi Mojahedian</a>, 
<a href="/search/cs?searchtype=author&query=Yassaee%2C+M+H">Mohammad Hossein Yassaee</a>, 
<a href="/search/cs?searchtype=author&query=Mirmohseni%2C+M">Mahtab Mirmohseni</a>, 
<a href="/search/cs?searchtype=author&query=Aref%2C+M+R">Mohammad Reza Aref</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06741" title="Abstract">arXiv:2305.06741</a> (replaced) [<a href="/pdf/2305.06741" title="Download PDF">pdf</a>, <a href="/format/2305.06741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IVP-VAE: Modeling EHR Time Series with Initial Value Problem Solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jingge Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Basso%2C+L">Leonie Basso</a>, 
<a href="/search/cs?searchtype=author&query=Nejdl%2C+W">Wolfgang Nejdl</a>, 
<a href="/search/cs?searchtype=author&query=Ganguly%2C+N">Niloy Ganguly</a>, 
<a href="/search/cs?searchtype=author&query=Sikdar%2C+S">Sandipan Sikdar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 Camera-Ready Version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08353" title="Abstract">arXiv:2305.08353</a> (replaced) [<a href="/pdf/2305.08353" title="Download PDF">pdf</a>, <a href="/format/2305.08353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and Efficient Matching Algorithm with Deadline Instances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhao Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weixin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+C">Chenbo Yin</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Junze Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12138" title="Abstract">arXiv:2305.12138</a> (replaced) [<a href="/pdf/2305.12138" title="Download PDF">pdf</a>, <a href="/format/2305.12138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LMs: Understanding Code Syntax and Semantics for Code Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shangqing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhihao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ye Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+L">Liming Nie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12179" title="Abstract">arXiv:2305.12179</a> (replaced) [<a href="/pdf/2305.12179" title="Download PDF">pdf</a>, <a href="/format/2305.12179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Commodity-specific triads in the Dutch inter-industry production network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Di+Vece%2C+M">Marzio Di Vece</a>, 
<a href="/search/physics?searchtype=author&query=Pijpers%2C+F+P">Frank P. Pijpers</a>, 
<a href="/search/physics?searchtype=author&query=Garlaschelli%2C+D">Diego Garlaschelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sci Rep 14, 3625 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Information Theory (cs.IT); General Economics (econ.GN); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13691" title="Abstract">arXiv:2305.13691</a> (replaced) [<a href="/pdf/2305.13691" title="Download PDF">pdf</a>, <a href="/format/2305.13691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-Shot Data Synthesis for Open Domain Multi-Hop Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingda Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xilun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yih%2C+W">Wen-tau Yih</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EACL 2024 Camera Ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14120" title="Abstract">arXiv:2305.14120</a> (replaced) [<a href="/pdf/2305.14120" title="Download PDF">pdf</a>, <a href="/format/2305.14120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning relevant contextual variables within Bayesian Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martinelli%2C+J">Julien Martinelli</a>, 
<a href="/search/cs?searchtype=author&query=Bharti%2C+A">Ayush Bharti</a>, 
<a href="/search/cs?searchtype=author&query=Tiihonen%2C+A">Armi Tiihonen</a>, 
<a href="/search/cs?searchtype=author&query=John%2C+S+T">S.T. John</a>, 
<a href="/search/cs?searchtype=author&query=Filstroff%2C+L">Louis Filstroff</a>, 
<a href="/search/cs?searchtype=author&query=Sloman%2C+S+J">Sabina J. Sloman</a>, 
<a href="/search/cs?searchtype=author&query=Rinke%2C+P">Patrick Rinke</a>, 
<a href="/search/cs?searchtype=author&query=Kaski%2C+S">Samuel Kaski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14610" title="Abstract">arXiv:2305.14610</a> (replaced) [<a href="/pdf/2305.14610" title="Download PDF">pdf</a>, <a href="/format/2305.14610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> This Land is {Your, My} Land: Evaluating Geopolitical Biases in Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bryan Li</a>, 
<a href="/search/cs?searchtype=author&query=Haider%2C+S">Samar Haider</a>, 
<a href="/search/cs?searchtype=author&query=Callison-Burch%2C+C">Chris Callison-Burch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15984" title="Abstract">arXiv:2305.15984</a> (replaced) [<a href="/pdf/2305.15984" title="Download PDF">pdf</a>, <a href="/format/2305.15984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Inter-treatment Information Sharing for Individualized Treatment  Effects Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chauhan%2C+V+K">Vinod Kumar Chauhan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiandong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ghosheh%2C+G">Ghadeer Ghosheh</a>, 
<a href="/search/cs?searchtype=author&query=Molaei%2C+S">Soheila Molaei</a>, 
<a href="/search/cs?searchtype=author&query=Clifton%2C+D+A">David A. Clifton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to The 27th International Conference on Artificial Intelligence and Statistics (AISTATS) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17148" title="Abstract">arXiv:2305.17148</a> (replaced) [<a href="/pdf/2305.17148" title="Download PDF">pdf</a>, <a href="/ps/2305.17148" title="Download PostScript">ps</a>, <a href="/format/2305.17148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Low-dimensional Synthetic Data from  High-dimensional Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yiyun He</a>, 
<a href="/search/cs?searchtype=author&query=Strohmer%2C+T">Thomas Strohmer</a>, 
<a href="/search/cs?searchtype=author&query=Vershynin%2C+R">Roman Vershynin</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yizhe Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Data Structures and Algorithms (cs.DS); Probability (math.PR); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17301" title="Abstract">arXiv:2305.17301</a> (replaced) [<a href="/pdf/2305.17301" title="Download PDF">pdf</a>, <a href="/ps/2305.17301" title="Download PostScript">ps</a>, <a href="/format/2305.17301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability-penalty-adaptive follow-the-regularized-leader: Sparsity,  game-dependency, and best-of-both-worlds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsuchiya%2C+T">Taira Tsuchiya</a>, 
<a href="/search/cs?searchtype=author&query=Ito%2C+S">Shinji Ito</a>, 
<a href="/search/cs?searchtype=author&query=Honda%2C+J">Junya Honda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published version in Advances in Neural Information Processing Systems 36 (NeurIPS 2023), 32 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18797" title="Abstract">arXiv:2305.18797</a> (replaced) [<a href="/pdf/2305.18797" title="Download PDF">pdf</a>, <a href="/format/2305.18797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Weakly Supervised Audio-Visual Violence Detection in Hyperbolic  Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xiaogang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Hao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yikai Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Keyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+P">Ping Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zizhao Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 12 figures, typos are fixed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01378" title="Abstract">arXiv:2306.01378</a> (replaced) [<a href="/pdf/2306.01378" title="Download PDF">pdf</a>, <a href="/format/2306.01378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coalition Formation with Bounded Coalition Size
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Levinger%2C+C">Chaya Levinger</a>, 
<a href="/search/cs?searchtype=author&query=Hazon%2C+N">Noam Hazon</a>, 
<a href="/search/cs?searchtype=author&query=Simola%2C+S">Sofia Simola</a>, 
<a href="/search/cs?searchtype=author&query=Azaria%2C+A">Amos Azaria</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in AAMAS-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01896" title="Abstract">arXiv:2306.01896</a> (replaced) [<a href="/pdf/2306.01896" title="Download PDF">pdf</a>, <a href="/format/2306.01896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Stabilize Online Reinforcement Learning in Unbounded State  Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pavse%2C+B+S">Brahma S. Pavse</a>, 
<a href="/search/cs?searchtype=author&query=Zurek%2C+M">Matthew Zurek</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yudong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Qiaomin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Hanna%2C+J+P">Josiah P. Hanna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02060" title="Abstract">arXiv:2306.02060</a> (replaced) [<a href="/pdf/2306.02060" title="Download PDF">pdf</a>, <a href="/format/2306.02060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A unified Bayesian inversion approach for a class of tumor growth models  with different pressure laws
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Feng%2C+Y">Yu Feng</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+L">Liu Liu</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+Z">Zhennan Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02586" title="Abstract">arXiv:2306.02586</a> (replaced) [<a href="/pdf/2306.02586" title="Download PDF">pdf</a>, <a href="/format/2306.02586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Internet of Things Meets Robotics: A Survey of Cloud-based Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eze%2C+C">Chrisantus Eze</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03589" title="Abstract">arXiv:2306.03589</a> (replaced) [<a href="/pdf/2306.03589" title="Download PDF">pdf</a>, <a href="/format/2306.03589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How does over-squashing affect the power of GNNs?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di+Giovanni%2C+F">Francesco Di Giovanni</a>, 
<a href="/search/cs?searchtype=author&query=Rusch%2C+T+K">T. Konstantin Rusch</a>, 
<a href="/search/cs?searchtype=author&query=Bronstein%2C+M+M">Michael M. Bronstein</a>, 
<a href="/search/cs?searchtype=author&query=Deac%2C+A">Andreea Deac</a>, 
<a href="/search/cs?searchtype=author&query=Lackenby%2C+M">Marc Lackenby</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Siddhartha Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Veli%C4%8Dkovi%C4%87%2C+P">Petar Veli&#x10d;kovi&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages; Published in Transactions on Machine Learning Research (TMLR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04848" title="Abstract">arXiv:2306.04848</a> (replaced) [<a href="/pdf/2306.04848" title="Download PDF">pdf</a>, <a href="/format/2306.04848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpreting and Improving Diffusion Models Using the Euclidean Distance  Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Permenter%2C+F">Frank Permenter</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chenyang Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 9 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06064" title="Abstract">arXiv:2306.06064</a> (replaced) [<a href="/pdf/2306.06064" title="Download PDF">pdf</a>, <a href="/format/2306.06064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Algorithmic Reasoning for Combinatorial Optimisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Georgiev%2C+D">Dobrik Georgiev</a>, 
<a href="/search/cs?searchtype=author&query=Numeroso%2C+D">Danilo Numeroso</a>, 
<a href="/search/cs?searchtype=author&query=Bacciu%2C+D">Davide Bacciu</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06123" title="Abstract">arXiv:2306.06123</a> (replaced) [<a href="/pdf/2306.06123" title="Download PDF">pdf</a>, <a href="/format/2306.06123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial attacks and defenses in explainable artificial intelligence:  A survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baniecki%2C+H">Hubert Baniecki</a>, 
<a href="/search/cs?searchtype=author&query=Biecek%2C+P">Przemyslaw Biecek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Information Fusion
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06375" title="Abstract">arXiv:2306.06375</a> (replaced) [<a href="/pdf/2306.06375" title="Download PDF">pdf</a>, <a href="/ps/2306.06375" title="Download PostScript">ps</a>, <a href="/format/2306.06375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimized Gradient Tracking for Decentralized Online Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S+D">Shivangi Dubey Sharma</a> (1), 
<a href="/search/cs?searchtype=author&query=Rajawat%2C+K">Ketan Rajawat</a> (1),  ((1) Indian Institute of Technology Kanpur)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 6 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06997" title="Abstract">arXiv:2306.06997</a> (replaced) [<a href="/pdf/2306.06997" title="Download PDF">pdf</a>, <a href="/format/2306.06997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Slot-VAE: Object-Centric Scene Generation with Slot Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanbo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Letao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dauwels%2C+J">Justin Dauwels</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICML 2023 <a href="https://proceedings.mlr.press/v202/wang23r.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07435" title="Abstract">arXiv:2306.07435</a> (replaced) [<a href="/pdf/2306.07435" title="Download PDF">pdf</a>, <a href="/format/2306.07435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Randomized least-squares with minimal oversampling and interpolation in  general spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chkifa%2C+A">Abdellah Chkifa</a>, 
<a href="/search/math?searchtype=author&query=Dolbeault%2C+M">Matthieu Dolbeault</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09686" title="Abstract">arXiv:2306.09686</a> (replaced) [<a href="/pdf/2306.09686" title="Download PDF">pdf</a>, <a href="/format/2306.09686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collapsed Inference for Bayesian Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhe Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Van+den+Broeck%2C+G">Guy Van den Broeck</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10564" title="Abstract">arXiv:2306.10564</a> (replaced) [<a href="/pdf/2306.10564" title="Download PDF">pdf</a>, <a href="/format/2306.10564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On stability and state-norm estimation of switched systems under  restricted switching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kundu%2C+A">Atreyee Kundu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 2 figures. Longer version of a manuscript under review. arXiv admin note: text overlap with <a href="/abs/2207.07764">arXiv:2207.07764</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11154" title="Abstract">arXiv:2306.11154</a> (replaced) [<a href="/pdf/2306.11154" title="Download PDF">pdf</a>, <a href="/format/2306.11154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Truth Serum for Eliciting Self-Evaluations in Scientific Reviews
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jibang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haifeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yifan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+W">Weijie Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12510" title="Abstract">arXiv:2306.12510</a> (replaced) [<a href="/pdf/2306.12510" title="Download PDF">pdf</a>, <a href="/ps/2306.12510" title="Download PostScript">ps</a>, <a href="/format/2306.12510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Analysis of Segment Anything Model and U-Net for Breast  Tumor Detection in Ultrasound and Mammography Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ahmadi%2C+M">Mohsen Ahmadi</a>, 
<a href="/search/eess?searchtype=author&query=Nia%2C+M+F">Masoumeh Farhadi Nia</a>, 
<a href="/search/eess?searchtype=author&query=Asgarian%2C+S">Sara Asgarian</a>, 
<a href="/search/eess?searchtype=author&query=Danesh%2C+K">Kasra Danesh</a>, 
<a href="/search/eess?searchtype=author&query=Irankhah%2C+E">Elyas Irankhah</a>, 
<a href="/search/eess?searchtype=author&query=Lonbar%2C+A+G">Ahmad Gholizadeh Lonbar</a>, 
<a href="/search/eess?searchtype=author&query=Sharifi%2C+A">Abbas Sharifi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00668" title="Abstract">arXiv:2307.00668</a> (replaced) [<a href="/pdf/2307.00668" title="Download PDF">pdf</a>, <a href="/format/2307.00668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Sensing with Predictive Coding and Uncertainty Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharafeldin%2C+A">Abdelrahman Sharafeldin</a>, 
<a href="/search/cs?searchtype=author&query=Imam%2C+N">Nabil Imam</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+H">Hannah Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, LaTeX; Fixed a small issue with section numbering; Added more experiments, baselines, and relevant references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01063" title="Abstract">arXiv:2307.01063</a> (replaced) [<a href="/pdf/2307.01063" title="Download PDF">pdf</a>, <a href="/ps/2307.01063" title="Download PostScript">ps</a>, <a href="/format/2307.01063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthesising Full-Information Protocols
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berwanger%2C+D">Dietmar Berwanger</a>, 
<a href="/search/cs?searchtype=author&query=Doyen%2C+L">Laurent Doyen</a>, 
<a href="/search/cs?searchtype=author&query=Soullard%2C+T">Thomas Soullard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03307" title="Abstract">arXiv:2307.03307</a> (replaced) [<a href="/pdf/2307.03307" title="Download PDF">pdf</a>, <a href="/format/2307.03307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient parallel implementation of the multiplicative weight update  method for graph-based linear programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ju%2C+C">Caleb Ju</a>, 
<a href="/search/cs?searchtype=author&query=Yesil%2C+S">Serif Yesil</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mengyuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chekuri%2C+C">Chandra Chekuri</a>, 
<a href="/search/cs?searchtype=author&query=Solomonik%2C+E">Edgar Solomonik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updates to funding and small revisions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Discrete Mathematics (cs.DM); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06299" title="Abstract">arXiv:2307.06299</a> (replaced) [<a href="/pdf/2307.06299" title="Download PDF">pdf</a>, <a href="/ps/2307.06299" title="Download PostScript">ps</a>, <a href="/format/2307.06299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Certified Proof Checker for Deep Neural Network Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Desmartin%2C+R">Remi Desmartin</a>, 
<a href="/search/cs?searchtype=author&query=Isac%2C+O">Omri Isac</a>, 
<a href="/search/cs?searchtype=author&query=Passmore%2C+G">Grant Passmore</a>, 
<a href="/search/cs?searchtype=author&query=Stark%2C+K">Kathrin Stark</a>, 
<a href="/search/cs?searchtype=author&query=Katz%2C+G">Guy Katz</a>, 
<a href="/search/cs?searchtype=author&query=Komendantskaya%2C+E">Ekaterina Komendantskaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a preprint version of the paper that appeared at LOPSTR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06887" title="Abstract">arXiv:2307.06887</a> (replaced) [<a href="/pdf/2307.06887" title="Download PDF">pdf</a>, <a href="/format/2307.06887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provable Multi-Task Representation Learning by Two-Layer ReLU Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Collins%2C+L">Liam Collins</a>, 
<a href="/search/cs?searchtype=author&query=Hassani%2C+H">Hamed Hassani</a>, 
<a href="/search/cs?searchtype=author&query=Soltanolkotabi%2C+M">Mahdi Soltanolkotabi</a>, 
<a href="/search/cs?searchtype=author&query=Mokhtari%2C+A">Aryan Mokhtari</a>, 
<a href="/search/cs?searchtype=author&query=Shakkottai%2C+S">Sanjay Shakkottai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07350" title="Abstract">arXiv:2307.07350</a> (replaced) [<a href="/pdf/2307.07350" title="Download PDF">pdf</a>, <a href="/ps/2307.07350" title="Download PostScript">ps</a>, <a href="/format/2307.07350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond the worst case: Distortion in impartial culture electorates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caragiannis%2C+I">Ioannis Caragiannis</a>, 
<a href="/search/cs?searchtype=author&query=Fehrs%2C+K">Karl Fehrs</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08433" title="Abstract">arXiv:2307.08433</a> (replaced) [<a href="/pdf/2307.08433" title="Download PDF">pdf</a>, <a href="/format/2307.08433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From random-walks to graph-sprints: a low-latency node embedding  framework on continuous-time dynamic graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eddin%2C+A+N">Ahmad Naser Eddin</a>, 
<a href="/search/cs?searchtype=author&query=Bono%2C+J">Jacopo Bono</a>, 
<a href="/search/cs?searchtype=author&query=Apar%C3%ADcio%2C+D">David Apar&#xed;cio</a>, 
<a href="/search/cs?searchtype=author&query=Ferreira%2C+H">Hugo Ferreira</a>, 
<a href="/search/cs?searchtype=author&query=Ascens%C3%A3o%2C+J">Jo&#xe3;o Ascens&#xe3;o</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+P">Pedro Ribeiro</a>, 
<a href="/search/cs?searchtype=author&query=Bizarro%2C+P">Pedro Bizarro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08533" title="Abstract">arXiv:2307.08533</a> (replaced) [<a href="/pdf/2307.08533" title="Download PDF">pdf</a>, <a href="/ps/2307.08533" title="Download PostScript">ps</a>, <a href="/format/2307.08533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Processing with Linear Optics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Yildirim%2C+M">Mustafa Yildirim</a>, 
<a href="/search/physics?searchtype=author&query=Dinc%2C+N+U">Niyazi Ulas Dinc</a>, 
<a href="/search/physics?searchtype=author&query=Oguz%2C+I">Ilker Oguz</a>, 
<a href="/search/physics?searchtype=author&query=Psaltis%2C+D">Demetri Psaltis</a>, 
<a href="/search/physics?searchtype=author&query=Moser%2C+C">Christophe Moser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages and 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08701" title="Abstract">arXiv:2307.08701</a> (replaced) [<a href="/pdf/2307.08701" title="Download PDF">pdf</a>, <a href="/format/2307.08701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AlpaGasus: Training A Better Alpaca with Fewer Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lichang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shiyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jun Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gunaratna%2C+K">Kalpa Gunaratna</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+V">Vikas Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zheng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+V">Vijay Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Heng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hongxia Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 Pages; 29 Figures; 15 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09350" title="Abstract">arXiv:2307.09350</a> (replaced) [<a href="/pdf/2307.09350" title="Download PDF">pdf</a>, <a href="/format/2307.09350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Role of Dimension in the Online Chasing Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papazov%2C+H">Hristo Papazov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09616" title="Abstract">arXiv:2307.09616</a> (replaced) [<a href="/pdf/2307.09616" title="Download PDF">pdf</a>, <a href="/format/2307.09616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous Non-monotone DR-submodular Maximization with Down-closed  Convex Constraint
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shengminjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+D">Donglei Du</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenguo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dachuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Suixiang Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11018" title="Abstract">arXiv:2307.11018</a> (replaced) [<a href="/pdf/2307.11018" title="Download PDF">pdf</a>, <a href="/format/2307.11018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Amortized Variational Inference: When and Why?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Margossian%2C+C+C">Charles C. Margossian</a>, 
<a href="/search/stat?searchtype=author&query=Blei%2C+D+M">David M. Blei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11607" title="Abstract">arXiv:2307.11607</a> (replaced) [<a href="/pdf/2307.11607" title="Download PDF">pdf</a>, <a href="/format/2307.11607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Optimal Diverse Feature Sets with Alternative Feature Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bach%2C+J">Jakob Bach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Changes from v1 to v2: Experiments for heuristic search methods added; various minor changes and additions to synchronize with journal version (currently still under review)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13808" title="Abstract">arXiv:2307.13808</a> (replaced) [<a href="/pdf/2307.13808" title="Download PDF">pdf</a>, <a href="/format/2307.13808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Watermarking Conditional Text Generation for AI Detection: Unveiling  Challenges and a Semantic-Aware Watermark Remedy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+D">Deyi Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yue Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures (accepted to AAAI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01037" title="Abstract">arXiv:2308.01037</a> (replaced) [<a href="/pdf/2308.01037" title="Download PDF">pdf</a>, <a href="/format/2308.01037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Fast Monte Carlo algorithm for evaluating matrix functions with  application in complex networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guidotti%2C+N+L">Nicolas L. Guidotti</a>, 
<a href="/search/cs?searchtype=author&query=Acebr%C3%B3n%2C+J+A">Juan A. Acebr&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Monteiro%2C+J">Jos&#xe9; Monteiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the Journal of Scientific Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01413" title="Abstract">arXiv:2308.01413</a> (replaced) [<a href="/pdf/2308.01413" title="Download PDF">pdf</a>, <a href="/format/2308.01413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LaFiCMIL: Rethinking Large File Classification from the Perspective of  Correlated Multiple Instance Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Tiezhu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Pian%2C+W">Weiguo Pian</a>, 
<a href="/search/cs?searchtype=author&query=Daoudi%2C+N">Nadia Daoudi</a>, 
<a href="/search/cs?searchtype=author&query=Allix%2C+K">Kevin Allix</a>, 
<a href="/search/cs?searchtype=author&query=Bissyand%C3%A9%2C+T+F">Tegawend&#xe9; F. Bissyand&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+J">Jacques Klein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages; manuscript revision
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06686" title="Abstract">arXiv:2308.06686</a> (replaced) [<a href="/pdf/2308.06686" title="Download PDF">pdf</a>, <a href="/format/2308.06686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TorchQL: A Programming Framework for Integrity Constraints in Machine  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naik%2C+A">Aaditya Naik</a>, 
<a href="/search/cs?searchtype=author&query=Stein%2C+A">Adam Stein</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yinjun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+E">Eric Wong</a>, 
<a href="/search/cs?searchtype=author&query=Naik%2C+M">Mayur Naik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07173" title="Abstract">arXiv:2308.07173</a> (replaced) [<a href="/pdf/2308.07173" title="Download PDF">pdf</a>, <a href="/format/2308.07173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing State Estimator for Autonomous Racing : Leveraging Multi-modal  System and Managing Computing Resources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Daegyu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+H">Hyunwoo Nam</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+C">Chanhoe Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Nah%2C+S">Sungwon Nah</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+S">Seongwoo Moon</a>, 
<a href="/search/cs?searchtype=author&query=Shim%2C+D+H">D. Hyunchul Shim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2207.12232">arXiv:2207.12232</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Intelligent Vehicles(2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08426" title="Abstract">arXiv:2308.08426</a> (replaced) [<a href="/pdf/2308.08426" title="Download PDF">pdf</a>, <a href="/format/2308.08426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Robust Model Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Oshin%2C+A">Alex Oshin</a>, 
<a href="/search/math?searchtype=author&query=Almubarak%2C+H">Hassan Almubarak</a>, 
<a href="/search/math?searchtype=author&query=Theodorou%2C+E+A">Evangelos A. Theodorou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10630" title="Abstract">arXiv:2308.10630</a> (replaced) [<a href="/pdf/2308.10630" title="Download PDF">pdf</a>, <a href="/format/2308.10630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Homogenization Approach for Gradient-Dominated Stochastic Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tan%2C+J">Jiyuan Tan</a>, 
<a href="/search/math?searchtype=author&query=Xue%2C+C">Chenyu Xue</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+C">Chuwen Zhang</a>, 
<a href="/search/math?searchtype=author&query=Deng%2C+Q">Qi Deng</a>, 
<a href="/search/math?searchtype=author&query=Ge%2C+D">Dongdong Ge</a>, 
<a href="/search/math?searchtype=author&query=Ye%2C+Y">Yinyu Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12367" title="Abstract">arXiv:2308.12367</a> (replaced) [<a href="/pdf/2308.12367" title="Download PDF">pdf</a>, <a href="/format/2308.12367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SafeAR: Safe Algorithmic Recourse by Risk-Aware Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haochen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S">Shubham Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Patra%2C+S">Sunandita Patra</a>, 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+S">Sriram Gopalakrishnan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024 main track with oral presentation; Supplemental material appended to main paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00851" title="Abstract">arXiv:2309.00851</a> (replaced) [<a href="/pdf/2309.00851" title="Download PDF">pdf</a>, <a href="/format/2309.00851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Drift Analysis with Fitness Levels for Elitist Evolutionary Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jun He</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuren Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01592" title="Abstract">arXiv:2309.01592</a> (replaced) [<a href="/pdf/2309.01592" title="Download PDF">pdf</a>, <a href="/format/2309.01592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Les Houches Lectures on Deep Learning at Large &amp; Infinite Width
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bahri%2C+Y">Yasaman Bahri</a>, 
<a href="/search/stat?searchtype=author&query=Hanin%2C+B">Boris Hanin</a>, 
<a href="/search/stat?searchtype=author&query=Brossollet%2C+A">Antonin Brossollet</a>, 
<a href="/search/stat?searchtype=author&query=Erba%2C+V">Vittorio Erba</a>, 
<a href="/search/stat?searchtype=author&query=Keup%2C+C">Christian Keup</a>, 
<a href="/search/stat?searchtype=author&query=Pacelli%2C+R">Rosalba Pacelli</a>, 
<a href="/search/stat?searchtype=author&query=Simon%2C+J+B">James B. Simon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> These are notes from lectures delivered by Yasaman Bahri and Boris Hanin at the 2022 Les Houches Summer School on Statistics Physics and Machine Learning and a first version of them were transcribed by Antonin Brossollet, Vittorio Erba, Christian Keup, Rosalba Pacelli, James B. Simon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); High Energy Physics - Theory (hep-th); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03041" title="Abstract">arXiv:2309.03041</a> (replaced) [<a href="/pdf/2309.03041" title="Download PDF">pdf</a>, <a href="/format/2309.03041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Refutation of Shapley Values for Explainability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanxiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Marques-Silva%2C+J">Joao Marques-Silva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06950" title="Abstract">arXiv:2309.06950</a> (replaced) [<a href="/pdf/2309.06950" title="Download PDF">pdf</a>, <a href="/format/2309.06950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Active Metric-Semantic SLAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+Y">Yuezhan Tao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Spasojevic%2C+I">Igor Spasojevic</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+S">Saurav Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vijay Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by RA-L
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07138" title="Abstract">arXiv:2309.07138</a> (replaced) [<a href="/pdf/2309.07138" title="Download PDF">pdf</a>, <a href="/ps/2309.07138" title="Download PostScript">ps</a>, <a href="/format/2309.07138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Blind Source Separation via Multi-Encoder Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Webster%2C+M+B">Matthew B. Webster</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+J">Joonnyong Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 8 figures, submitted for review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07462" title="Abstract">arXiv:2309.07462</a> (replaced) [<a href="/pdf/2309.07462" title="Download PDF">pdf</a>, <a href="/format/2309.07462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Large Language Model-based Evaluators the Solution to Scaling Up  Multilingual Evaluation?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hada%2C+R">Rishav Hada</a>, 
<a href="/search/cs?searchtype=author&query=Gumma%2C+V">Varun Gumma</a>, 
<a href="/search/cs?searchtype=author&query=de+Wynter%2C+A">Adrian de Wynter</a>, 
<a href="/search/cs?searchtype=author&query=Diddee%2C+H">Harshita Diddee</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+M">Mohamed Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Choudhury%2C+M">Monojit Choudhury</a>, 
<a href="/search/cs?searchtype=author&query=Bali%2C+K">Kalika Bali</a>, 
<a href="/search/cs?searchtype=author&query=Sitaram%2C+S">Sunayana Sitaram</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EACL 2024 findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07822" title="Abstract">arXiv:2309.07822</a> (replaced) [<a href="/pdf/2309.07822" title="Download PDF">pdf</a>, <a href="/format/2309.07822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CATfOOD: Counterfactual Augmented Training for Improving Out-of-Domain  Performance and Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sachdeva%2C+R">Rachneet Sachdeva</a>, 
<a href="/search/cs?searchtype=author&query=Tutek%2C+M">Martin Tutek</a>, 
<a href="/search/cs?searchtype=author&query=Gurevych%2C+I">Iryna Gurevych</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EACL 2024 main conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17016" title="Abstract">arXiv:2309.17016</a> (replaced) [<a href="/pdf/2309.17016" title="Download PDF">pdf</a>, <a href="/format/2309.17016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Agnostic Learning with Average Smoothness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hanneke%2C+S">Steve Hanneke</a>, 
<a href="/search/cs?searchtype=author&query=Kontorovich%2C+A">Aryeh Kontorovich</a>, 
<a href="/search/cs?searchtype=author&query=Kornowski%2C+G">Guy Kornowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ALT 2024 camera ready version. arXiv admin note: text overlap with <a href="/abs/2302.06005">arXiv:2302.06005</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00684" title="Abstract">arXiv:2310.00684</a> (replaced) [<a href="/pdf/2310.00684" title="Download PDF">pdf</a>, <a href="/format/2310.00684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Many Views Are Needed to Reconstruct an Unknown Object Using NeRF?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Sicong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Liren Jin</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Popovi%C4%87%2C+M">Marija Popovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Bennewitz%2C+M">Maren Bennewitz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Sicong Pan and Liren Jin have equal contribution. Publication to appear in IEEE International Conference on Robotics and Automation (ICRA), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00685" title="Abstract">arXiv:2310.00685</a> (replaced) [<a href="/pdf/2310.00685" title="Download PDF">pdf</a>, <a href="/format/2310.00685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Implicit Reconstruction Using One-Shot View Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Sicong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Liren Jin</a>, 
<a href="/search/cs?searchtype=author&query=Popovi%C4%87%2C+M">Marija Popovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Bennewitz%2C+M">Maren Bennewitz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Hao Hu and Sicong Pan have equal contribution. Publication to appear in IEEE International Conference on Robotics and Automation (ICRA), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01412" title="Abstract">arXiv:2310.01412</a> (replaced) [<a href="/pdf/2310.01412" title="Download PDF">pdf</a>, <a href="/format/2310.01412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DriveGPT4: Interpretable End-to-end Autonomous Driving via Large  Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhenhua Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yujia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+E">Enze Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K+K">Kwan-Yee. K. Wong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hengshuang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The project page is available at <a href="https://tonyxuqaq.github.io/projects/DriveGPT4/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04918" title="Abstract">arXiv:2310.04918</a> (replaced) [<a href="/pdf/2310.04918" title="Download PDF">pdf</a>, <a href="/format/2310.04918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SWAP: Sparse Entropic Wasserstein Regression for Robust Network Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=You%2C+L">Lei You</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H+V">Hei Victor Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05404" title="Abstract">arXiv:2310.05404</a> (replaced) [<a href="/pdf/2310.05404" title="Download PDF">pdf</a>, <a href="/format/2310.05404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Maze of Multilingual Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nezhad%2C+S+B">Sina Bagheri Nezhad</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+A">Ameeta Agrawal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05955" title="Abstract">arXiv:2310.05955</a> (replaced) [<a href="/pdf/2310.05955" title="Download PDF">pdf</a>, <a href="/format/2310.05955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Quality-Diversity approaches for constrained optimization  problems with mixed continuous, discrete and categorical variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Brevault%2C+L">Loic Brevault</a>, 
<a href="/search/math?searchtype=author&query=Balesdent%2C+M">Mathieu Balesdent</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07048" title="Abstract">arXiv:2310.07048</a> (replaced) [<a href="/pdf/2310.07048" title="Download PDF">pdf</a>, <a href="/format/2310.07048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedMFS: Federated Multimodal Fusion Learning with Selective Modality  Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Liangqi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+D">Dong-Jun Han</a>, 
<a href="/search/cs?searchtype=author&query=Chellapandi%2C+V+P">Vishnu Pandi Chellapandi</a>, 
<a href="/search/cs?searchtype=author&query=%C5%BBak%2C+S+H">Stanislaw H. &#x17b;ak</a>, 
<a href="/search/cs?searchtype=author&query=Brinton%2C+C+G">Christopher G. Brinton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08833" title="Abstract">arXiv:2310.08833</a> (replaced) [<a href="/pdf/2310.08833" title="Download PDF">pdf</a>, <a href="/format/2310.08833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Sample Complexity for Average Reward Markov Decision Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengbo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Blanchet%2C+J">Jose Blanchet</a>, 
<a href="/search/cs?searchtype=author&query=Glynn%2C+P">Peter Glynn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09342" title="Abstract">arXiv:2310.09342</a> (replaced) [<a href="/pdf/2310.09342" title="Download PDF">pdf</a>, <a href="/format/2310.09342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ranking LLM-Generated Loop Invariants for Program Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Saikat Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Lahiri%2C+S+K">Shuvendu K. Lahiri</a>, 
<a href="/search/cs?searchtype=author&query=Fakhoury%2C+S">Sarah Fakhoury</a>, 
<a href="/search/cs?searchtype=author&query=Musuvathi%2C+M">Madanlal Musuvathi</a>, 
<a href="/search/cs?searchtype=author&query=Lal%2C+A">Akash Lal</a>, 
<a href="/search/cs?searchtype=author&query=Rastogi%2C+A">Aseem Rastogi</a>, 
<a href="/search/cs?searchtype=author&query=Senthilnathan%2C+A">Aditya Senthilnathan</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+R">Rahul Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Swamy%2C+N">Nikhil Swamy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of The 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP-findings 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09401" title="Abstract">arXiv:2310.09401</a> (replaced) [<a href="/pdf/2310.09401" title="Download PDF">pdf</a>, <a href="/format/2310.09401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CROWN: A Novel Approach to Comprehending Users&#x27; Preferences for Accurate  Personalized News Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ko%2C+Y">Yunyong Ko</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+S">Seongeun Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sang-Wook Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09518" title="Abstract">arXiv:2310.09518</a> (replaced) [<a href="/pdf/2310.09518" title="Download PDF">pdf</a>, <a href="/format/2310.09518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instruction Tuning with Human Curriculum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+B+W">Bruce W. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+H">Hyunsoo Cho</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+K+M">Kang Min Yoo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review, *ACL
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09877" title="Abstract">arXiv:2310.09877</a> (replaced) [<a href="/pdf/2310.09877" title="Download PDF">pdf</a>, <a href="/format/2310.09877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical inference using machine learning and classical techniques  based on accumulated local effects (ALE)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Okoli%2C+C">Chitu Okoli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 1. P-values have been added to the analysis. 2. Neural network demonstration replaced with random forest. 3. Effects plot shows NALED band based on p-values
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11009" title="Abstract">arXiv:2310.11009</a> (replaced) [<a href="/pdf/2310.11009" title="Download PDF">pdf</a>, <a href="/format/2310.11009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LPFormer: An Adaptive Graph Transformer for Link Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shomer%2C+H">Harry Shomer</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+H">Haitao Mao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juanhui Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiliang Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13576" title="Abstract">arXiv:2310.13576</a> (replaced) [<a href="/pdf/2310.13576" title="Download PDF">pdf</a>, <a href="/format/2310.13576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tree Search in DAG Space with Model-based Reinforcement Learning for  Causal Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Darvariu%2C+V">Victor-Alexandru Darvariu</a>, 
<a href="/search/cs?searchtype=author&query=Hailes%2C+S">Stephen Hailes</a>, 
<a href="/search/cs?searchtype=author&query=Musolesi%2C+M">Mirco Musolesi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14821" title="Abstract">arXiv:2310.14821</a> (replaced) [<a href="/pdf/2310.14821" title="Download PDF">pdf</a>, <a href="/format/2310.14821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mysticeti: Low-Latency DAG Consensus with Fast Commit Path
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Babel%2C+K">Kushal Babel</a>, 
<a href="/search/cs?searchtype=author&query=Chursin%2C+A">Andrey Chursin</a>, 
<a href="/search/cs?searchtype=author&query=Danezis%2C+G">George Danezis</a>, 
<a href="/search/cs?searchtype=author&query=Kokoris-Kogias%2C+L">Lefteris Kokoris-Kogias</a>, 
<a href="/search/cs?searchtype=author&query=Sonnino%2C+A">Alberto Sonnino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15903" title="Abstract">arXiv:2310.15903</a> (replaced) [<a href="/pdf/2310.15903" title="Download PDF">pdf</a>, <a href="/ps/2310.15903" title="Download PostScript">ps</a>, <a href="/format/2310.15903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Collapse in Multi-label Learning with Pick-all-label Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pengyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yutong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Q">Qing Qu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17022" title="Abstract">arXiv:2310.17022</a> (replaced) [<a href="/pdf/2310.17022" title="Download PDF">pdf</a>, <a href="/format/2310.17022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controlled Decoding from Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mudgal%2C+S">Sidharth Mudgal</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ganapathy%2C+H">Harish Ganapathy</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">YaGuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yanping Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Heng-Tze Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Collins%2C+M">Michael Collins</a>, 
<a href="/search/cs?searchtype=author&query=Strohman%2C+T">Trevor Strohman</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jilin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Beutel%2C+A">Alex Beutel</a>, 
<a href="/search/cs?searchtype=author&query=Beirami%2C+A">Ahmad Beirami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17143" title="Abstract">arXiv:2310.17143</a> (replaced) [<a href="/pdf/2310.17143" title="Download PDF">pdf</a>, <a href="/ps/2310.17143" title="Download PostScript">ps</a>, <a href="/format/2310.17143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Techniques for supercharging academic writing with generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhicheng Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 2 figures, 1 table, 1 box
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17816" title="Abstract">arXiv:2310.17816</a> (replaced) [<a href="/pdf/2310.17816" title="Download PDF">pdf</a>, <a href="/format/2310.17816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Discovery by Partitioning: Polynomial-Time Causal Discovery Around  Exposure-Outcome Pairs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Maasch%2C+J">Jacqueline Maasch</a>, 
<a href="/search/stat?searchtype=author&query=Pan%2C+W">Weishen Pan</a>, 
<a href="/search/stat?searchtype=author&query=Gupta%2C+S">Shantanu Gupta</a>, 
<a href="/search/stat?searchtype=author&query=Kuleshov%2C+V">Volodymyr Kuleshov</a>, 
<a href="/search/stat?searchtype=author&query=Gan%2C+K">Kyra Gan</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+F">Fei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18463" title="Abstract">arXiv:2310.18463</a> (replaced) [<a href="/pdf/2310.18463" title="Download PDF">pdf</a>, <a href="/format/2310.18463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PeTailor: Improving Large Language Model by Tailored Chunk Scorer in  Biomedical Triple Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingchen Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">M. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Huixue Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Kilicoglu%2C+H">Halil Kilicoglu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> this is the second preprint version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19791" title="Abstract">arXiv:2310.19791</a> (replaced) [<a href="/pdf/2310.19791" title="Download PDF">pdf</a>, <a href="/format/2310.19791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LILO: Learning Interpretable Libraries by Compressing and Documenting  Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grand%2C+G">Gabriel Grand</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+L">Lionel Wong</a>, 
<a href="/search/cs?searchtype=author&query=Bowers%2C+M">Matthew Bowers</a>, 
<a href="/search/cs?searchtype=author&query=Olausson%2C+T+X">Theo X. Olausson</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Muxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tenenbaum%2C+J+B">Joshua B. Tenenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Andreas%2C+J">Jacob Andreas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03415" title="Abstract">arXiv:2311.03415</a> (replaced) [<a href="/pdf/2311.03415" title="Download PDF">pdf</a>, <a href="/format/2311.03415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PowerFlowNet: Power Flow Approximation Using Message Passing Graph  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+N">Nan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Orfanoudakis%2C+S">Stavros Orfanoudakis</a>, 
<a href="/search/cs?searchtype=author&query=Cardenas%2C+N+O">Nathan Ordonez Cardenas</a>, 
<a href="/search/cs?searchtype=author&query=Giraldo%2C+J+S">Juan S. Giraldo</a>, 
<a href="/search/cs?searchtype=author&query=Vergara%2C+P+P">Pedro P. Vergara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06840" title="Abstract">arXiv:2311.06840</a> (replaced) [<a href="/pdf/2311.06840" title="Download PDF">pdf</a>, <a href="/ps/2311.06840" title="Download PostScript">ps</a>, <a href="/format/2311.06840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Omitted Labels in Causality: A Study of Paradoxes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mazaheri%2C+B">Bijan Mazaheri</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Siddharth Jain</a>, 
<a href="/search/cs?searchtype=author&query=Cook%2C+M">Matthew Cook</a>, 
<a href="/search/cs?searchtype=author&query=Bruck%2C+J">Jehoshua Bruck</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Social and Information Networks (cs.SI); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09593" title="Abstract">arXiv:2311.09593</a> (replaced) [<a href="/pdf/2311.09593" title="Download PDF">pdf</a>, <a href="/format/2311.09593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Step Dialogue Workflow Action Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramakrishnan%2C+R">Ramya Ramakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Elenberg%2C+E+R">Ethan R. Elenberg</a>, 
<a href="/search/cs?searchtype=author&query=Narangodage%2C+H">Hashan Narangodage</a>, 
<a href="/search/cs?searchtype=author&query=McDonald%2C+R">Ryan McDonald</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09904" title="Abstract">arXiv:2311.09904</a> (replaced) [<a href="/pdf/2311.09904" title="Download PDF">pdf</a>, <a href="/format/2311.09904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Capacitated Network Bargaining Games: Stability and Structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanit%C3%A0%2C+L">Laura Sanit&#xe0;</a>, 
<a href="/search/cs?searchtype=author&query=Verberk%2C+L">Lucy Verberk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12904" title="Abstract">arXiv:2311.12904</a> (replaced) [<a href="/pdf/2311.12904" title="Download PDF">pdf</a>, <a href="/ps/2311.12904" title="Download PostScript">ps</a>, <a href="/format/2311.12904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Compute Gr&#xf6;bner Bases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kera%2C+H">Hiroshi Kera</a>, 
<a href="/search/math?searchtype=author&query=Ishihara%2C+Y">Yuki Ishihara</a>, 
<a href="/search/math?searchtype=author&query=Kambe%2C+Y">Yuta Kambe</a>, 
<a href="/search/math?searchtype=author&query=Vaccon%2C+T">Tristan Vaccon</a>, 
<a href="/search/math?searchtype=author&query=Yokoyama%2C+K">Kazuhiro Yokoyama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 24 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Commutative Algebra (math.AC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15024" title="Abstract">arXiv:2311.15024</a> (replaced) [<a href="/pdf/2311.15024" title="Download PDF">pdf</a>, <a href="/ps/2311.15024" title="Download PostScript">ps</a>, <a href="/format/2311.15024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Study of Watering Hole Attack Detection Using Supervised  Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aktar%2C+M+N">Mst. Nishita Aktar</a>, 
<a href="/search/cs?searchtype=author&query=Akter%2C+S">Sornali Akter</a>, 
<a href="/search/cs?searchtype=author&query=Saad%2C+M+N+I">Md. Nusaim Islam Saad</a>, 
<a href="/search/cs?searchtype=author&query=Jisun%2C+J+H">Jakir Hosen Jisun</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+K+M">Kh. Mustafizur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Sakib%2C+M+N">Md. Nazmus Sakib</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15578" title="Abstract">arXiv:2311.15578</a> (replaced) [<a href="/pdf/2311.15578" title="Download PDF">pdf</a>, <a href="/format/2311.15578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental Analysis of Large-scale Learnable Vector Storage  Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hailin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Penghao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+X">Xupeng Miao</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yingxia Shao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zirui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+B">Bin Cui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18083" title="Abstract">arXiv:2311.18083</a> (replaced) [<a href="/pdf/2311.18083" title="Download PDF">pdf</a>, <a href="/format/2311.18083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta Co-Training: Two Views are Better than One
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rothenberger%2C+J+C">Jay C. Rothenberger</a>, 
<a href="/search/cs?searchtype=author&query=Diochnos%2C+D+I">Dimitrios I. Diochnos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 14 figures, 10 tables, for implementation see <a href="https://github.com/JayRothenberger/Meta-Co-Training">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01046" title="Abstract">arXiv:2312.01046</a> (replaced) [<a href="/pdf/2312.01046" title="Download PDF">pdf</a>, <a href="/format/2312.01046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bagged Regularized $k$-Distances for Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cai%2C+Y">Yuchao Cai</a>, 
<a href="/search/stat?searchtype=author&query=Ma%2C+Y">Yuheng Ma</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+H">Hanfang Yang</a>, 
<a href="/search/stat?searchtype=author&query=Hang%2C+H">Hanyuan Hang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01981" title="Abstract">arXiv:2312.01981</a> (replaced) [<a href="/pdf/2312.01981" title="Download PDF">pdf</a>, <a href="/ps/2312.01981" title="Download PostScript">ps</a>, <a href="/format/2312.01981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Competition Dynamics in Mobile App Markets through User  Reviews
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Motger%2C+Q">Quim Motger</a>, 
<a href="/search/cs?searchtype=author&query=Franch%2C+X">Xavier Franch</a>, 
<a href="/search/cs?searchtype=author&query=Gervasi%2C+V">Vincenzo Gervasi</a>, 
<a href="/search/cs?searchtype=author&query=Marco%2C+J">Jordi Marco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02762" title="Abstract">arXiv:2312.02762</a> (replaced) [<a href="/pdf/2312.02762" title="Download PDF">pdf</a>, <a href="/format/2312.02762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Cortical Anomaly through Masked Encoding for Unsupervised  Heterogeneity Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+H">Hao-Chun Yang</a>, 
<a href="/search/eess?searchtype=author&query=Andreassen%2C+O">Ole Andreassen</a>, 
<a href="/search/eess?searchtype=author&query=Westlye%2C+L+T">Lars Tjelta Westlye</a>, 
<a href="/search/eess?searchtype=author&query=Marquand%2C+A+F">Andre F. Marquand</a>, 
<a href="/search/eess?searchtype=author&query=Beckmann%2C+C+F">Christian F. Beckmann</a>, 
<a href="/search/eess?searchtype=author&query=Wolfers%2C+T">Thomas Wolfers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, LaTeX; typos corrected, introduction refined
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03096" title="Abstract">arXiv:2312.03096</a> (replaced) [<a href="/pdf/2312.03096" title="Download PDF">pdf</a>, <a href="/format/2312.03096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Causes Polysemanticity? An Alternative Origin Story of Mixed  Selectivity from Incidental Causes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lecomte%2C+V">Victor Lecomte</a>, 
<a href="/search/cs?searchtype=author&query=Thaman%2C+K">Kushal Thaman</a>, 
<a href="/search/cs?searchtype=author&query=Schaeffer%2C+R">Rylan Schaeffer</a>, 
<a href="/search/cs?searchtype=author&query=Bashkansky%2C+N">Naomi Bashkansky</a>, 
<a href="/search/cs?searchtype=author&query=Chow%2C+T">Trevor Chow</a>, 
<a href="/search/cs?searchtype=author&query=Koyejo%2C+S">Sanmi Koyejo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04051" title="Abstract">arXiv:2312.04051</a> (replaced) [<a href="/pdf/2312.04051" title="Download PDF">pdf</a>, <a href="/ps/2312.04051" title="Download PostScript">ps</a>, <a href="/format/2312.04051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Corrigendum: PLS is contained in PLC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ishizuka%2C+T">Takashi Ishizuka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> There is a significant error in the proof of Lemma 14
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06441" title="Abstract">arXiv:2312.06441</a> (replaced) [<a href="/pdf/2312.06441" title="Download PDF">pdf</a>, <a href="/format/2312.06441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Graph-Based Fraud Detection in Sight of Heterophily and  Spectrum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Fan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Nan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+X">Xuezhi Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xibin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+H">Hai Wan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06505" title="Abstract">arXiv:2312.06505</a> (replaced) [<a href="/pdf/2312.06505" title="Download PDF">pdf</a>, <a href="/format/2312.06505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grounded Question-Answering in Long Egocentric Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di%2C+S">Shangzhe Di</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weidi Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06646" title="Abstract">arXiv:2312.06646</a> (replaced) [<a href="/pdf/2312.06646" title="Download PDF">pdf</a>, <a href="/format/2312.06646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational Copyright: Towards A Royalty Model for Music Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Junwei Deng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jiaqi Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07399" title="Abstract">arXiv:2312.07399</a> (replaced) [<a href="/pdf/2312.07399" title="Download PDF">pdf</a>, <a href="/format/2312.07399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models are Clinical Reasoners: Reasoning-Aware Diagnosis  Framework with Prompt-Generated Rationales
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwon%2C+T">Taeyoon Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Ong%2C+K+T">Kai Tzu-iunn Ong</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+D">Dongjin Kang</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+S">Seungjun Moon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+R">Jeong Ryong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+D">Dosik Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Sim%2C+Y">Yongsik Sim</a>, 
<a href="/search/cs?searchtype=author&query=Sohn%2C+B">Beomseok Sohn</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongha Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yeo%2C+J">Jinyoung Yeo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09533" title="Abstract">arXiv:2312.09533</a> (replaced) [<a href="/pdf/2312.09533" title="Download PDF">pdf</a>, <a href="/format/2312.09533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Robustness on Image Classification with $k$-means
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Omari%2C+R">Rollin Omari</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junae Kim</a>, 
<a href="/search/cs?searchtype=author&query=Montague%2C+P">Paul Montague</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, 2 equations, 1 algorithm
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10622" title="Abstract">arXiv:2312.10622</a> (replaced) [<a href="/pdf/2312.10622" title="Download PDF">pdf</a>, <a href="/format/2312.10622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unit Test Generation using Generative AI : A Comparative Performance  Analysis of Autogeneration Tools
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhatia%2C+S">Shreya Bhatia</a>, 
<a href="/search/cs?searchtype=author&query=Gandhi%2C+T">Tarushi Gandhi</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+D">Dhruv Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Jalote%2C+P">Pankaj Jalote</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to LLM4Code @ ICSE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12173" title="Abstract">arXiv:2312.12173</a> (replaced) [<a href="/pdf/2312.12173" title="Download PDF">pdf</a>, <a href="/format/2312.12173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Globally Convergent Policy Gradient Method for Linear Quadratic  Gaussian (LQG) Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sadamoto%2C+T">Tomonori Sadamoto</a>, 
<a href="/search/math?searchtype=author&query=Nakamata%2C+F">Fumiya Nakamata</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14916" title="Abstract">arXiv:2312.14916</a> (replaced) [<a href="/pdf/2312.14916" title="Download PDF">pdf</a>, <a href="/format/2312.14916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complexity of Local Search for Euclidean Clustering Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manthey%2C+B">Bodo Manthey</a>, 
<a href="/search/cs?searchtype=author&query=Morawietz%2C+N">Nils Morawietz</a>, 
<a href="/search/cs?searchtype=author&query=van+Rhijn%2C+J">Jesse van Rhijn</a>, 
<a href="/search/cs?searchtype=author&query=Sommer%2C+F">Frank Sommer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15230" title="Abstract">arXiv:2312.15230</a> (replaced) [<a href="/pdf/2312.15230" title="Download PDF">pdf</a>, <a href="/format/2312.15230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PERP: Rethinking the Prune-Retrain Paradigm in the Era of LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zimmer%2C+M">Max Zimmer</a>, 
<a href="/search/cs?searchtype=author&query=Andoni%2C+M">Megi Andoni</a>, 
<a href="/search/cs?searchtype=author&query=Spiegel%2C+C">Christoph Spiegel</a>, 
<a href="/search/cs?searchtype=author&query=Pokutta%2C+S">Sebastian Pokutta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 4 figures, 15 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16044" title="Abstract">arXiv:2312.16044</a> (replaced) [<a href="/pdf/2312.16044" title="Download PDF">pdf</a>, <a href="/format/2312.16044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMLight: Large Language Models as Traffic Signal Control Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+S">Siqi Lai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weijia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16690" title="Abstract">arXiv:2312.16690</a> (replaced) [<a href="/pdf/2312.16690" title="Download PDF">pdf</a>, <a href="/format/2312.16690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resonance based schemes for SPDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Armstrong-Goodall%2C+J">Jacob Armstrong-Goodall</a>, 
<a href="/search/math?searchtype=author&query=Bruned%2C+Y">Yvain Bruned</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17133" title="Abstract">arXiv:2312.17133</a> (replaced) [<a href="/pdf/2312.17133" title="Download PDF">pdf</a>, <a href="/format/2312.17133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ARTrackV2: Prompting Autoregressive Tracker Where to Look and How to  Describe
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yifan Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zeyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yihong Gong</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xing Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17173" title="Abstract">arXiv:2312.17173</a> (replaced) [<a href="/pdf/2312.17173" title="Download PDF">pdf</a>, <a href="/format/2312.17173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Vacuous Generalization Bounds for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Lotfi%2C+S">Sanae Lotfi</a>, 
<a href="/search/stat?searchtype=author&query=Finzi%2C+M">Marc Finzi</a>, 
<a href="/search/stat?searchtype=author&query=Kuang%2C+Y">Yilun Kuang</a>, 
<a href="/search/stat?searchtype=author&query=Rudner%2C+T+G+J">Tim G. J. Rudner</a>, 
<a href="/search/stat?searchtype=author&query=Goldblum%2C+M">Micah Goldblum</a>, 
<a href="/search/stat?searchtype=author&query=Wilson%2C+A+G">Andrew Gordon Wilson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17430" title="Abstract">arXiv:2312.17430</a> (replaced) [<a href="/pdf/2312.17430" title="Download PDF">pdf</a>, <a href="/format/2312.17430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LEFL: Low Entropy Client Sampling in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abebe%2C+W">Waqwoya Abebe</a>, 
<a href="/search/cs?searchtype=author&query=Munoz%2C+P">Pablo Munoz</a>, 
<a href="/search/cs?searchtype=author&query=Jannesari%2C+A">Ali Jannesari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00236" title="Abstract">arXiv:2401.00236</a> (replaced) [<a href="/pdf/2401.00236" title="Download PDF">pdf</a>, <a href="/ps/2401.00236" title="Download PostScript">ps</a>, <a href="/format/2401.00236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simultaneously determine elastic impedance and shape by a Newton-type  iterative method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sun%2C+Y">Yao Sun</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+P">Pan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00691" title="Abstract">arXiv:2401.00691</a> (replaced) [<a href="/pdf/2401.00691" title="Download PDF">pdf</a>, <a href="/format/2401.00691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Gradient Descent for Additive Nonparametric Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/stat?searchtype=author&query=Klusowski%2C+J+M">Jason M. Klusowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01269" title="Abstract">arXiv:2401.01269</a> (replaced) [<a href="/pdf/2401.01269" title="Download PDF">pdf</a>, <a href="/format/2401.01269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLbezpeky: Leveraging Large Language Models for Vulnerability Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mathews%2C+N+S">Noble Saji Mathews</a>, 
<a href="/search/cs?searchtype=author&query=Brus%2C+Y">Yelizaveta Brus</a>, 
<a href="/search/cs?searchtype=author&query=Aafer%2C+Y">Yousra Aafer</a>, 
<a href="/search/cs?searchtype=author&query=Nagappan%2C+M">Meiyappan Nagappan</a>, 
<a href="/search/cs?searchtype=author&query=McIntosh%2C+S">Shane McIntosh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This project report was presented as a part of the course CS858 at the University of Waterloo under the supervision of Prof. Yousra Aafer
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01335" title="Abstract">arXiv:2401.01335</a> (replaced) [<a href="/pdf/2401.01335" title="Download PDF">pdf</a>, <a href="/format/2401.01335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Play Fine-Tuning Converts Weak Language Models to Strong Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zixiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yihe Deng</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Huizhuo Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+K">Kaixuan Ji</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Quanquan Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 6 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01854" title="Abstract">arXiv:2401.01854</a> (replaced) [<a href="/pdf/2401.01854" title="Download PDF">pdf</a>, <a href="/format/2401.01854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilingual Instruction Tuning With Just a Pinch of Multilinguality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaham%2C+U">Uri Shaham</a>, 
<a href="/search/cs?searchtype=author&query=Herzig%2C+J">Jonathan Herzig</a>, 
<a href="/search/cs?searchtype=author&query=Aharoni%2C+R">Roee Aharoni</a>, 
<a href="/search/cs?searchtype=author&query=Szpektor%2C+I">Idan Szpektor</a>, 
<a href="/search/cs?searchtype=author&query=Tsarfaty%2C+R">Reut Tsarfaty</a>, 
<a href="/search/cs?searchtype=author&query=Eyal%2C+M">Matan Eyal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04301" title="Abstract">arXiv:2401.04301</a> (replaced) [<a href="/pdf/2401.04301" title="Download PDF">pdf</a>, <a href="/format/2401.04301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Setting the Record Straight on Transformer Oversmoothing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dovonon%2C+G+J">Gb&#xe8;tondji J-S Dovonon</a>, 
<a href="/search/cs?searchtype=author&query=Bronstein%2C+M+M">Michael M. Bronstein</a>, 
<a href="/search/cs?searchtype=author&query=Kusner%2C+M+J">Matt J. Kusner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04305" title="Abstract">arXiv:2401.04305</a> (replaced) [<a href="/pdf/2401.04305" title="Download PDF">pdf</a>, <a href="/format/2401.04305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Deep Active Learning &amp; Data Subset Selection: Unifying  Principles with Information-Theory Intuitions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kirsch%2C+A">Andreas Kirsch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04632" title="Abstract">arXiv:2401.04632</a> (replaced) [<a href="/pdf/2401.04632" title="Download PDF">pdf</a>, <a href="/format/2401.04632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypercomplex neural network in time series forecasting of stock data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kycia%2C+R">Rados&#x142;aw Kycia</a>, 
<a href="/search/cs?searchtype=author&query=Niemczynowicz%2C+A">Agnieszka Niemczynowicz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05321" title="Abstract">arXiv:2401.05321</a> (replaced) [<a href="/pdf/2401.05321" title="Download PDF">pdf</a>, <a href="/format/2401.05321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Time-Space Tradeoffs for Matrix Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beame%2C+P">Paul Beame</a>, 
<a href="/search/cs?searchtype=author&query=Kornerup%2C+N">Niels Kornerup</a>, 
<a href="/search/cs?searchtype=author&query=Whitmeyer%2C+M">Michael Whitmeyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 2 figures Replacement adds an improved lower bound for boolean matrix multiplication, adds Michael Whitmeyer as an author, fixes Niels Kornerup's funding information, and fixes some minor typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06056" title="Abstract">arXiv:2401.06056</a> (replaced) [<a href="/pdf/2401.06056" title="Download PDF">pdf</a>, <a href="/format/2401.06056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MatSynth: A Modern PBR Materials Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vecchio%2C+G">Giuseppe Vecchio</a>, 
<a href="/search/cs?searchtype=author&query=Deschaintre%2C+V">Valentin Deschaintre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06366" title="Abstract">arXiv:2401.06366</a> (replaced) [<a href="/pdf/2401.06366" title="Download PDF">pdf</a>, <a href="/ps/2401.06366" title="Download PostScript">ps</a>, <a href="/format/2401.06366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Network Anatomy and Real-Time Measurement of Nvidia GeForce NOW Cloud  Gaming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+M">Minzhao Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Madanapalli%2C+S+C">Sharat Chandra Madanapalli</a>, 
<a href="/search/cs?searchtype=author&query=Vishwanath%2C+A">Arun Vishwanath</a>, 
<a href="/search/cs?searchtype=author&query=Sivaraman%2C+V">Vijay Sivaraman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted at Passive and Active Measurement (PAM) conference Mar 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06713" title="Abstract">arXiv:2401.06713</a> (replaced) [<a href="/pdf/2401.06713" title="Download PDF">pdf</a>, <a href="/format/2401.06713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Picasso: Memory-Efficient Graph Coloring Using Palettes With  Applications in Quantum Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferdous%2C+S+M">S M Ferdous</a>, 
<a href="/search/cs?searchtype=author&query=Neff%2C+R">Reece Neff</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Bo Peng</a>, 
<a href="/search/cs?searchtype=author&query=Shuvo%2C+S">Salman Shuvo</a>, 
<a href="/search/cs?searchtype=author&query=Minutoli%2C+M">Marco Minutoli</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+S">Sayak Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Kowalski%2C+K">Karol Kowalski</a>, 
<a href="/search/cs?searchtype=author&query=Becchi%2C+M">Michela Becchi</a>, 
<a href="/search/cs?searchtype=author&query=Halappanavar%2C+M">Mahantesh Halappanavar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IPDPS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09002" title="Abstract">arXiv:2401.09002</a> (replaced) [<a href="/pdf/2401.09002" title="Download PDF">pdf</a>, <a href="/format/2401.09002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AttackEval: How to Evaluate the Effectiveness of Jailbreak Attacking on  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=shu%2C+D">Dong shu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Mingyu Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Suiyuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Beichen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zihao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongfeng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09053" title="Abstract">arXiv:2401.09053</a> (replaced) [<a href="/pdf/2401.09053" title="Download PDF">pdf</a>, <a href="/ps/2401.09053" title="Download PostScript">ps</a>, <a href="/format/2401.09053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On some computational properties of open sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Normann%2C+D">Dag Normann</a>, 
<a href="/search/math?searchtype=author&query=Sanders%2C+S">Sam Sanders</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09273" title="Abstract">arXiv:2401.09273</a> (replaced) [<a href="/pdf/2401.09273" title="Download PDF">pdf</a>, <a href="/format/2401.09273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A classification of bisimilarities for general Markov decision processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moroni%2C+M+S">Mart&#xed;n Santiago Moroni</a>, 
<a href="/search/cs?searchtype=author&query=Terraf%2C+P+S">Pedro S&#xe1;nchez Terraf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages. v2: Reference to prior example due to D. Gburek and added acknowledgment
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10386" title="Abstract">arXiv:2401.10386</a> (replaced) [<a href="/pdf/2401.10386" title="Download PDF">pdf</a>, <a href="/format/2401.10386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noninvasive Acute Compartment Syndrome Diagnosis Using Random Forest  Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hweij%2C+Z+A">Zaina Abu Hweij</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+F">Florence Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sophie Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Medical Physics (physics.med-ph)

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11911" title="Abstract">arXiv:2401.11911</a> (replaced) [<a href="/pdf/2401.11911" title="Download PDF">pdf</a>, <a href="/format/2401.11911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blinded by Generated Contexts: How Language Models Merge Generated and  Retrieved Contexts for Open-Domain QA?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+H">Hexiang Tan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wanli Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuanzhuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Q">Qi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12005" title="Abstract">arXiv:2401.12005</a> (replaced) [<a href="/pdf/2401.12005" title="Download PDF">pdf</a>, <a href="/format/2401.12005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ALMs: Authorial Language Models for Authorship Attribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Weihang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Murakami%2C+A">Akira Murakami</a>, 
<a href="/search/cs?searchtype=author&query=Grieve%2C+J">Jack Grieve</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12117" title="Abstract">arXiv:2401.12117</a> (replaced) [<a href="/pdf/2401.12117" title="Download PDF">pdf</a>, <a href="/format/2401.12117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Curious Case of Nonverbal Abstract Reasoning with Multi-Modal Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahrabian%2C+K">Kian Ahrabian</a>, 
<a href="/search/cs?searchtype=author&query=Sourati%2C+Z">Zhivar Sourati</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+K">Kexuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiarui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yifan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Morstatter%2C+F">Fred Morstatter</a>, 
<a href="/search/cs?searchtype=author&query=Pujara%2C+J">Jay Pujara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and datasets are available at <a href="https://github.com/kahrabian/mllm-nvar">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12258" title="Abstract">arXiv:2401.12258</a> (replaced) [<a href="/pdf/2401.12258" title="Download PDF">pdf</a>, <a href="/format/2401.12258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergent Dominance Hierarchies in Reinforcement Learning Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rachum%2C+R">Ram Rachum</a>, 
<a href="/search/cs?searchtype=author&query=Nakar%2C+Y">Yonatan Nakar</a>, 
<a href="/search/cs?searchtype=author&query=Tomlinson%2C+B">Bill Tomlinson</a>, 
<a href="/search/cs?searchtype=author&query=Alon%2C+N">Nitay Alon</a>, 
<a href="/search/cs?searchtype=author&query=Mirsky%2C+R">Reuth Mirsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12467" title="Abstract">arXiv:2401.12467</a> (replaced) [<a href="/pdf/2401.12467" title="Download PDF">pdf</a>, <a href="/format/2401.12467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An open dataset for the evolution of oracle bone characters: EVOBC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+H">Haisu Guan</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+J">Jinpeng Wan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaile Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+Z">Zhebin Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lianwen Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12561" title="Abstract">arXiv:2401.12561</a> (replaced) [<a href="/pdf/2401.12561" title="Download PDF">pdf</a>, <a href="/format/2401.12561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EndoGaussian: Real-time Gaussian Splatting for Dynamic Endoscopic Scene  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yifan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yixuan Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13666" title="Abstract">arXiv:2401.13666</a> (replaced) [<a href="/e-print/2401.13666" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algebraic methods for solving recognition problems with non-crossing  classes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kabulov%2C+A">Anvar Kabulov</a>, 
<a href="/search/cs?searchtype=author&query=Babadzhanov%2C+A">Alimdzhan Babadzhanov</a>, 
<a href="/search/cs?searchtype=author&query=Saymanov%2C+I">Islambek Saymanov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> I will rework and improve it and post it again
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14887" title="Abstract">arXiv:2401.14887</a> (replaced) [<a href="/pdf/2401.14887" title="Download PDF">pdf</a>, <a href="/format/2401.14887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Power of Noise: Redefining Retrieval for RAG Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cuconasu%2C+F">Florin Cuconasu</a>, 
<a href="/search/cs?searchtype=author&query=Trappolini%2C+G">Giovanni Trappolini</a>, 
<a href="/search/cs?searchtype=author&query=Siciliano%2C+F">Federico Siciliano</a>, 
<a href="/search/cs?searchtype=author&query=Filice%2C+S">Simone Filice</a>, 
<a href="/search/cs?searchtype=author&query=Campagnano%2C+C">Cesare Campagnano</a>, 
<a href="/search/cs?searchtype=author&query=Maarek%2C+Y">Yoelle Maarek</a>, 
<a href="/search/cs?searchtype=author&query=Tonellotto%2C+N">Nicola Tonellotto</a>, 
<a href="/search/cs?searchtype=author&query=Silvestri%2C+F">Fabrizio Silvestri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15042" title="Abstract">arXiv:2401.15042</a> (replaced) [<a href="/pdf/2401.15042" title="Download PDF">pdf</a>, <a href="/format/2401.15042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PROXYQA: An Alternative Framework for Evaluating Long-Form Text  Generation with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+H">Haochen Tan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhijiang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhili Liu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yunlong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoguang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yasheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+L">Lifeng Shang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Linqi Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15170" title="Abstract">arXiv:2401.15170</a> (replaced) [<a href="/pdf/2401.15170" title="Download PDF">pdf</a>, <a href="/format/2401.15170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Qualitative Coding with LLMs: Chain-of-Thought Reasoning  Matches Human Performance in Some Hermeneutic Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dunivin%2C+Z+O">Zackary Okun Dunivin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15229" title="Abstract">arXiv:2401.15229</a> (replaced) [<a href="/pdf/2401.15229" title="Download PDF">pdf</a>, <a href="/format/2401.15229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolving AI Risk Management: A Maturity Model based on the NIST AI Risk  Management Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dotan%2C+R">Ravit Dotan</a>, 
<a href="/search/cs?searchtype=author&query=Blili-Hamelin%2C+B">Borhane Blili-Hamelin</a>, 
<a href="/search/cs?searchtype=author&query=Madhavan%2C+R">Ravi Madhavan</a>, 
<a href="/search/cs?searchtype=author&query=Matthews%2C+J">Jeanna Matthews</a>, 
<a href="/search/cs?searchtype=author&query=Scarpino%2C+J">Joshua Scarpino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15292" title="Abstract">arXiv:2401.15292</a> (replaced) [<a href="/pdf/2401.15292" title="Download PDF">pdf</a>, <a href="/format/2401.15292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Block Sparse Regularization under Arbitrary Linear Transform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Furuhashi%2C+T">Takanobu Furuhashi</a>, 
<a href="/search/cs?searchtype=author&query=Hontani%2C+H">Hidekata Hontani</a>, 
<a href="/search/cs?searchtype=author&query=Yokota%2C+T">Tatsuya Yokota</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15365" title="Abstract">arXiv:2401.15365</a> (replaced) [<a href="/pdf/2401.15365" title="Download PDF">pdf</a>, <a href="/format/2401.15365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An open dataset for oracle bone script recognition and decipherment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaile Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shengwei Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yongge Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+J">Jinpeng Wan</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+H">Haisu Guan</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+Z">Zhebin Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lianwen Jin</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuliang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15456" title="Abstract">arXiv:2401.15456</a> (replaced) [<a href="/pdf/2401.15456" title="Download PDF">pdf</a>, <a href="/ps/2401.15456" title="Download PostScript">ps</a>, <a href="/format/2401.15456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Product Mixing in Compact Lie Groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ellis%2C+D">David Ellis</a>, 
<a href="/search/math?searchtype=author&query=Kindler%2C+G">Guy Kindler</a>, 
<a href="/search/math?searchtype=author&query=Lifshitz%2C+N">Noam Lifshitz</a>, 
<a href="/search/math?searchtype=author&query=Minzer%2C+D">Dor Minzer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Bugs fixed in the proofs of Claim 10.5 and Lemma 10.6. Other minor changes to improve readability
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC); Group Theory (math.GR); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15719" title="Abstract">arXiv:2401.15719</a> (replaced) [<a href="/pdf/2401.15719" title="Download PDF">pdf</a>, <a href="/ps/2401.15719" title="Download PostScript">ps</a>, <a href="/format/2401.15719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rates of Convergence in the Central Limit Theorem for Markov Chains,  with an Application to TD Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Srikant%2C+R">R. Srikant</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16013" title="Abstract">arXiv:2401.16013</a> (replaced) [<a href="/pdf/2401.16013" title="Download PDF">pdf</a>, <a href="/format/2401.16013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SERL: A Software Suite for Sample-Efficient Robotic Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jianlan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zheyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Charles Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y+L">You Liang Tan</a>, 
<a href="/search/cs?searchtype=author&query=Berg%2C+J">Jacob Berg</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Archit Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Schaal%2C+S">Stefan Schaal</a>, 
<a href="/search/cs?searchtype=author&query=Finn%2C+C">Chelsea Finn</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhishek Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16268" title="Abstract">arXiv:2401.16268</a> (replaced) [<a href="/pdf/2401.16268" title="Download PDF">pdf</a>, <a href="/ps/2401.16268" title="Download PostScript">ps</a>, <a href="/format/2401.16268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A.I. In All The Wrong Places
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%B6hlen%2C+M">Marc B&#xf6;hlen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruolin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xiaoxu Dong</a>, 
<a href="/search/cs?searchtype=author&query=Gopaladinne%2C+S">Srikar Gopaladinne</a>, 
<a href="/search/cs?searchtype=author&query=Gorla%2C+H">Hemanth Gorla</a>, 
<a href="/search/cs?searchtype=author&query=Kandukuri%2C+D">Divya Kandukuri</a>, 
<a href="/search/cs?searchtype=author&query=Mansfield%2C+S">Sean Mansfield</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 3 tables, 4 images
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.18050" title="Abstract">arXiv:2401.18050</a> (replaced) [<a href="/pdf/2401.18050" title="Download PDF">pdf</a>, <a href="/ps/2401.18050" title="Download PostScript">ps</a>, <a href="/format/2401.18050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypermultiplexed Integrated Tensor Optical Processor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ou%2C+S">Shaoyuan Ou</a>, 
<a href="/search/cs?searchtype=author&query=Sludds%2C+A">Alexander Sludds</a>, 
<a href="/search/cs?searchtype=author&query=Hamerly%2C+R">Ryan Hamerly</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Ke Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+H">Hanke Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+E">Eric Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Englund%2C+D">Dirk Englund</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+M">Mengjie Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zaijun Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Optics (physics.optics)

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00060" title="Abstract">arXiv:2402.00060</a> (replaced) [<a href="/pdf/2402.00060" title="Download PDF">pdf</a>, <a href="/format/2402.00060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Treatment of Epistemic Uncertainty in Conjunction Analysis with  Dempster-Shafer Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanchez%2C+L">Luis Sanchez</a>, 
<a href="/search/cs?searchtype=author&query=Vasile%2C+M">Massimiliano Vasile</a>, 
<a href="/search/cs?searchtype=author&query=Sanvido%2C+S">Silvia Sanvido</a>, 
<a href="/search/cs?searchtype=author&query=Mertz%2C+K">Klaus Mertz</a>, 
<a href="/search/cs?searchtype=author&query=Taillan%2C+C">Christophe Taillan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 23 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Theory (cs.IT); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00220" title="Abstract">arXiv:2402.00220</a> (replaced) [<a href="/pdf/2402.00220" title="Download PDF">pdf</a>, <a href="/format/2402.00220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Circuit Approach to Constructing Blockchains on Blockchains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tas%2C+E+N">Ertem Nusret Tas</a>, 
<a href="/search/cs?searchtype=author&query=Tse%2C+D">David Tse</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00559" title="Abstract">arXiv:2402.00559</a> (replaced) [<a href="/pdf/2402.00559" title="Download PDF">pdf</a>, <a href="/format/2402.00559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Chain-of-Thought Is as Strong as Its Weakest Link: A Benchmark for  Verifiers of Reasoning Chains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jacovi%2C+A">Alon Jacovi</a>, 
<a href="/search/cs?searchtype=author&query=Bitton%2C+Y">Yonatan Bitton</a>, 
<a href="/search/cs?searchtype=author&query=Bohnet%2C+B">Bernd Bohnet</a>, 
<a href="/search/cs?searchtype=author&query=Herzig%2C+J">Jonathan Herzig</a>, 
<a href="/search/cs?searchtype=author&query=Honovich%2C+O">Or Honovich</a>, 
<a href="/search/cs?searchtype=author&query=Tseng%2C+M">Michael Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Collins%2C+M">Michael Collins</a>, 
<a href="/search/cs?searchtype=author&query=Aharoni%2C+R">Roee Aharoni</a>, 
<a href="/search/cs?searchtype=author&query=Geva%2C+M">Mor Geva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Dataset at <a href="https://huggingface.co/datasets/google/reveal">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00746" title="Abstract">arXiv:2402.00746</a> (replaced) [<a href="/pdf/2402.00746" title="Download PDF">pdf</a>, <a href="/format/2402.00746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Health-LLM: Personalized Retrieval-Augmented Disease Prediction Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Mingyu Jin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qinkai Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+D">Dong Shu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Suiyuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+M">Mengnan Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Y">Yanda Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00786" title="Abstract">arXiv:2402.00786</a> (replaced) [<a href="/pdf/2402.00786" title="Download PDF">pdf</a>, <a href="/format/2402.00786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CroissantLLM: A Truly Bilingual French-English Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faysse%2C+M">Manuel Faysse</a>, 
<a href="/search/cs?searchtype=author&query=Fernandes%2C+P">Patrick Fernandes</a>, 
<a href="/search/cs?searchtype=author&query=Guerreiro%2C+N+M">Nuno M. Guerreiro</a>, 
<a href="/search/cs?searchtype=author&query=Loison%2C+A">Ant&#xf3;nio Loison</a>, 
<a href="/search/cs?searchtype=author&query=Alves%2C+D+M">Duarte M. Alves</a>, 
<a href="/search/cs?searchtype=author&query=Corro%2C+C">Caio Corro</a>, 
<a href="/search/cs?searchtype=author&query=Boizard%2C+N">Nicolas Boizard</a>, 
<a href="/search/cs?searchtype=author&query=Alves%2C+J">Jo&#xe3;o Alves</a>, 
<a href="/search/cs?searchtype=author&query=Rei%2C+R">Ricardo Rei</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+P+H">Pedro H. Martins</a>, 
<a href="/search/cs?searchtype=author&query=Casademunt%2C+A+B">Antoni Bigata Casademunt</a>, 
<a href="/search/cs?searchtype=author&query=Yvon%2C+F">Fran&#xe7;ois Yvon</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+A+F+T">Andr&#xe9; F.T. Martins</a>, 
<a href="/search/cs?searchtype=author&query=Viaud%2C+G">Gautier Viaud</a>, 
<a href="/search/cs?searchtype=author&query=Hudelot%2C+C">C&#xe9;line Hudelot</a>, 
<a href="/search/cs?searchtype=author&query=Colombo%2C+P">Pierre Colombo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00899" title="Abstract">arXiv:2402.00899</a> (replaced) [<a href="/pdf/2402.00899" title="Download PDF">pdf</a>, <a href="/format/2402.00899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly Supervised Learners for Correction of AI Errors with Provable  Performance Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tyukin%2C+I+Y">Ivan Y. Tyukin</a>, 
<a href="/search/cs?searchtype=author&query=Tyukina%2C+T">Tatiana Tyukina</a>, 
<a href="/search/cs?searchtype=author&query=van+Helden%2C+D">Daniel van Helden</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zedong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Mirkes%2C+E+M">Evgeny M. Mirkes</a>, 
<a href="/search/cs?searchtype=author&query=Sutton%2C+O+J">Oliver J. Sutton</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qinghua Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gorban%2C+A+N">Alexander N. Gorban</a>, 
<a href="/search/cs?searchtype=author&query=Allison%2C+P">Penelope Allison</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.01155" title="Abstract">arXiv:2402.01155</a> (replaced) [<a href="/pdf/2402.01155" title="Download PDF">pdf</a>, <a href="/format/2402.01155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CABINET: Content Relevance based Noise Reduction for Table Question  Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patnaik%2C+S">Sohan Patnaik</a>, 
<a href="/search/cs?searchtype=author&query=Changwal%2C+H">Heril Changwal</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+M">Milan Aggarwal</a>, 
<a href="/search/cs?searchtype=author&query=Bhatia%2C+S">Sumit Bhatia</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+Y">Yaman Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+B">Balaji Krishnamurthy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICLR 2024 (spotlight)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.01632" title="Abstract">arXiv:2402.01632</a> (replaced) [<a href="/pdf/2402.01632" title="Download PDF">pdf</a>, <a href="/format/2402.01632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Lengthscales: No-regret Bayesian Optimisation With Unknown  Hyperparameters Of Any Type
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ziomek%2C+J">Juliusz Ziomek</a>, 
<a href="/search/cs?searchtype=author&query=Adachi%2C+M">Masaki Adachi</a>, 
<a href="/search/cs?searchtype=author&query=Osborne%2C+M+A">Michael A. Osborne</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02006" title="Abstract">arXiv:2402.02006</a> (replaced) [<a href="/pdf/2402.02006" title="Download PDF">pdf</a>, <a href="/format/2402.02006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PresAIse, A Prescriptive AI Solution for Enterprises
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wei Sun</a>, 
<a href="/search/cs?searchtype=author&query=McFaddin%2C+S">Scott McFaddin</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+L+H">Linh Ha Tran</a>, 
<a href="/search/cs?searchtype=author&query=Subramanian%2C+S">Shivaram Subramanian</a>, 
<a href="/search/cs?searchtype=author&query=Greenewald%2C+K">Kristjan Greenewald</a>, 
<a href="/search/cs?searchtype=author&query=Tenzin%2C+Y">Yeshi Tenzin</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Z">Zack Xue</a>, 
<a href="/search/cs?searchtype=author&query=Drissi%2C+Y">Youssef Drissi</a>, 
<a href="/search/cs?searchtype=author&query=Ettl%2C+M">Markus Ettl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02196" title="Abstract">arXiv:2402.02196</a> (replaced) [<a href="/pdf/2402.02196" title="Download PDF">pdf</a>, <a href="/format/2402.02196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample-Efficient Clustering and Conquer Procedures for Parallel  Large-Scale Ranking and Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhang%2C+Z">Zishi Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Peng%2C+Y">Yijie Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02316" title="Abstract">arXiv:2402.02316</a> (replaced) [<a href="/pdf/2402.02316" title="Download PDF">pdf</a>, <a href="/format/2402.02316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Your Diffusion Model is Secretly a Certifiably Robust Classifier
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huanran Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yinpeng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+S">Shitong Shao</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Z">Zhongkai Hao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hang Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02651" title="Abstract">arXiv:2402.02651</a> (replaced) [<a href="/pdf/2402.02651" title="Download PDF">pdf</a>, <a href="/format/2402.02651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision-Language Models Provide Promptable Representations for  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">William Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mees%2C+O">Oier Mees</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Aviral Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03181" title="Abstract">arXiv:2402.03181</a> (replaced) [<a href="/pdf/2402.03181" title="Download PDF">pdf</a>, <a href="/format/2402.03181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> C-RAG: Certified Generation Risks for Retrieval-Augmented Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Mintong Kang</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCrel%2C+N+M">Nezihe Merve G&#xfc;rel</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Ning Yu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dawn Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03496" title="Abstract">arXiv:2402.03496</a> (replaced) [<a href="/pdf/2402.03496" title="Download PDF">pdf</a>, <a href="/format/2402.03496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can We Remove the Square-Root in Adaptive Gradient Methods? A  Second-Order Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Wu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Dangel%2C+F">Felix Dangel</a>, 
<a href="/search/cs?searchtype=author&query=Eschenhagen%2C+R">Runa Eschenhagen</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+J">Juhan Bae</a>, 
<a href="/search/cs?searchtype=author&query=Turner%2C+R+E">Richard E. Turner</a>, 
<a href="/search/cs?searchtype=author&query=Makhzani%2C+A">Alireza Makhzani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03666" title="Abstract">arXiv:2402.03666</a> (replaced) [<a href="/pdf/2402.03666" title="Download PDF">pdf</a>, <a href="/format/2402.03666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QuEST: Low-bit Diffusion Model Quantization via Efficient Selective  Finetuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+Y">Yuzhang Shang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhihang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Junyi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yan Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03781" title="Abstract">arXiv:2402.03781</a> (replaced) [<a href="/pdf/2402.03781" title="Download PDF">pdf</a>, <a href="/format/2402.03781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MolTC: Towards Molecular Relational Modeling In Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Fang%2C+J">Junfeng Fang</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+S">Shuai Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Wu%2C+C">Chang Wu</a>, 
<a href="/search/q-bio?searchtype=author&query=Yang%2C+Z">Zhengyi Yang</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+S">Sihang Li</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+K">Kun Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Du%2C+W">Wenjie Du</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+X">Xiang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04020" title="Abstract">arXiv:2402.04020</a> (replaced) [<a href="/pdf/2402.04020" title="Download PDF">pdf</a>, <a href="/ps/2402.04020" title="Download PostScript">ps</a>, <a href="/format/2402.04020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Examining Rail Transportation Route of Crude Oil in the United States  Using Crowdsourced Social Media Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuandong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Uddin%2C+M">Majbah Uddin</a>, 
<a href="/search/cs?searchtype=author&query=Chin%2C+S">Shih-Miao Chin</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+H">Ho-Ling Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaoli Chen</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transportation Research Record, 2678(1), 218-228 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04338" title="Abstract">arXiv:2402.04338</a> (replaced) [<a href="/e-print/2402.04338" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Logical recognition method for solving the problem of identification in  the Internet of Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saymanov%2C+I">Islambek Saymanov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> I will rework and improve it and post it again
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04390" title="Abstract">arXiv:2402.04390</a> (replaced) [<a href="/pdf/2402.04390" title="Download PDF">pdf</a>, <a href="/ps/2402.04390" title="Download PostScript">ps</a>, <a href="/format/2402.04390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Densely Multiplied Physics Informed Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+F">Feilong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+X">Xiaonan Hou</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+M">Min Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04691" title="Abstract">arXiv:2402.04691</a> (replaced) [<a href="/pdf/2402.04691" title="Download PDF">pdf</a>, <a href="/ps/2402.04691" title="Download PostScript">ps</a>, <a href="/format/2402.04691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Operators with Stochastic Gradient Descent in General Hilbert  Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Shi%2C+L">Lei Shi</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+J">Jia-Qi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 56 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Functional Analysis (math.FA); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05035" title="Abstract">arXiv:2402.05035</a> (replaced) [<a href="/e-print/2402.05035" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Domain Generalization for Medical Image Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+Z">Ziwei Niu</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+S">Shuyi Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shiao Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yen-wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Lanfen Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a withdrawn submission and will be considered invalid. Due to some errors and overlap with published papers, we have chosen to withdraw it
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05061" title="Abstract">arXiv:2402.05061</a> (replaced) [<a href="/pdf/2402.05061" title="Download PDF">pdf</a>, <a href="/ps/2402.05061" title="Download PostScript">ps</a>, <a href="/format/2402.05061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $H_{\infty}$-Optimal Estimator Synthesis for Coupled Linear 2D PDEs  using Convex Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jagt%2C+D+S">Declan S. Jagt</a>, 
<a href="/search/math?searchtype=author&query=Peet%2C+M+M">Matthew M. Peet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05098" title="Abstract">arXiv:2402.05098</a> (replaced) [<a href="/pdf/2402.05098" title="Download PDF">pdf</a>, <a href="/format/2402.05098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On diffusion models for amortized inference: Benchmarking and improving  stochastic control and sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sendera%2C+M">Marcin Sendera</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+S">Sarthak Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Lemos%2C+P">Pablo Lemos</a>, 
<a href="/search/cs?searchtype=author&query=Scimeca%2C+L">Luca Scimeca</a>, 
<a href="/search/cs?searchtype=author&query=Rector-Brooks%2C+J">Jarrid Rector-Brooks</a>, 
<a href="/search/cs?searchtype=author&query=Adam%2C+A">Alexandre Adam</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>, 
<a href="/search/cs?searchtype=author&query=Malkin%2C+N">Nikolay Malkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages; code: <a href="https://github.com/GFNOrg/gfn-diffusion">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05643" title="Abstract">arXiv:2402.05643</a> (replaced) [<a href="/pdf/2402.05643" title="Download PDF">pdf</a>, <a href="/format/2402.05643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Token-Based World Models with Parallel Observation Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cohen%2C+L">Lior Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kaixin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+B">Bingyi Kang</a>, 
<a href="/search/cs?searchtype=author&query=Mannor%2C+S">Shie Mannor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05785" title="Abstract">arXiv:2402.05785</a> (replaced) [<a href="/pdf/2402.05785" title="Download PDF">pdf</a>, <a href="/format/2402.05785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Limits of Transformer Language Models on Learning Algorithmic  Compositions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thomm%2C+J">Jonathan Thomm</a>, 
<a href="/search/cs?searchtype=author&query=Terzic%2C+A">Aleksandar Terzic</a>, 
<a href="/search/cs?searchtype=author&query=Karunaratne%2C+G">Geethan Karunaratne</a>, 
<a href="/search/cs?searchtype=author&query=Camposampiero%2C+G">Giacomo Camposampiero</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>, 
<a href="/search/cs?searchtype=author&query=Rahimi%2C+A">Abbas Rahimi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05872" title="Abstract">arXiv:2402.05872</a> (replaced) [<a href="/pdf/2402.05872" title="Download PDF">pdf</a>, <a href="/format/2402.05872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> You&#x27;ve Got to Feel It To Believe It: Multi-Modal Bayesian Inference for  Semantic and Property Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ewen%2C+P">Parker Ewen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuzhen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Anran Li</a>, 
<a href="/search/cs?searchtype=author&query=Bagali%2C+A">Anup Bagali</a>, 
<a href="/search/cs?searchtype=author&query=Gunjal%2C+G">Gitesh Gunjal</a>, 
<a href="/search/cs?searchtype=author&query=Vasudevan%2C+R">Ram Vasudevan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06089" title="Abstract">arXiv:2402.06089</a> (replaced) [<a href="/pdf/2402.06089" title="Download PDF">pdf</a>, <a href="/format/2402.06089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Assistance for UX: A Literature Review Through Human-Centered AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yuwen Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuewen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qinyi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chengzhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T+J">Toby Jia-Jun Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06126" title="Abstract">arXiv:2402.06126</a> (replaced) [<a href="/pdf/2402.06126" title="Download PDF">pdf</a>, <a href="/format/2402.06126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learn To be Efficient: Build Structured Sparsity in Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Haizhong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiaoyan Bai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Beidi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+F">Fan Lai</a>, 
<a href="/search/cs?searchtype=author&query=Prakash%2C+A">Atul Prakash</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06198" title="Abstract">arXiv:2402.06198</a> (replaced) [<a href="/e-print/2402.06198" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GS-CLIP: Gaussian Splatting for Contrastive Language-Image-3D  Pretraining from Real-World Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yanpeng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yihan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaodan Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The content of the technical report needs to be updated and retracted to avoid other impacts
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06260" title="Abstract">arXiv:2402.06260</a> (replaced) [<a href="/pdf/2402.06260" title="Download PDF">pdf</a>, <a href="/format/2402.06260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vertex-minor universal graphs for generating entangled quantum  subsystems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Cautr%C3%A8s%2C+M">Maxime Cautr&#xe8;s</a>, 
<a href="/search/quant-ph?searchtype=author&query=Claudet%2C+N">Nathan Claudet</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mhalla%2C+M">Mehdi Mhalla</a>, 
<a href="/search/quant-ph?searchtype=author&query=Perdrix%2C+S">Simon Perdrix</a>, 
<a href="/search/quant-ph?searchtype=author&query=Savin%2C+V">Valentin Savin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Thomass%C3%A9%2C+S">St&#xe9;phan Thomass&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06281" title="Abstract">arXiv:2402.06281</a> (replaced) [<a href="/pdf/2402.06281" title="Download PDF">pdf</a>, <a href="/format/2402.06281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Optimal Resource Allocation in Virtual Sensor Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delgado%2C+C">Carmen Delgado</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%A1llego%2C+J+R">Jos&#xe9; Ram&#xf3;n G&#xe1;llego</a>, 
<a href="/search/cs?searchtype=author&query=Canales%2C+M">Mar&#xed;a Canales</a>, 
<a href="/search/cs?searchtype=author&query=Ort%C3%ADn%2C+J">Jorge Ort&#xed;n</a>, 
<a href="/search/cs?searchtype=author&query=Bousnina%2C+S">Sonda Bousnina</a>, 
<a href="/search/cs?searchtype=author&query=Cesana%2C+M">Matteo Cesana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Journal Version: 41 pages, 14 figures, 41 references
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Ad Hoc Networks 2016
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06282" title="Abstract">arXiv:2402.06282</a> (replaced) [<a href="/pdf/2402.06282" title="Download PDF">pdf</a>, <a href="/format/2402.06282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieve, Merge, Predict: Augmenting Tables with Data Lakes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cappuzzo%2C+R">Riccardo Cappuzzo</a> (1), 
<a href="/search/cs?searchtype=author&query=Varoquaux%2C+G">Gael Varoquaux</a> (1), 
<a href="/search/cs?searchtype=author&query=Coelho%2C+A">Aimee Coelho</a> (2), 
<a href="/search/cs?searchtype=author&query=Papotti%2C+P">Paolo Papotti</a> (3) ((1) SODA Team - Inria Saclay, (2) Dataiku, (3) EURECOM)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages + references, 11 figures. Under submission at VLDB2024 (EA&amp;B track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06846" title="Abstract">arXiv:2402.06846</a> (replaced) [<a href="/pdf/2402.06846" title="Download PDF">pdf</a>, <a href="/format/2402.06846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> System-level Analysis of Adversarial Attacks and Defenses on  Intelligence in O-RAN based Cellular Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chiejina%2C+A">Azuka Chiejina</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Brian Kim</a>, 
<a href="/search/cs?searchtype=author&query=Chowhdury%2C+K">Kaushik Chowhdury</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+V+K">Vijay K. Shah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> his paper has been accepted for publication in ACM WiSec 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06864" title="Abstract">arXiv:2402.06864</a> (replaced) [<a href="/pdf/2402.06864" title="Download PDF">pdf</a>, <a href="/format/2402.06864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discriminative Adversarial Unlearning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+R">Rohan Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shijie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+K">Kaiyi Ji</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Changyou Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages including references, 2 tables, 2 figures and 1 algorithm
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06938" title="Abstract">arXiv:2402.06938</a> (replaced) [<a href="/pdf/2402.06938" title="Download PDF">pdf</a>, <a href="/format/2402.06938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Resource Scheduling for Distributed Infrastructures Using  Negotiation Capabilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+J">Junjie Chu</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+P">Prashant Singh</a>, 
<a href="/search/cs?searchtype=author&query=Toor%2C+S">Salman Toor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE CLOUD 2023. 13 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06974" title="Abstract">arXiv:2402.06974</a> (replaced) [<a href="/pdf/2402.06974" title="Download PDF">pdf</a>, <a href="/format/2402.06974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-linear Fusion in Federated Learning: A Hypernetwork Approach to  Federated Domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bartholet%2C+M">Marc Bartholet</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taehyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Beuret%2C+A">Ami Beuret</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Se-Young Yun</a>, 
<a href="/search/cs?searchtype=author&query=Buhmann%2C+J+M">Joachim M. Buhmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07107" title="Abstract">arXiv:2402.07107</a> (replaced) [<a href="/pdf/2402.07107" title="Download PDF">pdf</a>, <a href="/format/2402.07107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Echoes of Socratic Doubt: Embracing Uncertainty in Calibrated Evidential  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stutts%2C+A+C">Alex Christopher Stutts</a>, 
<a href="/search/cs?searchtype=author&query=Erricolo%2C+D">Danilo Erricolo</a>, 
<a href="/search/cs?searchtype=author&query=Tulabandhula%2C+T">Theja Tulabandhula</a>, 
<a href="/search/cs?searchtype=author&query=Trivedi%2C+A+R">Amit Ranjan Trivedi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07197" title="Abstract">arXiv:2402.07197</a> (replaced) [<a href="/pdf/2402.07197" title="Download PDF">pdf</a>, <a href="/format/2402.07197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphTranslator: Aligning Graph Model to Large Language Model for  Open-ended Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengmei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mingwei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Shen Fan</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+Y">Yanhu Mo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaoxiao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chuan Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07211" title="Abstract">arXiv:2402.07211</a> (replaced) [<a href="/pdf/2402.07211" title="Download PDF">pdf</a>, <a href="/format/2402.07211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Fast Stochastic Sampling in Diffusion Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pandey%2C+K">Kushagra Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Rudolph%2C+M">Maja Rudolph</a>, 
<a href="/search/cs?searchtype=author&query=Mandt%2C+S">Stephan Mandt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the NeurIPS'23 Workshop on Diffusion Models. Full version of this work can be found at <a href="/abs/2310.07894">arXiv:2310.07894</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07282" title="Abstract">arXiv:2402.07282</a> (replaced) [<a href="/pdf/2402.07282" title="Download PDF">pdf</a>, <a href="/format/2402.07282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How do Large Language Models Navigate Conflicts between Honesty and  Helpfulness?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ryan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sumers%2C+T+R">Theodore R. Sumers</a>, 
<a href="/search/cs?searchtype=author&query=Dasgupta%2C+I">Ishita Dasgupta</a>, 
<a href="/search/cs?searchtype=author&query=Griffiths%2C+T+L">Thomas L. Griffiths</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07309" title="Abstract">arXiv:2402.07309</a> (replaced) [<a href="/pdf/2402.07309" title="Download PDF">pdf</a>, <a href="/format/2402.07309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperBERT: Mixing Hypergraph-Aware Layers with Language Models for Node  Classification on Text-Attributed Hypergraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bazaga%2C+A">Adri&#xe1;n Bazaga</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Micklem%2C+G">Gos Micklem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07355" title="Abstract">arXiv:2402.07355</a> (replaced) [<a href="/pdf/2402.07355" title="Download PDF">pdf</a>, <a href="/ps/2402.07355" title="Download PostScript">ps</a>, <a href="/format/2402.07355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling from the Mean-Field Stationary Distribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kook%2C+Y">Yunbum Kook</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+M+S">Matthew S. Zhang</a>, 
<a href="/search/math?searchtype=author&query=Chewi%2C+S">Sinho Chewi</a>, 
<a href="/search/math?searchtype=author&query=Erdogdu%2C+M+A">Murat A. Erdogdu</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+M+B">Mufan Bill Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07357" title="Abstract">arXiv:2402.07357</a> (replaced) [<a href="/pdf/2402.07357" title="Download PDF">pdf</a>, <a href="/format/2402.07357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regression Trees for Fast and Adaptive Prediction Intervals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cabezas%2C+L+M+C">Luben M. C. Cabezas</a>, 
<a href="/search/stat?searchtype=author&query=Otto%2C+M+P">Mateus P. Otto</a>, 
<a href="/search/stat?searchtype=author&query=Izbicki%2C+R">Rafael Izbicki</a>, 
<a href="/search/stat?searchtype=author&query=Stern%2C+R+B">Rafael B. Stern</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07420" title="Abstract">arXiv:2402.07420</a> (replaced) [<a href="/pdf/2402.07420" title="Download PDF">pdf</a>, <a href="/format/2402.07420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Transit Obfuscation Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Takahashi%2C+H">Hideaki Takahashi</a>, 
<a href="/search/cs?searchtype=author&query=Fukunaga%2C+A">Alex Fukunaga</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07426" title="Abstract">arXiv:2402.07426</a> (replaced) [<a href="/pdf/2402.07426" title="Download PDF">pdf</a>, <a href="/ps/2402.07426" title="Download PostScript">ps</a>, <a href="/format/2402.07426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational Aspects of Bayesian Persuasion under Approximate Best  Response
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kunhe Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanrui Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07431" title="Abstract">arXiv:2402.07431</a> (replaced) [<a href="/pdf/2402.07431" title="Download PDF">pdf</a>, <a href="/format/2402.07431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SALAD: Smart AI Language Assistant Daily
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nihal%2C+R+A">Ragib Amin Nihal</a>, 
<a href="/search/cs?searchtype=author&query=Quoc%2C+T+D+H">Tran Dong Huu Quoc</a>, 
<a href="/search/cs?searchtype=author&query=Zirui%2C+L">Lin Zirui</a>, 
<a href="/search/cs?searchtype=author&query=Yimimg%2C+X">Xu Yimimg</a>, 
<a href="/search/cs?searchtype=author&query=Haoran%2C+L">Liu Haoran</a>, 
<a href="/search/cs?searchtype=author&query=Zhaoyi%2C+A">An Zhaoyi</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kyou Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07446" title="Abstract">arXiv:2402.07446</a> (replaced) [<a href="/pdf/2402.07446" title="Download PDF">pdf</a>, <a href="/format/2402.07446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quality Does Matter: A Detailed Look at the Quality and Utility of  Web-Mined Parallel Corpora
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ranathunga%2C+S">Surangika Ranathunga</a>, 
<a href="/search/cs?searchtype=author&query=de+Silva%2C+N">Nisansa de Silva</a>, 
<a href="/search/cs?searchtype=author&query=Velayuthan%2C+M">Menan Velayuthan</a>, 
<a href="/search/cs?searchtype=author&query=Fernando%2C+A">Aloka Fernando</a>, 
<a href="/search/cs?searchtype=author&query=Rathnayake%2C+C">Charitha Rathnayake</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07462" title="Abstract">arXiv:2402.07462</a> (replaced) [<a href="/pdf/2402.07462" title="Download PDF">pdf</a>, <a href="/ps/2402.07462" title="Download PostScript">ps</a>, <a href="/format/2402.07462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hormetic Approach to the Value-Loading Problem: Preventing the  Paperclip Apocalypse?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Henry%2C+N+I+N">Nathan I. N. Henry</a>, 
<a href="/search/cs?searchtype=author&query=Pedersen%2C+M">Mangor Pedersen</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+M">Matt Williams</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+J+L+B">Jamin L. B. Martin</a>, 
<a href="/search/cs?searchtype=author&query=Donkin%2C+L">Liesje Donkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07480" title="Abstract">arXiv:2402.07480</a> (replaced) [<a href="/pdf/2402.07480" title="Download PDF">pdf</a>, <a href="/format/2402.07480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topological safeguard for evasion attack interpreting the neural  networks&#x27; behavior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Echeberria-Barrio%2C+X">Xabier Echeberria-Barrio</a>, 
<a href="/search/cs?searchtype=author&query=Gil-Lerchundi%2C+A">Amaia Gil-Lerchundi</a>, 
<a href="/search/cs?searchtype=author&query=Mendialdua%2C+I">I&#xf1;igo Mendialdua</a>, 
<a href="/search/cs?searchtype=author&query=Orduna-Urrutia%2C+R">Raul Orduna-Urrutia</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Pattern Recognition, Volume 147, 2024, 110130, ISSN 0031-3203
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07595" title="Abstract">arXiv:2402.07595</a> (replaced) [<a href="/pdf/2402.07595" title="Download PDF">pdf</a>, <a href="/format/2402.07595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Analysis of ImageNet Pre-Trained Deep Learning Models and  DINOv2 in Medical Imaging Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yuning Huang</a>, 
<a href="/search/eess?searchtype=author&query=Zou%2C+J">Jingchen Zou</a>, 
<a href="/search/eess?searchtype=author&query=Meng%2C+L">Lanxi Meng</a>, 
<a href="/search/eess?searchtype=author&query=Yue%2C+X">Xin Yue</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Q">Qing Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jianqiang Li</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+C">Changwei Song</a>, 
<a href="/search/eess?searchtype=author&query=Jimenez%2C+G">Gabriel Jimenez</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Shaowu Li</a>, 
<a href="/search/eess?searchtype=author&query=Fu%2C+G">Guanghui Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07735" title="Abstract">arXiv:2402.07735</a> (replaced) [<a href="/pdf/2402.07735" title="Download PDF">pdf</a>, <a href="/format/2402.07735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Structure Inference with BAM: Introducing the Bilinear Attention  Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Froehlich%2C+P">Philipp Froehlich</a>, 
<a href="/search/stat?searchtype=author&query=Koeppl%2C+H">Heinz Koeppl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07787" title="Abstract">arXiv:2402.07787</a> (replaced) [<a href="/pdf/2402.07787" title="Download PDF">pdf</a>, <a href="/format/2402.07787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extensible Multi-Granularity Fusion Network for Aspect-based Sentiment  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiaowei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiujuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07839" title="Abstract">arXiv:2402.07839</a> (replaced) [<a href="/pdf/2402.07839" title="Download PDF">pdf</a>, <a href="/format/2402.07839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Meta-Pruning via Optimal Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Theus%2C+A">Alexander Theus</a>, 
<a href="/search/cs?searchtype=author&query=Geimer%2C+O">Olin Geimer</a>, 
<a href="/search/cs?searchtype=author&query=Wicke%2C+F">Friedrich Wicke</a>, 
<a href="/search/cs?searchtype=author&query=Hofmann%2C+T">Thomas Hofmann</a>, 
<a href="/search/cs?searchtype=author&query=Anagnostidis%2C+S">Sotiris Anagnostidis</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S+P">Sidak Pal Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a Spotlight (top 5% of submissions) at the International Conference on Learning Representations (ICLR) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07874" title="Abstract">arXiv:2402.07874</a> (replaced) [<a href="/pdf/2402.07874" title="Download PDF">pdf</a>, <a href="/format/2402.07874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Factorizing the Brauer monoid in polynomial time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Marchei%2C+D">Daniele Marchei</a>, 
<a href="/search/math?searchtype=author&query=Merelli%2C+E">Emanuela Merelli</a>, 
<a href="/search/math?searchtype=author&query=Francis%2C+A">Andrew Francis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Rings and Algebras (math.RA)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07896" title="Abstract">arXiv:2402.07896</a> (replaced) [<a href="/pdf/2402.07896" title="Download PDF">pdf</a>, <a href="/format/2402.07896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Suppressing Pink Elephants with Direct Principle Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castricato%2C+L">Louis Castricato</a>, 
<a href="/search/cs?searchtype=author&query=Lile%2C+N">Nathan Lile</a>, 
<a href="/search/cs?searchtype=author&query=Anand%2C+S">Suraj Anand</a>, 
<a href="/search/cs?searchtype=author&query=Schoelkopf%2C+H">Hailey Schoelkopf</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+S">Siddharth Verma</a>, 
<a href="/search/cs?searchtype=author&query=Biderman%2C+S">Stella Biderman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07900" title="Abstract">arXiv:2402.07900</a> (replaced) [<a href="/pdf/2402.07900" title="Download PDF">pdf</a>, <a href="/format/2402.07900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wavefront Randomization Improves Deconvolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kohli%2C+A">Amit Kohli</a>, 
<a href="/search/cs?searchtype=author&query=Angelopoulos%2C+A+N">Anastasios N. Angelopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Waller%2C+L">Laura Waller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV); Optics (physics.optics)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item341">Cross-lists</a></li>
<li><a href="#item387">Replacements</a></li>
</ul>
<small>[ total of 636 entries:  <b>1-636</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2402">2402</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
