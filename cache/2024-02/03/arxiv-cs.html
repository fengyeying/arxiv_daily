<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Wed 31 Jan 24  to  Thu  1 Feb 24, announced Fri,  2 Feb 24</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item380">Cross-lists</a></li>
<li><a href="#item429">Replacements</a></li>
</ul>
<small>[ total of 643 entries:  <b>1-643</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Fri,  2 Feb 24</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00002" title="Abstract">arXiv:2402.00002</a> [<a href="/pdf/2402.00002" title="Download PDF">pdf</a>, <a href="/format/2402.00002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Raptor Encoding for Low-Latency Concurrent Multi-PDU Session  Transmission with Security Consideration in B5G Edge Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhongfu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xinsheng Ji</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+W">Wei You</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mingyan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhimo Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Deqiang Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">In B5G edge networks, end-to-end low-latency and high-reliability
transmissions between edge computing nodes and terminal devices are essential.
This paper investigates the queue-aware coding scheduling transmission of
randomly arriving data packets, taking into account potential eavesdroppers in
edge networks. To address these concerns, we introduce SCLER, a Protocol Data
Units (PDU) Raptor-encoded multi-path transmission method that overcomes the
challenges of a larger attack surface in Concurrent Multipath Transfer (CMT),
excessive delay due to asymmetric delay\&amp;bandwidth, and lack of interaction
among PDU session bearers. We propose a secure and reliable transmission scheme
based on Raptor encoding and distribution that incorporates a queue
length-aware encoding strategy. This strategy is modeled using Constrained
Markov Decision Process (CMDP), and we solve the constraint optimization
problem of optimal decision-making based on a threshold strategy. Numerical
results indicate that SCLER effectively reduces data leakage risks while
achieving the optimal balance between delay and reliability, thereby ensuring
data security. Importantly, the proposed system is compatible with current
mobile networks and demonstrates practical applicability.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00003" title="Abstract">arXiv:2402.00003</a> [<a href="/pdf/2402.00003" title="Download PDF">pdf</a>, <a href="/format/2402.00003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Validating Properties of RIS Channel Models with Prototypical  Measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weinberger%2C+K">Kevin Weinberger</a>, 
<a href="/search/cs?searchtype=author&query=Tewes%2C+S">Simon Tewes</a>, 
<a href="/search/cs?searchtype=author&query=Sezgin%2C+A">Aydin Sezgin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 9 figured, submitted to EuCAP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The integration of Reconfigurable Intelligent Surfaces (RIS) holds
substantial promise for revolutionizing 6G wireless networks, offering
unprecedented capabilities for real-time control over communication
environments. However, determining optimal RIS configurations remains a pivotal
challenge, necessitating the development of accurate analytical models. While
theoretically derived models provide valuable insights, their potentially
idealistic assumptions do not always translate well to practical measurements.
This becomes especially problematic in mobile environments, where signals
arrive from various directions. This study deploys an RIS prototype on a
turntable, capturing the RIS channels' dependency on the angle of incoming
signals. The difference between theory and practice is bridged by refining a
model with angle-dependent reflection coefficients. The improved model exhibits
a significantly closer alignment with real-world measurements. Analysis of the
reflect coefficients reveals that non-perpendicular receiver angles can induce
an additional attenuation of up to -14.5dB. Additionally, we note significant
phase shift deviations, varying for each reflect element.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00004" title="Abstract">arXiv:2402.00004</a> [<a href="/pdf/2402.00004" title="Download PDF">pdf</a>, <a href="/ps/2402.00004" title="Download PostScript">ps</a>, <a href="/format/2402.00004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revolutionizing Underwater Exploration of Autonomous Underwater Vehicles  (AUVs) and Seabed Image Processing Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=R%2C+R+S">Rajesh Sharma R</a>, 
<a href="/search/cs?searchtype=author&query=Sungheetha%2C+A">Akey Sungheetha</a>, 
<a href="/search/cs?searchtype=author&query=R%2C+D+C">Dr Chinnaiyan R</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The oceans in the Earth's in one of the last border lines on the World, with
only a fraction of their depths having been explored. Advancements in
technology have led to the development of Autonomous Underwater Vehicles (AUVs)
that can operate independently and perform complex tasks underwater. These
vehicles have revolutionized underwater exploration, allowing us to study and
understand our oceans like never before. In addition to AUVs, image processing
techniques have also been developed that can help us to better understand the
seabed and its features. In this comprehensive survey, we will explore the
latest advancements in AUV technology and seabed image processing techniques.
We'll discuss how these advancements are changing the way we explore and
understand our oceans, and their potential impact on the future of marine
science. Join us on this journey to discover the exciting world of underwater
exploration and the technologies that are driving it forward.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00008" title="Abstract">arXiv:2402.00008</a> [<a href="/pdf/2402.00008" title="Download PDF">pdf</a>, <a href="/ps/2402.00008" title="Download PostScript">ps</a>, <a href="/format/2402.00008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grant-Free Power Allocation for Ultra-Dense Internet of Things  Environments: A Mean-Field Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nadif%2C+S">Sami Nadif</a>, 
<a href="/search/cs?searchtype=author&query=Sabir%2C+E">Essaid Sabir</a>, 
<a href="/search/cs?searchtype=author&query=Elbiaze%2C+H">Halima Elbiaze</a>, 
<a href="/search/cs?searchtype=author&query=Haqiq%2C+A">Abdelkrim Haqiq</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Journal of Network and Computer Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Grant free access, in which each Internet of Things (IoT) device delivers its
packets through a randomly selected resource without spending time on
handshaking procedures, is a promising solution for supporting the massive
connectivity required for IoT systems. In this paper, we explore grant free
access with multi packet reception capabilities, with an emphasis on ultra low
end IoT applications with small data sizes, sporadic activity, and energy usage
constraints. We propose a power allocation scheme that integrates the IoT
device's traffic and energy budget by using a stochastic geometry framework and
meanfield game theory to model and analyze mutual interference among active IoT
devices.We also derive a Markov chain model to capture and track the IoT
device's queue length and derive the successful transmission probability at
steady state. Simulation results illustrate the optimal power allocation
strategy and show the effectiveness of the proposed approach.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00009" title="Abstract">arXiv:2402.00009</a> [<a href="/pdf/2402.00009" title="Download PDF">pdf</a>, <a href="/format/2402.00009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Markovian embedding of nonlocal equations using spectral representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jaganathan%2C+D">Divya Jaganathan</a>, 
<a href="/search/math?searchtype=author&query=Valani%2C+R+N">Rahil N. Valani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Nonlocal evolutionary equations containing memory terms model a variety of
non-Markovian processes. We present a Markovian embedding procedure for a class
of nonlocal equations by utilising the spectral representation of the nonlinear
memory kernel. This allows us to transform the nonlocal system to a
local-in-time system in an abstract extended space. We demonstrate our
embedding procedure and its efficacy for two different physical models, namely
the (i) 1D walking droplet and (ii) the 1D single-phase Stefan problem.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00010" title="Abstract">arXiv:2402.00010</a> [<a href="/pdf/2402.00010" title="Download PDF">pdf</a>, <a href="/ps/2402.00010" title="Download PostScript">ps</a>, <a href="/format/2402.00010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Going Viral: An Analysis of Advertising of Technology Products on TikTok
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+E">Ekansh Agrawal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Social media has transformed the advertising landscape, becoming an essential
tool for reaching and connecting with consumers. Its sharing and engagement
features amplify brand exposure, while its cost-effective options provide
businesses with flexible advertising solutions. TikTok is a more recent social
media platform that has gained popularity for advertising, particularly in the
realm of e-commerce, due to its large user base and viral nature. TikTok had
1.2 billion monthly active users in Q4 2021, generating an estimated $4.6
billion revenue in 2021. Virality can lead to a massive increase in brand
exposure, reaching a vast audience that may not have been accessible through
traditional marketing efforts alone. Advertisements for technological products
are an example of such viral ads that are abundant on TikTok. The goal of this
thesis is to understand how creators, community activity, and the
recommendation algorithm influence the virality of advertisements for
technology products on TikTok. The study analyzes various aspects of virality,
including sentiment analysis, content characteristics, and the role of
influencers. It employs data scraping and natural language processing tools to
analyze metadata from 2,000 TikTok posts and 274,651, offering insights into
the nuances of viral tech product advertising on TikTok.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00011" title="Abstract">arXiv:2402.00011</a> [<a href="/pdf/2402.00011" title="Download PDF">pdf</a>, <a href="/ps/2402.00011" title="Download PostScript">ps</a>, <a href="/format/2402.00011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Choosing the Right Path for AI Integration in Engineering Companies: A  Strategic Guide
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dzhusupova%2C+R">Rimma Dzhusupova</a>, 
<a href="/search/cs?searchtype=author&query=Bosch%2C+J">Jan Bosch</a>, 
<a href="/search/cs?searchtype=author&query=Olsson%2C+H+H">Helena Holmstrom Olsson</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The Journal of Systems &amp; Software, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
<p class="mathjax">The Engineering, Procurement and Construction (EPC) businesses operating
within the energy sector are recognizing the increasing importance of
Artificial Intelligence (AI). Many EPC companies and their clients have
realized the benefits of applying AI to their businesses in order to reduce
manual work, drive productivity, and streamline future operations of engineered
installations in a highly competitive industry. The current AI market offers
various solutions and services to support this industry, but organizations must
understand how to acquire AI technology in the most beneficial way based on
their business strategy and available resources. This paper presents a
framework for EPC companies in their transformation towards AI. Our work is
based on examples of project execution of AI-based products development at one
of the biggest EPC contractors worldwide and on insights from EPC vendor
companies already integrating AI into their engineering solutions. The paper
covers the entire life cycle of building AI solutions, from initial business
understanding to deployment and further evolution. The framework identifies how
various factors influence the choice of approach toward AI project development
within large international engineering corporations. By presenting a practical
guide for optimal approach selection, this paper contributes to the research in
AI project management and organizational strategies for integrating AI
technology into businesses. The framework might also help engineering companies
choose the optimum AI approach to create business value.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00013" title="Abstract">arXiv:2402.00013</a> [<a href="/pdf/2402.00013" title="Download PDF">pdf</a>, <a href="/format/2402.00013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> No More Trade-Offs. GPT and Fully Informative Privacy Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pa%C5%82ka%2C+P">Przemys&#x142;aw Pa&#x142;ka</a>, 
<a href="/search/cs?searchtype=author&query=Lippi%2C+M">Marco Lippi</a>, 
<a href="/search/cs?searchtype=author&query=Lagioia%2C+F">Francesca Lagioia</a>, 
<a href="/search/cs?searchtype=author&query=Liepi%C5%86a%2C+R">R&#x16b;ta Liepi&#x146;a</a>, 
<a href="/search/cs?searchtype=author&query=Sartor%2C+G">Giovanni Sartor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The paper reports the results of an experiment aimed at testing to what
extent ChatGPT 3.5 and 4 is able to answer questions regarding privacy policies
designed in the new format that we propose. In a world of human-only
interpreters, there was a trade-off between comprehensiveness and
comprehensibility of privacy policies, leading to the actual policies not
containing enough information for users to learn anything meaningful. Having
shown that GPT performs relatively well with the new format, we provide
experimental evidence supporting our policy suggestion, namely that the law
should require fully comprehensive privacy policies, even if this means they
become less concise.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00015" title="Abstract">arXiv:2402.00015</a> [<a href="/pdf/2402.00015" title="Download PDF">pdf</a>, <a href="/format/2402.00015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maintaining User Trust Through Multistage Uncertainty Aware Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+C">Chandan Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Papanai%2C+A">Ashish Papanai</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+J">Jerome White</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AAAI 2024 workshop of Deployable AI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper describes and evaluates a multistage approach to AI deployment.
Each stage involves a more accurate method of inference, yet engaging each
comes with an increasing cost. In outlining the architecture, we present a
method for quantifying model uncertainty that facilitates confident deferral
decisions. The architecture is currently under active deployment to thousands
of cotton farmers across India. The broader idea however is applicable to a
growing sector of AI deployments in challenging low resources settings.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00017" title="Abstract">arXiv:2402.00017</a> [<a href="/pdf/2402.00017" title="Download PDF">pdf</a>, <a href="/format/2402.00017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deploying ADVISER: Impact and Lessons from Using Artificial Intelligence  for Child Vaccination Uptake in Nigeria
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kehinde%2C+O">Opadele Kehinde</a>, 
<a href="/search/cs?searchtype=author&query=Abdul%2C+R">Ruth Abdul</a>, 
<a href="/search/cs?searchtype=author&query=Afolabi%2C+B">Bose Afolabi</a>, 
<a href="/search/cs?searchtype=author&query=Vir%2C+P">Parminder Vir</a>, 
<a href="/search/cs?searchtype=author&query=Namblard%2C+C">Corinne Namblard</a>, 
<a href="/search/cs?searchtype=author&query=Mukhopadhyay%2C+A">Ayan Mukhopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Adereni%2C+A">Abiodun Adereni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">More than 5 million children under five years die from largely preventable or
treatable medical conditions every year, with an overwhelmingly large
proportion of deaths occurring in underdeveloped countries with low vaccination
uptake. One of the United Nations' sustainable development goals (SDG 3) aims
to end preventable deaths of newborns and children under five years of age. We
focus on Nigeria, where the rate of infant mortality is appalling. In
particular, low vaccination uptake in Nigeria is a major driver of more than
2,000 daily deaths of children under the age of five years. In this paper, we
describe our collaboration with government partners in Nigeria to deploy
ADVISER: AI-Driven Vaccination Intervention Optimiser. The framework, based on
an integer linear program that seeks to maximize the cumulative probability of
successful vaccination, is the first successful deployment of an AI-enabled
toolchain for optimizing the allocation of health interventions in Nigeria. In
this paper, we provide a background of the ADVISER framework and present
results, lessons, and success stories of deploying ADVISER to more than 13,000
families in the state of Oyo, Nigeria.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00020" title="Abstract">arXiv:2402.00020</a> [<a href="/pdf/2402.00020" title="Download PDF">pdf</a>, <a href="/ps/2402.00020" title="Download PostScript">ps</a>, <a href="/format/2402.00020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Review on Application of Drone in Spraying Pesticides and Fertilizers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Souvanhnakhoomman%2C+S">Sane Souvanhnakhoomman</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Engineering Research &amp; Technology
  (IJERT), Vol. 10 Issue 11, November-2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In today's agriculture, there are far too many innovations involved. One of
the emerging technologies is pesticide spraying using drones. Manual pesticide
spraying has a number of negative consequences for the people who are involved
in the spraying operation. The result of exposure symptoms can include minor
skin inflammation and birth abnormalities, tumors, genetic modifications, nerve
and blood diseases, endocrinal interference, coma or death. However, Drone can
be used to automate fertilizer application, pesticide spraying, and field
tracking. This paper provides a concise overview of the use of drones for field
inspection and pesticide spraying. displays different methodologies and
controllers of agriculture drone and explains some essential Drone Hardware,
Software elements and applications
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00021" title="Abstract">arXiv:2402.00021</a> [<a href="/pdf/2402.00021" title="Download PDF">pdf</a>, <a href="/format/2402.00021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monitoring-Supported Value Generation for Managing Structures and  Infrastructure Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kamariotis%2C+A">Antonios Kamariotis</a>, 
<a href="/search/cs?searchtype=author&query=Chatzi%2C+E">Eleni Chatzi</a>, 
<a href="/search/cs?searchtype=author&query=Straub%2C+D">Daniel Straub</a>, 
<a href="/search/cs?searchtype=author&query=Dervilis%2C+N">Nikolaos Dervilis</a>, 
<a href="/search/cs?searchtype=author&query=Goebel%2C+K">Kai Goebel</a>, 
<a href="/search/cs?searchtype=author&query=Hughes%2C+A+J">Aidan J. Hughes</a>, 
<a href="/search/cs?searchtype=author&query=Lombaert%2C+G">Geert Lombaert</a>, 
<a href="/search/cs?searchtype=author&query=Papadimitriou%2C+C">Costas Papadimitriou</a>, 
<a href="/search/cs?searchtype=author&query=Papakonstantinou%2C+K+G">Konstantinos G. Papakonstantinou</a>, 
<a href="/search/cs?searchtype=author&query=Pozzi%2C+M">Matteo Pozzi</a>, 
<a href="/search/cs?searchtype=author&query=Todd%2C+M">Michael Todd</a>, 
<a href="/search/cs?searchtype=author&query=Worden%2C+K">Keith Worden</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">To maximize its value, the design, development and implementation of
Structural Health Monitoring (SHM) should focus on its role in facilitating
decision support. In this position paper, we offer perspectives on the synergy
between SHM and decision-making. We propose a classification of SHM use cases
aligning with various dimensions that are closely linked to the respective
decision contexts. The types of decisions that have to be supported by the SHM
system within these settings are discussed along with the corresponding
challenges. We provide an overview of different classes of models that are
required for integrating SHM in the decision-making process to support
management and operation and maintenance of structures and infrastructure
systems. Fundamental decision-theoretic principles and state-of-the-art methods
for optimizing maintenance and operational decision-making under uncertainty
are briefly discussed. Finally, we offer a viewpoint on the appropriate course
of action for quantifying, validating and maximizing the added value generated
by SHM. This work aspires to synthesize the different perspectives of the SHM,
Prognostic Health Management (PHM), and reliability communities, and deliver a
roadmap towards monitoring-based decision support.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00023" title="Abstract">arXiv:2402.00023</a> [<a href="/pdf/2402.00023" title="Download PDF">pdf</a>, <a href="/format/2402.00023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Multi-Temporal Sentinel-1 and Sentinel-2 data for water bodies  mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Russo%2C+L">Luigi Russo</a>, 
<a href="/search/cs?searchtype=author&query=Mauro%2C+F">Francesco Mauro</a>, 
<a href="/search/cs?searchtype=author&query=Memar%2C+B">Babak Memar</a>, 
<a href="/search/cs?searchtype=author&query=Sebastianelli%2C+A">Alessandro Sebastianelli</a>, 
<a href="/search/cs?searchtype=author&query=Gamba%2C+P">Paolo Gamba</a>, 
<a href="/search/cs?searchtype=author&query=Ullo%2C+S+L">Silvia Liberata Ullo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Climate change is intensifying extreme weather events, causing both water
scarcity and severe rainfall unpredictability, and posing threats to
sustainable development, biodiversity, and access to water and sanitation. This
paper aims to provide valuable insights for comprehensive water resource
monitoring under diverse meteorological conditions. An extension of the
SEN2DWATER dataset is proposed to enhance its capabilities for water basin
segmentation. Through the integration of temporally and spatially aligned radar
information from Sentinel-1 data with the existing multispectral Sentinel-2
data, a novel multisource and multitemporal dataset is generated. Benchmarking
the enhanced dataset involves the application of indices such as the Soil Water
Index (SWI) and Normalized Difference Water Index (NDWI), along with an
unsupervised Machine Learning (ML) classifier (k-means clustering). Promising
results are obtained and potential future developments and applications arising
from this research are also explored.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00025" title="Abstract">arXiv:2402.00025</a> [<a href="/pdf/2402.00025" title="Download PDF">pdf</a>, <a href="/format/2402.00025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating a Triton Fused Kernel for W4A16 Quantized Inference with  SplitK work decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoque%2C+A">Adnan Hoque</a>, 
<a href="/search/cs?searchtype=author&query=Wright%2C+L">Less Wright</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jamie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Srivatsa%2C+M">Mudhakar Srivatsa</a>, 
<a href="/search/cs?searchtype=author&query=Ganti%2C+R">Raghu Ganti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We propose an implementation of an efficient fused matrix multiplication
kernel for W4A16 quantized inference, where we perform dequantization and GEMM
in a fused kernel using a SplitK work decomposition. Our implementation shows
improvement for the type of skinny matrix-matrix multiplications found in
foundation model inference workloads. In particular, this paper surveys the
type of matrix multiplication between a skinny activation matrix and a square
weight matrix. Our results show an average of 65% speed improvement on A100,
and an average of 124% speed improvement on H100 (with a peak of 295%) for a
range of matrix dimensions including those found in a llama-style model, where
m &lt; n = k.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00027" title="Abstract">arXiv:2402.00027</a> [<a href="/pdf/2402.00027" title="Download PDF">pdf</a>, <a href="/format/2402.00027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perspectives on locally weighted ensemble Kalman methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wacker%2C+P">Philipp Wacker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR); Computation (stat.CO)

</div>
<p class="mathjax">This manuscript derives locally weighted ensemble Kalman methods from the
point of view of ensemble-based function approximation. This is done by using
pointwise evaluations to build up a local linear or quadratic approximation of
a function, tapering off the effect of distant particles via local weighting.
This introduces a possible candidate (the locally weighted Ensemble Kalman
method) for combining the strengths of the particle filter (ability to cope
with nonlinear maps and non-Gaussian distributions) and the Ensemble Kalman
filter (no filter degeneracy), and can also be applied to optimisation and
sampling tasks.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00028" title="Abstract">arXiv:2402.00028</a> [<a href="/pdf/2402.00028" title="Download PDF">pdf</a>, <a href="/format/2402.00028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Rendering and Its Hardware Acceleration: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xinkai Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jieting Xu</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+Y">Yuchi Huo</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+H">Hujun Bao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Neural rendering is a new image and video generation method based on deep
learning. It combines the deep learning model with the physical knowledge of
computer graphics, to obtain a controllable and realistic scene model, and
realize the control of scene attributes such as lighting, camera parameters,
posture and so on. On the one hand, neural rendering can not only make full use
of the advantages of deep learning to accelerate the traditional forward
rendering process, but also provide new solutions for specific tasks such as
inverse rendering and 3D reconstruction. On the other hand, the design of
innovative hardware structures that adapt to the neural rendering pipeline
breaks through the parallel computing and power consumption bottleneck of
existing graphics processors, which is expected to provide important support
for future key areas such as virtual and augmented reality, film and television
creation and digital entertainment, artificial intelligence and the metaverse.
In this paper, we review the technical connotation, main challenges, and
research progress of neural rendering. On this basis, we analyze the common
requirements of neural rendering pipeline for hardware acceleration and the
characteristics of the current hardware acceleration architecture, and then
discuss the design challenges of neural rendering processor architecture.
Finally, the future development trend of neural rendering processor
architecture is prospected.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00029" title="Abstract">arXiv:2402.00029</a> [<a href="/pdf/2402.00029" title="Download PDF">pdf</a>, <a href="/format/2402.00029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Public Opinion on Responsible AI Through The Lens of Cultural  Consensus Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gurkan%2C+N">Necdet Gurkan</a>, 
<a href="/search/cs?searchtype=author&query=Suchow%2C+J+W">Jordan W. Suchow</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 57th Hawaii International Conference on System
  Sciences, 713-723 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As the societal implications of Artificial Intelligence (AI) continue to
grow, the pursuit of responsible AI necessitates public engagement in its
development and governance processes. This involvement is crucial for capturing
diverse perspectives and promoting equitable practices and outcomes. We applied
Cultural Consensus Theory (CCT) to a nationally representative survey dataset
on various aspects of AI to discern beliefs and attitudes about responsible AI
in the United States. Our results offer valuable insights by identifying shared
and contrasting views on responsible AI. Furthermore, these findings serve as
critical reference points for developers and policymakers, enabling them to
more effectively consider individual variances and group-level cultural
perspectives when making significant decisions and addressing the public's
concerns.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00030" title="Abstract">arXiv:2402.00030</a> [<a href="/pdf/2402.00030" title="Download PDF">pdf</a>, <a href="/ps/2402.00030" title="Download PostScript">ps</a>, <a href="/format/2402.00030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolution-Bootstrapped Simulation: Artificial or Human Intelligence:  Which Came First?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bilokon%2C+P+A">Paul Alexander Bilokon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, no figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Populations and Evolution (q-bio.PE)

</div>
<p class="mathjax">Humans have created artificial intelligence (AI), not the other way around.
This statement is deceptively obvious. In this note, we decided to challenge
this statement as a small, lighthearted Gedankenexperiment. We ask a simple
question: in a world driven by evolution by natural selection, would neural
networks or humans be likely to evolve first? We compare the
Solomonoff--Kolmogorov--Chaitin complexity of the two and find neural networks
(even LLMs) to be significantly simpler than humans. Further, we claim that it
is unnecessary for any complex human-made equipment to exist for there to be
neural networks. Neural networks may have evolved as naturally occurring
objects before humans did as a form of chemical reaction-based or enzyme-based
computation. Now that we know that neural networks can pass the Turing test and
suspect that they may be capable of superintelligence, we ask whether the
natural evolution of neural networks could lead from pure evolution by natural
selection to what we call evolution-bootstrapped simulation. The evolution of
neural networks does not involve irreducible complexity; would easily allow
irreducible complexity to exist in the evolution-bootstrapped simulation; is a
falsifiable scientific hypothesis; and is independent of / orthogonal to the
issue of intelligent design.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00031" title="Abstract">arXiv:2402.00031</a> [<a href="/pdf/2402.00031" title="Download PDF">pdf</a>, <a href="/format/2402.00031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Integrated Framework for Team Formation and Winner Prediction in the  FIRST Robotics Competition: Model, Algorithm, and Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Galbiati%2C+F">Federico Galbiati</a>, 
<a href="/search/cs?searchtype=author&query=Gran%2C+R+X">Ranier X. Gran</a>, 
<a href="/search/cs?searchtype=author&query=Jacques%2C+B+D">Brendan D. Jacques</a>, 
<a href="/search/cs?searchtype=author&query=Mulhern%2C+S+J">Sullivan J. Mulhern</a>, 
<a href="/search/cs?searchtype=author&query=Ngan%2C+C">Chun-Kit Ngan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">This research work aims to develop an analytical approach for optimizing team
formation and predicting team performance in a competitive environment based on
data on the competitors' skills prior to the team formation. There are several
approaches in scientific literature to optimize and predict a team's
performance. However, most studies employ fine-grained skill statistics of the
individual members or constraints such as teams with a set group of members.
Currently, no research tackles the highly constrained domain of the FIRST
Robotics Competition. This research effort aims to fill this gap by providing
an analytical method for optimizing and predicting team performance in a
competitive environment while allowing these constraints and only using metrics
on previous team performance, not on each individual member's performance. We
apply our method to the drafting process of the FIRST Robotics competition, a
domain in which the skills change year-over-year, team members change
throughout the season, each match only has a superficial set of statistics, and
alliance formation is key to competitive success. First, we develop a method
that could extrapolate individual members' performance based on overall team
performance. An alliance optimization algorithm is developed to optimize team
formation and a deep neural network model is trained to predict the winning
team, both using highly post-processed real-world data. Our method is able to
successfully extract individual members' metrics from overall team statistics,
form competitive teams, and predict the winning team with 84.08% accuracy.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00032" title="Abstract">arXiv:2402.00032</a> [<a href="/pdf/2402.00032" title="Download PDF">pdf</a>, <a href="/format/2402.00032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-objective Generative Design Framework and Realization for  Quasi-serial Manipulator: Considering Kinematic and Dynamic Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sumin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sunwoong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+N">Namwoo Kang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper proposes a framework that optimizes the linkage mechanism of the
quasi-serial manipulator for target tasks. This process is explained through a
case study of 2-degree-of-freedom linkage mechanisms, which significantly
affect the workspace of the quasi-serial manipulator. First, a vast
quasi-serial mechanism is generated with a workspace satisfying a target task
and it converts it into a 3D CAD model. Then, the workspace and required torque
performance of each mechanism are evaluated through kinematic and dynamic
analysis. A deep learning-based surrogate model is leveraged to efficiently
predict mechanisms and performance during the optimization process. After model
training, a multi-objective optimization problem is formulated under the
mechanical and dynamic conditions of the manipulator. The design goal of the
manipulator is to recommend quasi-serial mechanisms with optimized kinematic
(workspace) and dynamic (joint torque) performance that satisfies the target
task. To investigate the underlying physics from the obtained Pareto solutions,
various data mining techniques are performed to extract design rules that can
provide practical design guidance. Finally, the manipulator was designed in
detail for realization with 3D printed parts, including topology optimization.
Also, the task-based optimized manipulator is verified through a payload test.
Based on these results, the proposed framework has the potential for other real
applications as realized cases and provides a reasonable design plan through
the design rule extraction.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00033" title="Abstract">arXiv:2402.00033</a> [<a href="/pdf/2402.00033" title="Download PDF">pdf</a>, <a href="/format/2402.00033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LF-ViT: Reducing Spatial Redundancy in Vision Transformer for Efficient  Image Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Youbing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yun Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+A">Anqi Lu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhiqiang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+D">Dawei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhijun Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The Vision Transformer (ViT) excels in accuracy when handling high-resolution
images, yet it confronts the challenge of significant spatial redundancy,
leading to increased computational and memory requirements. To address this, we
present the Localization and Focus Vision Transformer (LF-ViT). This model
operates by strategically curtailing computational demands without impinging on
performance. In the Localization phase, a reduced-resolution image is
processed; if a definitive prediction remains elusive, our pioneering
Neighborhood Global Class Attention (NGCA) mechanism is triggered, effectively
identifying and spotlighting class-discriminative regions based on initial
findings. Subsequently, in the Focus phase, this designated region is used from
the original image to enhance recognition. Uniquely, LF-ViT employs consistent
parameters across both phases, ensuring seamless end-to-end optimization. Our
empirical tests affirm LF-ViT's prowess: it remarkably decreases Deit-S's FLOPs
by 63\% and concurrently amplifies throughput twofold. Code of this project is
at https://github.com/edgeai1/LF-ViT.git.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00034" title="Abstract">arXiv:2402.00034</a> [<a href="/pdf/2402.00034" title="Download PDF">pdf</a>, <a href="/format/2402.00034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why does Prediction Accuracy Decrease over Time? Uncertain Positive  Learning for Cloud Failure Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haozhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+M">Minghua Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yudong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Pu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Lingling Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ze Li</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+Y">Yingnong Dang</a>, 
<a href="/search/cs?searchtype=author&query=Chintalapati%2C+M">Murali Chintalapati</a>, 
<a href="/search/cs?searchtype=author&query=Rajmohan%2C+S">Saravan Rajmohan</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qingwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the rapid growth of cloud computing, a variety of software services have
been deployed in the cloud. To ensure the reliability of cloud services, prior
studies focus on failure instance (disk, node, and switch, etc.) prediction.
Once the output of prediction is positive, mitigation actions are taken to
rapidly resolve the underlying failure. According to our real-world practice in
Microsoft Azure, we find that the prediction accuracy may decrease by about 9%
after retraining the models. Considering that the mitigation actions may result
in uncertain positive instances since they cannot be verified after mitigation,
which may introduce more noise while updating the prediction model. To the best
of our knowledge, we are the first to identify this Uncertain Positive Learning
(UPLearning) issue in the real-world cloud failure prediction scenario. To
tackle this problem, we design an Uncertain Positive Learning Risk Estimator
(Uptake) approach. Using two real-world datasets of disk failure prediction and
conducting node prediction experiments in Microsoft Azure, which is a top-tier
cloud provider that serves millions of users, we demonstrate Uptake can
significantly improve the failure prediction accuracy by 5% on average.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00035" title="Abstract">arXiv:2402.00035</a> [<a href="/pdf/2402.00035" title="Download PDF">pdf</a>, <a href="/format/2402.00035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness Assessment of a Runway Object Classifier for Safe Aircraft  Taxiing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elboher%2C+Y">Yizhak Elboher</a>, 
<a href="/search/cs?searchtype=author&query=Elsaleh%2C+R">Raya Elsaleh</a>, 
<a href="/search/cs?searchtype=author&query=Isac%2C+O">Omri Isac</a>, 
<a href="/search/cs?searchtype=author&query=Ducoffe%2C+M">M&#xe9;lanie Ducoffe</a>, 
<a href="/search/cs?searchtype=author&query=Galametz%2C+A">Audrey Galametz</a>, 
<a href="/search/cs?searchtype=author&query=Pov%C3%A9da%2C+G">Guillaume Pov&#xe9;da</a>, 
<a href="/search/cs?searchtype=author&query=Boumazouza%2C+R">Ryma Boumazouza</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+N">No&#xe9;mie Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Katz%2C+G">Guy Katz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">As deep neural networks (DNNs) are becoming the prominent solution for many
computational problems, the aviation industry seeks to explore their potential
in alleviating pilot workload and in improving operational safety. However, the
use of DNNs in this type of safety-critical applications requires a thorough
certification process. This need can be addressed through formal verification,
which provides rigorous assurances -- e.g.,~by proving the absence of certain
mispredictions. In this case-study paper, we demonstrate this process using an
image-classifier DNN currently under development at Airbus and intended for use
during the aircraft taxiing phase. We use formal methods to assess this DNN's
robustness to three common image perturbation types: noise, brightness and
contrast, and some of their combinations. This process entails multiple
invocations of the underlying verifier, which might be computationally
expensive; and we therefore propose a method that leverages the monotonicity of
these robustness properties, as well as the results of past verification
queries, in order to reduce the overall number of verification queries required
by nearly 60%. Our results provide an indication of the level of robustness
achieved by the DNN classifier under study, and indicate that it is
considerably more vulnerable to noise than to brightness or contrast
perturbations.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00036" title="Abstract">arXiv:2402.00036</a> [<a href="/pdf/2402.00036" title="Download PDF">pdf</a>, <a href="/format/2402.00036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kronecker Product Feature Fusion for Convolutional Neural Network in  Remote Sensing Scene Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yinzhu Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Remote Sensing Scene Classification is a challenging and valuable research
topic, in which Convolutional Neural Network (CNN) has played a crucial role.
CNN can extract hierarchical convolutional features from remote sensing
imagery, and Feature Fusion of different layers can enhance CNN's performance.
Two successful Feature Fusion methods, Add and Concat, are employed in certain
state-of-the-art CNN algorithms. In this paper, we propose a novel Feature
Fusion algorithm, which unifies the aforementioned methods using the Kronecker
Product (KPFF), and we discuss the Backpropagation procedure associated with
this algorithm. To validate the efficacy of the proposed method, a series of
experiments are designed and conducted. The results demonstrate its
effectiveness of enhancing CNN's accuracy in Remote sensing scene
classification.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00037" title="Abstract">arXiv:2402.00037</a> [<a href="/pdf/2402.00037" title="Download PDF">pdf</a>, <a href="/ps/2402.00037" title="Download PostScript">ps</a>, <a href="/format/2402.00037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Catalyzing Equity in STEM Teams: Harnessing Generative AI for Inclusion  and Diversity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nixon%2C+N">Nia Nixon</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yiwen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Snow%2C+L">Lauren Snow</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 0 figure, to be published in Policy Insights from Behavioral and Brain Sciences
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Collaboration is key to STEM, where multidisciplinary team research can solve
complex problems. However, inequality in STEM fields hinders their full
potential, due to persistent psychological barriers in underrepresented
students' experience. This paper documents teamwork in STEM and explores the
transformative potential of computational modeling and generative AI in
promoting STEM-team diversity and inclusion. Leveraging generative AI, this
paper outlines two primary areas for advancing diversity, equity, and
inclusion. First, formalizing collaboration assessment with inclusive analytics
can capture fine-grained learner behavior. Second, adaptive, personalized AI
systems can support diversity and inclusion in STEM teams. Four policy
recommendations highlight AI's capacity: formalized collaborative skill
assessment, inclusive analytics, funding for socio-cognitive research, human-AI
teaming for inclusion training. Researchers, educators, policymakers can build
an equitable STEM ecosystem. This roadmap advances AI-enhanced collaboration,
offering a vision for the future of STEM where diverse voices are actively
encouraged and heard within collaborative scientific endeavors.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00040" title="Abstract">arXiv:2402.00040</a> [<a href="/pdf/2402.00040" title="Download PDF">pdf</a>, <a href="/format/2402.00040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving High-dimensional Parametric Elliptic Equation Using Tensor  Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+H">Hongtao Chen</a>, 
<a href="/search/math?searchtype=author&query=Fu%2C+R">Rui Fu</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>, 
<a href="/search/math?searchtype=author&query=Xie%2C+H">Hehu Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 25 figures. arXiv admin note: substantial text overlap with <a href="/abs/2311.02732">arXiv:2311.02732</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we introduce a tensor neural network based machine learning
method for solving the elliptic partial differential equations with random
coefficients in a bounded physical domain. With the help of tensor product
structure, we can transform the high-dimensional integrations of tensor neural
network functions to one-dimensional integrations which can be computed with
the classical quadrature schemes with high accuracy. The complexity of its
calculation can be reduced from the exponential scale to a polynomial scale.
The corresponding machine learning method is designed for solving
high-dimensional parametric elliptic equations. Some numerical examples are
provided to validate the accuracy and efficiency of the proposed algorithms.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00041" title="Abstract">arXiv:2402.00041</a> [<a href="/pdf/2402.00041" title="Download PDF">pdf</a>, <a href="/format/2402.00041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-temporal-demand clustering for solving large-scale vehicle  routing problems with time windows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kerscher%2C+C">Christoph Kerscher</a>, 
<a href="/search/cs?searchtype=author&query=Minner%2C+S">Stefan Minner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Optimization and Control (math.OC)

</div>
<p class="mathjax">Several metaheuristics use decomposition and pruning strategies to solve
large-scale instances of the vehicle routing problem (VRP). Those complexity
reduction techniques often rely on simple, problem-specific rules. However, the
growth in available data and advances in computer hardware enable data-based
approaches that use machine learning (ML) to improve scalability of solution
algorithms. We propose a decompose-route-improve (DRI) framework that groups
customers using clustering. Its similarity metric incorporates customers'
spatial, temporal, and demand data and is formulated to reflect the problem's
objective function and constraints. The resulting sub-routing problems can
independently be solved using any suitable algorithm. We apply pruned local
search (LS) between solved subproblems to improve the overall solution. Pruning
is based on customers' similarity information obtained in the decomposition
phase. In a computational study, we parameterize and compare existing
clustering algorithms and benchmark the DRI against the Hybrid Genetic Search
(HGS) of Vidal et al. (2013). Results show that our data-based approach
outperforms classic cluster-first, route-second approaches solely based on
customers' spatial information. The newly introduced similarity metric forms
separate sub-VRPs and improves the selection of LS moves in the improvement
phase. Thus, the DRI scales existing metaheuristics to achieve high-quality
solutions faster for large-scale VRPs by efficiently reducing complexity.
Further, the DRI can be easily adapted to various solution methods and VRP
characteristics, such as distribution of customer locations and demands, depot
location, and different time window scenarios, making it a generalizable
approach to solving routing problems.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00042" title="Abstract">arXiv:2402.00042</a> [<a href="/pdf/2402.00042" title="Download PDF">pdf</a>, <a href="/ps/2402.00042" title="Download PostScript">ps</a>, <a href="/format/2402.00042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimized Task Assignment and Predictive Maintenance for Industrial  Machines using Markov Decision Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nasir%2C+A">Ali Nasir</a>, 
<a href="/search/cs?searchtype=author&query=Mekid%2C+S">Samir Mekid</a>, 
<a href="/search/cs?searchtype=author&query=Sawlan%2C+Z">Zaid Sawlan</a>, 
<a href="/search/cs?searchtype=author&query=Alsawafy%2C+O">Omar Alsawafy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 11 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper considers a distributed decision-making approach for manufacturing
task assignment and condition-based machine health maintenance. Our approach
considers information sharing between the task assignment and health management
decision-making agents. We propose the design of the decision-making agents
based on Markov decision processes. The key advantage of using a Markov
decision process-based approach is the incorporation of uncertainty involved in
the decision-making process. The paper provides detailed mathematical models
along with the associated practical execution strategy. In order to demonstrate
the effectiveness and practical applicability of our proposed approach, we have
included a detailed numerical case study that is based on open source milling
machine tool degradation data. Our case study indicates that the proposed
approach offers flexibility in terms of the selection of cost parameters and it
allows for offline computation and analysis of the decision-making policy.
These features create and opportunity for the future work on learning of the
cost parameters associated with our proposed model using artificial
intelligence.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00043" title="Abstract">arXiv:2402.00043</a> [<a href="/pdf/2402.00043" title="Download PDF">pdf</a>, <a href="/format/2402.00043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive and Intelligent Root Cause Analysis in Manufacturing with  Causal Bayesian Networks and Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wehner%2C+C">Christoph Wehner</a>, 
<a href="/search/cs?searchtype=author&query=Kertel%2C+M">Maximilian Kertel</a>, 
<a href="/search/cs?searchtype=author&query=Wewerka%2C+J">Judith Wewerka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
<p class="mathjax">Root Cause Analysis (RCA) in the manufacturing of electric vehicles is the
process of identifying fault causes. Traditionally, the RCA is conducted
manually, relying on process expert knowledge. Meanwhile, sensor networks
collect significant amounts of data in the manufacturing process. Using this
data for RCA makes it more efficient. However, purely data-driven methods like
Causal Bayesian Networks have problems scaling to large-scale, real-world
manufacturing processes due to the vast amount of potential cause-effect
relationships (CERs). Furthermore, purely data-driven methods have the
potential to leave out already known CERs or to learn spurious CERs. The paper
contributes by proposing an interactive and intelligent RCA tool that combines
expert knowledge of an electric vehicle manufacturing process and a data-driven
machine learning method. It uses reasoning over a large-scale Knowledge Graph
of the manufacturing process while learning a Causal Bayesian Network. In
addition, an Interactive User Interface enables a process expert to give
feedback to the root cause graph by adding and removing information to the
Knowledge Graph. The interactive and intelligent RCA tool reduces the learning
time of the Causal Bayesian Network while decreasing the number of spurious
CERs. Thus, the interactive and intelligent RCA tool closes the feedback loop
between expert and machine learning method.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00044" title="Abstract">arXiv:2402.00044</a> [<a href="/pdf/2402.00044" title="Download PDF">pdf</a>, <a href="/format/2402.00044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training microrobots to swim by a large language model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhuoqun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lailai Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine learning and artificial intelligence have recently represented a
popular paradigm for designing and optimizing robotic systems across various
scales. Recent studies have showcased the innovative application of large
language models (LLMs) in industrial control [1] and in directing legged
walking robots [2]. In this study, we utilize an LLM, GPT-4, to train two
prototypical microrobots for swimming in viscous fluids. Adopting a few-shot
learning approach, we develop a minimal, unified prompt composed of only five
sentences. The same concise prompt successfully guides two distinct articulated
microrobots -- the three-link swimmer and the three-sphere swimmer -- in
mastering their signature strokes. These strokes, initially conceptualized by
physicists, are now effectively interpreted and applied by the LLM, enabling
the microrobots to circumvent the physical constraints inherent to
micro-locomotion. Remarkably, our LLM-based decision-making strategy
substantially surpasses a traditional reinforcement learning method in terms of
training speed. We discuss the nuanced aspects of prompt design, particularly
emphasizing the reduction of monetary expenses of using GPT-4.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00045" title="Abstract">arXiv:2402.00045</a> [<a href="/pdf/2402.00045" title="Download PDF">pdf</a>, <a href="/format/2402.00045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Multimedia Generated by Large AI Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Li Lin</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+N">Neeraj Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Hainan Ren</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chun-Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+F">Feng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Verdoliva%2C+L">Luisa Verdoliva</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shu Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The rapid advancement of Large AI Models (LAIMs), particularly diffusion
models and large language models, has marked a new era where AI-generated
multimedia is increasingly integrated into various aspects of daily life.
Although beneficial in numerous fields, this content presents significant
risks, including potential misuse, societal disruptions, and ethical concerns.
Consequently, detecting multimedia generated by LAIMs has become crucial, with
a marked rise in related research. Despite this, there remains a notable gap in
systematic surveys that focus specifically on detecting LAIM-generated
multimedia. Addressing this, we provide the first survey to comprehensively
cover existing research on detecting multimedia (such as text, images, videos,
audio, and multimodal content) created by LAIMs. Specifically, we introduce a
novel taxonomy for detection methods, categorized by media modality, and
aligned with two perspectives: pure detection (aiming to enhance detection
performance) and beyond detection (adding attributes like generalizability,
robustness, and interpretability to detectors). Additionally, we have presented
a brief overview of generation mechanisms, public datasets, and online
detection tools to provide a valuable resource for researchers and
practitioners in this field. Furthermore, we identify current challenges in
detection and propose directions for future research that address unexplored,
ongoing, and emerging issues in detecting multimedia generated by LAIMs. Our
aim for this survey is to fill an academic gap and contribute to global AI
security efforts, helping to ensure the integrity of information in the digital
realm. The project link is
https://github.com/Purdue-M2/Detect-LAIM-generated-Multimedia-Survey.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00046" title="Abstract">arXiv:2402.00046</a> [<a href="/pdf/2402.00046" title="Download PDF">pdf</a>, <a href="/format/2402.00046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introducing PetriRL: An Innovative Framework for JSSP Resolution  Integrating Petri nets and Event-based Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lassoued%2C+S">Sofiene Lassoued</a>, 
<a href="/search/cs?searchtype=author&query=Schwung%2C+A">Andreas Schwung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Quality scheduling in industrial job shops is crucial. Although neural
networks excel in solving these problems, their limited explainability hinders
their widespread industrial adoption. In this research, we introduce an
innovative framework for solving job shop scheduling problems (JSSP). Our
methodology leverages Petri nets to model the job shop, not only improving
explainability but also enabling direct incorporation of raw data without the
need to preprocess JSSP instances into disjunctive graphs. The Petri net, with
its controlling capacities, also governs the automated components of the
process, allowing the agent to focus on critical decision-making, particularly
resource allocation. The integration of event-based control and action masking
in our approach yields competitive performance on public test benchmarks.
Comparative analyses across a wide spectrum of optimization solutions,
including heuristics, metaheuristics, and learning-based algorithms, highlight
the competitiveness of our approach in large instances and its superiority over
all competitors in small to medium-sized scenarios. Ultimately, our approach
not only demonstrates a robust ability to generalize across various instance
sizes but also leverages the Petri net's graph nature to dynamically add job
operations during the inference phase without the need for agent retraining,
thereby enhancing flexibility.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00048" title="Abstract">arXiv:2402.00048</a> [<a href="/pdf/2402.00048" title="Download PDF">pdf</a>, <a href="/format/2402.00048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IICONGRAPH: improved Iconographic and Iconological Statements in  Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sartini%2C+B">Bruno Sartini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Iconography and iconology are fundamental domains when it comes to
understanding artifacts of cultural heritage. Iconography deals with the study
and interpretation of visual elements depicted in artifacts and their
symbolism, while iconology delves deeper, exploring the underlying cultural and
historical meanings. Despite the advances in representing cultural heritage
with Linked Open Data (LOD), recent studies show persistent gaps in the
representation of iconographic and iconological statements in current knowledge
graphs (KGs). To address them, this paper presents IICONGRAPH, a KG that was
created by refining and extending the iconographic and iconological statements
of ArCo (the Italian KG of cultural heritage) and Wikidata. The development of
IICONGRAPH was also driven by a series of requirements emerging from research
case studies that were unattainable in the non-reengineered versions of the
KGs. The evaluation results demonstrate that IICONGRAPH not only outperforms
ArCo and Wikidata through domain-specific assessments from the literature but
also serves as a robust platform for addressing the formulated research
questions. IICONGRAPH is released and documented in accordance with the FAIR
principles to guarantee the resource's reusability. The algorithms used to
create it and assess the research questions have also been made available to
ensure transparency and reproducibility. While future work focuses on ingesting
more data into the KG, and on implementing it as a backbone of LLM-based
question answering systems, the current version of IICONGRAPH still emerges as
a valuable asset, contributing to the evolving landscape of cultural heritage
representation within Knowledge Graphs, the Semantic Web, and beyond.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00049" title="Abstract">arXiv:2402.00049</a> [<a href="/pdf/2402.00049" title="Download PDF">pdf</a>, <a href="/ps/2402.00049" title="Download PostScript">ps</a>, <a href="/format/2402.00049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Dynamical Model for Reluctance Actuators Including Saturation,  Hysteresis and Eddy Currents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ramirez-Laboreo%2C+E">Edgar Ramirez-Laboreo</a> (1), 
<a href="/search/eess?searchtype=author&query=Roes%2C+M+G+L">Maurice G. L. Roes</a> (2), 
<a href="/search/eess?searchtype=author&query=Sagues%2C+C">Carlos Sagues</a> (1) ((1) Universidad de Zaragoza, (2) Eindhoven University of Technology)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 13 figures. This is the accepted version of an already published paper (see Journal reference)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in IEEE/ASME Transactions on Mechatronics, vol. 24, no. 3, pp.
  1396-1406, June 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">A novel hybrid dynamical model for single-coil, short-stroke reluctance
actuators is presented in this paper. The model, which is partially based on
the principles of magnetic equivalent circuits, includes the magnetic phenomena
of hysteresis and saturation by means of the generalized Preisach model. In
addition, the eddy currents induced in the iron core are also considered, and
the flux fringing effect in the air is incorporated by using results from
finite element simulations. An explicit solution of the dynamics without need
of inverting the Preisach model is derived, and the hybrid automaton that
results from combining the electromagnetic and motion equations is presented
and discussed. Finally, an identification method to determine the model
parameters is proposed and experimentally illustrated on a real actuator. The
results are presented and the advantages of our modeling method are emphasized.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00050" title="Abstract">arXiv:2402.00050</a> [<a href="/pdf/2402.00050" title="Download PDF">pdf</a>, <a href="/ps/2402.00050" title="Download PostScript">ps</a>, <a href="/format/2402.00050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Electromagnetic Estimation for Reluctance Actuators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ramirez-Laboreo%2C+E">Edgar Ramirez-Laboreo</a> (1), 
<a href="/search/eess?searchtype=author&query=Moya-Lasheras%2C+E">Eduardo Moya-Lasheras</a> (1), 
<a href="/search/eess?searchtype=author&query=Sagues%2C+C">Carlos Sagues</a> (1) ((1) Universidad de Zaragoza)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures This is the accepted version of an already published paper (see Journal reference)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in IEEE Transactions on Industrial Electronics, vol. 66, no. 3,
  pp. 1952-1961, March 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Several modeling, estimation, and control strategies have been recently
presented for simple reluctance devices like solenoid valves and
electromagnetic switches. In this paper, we present a new algorithm to online
estimate the flux linkage and the electrical time-variant parameters of these
devices, namely the resistance and the inductance, only by making use of
discrete-time measurements of voltage and current. The algorithm, which is
robust against measurement noise, is able to deal with temperature variations
of the device and provides accurate estimations during the motion of the
armature. Additionally, an integral {estimator} that uses the start of each
operation of the actuator as reset condition has been also implemented for
comparative purposes. The performances of both estimation methods are studied
and compared by means of simulations and experimental tests, and the benefits
of our proposal are emphasized. Possible uses of the estimates and further
modeling developments are also described and discussed.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00051" title="Abstract">arXiv:2402.00051</a> [<a href="/pdf/2402.00051" title="Download PDF">pdf</a>, <a href="/ps/2402.00051" title="Download PostScript">ps</a>, <a href="/format/2402.00051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Implementation of Hardware Accelerators for Neural Processing  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mayannavar%2C+S">Shilpa Mayannavar</a>, 
<a href="/search/cs?searchtype=author&query=Wali%2C+U">Uday Wali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Primary motivation for this work was the need to implement hardware
accelerators for a newly proposed ANN structure called Auto Resonance Network
(ARN) for robotic motion planning. ARN is an approximating feed-forward
hierarchical and explainable network. It can be used in various AI applications
but the application base was small. Therefore, the objective of the research
was twofold: to develop a new application using ARN and to implement a hardware
accelerator for ARN. As per the suggestions given by the Doctoral Committee, an
image recognition system using ARN has been implemented. An accuracy of around
94% was achieved with only 2 layers of ARN. The network also required a small
training data set of about 500 images. Publicly available MNIST dataset was
used for this experiment. All the coding was done in Python. Massive
parallelism seen in ANNs presents several challenges to CPU design. For a given
functionality, e.g., multiplication, several copies of serial modules can be
realized within the same area as a parallel module. Advantage of using serial
modules compared to parallel modules under area constraints has been discussed.
One of the module often useful in ANNs is a multi-operand addition. One problem
in its implementation is that the estimation of carry bits when the number of
operands changes. A theorem to calculate exact number of carry bits required
for a multi-operand addition has been presented in the thesis which alleviates
this problem. The main advantage of the modular approach to multi-operand
addition is the possibility of pipelined addition with low reconfiguration
overhead. This results in overall increase in throughput for large number of
additions, typically seen in several DNN configurations.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00052" title="Abstract">arXiv:2402.00052</a> [<a href="/pdf/2402.00052" title="Download PDF">pdf</a>, <a href="/format/2402.00052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot Sequential Neuro-symbolic Reasoning for Automatically  Generating Architecture Schematic Designs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kodnongbua%2C+M">Milin Kodnongbua</a>, 
<a href="/search/cs?searchtype=author&query=Curtis%2C+L+H">Lawrence H. Curtis</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+A">Adriana Schulz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)

</div>
<p class="mathjax">This paper introduces a novel automated system for generating architecture
schematic designs aimed at streamlining complex decision-making at the
multifamily real estate development project's outset. Leveraging the combined
strengths of generative AI (neuro reasoning) and mathematical program solvers
(symbolic reasoning), the method addresses both the reliance on expert insights
and technical challenges in architectural schematic design. To address the
large-scale and interconnected nature of design decisions needed for designing
a whole building, we proposed a novel sequential neuro-symbolic reasoning
approach, emulating traditional architecture design processes from initial
concept to detailed layout. To remove the need to hand-craft a cost function to
approximate the desired objectives, we propose a solution that uses neuro
reasoning to generate constraints and cost functions that the symbolic solvers
can use to solve. We also incorporate feedback loops for each design stage to
ensure a tight integration between neuro and symbolic reasoning. Developed
using GPT-4 without further training, our method's effectiveness is validated
through comparative studies with real-world buildings. Our method can generate
various building designs in accordance with the understanding of the
neighborhood, showcasing its potential to transform the realm of architectural
schematic design.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00053" title="Abstract">arXiv:2402.00053</a> [<a href="/pdf/2402.00053" title="Download PDF">pdf</a>, <a href="/format/2402.00053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are We Wasting Time? A Fast, Accurate Performance Evaluation Framework  for Knowledge Graph Link Predictors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cornell%2C+F">Filip Cornell</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yifei Jin</a>, 
<a href="/search/cs?searchtype=author&query=Karlgren%2C+J">Jussi Karlgren</a>, 
<a href="/search/cs?searchtype=author&query=Girdzijauskas%2C+S">Sarunas Girdzijauskas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The standard evaluation protocol for measuring the quality of Knowledge Graph
Completion methods - the task of inferring new links to be added to a graph -
typically involves a step which ranks every entity of a Knowledge Graph to
assess their fit as a head or tail of a candidate link to be added. In
Knowledge Graphs on a larger scale, this task rapidly becomes prohibitively
heavy. Previous approaches mitigate this problem by using random sampling of
entities to assess the quality of links predicted or suggested by a method.
However, we show that this approach has serious limitations since the ranking
metrics produced do not properly reflect true outcomes. In this paper, we
present a thorough analysis of these effects along with the following findings.
First, we empirically find and theoretically motivate why sampling uniformly at
random vastly overestimates the ranking performance of a method. We show that
this can be attributed to the effect of easy versus hard negative candidates.
Second, we propose a framework that uses relational recommenders to guide the
selection of candidates for evaluation. We provide both theoretical and
empirical justification of our methodology, and find that simple and fast
methods can work extremely well, and that they match advanced neural
approaches. Even when a large portion of true candidates for a property are
missed, the estimation barely deteriorates. With our proposed framework, we can
reduce the time and computation needed similar to random sampling strategies
while vastly improving the estimation; on ogbl-wikikg2, we show that accurate
estimations of the full, filtered ranking can be obtained in 20 seconds instead
of 30 minutes. We conclude that considerable computational effort can be saved
by effective preprocessing and sampling methods and still reliably predict
performance accurately of the true performance for the entire ranking
procedure.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00059" title="Abstract">arXiv:2402.00059</a> [<a href="/pdf/2402.00059" title="Download PDF">pdf</a>, <a href="/format/2402.00059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FengWu-GHR: Learning the Kilometer-scale Medium-range Global Weather  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+T">Tao Han</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Song Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+F">Fenghua Ling</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+J">Junchao Gong</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jingjia Luo</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Junxia Gu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+K">Kan Dai</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+L">Lei Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">Kilometer-scale modeling of global atmosphere dynamics enables fine-grained
weather forecasting and decreases the risk of disastrous weather and climate
activity. Therefore, building a kilometer-scale global forecast model is a
persistent pursuit in the meteorology domain. Active international efforts have
been made in past decades to improve the spatial resolution of numerical
weather models. Nonetheless, developing the higher resolution numerical model
remains a long-standing challenge due to the substantial consumption of
computational resources. Recent advances in data-driven global weather
forecasting models utilize reanalysis data for model training and have
demonstrated comparable or even higher forecasting skills than numerical
models. However, they are all limited by the resolution of reanalysis data and
incapable of generating higher-resolution forecasts. This work presents
FengWu-GHR, the first data-driven global weather forecasting model running at
the 0.09$^{\circ}$ horizontal resolution. FengWu-GHR introduces a novel
approach that opens the door for operating ML-based high-resolution forecasts
by inheriting prior knowledge from a pretrained low-resolution model. The
hindcast of weather prediction in 2022 indicates that FengWu-GHR is superior to
the IFS-HRES. Furthermore, evaluations on station observations and case studies
of extreme events support the competitive operational forecasting skill of
FengWu-GHR at the high resolution.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00060" title="Abstract">arXiv:2402.00060</a> [<a href="/pdf/2402.00060" title="Download PDF">pdf</a>, <a href="/format/2402.00060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Treatment of Epistemic Uncertainty in Conjunction Analysis with  Dempster-Shafer Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanchez%2C+L">Luis Sanchez</a>, 
<a href="/search/cs?searchtype=author&query=Vasile%2C+M">Massimiliano Vasile</a>, 
<a href="/search/cs?searchtype=author&query=Sanvido%2C+S">Silvia Sanvido</a>, 
<a href="/search/cs?searchtype=author&query=Mertz%2C+K">Klaus Mertz</a>, 
<a href="/search/cs?searchtype=author&query=Taillan%2C+C">Christophe Taillan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 22 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Theory (cs.IT); Probability (math.PR)

</div>
<p class="mathjax">The paper presents an approach to the modelling of epistemic uncertainty in
Conjunction Data Messages (CDM) and the classification of conjunction events
according to the confidence in the probability of collision. The approach
proposed in this paper is based on the Dempster-Shafer Theory (DSt) of evidence
and starts from the assumption that the observed CDMs are drawn from a family
of unknown distributions. The Dvoretzky-Kiefer-Wolfowitz (DKW) inequality is
used to construct robust bounds on such a family of unknown distributions
starting from a time series of CDMs. A DSt structure is then derived from the
probability boxes constructed with DKW inequality. The DSt structure
encapsulates the uncertainty in the CDMs at every point along the time series
and allows the computation of the belief and plausibility in the realisation of
a given probability of collision. The methodology proposed in this paper is
tested on a number of real events and compared against existing practices in
the European and French Space Agencies.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00063" title="Abstract">arXiv:2402.00063</a> [<a href="/pdf/2402.00063" title="Download PDF">pdf</a>, <a href="/format/2402.00063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Time-varying Shockwave Speed Model for Trajectory Reconstruction using  Lagrangian and Eulerian Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Kouvelas%2C+A">Anastasios Kouvelas</a>, 
<a href="/search/eess?searchtype=author&query=Makridis%2C+M+A">Michail A. Makridis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Inference of detailed vehicle trajectories is crucial for applications such
as traffic flow modeling, energy consumption estimation, and traffic flow
optimization. Static sensors can provide only aggregated information, posing
challenges in reconstructing individual vehicle trajectories. Shockwave theory
is used to reproduce oscillations that occur between sensors. However, as the
emerging of connected vehicles grows, probe data offers significant
opportunities for more precise trajectory reconstruction. Existing methods rely
on Eulerian observations (e.g., data from static sensors) and Lagrangian
observations (e.g., data from probe vehicles) incorporating shockwave theory
and car-following modeling. Despite these advancements, a prevalent issue lies
in the static assignment of shockwave speed, which may not be able to reflect
the traffic oscillations in a short time period caused by varying response
times and vehicle dynamics. Moreover, energy consumption estimation is largely
ignored. In response, this paper proposes a novel framework that integrates
Eulerian and Lagrangian observations for trajectory reconstruction. The
approach introduces a calibration algorithm for time-varying shockwave speed.
The calibrated shockwave speed of the CV is then utilized for trajectory
reconstruction of other non-connected vehicles based on shockwave theory.
Additionaly, vehicle and driver dynamics are introduced to optimize the
trajectory and estimate energy consumption. The proposed method is evaluated
using real-world datasets, demonstrating superior performance in terms of
trajectory accuracy, reproducing traffic oscillations, and estimating energy
consumption.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00064" title="Abstract">arXiv:2402.00064</a> [<a href="/pdf/2402.00064" title="Download PDF">pdf</a>, <a href="/ps/2402.00064" title="Download PostScript">ps</a>, <a href="/format/2402.00064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Merging plans with incomplete knowledge about actions and goals through  an agent-based reputation system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carbo%2C+J">Javier Carbo</a>, 
<a href="/search/cs?searchtype=author&query=Molina%2C+J+M">Jose M Molina</a>, 
<a href="/search/cs?searchtype=author&query=Patricio%2C+M+A">Miguel A Patricio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Managing transition plans is one of the major problems of people with
cognitive disabilities. Therefore, finding an automated way to generate such
plans would be a helpful tool for this community. In this paper we have
specifically proposed and compared different alternative ways to merge plans
formed by sequences of actions of unknown similarities between goals and
actions executed by several operator agents which cooperate between them
applying such actions over some passive elements (node agents) that require
additional executions of another plan after some time of use. Such ignorance of
the similarities between plan actions and goals would justify the use of a
distributed recommendation system that would provide an useful plan to be
applied for a certain goal to a given operator agent, generated from the known
results of previous executions of different plans by other operator agents.
Here we provide the general framework of execution (agent system), and the
different merging algorithms applied to this problem. The proposed agent system
would act as an useful cognitive assistant for people with intelectual
disabilities such as autism.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00065" title="Abstract">arXiv:2402.00065</a> [<a href="/pdf/2402.00065" title="Download PDF">pdf</a>, <a href="/ps/2402.00065" title="Download PostScript">ps</a>, <a href="/format/2402.00065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A technical note for the 91-clauses SAT resolution with Indirect QAOA  based approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fleury%2C+G">Gerard Fleury</a>, 
<a href="/search/cs?searchtype=author&query=Lacomme%2C+P">Philippe Lacomme</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">This paper addresses the resolution of the 3-SAT problem using a QAOA-like
approach. The chosen principle involves modeling the solution ranks of the
3-SAT problem, which, in this particular case, directly represent a solution.
This results in a highly compact circuit with few gates, enabling the modeling
of large-sized 3-SAT problems. Numerical experimentation demonstrates that the
approach can solve instances composed of 91 clauses and 20 variables with an
implementation based on Qiskit.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00066" title="Abstract">arXiv:2402.00066</a> [<a href="/pdf/2402.00066" title="Download PDF">pdf</a>, <a href="/ps/2402.00066" title="Download PostScript">ps</a>, <a href="/format/2402.00066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TrackGPT -- A generative pre-trained transformer for cross-domain entity  trajectory forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stroh%2C+N">Nicholas Stroh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The forecasting of entity trajectories at future points in time is a critical
capability gap in applications across both Commercial and Defense sectors.
Transformers, and specifically Generative Pre-trained Transformer (GPT)
networks have recently revolutionized several fields of Artificial
Intelligence, most notably Natural Language Processing (NLP) with the advent of
Large Language Models (LLM) like OpenAI's ChatGPT. In this research paper, we
introduce TrackGPT, a GPT-based model for entity trajectory forecasting that
has shown utility across both maritime and air domains, and we expect to
perform well in others. TrackGPT stands as a pioneering GPT model capable of
producing accurate predictions across diverse entity time series datasets,
demonstrating proficiency in generating both long-term forecasts with sustained
accuracy and short-term forecasts with high precision. We present benchmarks
against state-of-the-art deep learning techniques, showing that TrackGPT's
forecasting capability excels in terms of accuracy, reliability, and
modularity. Importantly, TrackGPT achieves these results while remaining
domain-agnostic and requiring minimal data features (only location and time)
compared to models achieving similar performance. In conclusion, our findings
underscore the immense potential of applying GPT architectures to the task of
entity trajectory forecasting, exemplified by the innovative TrackGPT model.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00068" title="Abstract">arXiv:2402.00068</a> [<a href="/pdf/2402.00068" title="Download PDF">pdf</a>, <a href="/format/2402.00068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT4Battery: An LLM-driven Framework for Adaptive State of Health  Estimation of Raw Li-ion Batteries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yuyuan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+G">Guosheng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhihong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">State of health (SOH) is a crucial indicator for assessing the degradation
level of batteries that cannot be measured directly but requires estimation.
Accurate SOH estimation enhances detection, control, and feedback for Li-ion
batteries, allowing for safe and efficient energy management and guiding the
development of new-generation batteries. Despite the significant progress in
data-driven SOH estimation, the time and resource-consuming degradation
experiments for generating lifelong training data pose a challenge in
establishing one large model capable of handling diverse types of Li-ion
batteries, e.g., cross-chemistry, cross-manufacturer, and cross-capacity.
Hence, this paper utilizes the strong generalization capability of large
language model (LLM) to proposes a novel framework for adaptable SOH estimation
across diverse batteries. To match the real scenario where unlabeled data
sequentially arrives in use with distribution shifts, the proposed model is
modified by a test-time training technique to ensure estimation accuracy even
at the battery's end of life. The validation results demonstrate that the
proposed framework achieves state-of-the-art accuracy on four widely recognized
datasets collected from 62 batteries. Furthermore, we analyze the theoretical
challenges of cross-battery estimation and provide a quantitative explanation
of the effectiveness of our method.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00069" title="Abstract">arXiv:2402.00069</a> [<a href="/pdf/2402.00069" title="Download PDF">pdf</a>, <a href="/format/2402.00069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using the Abstract Computer Architecture Description Language to Model  AI Hardware Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+M+M">Mika Markus M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Borst%2C+A+R+M">Alexander Richard Manfred Borst</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BCbeck%2C+K">Konstantin L&#xfc;beck</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+A+L">Alexander Louis-Ferdinand Jung</a>, 
<a href="/search/cs?searchtype=author&query=Bringmann%2C+O">Oliver Bringmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted Version for: MBMV'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Artificial Intelligence (AI) has witnessed remarkable growth, particularly
through the proliferation of Deep Neural Networks (DNNs). These powerful models
drive technological advancements across various domains. However, to harness
their potential in real-world applications, specialized hardware accelerators
are essential. This demand has sparked a market for parameterizable AI hardware
accelerators offered by different vendors.
<br />Manufacturers of AI-integrated products face a critical challenge: selecting
an accelerator that aligns with their product's performance requirements. The
decision involves choosing the right hardware and configuring a suitable set of
parameters. However, comparing different accelerator design alternatives
remains a complex task. Often, engineers rely on data sheets, spreadsheet
calculations, or slow black-box simulators, which only offer a coarse
understanding of the performance characteristics.
<br />The Abstract Computer Architecture Description Language (ACADL) is a concise
formalization of computer architecture block diagrams, which helps to
communicate computer architecture on different abstraction levels and allows
for inferring performance characteristics. In this paper, we demonstrate how to
use the ACADL to model AI hardware accelerators, use their ACADL description to
map DNNs onto them, and explain the timing simulation semantics to gather
performance results.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00070" title="Abstract">arXiv:2402.00070</a> [<a href="/pdf/2402.00070" title="Download PDF">pdf</a>, <a href="/format/2402.00070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EvoMerge: Neuroevolution for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yushu Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The current submission is the first draft, published for the sole purpose of sharing an idea and encouraging community effort. A more consolidated version may come later
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Extensive fine-tuning on Large Language Models does not always yield better
results. Oftentimes, models tend to get better at imitating one form of data
without gaining greater reasoning ability and may even end up losing some
intelligence. Here I introduce EvoMerge, a systematic approach to large
language model training and merging. Leveraging model merging for weight
crossover and fine-tuning for weight mutation, EvoMerge establishes an
evolutionary process aimed at pushing models beyond the limits of conventional
fine-tuning.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00071" title="Abstract">arXiv:2402.00071</a> [<a href="/pdf/2402.00071" title="Download PDF">pdf</a>, <a href="/ps/2402.00071" title="Download PostScript">ps</a>, <a href="/format/2402.00071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unraveling the Impact of Initial Choices and In-Loop Interventions on  Learning Dynamics in Autonomous Scanning Probe Microscopy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Slautin%2C+B+N">Boris N. Slautin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yongtao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Funakubo%2C+H">Hiroshi Funakubo</a>, 
<a href="/search/cs?searchtype=author&query=Kalinin%2C+S+V">Sergei V. Kalinin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Materials Science (cond-mat.mtrl-sci)

</div>
<p class="mathjax">The current focus in Autonomous Experimentation (AE) is on developing robust
workflows to conduct the AE effectively. This entails the need for well-defined
approaches to guide the AE process, including strategies for hyperparameter
tuning and high-level human interventions within the workflow loop. This paper
presents a comprehensive analysis of the influence of initial experimental
conditions and in-loop interventions on the learning dynamics of Deep Kernel
Learning (DKL) within the realm of AE in Scanning Probe Microscopy. We explore
the concept of 'seed effect', where the initial experiment setup has a
substantial impact on the subsequent learning trajectory. Additionally, we
introduce an approach of the seed point interventions in AE allowing the
operator to influence the exploration process. Using a dataset from
Piezoresponse Force Microscopy (PFM) on PbTiO3 thin films, we illustrate the
impact of the 'seed effect' and in-loop seed interventions on the effectiveness
of DKL in predicting material properties. The study highlights the importance
of initial choices and adaptive interventions in optimizing learning rates and
enhancing the efficiency of automated material characterization. This work
offers valuable insights into designing more robust and effective AE workflows
in microscopy with potential applications across various characterization
techniques. The analysis code that supports the funding is publicly available
at https://github.com/Slautin/2024_Seed_effect_DKL_BO.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00072" title="Abstract">arXiv:2402.00072</a> [<a href="/pdf/2402.00072" title="Download PDF">pdf</a>, <a href="/ps/2402.00072" title="Download PostScript">ps</a>, <a href="/format/2402.00072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable AI for survival analysis: a median-SHAP approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ter-Minassian%2C+L">Lucile Ter-Minassian</a>, 
<a href="/search/cs?searchtype=author&query=Ghalebikesabi%2C+S">Sahra Ghalebikesabi</a>, 
<a href="/search/cs?searchtype=author&query=Diaz-Ordaz%2C+K">Karla Diaz-Ordaz</a>, 
<a href="/search/cs?searchtype=author&query=Holmes%2C+C">Chris Holmes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the Interpretable Machine Learning for Healthcare (IMLH) workshop of the ICML 2022 Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">With the adoption of machine learning into routine clinical practice comes
the need for Explainable AI methods tailored to medical applications. Shapley
values have sparked wide interest for locally explaining models. Here, we
demonstrate their interpretation strongly depends on both the summary statistic
and the estimator for it, which in turn define what we identify as an 'anchor
point'. We show that the convention of using a mean anchor point may generate
misleading interpretations for survival analysis and introduce median-SHAP, a
method for explaining black-box models predicting individual survival times.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00074" title="Abstract">arXiv:2402.00074</a> [<a href="/pdf/2402.00074" title="Download PDF">pdf</a>, <a href="/format/2402.00074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Realization of a Novel Buck-Boost Phase-Modular Three-Phase  AC/DC Converter System with Low Component Number
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhetessov%2C+A">Aidar Zhetessov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 80 pages, Master Thesis at ETH Zurich
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Scalability and modularity are key features for future power converters, such
that these systems can be easily employed in many applications with different
electrical specifications. In this thesis, the potential of a new bidirectional
phase-modular three-phase AC/DC converter with buck-boost capability is
evaluated by means of studying two potential application cases and developing a
hardware prototype for one of them. The DC-DC inverting buck-boost converter is
a well-known and established topology. By connecting three such systems in
parallel, a phase-modular bidirectional buck-boost DC-AC converter employing a
minimum number of active components results, where for given AC voltage
amplitudes, an arbitrary DC voltage can be generated and vice versa. Such a
three-phase converter was not yet described in literature and this project aims
at investigating the fundamental topology properties, as well as its
performance limits. A hardware demonstrator is designed for one potential
application in order to verify the basic operation and the expected high
performance in terms of efficiency and power density.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00075" title="Abstract">arXiv:2402.00075</a> [<a href="/pdf/2402.00075" title="Download PDF">pdf</a>, <a href="/format/2402.00075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D-Nikud: Enhancing Hebrew Diacritization with LSTM and Pretrained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rosenthal%2C+A">Adi Rosenthal</a>, 
<a href="/search/cs?searchtype=author&query=Shaked%2C+N">Nadav Shaked</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">D-Nikud, a novel approach to Hebrew diacritization that integrates the
strengths of LSTM networks and BERT-based (transformer) pre-trained model.
Inspired by the methodologies employed in Nakdimon, we integrate it with the
TavBERT pre-trained model, our system incorporates advanced architectural
choices and diverse training data. Our experiments showcase state-of-the-art
results on several benchmark datasets, with a particular emphasis on modern
texts and more specified diacritization like gender.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00076" title="Abstract">arXiv:2402.00076</a> [<a href="/pdf/2402.00076" title="Download PDF">pdf</a>, <a href="/ps/2402.00076" title="Download PostScript">ps</a>, <a href="/format/2402.00076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploitation Strategies in Conditional Markov Chain Search: A case study  on the three-index assignment problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+S">Sahil Patel</a>, 
<a href="/search/cs?searchtype=author&query=Karapetyan%2C+D">Daniel Karapetyan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The Conditional Markov Chain Search (CMCS) is a framework for automated
design of metaheuristics for discrete combinatorial optimisation problems.
Given a set of algorithmic components such as hill climbers and mutations, CMCS
decides in which order to apply those components. The decisions are dictated by
the CMCS configuration that can be learnt offline. CMCS does not have an
acceptance criterion; any moves are accepted by the framework. As a result, it
is particularly good in exploration but is not as good at exploitation. In this
study, we explore several extensions of the framework to improve its
exploitation abilities. To perform a computational study, we applied the
framework to the three-index assignment problem. The results of our experiments
showed that a two-stage CMCS is indeed superior to a single-stage CMCS.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00080" title="Abstract">arXiv:2402.00080</a> [<a href="/pdf/2402.00080" title="Download PDF">pdf</a>, <a href="/ps/2402.00080" title="Download PostScript">ps</a>, <a href="/format/2402.00080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arithmetic Average Density Fusion -- Part IV: Distributed Heterogeneous  Fusion of RFS and LRFS Filters via Variational Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+T">Tiancheng Li</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+H">Haozhe Liang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+G">Guchong Li</a>, 
<a href="/search/eess?searchtype=author&query=Herrero%2C+J+G">Jes&#xfa;s Garc&#xed;a Herrero</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+Q">Quan Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages,14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper, the fourth part of a series of papers on the arithmetic average
(AA) density fusion approach and its application for target tracking, addresses
the intricate challenge of distributed heterogeneous multisensor multitarget
tracking, where each inter-connected sensor operates a probability hypothesis
density (PHD) filter, a multiple Bernoulli (MB) filter or a labeled MB (LMB)
filter and they cooperate with each other via information fusion. Earlier
papers in this series have proven that the proper AA fusion of these filters is
all exactly built on averaging their respective unlabeled/labeled PHDs. Based
on this finding, two PHD-AA fusion approaches are proposed via variational
minimization of the upper bound of the Kullback-Leibler divergence between the
local and multi-filter averaged PHDs subject to cardinality consensus based on
the Gaussian mixture implementation, enabling heterogeneous filter cooperation.
One focuses solely on fitting the weights of the local Gaussian components
(L-GCs), while the other simultaneously fits all the parameters of the L-GCs at
each sensor, both seeking average consensus on the unlabeled PHD, irrespective
of the specific posterior form of the local filters. For the distributed
peer-to-peer communication, both the classic consensus and flooding paradigms
have been investigated. Simulations have demonstrated the effectiveness and
flexibility of the proposed approaches in both homogeneous and heterogeneous
scenarios.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00083" title="Abstract">arXiv:2402.00083</a> [<a href="/pdf/2402.00083" title="Download PDF">pdf</a>, <a href="/format/2402.00083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Access Differences to Reduce Disparity in Resource Allocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Andrews%2C+K">Kenya Andrews</a>, 
<a href="/search/cs?searchtype=author&query=Ohannessian%2C+M">Mesrob Ohannessian</a>, 
<a href="/search/cs?searchtype=author&query=Berger-Wolf%2C+T">Tanya Berger-Wolf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Association for Computing Machinery (2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Motivated by COVID-19 vaccine allocation, where vulnerable subpopulations are
simultaneously more impacted in terms of health and more disadvantaged in terms
of access to the vaccine, we formalize and study the problem of resource
allocation when there are inherent access differences that correlate with
advantage and disadvantage. We identify reducing resource disparity as a key
goal in this context and show its role as a proxy to more nuanced downstream
impacts. We develop a concrete access model that helps quantify how a given
allocation translates to resource flow for the advantaged vs. the
disadvantaged, based on the access gap between them. We then provide a
methodology for access-aware allocation. Intuitively, the resulting allocation
leverages more vaccines in locations with higher vulnerable populations to
mitigate the access gap and reduce overall disparity. Surprisingly, knowledge
of the access gap is often not needed to perform access-aware allocation. To
support this formalism, we provide empirical evidence for our access model and
show that access-aware allocation can significantly reduce resource disparity
and thus improve downstream outcomes. We demonstrate this at various scales,
including at county, state, national, and global levels.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00084" title="Abstract">arXiv:2402.00084</a> [<a href="/pdf/2402.00084" title="Download PDF">pdf</a>, <a href="/format/2402.00084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EPSD: Early Pruning with Self-Distillation for Efficient Model  Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ning Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yichen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+Z">Zhengping Che</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+R">Rui Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fachao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+X">Xiaofeng Mou</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yi Chang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jian Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors are with equal contributions. Paper accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Neural network compression techniques, such as knowledge distillation (KD)
and network pruning, have received increasing attention. Recent work `Prune,
then Distill' reveals that a pruned student-friendly teacher network can
benefit the performance of KD. However, the conventional teacher-student
pipeline, which entails cumbersome pre-training of the teacher and complicated
compression steps, makes pruning with KD less efficient. In addition to
compressing models, recent compression techniques also emphasize the aspect of
efficiency. Early pruning demands significantly less computational cost in
comparison to the conventional pruning methods as it does not require a large
pre-trained model. Likewise, a special case of KD, known as self-distillation
(SD), is more efficient since it requires no pre-training or student-teacher
pair selection. This inspires us to collaborate early pruning with SD for
efficient model compression. In this work, we propose the framework named Early
Pruning with Self-Distillation (EPSD), which identifies and preserves
distillable weights in early pruning for a given SD task. EPSD efficiently
combines early pruning and self-distillation in a two-step process, maintaining
the pruned network's trainability for compression. Instead of a simple
combination of pruning and SD, EPSD enables the pruned network to favor SD by
keeping more distillable weights before training to ensure better distillation
of the pruned network. We demonstrated that EPSD improves the training of
pruned networks, supported by visual and quantitative analyses. Our evaluation
covered diverse benchmarks (CIFAR-10/100, Tiny-ImageNet, full ImageNet,
CUB-200-2011, and Pascal VOC), with EPSD outperforming advanced pruning and SD
techniques.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00085" title="Abstract">arXiv:2402.00085</a> [<a href="/pdf/2402.00085" title="Download PDF">pdf</a>, <a href="/ps/2402.00085" title="Download PostScript">ps</a>, <a href="/format/2402.00085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scheduled Curiosity-Deep Dyna-Q: Efficient Exploration for Dialog Policy  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+X">Xuecheng Niu</a>, 
<a href="/search/cs?searchtype=author&query=Ito%2C+A">Akinori Ito</a>, 
<a href="/search/cs?searchtype=author&query=Nose%2C+T">Takashi Nose</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Training task-oriented dialog agents based on reinforcement learning is
time-consuming and requires a large number of interactions with real users. How
to grasp dialog policy within limited dialog experiences remains an obstacle
that makes the agent training process less efficient. In addition, most
previous frameworks start training by randomly choosing training samples, which
differs from the human learning method and hurts the efficiency and stability
of training. Therefore, we propose Scheduled Curiosity-Deep Dyna-Q (SC-DDQ), a
curiosity-driven curriculum learning framework based on a state-of-the-art
model-based reinforcement learning dialog model, Deep Dyna-Q (DDQ).
Furthermore, we designed learning schedules for SC-DDQ and DDQ, respectively,
following two opposite training strategies: classic curriculum learning and its
reverse version. Our results show that by introducing scheduled learning and
curiosity, the new framework leads to a significant improvement over the DDQ
and Deep Q-learning(DQN). Surprisingly, we found that traditional curriculum
learning was not always effective. Specifically, according to the experimental
results, the easy-first and difficult-first strategies are more suitable for
SC-DDQ and DDQ. To analyze our results, we adopted the entropy of sampled
actions to depict action exploration and found that training strategies with
high entropy in the first stage and low entropy in the last stage lead to
better performance.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00086" title="Abstract">arXiv:2402.00086</a> [<a href="/pdf/2402.00086" title="Download PDF">pdf</a>, <a href="/format/2402.00086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrosynthesis prediction enhanced by in-silico reaction data  augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+Y">Yiming Mo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenguan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent advances in machine learning (ML) have expedited retrosynthesis
research by assisting chemists to design experiments more efficiently. However,
all ML-based methods consume substantial amounts of paired training data (i.e.,
chemical reaction: product-reactant(s) pair), which is costly to obtain.
Moreover, companies view reaction data as a valuable asset and restrict the
accessibility to researchers. These issues prevent the creation of more
powerful retrosynthesis models due to their data-driven nature. As a response,
we exploit easy-to-access unpaired data (i.e., one component of
product-reactant(s) pair) for generating in-silico paired data to facilitate
model training. Specifically, we present RetroWISE, a self-boosting framework
that employs a base model inferred from real paired data to perform in-silico
reaction generation and augmentation using unpaired data, ultimately leading to
a superior model. On three benchmark datasets, RetroWISE achieves the best
overall performance against state-of-the-art models (e.g., +8.6% top-1 accuracy
on the USPTO-50K test dataset). Moreover, it consistently improves the
prediction accuracy of rare transformations. These results show that Retro-
WISE overcomes the training bottleneck by in-silico reactions, thereby paving
the way toward more effective ML-based retrosynthesis models.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00089" title="Abstract">arXiv:2402.00089</a> [<a href="/pdf/2402.00089" title="Download PDF">pdf</a>, <a href="/ps/2402.00089" title="Download PostScript">ps</a>, <a href="/format/2402.00089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCAPE: Searching Conceptual Architecture Prompts using Evolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+S+L">Soo Ling Lim</a>, 
<a href="/search/cs?searchtype=author&query=Bentley%2C+P+J">Peter J Bentley</a>, 
<a href="/search/cs?searchtype=author&query=Ishikawa%2C+F">Fuyuki Ishikawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Conceptual architecture involves a highly creative exploration of novel
ideas, often taken from other disciplines as architects consider radical new
forms, materials, textures and colors for buildings. While today's generative
AI systems can produce remarkable results, they lack the creativity
demonstrated for decades by evolutionary algorithms. SCAPE, our proposed tool,
combines evolutionary search with generative AI, enabling users to explore
creative and good quality designs inspired by their initial input through a
simple point and click interface. SCAPE injects randomness into generative AI,
and enables memory, making use of the built-in language skills of GPT-4 to vary
prompts via text-based mutation and crossover. We demonstrate that compared to
DALL-E 3, SCAPE enables a 67% improvement in image novelty, plus improvements
in quality and effectiveness of use; we show that in just 3 iterations SCAPE
has a 24% image novelty increase enabling effective exploration, plus
optimization of images by users. We use more than 20 independent architects to
assess SCAPE, who provide markedly positive feedback.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00091" title="Abstract">arXiv:2402.00091</a> [<a href="/pdf/2402.00091" title="Download PDF">pdf</a>, <a href="/ps/2402.00091" title="Download PostScript">ps</a>, <a href="/format/2402.00091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nash Soft Actor-Critic LEO Satellite Handover Management Algorithm for  Flying Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jinxuan Chen</a>, 
<a href="/search/eess?searchtype=author&query=Ozger%2C+M">Mustafa Ozger</a>, 
<a href="/search/eess?searchtype=author&query=Cavdar%2C+C">Cicek Cavdar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Compared with the terrestrial networks (TN), which can only support limited
coverage areas, low-earth orbit (LEO) satellites can provide seamless global
coverage and high survivability in case of emergencies. Nevertheless, the swift
movement of the LEO satellites poses a challenge: frequent handovers are
inevitable, compromising the quality of service (QoS) of users and leading to
discontinuous connectivity. Moreover, considering LEO satellite connectivity
for different flying vehicles (FVs) when coexisting with ground terminals, an
efficient satellite handover decision control and mobility management strategy
is required to reduce the number of handovers and allocate resources that align
with different users' requirements. In this paper, a novel distributed
satellite handover strategy based on Multi-Agent Reinforcement Learning (MARL)
and game theory named Nash-SAC has been proposed to solve these problems. From
the simulation results, the Nash-SAC-based handover strategy can effectively
reduce the handovers by over 16 percent and the blocking rate by over 18
percent, outperforming local benchmarks such as traditional Q-learning. It also
greatly improves the network utility used to quantify the performance of the
whole system by up to 48 percent and caters to different users requirements,
providing reliable and robust connectivity for both FVs and ground terminals.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00092" title="Abstract">arXiv:2402.00092</a> [<a href="/pdf/2402.00092" title="Download PDF">pdf</a>, <a href="/format/2402.00092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Episodic-free Task Selection for Few-shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Episodic training is a mainstream training strategy for few-shot learning. In
few-shot scenarios, however, this strategy is often inferior to some
non-episodic training strategy, e. g., Neighbourhood Component Analysis (NCA),
which challenges the principle that training conditions must match testing
conditions. Thus, a question is naturally asked: How to search for
episodic-free tasks for better few-shot learning? In this work, we propose a
novel meta-training framework beyond episodic training. In this framework,
episodic tasks are not used directly for training, but for evaluating the
effectiveness of some selected episodic-free tasks from a task set that are
performed for training the meta-learners. The selection criterion is designed
with the affinity, which measures the degree to which loss decreases when
executing the target tasks after training with the selected tasks. In
experiments, the training task set contains some promising types, e. g.,
contrastive learning and classification, and the target few-shot tasks are
achieved with the nearest centroid classifiers on the miniImageNet,
tiered-ImageNet and CIFAR-FS datasets. The experimental results demonstrate the
effectiveness of our approach.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00093" title="Abstract">arXiv:2402.00093</a> [<a href="/pdf/2402.00093" title="Download PDF">pdf</a>, <a href="/format/2402.00093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChIRAAG: ChatGPT Informed Rapid and Automated Assertion Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mali%2C+B">Bhabesh Mali</a>, 
<a href="/search/cs?searchtype=author&query=Maddala%2C+K">Karthik Maddala</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+S">Sweeya Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+V">Vatsal Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Karfa%2C+C">Chandan Karfa</a>, 
<a href="/search/cs?searchtype=author&query=Karri%2C+R">Ramesh Karri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures and 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">System Verilog Assertion (SVA) formulation, a critical yet complex task, is a
pre-requisite in the Formal Property Verification (FPV) process. Traditionally,
SVA formulation involves expert-driven interpretation of specifications. This
is time consuming and prone to human error. However, recent advances in Large
Language Models (LLM), LLM-informed automatic assertion generation is gaining
interest. We designed a novel LLM-based pipeline to generate assertions in
English Language, Linear Temporal Logic, and SVA from natural language
specifications. We developed a custom LLM-based on OpenAI GPT4 for our
experiments. Furthermore, we developed testbenches to verify/validate the
LLM-generated assertions. Only 43% of LLM-generated raw assertions had errors,
including syntax and logical errors. By iteratively prompting the LLMs using
carefully crafted prompts derived from test case failures, the pipeline could
generate correct SVAs after a maximum of nine iterations of prompting. Our
results show that LLMs can streamline the assertion generation workflow,
reshaping verification workflows.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00094" title="Abstract">arXiv:2402.00094</a> [<a href="/pdf/2402.00094" title="Download PDF">pdf</a>, <a href="/ps/2402.00094" title="Download PostScript">ps</a>, <a href="/format/2402.00094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Neural Networks: A Formulation Via Non-Archimedean Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Z%C3%BA%C3%B1iga-Galindo%2C+W+A">W. A. Z&#xfa;&#xf1;iga-Galindo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce a new class of deep neural networks (DNNs) with multilayered
tree-like architectures. The architectures are codified using numbers from the
ring of integers of non-Archimdean local fields. These rings have a natural
hierarchical organization as infinite rooted trees. Natural morphisms on these
rings allow us to construct finite multilayered architectures. The new DNNs are
robust universal approximators of real-valued functions defined on the
mentioned rings. We also show that the DNNs are robust universal approximators
of real-valued square-integrable functions defined in the unit interval.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00097" title="Abstract">arXiv:2402.00097</a> [<a href="/pdf/2402.00097" title="Download PDF">pdf</a>, <a href="/format/2402.00097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Code-Aware Prompting: A study of Coverage Guided Test Generation in  Regression Setting using LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ryan%2C+G">Gabriel Ryan</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Siddhartha Jain</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+M">Mingyue Shang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaofei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ramanathan%2C+M+K">Murali Krishna Ramanathan</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+B">Baishakhi Ray</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Testing plays a pivotal role in ensuring software quality, yet conventional
Search Based Software Testing (SBST) methods often struggle with complex
software units, achieving suboptimal test coverage. Recent work using large
language models (LLMs) for test generation have focused on improving generation
quality through optimizing the test generation context and correcting errors in
model outputs, but use fixed prompting strategies that prompt the model to
generate tests without additional guidance. As a result LLM-generated test
suites still suffer from low coverage. In this paper, we present SymPrompt, a
code-aware prompting strategy for LLMs in test generation. SymPrompt's approach
is based on recent work that demonstrates LLMs can solve more complex logical
problems when prompted to reason about the problem in a multi-step fashion. We
apply this methodology to test generation by deconstructing the testsuite
generation process into a multi-stage sequence, each of which is driven by a
specific prompt aligned with the execution paths of the method under test, and
exposing relevant type and dependency focal context to the model. Our approach
enables pretrained LLMs to generate more complete test cases without any
additional training. We implement SymPrompt using the TreeSitter parsing
framework and evaluate on a benchmark challenging methods from open source
Python projects. SymPrompt enhances correct test generations by a factor of 5
and bolsters relative coverage by 26% for CodeGen2. Notably, when applied to
GPT-4, symbolic path prompts improve coverage by over 2x compared to baseline
prompting strategies.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00121" title="Abstract">arXiv:2402.00121</a> [<a href="/pdf/2402.00121" title="Download PDF">pdf</a>, <a href="/format/2402.00121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing for Sustained Motivation: A Review of Self-Determination  Theory in Behaviour Change Technologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alberts%2C+L">Lize Alberts</a>, 
<a href="/search/cs?searchtype=author&query=Lyngs%2C+U">Ulrik Lyngs</a>, 
<a href="/search/cs?searchtype=author&query=Lukoff%2C+K">Kai Lukoff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the Interacting with Computers (IwC) special issue on self-determination theory in HCI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Recent years have seen a surge in applications and technologies aimed at
motivating users to achieve personal goals and improve their wellbeing.
However, these often fail to promote long-term behaviour change, and sometimes
even backfire. We consider how self-determination theory (SDT), a metatheory of
human motivation and wellbeing, can help explain why such technologies fail,
and how they may better help users internalise the motivation behind their
goals and make enduring changes in their behaviour. In this work, we
systematically reviewed 15 papers in the ACM Digital Library that apply SDT to
the design of behaviour change technologies (BCTs). We identified 50
suggestions for design features in BCTs, grounded in SDT, that researchers have
applied to enhance user motivation. However, we find that SDT is often
leveraged to optimise engagement with the technology itself rather than with
the targeted behaviour change per se. When interpreted through the lens of SDT,
the implication is that BCTs may fail to cultivate sustained changes in
behaviour, as users' motivation depends on their enjoyment of the intervention,
which may wane over time. An underexplored opportunity remains for designers to
leverage SDT to support users to internalise the ultimate goals and value of
certain behaviour changes, enhancing their motivation to sustain these changes
in the long term.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00123" title="Abstract">arXiv:2402.00123</a> [<a href="/pdf/2402.00123" title="Download PDF">pdf</a>, <a href="/format/2402.00123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Template-based and Template-free Language Model Probing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaier%2C+S">Sagi Shaier</a>, 
<a href="/search/cs?searchtype=author&query=Bennett%2C+K">Kevin Bennett</a>, 
<a href="/search/cs?searchtype=author&query=Hunter%2C+L+E">Lawrence E Hunter</a>, 
<a href="/search/cs?searchtype=author&query=von+der+Wense%2C+K">Katharina von der Wense</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The differences between cloze-task language model (LM) probing with 1)
expert-made templates and 2) naturally-occurring text have often been
overlooked. Here, we evaluate 16 different LMs on 10 probing English datasets
-- 4 template-based and 6 template-free -- in general and biomedical domains to
answer the following research questions: (RQ1) Do model rankings differ between
the two approaches? (RQ2) Do models' absolute scores differ between the two
approaches? (RQ3) Do the answers to RQ1 and RQ2 differ between general and
domain-specific models? Our findings are: 1) Template-free and template-based
approaches often rank models differently, except for the top domain-specific
models. 2) Scores decrease by up to 42% Acc@1 when comparing parallel
template-free and template-based prompts. 3) Perplexity is negatively
correlated with accuracy in the template-free approach, but,
counter-intuitively, they are positively correlated for template-based probing.
4) Models tend to predict the same answers frequently across prompts for
template-based probing, which is less common when employing template-free
techniques.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00126" title="Abstract">arXiv:2402.00126</a> [<a href="/pdf/2402.00126" title="Download PDF">pdf</a>, <a href="/format/2402.00126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Common Sense Reasoning for Deep Fake Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Colman%2C+B">Ben Colman</a>, 
<a href="/search/cs?searchtype=author&query=Shahriyari%2C+A">Ali Shahriyari</a>, 
<a href="/search/cs?searchtype=author&query=Bharaj%2C+G">Gaurav Bharaj</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">State-of-the-art approaches rely on image-based features extracted via neural
networks for the deepfake detection binary classification. While these
approaches trained in the supervised sense extract likely fake features, they
may fall short in representing unnatural `non-physical' semantic facial
attributes -- blurry hairlines, double eyebrows, rigid eye pupils, or unnatural
skin shading. However, such facial attributes are generally easily perceived by
humans via common sense reasoning. Furthermore, image-based feature extraction
methods that provide visual explanation via saliency maps can be hard to be
interpreted by humans. To address these challenges, we propose the use of
common sense reasoning to model deepfake detection, and extend it to the
Deepfake Detection VQA (DD-VQA) task with the aim to model human intuition in
explaining the reason behind labeling an image as either real or fake. To this
end, we introduce a new dataset that provides answers to the questions related
to the authenticity of an image, along with its corresponding explanations. We
also propose a Vision and Language Transformer-based framework for the DD-VQA
task, incorporating text and image aware feature alignment formulations.
Finally, we evaluate our method on both the performance of deepfake detection
and the quality of the generated explanations. We hope that this task inspires
researchers to explore new avenues for enhancing language-based
interpretability and cross-modality applications in the realm of deepfake
detection.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00128" title="Abstract">arXiv:2402.00128</a> [<a href="/pdf/2402.00128" title="Download PDF">pdf</a>, <a href="/format/2402.00128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time Traffic Object Detection for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+A+H">Abdul Hannan Khan</a>, 
<a href="/search/cs?searchtype=author&query=Rizvi%2C+S+T+R">Syed Tahseen Raza Rizvi</a>, 
<a href="/search/cs?searchtype=author&query=Dengel%2C+A">Andreas Dengel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With recent advances in computer vision, it appears that autonomous driving
will be part of modern society sooner rather than later. However, there are
still a significant number of concerns to address. Although modern computer
vision techniques demonstrate superior performance, they tend to prioritize
accuracy over efficiency, which is a crucial aspect of real-time applications.
Large object detection models typically require higher computational power,
which is achieved by using more sophisticated onboard hardware. For autonomous
driving, these requirements translate to increased fuel costs and, ultimately,
a reduction in mileage. Further, despite their computational demands, the
existing object detectors are far from being real-time. In this research, we
assess the robustness of our previously proposed, highly efficient pedestrian
detector LSFM on well-established autonomous driving benchmarks, including
diverse weather conditions and nighttime scenes. Moreover, we extend our LSFM
model for general object detection to achieve real-time object detection in
traffic scenes. We evaluate its performance, low latency, and generalizability
on traffic object detection datasets. Furthermore, we discuss the inadequacy of
the current key performance indicator employed by object detection systems in
the context of autonomous driving and propose a more suitable alternative that
incorporates real-time requirements.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00129" title="Abstract">arXiv:2402.00129</a> [<a href="/pdf/2402.00129" title="Download PDF">pdf</a>, <a href="/format/2402.00129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CMRNext: Camera to LiDAR Matching in the Wild for Localization and  Extrinsic Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cattaneo%2C+D">Daniele Cattaneo</a>, 
<a href="/search/cs?searchtype=author&query=Valada%2C+A">Abhinav Valada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">LiDARs are widely used for mapping and localization in dynamic environments.
However, their high cost limits their widespread adoption. On the other hand,
monocular localization in LiDAR maps using inexpensive cameras is a
cost-effective alternative for large-scale deployment. Nevertheless, most
existing approaches struggle to generalize to new sensor setups and
environments, requiring retraining or fine-tuning. In this paper, we present
CMRNext, a novel approach for camera-LIDAR matching that is independent of
sensor-specific parameters, generalizable, and can be used in the wild for
monocular localization in LiDAR maps and camera-LiDAR extrinsic calibration.
CMRNext exploits recent advances in deep neural networks for matching
cross-modal data and standard geometric techniques for robust pose estimation.
We reformulate the point-pixel matching problem as an optical flow estimation
problem and solve the Perspective-n-Point problem based on the resulting
correspondences to find the relative pose between the camera and the LiDAR
point cloud. We extensively evaluate CMRNext on six different robotic
platforms, including three publicly available datasets and three in-house
robots. Our experimental evaluations demonstrate that CMRNext outperforms
existing approaches on both tasks and effectively generalizes to previously
unseen environments and sensor setups in a zero-shot manner. We make the code
and pre-trained models publicly available at <a href="http://cmrnext.cs.uni-freiburg.de">this http URL</a> .
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00132" title="Abstract">arXiv:2402.00132</a> [<a href="/pdf/2402.00132" title="Download PDF">pdf</a>, <a href="/ps/2402.00132" title="Download PostScript">ps</a>, <a href="/format/2402.00132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A study on the dynamic model of a three-phase grid-connected inverter  and an innovative method for its verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Esfandiari%2C+A">Arash Esfandiari</a>, 
<a href="/search/eess?searchtype=author&query=Hashemnia%2C+M+N">Mohammad Naser Hashemnia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Applied Physics (physics.app-ph)

</div>
<p class="mathjax">The ever-increasing use of renewable energy sources has underlined the role
of power electronic converters as an interface between these resources and the
power grid. One application of these converters is in three-phase inverters
utilized in a solar power plant to inject active/reactive power to the grid.
The dynamic model of power electronic converters is necessary for investigating
the overall system stability and the design of the controller for the
converters. Generally, the inverter dynamic model is needed to investigate the
dynamic behavior of inverters in different applications. This paper is a study
of the dynamical model of the grid-connected voltage source inverter, which is
extracted by the state-space averaging (SSA) method. This model is verified by
applying the values of the operating point to the inverter in Matlab Simulink
environment. To attain the steady-state operating point, the zero component of
the duty ratio of the converter is required. To obtain this component, the
matrix form of the converter's average equations is used. Overally, using the
above methods provides a more efficient and clear understanding of the dynamic
model of the converter.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00133" title="Abstract">arXiv:2402.00133</a> [<a href="/pdf/2402.00133" title="Download PDF">pdf</a>, <a href="/ps/2402.00133" title="Download PostScript">ps</a>, <a href="/format/2402.00133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Constant-Depth Circuit Complexity of Generating Quasigroups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Collins%2C+N+A">Nathaniel A. Collins</a>, 
<a href="/search/cs?searchtype=author&query=Grochow%2C+J+A">Joshua A. Grochow</a>, 
<a href="/search/cs?searchtype=author&query=Levet%2C+M">Michael Levet</a>, 
<a href="/search/cs?searchtype=author&query=Wei%C3%9F%2C+A">Armin Wei&#xdf;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS); Combinatorics (math.CO); Group Theory (math.GR)

</div>
<p class="mathjax">We investigate the constant-depth circuit complexity of the Isomorphism
Problem, Minimum Generating Set Problem (MGS), and Sub(quasi)group Membership
Problem (Membership) for groups and quasigroups (=Latin squares), given as
input in terms of their multiplication (Cayley) tables. Despite decades of
research on these problems, lower bounds for these problems even against
depth-$2$ AC circuits remain unknown. Perhaps surprisingly, Chattopadhyay,
Tor\'an, and Wagner (FSTTCS 2010; ACM Trans. Comput. Theory, 2013) showed that
Quasigroup Isomorphism could be solved by AC circuits of depth $O(\log \log n)$
using $O(\log^2 n)$ nondeterministic bits, a class we denote
$\exists^{\log^2(n)}FOLL$. We narrow this gap by improving the upper bound for
many of these problems to $quasiAC^0$, thus decreasing the depth to constant.
<br />In particular, we show:
<br />- MGS for quasigroups is in $\exists^{\log^2(n)}\forall^{\log
n}NTIME(\mathrm{polylog}(n))\subseteq quasiAC^0$. Papadimitriou and Yannakakis
(J. Comput. Syst. Sci., 1996) conjectured that this problem was
$\exists^{\log^2(n)}P$-complete; our results refute a version of that
conjecture for completeness under $quasiAC^0$ reductions unconditionally, and
under polylog-space reductions assuming EXP $\neq$ PSPACE.
<br />- MGS for groups is in $AC^{1}(L)$, improving on the previous upper bound of
P (Lucchini &amp; Thakkar, J. Algebra, 2024).
<br />- Quasigroup Isomorphism belongs to
$\exists^{\log^2(n)}AC^0(DTISP(\mathrm{polylog},\log)\subseteq quasiAC^0$,
improving on the previous bound of
$\exists^{\log^2(n)}L\cap\exists^{\log^2(n)}FOLL\subseteq quasiFOLL$
(Chattopadhyay, Tor\'an, &amp; Wagner, ibid.; Levet, Australas. J. Combin., 2023).
<br />Our results suggest that understanding the constant-depth circuit complexity
may be key to resolving the complexity of problems concerning (quasi)groups in
the multiplication table model.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00135" title="Abstract">arXiv:2402.00135</a> [<a href="/pdf/2402.00135" title="Download PDF">pdf</a>, <a href="/format/2402.00135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Reinforcement Learning Based Controller to Minimize Forces on the  Crutches of a Lower-Limb Exoskeleton
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Utku%2C+A+E">Aydin Emre Utku</a>, 
<a href="/search/cs?searchtype=author&query=Ada%2C+S+E">Suzan Ece Ada</a>, 
<a href="/search/cs?searchtype=author&query=Hatipoglu%2C+M">Muhammet Hatipoglu</a>, 
<a href="/search/cs?searchtype=author&query=Derman%2C+M">Mustafa Derman</a>, 
<a href="/search/cs?searchtype=author&query=Ugur%2C+E">Emre Ugur</a>, 
<a href="/search/cs?searchtype=author&query=Samur%2C+E">Evren Samur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Metabolic energy consumption of a powered lower-limb exoskeleton user mainly
comes from the upper body effort since the lower body is considered to be
passive. However, the upper body effort of the users is largely ignored in the
literature when designing motion controllers. In this work, we use deep
reinforcement learning to develop a locomotion controller that minimizes ground
reaction forces (GRF) on crutches. The rationale for minimizing GRF is to
reduce the upper body effort of the user. Accordingly, we design a model and a
learning framework for a human-exoskeleton system with crutches. We formulate a
reward function to encourage the forward displacement of a human-exoskeleton
system while satisfying the predetermined constraints of a physical robot. We
evaluate our new framework using Proximal Policy Optimization, a
state-of-the-art deep reinforcement learning (RL) method, on the MuJoCo physics
simulator with different hyperparameters and network architectures over
multiple trials. We empirically show that our learning model can generate joint
torques based on the joint angle, velocities, and the GRF on the feet and
crutch tips. The resulting exoskeleton model can directly generate joint
torques from states in line with the RL framework. Finally, we empirically show
that policy trained using our method can generate a gait with a 35% reduction
in GRF with respect to the baseline.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00136" title="Abstract">arXiv:2402.00136</a> [<a href="/pdf/2402.00136" title="Download PDF">pdf</a>, <a href="/ps/2402.00136" title="Download PostScript">ps</a>, <a href="/format/2402.00136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transdisciplinary Multi Modal Approach to Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Casado%2C+J">Johanna Casado</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa%2C+B">Beatriz Garc&#xed;a</a>, 
<a href="/search/cs?searchtype=author&query=Lucero%2C+N+M+M+B">Natasha Maria Monserrat Bertaina Lucero</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures, 14th International Multi-Conference on Complexity, Informatics, and Cybernetics: IMCIC 2023; Trans-Disciplinary Communications meeting, March 31, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">The muti-modal or multi-sensorial perception of nature is presented in this
article as part of research devoted to inclusive tools developed in the
framework of User Centered Design. This proposal shows that it is possible to
work in a transdisciplinary way, establishing feedback not only between
designers and final users, but also between humans and computers, to reduce
errors and co-design the resources according to personal needs. As part of the
present research, we present the basis for a new accessible software, sonoUno,
which was designed with the user in mind from the beginning, and we propose a
training activity to enhance the user's capacities, expand the detection of
different kinds of natural signals, and improve the comprehension of the Human
Computer Interfaces, opening new windows to the sciences for diverse
populations, not only in education and outreach but also in research. Some
examples of the exploitation of these new devices and tools are also presented.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00137" title="Abstract">arXiv:2402.00137</a> [<a href="/pdf/2402.00137" title="Download PDF">pdf</a>, <a href="/format/2402.00137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Neurodegenerative Disease Subtyping Explained by ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reyes%2C+D+M">Diego Machado Reyes</a>, 
<a href="/search/cs?searchtype=author&query=Chao%2C+H">Hanqing Chao</a>, 
<a href="/search/cs?searchtype=author&query=Hahn%2C+J">Juergen Hahn</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+P">Pingkun Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Alzheimer's disease (AD) is the most prevalent neurodegenerative disease; yet
its currently available treatments are limited to stopping disease progression.
Moreover, effectiveness of these treatments is not guaranteed due to the
heterogenetiy of the disease. Therefore, it is essential to be able to identify
the disease subtypes at a very early stage. Current data driven approaches are
able to classify the subtypes at later stages of AD or related disorders, but
struggle when predicting at the asymptomatic or prodromal stage. Moreover, most
existing models either lack explainability behind the classification or only
use a single modality for the assessment, limiting scope of its analysis. Thus,
we propose a multimodal framework that uses early-stage indicators such as
imaging, genetics and clinical assessments to classify AD patients into
subtypes at early stages. Similarly, we build prompts and use large language
models, such as ChatGPT, to interpret the findings of our model. In our
framework, we propose a tri-modal co-attention mechanism (Tri-COAT) to
explicitly learn the cross-modal feature associations. Our proposed model
outperforms baseline models and provides insight into key cross-modal feature
associations supported by known biological mechanisms.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00138" title="Abstract">arXiv:2402.00138</a> [<a href="/pdf/2402.00138" title="Download PDF">pdf</a>, <a href="/ps/2402.00138" title="Download PostScript">ps</a>, <a href="/format/2402.00138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decomposable Submodular Maximization in Federated Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rafiey%2C+A">Akbar Rafiey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Submodular functions, as well as the sub-class of decomposable submodular
functions, and their optimization appear in a wide range of applications in
machine learning, recommendation systems, and welfare maximization. However,
optimization of decomposable submodular functions with millions of component
functions is computationally prohibitive. Furthermore, the component functions
may be private (they might represent user preference function, for example) and
cannot be widely shared. To address these issues, we propose a {\em federated
optimization} setting for decomposable submodular optimization. In this
setting, clients have their own preference functions, and a weighted sum of
these preferences needs to be maximized. We implement the popular {\em
continuous greedy} algorithm in this setting where clients take parallel small
local steps towards the local solution and then the local changes are
aggregated at a central server. To address the large number of clients, the
aggregation is performed only on a subsampled set. Further, the aggregation is
performed only intermittently between stretches of parallel local steps, which
reduces communication cost significantly. We show that our federated algorithm
is guaranteed to provide a good approximate solution, even in the presence of
above cost-cutting measures. Finally, we show how the federated setting can be
incorporated in solving fundamental discrete submodular optimization problems
such as Maximum Coverage and Facility Location.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00143" title="Abstract">arXiv:2402.00143</a> [<a href="/pdf/2402.00143" title="Download PDF">pdf</a>, <a href="/format/2402.00143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making a Long Story Short in Conversation Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+Y">Yufei Tao</a>, 
<a href="/search/cs?searchtype=author&query=Mines%2C+T">Tiernan Mines</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+A">Ameeta Agrawal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted by TEICAI workshop at EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Conversation systems accommodate diverse users with unique personalities and
distinct writing styles. Within the domain of multi-turn dialogue modeling,
this work studies the impact of varied utterance lengths on the quality of
subsequent responses generated by conversation models. Using GPT-3 as the base
model, multiple dialogue datasets, and several metrics, we conduct a thorough
exploration of this aspect of conversational models. Our analysis sheds light
on the complex relationship between utterance lengths and the quality of
follow-up responses generated by dialogue systems. Empirical findings suggests
that, for certain types of conversations, utterance lengths can be reduced by
up to 72% without any noticeable difference in the quality of follow-up
responses.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00147" title="Abstract">arXiv:2402.00147</a> [<a href="/pdf/2402.00147" title="Download PDF">pdf</a>, <a href="/ps/2402.00147" title="Download PostScript">ps</a>, <a href="/format/2402.00147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure-preserving approximation for the non-isothermal  Cahn-Hilliard-Navier-Stokes system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Brunk%2C+A">Aaron Brunk</a>, 
<a href="/search/math?searchtype=author&query=Schumann%2C+D">Dennis Schumann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages; Proceedings of ENUMATH23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">In this work we propose and analyse a structure-preserving approximation of
the non-isothermal Cahn-Hilliard-Navier-Stokes system using conforming finite
elements in space and implicit time discretisation with convex-concave
splitting. The system is first reformulated into a variational form which
reveal the structure of the equations, which is then used in the subsequent
approximation.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00149" title="Abstract">arXiv:2402.00149</a> [<a href="/pdf/2402.00149" title="Download PDF">pdf</a>, <a href="/format/2402.00149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Language Adapters in Cross-Lingual Transfer for NLU
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kunz%2C+J">Jenny Kunz</a>, 
<a href="/search/cs?searchtype=author&query=Holmstr%C3%B6m%2C+O">Oskar Holmstr&#xf6;m</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Modular deep learning has been proposed for the efficient adaption of
pre-trained models to new tasks, domains and languages. In particular,
combining language adapters with task adapters has shown potential where no
supervised data exists for a language. In this paper, we explore the role of
language adapters in zero-shot cross-lingual transfer for natural language
understanding (NLU) benchmarks. We study the effect of including a
target-language adapter in detailed ablation studies with two multilingual
models and three multilingual datasets. Our results show that the effect of
target-language adapters is highly inconsistent across tasks, languages and
models. Retaining the source-language adapter instead often leads to an
equivalent, and sometimes to a better, performance. Removing the language
adapter after training has only a weak negative effect, indicating that the
language adapters do not have a strong impact on the predictions.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00152" title="Abstract">arXiv:2402.00152</a> [<a href="/pdf/2402.00152" title="Download PDF">pdf</a>, <a href="/format/2402.00152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deeper or Wider: A Perspective from Optimal Generalization Error with  Sobolev Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yahong Yang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Juncai He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2310.10766">arXiv:2310.10766</a>, <a href="/abs/2305.08466">arXiv:2305.08466</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
<p class="mathjax">Constructing the architecture of a neural network is a challenging pursuit
for the machine learning community, and the dilemma of whether to go deeper or
wider remains a persistent question. This paper explores a comparison between
deeper neural networks (DeNNs) with a flexible number of layers and wider
neural networks (WeNNs) with limited hidden layers, focusing on their optimal
generalization error in Sobolev losses. Analytical investigations reveal that
the architecture of a neural network can be significantly influenced by various
factors, including the number of sample points, parameters within the neural
networks, and the regularity of the loss function. Specifically, a higher
number of parameters tends to favor WeNNs, while an increased number of sample
points and greater regularity in the loss function lean towards the adoption of
DeNNs. We ultimately apply this theory to address partial differential
equations using deep Ritz and physics-informed neural network (PINN) methods,
guiding the design of neural networks.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00153" title="Abstract">arXiv:2402.00153</a> [<a href="/pdf/2402.00153" title="Download PDF">pdf</a>, <a href="/format/2402.00153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully Data-Driven Model for Increasing Sampling Rate Frequency of  Seismic Data using Super-Resolution Generative Adversarial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gholizadeh%2C+N">Navid Gholizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Katebi%2C+J">Javad Katebi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Geophysics (physics.geo-ph)

</div>
<p class="mathjax">High-quality data is one of the key requirements for any engineering
application. In earthquake engineering practice, accurate data is pivotal in
predicting the response of structure or damage detection process in an
Structural Health Monitoring (SHM) application with less uncertainty. However,
obtaining high-resolution data is fraught with challenges, such as significant
costs, extensive data channels, and substantial storage requirements. To
address these challenges, this study employs super-resolution generative
adversarial networks (SRGANs) to improve the resolution of time-history data
such as the data obtained by a sensor network in an SHM application, marking
the first application of SRGANs in earthquake engineering domain. The
time-series data are transformed into RGB values, converting raw data into
images. SRGANs are then utilized to upscale these low-resolution images,
thereby enhancing the overall sensor resolution. This methodology not only
offers potential reductions in data storage requirements but also simplifies
the sensor network, which could result in lower installation and maintenance
costs. The proposed SRGAN method is rigorously evaluated using real seismic
data, and its performance is compared with traditional enhancement techniques.
The findings of this study pave the way for cost-effective and efficient
improvements in the resolution of sensors used in SHM systems, with promising
implications for the safety and sustainability of infrastructures worldwide.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00156" title="Abstract">arXiv:2402.00156</a> [<a href="/pdf/2402.00156" title="Download PDF">pdf</a>, <a href="/format/2402.00156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Erie: A Declarative Grammar for Data Sonification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyeok Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yea-Seul Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hullman%2C+J">Jessica Hullman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 19 tables, 4 figures. Accepted at ACH CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Data sonification-mapping data variables to auditory variables, such as pitch
or volume-is used for data accessibility, scientific exploration, and
data-driven art (e.g., museum exhibitions) among others. While a substantial
amount of research has been made on effective and intuitive sonification
design, software support is not commensurate, limiting researchers from fully
exploring its capabilities. We contribute Erie, a declarative grammar for data
sonification, that enables abstractly expressing auditory mappings. Erie
supports specifying extensible tone designs (e.g., periodic wave, sampling,
frequency/amplitude modulation synthesizers), various encoding channels,
auditory legends, and composition options like sequencing and overlaying. Using
standard Web Audio and Web Speech APIs, we provide an Erie compiler for web
environments. We demonstrate the expressiveness and feasibility of Erie by
replicating research prototypes presented by prior work and provide a
sonification design gallery. We discuss future steps to extend Erie toward
other audio computing environments and support interactive data sonification.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00157" title="Abstract">arXiv:2402.00157</a> [<a href="/pdf/2402.00157" title="Download PDF">pdf</a>, <a href="/format/2402.00157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Mathematical Reasoning: Progresses and  Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahn%2C+J">Janice Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+R">Rishu Verma</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+R">Renze Lou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Di Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wenpeng Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EACL 2024 Student Research Workshop, 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Mathematical reasoning serves as a cornerstone for assessing the fundamental
cognitive capabilities of human intelligence. In recent times, there has been a
notable surge in the development of Large Language Models (LLMs) geared towards
the automated resolution of mathematical problems. However, the landscape of
mathematical problem types is vast and varied, with LLM-oriented techniques
undergoing evaluation across diverse datasets and settings. This diversity
makes it challenging to discern the true advancements and obstacles within this
burgeoning field. This survey endeavors to address four pivotal dimensions: i)
a comprehensive exploration of the various mathematical problems and their
corresponding datasets that have been investigated; ii) an examination of the
spectrum of LLM-oriented techniques that have been proposed for mathematical
problem-solving; iii) an overview of factors and concerns affecting LLMs in
solving math; and iv) an elucidation of the persisting challenges within this
domain. To the best of our knowledge, this survey stands as one of the first
extensive examinations of the landscape of LLMs in the realm of mathematics,
providing a holistic perspective on the current state, accomplishments, and
future challenges in this rapidly evolving field.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00159" title="Abstract">arXiv:2402.00159</a> [<a href="/pdf/2402.00159" title="Download PDF">pdf</a>, <a href="/format/2402.00159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dolma: an Open Corpus of Three Trillion Tokens for Language Model  Pretraining Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soldaini%2C+L">Luca Soldaini</a>, 
<a href="/search/cs?searchtype=author&query=Kinney%2C+R">Rodney Kinney</a>, 
<a href="/search/cs?searchtype=author&query=Bhagia%2C+A">Akshita Bhagia</a>, 
<a href="/search/cs?searchtype=author&query=Schwenk%2C+D">Dustin Schwenk</a>, 
<a href="/search/cs?searchtype=author&query=Atkinson%2C+D">David Atkinson</a>, 
<a href="/search/cs?searchtype=author&query=Authur%2C+R">Russell Authur</a>, 
<a href="/search/cs?searchtype=author&query=Bogin%2C+B">Ben Bogin</a>, 
<a href="/search/cs?searchtype=author&query=Chandu%2C+K">Khyathi Chandu</a>, 
<a href="/search/cs?searchtype=author&query=Dumas%2C+J">Jennifer Dumas</a>, 
<a href="/search/cs?searchtype=author&query=Elazar%2C+Y">Yanai Elazar</a>, 
<a href="/search/cs?searchtype=author&query=Hofmann%2C+V">Valentin Hofmann</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+A+H">Ananya Harsh Jha</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sachin Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Lucy%2C+L">Li Lucy</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+X">Xinxi Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Lambert%2C+N">Nathan Lambert</a>, 
<a href="/search/cs?searchtype=author&query=Magnusson%2C+I">Ian Magnusson</a>, 
<a href="/search/cs?searchtype=author&query=Morrison%2C+J">Jacob Morrison</a>, 
<a href="/search/cs?searchtype=author&query=Muennighoff%2C+N">Niklas Muennighoff</a>, 
<a href="/search/cs?searchtype=author&query=Naik%2C+A">Aakanksha Naik</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+C">Crystal Nam</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+M+E">Matthew E. Peters</a>, 
<a href="/search/cs?searchtype=author&query=Ravichander%2C+A">Abhilasha Ravichander</a>, 
<a href="/search/cs?searchtype=author&query=Richardson%2C+K">Kyle Richardson</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zejiang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Strubell%2C+E">Emma Strubell</a>, 
<a href="/search/cs?searchtype=author&query=Subramani%2C+N">Nishant Subramani</a>, 
<a href="/search/cs?searchtype=author&query=Tafjord%2C+O">Oyvind Tafjord</a>, 
<a href="/search/cs?searchtype=author&query=Walsh%2C+P">Pete Walsh</a>, 
<a href="/search/cs?searchtype=author&query=Zettlemoyer%2C+L">Luke Zettlemoyer</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+N+A">Noah A. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Hajishirzi%2C+H">Hannaneh Hajishirzi</a>, 
<a href="/search/cs?searchtype=author&query=Beltagy%2C+I">Iz Beltagy</a>, 
<a href="/search/cs?searchtype=author&query=Groeneveld%2C+D">Dirk Groeneveld</a>, 
<a href="/search/cs?searchtype=author&query=Dodge%2C+J">Jesse Dodge</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+K">Kyle Lo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Dataset available at: <a href="https://huggingface.co/datasets/allenai/dolma">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Language models have become a critical technology to tackling a wide range of
natural language processing tasks, yet many details about how the
best-performing language models were developed are not reported. In particular,
information about their pretraining corpora is seldom discussed: commercial
language models rarely provide any information about their data; even open
models rarely release datasets they are trained on, or an exact recipe to
reproduce them. As a result, it is challenging to conduct certain threads of
language modeling research, such as understanding how training data impacts
model capabilities and shapes their limitations. To facilitate open research on
language model pretraining, we release Dolma, a three trillion tokens English
corpus, built from a diverse mixture of web content, scientific papers, code,
public-domain books, social media, and encyclopedic materials. In addition, we
open source our data curation toolkit to enable further experimentation and
reproduction of our work. In this report, we document Dolma, including its
design principles, details about its construction, and a summary of its
contents. We interleave this report with analyses and experimental results from
training language models on intermediate states of Dolma to share what we have
learned about important data curation practices, including the role of content
or quality filters, deduplication, and multi-source mixing. Dolma has been used
to train OLMo, a state-of-the-art, open language model and framework designed
to build and study the science of language modeling.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00160" title="Abstract">arXiv:2402.00160</a> [<a href="/pdf/2402.00160" title="Download PDF">pdf</a>, <a href="/format/2402.00160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Clinical Pseudo-notes for Emergency Department Prediction  Tasks using Multiple Embedding Model for EHR (MEME)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S+A">Simon A. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Sujay Jain</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Alex Chen</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+A">Arabdha Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jennifer Fang</a>, 
<a href="/search/cs?searchtype=author&query=Rudas%2C+A">Akos Rudas</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+J+N">Jeffrey N. Chiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this work, we introduce Multiple Embedding Model for EHR (MEME), an
approach that views Electronic Health Records (EHR) as multimodal data. This
approach incorporates "pseudo-notes", textual representations of tabular EHR
concepts such as diagnoses and medications, and allows us to effectively employ
Large Language Models (LLMs) for EHR representation. This framework also adopts
a multimodal approach, embedding each EHR modality separately. We demonstrate
the effectiveness of MEME by applying it to several tasks within the Emergency
Department across multiple hospital systems. Our findings show that MEME
surpasses the performance of both single modality embedding methods and
traditional machine learning approaches. However, we also observe notable
limitations in generalizability across hospital institutions for all tested
models.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00162" title="Abstract">arXiv:2402.00162</a> [<a href="/pdf/2402.00162" title="Download PDF">pdf</a>, <a href="/format/2402.00162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Behind the Myth of Exploration in Policy Gradients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bolland%2C+A">Adrien Bolland</a>, 
<a href="/search/cs?searchtype=author&query=Lambrechts%2C+G">Gaspard Lambrechts</a>, 
<a href="/search/cs?searchtype=author&query=Ernst%2C+D">Damien Ernst</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Policy-gradient algorithms are effective reinforcement learning methods for
solving control problems with continuous state and action spaces. To compute
near-optimal policies, it is essential in practice to include exploration terms
in the learning objective. Although the effectiveness of these terms is usually
justified by an intrinsic need to explore environments, we propose a novel
analysis and distinguish two different implications of these techniques. First,
they make it possible to smooth the learning objective and to eliminate local
optima while preserving the global maximum. Second, they modify the gradient
estimates, increasing the probability that the stochastic parameter update
eventually provides an optimal policy. In light of these effects, we discuss
and illustrate empirically exploration strategies based on entropy bonuses,
highlighting their limitations and opening avenues for future works in the
design and analysis of such strategies.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00163" title="Abstract">arXiv:2402.00163</a> [<a href="/pdf/2402.00163" title="Download PDF">pdf</a>, <a href="/format/2402.00163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Object Detection Quality in Football Through Super-Resolution  Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seweryn%2C+K">Karolina Seweryn</a>, 
<a href="/search/cs?searchtype=author&query=Ch%C4%99%C4%87%2C+G">Gabriel Ch&#x119;&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=%C5%81ukasik%2C+S">Szymon &#x141;ukasik</a>, 
<a href="/search/cs?searchtype=author&query=Wr%C3%B3blewska%2C+A">Anna Wr&#xf3;blewska</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study explores the potential of super-resolution techniques in enhancing
object detection accuracy in football. Given the sport's fast-paced nature and
the critical importance of precise object (e.g. ball, player) tracking for both
analysis and broadcasting, super-resolution could offer significant
improvements. We investigate how advanced image processing through
super-resolution impacts the accuracy and reliability of object detection
algorithms in processing football match footage.
<br />Our methodology involved applying state-of-the-art super-resolution
techniques to a diverse set of football match videos from SoccerNet, followed
by object detection using Faster R-CNN. The performance of these algorithms,
both with and without super-resolution enhancement, was rigorously evaluated in
terms of detection accuracy.
<br />The results indicate a marked improvement in object detection accuracy when
super-resolution preprocessing is applied. The improvement of object detection
through the integration of super-resolution techniques yields significant
benefits, especially for low-resolution scenarios, with a notable 12\% increase
in mean Average Precision (mAP) at an IoU (Intersection over Union) range of
0.50:0.95 for 320x240 size images when increasing the resolution fourfold using
RLFN. As the dimensions increase, the magnitude of improvement becomes more
subdued; however, a discernible improvement in the quality of detection is
consistently evident. Additionally, we discuss the implications of these
findings for real-time sports analytics, player tracking, and the overall
viewing experience. The study contributes to the growing field of sports
technology by demonstrating the practical benefits and limitations of
integrating super-resolution techniques in football analytics and broadcasting.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00179" title="Abstract">arXiv:2402.00179</a> [<a href="/pdf/2402.00179" title="Download PDF">pdf</a>, <a href="/format/2402.00179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> De-identification is not always enough
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+A+R">Atiquer Rahman Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Chuang%2C+Y">Yao-Shun Chuang</a>, 
<a href="/search/cs?searchtype=author&query=Mohammed%2C+N">Noman Mohammed</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiaoqian Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">For sharing privacy-sensitive data, de-identification is commonly regarded as
adequate for safeguarding privacy. Synthetic data is also being considered as a
privacy-preserving alternative. Recent successes with numerical and tabular
data generative models and the breakthroughs in large generative language
models raise the question of whether synthetically generated clinical notes
could be a viable alternative to real notes for research purposes. In this
work, we demonstrated that (i) de-identification of real clinical notes does
not protect records against a membership inference attack, (ii) proposed a
novel approach to generate synthetic clinical notes using the current
state-of-the-art large language models, (iii) evaluated the performance of the
synthetically generated notes in a clinical domain task, and (iv) proposed a
way to mount a membership inference attack where the target model is trained
with synthetic data. We observed that when synthetically generated notes
closely match the performance of real data, they also exhibit similar privacy
concerns to the real data. Whether other approaches to synthetically generated
clinical notes could offer better trade-offs and become a better alternative to
sensitive real notes warrants further investigation.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00186" title="Abstract">arXiv:2402.00186</a> [<a href="/pdf/2402.00186" title="Download PDF">pdf</a>, <a href="/format/2402.00186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distance and Collision Probability Estimation from Gaussian Surface  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goel%2C+K">Kshitij Goel</a>, 
<a href="/search/cs?searchtype=author&query=Tabib%2C+W">Wennie Tabib</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computational Geometry (cs.CG); Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)

</div>
<p class="mathjax">This paper describes continuous-space methodologies to estimate the collision
probability, Euclidean distance and gradient between an ellipsoidal robot model
and an environment surface modeled as a set of Gaussian distributions.
Continuous-space collision probability estimation is critical for
uncertainty-aware motion planning. Most collision detection and avoidance
approaches assume the robot is modeled as a sphere, but ellipsoidal
representations provide tighter approximations and enable navigation in
cluttered and narrow spaces. State-of-the-art methods derive the Euclidean
distance and gradient by processing raw point clouds, which is computationally
expensive for large workspaces. Recent advances in Gaussian surface modeling
(e.g. mixture models, splatting) enable compressed and high-fidelity surface
representations. Few methods exist to estimate continuous-space occupancy from
such models. They require Gaussians to model free space and are unable to
estimate the collision probability, Euclidean distance and gradient for an
ellipsoidal robot. The proposed methods bridge this gap by extending prior work
in ellipsoid-to-ellipsoid Euclidean distance and collision probability
estimation to Gaussian surface models. A geometric blending approach is also
proposed to improve collision probability estimation. The approaches are
evaluated with numerical 2D and 3D experiments using real-world point cloud
data.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00188" title="Abstract">arXiv:2402.00188</a> [<a href="/pdf/2402.00188" title="Download PDF">pdf</a>, <a href="/format/2402.00188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Graph Pencil Method: Mapping Subgraph Densities to Stochastic Block  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gunderson%2C+L+M">Lee M Gunderson</a>, 
<a href="/search/cs?searchtype=author&query=Bravo-Hermsdorff%2C+G">Gecia Bravo-Hermsdorff</a>, 
<a href="/search/cs?searchtype=author&query=Orbanz%2C+P">Peter Orbanz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO); Statistics Theory (math.ST)

</div>
<p class="mathjax">In this work, we describe a method that determines an exact map from a finite
set of subgraph densities to the parameters of a stochastic block model (SBM)
matching these densities. Given a number $K$ of blocks, the subgraph densities
of a finite number of stars and bistars uniquely determines a single element of
the class of all degree-separated stochastic block models with $K$ blocks. Our
method makes it possible to translate estimates of these subgraph densities
into model parameters, and hence to use subgraph densities directly for
inference. The computational overhead is negligible; computing the translation
map is polynomial in $K$, but independent of the graph size once the subgraph
densities are given.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00190" title="Abstract">arXiv:2402.00190</a> [<a href="/pdf/2402.00190" title="Download PDF">pdf</a>, <a href="/ps/2402.00190" title="Download PostScript">ps</a>, <a href="/format/2402.00190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> REACT: Two Datasets for Analyzing Both Human Reactions and Evaluative  Feedback to Robots Over Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Candon%2C+K">Kate Candon</a>, 
<a href="/search/cs?searchtype=author&query=Georgiou%2C+N+C">Nicholas C. Georgiou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Helen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Richardson%2C+S">Sidney Richardson</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Scassellati%2C+B">Brian Scassellati</a>, 
<a href="/search/cs?searchtype=author&query=V%C3%A1zquez%2C+M">Marynel V&#xe1;zquez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Recent work in Human-Robot Interaction (HRI) has shown that robots can
leverage implicit communicative signals from users to understand how they are
being perceived during interactions. For example, these signals can be gaze
patterns, facial expressions, or body motions that reflect internal human
states. To facilitate future research in this direction, we contribute the
REACT database, a collection of two datasets of human-robot interactions that
display users' natural reactions to robots during a collaborative game and a
photography scenario. Further, we analyze the datasets to show that interaction
history is an important factor that can influence human reactions to robots. As
a result, we believe that future models for interpreting implicit feedback in
HRI should explicitly account for this history. REACT opens up doors to this
possibility in the future.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00194" title="Abstract">arXiv:2402.00194</a> [<a href="/pdf/2402.00194" title="Download PDF">pdf</a>, <a href="/ps/2402.00194" title="Download PostScript">ps</a>, <a href="/format/2402.00194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational orders of convergence of iterative methods for Richards&#x27;  equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Suciu%2C+N">Nicolae Suciu</a>, 
<a href="/search/math?searchtype=author&query=Radu%2C+F+A">Florin A. Radu</a>, 
<a href="/search/math?searchtype=author&query=Stokke%2C+J+S">Jakob S. Stokke</a>, 
<a href="/search/math?searchtype=author&query=C%C4%83tina%C5%9F%2C+E">Emil C&#x103;tina&#x15f;</a>, 
<a href="/search/math?searchtype=author&query=Malina%2C+A">Andra Malina</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Numerical solutions for flows in partially saturated porous media pose
challenges related to the non-linearity and elliptic-parabolic degeneracy of
the governing Richards' equation. Iterative methods are therefore required to
manage the complexity of the flow problem. Norms of successive corrections in
the iterative procedure form sequences of positive numbers. Definitions of
computational orders of convergence and theoretical results for abstract
convergent sequences can thus be used to evaluate and compare different
iterative methods. We analyze in this frame Newton's and $L$-scheme methods for
an implicit finite element method (FEM) and the $L$-scheme for an explicit
finite difference method (FDM). We also investigate the effect of the Anderson
Acceleration (AA) on both the implicit and the explicit $L$-schemes.
Considering a two-dimensional test problem, we found that the AA halves the
number of iterations and renders the convergence of the FEM scheme two times
faster. As for the FDM approach, AA does not reduce the number of iterations
and even increases the computational effort. Instead, being explicit, the FDM
$L$-scheme without AA is faster and as accurate as the FEM $L$-scheme with AA.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00195" title="Abstract">arXiv:2402.00195</a> [<a href="/pdf/2402.00195" title="Download PDF">pdf</a>, <a href="/format/2402.00195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dataset Condensation Driven Machine Unlearning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+J+I">Junaid Iqbal Khan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The current trend in data regulation requirements and privacy-preserving
machine learning has emphasized the importance of machine unlearning. The naive
approach to unlearning training data by retraining over the complement of the
forget samples is susceptible to computational challenges. These challenges
have been effectively addressed through a collection of techniques falling
under the umbrella of machine unlearning. However, there still exists a lack of
sufficiency in handling persistent computational challenges in harmony with the
utility and privacy of unlearned model. We attribute this to the lack of work
on improving the computational complexity of approximate unlearning from the
perspective of the training dataset. In this paper, we aim to fill this gap by
introducing dataset condensation as an essential component of machine
unlearning in the context of image classification. To achieve this goal, we
propose new dataset condensation techniques and an innovative unlearning scheme
that strikes a balance between machine unlearning privacy, utility, and
efficiency. Furthermore, we present a novel and effective approach to
instrumenting machine unlearning and propose its application in defending
against membership inference and model inversion attacks. Additionally, we
explore a new application of our approach, which involves removing data from
`condensed model', which can be employed to quickly train any arbitrary model
without being influenced by unlearning samples.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00197" title="Abstract">arXiv:2402.00197</a> [<a href="/pdf/2402.00197" title="Download PDF">pdf</a>, <a href="/format/2402.00197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Determination of Trace Organic Contaminant Concentration via Machine  Classification of Surface-Enhanced Raman Spectra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jayaprakash%2C+V">Vishnu Jayaprakash</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+J+B">Jae Bem You</a>, 
<a href="/search/cs?searchtype=author&query=Kanike%2C+C">Chiranjeevi Kanike</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinfeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=McCallum%2C+C">Christopher McCallum</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuehua Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Accurate detection and analysis of traces of persistent organic pollutants in
water is important in many areas, including environmental monitoring and food
quality control, due to their long environmental stability and potential
bioaccumulation. While conventional analysis of organic pollutants requires
expensive equipment, surface enhanced Raman spectroscopy (SERS) has
demonstrated great potential for accurate detection of these contaminants.
However, SERS analytical difficulties, such as spectral preprocessing,
denoising, and substrate-based spectral variation, have hindered widespread use
of the technique. Here, we demonstrate an approach for predicting the
concentration of sample pollutants from messy, unprocessed Raman data using
machine learning. Frequency domain transform methods, including the Fourier and
Walsh Hadamard transforms, are applied to sets of Raman spectra of three model
micropollutants in water (rhodamine 6G, chlorpyrifos, and triclosan), which are
then used to train machine learning algorithms. Using standard machine learning
models, the concentration of sample pollutants are predicted with more than 80
percent cross-validation accuracy from raw Raman data. cross-validation
accuracy of 85 percent was achieved using deep learning for a moderately sized
dataset (100 spectra), and 70 to 80 percent cross-validation accuracy was
achieved even for very small datasets (50 spectra). Additionally, standard
models were shown to accurately identify characteristic peaks via analysis of
their importance scores. The approach shown here has the potential to be
applied to facilitate accurate detection and analysis of persistent organic
pollutants by surface-enhanced Raman spectroscopy.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00199" title="Abstract">arXiv:2402.00199</a> [<a href="/pdf/2402.00199" title="Download PDF">pdf</a>, <a href="/format/2402.00199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViTacTip: Design and Verification of a Novel Biomimetic Physical  Vision-Tactile Fusion Sensor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+W">Wen Fan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoran Li</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+W">Weiyong Si</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Shan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Lepora%2C+N">Nathan Lepora</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dandan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, 2024 IEEE International Conference on Robotics and Automation (ICRA 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Tactile sensing is significant for robotics since it can obtain physical
contact information during manipulation. To capture multimodal contact
information within a compact framework, we designed a novel sensor called
ViTacTip, which seamlessly integrates both tactile and visual perception
capabilities into a single, integrated sensor unit. ViTacTip features a
transparent skin to capture fine features of objects during contact, which can
be known as the see-through-skin mechanism. In the meantime, the biomimetic
tips embedded in ViTacTip can amplify touch motions during tactile perception.
For comparative analysis, we also fabricated a ViTac sensor devoid of
biomimetic tips, as well as a TacTip sensor with opaque skin. Furthermore, we
develop a Generative Adversarial Network (GAN)-based approach for modality
switching between different perception modes, effectively alternating the
emphasis between vision and tactile perception modes. We conducted a
performance evaluation of the proposed sensor across three distinct tasks: i)
grating identification, ii) pose regression, and iii) contact localization and
force estimation. In the grating identification task, ViTacTip demonstrated an
accuracy of 99.72%, surpassing TacTip, which achieved 94.60%. It also exhibited
superior performance in both pose and force estimation tasks with the minimum
error of 0.08mm and 0.03N, respectively, in contrast to ViTac's 0.12mm and
0.15N. Results indicate that ViTacTip outperforms single-modality sensors.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00201" title="Abstract">arXiv:2402.00201</a> [<a href="/pdf/2402.00201" title="Download PDF">pdf</a>, <a href="/format/2402.00201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Experiment on Feature Selection using Logistic Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+R">Raisa Islam</a>, 
<a href="/search/cs?searchtype=author&query=Mazumdar%2C+S">Subhasish Mazumdar</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+R">Rakibul Islam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In supervised machine learning, feature selection plays a very important role
by potentially enhancing explainability and performance as measured by
computing time and accuracy-related metrics. In this paper, we investigate a
method for feature selection based on the well-known L1 and L2 regularization
strategies associated with logistic regression (LR). It is well known that the
learned coefficients, which serve as weights, can be used to rank the features.
Our approach is to synthesize the findings of L1 and L2 regularization. For our
experiment, we chose the CIC-IDS2018 dataset owing partly to its size and also
to the existence of two problematic classes that are hard to separate. We
report first with the exclusion of one of them and then with its inclusion. We
ranked features first with L1 and then with L2, and then compared logistic
regression with L1 (LR+L1) against that with L2 (LR+L2) by varying the sizes of
the feature sets for each of the two rankings. We found no significant
difference in accuracy between the two methods once the feature set is
selected. We chose a synthesis, i.e., only those features that were present in
both the sets obtained from L1 and that from L2, and experimented with it on
more complex models like Decision Tree and Random Forest and observed that the
accuracy was very close in spite of the small size of the feature set.
Additionally, we also report on the standard metrics: accuracy, precision,
recall, and f1-score.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00203" title="Abstract">arXiv:2402.00203</a> [<a href="/pdf/2402.00203" title="Download PDF">pdf</a>, <a href="/ps/2402.00203" title="Download PostScript">ps</a>, <a href="/format/2402.00203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evidence Tampering and Chain of Custody in Layered Attestations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kretz%2C+I+D">Ian D. Kretz</a>, 
<a href="/search/cs?searchtype=author&query=Parran%2C+C+C">Clare C. Parran</a>, 
<a href="/search/cs?searchtype=author&query=Ramsdell%2C+J+D">John D. Ramsdell</a>, 
<a href="/search/cs?searchtype=author&query=Rowe%2C+P+D">Paul D. Rowe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In distributed systems, trust decisions are made on the basis of integrity
evidence generated via remote attestation. Examples of the kinds of evidence
that might be collected are boot time image hash values; fingerprints of
initialization files for userspace applications; and a comprehensive
measurement of a running kernel. In layered attestations, evidence is typically
composed of measurements of key subcomponents taken from different trust
boundaries within a target system. Discrete measurement evidence is bundled
together for appraisal by the components that collectively perform the
attestation.
<br />In this paper, we initiate the study of evidence chain of custody for remote
attestation. Using the Copland attestation specification language, we formally
define the conditions under which a runtime adversary active on the target
system can tamper with measurement evidence. We present algorithms for
identifying all such tampering opportunities for given evidence as well as
tampering "strategies" by which an adversary can modify incriminating evidence
without being detected. We then define a procedure for transforming a
Copland-specified attestation into a maximally tamper-resistant version of
itself. Our efforts are intended to help attestation protocol designers ensure
their protocols reduce evidence tampering opportunities to the smallest, most
trustworthy set of components possible.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00205" title="Abstract">arXiv:2402.00205</a> [<a href="/pdf/2402.00205" title="Download PDF">pdf</a>, <a href="/format/2402.00205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralised, Collaborative, and Privacy-preserving Machine Learning  for Multi-Hospital Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Congyu Fang</a>, 
<a href="/search/cs?searchtype=author&query=Dziedzic%2C+A">Adam Dziedzic</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Oliva%2C+L">Laura Oliva</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+A">Amol Verma</a>, 
<a href="/search/cs?searchtype=author&query=Razak%2C+F">Fahad Razak</a>, 
<a href="/search/cs?searchtype=author&query=Papernot%2C+N">Nicolas Papernot</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Machine Learning (ML) has demonstrated its great potential on medical data
analysis. Large datasets collected from diverse sources and settings are
essential for ML models in healthcare to achieve better accuracy and
generalizability. Sharing data across different healthcare institutions is
challenging because of complex and varying privacy and regulatory requirements.
Hence, it is hard but crucial to allow multiple parties to collaboratively
train an ML model leveraging the private datasets available at each party
without the need for direct sharing of those datasets or compromising the
privacy of the datasets through collaboration. In this paper, we address this
challenge by proposing Decentralized, Collaborative, and Privacy-preserving ML
for Multi-Hospital Data (DeCaPH). It offers the following key benefits: (1) it
allows different parties to collaboratively train an ML model without
transferring their private datasets; (2) it safeguards patient privacy by
limiting the potential privacy leakage arising from any contents shared across
the parties during the training process; and (3) it facilitates the ML model
training without relying on a centralized server. We demonstrate the
generalizability and power of DeCaPH on three distinct tasks using real-world
distributed medical datasets: patient mortality prediction using electronic
health records, cell-type classification using single-cell human genomes, and
pathology identification using chest radiology images. We demonstrate that the
ML models trained with DeCaPH framework have an improved utility-privacy
trade-off, showing it enables the models to have good performance while
preserving the privacy of the training data points. In addition, the ML models
trained with DeCaPH framework in general outperform those trained solely with
the private datasets from individual parties, showing that DeCaPH enhances the
model generalizability.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00208" title="Abstract">arXiv:2402.00208</a> [<a href="/pdf/2402.00208" title="Download PDF">pdf</a>, <a href="/format/2402.00208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MP-SL: Multihop Parallel Split Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tirana%2C+J">Joana Tirana</a>, 
<a href="/search/cs?searchtype=author&query=Lalis%2C+S">Spyros Lalis</a>, 
<a href="/search/cs?searchtype=author&query=Chatzopoulos%2C+D">Dimitris Chatzopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated Learning (FL) stands out as a widely adopted protocol facilitating
the training of Machine Learning (ML) models while maintaining decentralized
data. However, challenges arise when dealing with a heterogeneous set of
participating devices, causing delays in the training process, particularly
among devices with limited resources. Moreover, the task of training ML models
with a vast number of parameters demands computing and memory resources beyond
the capabilities of small devices, such as mobile and Internet of Things (IoT)
devices. To address these issues, techniques like Parallel Split Learning (SL)
have been introduced, allowing multiple resource-constrained devices to
actively participate in collaborative training processes with assistance from
resourceful compute nodes. Nonetheless, a drawback of Parallel SL is the
substantial memory allocation required at the compute nodes, for instance
training VGG-19 with 100 participants needs 80 GB. In this paper, we introduce
Multihop Parallel SL (MP-SL), a modular and extensible ML as a Service (MLaaS)
framework designed to facilitate the involvement of resource-constrained
devices in collaborative and distributed ML model training. Notably, to
alleviate memory demands per compute node, MP-SL supports multihop Parallel
SL-based training. This involves splitting the model into multiple parts and
utilizing multiple compute nodes in a pipelined manner. Extensive
experimentation validates MP-SL's capability to handle system heterogeneity,
demonstrating that the multihop configuration proves more efficient than
horizontally scaled one-hop Parallel SL setups, especially in scenarios
involving more cost-effective compute nodes.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00209" title="Abstract">arXiv:2402.00209</a> [<a href="/pdf/2402.00209" title="Download PDF">pdf</a>, <a href="/format/2402.00209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling and numerical simulation of fully Eulerian fluid-structure  interaction using cut finite elements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Frei%2C+S">Stefan Frei</a>, 
<a href="/search/math?searchtype=author&query=Knoke%2C+T">Tobias Knoke</a>, 
<a href="/search/math?searchtype=author&query=Steinbach%2C+M+C">Marc C. Steinbach</a>, 
<a href="/search/math?searchtype=author&query=Wenske%2C+A">Anne-Kathrin Wenske</a>, 
<a href="/search/math?searchtype=author&query=Wick%2C+T">Thomas Wick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present a monolithic finite element formulation for (nonlinear)
fluid-structure interaction in Eulerian coordinates. For the discretization we
employ an unfitted finite element method based on inf-sup stable finite
elements. So-called ghost penalty terms are used to guarantee the robustness of
the approach independently of the way the interface cuts the finite element
mesh. The resulting system is solved in a monolithic fashion using Newton's
method. Our developments are tested on a numerical example with fixed
interface.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00218" title="Abstract">arXiv:2402.00218</a> [<a href="/pdf/2402.00218" title="Download PDF">pdf</a>, <a href="/format/2402.00218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Usable-by-Construction: a formal framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reeves%2C+S">Steve Reeves</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Logic in Computer Science (cs.LO); Software Engineering (cs.SE)

</div>
<p class="mathjax">We propose here to look at how abstract a model of a usable system can be,
but still say something useful and interesting, so this paper is an exercise in
abstraction and formalisation, with usability-of-design as an example target
use.
<br />We take the view that when we claim to be designing a usable system we have,
at the very least, to give assurances about its usability properties. This is a
very abstract notion, but provides the basis for future work, and shows, even
at this level that there are things to say about the (very concrete) business
of designing and building usable, interactive systems.
<br />Various forms of verification and validation can provide a high level of
assurance but it can be very costly, and there is clearly a lot of resistance
to doing things this way.
<br />In this paper, we introduce the idea of usable-by-construction, which adopts
and applies the ideas of correct-by-construction to (very abstractly) thinking
about usable systems.
<br />We give a set of construction rules or tactics to develop designs of usable
systems, and we also formalize them into a state suitable for, for example, a
proof assistant to check claims made for the system as designed.
<br />In the future, these tactics would allow us to create systems that have the
required usability properties and thus provide a basis to a
usable-by-construction system. Also, we should then go on to show that the
tactics preserve properties by using an example system with industrial strength
requirements. And we might also consider future research directions.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00219" title="Abstract">arXiv:2402.00219</a> [<a href="/pdf/2402.00219" title="Download PDF">pdf</a>, <a href="/format/2402.00219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedCore: Straggler-Free Federated Learning with Distributed Coresets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hongpeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Haotian Gu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+E+K">Eun Kyung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Eilam%2C+T">Tamar Eilam</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Deming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Nahrstedt%2C+K">Klara Nahrstedt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated learning (FL) is a machine learning paradigm that allows multiple
clients to collaboratively train a shared model while keeping their data
on-premise. However, the straggler issue, due to slow clients, often hinders
the efficiency and scalability of FL. This paper presents FedCore, an algorithm
that innovatively tackles the straggler problem via the decentralized selection
of coresets, representative subsets of a dataset. Contrary to existing
centralized coreset methods, FedCore creates coresets directly on each client
in a distributed manner, ensuring privacy preservation in FL. FedCore
translates the coreset optimization problem into a more tractable k-medoids
clustering problem and operates distributedly on each client. Theoretical
analysis confirms FedCore's convergence, and practical evaluations demonstrate
an 8x reduction in FL training time, without compromising model accuracy. Our
extensive evaluations also show that FedCore generalizes well to existing FL
frameworks.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00220" title="Abstract">arXiv:2402.00220</a> [<a href="/pdf/2402.00220" title="Download PDF">pdf</a>, <a href="/format/2402.00220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Circuit Approach to Constructing Blockchains on Blockchains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tas%2C+E+N">Ertem Nusret Tas</a>, 
<a href="/search/cs?searchtype=author&query=Tse%2C+D">David Tse</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Since the creation of Bitcoin 15 years ago, there has been an explosion in
the number of permissionless blockchains. Each of these blockchains provides an
open ledger that anyone can read from and write to. In this multi-chain world,
an important question emerges: how can we build a more secure overlay
blockchain by reading from and writing to a given set of blockchains? Drawing
an analogy with switching circuits, we approach the problem by defining two
basic compositional operations between blockchains, serial and triangular
compositions, and use these operations as building blocks to construct general
overlay blockchains. Under the partially synchronous setting, we have the
following results: 1) the serial composition, between two blockchains, yields
an overlay blockchain that is safe if at least one of the two underlay
blockchains is safe and that is live if both underlay blockchains are live; 2)
the triangular composition between three blockchains, akin to parallel
composition of switching circuits, yields an overlay blockchain that is safe if
all underlay blockchains are safe and that is live if at least half of them are
live; 3) repeated composition of these two basic operations can yield all
possible tradeoffs of safety and liveness for an overlay blockchain built on
arbitrary number of underlay chains. The results are also extended to the
synchronous setting.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00224" title="Abstract">arXiv:2402.00224</a> [<a href="/pdf/2402.00224" title="Download PDF">pdf</a>, <a href="/format/2402.00224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Based Dynamic Cluster Reconfiguration for UAV Mobility  Management with 3D Beamforming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meer%2C+I+A">Irshad A. Meer</a>, 
<a href="/search/cs?searchtype=author&query=Besser%2C+K">Karl-Ludwig Besser</a>, 
<a href="/search/cs?searchtype=author&query=Ozger%2C+M">Mustafa Ozger</a>, 
<a href="/search/cs?searchtype=author&query=Schupke%2C+D">Dominic Schupke</a>, 
<a href="/search/cs?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>, 
<a href="/search/cs?searchtype=author&query=Cavdar%2C+C">Cicek Cavdar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In modern cell-less wireless networks, mobility management is undergoing a
significant transformation, transitioning from single-link handover management
to a more adaptable multi-connectivity cluster reconfiguration approach,
including often conflicting objectives like energy-efficient power allocation
and satisfying varying reliability requirements. In this work, we address the
challenge of dynamic clustering and power allocation for unmanned aerial
vehicle (UAV) communication in wireless interference networks. Our objective
encompasses meeting varying reliability demands, minimizing power consumption,
and reducing the frequency of cluster reconfiguration. To achieve these
objectives, we introduce a novel approach based on reinforcement learning using
a masked soft actor-critic algorithm, specifically tailored for dynamic
clustering and power allocation.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00225" title="Abstract">arXiv:2402.00225</a> [<a href="/pdf/2402.00225" title="Download PDF">pdf</a>, <a href="/format/2402.00225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometry aware 3D generation from in-the-wild images in ImageNet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Q">Qijia Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guangrun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generating accurate 3D models is a challenging problem that traditionally
requires explicit learning from 3D datasets using supervised learning. Although
recent advances have shown promise in learning 3D models from 2D images, these
methods often rely on well-structured datasets with multi-view images of each
instance or camera pose information. Furthermore, these datasets usually
contain clean backgrounds with simple shapes, making them expensive to acquire
and hard to generalize, which limits the applicability of these methods. To
overcome these limitations, we propose a method for reconstructing 3D geometry
from the diverse and unstructured Imagenet dataset without camera pose
information. We use an efficient triplane representation to learn 3D models
from 2D images and modify the architecture of the generator backbone based on
StyleGAN2 to adapt to the highly diverse dataset. To prevent mode collapse and
improve the training stability on diverse data, we propose to use multi-view
discrimination. The trained generator can produce class-conditional 3D models
as well as renderings from arbitrary viewpoints. The class-conditional
generation results demonstrate significant improvement over the current
state-of-the-art method. Additionally, using PTI, we can efficiently
reconstruct the whole 3D geometry from single-view images.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00232" title="Abstract">arXiv:2402.00232</a> [<a href="/pdf/2402.00232" title="Download PDF">pdf</a>, <a href="/format/2402.00232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Label Hierarchy with Supervised Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lian%2C+R">Ruixue Lian</a>, 
<a href="/search/cs?searchtype=author&query=Sethares%2C+W+A">William A. Sethares</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Junjie Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Supervised contrastive learning (SCL) frameworks treat each class as
independent and thus consider all classes to be equally important. This
neglects the common scenario in which label hierarchy exists, where
fine-grained classes under the same category show more similarity than very
different ones. This paper introduces a family of Label-Aware SCL methods
(LASCL) that incorporates hierarchical information to SCL by leveraging
similarities between classes, resulting in creating a more well-structured and
discriminative feature space. This is achieved by first adjusting the distance
between instances based on measures of the proximity of their classes with the
scaled instance-instance-wise contrastive. An additional instance-center-wise
contrastive is introduced to move within-class examples closer to their
centers, which are represented by a set of learnable label parameters. The
learned label parameters can be directly used as a nearest neighbor classifier
without further finetuning. In this way, a better feature representation is
generated with improvements of intra-cluster compactness and inter-cluster
separation. Experiments on three datasets show that the proposed LASCL works
well on text classification of distinguishing a single label among
multi-labels, outperforming the baseline supervised approaches. Our code is
publicly available.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00233" title="Abstract">arXiv:2402.00233</a> [<a href="/pdf/2402.00233" title="Download PDF">pdf</a>, <a href="/ps/2402.00233" title="Download PostScript">ps</a>, <a href="/format/2402.00233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Architecture for Software Engineering Gamification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pedreira%2C+%C3%93">&#xd3;scar Pedreira</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa%2C+F">F&#xe9;lix Garc&#xed;a</a>, 
<a href="/search/cs?searchtype=author&query=Piattini%2C+M">Mario Piattini</a>, 
<a href="/search/cs?searchtype=author&query=Corti%C3%B1as%2C+A">Alejandro Corti&#xf1;as</a>, 
<a href="/search/cs?searchtype=author&query=Cerdeira-Pena%2C+A">Ana Cerdeira-Pena</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Tsinghua Science and Technology, 25(6):776-797, December 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Gamification has been applied in software engineering to improve quality and
results by increasing people's motivation and engagement. A systematic mapping
has identified research gaps in the field, one of them being the difficulty of
creating an integrated gamified environment comprising all the tools of an
organization, since most existing gamified tools are custom developments or
prototypes. In this paper, we propose a gamification software architecture that
allows us to transform the work environment of a software organization into an
integrated gamified environment, i.e., the organization can maintain its tools,
and the rewards obtained by the users for their actions in different tools will
mount up. We developed a gamification engine based on our proposal, and we
carried out a case study in which we applied it in a real software development
company. The case study shows that the gamification engine has allowed the
company to create a gamified workplace by integrating custom developed tools
and off-the-shelf tools such as Redmine, TestLink, or JUnit, with the
gamification engine. Two main advantages can be highlighted: (i) our solution
allows the organization to maintain its current tools, and (ii) the rewards for
actions in any tool accumulate in a centralized gamified environment.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00234" title="Abstract">arXiv:2402.00234</a> [<a href="/pdf/2402.00234" title="Download PDF">pdf</a>, <a href="/format/2402.00234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Generative AI systems Capable of Supporting Information Needs of  Patients?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajagopal%2C+S">Shreya Rajagopal</a>, 
<a href="/search/cs?searchtype=author&query=Hazarika%2C+S">Subhashis Hazarika</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sookyung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Chiou%2C+Y">Yan-ming Chiou</a>, 
<a href="/search/cs?searchtype=author&query=Sohn%2C+J+H">Jae Ho Sohn</a>, 
<a href="/search/cs?searchtype=author&query=Subramonyam%2C+H">Hari Subramonyam</a>, 
<a href="/search/cs?searchtype=author&query=Mohan%2C+S">Shiwali Mohan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Patients managing a complex illness such as cancer face a complex information
challenge where they not only must learn about their illness but also how to
manage it. Close interaction with healthcare experts (radiologists,
oncologists) can improve patient learning and thereby, their disease outcome.
However, this approach is resource intensive and takes expert time away from
other critical tasks. Given the recent advancements in Generative AI models
aimed at improving the healthcare system, our work investigates whether and how
generative visual question answering systems can responsibly support patient
information needs in the context of radiology imaging data. We conducted a
formative need-finding study in which participants discussed chest computed
tomography (CT) scans and associated radiology reports of a fictitious close
relative with a cardiothoracic radiologist. Using thematic analysis of the
conversation between participants and medical experts, we identified commonly
occurring themes across interactions, including clarifying medical terminology,
locating the problems mentioned in the report in the scanned image,
understanding disease prognosis, discussing the next diagnostic steps, and
comparing treatment options. Based on these themes, we evaluated two
state-of-the-art generative visual language models against the radiologist's
responses. Our results reveal variability in the quality of responses generated
by the models across various themes. We highlight the importance of
patient-facing generative AI systems to accommodate a diverse range of
conversational themes, catering to the real-world informational needs of
patients.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00235" title="Abstract">arXiv:2402.00235</a> [<a href="/pdf/2402.00235" title="Download PDF">pdf</a>, <a href="/format/2402.00235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the limits of decoder-only models trained on public speech  recognition corpora
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Ankit Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Saon%2C+G">George Saon</a>, 
<a href="/search/cs?searchtype=author&query=Kingsbury%2C+B">Brian Kingsbury</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The emergence of industrial-scale speech recognition (ASR) models such as
Whisper and USM, trained on 1M hours of weakly labelled and 12M hours of audio
only proprietary data respectively, has led to a stronger need for large scale
public ASR corpora and competitive open source pipelines. Unlike the said
models, large language models are typically based on Transformer decoders, and
it remains unclear if decoder-only models trained on public data alone can
deliver competitive performance. In this work, we investigate factors such as
choice of training datasets and modeling components necessary for obtaining the
best performance using public English ASR corpora alone. Our Decoder-Only
Transformer for ASR (DOTA) model comprehensively outperforms the
encoder-decoder open source replication of Whisper (OWSM) on nearly all English
ASR benchmarks and outperforms Whisper large-v3 on 7 out of 15 test sets. We
release our codebase and model checkpoints under permissive license.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00236" title="Abstract">arXiv:2402.00236</a> [<a href="/pdf/2402.00236" title="Download PDF">pdf</a>, <a href="/ps/2402.00236" title="Download PostScript">ps</a>, <a href="/format/2402.00236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Positional Encoding Helps Recurrent Neural Networks Handle a Large  Vocabulary
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morita%2C+T">Takashi Morita</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">This study discusses the effects of positional encoding on recurrent neural
networks (RNNs) utilizing synthetic benchmarks. Positional encoding
"time-stamps" data points in time series and complements the capabilities of
Transformer neural networks, which lack an inherent mechanism for representing
the data order. By contrast, RNNs can encode the temporal information of data
points on their own, rendering their use of positional encoding seemingly
"redundant". Nonetheless, empirical investigations reveal the effectiveness of
positional encoding even when coupled with RNNs, specifically for handling a
large vocabulary that yields diverse observations. These findings pave the way
for a new line of research on RNNs, concerning the combination of input-driven
and autonomous time representation. Additionally, biological implications of
the computational/simulational results are discussed, in the light of the
affinity between the sinusoidal implementation of positional encoding and
neural oscillations in biological brains.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00238" title="Abstract">arXiv:2402.00238</a> [<a href="/pdf/2402.00238" title="Download PDF">pdf</a>, <a href="/format/2402.00238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CNN-FL for Biotechnology Industry Empowered by Internet-of-BioNano  Things and Digital Twins
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohammad">Mohammad</a> (Behdad)
<a href="/search/cs?searchtype=author&query=Jamshidi">Jamshidi</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+D+T">Dinh Thai Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+N">Diep N. Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Image and Video Processing (eess.IV); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Digital twins (DTs) are revolutionizing the biotechnology industry by
enabling sophisticated digital representations of biological assets,
microorganisms, drug development processes, and digital health applications.
However, digital twinning at micro and nano scales, particularly in modeling
complex entities like bacteria, presents significant challenges in terms of
requiring advanced Internet of Things (IoT) infrastructure and computing
approaches to achieve enhanced accuracy and scalability. In this work, we
propose a novel framework that integrates the Internet of Bio-Nano Things
(IoBNT) with advanced machine learning techniques, specifically convolutional
neural networks (CNN) and federated learning (FL), to effectively tackle the
identified challenges. Within our framework, IoBNT devices are deployed to
gather image-based biological data across various physical environments,
leveraging the strong capabilities of CNNs for robust machine vision and
pattern recognition. Subsequently, FL is utilized to aggregate insights from
these disparate data sources, creating a refined global model that continually
enhances accuracy and predictive reliability, which is crucial for the
effective deployment of DTs in biotechnology. The primary contribution is the
development of a novel framework that synergistically combines CNN and FL,
augmented by the capabilities of the IoBNT. This novel approach is specifically
tailored to enhancing DTs in the biotechnology industry. The results showcase
enhancements in the reliability and safety of microorganism DTs, while
preserving their accuracy. Furthermore, the proposed framework excels in energy
efficiency and security, offering a user-friendly and adaptable solution. This
broadens its applicability across diverse sectors, including biotechnology and
pharmaceutical industries, as well as clinical and hospital settings.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00240" title="Abstract">arXiv:2402.00240</a> [<a href="/pdf/2402.00240" title="Download PDF">pdf</a>, <a href="/format/2402.00240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral Norm of Convolutional Layers with Circular and Zero Paddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delattre%2C+B">Blaise Delattre</a>, 
<a href="/search/cs?searchtype=author&query=Barth%C3%A9lemy%2C+Q">Quentin Barth&#xe9;lemy</a>, 
<a href="/search/cs?searchtype=author&query=Allauzen%2C+A">Alexandre Allauzen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper leverages the use of \emph{Gram iteration} an efficient,
deterministic, and differentiable method for computing spectral norm with an
upper bound guarantee. Designed for circular convolutional layers, we
generalize the use of the Gram iteration to zero padding convolutional layers
and prove its quadratic convergence. We also provide theorems for bridging the
gap between circular and zero padding convolution's spectral norm. We design a
\emph{spectral rescaling} that can be used as a competitive $1$-Lipschitz layer
that enhances network robustness. Demonstrated through experiments, our method
outperforms state-of-the-art techniques in precision, computational cost, and
scalability. The code of experiments is available at
https://github.com/blaisedelattre/lip4conv.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00243" title="Abstract">arXiv:2402.00243</a> [<a href="/pdf/2402.00243" title="Download PDF">pdf</a>, <a href="/format/2402.00243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Capacity Constraint Analysis Using Object Detection for Smart  Manufacturing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+H+M">Hafiz Mughees Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Rahimi%2C+A">Afshin Rahimi</a>, 
<a href="/search/cs?searchtype=author&query=Hayat%2C+K">Khizer Hayat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The increasing popularity of Deep Learning (DL) based Object Detection (OD)
methods and their real-world applications have opened new venues in smart
manufacturing. Traditional industries struck by capacity constraints after
Coronavirus Disease (COVID-19) require non-invasive methods for in-depth
operations' analysis to optimize and increase their revenue. In this study, we
have initially developed a Convolutional Neural Network (CNN) based OD model to
tackle this issue. This model is trained to accurately identify the presence of
chairs and individuals on the production floor. The identified objects are then
passed to the CNN based tracker, which tracks them throughout their life cycle
in the workstation. The extracted meta-data is further processed through a
novel framework for the capacity constraint analysis. We identified that the
Station C is only 70.6% productive through 6 months. Additionally, the time
spent at each station is recorded and aggregated for each object. This data
proves helpful in conducting annual audits and effectively managing labor and
material over time.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00247" title="Abstract">arXiv:2402.00247</a> [<a href="/pdf/2402.00247" title="Download PDF">pdf</a>, <a href="/format/2402.00247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards AI-Assisted Synthesis of Verified Dafny Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Misu%2C+M+R+H">Md Rakib Hossain Misu</a>, 
<a href="/search/cs?searchtype=author&query=Lopes%2C+C+V">Cristina V. Lopes</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+I">Iris Ma</a>, 
<a href="/search/cs?searchtype=author&query=Noble%2C+J">James Noble</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an author provided preprint. The final version will be published at Proc. ACM Softw. Eng; FSE 2024, in July 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Large stochastic language models show great promise in many domains,
including programming. A promise is easy to make but hard to keep, and language
models often fail to keep their promises when applied to programming,
generating erroneous code. One promising avenue to keep models honest is to
have them generate code in a language that supports formal verification: if and
when that is adopted, the model would provide proof along with the code, and
that proof would be automatically verified. Unfortunately, existing large
language models show a severe lack of proficiency in verified programming
languages. In this paper we demonstrate how to improve two pretrained models'
proficiency in the Dafny verified programming language. Using 178 programming
problems from the MBPP dataset, we prompt two contemporary models (GPT-4 and
PaLM-2) to generate methods in Dafny. We use three different types of prompts:
a direct contextless prompt, a second one that includes a signature of the
method and test cases, and a third one that decomposes the problem into steps
and includes dynamically chosen similar examples. Our results show that GPT-4
is better than PaLM-2, but that, in both models, the third prompt greatly
improves the success of the generation task for the direct prompt. With the
third prompt, GPT-4 was able to generate verified (and human-evaluated) Dafny
methods in 58% of the cases, while the first prompt generated verified (and
human-evaluated) methods in only 19% of the cases. Surprisingly, the second
prompt had the worst performance, with only 10%. One tangible contribution of
our work is a collection of 153 MBPP problems that are implemented and formally
verified in Dafny, 50 of which were written by us and 103 were automatically
synthesized by GPT-4. Additionally, our results demonstrate that the benefits
of formal program verification (proof of correctness) are now within reach...
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00250" title="Abstract">arXiv:2402.00250</a> [<a href="/pdf/2402.00250" title="Download PDF">pdf</a>, <a href="/format/2402.00250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LRDif: Diffusion Models for Under-Display Camera Emotion Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhifeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sankaranarayana%2C+R">Ramesh Sankaranarayana</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This study introduces LRDif, a novel diffusion-based framework designed
specifically for facial expression recognition (FER) within the context of
under-display cameras (UDC). To address the inherent challenges posed by UDC's
image degradation, such as reduced sharpness and increased noise, LRDif employs
a two-stage training strategy that integrates a condensed preliminary
extraction network (FPEN) and an agile transformer network (UDCformer) to
effectively identify emotion labels from UDC images. By harnessing the robust
distribution mapping capabilities of Diffusion Models (DMs) and the spatial
dependency modeling strength of transformers, LRDif effectively overcomes the
obstacles of noise and distortion inherent in UDC environments. Comprehensive
experiments on standard FER datasets including RAF-DB, KDEF, and FERPlus, LRDif
demonstrate state-of-the-art performance, underscoring its potential in
advancing FER applications. This work not only addresses a significant gap in
the literature by tackling the UDC challenge in FER but also sets a new
benchmark for future research in the field.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00251" title="Abstract">arXiv:2402.00251</a> [<a href="/pdf/2402.00251" title="Download PDF">pdf</a>, <a href="/format/2402.00251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Non-Parametric Uncertainty Quantification for Black-Box Large  Language Models and Decision Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y+H">Yao-Hung Hubert Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Talbott%2C+W">Walter Talbott</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Step-by-step decision planning with large language models (LLMs) is gaining
attention in AI agent development. This paper focuses on decision planning with
uncertainty estimation to address the hallucination problem in language models.
Existing approaches are either white-box or computationally demanding, limiting
use of black-box proprietary LLMs within budgets. The paper's first
contribution is a non-parametric uncertainty quantification method for LLMs,
efficiently estimating point-wise dependencies between input-decision on the
fly with a single inference, without access to token logits. This estimator
informs the statistical interpretation of decision trustworthiness. The second
contribution outlines a systematic design for a decision-making agent,
generating actions like ``turn on the bathroom light'' based on user prompts
such as ``take a bath''. Users will be asked to provide preferences when more
than one action has high estimated point-wise dependencies. In conclusion, our
uncertainty estimation and decision-making agent design offer a cost-efficient
approach for AI agent development.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00253" title="Abstract">arXiv:2402.00253</a> [<a href="/pdf/2402.00253" title="Download PDF">pdf</a>, <a href="/format/2402.00253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Hallucination in Large Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hanchao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+W">Wenyuan Xue</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yifei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dapeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiutian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Ke Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Liping Hou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rongjun Li</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wei Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent development of Large Vision-Language Models (LVLMs) has attracted
growing attention within the AI landscape for its practical implementation
potential. However, ``hallucination'', or more specifically, the misalignment
between factual visual content and corresponding textual generation, poses a
significant challenge of utilizing LVLMs. In this comprehensive survey, we
dissect LVLM-related hallucinations in an attempt to establish an overview and
facilitate future mitigation. Our scrutiny starts with a clarification of the
concept of hallucinations in LVLMs, presenting a variety of hallucination
symptoms and highlighting the unique challenges inherent in LVLM
hallucinations. Subsequently, we outline the benchmarks and methodologies
tailored specifically for evaluating hallucinations unique to LVLMs.
Additionally, we delve into an investigation of the root causes of these
hallucinations, encompassing insights from the training data and model
components. We also critically review existing methods for mitigating
hallucinations. The open questions and future directions pertaining to
hallucinations within LVLMs are discussed to conclude this survey.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00254" title="Abstract">arXiv:2402.00254</a> [<a href="/pdf/2402.00254" title="Download PDF">pdf</a>, <a href="/format/2402.00254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vertical Symbolic Regression via Deep Policy Gradient
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+N">Nan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Nasim%2C+M">Md Nasim</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Y">Yexiang Xue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> see animated demo at: vsr-dpg.github.io
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Vertical Symbolic Regression (VSR) recently has been proposed to expedite the
discovery of symbolic equations with many independent variables from
experimental data. VSR reduces the search spaces following the vertical
discovery path by building from reduced-form equations involving a subset of
independent variables to full-fledged ones. Proved successful by many symbolic
regressors, deep neural networks are expected to further scale up VSR.
Nevertheless, directly combining VSR with deep neural networks will result in
difficulty in passing gradients and other engineering issues. We propose
Vertical Symbolic Regression using Deep Policy Gradient (VSR-DPG) and
demonstrate that VSR-DPG can recover ground-truth equations involving multiple
input variables, significantly beyond both deep reinforcement learning-based
approaches and previous VSR variants. Our VSR-DPG models symbolic regression as
a sequential decision-making process, in which equations are built from
repeated applications of grammar rules. The integrated deep model is trained to
maximize a policy gradient objective. Experimental results demonstrate that our
VSR-DPG significantly outperforms popular baselines in identifying both
algebraic equations and ordinary differential equations on a series of
benchmarks.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00258" title="Abstract">arXiv:2402.00258</a> [<a href="/pdf/2402.00258" title="Download PDF">pdf</a>, <a href="/format/2402.00258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-group Learning for Hierarchical Groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Samuel Deng</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+D">Daniel Hsu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The multi-group learning model formalizes the learning scenario in which a
single predictor must generalize well on multiple, possibly overlapping
subgroups of interest. We extend the study of multi-group learning to the
natural case where the groups are hierarchically structured. We design an
algorithm for this setting that outputs an interpretable and deterministic
decision tree predictor with near-optimal sample complexity. We then conduct an
empirical evaluation of our algorithm and find that it achieves attractive
generalization properties on real datasets with hierarchical group structure.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00260" title="Abstract">arXiv:2402.00260</a> [<a href="/pdf/2402.00260" title="Download PDF">pdf</a>, <a href="/ps/2402.00260" title="Download PostScript">ps</a>, <a href="/format/2402.00260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards scalable robotic intervention of children with Autism Spectrum  Disorder using LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+R">Ruchik Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Welch%2C+K+C">Karla Conn Welch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we propose a social robot capable of verbally interacting with
children with Autism Spectrum Disorder (ASD). This communication is meant to
teach perspective-taking using text generated using a Large Language Model
(LLM) pipeline. The social robot NAO acts as a stimulator (verbally describes a
social situation and asks a question), prompter (presents three options to
choose from), and reinforcer (praises when the answer is correct). For the role
of the stimulator, the social situation, questions, and options are generated
using our LLM pipeline. We compare two approaches: GPT-2 + BART and GPT-2 +
GPT-2, where the first GPT-2 common between the pipelines is used for
unsupervised social situation generation. We use the SOCIALIQA dataset to
fine-tune all of our LLM pipelines. We found that the GPT-2 + BART pipeline had
a better BERTscore for generating the questions and the options by combining
their individual loss functions. This observation was also consistent with the
human evaluations. Lastly, the unsupervised generation of social situations was
visualized using T-SNE plots, and the entire pipeline was evaluated for
appropriateness for children with ASD by human experts.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00261" title="Abstract">arXiv:2402.00261</a> [<a href="/pdf/2402.00261" title="Download PDF">pdf</a>, <a href="/format/2402.00261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Neural Network Systems for Image Analysis using Vector  Spaces and Inverse Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pattichis%2C+R">Rebecca Pattichis</a>, 
<a href="/search/cs?searchtype=author&query=Pattichis%2C+M+S">Marios S. Pattichis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">There is strong interest in developing mathematical methods that can be used
to understand complex neural networks used in image analysis. In this paper, we
introduce techniques from Linear Algebra to model neural network layers as maps
between signal spaces. First, we demonstrate how signal spaces can be used to
visualize weight spaces and convolutional layer kernels. We also demonstrate
how residual vector spaces can be used to further visualize information lost at
each layer. Second, we introduce the concept of invertible networks and an
algorithm for computing input images that yield specific outputs. We
demonstrate our approach on two invertible networks and ResNet18.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00262" title="Abstract">arXiv:2402.00262</a> [<a href="/pdf/2402.00262" title="Download PDF">pdf</a>, <a href="/ps/2402.00262" title="Download PostScript">ps</a>, <a href="/format/2402.00262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational Experiments Meet Large Language Model Based Agents: A  Survey and Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+X">Xiao Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Deyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiangning Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Donghua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zihan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yifan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+P">Peilin Ji</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juanjuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wanpeng Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Computational experiments have emerged as a valuable method for studying
complex systems, involving the algorithmization of counterfactuals. However,
accurately representing real social systems in Agent-based Modeling (ABM) is
challenging due to the diverse and intricate characteristics of humans,
including bounded rationality and heterogeneity. To address this limitation,
the integration of Large Language Models (LLMs) has been proposed, enabling
agents to possess anthropomorphic abilities such as complex reasoning and
autonomous learning. These agents, known as LLM-based Agent, offer the
potential to enhance the anthropomorphism lacking in ABM. Nonetheless, the
absence of explicit explainability in LLMs significantly hinders their
application in the social sciences. Conversely, computational experiments excel
in providing causal analysis of individual behaviors and complex phenomena.
Thus, combining computational experiments with LLM-based Agent holds
substantial research potential. This paper aims to present a comprehensive
exploration of this fusion. Primarily, it outlines the historical development
of agent structures and their evolution into artificial societies, emphasizing
their importance in computational experiments. Then it elucidates the
advantages that computational experiments and LLM-based Agents offer each
other, considering the perspectives of LLM-based Agent for computational
experiments and vice versa. Finally, this paper addresses the challenges and
future trends in this research domain, offering guidance for subsequent related
studies.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00263" title="Abstract">arXiv:2402.00263</a> [<a href="/pdf/2402.00263" title="Download PDF">pdf</a>, <a href="/format/2402.00263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does \textsc{DetectGPT} Fully Utilize Perturbation? Selective  Perturbation on Model-Based Contrastive Learning Detector would be Better
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shengchao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yichen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zehua Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengzhengxu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaohan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yu Lan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chao Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The burgeoning capabilities of large language models (LLMs) have raised
growing concerns about abuse. DetectGPT, a zero-shot metric-based unsupervised
machine-generated text detector, first introduces perturbation and shows great
performance improvement. However, DetectGPT's random perturbation strategy
might introduce noise, limiting the distinguishability and further performance
improvements. Moreover, its logit regression module relies on setting the
threshold, which harms the generalizability and applicability of individual or
small-batch inputs. Hence, we propose a novel detector, \modelname{}, which
uses selective strategy perturbation to relieve the important information loss
caused by random masking, and multi-pair contrastive learning to capture the
implicit pattern information during perturbation, facilitating few-shot
performance. The experiments show that \modelname{} outperforms the SOTA method
by 1.20\% in accuracy on average on four public datasets. We further analyze
the effectiveness, robustness, and generalization of our perturbation method.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00267" title="Abstract">arXiv:2402.00267</a> [<a href="/pdf/2402.00267" title="Download PDF">pdf</a>, <a href="/ps/2402.00267" title="Download PostScript">ps</a>, <a href="/format/2402.00267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Not All Learnable Distribution Classes are Privately Learnable
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bun%2C+M">Mark Bun</a>, 
<a href="/search/cs?searchtype=author&query=Kamath%2C+G">Gautam Kamath</a>, 
<a href="/search/cs?searchtype=author&query=Mouzakis%2C+A">Argyris Mouzakis</a>, 
<a href="/search/cs?searchtype=author&query=Singhal%2C+V">Vikrant Singhal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in ALT 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Cryptography and Security (cs.CR); Machine Learning (stat.ML)

</div>
<p class="mathjax">We give an example of a class of distributions that is learnable in total
variation distance with a finite number of samples, but not learnable under
$(\varepsilon, \delta)$-differential privacy. This refutes a conjecture of
Ashtiani.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00271" title="Abstract">arXiv:2402.00271</a> [<a href="/pdf/2402.00271" title="Download PDF">pdf</a>, <a href="/format/2402.00271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Crucial Parameter for Rank-Frequency Relation in Natural Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Chenchen Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">$f \propto r^{-\alpha} \cdot (r+\gamma)^{-\beta}$ has been empirically shown
more precise than a na\"ive power law $f\propto r^{-\alpha}$ to model the
rank-frequency ($r$-$f$) relation of words in natural languages. This work
shows that the only crucial parameter in the formulation is $\gamma$, which
depicts the resistance to vocabulary growth on a corpus. A method of parameter
estimation by searching an optimal $\gamma$ is proposed, where a ``zeroth
word'' is introduced technically for the calculation. The formulation and
parameters are further discussed with several case studies.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00275" title="Abstract">arXiv:2402.00275</a> [<a href="/pdf/2402.00275" title="Download PDF">pdf</a>, <a href="/ps/2402.00275" title="Download PostScript">ps</a>, <a href="/format/2402.00275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Maude strategy language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eker%2C+S">Steven Eker</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%AD-Oliet%2C+N">Narciso Mart&#xed;-Oliet</a>, 
<a href="/search/cs?searchtype=author&query=Meseguer%2C+J">Jos&#xe9; Meseguer</a>, 
<a href="/search/cs?searchtype=author&query=Rubio%2C+R">Rub&#xe9;n Rubio</a>, 
<a href="/search/cs?searchtype=author&query=Verdejo%2C+A">Alberto Verdejo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J. Logic. Algebr. Program 134 (2023) article 100887
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Rewriting logic is a natural and expressive framework for the specification
of concurrent systems and logics. The Maude specification language provides an
implementation of this formalism that allows executing, verifying, and
analyzing the represented systems. These specifications declare their objects
by means of terms and equations, and provide rewriting rules to represent
potentially non-deterministic local transformations on the state. Sometimes a
controlled application of these rules is required to reduce non-determinism, to
capture global, goal-oriented or efficiency concerns, or to select specific
executions for their analysis. That is what we call a strategy. In order to
express them, respecting the separation of concerns principle, a Maude strategy
language was proposed and developed. The first implementation of the strategy
language was done in Maude itself using its reflective features. After ample
experimentation, some more features have been added and, for greater
efficiency, the strategy language has been implemented in C++ as an integral
part of the Maude system.
<br />This paper describes the Maude strategy language along with its semantics,
its implementation decisions, and several application examples from various
fields.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00276" title="Abstract">arXiv:2402.00276</a> [<a href="/pdf/2402.00276" title="Download PDF">pdf</a>, <a href="/format/2402.00276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Program Debloating with 1-DU Chain Minimality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Myeongsoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Pande%2C+S">Santosh Pande</a>, 
<a href="/search/cs?searchtype=author&query=Orso%2C+A">Alessandro Orso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the 46th IEEE/ACM International Conference on Software Engineering: Companion Proceedings(ICSE-Companion 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Modern software often struggles with bloat, leading to increased memory
consumption and security vulnerabilities from unused code. In response, various
program debloating techniques have been developed, typically utilizing test
cases that represent functionalities users want to retain. These methods range
from aggressive approaches, which prioritize maximal code reduction but may
overfit to test cases and potentially reintroduce past security issues, to
conservative strategies that aim to preserve all influenced code, often at the
expense of less effective bloat reduction and security improvement. In this
research, we present RLDebloatDU, an innovative debloating technique that
employs 1-DU chain minimality within abstract syntax trees. Our approach
maintains essential program data dependencies, striking a balance between
aggressive code reduction and the preservation of program semantics. We
evaluated RLDebloatDU on ten Linux kernel programs, comparing its performance
with two leading debloating techniques: Chisel, known for its aggressive
debloating approach, and Razor, recognized for its conservative strategy.
RLDebloatDU significantly lowers the incidence of Common Vulnerabilities and
Exposures (CVEs) and improves soundness compared to both, highlighting its
efficacy in reducing security issues without reintroducing resolved security
issues.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00279" title="Abstract">arXiv:2402.00279</a> [<a href="/pdf/2402.00279" title="Download PDF">pdf</a>, <a href="/format/2402.00279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rapid Integrator for a Class of Multi-Contact Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anderson%2C+M">Marion Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Revzen%2C+S">Shai Revzen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Many problems in robotics involve creating or breaking multiple contacts
nearly simultaneously or in an indeterminate order. We present a novel general
purpose numerical integrator based on the theory of Event Selected Systems
(ESS). Many multicontact models are ESS, which has recently been shown to imply
that despite a discontinuous vector field, the flow of these systems is
continuous, piecewise smooth, and has a well defined orbital derivative for all
trajectories, which can be rapidly computed. We provide an elementary proof
that our integrator is first-order accurate and verify numerically that it is
in fact second-order accurate as its construction anticipated. We also compare
our integrator, implemented in NumPy, to a MuJoCo simulation on models with 2
to 100 contacts, and confirm that the increase in simulation time per contact
is nearly identical. The results suggest that this novel integrator can be
invaluable for modelling and control in many robotics applications.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00281" title="Abstract">arXiv:2402.00281</a> [<a href="/pdf/2402.00281" title="Download PDF">pdf</a>, <a href="/format/2402.00281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guided Interpretable Facial Expression Recognition via Spatial Action  Unit Cues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belharbi%2C+S">Soufiane Belharbi</a>, 
<a href="/search/cs?searchtype=author&query=Pedersoli%2C+M">Marco Pedersoli</a>, 
<a href="/search/cs?searchtype=author&query=Koerich%2C+A+L">Alessandro Lameiras Koerich</a>, 
<a href="/search/cs?searchtype=author&query=Bacon%2C+S">Simon Bacon</a>, 
<a href="/search/cs?searchtype=author&query=Granger%2C+E">Eric Granger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While state-of-the-art facial expression recognition (FER) classifiers
achieve a high level of accuracy, they lack interpretability, an important
aspect for end-users. To recognize basic facial expressions, experts resort to
a codebook associating a set of spatial action units to a facial expression. In
this paper, we follow the same expert footsteps, and propose a learning
strategy that allows us to explicitly incorporate spatial action units (aus)
cues into the classifier's training to build a deep interpretable model. In
particular, using this aus codebook, input image expression label, and facial
landmarks, a single action units heatmap is built to indicate the most
discriminative regions of interest in the image w.r.t the facial expression. We
leverage this valuable spatial cue to train a deep interpretable classifier for
FER. This is achieved by constraining the spatial layer features of a
classifier to be correlated with \aus map. Using a composite loss, the
classifier is trained to correctly classify an image while yielding
interpretable visual layer-wise attention correlated with aus maps, simulating
the experts' decision process. This is achieved using only the image class
expression as supervision and without any extra manual annotations. Moreover,
our method is generic. It can be applied to any CNN- or transformer-based deep
classifier without the need for architectural change or adding significant
training time. Our extensive evaluation on two public benchmarks RAFDB, and
AFFECTNET datasets shows that our proposed strategy can improve layer-wise
interpretability without degrading classification performance. In addition, we
explore a common type of interpretable classifiers that rely on
Class-Activation Mapping methods (CAMs), and we show that our training
technique improves the CAM interpretability.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00284" title="Abstract">arXiv:2402.00284</a> [<a href="/pdf/2402.00284" title="Download PDF">pdf</a>, <a href="/format/2402.00284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PAP-REC: Personalized Automatic Prompt for Recommendation Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zelong Li</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Jianchao Ji</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yingqiang Ge</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+W">Wenyue Hua</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongfeng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently emerged prompt-based Recommendation Language Models (RLM) can solve
multiple recommendation tasks uniformly. The RLMs make full use of the
inherited knowledge learned from the abundant pre-training data to solve the
downstream recommendation tasks by prompts, without introducing additional
parameters or network training. However, handcrafted prompts require
significant expertise and human effort since slightly rewriting prompts may
cause massive performance changes. In this paper, we propose PAP-REC, a
framework to generate the Personalized Automatic Prompt for RECommendation
language models to mitigate the inefficiency and ineffectiveness problems
derived from manually designed prompts. Specifically, personalized automatic
prompts allow different users to have different prompt tokens for the same
task, automatically generated using a gradient-based method. One challenge for
personalized automatic prompt generation for recommendation language models is
the extremely large search space, leading to a long convergence time. To
effectively and efficiently address the problem, we develop surrogate metrics
and leverage an alternative updating schedule for prompting recommendation
language models. Experimental results show that our PAP-REC framework manages
to generate personalized prompts, and the automatically generated prompts
outperform manually constructed prompts and also outperform various baseline
recommendation models. The source code of the work is available at
https://github.com/rutgerswiselab/PAP-REC.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00290" title="Abstract">arXiv:2402.00290</a> [<a href="/pdf/2402.00290" title="Download PDF">pdf</a>, <a href="/format/2402.00290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Embodied Interactive Agent for Cafe Scene
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xinshuai Song</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+K">Kaixuan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weixing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jingzhou Luo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the surge in the development of large language models, embodied
intelligence has attracted increasing attention. Nevertheless, prior works on
embodied intelligence typically encode scene or historical memory in an
unimodal manner, either visual or linguistic, which complicates the alignment
of the model's action planning with embodied control. To overcome this
limitation, we introduce the Multimodal Embodied Interactive Agent (MEIA),
capable of translating high-level tasks expressed in natural language into a
sequence of executable actions. Specifically, we propose a novel Multimodal
Environment Memory (MEM) module, facilitating the integration of embodied
control with large models through the visual-language memory of scenes. This
capability enables MEIA to generate executable action plans based on diverse
requirements and the robot's capabilities. We conduct experiments in a dynamic
virtual cafe environment, utilizing multiple large models through zero-shot
learning, and carefully design scenarios for various situations. The
experimental results showcase the promising performance of our MEIA in various
embodied interactive tasks.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00292" title="Abstract">arXiv:2402.00292</a> [<a href="/pdf/2402.00292" title="Download PDF">pdf</a>, <a href="/format/2402.00292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective Bug Detection in Graph Database Engines: An LLM-based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiayi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhengyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ronghua Li</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Hongchao Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoren Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Graph database engines play a pivotal role in efficiently storing and
managing graph data across various domains, including bioinformatics, knowledge
graphs, and recommender systems. Ensuring data accuracy within graph database
engines is paramount, as inaccuracies can yield unreliable analytical outcomes.
Current bug-detection approaches are confined to specific graph query
languages, limiting their applicabilities when handling graph database engines
that use various graph query languages across various domains. Moreover, they
require extensive prior knowledge to generate queries for detecting bugs. To
address these challenges, we introduces DGDB, a novel paradigm harnessing large
language models(LLM), such as ChatGPT, for comprehensive bug detection in graph
database engines. DGDB leverages ChatGPT to generate high-quality queries for
different graph query languages. It subsequently employs differential testing
to identify bugs in graph database engines. We applied this paradigm to graph
database engines using the Gremlin query language and those using the Cypher
query language, generating approximately 4,000 queries each. In the latest
versions of Neo4j, Agensgraph, and JanusGraph databases, we detected 2, 5, and
3 wrong-result bugs, respectively.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00293" title="Abstract">arXiv:2402.00293</a> [<a href="/pdf/2402.00293" title="Download PDF">pdf</a>, <a href="/format/2402.00293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FineBio: A Fine-Grained Video Dataset of Biological Experiments with  Hierarchical Annotation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yagi%2C+T">Takuma Yagi</a>, 
<a href="/search/cs?searchtype=author&query=Ohashi%2C+M">Misaki Ohashi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yifei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Furuta%2C+R">Ryosuke Furuta</a>, 
<a href="/search/cs?searchtype=author&query=Adachi%2C+S">Shungo Adachi</a>, 
<a href="/search/cs?searchtype=author&query=Mitsuyama%2C+T">Toutai Mitsuyama</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+Y">Yoichi Sato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the development of science, accurate and reproducible documentation of the
experimental process is crucial. Automatic recognition of the actions in
experiments from videos would help experimenters by complementing the recording
of experiments. Towards this goal, we propose FineBio, a new fine-grained video
dataset of people performing biological experiments. The dataset consists of
multi-view videos of 32 participants performing mock biological experiments
with a total duration of 14.5 hours. One experiment forms a hierarchical
structure, where a protocol consists of several steps, each further decomposed
into a set of atomic operations. The uniqueness of biological experiments is
that while they require strict adherence to steps described in each protocol,
there is freedom in the order of atomic operations. We provide hierarchical
annotation on protocols, steps, atomic operations, object locations, and their
manipulation states, providing new challenges for structured activity
understanding and hand-object interaction recognition. To find out challenges
on activity understanding in biological experiments, we introduce baseline
models and results on four different tasks, including (i) step segmentation,
(ii) atomic operation detection (iii) object detection, and (iv)
manipulated/affected object detection. Dataset and code are available from
https://github.com/aistairc/FineBio.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00295" title="Abstract">arXiv:2402.00295</a> [<a href="/pdf/2402.00295" title="Download PDF">pdf</a>, <a href="/ps/2402.00295" title="Download PostScript">ps</a>, <a href="/format/2402.00295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Evaluation of Traditional and Deep Learning-Based  Segmentation Methods for Spoil Pile Delineation Using UAV Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thiruchittampalam%2C+S">Sureka Thiruchittampalam</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+B+P">Bikram P. Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Glenn%2C+N+F">Nancy F. Glenn</a>, 
<a href="/search/cs?searchtype=author&query=Raval%2C+S">Simit Raval</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Applications (stat.AP)

</div>
<p class="mathjax">The stability of mine dumps is contingent upon the precise arrangement of
spoil piles, taking into account their geological and geotechnical attributes.
Yet, on-site characterisation of individual piles poses a formidable challenge.
The utilisation of image-based techniques for spoil pile characterisation,
employing remotely acquired data through unmanned aerial systems, is a
promising complementary solution. Image processing, such as object-based
classification and feature extraction, are dependent upon effective
segmentation. This study refines and juxtaposes various segmentation
approaches, specifically colour-based and morphology-based techniques. The
objective is to enhance and evaluate avenues for object-based analysis for
spoil characterisation within the context of mining environments. Furthermore,
a comparative analysis is conducted between conventional segmentation
approaches and those rooted in deep learning methodologies. Among the diverse
segmentation approaches evaluated, the morphology-based deep learning
segmentation approach, Segment Anything Model (SAM), exhibited superior
performance in comparison to other approaches. This outcome underscores the
efficacy of incorporating advanced morphological and deep learning techniques
for accurate and efficient spoil pile characterisation. The findings of this
study contribute valuable insights to the optimisation of segmentation
strategies, thereby advancing the application of image-based techniques for the
characterisation of spoil piles in mining environments.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00296" title="Abstract">arXiv:2402.00296</a> [<a href="/pdf/2402.00296" title="Download PDF">pdf</a>, <a href="/format/2402.00296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Level, Collaborative Task Planning Grammar and Execution for  Heterogeneous Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+A">Amy Fang</a>, 
<a href="/search/cs?searchtype=author&query=Kress-Gazit%2C+H">Hadas Kress-Gazit</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the Proceedings of the 2024 International Conference on Autonomous Agents and Multiagent Systems (AAMAS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We propose a new multi-agent task grammar to encode collaborative tasks for a
team of heterogeneous agents that can have overlapping capabilities. The
grammar allows users to specify the relationship between agents and parts of
the task without providing explicit assignments or constraints on the number of
agents required. We develop a method to automatically find a team of agents and
synthesize correct-by-construction control with synchronization policies to
satisfy the task. We demonstrate the scalability of our approach through
simulation and compare our method to existing task grammars that encode
multi-agent tasks.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00300" title="Abstract">arXiv:2402.00300</a> [<a href="/pdf/2402.00300" title="Download PDF">pdf</a>, <a href="/format/2402.00300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised learning of video representations from a child&#x27;s  perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Orhan%2C+A+E">A. Emin Orhan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wentao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A+N">Alex N. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+M">Mengye Ren</a>, 
<a href="/search/cs?searchtype=author&query=Lake%2C+B+M">Brenden M. Lake</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures; code &amp; models available from <a href="https://github.com/eminorhan/video-models">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Children learn powerful internal models of the world around them from a few
years of egocentric visual experience. Can such internal models be learned from
a child's visual experience with highly generic learning algorithms or do they
require strong inductive biases? Recent advances in collecting large-scale,
longitudinal, developmentally realistic video datasets and generic
self-supervised learning (SSL) algorithms are allowing us to begin to tackle
this nature vs. nurture question. However, existing work typically focuses on
image-based SSL algorithms and visual capabilities that can be learned from
static images (e.g. object recognition), thus ignoring temporal aspects of the
world. To close this gap, here we train self-supervised video models on
longitudinal, egocentric headcam recordings collected from a child over a two
year period in their early development (6-31 months). The resulting models are
highly effective at facilitating the learning of action concepts from a small
number of labeled examples; they have favorable data size scaling properties;
and they display emergent video interpolation capabilities. Video models also
learn more robust object representations than image-based models trained with
the exact same data. These results suggest that important temporal aspects of a
child's internal model of the world may be learnable from their visual
experience using highly generic learning algorithms and without strong
inductive biases.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00304" title="Abstract">arXiv:2402.00304</a> [<a href="/pdf/2402.00304" title="Download PDF">pdf</a>, <a href="/format/2402.00304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariance-powered Trustworthy Defense via Remove Then Restore
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xiaowei Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuhang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lina Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Adversarial attacks pose a challenge to the deployment of deep neural
networks (DNNs), while previous defense models overlook the generalization to
various attacks. Inspired by targeted therapies for cancer, we view adversarial
samples as local lesions of natural benign samples, because a key finding is
that salient attack in an adversarial sample dominates the attacking process,
while trivial attack unexpectedly provides trustworthy evidence for obtaining
generalizable robustness. Based on this finding, a Pixel Surgery and Semantic
Regeneration (PSSR) model following the targeted therapy mechanism is
developed, which has three merits: 1) To remove the salient attack, a
score-based Pixel Surgery module is proposed, which retains the trivial attack
as a kind of invariance information. 2) To restore the discriminative content,
a Semantic Regeneration module based on a conditional alignment extrapolator is
proposed, which achieves pixel and semantic consistency. 3) To further
harmonize robustness and accuracy, an intractable problem, a self-augmentation
regularizer with adversarial R-drop is designed. Experiments on numerous
benchmarks show the superiority of PSSR.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00306" title="Abstract">arXiv:2402.00306</a> [<a href="/pdf/2402.00306" title="Download PDF">pdf</a>, <a href="/format/2402.00306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Accurate and Low-Parameter Machine Learning Architecture for Next  Location Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jary%2C+C">Calvin Jary</a>, 
<a href="/search/cs?searchtype=author&query=Kahani%2C+N">Nafiseh Kahani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 page conference paper. Paper was accepted and presented in person at the 2023 IEEE Future Networks World Forum, in Baltimore, Maryland, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Next location prediction is a discipline that involves predicting a users
next location. Its applications include resource allocation, quality of
service, energy efficiency, and traffic management. This paper proposes an
energy-efficient, small, and low parameter machine learning (ML) architecture
for accurate next location prediction, deployable on modest base stations and
edge devices. To accomplish this we ran a hundred hyperparameter experiments on
the full human mobility patterns of an entire city, to determine an exact ML
architecture that reached a plateau of accuracy with the least amount of model
parameters. We successfully achieved a reduction in the number of model
parameters within published ML architectures from 202 million down to 2
million. This reduced the total size of the model parameters from 791 MB down
to 8 MB. Additionally, this decreased the training time by a factor of four,
the amount of graphics processing unit (GPU) memory needed for training by a
factor of twenty, and the overall accuracy was increased from 80.16% to 82.54%.
This improvement allows for modest base stations and edge devices which do not
have a large amount of memory or storage, to deploy and utilize the proposed ML
architecture for next location prediction.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00309" title="Abstract">arXiv:2402.00309</a> [<a href="/pdf/2402.00309" title="Download PDF">pdf</a>, <a href="/format/2402.00309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Exam-based Evaluation Approach Beyond Traditional Relevance Judgments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farzi%2C+N">Naghmeh Farzi</a>, 
<a href="/search/cs?searchtype=author&query=Dietz%2C+L">Laura Dietz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Current IR evaluation is based on relevance judgments, created either
manually or automatically, with decisions outsourced to Large Language Models
(LLMs). We offer an alternative paradigm, that never relies on relevance
judgments in any form. Instead, a text is defined as relevant if it contains
information that enables the answering of key questions. We use this idea to
design the EXAM Answerability Metric to evaluate information
retrieval/generation systems for their ability to provide topically relevant
information.
<br />We envision the role of a human judge to edit and define an exam question
bank that will test for the presence of relevant information in text. We
support this step by generating an initial set of exam questions. In the next
phase, an LLM-based question answering system will automatically grade system
responses by tracking which exam questions are answerable with which system
responses. We propose two evaluation measures, the recall-oriented EXAM Cover
metric, and the precision-oriented EXAM Qrels metric, the latter which can be
implemented with trec_eval. This paradigm not only allows for the expansion of
the exam question set post-hoc but also facilitates the ongoing evaluation of
future information systems, whether they focus on retrieval, generation, or
both.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00313" title="Abstract">arXiv:2402.00313</a> [<a href="/pdf/2402.00313" title="Download PDF">pdf</a>, <a href="/format/2402.00313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control in Stochastic Environment with Delays: A Model-based  Reinforcement Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zhiyuan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Florescu%2C+I">Ionut Florescu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chihoon Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In this paper we are introducing a new reinforcement learning method for
control problems in environments with delayed feedback. Specifically, our
method employs stochastic planning, versus previous methods that used
deterministic planning. This allows us to embed risk preference in the policy
optimization problem. We show that this formulation can recover the optimal
policy for problems with deterministic transitions. We contrast our policy with
two prior methods from literature. We apply the methodology to simple tasks to
understand its features. Then, we compare the performance of the methods in
controlling multiple Atari games.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00315" title="Abstract">arXiv:2402.00315</a> [<a href="/pdf/2402.00315" title="Download PDF">pdf</a>, <a href="/ps/2402.00315" title="Download PostScript">ps</a>, <a href="/format/2402.00315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Distribution Learning with Local Private Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sima%2C+J">Jin Sima</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Changlong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Milenkovic%2C+O">Olgica Milenkovic</a>, 
<a href="/search/cs?searchtype=author&query=Szpankowski%2C+W">Wojciech Szpankowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Data Structures and Algorithms (cs.DS); Information Theory (cs.IT)

</div>
<p class="mathjax">We study the problem of online conditional distribution estimation with
\emph{unbounded} label sets under local differential privacy. Let $\mathcal{F}$
be a distribution-valued function class with unbounded label set. We aim at
estimating an \emph{unknown} function $f\in \mathcal{F}$ in an online fashion
so that at time $t$ when the context $\boldsymbol{x}_t$ is provided we can
generate an estimate of $f(\boldsymbol{x}_t)$ under KL-divergence knowing only
a privatized version of the true labels sampling from $f(\boldsymbol{x}_t)$.
The ultimate objective is to minimize the cumulative KL-risk of a finite
horizon $T$. We show that under $(\epsilon,0)$-local differential privacy of
the privatized labels, the KL-risk grows as
$\tilde{\Theta}(\frac{1}{\epsilon}\sqrt{KT})$ upto poly-logarithmic factors
where $K=|\mathcal{F}|$. This is in stark contrast to the
$\tilde{\Theta}(\sqrt{T\log K})$ bound demonstrated by Wu et al. (2023a) for
bounded label sets. As a byproduct, our results recover a nearly tight upper
bound for the hypothesis selection problem of gopi et al. (2020) established
only for the batch setting.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00318" title="Abstract">arXiv:2402.00318</a> [<a href="/pdf/2402.00318" title="Download PDF">pdf</a>, <a href="/ps/2402.00318" title="Download PostScript">ps</a>, <a href="/format/2402.00318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analog-digital Scheduling for Federated Learning: A  Communication-Efficient Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abrar%2C+M+F+U">Muhammad Faraz Ul Abrar</a>, 
<a href="/search/cs?searchtype=author&query=Michelusi%2C+N">Nicol&#xf2; Michelusi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Signal Processing (eess.SP)

</div>
<p class="mathjax">Over-the-air (OTA) computation has recently emerged as a
communication-efficient Federated Learning (FL) paradigm to train machine
learning models over wireless networks. However, its performance is limited by
the device with the worst SNR, resulting in fast yet noisy updates. On the
other hand, allocating orthogonal resource blocks (RB) to individual devices
via digital channels mitigates the noise problem, at the cost of increased
communication latency. In this paper, we address this discrepancy and present
ADFL, a novel Analog-Digital FL scheme: in each round, the parameter server
(PS) schedules each device to either upload its gradient via the analog OTA
scheme or transmit its quantized gradient over an orthogonal RB using the
``digital" scheme. Focusing on a single FL round, we cast the optimal
scheduling problem as the minimization of the mean squared error (MSE) on the
estimated global gradient at the PS, subject to a delay constraint, yielding
the optimal device scheduling configuration and quantization bits for the
digital devices. Our simulation results show that ADFL, by scheduling most of
the devices in the OTA scheme while also occasionally employing the digital
scheme for a few devices, consistently outperforms OTA-only and digital-only
schemes, in both i.i.d. and non-i.i.d. settings.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00319" title="Abstract">arXiv:2402.00319</a> [<a href="/pdf/2402.00319" title="Download PDF">pdf</a>, <a href="/format/2402.00319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCO-VIST: Social Interaction Commonsense Knowledge-based Visual  Storytelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+E">Eileen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S+C">Soyeon Caren Han</a>, 
<a href="/search/cs?searchtype=author&query=Poon%2C+J">Josiah Poon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Visual storytelling aims to automatically generate a coherent story based on
a given image sequence. Unlike tasks like image captioning, visual stories
should contain factual descriptions, worldviews, and human social commonsense
to put disjointed elements together to form a coherent and engaging
human-writeable story. However, most models mainly focus on applying factual
information and using taxonomic/lexical external knowledge when attempting to
create stories. This paper introduces SCO-VIST, a framework representing the
image sequence as a graph with objects and relations that includes human action
motivation and its social interaction commonsense knowledge. SCO-VIST then
takes this graph representing plot points and creates bridges between plot
points with semantic and occurrence-based edge weights. This weighted story
graph produces the storyline in a sequence of events using Floyd-Warshall's
algorithm. Our proposed framework produces stories superior across multiple
metrics in terms of visual grounding, coherence, diversity, and humanness, per
both automatic and human evaluations.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00321" title="Abstract">arXiv:2402.00321</a> [<a href="/pdf/2402.00321" title="Download PDF">pdf</a>, <a href="/format/2402.00321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SmartCooper: Vehicular Collaborative Perception with Adaptive Fusion and  Judger Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+H">Haonan An</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhengru Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guowen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xianhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuguang Fang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, autonomous driving has garnered significant attention due to
its potential for improving road safety through collaborative perception among
connected and autonomous vehicles (CAVs). However, time-varying channel
variations in vehicular transmission environments demand dynamic allocation of
communication resources. Moreover, in the context of collaborative perception,
it is important to recognize that not all CAVs contribute valuable data, and
some CAV data even have detrimental effects on collaborative perception. In
this paper, we introduce SmartCooper, an adaptive collaborative perception
framework that incorporates communication optimization and a judger mechanism
to facilitate CAV data fusion. Our approach begins with optimizing the
connectivity of vehicles while considering communication constraints. We then
train a learnable encoder to dynamically adjust the compression ratio based on
the channel state information (CSI). Subsequently, we devise a judger mechanism
to filter the detrimental image data reconstructed by adaptive decoders. We
evaluate the effectiveness of our proposed algorithm on the OpenCOOD platform.
Our results demonstrate a substantial reduction in communication costs by
23.10\% compared to the non-judger scheme. Additionally, we achieve a
significant improvement on the average precision of Intersection over Union
(AP@IoU) by 7.15\% compared with state-of-the-art schemes.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00322" title="Abstract">arXiv:2402.00322</a> [<a href="/pdf/2402.00322" title="Download PDF">pdf</a>, <a href="/format/2402.00322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bias in Opinion Summarisation from Pre-training to Adaptation: A Case  Study in Political Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+N">Nannan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Fayek%2C+H">Haytham Fayek</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiuzhen Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 1 figure, 6 tables, Accepted to EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Opinion summarisation aims to summarise the salient information and opinions
presented in documents such as product reviews, discussion forums, and social
media texts into short summaries that enable users to effectively understand
the opinions therein. Generating biased summaries has the risk of potentially
swaying public opinion. Previous studies focused on studying bias in opinion
summarisation using extractive models, but limited research has paid attention
to abstractive summarisation models. In this study, using political bias as a
case study, we first establish a methodology to quantify bias in abstractive
models, then trace it from the pre-trained models to the task of summarising
social media opinions using different models and adaptation methods. We find
that most models exhibit intrinsic bias. Using a social media text
summarisation dataset and contrasting various adaptation methods, we find that
tuning a smaller number of parameters is less biased compared to standard
fine-tuning; however, the diversity of topics in training data used for
fine-tuning is critical.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00324" title="Abstract">arXiv:2402.00324</a> [<a href="/pdf/2402.00324" title="Download PDF">pdf</a>, <a href="/format/2402.00324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Consistent Lebesgue Measure for Multi-label Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Demir%2C+K">Kaan Demir</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+B">Bach Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+B">Bing Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengjie Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Multi-label loss functions are usually non-differentiable, requiring
surrogate loss functions for gradient-based optimisation. The consistency of
surrogate loss functions is not proven and is exacerbated by the conflicting
nature of multi-label loss functions. To directly learn from multiple related,
yet potentially conflicting multi-label loss functions, we propose a Consistent
Lebesgue Measure-based Multi-label Learner (CLML) and prove that CLML can
achieve theoretical consistency under a Bayes risk framework. Empirical
evidence supports our theory by demonstrating that: (1) CLML can consistently
achieve state-of-the-art results; (2) the primary performance factor is the
Lebesgue measure design, as CLML optimises a simpler feedforward model without
additional label graph, perturbation-based conditioning, or semantic
embeddings; and (3) an analysis of the results not only distinguishes CLML's
effectiveness but also highlights inconsistencies between the surrogate and the
desired loss functions.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00325" title="Abstract">arXiv:2402.00325</a> [<a href="/pdf/2402.00325" title="Download PDF">pdf</a>, <a href="/ps/2402.00325" title="Download PostScript">ps</a>, <a href="/format/2402.00325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How digital twins provide new opportunities for managing change in  complex projects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Whyte%2C+J">Jennifer Whyte</a>, 
<a href="/search/eess?searchtype=author&query=Soman%2C+R">Ranjith Soman</a>, 
<a href="/search/eess?searchtype=author&query=Sacks%2C+R">Rafael Sacks</a>, 
<a href="/search/eess?searchtype=author&query=Mohammadi%2C+N">Neda Mohammadi</a>, 
<a href="/search/eess?searchtype=author&query=Naderpajouh%2C+N">Nader Naderpajouh</a>, 
<a href="/search/eess?searchtype=author&query=Hong%2C+W">Wei-Ting Hong</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+G">Ghang Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Digital twins provide opportunities for the development of new techniques for
managing change in complex projects, such as infrastructure, new energy and
resource projects. Managing change is an important element of a systems
approach to infrastructure, and for ensuring the systems integration and
handover to asset owners, yet it is often done poorly, becoming a source of
errors that lead projects to be over budget and schedule. We set out to
articulate the opportunities provided by the digital twin for advanced
methodologies for managing change in complex projects, through an under-pinning
state of the art review of the existing technical literature and a small pilot
to identify the characteristics of future data-driven solutions. This
identifies the need to integrate work on identifying systems interfaces, change
propagation and visualisation, and the potential to significantly extend the
limitations of existing solutions by using developments in the digital twin,
such as linked data, semantic enrichment, network analyses and machine
learning.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00326" title="Abstract">arXiv:2402.00326</a> [<a href="/pdf/2402.00326" title="Download PDF">pdf</a>, <a href="/format/2402.00326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PirateNets: Physics-informed Deep Learning with Residual Adaptive  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bowen Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Perdikaris%2C+P">Paris Perdikaris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 Pages, 15 Figures, 8 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">While physics-informed neural networks (PINNs) have become a popular deep
learning framework for tackling forward and inverse problems governed by
partial differential equations (PDEs), their performance is known to degrade
when larger and deeper neural network architectures are employed. Our study
identifies that the root of this counter-intuitive behavior lies in the use of
multi-layer perceptron (MLP) architectures with non-suitable initialization
schemes, which result in poor trainablity for the network derivatives, and
ultimately lead to an unstable minimization of the PDE residual loss. To
address this, we introduce Physics-informed Residual Adaptive Networks
(PirateNets), a novel architecture that is designed to facilitate stable and
efficient training of deep PINN models. PirateNets leverage a novel adaptive
residual connection, which allows the networks to be initialized as shallow
networks that progressively deepen during training. We also show that the
proposed initialization scheme allows us to encode appropriate inductive biases
corresponding to a given PDE system into the network architecture. We provide
comprehensive empirical evidence showing that PirateNets are easier to optimize
and can gain accuracy from considerably increased depth, ultimately achieving
state-of-the-art results across various benchmarks. All code and data
accompanying this manuscript will be made publicly available at
\url{https://github.com/PredictiveIntelligenceLab/jaxpi}.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00330" title="Abstract">arXiv:2402.00330</a> [<a href="/pdf/2402.00330" title="Download PDF">pdf</a>, <a href="/format/2402.00330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Night-Rider: Nocturnal Vision-aided Localization in Streetlight Maps  Using Invariant Extended Kalman Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+T">Tianxiao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Mingle Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chengzhong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+H">Hui Kong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Vision-aided localization for low-cost mobile robots in diverse environments
has attracted widespread attention recently. Although many current systems are
applicable in daytime environments, nocturnal visual localization is still an
open problem owing to the lack of stable visual information. An insight from
most nocturnal scenes is that the static and bright streetlights are reliable
visual information for localization. Hence we propose a nocturnal vision-aided
localization system in streetlight maps with a novel data association and
matching scheme using object detection methods. We leverage the Invariant
Extended Kalman Filter (InEKF) to fuse IMU, odometer, and camera measurements
for consistent state estimation at night. Furthermore, a tracking recovery
module is also designed for tracking failures. Experiments on multiple real
nighttime scenes validate that the system can achieve remarkably accurate and
robust localization in nocturnal environments.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00332" title="Abstract">arXiv:2402.00332</a> [<a href="/pdf/2402.00332" title="Download PDF">pdf</a>, <a href="/format/2402.00332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Spectral Bias and Robustness For Two-Layer Neural Networks:  SGD vs Adaptive Random Fourier Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kammonen%2C+A">Aku Kammonen</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+L">Lisi Liang</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+A">Anamika Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Tempone%2C+R">Ra&#xfa;l Tempone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 Pages, 4 Figures; Accepted in the International Conference on Scientific Computing and Machine Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We present experimental results highlighting two key differences resulting
from the choice of training algorithm for two-layer neural networks. The
spectral bias of neural networks is well known, while the spectral bias
dependence on the choice of training algorithm is less studied. Our experiments
demonstrate that an adaptive random Fourier features algorithm (ARFF) can yield
a spectral bias closer to zero compared to the stochastic gradient descent
optimizer (SGD). Additionally, we train two identically structured classifiers,
employing SGD and ARFF, to the same accuracy levels and empirically assess
their robustness against adversarial noise attacks.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00334" title="Abstract">arXiv:2402.00334</a> [<a href="/pdf/2402.00334" title="Download PDF">pdf</a>, <a href="/format/2402.00334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-agent Path Finding for Cooperative Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhongxia Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Han Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Cathy Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, IEEE International Conference on Robotics and Automation (ICRA), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Anticipating possible future deployment of connected and automated vehicles
(CAVs), cooperative autonomous driving at intersections has been studied by
many works in control theory and intelligent transportation across decades.
Simultaneously, recent parallel works in robotics have devised efficient
algorithms for multi-agent path finding (MAPF), though often in environments
with simplified kinematics. In this work, we hybridize insights and algorithms
from MAPF with the structure and heuristics of optimizing the crossing order of
CAVs at signal-free intersections. We devise an optimal and complete algorithm,
Order-based Search with Kinematics Arrival Time Scheduling (OBS-KATS), which
significantly outperforms existing algorithms, fixed heuristics, and
prioritized planning with KATS. The performance is maintained under different
vehicle arrival rates, lane lengths, crossing speeds, and control horizon.
Through ablations and dissections, we offer insight on the contributing factors
to OBS-KATS's performance. Our work is directly applicable to many similarly
scaled traffic and multi-robot scenarios with directed lanes.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00336" title="Abstract">arXiv:2402.00336</a> [<a href="/pdf/2402.00336" title="Download PDF">pdf</a>, <a href="/format/2402.00336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximating the Smallest $k$-Enclosing Geodesic Disc in a Simple  Polygon
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bose%2C+P">Prosenjit Bose</a>, 
<a href="/search/cs?searchtype=author&query=D%27Angelo%2C+A">Anthony D&#x27;Angelo</a>, 
<a href="/search/cs?searchtype=author&query=Durocher%2C+S">Stephane Durocher</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages (27 main content, 4 of references, then appendices), 10 figures (2 of which have 2 subfigures), preliminary version in WADS vol. 14079 of LNCS, pgs. 179 - 192, Springer, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">We consider the problem of finding a geodesic disc of smallest radius
containing at least $k$ points from a set of $n$ points in a simple polygon
that has $m$ vertices, $r$ of which are reflex vertices. We refer to such a
disc as a SKEG disc. We present an algorithm to compute a SKEG disc using
higher-order geodesic Voronoi diagrams with worst-case time $O(k^{2} n + k^{2}
r + \min(kr, r(n-k)) + m)$ ignoring polylogarithmic factors.
<br />We then present two $2$-approximation algorithms that find a geodesic disc
containing at least $k$ points whose radius is at most twice that of a SKEG
disc. The first algorithm computes a $2$-approximation with high probability in
$O((n^{2} / k) \log n \log r + m)$ worst-case time with $O(n + m)$ space. The
second algorithm runs in $O(n \log^{2} n \log r + m)$ expected time using $O(n
+ m)$ expected space, independent of $k$. Note that the first algorithm is
faster when $k \in \omega(n / \log n)$.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00340" title="Abstract">arXiv:2402.00340</a> [<a href="/pdf/2402.00340" title="Download PDF">pdf</a>, <a href="/format/2402.00340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can you Remove the Downstream Model for Speaker Recognition with  Self-Supervised Speech Features?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aldeneh%2C+Z">Zakaria Aldeneh</a>, 
<a href="/search/cs?searchtype=author&query=Higuchi%2C+T">Takuya Higuchi</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+J">Jee-weon Jung</a>, 
<a href="/search/cs?searchtype=author&query=Seto%2C+S">Skyler Seto</a>, 
<a href="/search/cs?searchtype=author&query=Likhomanenko%2C+T">Tatiana Likhomanenko</a>, 
<a href="/search/cs?searchtype=author&query=Shum%2C+S">Stephen Shum</a>, 
<a href="/search/cs?searchtype=author&query=Abdelaziz%2C+A+H">Ahmed Hussen Abdelaziz</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>, 
<a href="/search/cs?searchtype=author&query=Theobald%2C+B">Barry-John Theobald</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Self-supervised features are typically used in place of filter-banks in
speaker verification models. However, these models were originally designed to
ingest filter-banks as inputs, and thus, training them on top of
self-supervised features assumes that both feature types require the same
amount of learning for the task. In this work, we observe that pre-trained
self-supervised speech features inherently include information required for
downstream speaker verification task, and therefore, we can simplify the
downstream model without sacrificing performance. To this end, we revisit the
design of the downstream model for speaker verification using self-supervised
features. We show that we can simplify the model to use 97.51% fewer parameters
while achieving a 29.93% average improvement in performance on SUPERB.
Consequently, we show that the simplified downstream model is more data
efficient compared to baseline--it achieves better performance with only 60% of
the training data.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00341" title="Abstract">arXiv:2402.00341</a> [<a href="/pdf/2402.00341" title="Download PDF">pdf</a>, <a href="/format/2402.00341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recasting Regional Lighting for Shadow Removal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+Z">Zhanghan Ke</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Ke Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhenwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+R+W+H">Rynson W.H. Lau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Removing shadows requires an understanding of both lighting conditions and
object textures in a scene. Existing methods typically learn pixel-level color
mappings between shadow and non-shadow images, in which the joint modeling of
lighting and object textures is implicit and inadequate. We observe that in a
shadow region, the degradation degree of object textures depends on the local
illumination, while simply enhancing the local illumination cannot fully
recover the attenuated textures. Based on this observation, we propose to
condition the restoration of attenuated textures on the corrected local
lighting in the shadow region. Specifically, We first design a shadow-aware
decomposition network to estimate the illumination and reflectance layers of
shadow regions explicitly. We then propose a novel bilateral correction network
to recast the lighting of shadow regions in the illumination layer via a novel
local lighting correction module, and to restore the textures conditioned on
the corrected illumination layer via a novel illumination-guided texture
restoration module. We further annotate pixel-wise shadow masks for the public
SRD dataset, which originally contains only image pairs. Experiments on three
benchmarks show that our method outperforms existing state-of-the-art shadow
removal methods.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00342" title="Abstract">arXiv:2402.00342</a> [<a href="/pdf/2402.00342" title="Download PDF">pdf</a>, <a href="/format/2402.00342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey of Privacy Threats and Countermeasures in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hayashitani%2C+M">Masahiro Hayashitani</a>, 
<a href="/search/cs?searchtype=author&query=Mori%2C+J">Junki Mori</a>, 
<a href="/search/cs?searchtype=author&query=Teranishi%2C+I">Isamu Teranishi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Scheduled for renewal by March 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Federated learning is widely considered to be as a privacy-aware learning
method because no training data is exchanged directly between clients.
Nevertheless, there are threats to privacy in federated learning, and privacy
countermeasures have been studied. However, we note that common and unique
privacy threats among typical types of federated learning have not been
categorized and described in a comprehensive and specific way. In this paper,
we describe privacy threats and countermeasures for the typical types of
federated learning; horizontal federated learning, vertical federated learning,
and transfer federated learning.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00344" title="Abstract">arXiv:2402.00344</a> [<a href="/pdf/2402.00344" title="Download PDF">pdf</a>, <a href="/format/2402.00344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reimagining TaxiVis through an Immersive Space-Time Cube metaphor and  reflecting on potential benefits of Immersive Analytics for urban data  exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wagner%2C+J">Jorge Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+C+T">Claudio T. Silva</a>, 
<a href="/search/cs?searchtype=author&query=Stuerzlinger%2C+W">Wolfgang Stuerzlinger</a>, 
<a href="/search/cs?searchtype=author&query=Nedel%2C+L">Luciana Nedel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the proceedings of the IEEE VR 2024 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Current visualization research has identified the potential of more immersive
settings for data exploration, leveraging VR and AR technologies. To explore
how a traditional visualization system could be adapted into an immersive
framework, and how it could benefit from this, we decided to revisit a landmark
paper presented ten years ago at IEEE VIS. TaxiVis, by Ferreira et al., enabled
interactive spatio-temporal querying of a large dataset of taxi trips in New
York City. Here, we reimagine how TaxiVis' functionalities could be implemented
and extended in a 3D immersive environment. Among the unique features we
identify as being enabled by the Immersive TaxiVis prototype are alternative
uses of the additional visual dimension, a fully visual 3D spatio-temporal
query framework, and the opportunity to explore the data at different scales
and frames of reference. By revisiting the case studies from the original
paper, we demonstrate workflows that can benefit from this immersive
perspective. Through reporting on our experience, and on the vision and
reasoning behind our design decisions, we hope to contribute to the debate on
how conventional and immersive visualization paradigms can complement each
other and on how the exploration of urban datasets can be facilitated in the
coming years.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00345" title="Abstract">arXiv:2402.00345</a> [<a href="/pdf/2402.00345" title="Download PDF">pdf</a>, <a href="/format/2402.00345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IndiVec: An Exploration of Leveraging Large Language Models for Media  Bias Detection with Fine-Grained Bias Indicators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Luyang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lingzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiaoyan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jing Li</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kam-Fai Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This study focuses on media bias detection, crucial in today's era of
influential social media platforms shaping individual attitudes and opinions.
In contrast to prior work that primarily relies on training specific models
tailored to particular datasets, resulting in limited adaptability and subpar
performance on out-of-domain data, we introduce a general bias detection
framework, IndiVec, built upon large language models. IndiVec begins by
constructing a fine-grained media bias database, leveraging the robust
instruction-following capabilities of large language models and vector database
techniques. When confronted with new input for bias detection, our framework
automatically selects the most relevant indicator from the vector database and
employs majority voting to determine the input's bias label. IndiVec excels
compared to previous methods due to its adaptability (demonstrating consistent
performance across diverse datasets from various sources) and explainability
(providing explicit top-k indicators to interpret bias predictions).
Experimental results on four political bias datasets highlight IndiVec's
significant superiority over baselines. Furthermore, additional experiments and
analysis provide profound insights into the framework's effectiveness.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00346" title="Abstract">arXiv:2402.00346</a> [<a href="/pdf/2402.00346" title="Download PDF">pdf</a>, <a href="/format/2402.00346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental Application of Predictive Cost Adaptive Control to  Thermoacoustic Oscillations in a Rijke Tube
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Paredes%2C+J+A">Juan A. Paredes</a>, 
<a href="/search/eess?searchtype=author&query=Bernstein%2C+D+S">Dennis S. Bernstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Model predictive control (MPC) has been used successfully in diverse
applications. As its name suggests, MPC requires a model for predictive
optimization. The present paper focuses on the application of MPC to a Rijke
tube, in which a heating source and acoustic dynamics interact to produce
self-excited oscillations. Since the dynamics of a Rijke tube are difficult to
model to a high level of accuracy, the implementation of MPC requires
leveraging data from the physical setup as well as knowledge about
thermoacoustics, which is labor intensive and requires domain expertise. With
this motivation, the present paper uses predictive cost adaptive control (PCAC)
for sampled-data control of an experimental Rijke-tube setup. PCAC performs
online closed-loop linear model identification for receding-horizon
optimization based on the backward propagating Riccati equation. In place of
analytical modeling, open-loop experiments are used to create a simple
emulation model, which is used for choosing PCAC hyperparameters. PCAC is
applied to the Rijke-tube setup under various experimental scenarios.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00347" title="Abstract">arXiv:2402.00347</a> [<a href="/pdf/2402.00347" title="Download PDF">pdf</a>, <a href="/format/2402.00347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diverse Explanations from Data-driven and Domain-driven Perspectives for  Machine Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sichao Li</a>, 
<a href="/search/cs?searchtype=author&query=Barnard%2C+A">Amanda Barnard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Explanations of machine learning models are important, especially in
scientific areas such as chemistry, biology, and physics, where they guide
future laboratory experiments and resource requirements. These explanations can
be derived from well-trained machine learning models (data-driven perspective)
or specific domain knowledge (domain-driven perspective). However, there exist
inconsistencies between these perspectives due to accurate yet misleading
machine learning models and various stakeholders with specific needs, wants, or
aims. This paper calls attention to these inconsistencies and suggests a way to
find an accurate model with expected explanations that reinforce physical laws
and meet stakeholders' requirements from a set of equally-good models, also
known as Rashomon sets. Our goal is to foster a comprehensive understanding of
these inconsistencies and ultimately contribute to the integration of
eXplainable Artificial Intelligence (XAI) into scientific domains.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00348" title="Abstract">arXiv:2402.00348</a> [<a href="/pdf/2402.00348" title="Download PDF">pdf</a>, <a href="/format/2402.00348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ODICE: Revealing the Mystery of Distribution Correction Estimation via  Orthogonal-gradient Update
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+L">Liyuan Mao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haoran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xianyuan Zhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Spotlight @ ICLR 2024, first two authors contribute equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this study, we investigate the DIstribution Correction Estimation (DICE)
methods, an important line of work in offline reinforcement learning (RL) and
imitation learning (IL). DICE-based methods impose state-action-level behavior
constraint, which is an ideal choice for offline learning. However, they
typically perform much worse than current state-of-the-art (SOTA) methods that
solely use action-level behavior constraint. After revisiting DICE-based
methods, we find there exist two gradient terms when learning the value
function using true-gradient update: forward gradient (taken on the current
state) and backward gradient (taken on the next state). Using forward gradient
bears a large similarity to many offline RL methods, and thus can be regarded
as applying action-level constraint. However, directly adding the backward
gradient may degenerate or cancel out its effect if these two gradients have
conflicting directions. To resolve this issue, we propose a simple yet
effective modification that projects the backward gradient onto the normal
plane of the forward gradient, resulting in an orthogonal-gradient update, a
new learning rule for DICE-based methods. We conduct thorough theoretical
analyses and find that the projected backward gradient brings state-level
behavior regularization, which reveals the mystery of DICE-based methods: the
value learning objective does try to impose state-action-level constraint, but
needs to be used in a corrected way. Through toy examples and extensive
experiments on complex offline RL and IL tasks, we demonstrate that DICE-based
methods using orthogonal-gradient updates (O-DICE) achieve SOTA performance and
great robustness.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00350" title="Abstract">arXiv:2402.00350</a> [<a href="/pdf/2402.00350" title="Download PDF">pdf</a>, <a href="/format/2402.00350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models Based Fuzzing Techniques: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Linghan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Peizhou Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huaming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lei Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages submission under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the modern era where software plays a pivotal role, software security and
vulnerability analysis have become essential for software development. Fuzzing
test, as an efficient software testing method, are widely used in various
domains. Moreover, the rapid development of Large Language Models (LLMs) has
facilitated their application in the field of software testing, demonstrating
remarkable performance. Considering that existing fuzzing test techniques are
not entirely automated and software vulnerabilities continue to evolve, there
is a growing trend towards employing fuzzing test generated based on large
language models. This survey provides a systematic overview of the approaches
that fuse LLMs and fuzzing tests for software testing. In this paper, a
statistical analysis and discussion of the literature in three areas, namely
LLMs, fuzzing test, and fuzzing test generated based on LLMs, are conducted by
summarising the state-of-the-art methods up until 2024. Our survey also
investigates the potential for widespread deployment and application of fuzzing
test techniques generated by LLMs in the future.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00351" title="Abstract">arXiv:2402.00351</a> [<a href="/pdf/2402.00351" title="Download PDF">pdf</a>, <a href="/format/2402.00351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Unlearning for Image-to-Image Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guihong Li</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+H">Hsiang Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Chun-Fu">Chun-Fu</a> (Richard)
<a href="/search/cs?searchtype=author&query=Chen">Chen</a>, 
<a href="/search/cs?searchtype=author&query=Marculescu%2C+R">Radu Marculescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Machine unlearning has emerged as a new paradigm to deliberately forget data
samples from a given model in order to adhere to stringent regulations.
However, existing machine unlearning methods have been primarily focused on
classification models, leaving the landscape of unlearning for generative
models relatively unexplored. This paper serves as a bridge, addressing the gap
by providing a unifying framework of machine unlearning for image-to-image
generative models. Within this framework, we propose a
computationally-efficient algorithm, underpinned by rigorous theoretical
analysis, that demonstrates negligible performance degradation on the retain
samples, while effectively removing the information from the forget samples.
Empirical studies on two large-scale datasets, ImageNet-1K and Places-365,
further show that our algorithm does not rely on the availability of the retain
samples, which further complies with data retention policy. To our best
knowledge, this work is the first that represents systemic, theoretical,
empirical explorations of machine unlearning specifically tailored for
image-to-image generative models. Our code is available at
https://github.com/jpmorganchase/l2l-generator-unlearning.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00352" title="Abstract">arXiv:2402.00352</a> [<a href="/pdf/2402.00352" title="Download PDF">pdf</a>, <a href="/format/2402.00352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Data-Driven Autopilot for Fixed-Wing Aircraft Based on Model  Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Richards%2C+R+J">Riley J. Richards</a>, 
<a href="/search/eess?searchtype=author&query=Paredes%2C+J+A">Juan A. Paredes</a>, 
<a href="/search/eess?searchtype=author&query=Bernstein%2C+D+S">Dennis S. Bernstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Autopilots for fixed-wing aircraft are typically designed based on linearized
aerodynamic models consisting of stability and control derivatives obtained
from wind-tunnel testing. The resulting local controllers are then pieced
together using gain scheduling. For applications in which the aerodynamics are
unmodeled, the present paper proposes an autopilot based on predictive cost
adaptive control (PCAC). As an indirect adaptive control extension of model
predictive control, PCAC uses recursive least squares (RLS) with variable-rate
forgetting for online, closed-loop system identification. At each time step,
RLS-based system identification updates the coefficients of an input-output
model whose order is a hyperparameter specified by the user. For MPC, the
receding-horizon optimization can be performed by either the
backward-propagating Riccati equation or quadratic programming. The present
paper investigates the performance of PCAC for fixed-wing aircraft without the
use of any aerodynamic modeling or offline/prior data collection.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00353" title="Abstract">arXiv:2402.00353</a> [<a href="/pdf/2402.00353" title="Download PDF">pdf</a>, <a href="/format/2402.00353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Quality Medical Image Generation from Free-hand Sketch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cap%2C+Q+H">Quan Huu Cap</a>, 
<a href="/search/cs?searchtype=author&query=Fukuda%2C+A">Atsushi Fukuda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generating medical images from human-drawn free-hand sketches holds promise
for various important medical imaging applications. Due to the extreme
difficulty in collecting free-hand sketch data in the medical domain, most deep
learning-based methods have been proposed to generate medical images from the
synthesized sketches (e.g., edge maps or contours of segmentation masks from
real images). However, these models often fail to generalize on the free-hand
sketches, leading to unsatisfactory results. In this paper, we propose a
practical free-hand sketch-to-image generation model called Sketch2MedI that
learns to represent sketches in StyleGAN's latent space and generate medical
images from it. Thanks to the ability to encode sketches into this meaningful
representation space, Sketch2MedI only requires synthesized sketches for
training, enabling a cost-effective learning process. Our Sketch2MedI
demonstrates a robust generalization to free-hand sketches, resulting in
high-quality and realistic medical image generations. Comparative evaluations
of Sketch2MedI against the pix2pix, CycleGAN, UNIT, and U-GAT-IT models show
superior performance in generating pharyngeal images, both quantitative and
qualitative across various metrics.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00355" title="Abstract">arXiv:2402.00355</a> [<a href="/pdf/2402.00355" title="Download PDF">pdf</a>, <a href="/format/2402.00355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Primal-Dual Method for Safe Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weiqin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Onyejizu%2C+J">James Onyejizu</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+L">Long Vu</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+L">Lan Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Subramanian%2C+D">Dharmashankar Subramanian</a>, 
<a href="/search/cs?searchtype=author&query=Kar%2C+K">Koushik Kar</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Sandipan Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Paternain%2C+S">Santiago Paternain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
<p class="mathjax">Primal-dual methods have a natural application in Safe Reinforcement Learning
(SRL), posed as a constrained policy optimization problem. In practice however,
applying primal-dual methods to SRL is challenging, due to the inter-dependency
of the learning rate (LR) and Lagrangian multipliers (dual variables) each time
an embedded unconstrained RL problem is solved. In this paper, we propose,
analyze and evaluate adaptive primal-dual (APD) methods for SRL, where two
adaptive LRs are adjusted to the Lagrangian multipliers so as to optimize the
policy in each iteration. We theoretically establish the convergence,
optimality and feasibility of the APD algorithm. Finally, we conduct numerical
evaluation of the practical APD algorithm with four well-known environments in
Bullet-Safey-Gym employing two state-of-the-art SRL algorithms: PPO-Lagrangian
and DDPG-Lagrangian. All experiments show that the practical APD algorithm
outperforms (or achieves comparable performance) and attains more stable
training than the constant LR cases. Additionally, we substantiate the
robustness of selecting the two adaptive LRs by empirical evidence.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00356" title="Abstract">arXiv:2402.00356</a> [<a href="/pdf/2402.00356" title="Download PDF">pdf</a>, <a href="/format/2402.00356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Securing Cloud-Based Internet of Things: Challenges and Mitigations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+N">Nivedita Singh</a>, 
<a href="/search/cs?searchtype=author&query=Buyya%2C+R">Rajkumar Buyya</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyoungshich Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The Internet of Things (IoT) has seen remarkable advancements in recent
years, leading to a paradigm shift in the digital landscape. However, these
technological strides have also brought new challenges, particularly in terms
of cybersecurity. IoT devices are inherently connected to the internet, which
makes them more vulnerable to attack. In addition, IoT services often handle
sensitive user data, which could be misused by malicious actors or unauthorized
service providers. As more mainstream service providers emerge without uniform
regulations, these security risks are expected to escalate exponentially. The
task of maintaining the security of IoT devices while they interact with cloud
services is also challenging. Newer IoT services, especially those developed
and deployed via Platform-as-a-Service (PaaS) and Infrastructure-as-a-Service
(IaaS) models, pose additional security threats. Although IoT devices are
becoming more affordable and ubiquitous, their growing complexity could expose
users to heightened security and privacy risks. This paper highlights these
pressing security concerns associated with the widespread adoption of IoT
devices and services. We propose potential solutions to bridge the existing
security gaps and expect future challenges. Our approach entails a
comprehensive exploration of the key security challenges that IoT services are
currently facing. We also suggest proactive strategies to mitigate these risks,
strengthening the overall security of IoT devices and services.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00357" title="Abstract">arXiv:2402.00357</a> [<a href="/pdf/2402.00357" title="Download PDF">pdf</a>, <a href="/format/2402.00357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safety of Multimodal Large Language Models on Images and Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yichen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yunshi Lan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Attracted by the impressive power of Multimodal Large Language Models
(MLLMs), the public is increasingly utilizing them to improve the efficiency of
daily work. Nonetheless, the vulnerabilities of MLLMs to unsafe instructions
bring huge safety risks when these models are deployed in real-world scenarios.
In this paper, we systematically survey current efforts on the evaluation,
attack, and defense of MLLMs' safety on images and text. We begin with
introducing the overview of MLLMs on images and text and understanding of
safety, which helps researchers know the detailed scope of our survey. Then, we
review the evaluation datasets and metrics for measuring the safety of MLLMs.
Next, we comprehensively present attack and defense techniques related to
MLLMs' safety. Finally, we analyze several unsolved issues and discuss
promising research directions.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00364" title="Abstract">arXiv:2402.00364</a> [<a href="/pdf/2402.00364" title="Download PDF">pdf</a>, <a href="/format/2402.00364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A parallel domain decomposition method for solving elliptic equations on  manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Qin%2C+L">Lizhen Qin</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+F">Feng Wang</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+Y">Yun Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Comments are welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose a new numerical domain decomposition method for solving elliptic
equations on compact Riemannian manifolds. One advantage of this method is its
ability to bypass the need for global triangulations or grids on the manifolds.
Additionally, it features a highly parallel iterative scheme. To verify its
efficacy, we conduct numerical experiments on some $4$-dimensional manifolds
without and with boundary.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00365" title="Abstract">arXiv:2402.00365</a> [<a href="/pdf/2402.00365" title="Download PDF">pdf</a>, <a href="/format/2402.00365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> bypass4netns: Accelerating TCP/IP Communications in Rootless Containers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Matsumoto%2C+N">Naoki Matsumoto</a>, 
<a href="/search/cs?searchtype=author&query=Suda%2C+A">Akihiro Suda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Operating Systems (cs.OS)

</div>
<p class="mathjax">"Rootless containers" is a concept to run the entire container runtimes and
containers without the root privileges. It protects the host environment from
attackers exploiting container runtime vulnerabilities. However, when rootless
containers communicate with external endpoints, the network performance is low
compared to rootful containers because of the overhead of rootless networking
components. In this paper, we propose bypass4netns that accelerates TCP/IP
communications in rootless containers by bypassing slow networking components.
bypass4netns uses sockets allocated on the host. It switches sockets in
containers to the host's sockets by intercepting syscalls and injecting the
file descriptors using Seccomp. Our method with Seccomp can handle statically
linked applications that previous works could not handle. Also, we propose
high-performance rootless multi-node communication. We confirmed that rootless
containers with bypass4netns achieve more than 30x faster throughput than
rootless containers without it. In addition, we evaluated performance with
applications and it showed large improvements on some applications.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00366" title="Abstract">arXiv:2402.00366</a> [<a href="/pdf/2402.00366" title="Download PDF">pdf</a>, <a href="/format/2402.00366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Legged Robot State Estimation With Invariant Extended Kalman Filter  Using Neural Measurement Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Youm%2C+D">Donghoon Youm</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+H">Hyunsik Oh</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Suyoung Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyeongjun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hwangbo%2C+J">Jemin Hwangbo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8pages, 6paper, This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper introduces a novel proprioceptive state estimator for legged
robots that combines model-based filters and deep neural networks. Recent
studies have shown that neural networks such as multi-layer perceptron or
recurrent neural networks can estimate the robot states, including contact
probability and linear velocity. Inspired by this, we develop a state
estimation framework that integrates a neural measurement network (NMN) with an
invariant extended Kalman filter. We show that our framework improves
estimation performance in various terrains. Existing studies that combine
model-based filters and learning-based approaches typically use real-world
data. However, our approach relies solely on simulation data, as it allows us
to easily obtain extensive data. This difference leads to a gap between the
learning and the inference domain, commonly referred to as a sim-to-real gap.
We address this challenge by adapting existing learning techniques and
regularization. To validate our proposed method, we conduct experiments using a
quadruped robot on four types of terrain: \textit{flat}, \textit{debris},
\textit{soft}, and \textit{slippery}. We observe that our approach
significantly reduces position drift compared to the existing model-based state
estimator.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00367" title="Abstract">arXiv:2402.00367</a> [<a href="/pdf/2402.00367" title="Download PDF">pdf</a>, <a href="/format/2402.00367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Don&#x27;t Hallucinate, Abstain: Identifying LLM Knowledge Gaps via Multi-LLM  Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+S">Shangbin Feng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Weijia Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yike Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Wenxuan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Balachandran%2C+V">Vidhisha Balachandran</a>, 
<a href="/search/cs?searchtype=author&query=Tsvetkov%2C+Y">Yulia Tsvetkov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Despite efforts to expand the knowledge of large language models (LLMs),
knowledge gaps -- missing or outdated information in LLMs -- might always
persist given the evolving nature of knowledge. In this work, we study
approaches to identify LLM knowledge gaps and abstain from answering questions
when knowledge gaps are present. We first adapt existing approaches to model
calibration or adaptation through fine-tuning/prompting and analyze their
ability to abstain from generating low-confidence outputs. Motivated by their
failures in self-reflection and over-reliance on held-out sets, we propose two
novel approaches that are based on model collaboration, i.e., LLMs probing
other LLMs for knowledge gaps, either cooperatively or competitively. Extensive
experiments with three LLMs on four QA tasks featuring diverse knowledge
domains demonstrate that both cooperative and competitive approaches to
unveiling LLM knowledge gaps achieve up to 19.3% improvements on abstain
accuracy against the strongest baseline. Further analysis reveals that our
proposed mechanisms could help identify failure cases in retrieval augmentation
and pinpoint knowledge gaps in multi-hop reasoning.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00370" title="Abstract">arXiv:2402.00370</a> [<a href="/pdf/2402.00370" title="Download PDF">pdf</a>, <a href="/ps/2402.00370" title="Download PostScript">ps</a>, <a href="/format/2402.00370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the landscape of virtual academic conferences: A scoping  review of the 1984-2021 literature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Olechnicka%2C+A">Agnieszka Olechnicka</a>, 
<a href="/search/cs?searchtype=author&query=Ploszaj%2C+A">Adam Ploszaj</a>, 
<a href="/search/cs?searchtype=author&query=Zegler-Poleska%2C+E">Ewa Zegler-Poleska</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This study presents an overview of the literature on virtual academic
conferences, which have gained prominence due to the COVID-19 pandemic. We
conducted a scoping review analyzing 147 documents covering the literature
available up to October 5th, 2021. We examined the development of the field
focusing on the evolution of virtual academic conferences, main themes in the
literature, and its methodological and theoretical approaches. The results
indicate that the existing literature on virtual academic conferences is mainly
descriptive and lacks a theoretical framework. Future research should focus on
developing a solid theoretical framework to guide empirically and
methodologically robust studies on virtual academic conferences. We emphasize
the importance of recognizing their advantages and disadvantages from the
perspectives of different groups of scholars. This will be a crucial step in
establishing a framework for identifying and addressing dilemmas in online
scholarly communication according to the responsible research and innovation
approach.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00371" title="Abstract">arXiv:2402.00371</a> [<a href="/pdf/2402.00371" title="Download PDF">pdf</a>, <a href="/format/2402.00371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Does the Bot Say? Opportunities and Risks of Large Language Models  in Social Media Bot Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+S">Shangbin Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+H">Herun Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Ningnan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhaoxuan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+M">Minnan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Tsvetkov%2C+Y">Yulia Tsvetkov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Social media bot detection has always been an arms race between advancements
in machine learning bot detectors and adversarial bot strategies to evade
detection. In this work, we bring the arms race to the next level by
investigating the opportunities and risks of state-of-the-art large language
models (LLMs) in social bot detection. To investigate the opportunities, we
design novel LLM-based bot detectors by proposing a
mixture-of-heterogeneous-experts framework to divide and conquer diverse user
information modalities. To illuminate the risks, we explore the possibility of
LLM-guided manipulation of user textual and structured information to evade
detection. Extensive experiments with three LLMs on two datasets demonstrate
that instruction tuning on merely 1,000 annotated examples produces specialized
LLMs that outperform state-of-the-art baselines by up to 9.1% on both datasets,
while LLM-guided manipulation strategies could significantly bring down the
performance of existing bot detectors by up to 29.6% and harm the calibration
and reliability of bot detection systems.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00378" title="Abstract">arXiv:2402.00378</a> [<a href="/pdf/2402.00378" title="Download PDF">pdf</a>, <a href="/format/2402.00378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Minimum Depth of Circuits with Linear Number of Wires Encoding  Good Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Drucker%2C+A">Andrew Drucker</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> COCOON'23. Correction to the conference version: noted G\'{a}l et al.'s description/use (in the journal version) of rate-boosting of codes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Let $S_d(n)$ denote the minimum number of wires of a depth-$d$ (unbounded
fan-in) circuit encoding an error-correcting code $C:\{0, 1\}^n \to \{0,
1\}^{32n}$ with distance at least $4n$. G\'{a}l, Hansen, Kouck\'{y},
Pudl\'{a}k, and Viola [IEEE Trans. Inform. Theory 59(10), 2013] proved that
$S_d(n) = \Theta_d(\lambda_d(n)\cdot n)$ for any fixed $d \ge 3$. By improving
their construction and analysis, we prove $S_d(n)= O(\lambda_d(n)\cdot n)$.
Letting $d = \alpha(n)$, a version of the inverse Ackermann function, we obtain
circuits of linear size. This depth $\alpha(n)$ is the minimum possible to
within an additive constant 2; we credit the nearly-matching depth lower bound
to G\'{a}l et al., since it directly follows their method (although not
explicitly claimed or fully verified in that work), and is obtained by making
some constants explicit in a graph-theoretic lemma of Pudl\'{a}k
[Combinatorica, 14(2), 1994], extending it to super-constant depths.
<br />We also study a subclass of MDS codes $C: \mathbb{F}^n \to \mathbb{F}^m$
characterized by the Hamming-distance relation $\mathrm{dist}(C(x), C(y)) \ge m
- \mathrm{dist}(x, y) + 1$ for any distinct $x, y \in \mathbb{F}^n$. (For
linear codes this is equivalent to the generator matrix being totally
invertible.) We call these superconcentrator-induced codes, and we show their
tight connection with superconcentrators. Specifically, we observe that any
linear or nonlinear circuit encoding a superconcentrator-induced code must be a
superconcentrator graph, and any superconcentrator graph can be converted to a
linear circuit, over a sufficiently large field (exponential in the size of the
graph), encoding a superconcentrator-induced code.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00380" title="Abstract">arXiv:2402.00380</a> [<a href="/pdf/2402.00380" title="Download PDF">pdf</a>, <a href="/ps/2402.00380" title="Download PostScript">ps</a>, <a href="/format/2402.00380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $n$-Dimensional Volumetric Stretch Energy Minimization for  Volume-/Mass-Preserving Parameterizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tan%2C+Z">Zhong-Heng Tan</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+T">Tiexiang Li</a>, 
<a href="/search/math?searchtype=author&query=Lin%2C+W">Wen-Wei Lin</a>, 
<a href="/search/math?searchtype=author&query=Yau%2C+S">Shing-Tung Yau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we develop an $n$ dimensional volumetric stretch energy
($n$-VSE) functional for the volume-/mass-preserving parameterization of the
$n$-manifolds topologically equivalent to $n$-ball. The $n$-VSE has a lower
bound and equal to it if and only if the map is volume-/mass-preserving. This
motivates us to minimize the $n$-VSE to achieve the ideal
volume-/mass-preserving parameterization. In the discrete case, we also
guarantee the relation between the lower bound and the
volume-/mass-preservation, and propose the spherical and ball
volume-/mass-preserving parameterization algorithms. The numerical experiments
indicate the accuracy and robustness of the proposed algorithms. The modified
algorithms are applied to the manifold registration and deformation, showing
the versatility of $n$-VSE.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00381" title="Abstract">arXiv:2402.00381</a> [<a href="/pdf/2402.00381" title="Download PDF">pdf</a>, <a href="/ps/2402.00381" title="Download PostScript">ps</a>, <a href="/format/2402.00381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Joint Communication and Computation Framework for Digital Twin over  Wireless Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhaohui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingzhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoyang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, the problem of low-latency communication and computation
resource allocation for digital twin (DT) over wireless networks is
investigated. In the considered model, multiple physical devices in the
physical network (PN) needs to frequently offload the computation task related
data to the digital network twin (DNT), which is generated and controlled by
the central server. Due to limited energy budget of the physical devices, both
computation accuracy and wireless transmission power must be considered during
the DT procedure. This joint communication and computation problem is
formulated as an optimization problem whose goal is to minimize the overall
transmission delay of the system under total PN energy and DNT model accuracy
constraints. To solve this problem, an alternating algorithm with iteratively
solving device scheduling, power control, and data offloading subproblems. For
the device scheduling subproblem, the optimal solution is obtained in closed
form through the dual method. For the special case with one physical device,
the optimal number of transmission times is reveled. Based on the theoretical
findings, the original problem is transformed into a simplified problem and the
optimal device scheduling can be found. Numerical results verify that the
proposed algorithm can reduce the transmission delay of the system by up to
51.2\% compared to the conventional schemes.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00384" title="Abstract">arXiv:2402.00384</a> [<a href="/pdf/2402.00384" title="Download PDF">pdf</a>, <a href="/ps/2402.00384" title="Download PostScript">ps</a>, <a href="/format/2402.00384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive FRIT-based Recursive Robust Controller Design Using Forgetting  Factors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tsuruhara%2C+S">Satoshi Tsuruhara</a>, 
<a href="/search/eess?searchtype=author&query=Ito%2C+K">Kazuhisa Ito</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to The 32nd Mediterranean Conference on Control and Automation (MED2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Adaptive FRIT (A-FRIT) with exponential forgetting (EF) has been proposed for
time-varying systems to improve the data dependence of FRIT, which is a direct
data-driven tuning method. However, the EF-based method is not a reliable
controller because it can cause significant degradation of the control
performance and instability unless the persistent excitation (PE) condition is
satisfied. To solve this problem, we propose a new A-FRIT method based on
directional forgetting (DF) and exponential resetting that can forget old data
without instability regardless of the PE condition. To confirm the
effectiveness of the proposed method, we applied it to artificial muscle
control with strong asymmetric hysteresis characteristics and evaluated its
robust performance against load changes during the experiment. The experimental
results show that the proposed method based on DF achieves high control
performance and is robust against changes in the characteristics and/or target
trajectory. The proposed method is also practical because it does not require
system identification, model structure, or prior experimentation.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00385" title="Abstract">arXiv:2402.00385</a> [<a href="/pdf/2402.00385" title="Download PDF">pdf</a>, <a href="/format/2402.00385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational Morphology and Lexicography Modeling of Modern Standard  Arabic Nominals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khairallah%2C+C">Christian Khairallah</a>, 
<a href="/search/cs?searchtype=author&query=Marzouk%2C+R">Reham Marzouk</a>, 
<a href="/search/cs?searchtype=author&query=Khalifa%2C+S">Salam Khalifa</a>, 
<a href="/search/cs?searchtype=author&query=Nassar%2C+M">Mayar Nassar</a>, 
<a href="/search/cs?searchtype=author&query=Habash%2C+N">Nizar Habash</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of the Association for Computational Linguistics: EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Modern Standard Arabic (MSA) nominals present many morphological and lexical
modeling challenges that have not been consistently addressed previously. This
paper attempts to define the space of such challenges, and leverage a recently
proposed morphological framework to build a comprehensive and extensible model
for MSA nominals. Our model design addresses the nominals' intricate
morphotactics, as well as their paradigmatic irregularities. Our implementation
showcases enhanced accuracy and consistency compared to a commonly used MSA
morphological analyzer and generator. We make our models publicly available.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00386" title="Abstract">arXiv:2402.00386</a> [<a href="/pdf/2402.00386" title="Download PDF">pdf</a>, <a href="/format/2402.00386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AssertLLM: Generating and Evaluating Hardware Verification Assertions  from Design Specifications via Multi-LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+W">Wenji Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengming Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Min Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhiyuan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongce Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhiyao Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Assertion-based verification (ABV) is a critical method for ensuring design
circuits comply with their architectural specifications, which are typically
described in natural language. This process often requires significant
interpretation by engineers to convert these specifications into functional
verification assertions. Existing methods for generating assertions from
natural language specifications are limited to sentences extracted by
engineers, discouraging the practical application. In this work, we present
AssertLLM, an automatic assertion generation framework for complete
specification files. AssertLLM breaks down the complex task into three phases,
incorporating three customized Large Language Models (LLMs) for extracting
structural specifications, mapping signal definitions, and generating
assertions. Additionally, we provide an open-source benchmark for assessing
assertion generation capabilities. Our evaluation of AssertLLM on a full
design, encompassing 23 signals, demonstrates that 89% of the generated
assertions are both syntactically and functionally accurate.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00388" title="Abstract">arXiv:2402.00388</a> [<a href="/pdf/2402.00388" title="Download PDF">pdf</a>, <a href="/format/2402.00388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cumulative Distribution Function based General Temporal Point Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Maolin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zenglin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Ruocheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wanyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zitao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Langming Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Temporal Point Processes (TPPs) hold a pivotal role in modeling event
sequences across diverse domains, including social networking and e-commerce,
and have significantly contributed to the advancement of recommendation systems
and information retrieval strategies. Through the analysis of events such as
user interactions and transactions, TPPs offer valuable insights into
behavioral patterns, facilitating the prediction of future trends. However,
accurately forecasting future events remains a formidable challenge due to the
intricate nature of these patterns. The integration of Neural Networks with
TPPs has ushered in the development of advanced deep TPP models. While these
models excel at processing complex and nonlinear temporal data, they encounter
limitations in modeling intensity functions, grapple with computational
complexities in integral computations, and struggle to capture long-range
temporal dependencies effectively. In this study, we introduce the CuFun model,
representing a novel approach to TPPs that revolves around the Cumulative
Distribution Function (CDF). CuFun stands out by uniquely employing a monotonic
neural network for CDF representation, utilizing past events as a scaling
factor. This innovation significantly bolsters the model's adaptability and
precision across a wide range of data scenarios. Our approach addresses several
critical issues inherent in traditional TPP modeling: it simplifies
log-likelihood calculations, extends applicability beyond predefined density
function forms, and adeptly captures long-range temporal patterns. Our
contributions encompass the introduction of a pioneering CDF-based TPP model,
the development of a methodology for incorporating past event information into
future event prediction, and empirical validation of CuFun's effectiveness
through extensive experimentation on synthetic and real-world datasets.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00390" title="Abstract">arXiv:2402.00390</a> [<a href="/pdf/2402.00390" title="Download PDF">pdf</a>, <a href="/format/2402.00390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EASRec: Elastic Architecture Search for Efficient Long-term Sequential  Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Maolin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+C">Chenyi Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjie Gu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Ruocheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zijian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this age where data is abundant, the ability to distill meaningful
insights from the sea of information is essential. Our research addresses the
computational and resource inefficiencies that current Sequential Recommender
Systems (SRSs) suffer from. especially those employing attention-based models
like SASRec, These systems are designed for next-item recommendations in
various applications, from e-commerce to social networks. However, such systems
suffer from substantial computational costs and resource consumption during the
inference stage. To tackle these issues, our research proposes a novel method
that combines automatic pruning techniques with advanced model architectures.
We also explore the potential of resource-constrained Neural Architecture
Search (NAS), a technique prevalent in the realm of recommendation systems, to
fine-tune models for reduced FLOPs, latency, and energy usage while retaining
or even enhancing accuracy. The main contribution of our work is developing the
Elastic Architecture Search for Efficient Long-term Sequential Recommender
Systems (EASRec). This approach aims to find optimal compact architectures for
attention-based SRSs, ensuring accuracy retention. EASRec introduces data-aware
gates that leverage historical information from input data batch to improve the
performance of the recommendation network. Additionally, it utilizes a dynamic
resource constraint approach, which standardizes the search process and results
in more appropriate architectures. The effectiveness of our methodology is
validated through exhaustive experiments on three benchmark datasets, which
demonstrates EASRec's superiority in SRSs. Our research set a new standard for
future exploration into efficient and accurate recommender systems, signifying
a substantial advancement within this swiftly advancing field.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00393" title="Abstract">arXiv:2402.00393</a> [<a href="/pdf/2402.00393" title="Download PDF">pdf</a>, <a href="/format/2402.00393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Loss Function Considering Dead Zone for Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Inami%2C+K">Koki Inami</a>, 
<a href="/search/cs?searchtype=author&query=Yamane%2C+K">Koki Yamane</a>, 
<a href="/search/cs?searchtype=author&query=Sakaino%2C+S">Sho Sakaino</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures, Accepted at AMC2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">It is important to reveal the inverse dynamics of manipulators to improve
control performance of model-based control. Neural networks (NNs) are promising
techniques to represent complicated inverse dynamics while they require a large
amount of motion data. However, motion data in dead zones of actuators is not
suitable for training models decreasing the number of useful training data. In
this study, based on the fact that the manipulator joint does not work
irrespective of input torque in dead zones, we propose a new loss function that
considers only errors of joints not in dead zones. The proposed method enables
to increase in the amount of motion data available for training and the
accuracy of the inverse dynamics computation. Experiments on actual equipment
using a three-degree-of-freedom (DOF) manipulator showed higher accuracy than
conventional methods. We also confirmed and discussed the behavior of the model
of the proposed method in dead zones.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00395" title="Abstract">arXiv:2402.00395</a> [<a href="/pdf/2402.00395" title="Download PDF">pdf</a>, <a href="/format/2402.00395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ONE-SA: Enabling Nonlinear Operations in Systolic Arrays for Efficient  and Flexible Neural Network Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Ruiqi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+Y">Yinchen Ni</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xin He</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+A">An Zou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to DATE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The computation and memory-intensive nature of DNNs limits their use in many
mobile and embedded contexts. Application-specific integrated circuit (ASIC)
hardware accelerators employ matrix multiplication units (such as the systolic
arrays) and dedicated nonlinear function units to speed up DNN computations. A
close examination of these ASIC accelerators reveals that the designs are often
specialized and lack versatility across different networks, especially when the
networks have different types of computation. In this paper, we introduce a
novel systolic array architecture, which is capable of executing nonlinear
functions. By encompassing both inherent linear and newly enabled nonlinear
functions within the systolic arrays, the proposed architecture facilitates
versatile network inferences, substantially enhancing computational power and
energy efficiency. Experimental results show that employing this systolic array
enables seamless execution of entire DNNs, incurring only a negligible loss in
the network inference accuracy. Furthermore, assessment and evaluation with
FPGAs reveal that integrating nonlinear computation capacity into a systolic
array does not introduce extra notable (less than 1.5%) block memory memories
(BRAMs), look-up-tables (LUTs), or digital signal processors (DSPs) but a mere
13.3% - 24.1% more flip flops (FFs). In comparison to existing methodologies,
executing the networks with the proposed systolic array, which enables the
flexibility of different network models, yields up to 25.73x, 5.21x, and 1.54x
computational efficiency when compared to general-purpose CPUs, GPUs, and SoCs
respectively, while achieving comparable (83.4% - 135.8%) performance with the
conventional accelerators which are designed for specific neural network
models.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00396" title="Abstract">arXiv:2402.00396</a> [<a href="/pdf/2402.00396" title="Download PDF">pdf</a>, <a href="/format/2402.00396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Exploration for LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dwaracherla%2C+V">Vikranth Dwaracherla</a>, 
<a href="/search/cs?searchtype=author&query=Asghari%2C+S+M">Seyed Mohammad Asghari</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+B">Botao Hao</a>, 
<a href="/search/cs?searchtype=author&query=Van+Roy%2C+B">Benjamin Van Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">We present evidence of substantial benefit from efficient exploration in
gathering human feedback to improve large language models. In our experiments,
an agent sequentially generates queries while fitting a reward model to the
feedback received. Our best-performing agent generates queries using double
Thompson sampling, with uncertainty represented by an epistemic neural network.
Our results demonstrate that efficient exploration enables high levels of
performance with far fewer queries. Further, both uncertainty estimation and
the choice of exploration scheme play critical roles.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00397" title="Abstract">arXiv:2402.00397</a> [<a href="/pdf/2402.00397" title="Download PDF">pdf</a>, <a href="/format/2402.00397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-scale Traffic Pattern Bank for Cross-city Few-shot Traffic  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhanyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+G">Guanjie Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yanwei Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review. Text overlap with <a href="/abs/2308.09727">arXiv:2308.09727</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Traffic forecasting is crucial for intelligent transportation systems (ITS),
aiding in efficient resource allocation and effective traffic control. However,
its effectiveness often relies heavily on abundant traffic data, while many
cities lack sufficient data due to limited device support, posing a significant
challenge for traffic forecasting. Recognizing this challenge, we have made a
noteworthy observation: traffic patterns exhibit similarities across diverse
cities. Building on this key insight, we propose a solution for the cross-city
few-shot traffic forecasting problem called Multi-scale Traffic Pattern Bank
(MTPB). Primarily, MTPB initiates its learning process by leveraging data-rich
source cities, effectively acquiring comprehensive traffic knowledge through a
spatial-temporal-aware pre-training process. Subsequently, the framework
employs advanced clustering techniques to systematically generate a multi-scale
traffic pattern bank derived from the learned knowledge. Next, the traffic data
of the data-scarce target city could query the traffic pattern bank,
facilitating the aggregation of meta-knowledge. This meta-knowledge, in turn,
assumes a pivotal role as a robust guide in subsequent processes involving
graph reconstruction and forecasting. Empirical assessments conducted on
real-world traffic datasets affirm the superior performance of MTPB, surpassing
existing methods across various categories and exhibiting numerous attributes
conducive to the advancement of cross-city few-shot forecasting methodologies.
The code is available in https://github.com/zhyliu00/MTPB.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00398" title="Abstract">arXiv:2402.00398</a> [<a href="/pdf/2402.00398" title="Download PDF">pdf</a>, <a href="/format/2402.00398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconfigurable Intelligent Computational Surfaces for MEC-Assisted  Autonomous Driving Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xueyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhiwen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xuelin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chongwen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Alexandropoulos%2C+G+C">George C. Alexandropoulos</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Debbah%2C+M">Merouane Debbah</a>, 
<a href="/search/cs?searchtype=author&query=Yuen%2C+C">Chau Yuen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we focus on improving autonomous driving safety via task
offloading from cellular vehicles (CVs), using vehicle-to-infrastructure (V2I)
links, to an multi-access edge computing (MEC) server. Considering that the
frequencies used for V2I links can be reused for vehicle-to-vehicle (V2V)
communications to improve spectrum utilization, the receiver of each V2I link
may suffer from severe interference, causing outages in the task offloading
process. To tackle this issue, we propose the deployment of a reconfigurable
intelligent computational surface (RICS) to enable, not only V2I reflective
links, but also interference cancellation at the V2V links exploiting the
computational capability of its metamaterials. We devise a joint optimization
formulation for the task offloading ratio between the CVs and the MEC server,
the spectrum sharing strategy between V2V and V2I communications, as well as
the RICS reflection and refraction matrices, with the objective to maximize a
safety-based autonomous driving task. Due to the non-convexity of the problem
and the coupling among its free variables, we transform it into a more
tractable equivalent form, which is then decomposed into three sub-problems and
solved via an alternate approximation method. Our simulation results
demonstrate the effectiveness of the proposed RICS optimization in improving
the safety in autonomous driving networks.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00399" title="Abstract">arXiv:2402.00399</a> [<a href="/pdf/2402.00399" title="Download PDF">pdf</a>, <a href="/format/2402.00399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous-time Trajectory Estimation: A Comparative Study Between  Gaussian Process and Spline-based Approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Johnson%2C+J">Jacob Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Mangelson%2C+J">Joshua Mangelson</a>, 
<a href="/search/cs?searchtype=author&query=Barfoot%2C+T">Timothy Barfoot</a>, 
<a href="/search/cs?searchtype=author&query=Beard%2C+R">Randal Beard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Continuous-time trajectory estimation is an attractive alternative to
discrete-time batch estimation due to the ability to incorporate high-frequency
measurements from asynchronous sensors while keeping the number of optimization
parameters bounded. Two types of continuous-time estimation have become
prevalent in the literature: Gaussian process regression and spline-based
estimation. In this paper, we present a direct comparison between these two
methods. We first compare them using a simple linear system, and then compare
them in a camera and IMU sensor fusion scenario on SE(3) in both simulation and
hardware. Our results show that if the same measurements and motion model are
used, the two methods achieve similar trajectory accuracy. In addition, if the
spline order is chosen so that the degree-of-differentiability of the two
trajectory representations match, then they achieve similar solve times as
well.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00402" title="Abstract">arXiv:2402.00402</a> [<a href="/pdf/2402.00402" title="Download PDF">pdf</a>, <a href="/format/2402.00402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Bias Representations in Llama 2 Chat via Activation  Steering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+D">Dawn Lu</a>, 
<a href="/search/cs?searchtype=author&query=Rimsky%2C+N">Nina Rimsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We address the challenge of societal bias in Large Language Models (LLMs),
focusing on the Llama 2 7B Chat model. As LLMs are increasingly integrated into
decision-making processes with substantial societal impact, it becomes
imperative to ensure these models do not reinforce existing biases. Our
approach employs activation steering to probe for and mitigate biases related
to gender, race, and religion. This method manipulates model activations to
direct responses towards or away from biased outputs, utilizing steering
vectors derived from the StereoSet dataset and custom GPT4 generated gender
bias prompts. Our findings reveal inherent gender bias in Llama 2 7B Chat,
persisting even after Reinforcement Learning from Human Feedback (RLHF). We
also observe a predictable negative correlation between bias and the model's
tendency to refuse responses. Significantly, our study uncovers that RLHF tends
to increase the similarity in the model's representation of different forms of
societal biases, which raises questions about the model's nuanced understanding
of different forms of bias. This work also provides valuable insights into
effective red-teaming strategies for LLMs using activation steering,
particularly emphasizing the importance of integrating a refusal vector.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00404" title="Abstract">arXiv:2402.00404</a> [<a href="/pdf/2402.00404" title="Download PDF">pdf</a>, <a href="/format/2402.00404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Critical Node Detection Using Neural Network-based  Initialization in a Genetic Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chanjuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+S">Shike Ge</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhihan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+W">Wenbin Pei</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+E">Enqiang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+Y">Yi Mei</a>, 
<a href="/search/cs?searchtype=author&query=Ishibuchi%2C+H">Hisao Ishibuchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">The Critical Node Problem (CNP) is concerned with identifying the critical
nodes in a complex network. These nodes play a significant role in maintaining
the connectivity of the network, and removing them can negatively impact
network performance. CNP has been studied extensively due to its numerous
real-world applications. Among the different versions of CNP, CNP-1a has gained
the most popularity. The primary objective of CNP-1a is to minimize the
pair-wise connectivity in the remaining network after deleting a limited number
of nodes from a network. Due to the NP-hard nature of CNP-1a, many
heuristic/metaheuristic algorithms have been proposed to solve this problem.
However, most existing algorithms start with a random initialization, leading
to a high cost of obtaining an optimal solution. To improve the efficiency of
solving CNP-1a, a knowledge-guided genetic algorithm named K2GA has been
proposed. Unlike the standard genetic algorithm framework, K2GA has two main
components: a pretrained neural network to obtain prior knowledge on possible
critical nodes, and a hybrid genetic algorithm with local search for finding an
optimal set of critical nodes based on the knowledge given by the trained
neural network. The local search process utilizes a cut node-based greedy
strategy. The effectiveness of the proposed knowledgeguided genetic algorithm
is verified by experiments on 26 realworld instances of complex networks.
Experimental results show that K2GA outperforms the state-of-the-art algorithms
regarding the best, median, and average objective values, and improves the best
upper bounds on the best objective values for eight realworld instances.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00407" title="Abstract">arXiv:2402.00407</a> [<a href="/pdf/2402.00407" title="Download PDF">pdf</a>, <a href="/format/2402.00407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InfMAE: A Foundation Model in Infrared Modality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fangcen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chenqiang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yaming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Junjie Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+D">Deyu Meng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, the foundation models have swept the computer vision field
and facilitated the development of various tasks within different modalities.
However, it remains an open question on how to design an infrared foundation
model. In this paper, we propose InfMAE, a foundation model in infrared
modality. We release an infrared dataset, called Inf30 to address the problem
of lacking large-scale data for self-supervised learning in the infrared vision
community. Besides, we design an information-aware masking strategy, which is
suitable for infrared images. This masking strategy allows for a greater
emphasis on the regions with richer information in infrared images during the
self-supervised learning process, which is conducive to learning the
generalized representation. In addition, we adopt a multi-scale encoder to
enhance the performance of the pre-trained encoders in downstream tasks.
Finally, based on the fact that infrared images do not have a lot of details
and texture information, we design an infrared decoder module, which further
improves the performance of downstream tasks. Extensive experiments show that
our proposed method InfMAE outperforms other supervised methods and
self-supervised learning methods in three downstream tasks. Our code will be
made public at https://github.com/liufangcen/InfMAE.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00409" title="Abstract">arXiv:2402.00409</a> [<a href="/pdf/2402.00409" title="Download PDF">pdf</a>, <a href="/ps/2402.00409" title="Download PostScript">ps</a>, <a href="/format/2402.00409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Complexity of Interpolation by Polynomials with Non-negative Real  Coefficients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bando%2C+K">Katsuyuki Bando</a>, 
<a href="/search/math?searchtype=author&query=Ken%2C+E">Eitetsu Ken</a>, 
<a href="/search/math?searchtype=author&query=Onuki%2C+H">Hirotaka Onuki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, one figure and three algorithms, submitted to ISSAC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we consider interpolation by \textit{completely monotonous}
polynomials (CMPs for short), that is, polynomials with non-negative real
coefficients. In particular, given a finite set $S\subset \mathbb{R}_{&gt;0}
\times \mathbb{R}_{\geq 0}$, we consider \textit{the minimal polynomial} of
$S$, introduced by Berg [1985], which is `minimal,' in the sense that it is
eventually majorized by all the other CMPs interpolating $S$. We give an upper
bound of the degree of the minimal polynomial of $S$ when it exists.
Furthermore, we give another algorithm for computing the minimal polynomial of
given $S$ which utilizes an order structure on sign sequences. Applying the
upper bound above, we also analyze the computational complexity of algorithms
for computing minimal polynomials including ours.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00411" title="Abstract">arXiv:2402.00411</a> [<a href="/pdf/2402.00411" title="Download PDF">pdf</a>, <a href="/format/2402.00411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LM-HT SNN: Enhancing the Performance of SNN to ANN Counterpart through  Learnable Multi-hierarchical Threshold Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+Z">Zecheng Hao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xinyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhiyu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yujia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhaofei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tiejun Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Compared to traditional Artificial Neural Network (ANN), Spiking Neural
Network (SNN) has garnered widespread academic interest for its intrinsic
ability to transmit information in a more biological-inspired and
energy-efficient manner. However, despite previous efforts to optimize the
learning gradients and model structure of SNNs through various methods, SNNs
still lag behind ANNs in terms of performance to some extent. The recently
proposed multi-threshold model provides more possibilities for further
enhancing the learning capability of SNNs. In this paper, we rigorously analyze
the relationship among the multi-threshold model, vanilla spiking model and
quantized ANNs from a mathematical perspective, then propose a novel LM-HT
model, which is an equidistant multi-hierarchical model that can dynamically
regulate the global input current and membrane potential leakage on the time
dimension. In addition, we note that the direct training algorithm based on the
LM-HT model can seamlessly integrate with the traditional ANN-SNN Conversion
framework. This novel hybrid learning framework can effectively improve the
relatively poor performance of converted SNNs under low time latency. Extensive
experimental results have demonstrated that our LM-HT model can significantly
outperform previous state-of-the-art works on various types of datasets, which
promote SNNs to achieve a brand-new level of performance comparable to
quantized ANNs.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00412" title="Abstract">arXiv:2402.00412</a> [<a href="/pdf/2402.00412" title="Download PDF">pdf</a>, <a href="/format/2402.00412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hidding the Ghostwriters: An Adversarial Evaluation of AI-Generated  Student Essay Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xinlin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Ying Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Ben He</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Le Sun</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yingfei Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023 Main conference, Oral Presentation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have exhibited remarkable capabilities in text
generation tasks. However, the utilization of these models carries inherent
risks, including but not limited to plagiarism, the dissemination of fake news,
and issues in educational exercises. Although several detectors have been
proposed to address these concerns, their effectiveness against adversarial
perturbations, specifically in the context of student essay writing, remains
largely unexplored. This paper aims to bridge this gap by constructing
AIG-ASAP, an AI-generated student essay dataset, employing a range of text
perturbation methods that are expected to generate high-quality essays while
evading detection. Through empirical experiments, we assess the performance of
current AIGC detectors on the AIG-ASAP dataset. The results reveal that the
existing detectors can be easily circumvented using straightforward automatic
adversarial attacks. Specifically, we explore word substitution and sentence
substitution perturbation methods that effectively evade detection while
maintaining the quality of the generated essays. This highlights the urgent
need for more accurate and robust methods to detect AI-generated student essays
in the education domain.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00414" title="Abstract">arXiv:2402.00414</a> [<a href="/pdf/2402.00414" title="Download PDF">pdf</a>, <a href="/format/2402.00414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt-Time Symbolic Knowledge Capture with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%87%C3%B6pl%C3%BC%2C+T">Tolga &#xc7;&#xf6;pl&#xfc;</a>, 
<a href="/search/cs?searchtype=author&query=Bendiken%2C+A">Arto Bendiken</a>, 
<a href="/search/cs?searchtype=author&query=Skomorokhov%2C+A">Andrii Skomorokhov</a>, 
<a href="/search/cs?searchtype=author&query=Bateiko%2C+E">Eduard Bateiko</a>, 
<a href="/search/cs?searchtype=author&query=Cobb%2C+S">Stephen Cobb</a>, 
<a href="/search/cs?searchtype=author&query=Bouw%2C+J+J">Joshua J. Bouw</a> (Haltia, Inc.)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, 1 table preprint. Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Augmenting large language models (LLMs) with user-specific knowledge is
crucial for real-world applications, such as personal AI assistants. However,
LLMs inherently lack mechanisms for prompt-driven knowledge capture. This paper
investigates utilizing the existing LLM capabilities to enable prompt-driven
knowledge capture, with a particular emphasis on knowledge graphs. We address
this challenge by focusing on prompt-to-triple (P2T) generation. We explore
three methods: zero-shot prompting, few-shot prompting, and fine-tuning, and
then assess their performance via a specialized synthetic dataset. Our code and
datasets are publicly available at https://github.com/HaltiaAI/paper-PTSKC.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00418" title="Abstract">arXiv:2402.00418</a> [<a href="/pdf/2402.00418" title="Download PDF">pdf</a>, <a href="/ps/2402.00418" title="Download PostScript">ps</a>, <a href="/format/2402.00418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Short: Benchmarking transferable adversarial attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhibo Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiayu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhiyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huaming Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NDSS 2024 Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The robustness of deep learning models against adversarial attacks remains a
pivotal concern. This study presents, for the first time, an exhaustive review
of the transferability aspect of adversarial attacks. It systematically
categorizes and critically evaluates various methodologies developed to augment
the transferability of adversarial attacks. This study encompasses a spectrum
of techniques, including Generative Structure, Semantic Similarity, Gradient
Editing, Target Modification, and Ensemble Approach. Concurrently, this paper
introduces a benchmark framework \textit{TAA-Bench}, integrating ten leading
methodologies for adversarial attack transferability, thereby providing a
standardized and systematic platform for comparative analysis across diverse
model architectures. Through comprehensive scrutiny, we delineate the efficacy
and constraints of each method, shedding light on their underlying operational
principles and practical utility. This review endeavors to be a quintessential
resource for both scholars and practitioners in the field, charting the complex
terrain of adversarial transferability and setting a foundation for future
explorations in this vital sector. The associated codebase is accessible at:
https://github.com/KxPlaug/TAA-Bench
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00421" title="Abstract">arXiv:2402.00421</a> [<a href="/pdf/2402.00421" title="Download PDF">pdf</a>, <a href="/format/2402.00421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From PARIS to LE-PARIS: Toward Patent Response Automation with  Recommender Systems and Collaborative Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+J">Jung-Mei Chu</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+H">Hao-Cheng Lo</a>, 
<a href="/search/cs?searchtype=author&query=Hsiang%2C+J">Jieh Hsiang</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+C">Chun-Chieh Cho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures, summitted to a journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">In patent prosecution, timely and effective responses to Office Actions (OAs)
are crucial for acquiring patents, yet past automation and AI research have
scarcely addressed this aspect. To address this gap, our study introduces the
Patent Office Action Response Intelligence System (PARIS) and its advanced
version, the Large Language Model Enhanced PARIS (LE-PARIS). These systems are
designed to expedite the efficiency of patent attorneys in collaboratively
handling OA responses. The systems' key features include the construction of an
OA Topics Database, development of Response Templates, and implementation of
Recommender Systems and LLM-based Response Generation. Our validation involves
a multi-paradigmatic analysis using the USPTO Office Action database and
longitudinal data of attorney interactions with our systems over six years.
Through five studies, we examine the constructiveness of OA topics (studies 1
and 2) using topic modeling and the proposed Delphi process, the efficacy of
our proposed hybrid recommender system tailored for OA (both LLM-based and
non-LLM-based) (study 3), the quality of response generation (study 4), and the
practical value of the systems in real-world scenarios via user studies (study
5). Results demonstrate that both PARIS and LE-PARIS significantly meet key
metrics and positively impact attorney performance.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00422" title="Abstract">arXiv:2402.00422</a> [<a href="/pdf/2402.00422" title="Download PDF">pdf</a>, <a href="/format/2402.00422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightweight Pixel Difference Networks for Efficient Visual  Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Z">Zhuo Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiehua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Longguang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pietik%C3%A4inen%2C+M">Matti Pietik&#xe4;inen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Li Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We design a novel lightweight convolutional operator for computer vision tasks. Both full-precision networks and BNNs are developed. Accepted by TPAMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, there have been tremendous efforts in developing lightweight Deep
Neural Networks (DNNs) with satisfactory accuracy, which can enable the
ubiquitous deployment of DNNs in edge devices. The core challenge of developing
compact and efficient DNNs lies in how to balance the competing goals of
achieving high accuracy and high efficiency. In this paper we propose two novel
types of convolutions, dubbed \emph{Pixel Difference Convolution (PDC) and
Binary PDC (Bi-PDC)} which enjoy the following benefits: capturing higher-order
local differential information, computationally efficient, and able to be
integrated with existing DNNs. With PDC and Bi-PDC, we further present two
lightweight deep networks named \emph{Pixel Difference Networks (PiDiNet)} and
\emph{Binary PiDiNet (Bi-PiDiNet)} respectively to learn highly efficient yet
more accurate representations for visual tasks including edge detection and
object recognition. Extensive experiments on popular datasets (BSDS500,
ImageNet, LFW, YTF, \emph{etc.}) show that PiDiNet and Bi-PiDiNet achieve the
best accuracy-efficiency trade-off. For edge detection, PiDiNet is the first
network that can be trained without ImageNet, and can achieve the human-level
performance on BSDS500 at 100 FPS and with $&lt;$1M parameters. For object
recognition, among existing Binary DNNs, Bi-PiDiNet achieves the best accuracy
and a nearly $2\times$ reduction of computational cost on ResNet18. Code
available at
\href{https://github.com/hellozhuo/pidinet}{https://github.com/hellozhuo/pidinet}.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00424" title="Abstract">arXiv:2402.00424</a> [<a href="/pdf/2402.00424" title="Download PDF">pdf</a>, <a href="/format/2402.00424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reproducibility of Build Environments through Space and Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malka%2C+J">Julien Malka</a> (IP Paris, LTCI, ACES), 
<a href="/search/cs?searchtype=author&query=Zacchiroli%2C+S">Stefano Zacchiroli</a> (IP Paris, LTCI, ACES), 
<a href="/search/cs?searchtype=author&query=Zimmermann%2C+T">Th&#xe9;o Zimmermann</a> (ACES, INFRES, IP Paris)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46th International Conference on Software Engineering (ICSE 2024) - New Ideas and Emerging Results (NIER) Track, Apr 2024, Lisbonne, Portugal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Modern software engineering builds up on the composability of software
components, that rely on more and more direct and transitive dependencies to
build their functionalities. This principle of reusability however makes it
harder to reproduce projects' build environments, even though reproducibility
of build environments is essential for collaboration, maintenance and component
lifetime. In this work, we argue that functional package managers provide the
tooling to make build environments reproducible in space and time, and we
produce a preliminary evaluation to justify this claim. Using historical data,
we show that we are able to reproduce build environments of about 7 million Nix
packages, and to rebuild 99.94% of the 14 thousand packages from a 6-year-old
Nixpkgs revision.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00425" title="Abstract">arXiv:2402.00425</a> [<a href="/pdf/2402.00425" title="Download PDF">pdf</a>, <a href="/ps/2402.00425" title="Download PostScript">ps</a>, <a href="/format/2402.00425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Genetic Programming Theory and Practice: A Fifteen-Year Trajectory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sipper%2C+M">Moshe Sipper</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+J+H">Jason H. Moore</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Genetic Programming and Evolvable Machines (2020) 21:169-179
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">The GPTP workshop series, which began in 2003, has served over the years as a
focal meeting for genetic programming (GP) researchers. As such, we think it
provides an excellent source for studying the development of GP over the past
fifteen years. We thus present herein a trajectory of the thematic developments
in the field of GP.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00433" title="Abstract">arXiv:2402.00433</a> [<a href="/pdf/2402.00433" title="Download PDF">pdf</a>, <a href="/format/2402.00433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Merging Multi-Task Models via Weight-Ensembling Mixture of Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+A">Anke Tang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+N">Nan Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lefei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Merging various task-specific Transformer-based models trained on different
tasks into a single unified model can execute all the tasks concurrently.
Previous methods, exemplified by task arithmetic, have been proven to be both
effective and scalable. Existing methods have primarily focused on seeking a
static optimal solution within the original model parameter space. A notable
challenge is mitigating the interference between parameters of different
models, which can substantially deteriorate performance. In this paper, we
propose to merge most of the parameters while upscaling the MLP of the
Transformer layers to a weight-ensembling mixture of experts (MoE) module,
which can dynamically integrate shared and task-specific knowledge based on the
input, thereby providing a more flexible solution that can adapt to the
specific needs of each instance. Our key insight is that by identifying and
separating shared knowledge and task-specific knowledge, and then dynamically
integrating them, we can mitigate the parameter interference problem to a great
extent. We conduct the conventional multi-task model merging experiments and
evaluate the generalization and robustness of our method. The results
demonstrate the effectiveness of our method and provide a comprehensive
understanding of our method. The code is available at
https://anonymous.4open.science/r/weight-ensembling_MoE-67C9/
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00435" title="Abstract">arXiv:2402.00435</a> [<a href="/pdf/2402.00435" title="Download PDF">pdf</a>, <a href="/format/2402.00435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A practical existence theorem for reduced order models based on  convolutional autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Franco%2C+N+R">Nicola Rares Franco</a>, 
<a href="/search/math?searchtype=author&query=Brugiapaglia%2C+S">Simone Brugiapaglia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, deep learning has gained increasing popularity in the fields
of Partial Differential Equations (PDEs) and Reduced Order Modeling (ROM),
providing domain practitioners with new powerful data-driven techniques such as
Physics-Informed Neural Networks (PINNs), Neural Operators, Deep Operator
Networks (DeepONets) and Deep-Learning based ROMs (DL-ROMs). In this context,
deep autoencoders based on Convolutional Neural Networks (CNNs) have proven
extremely effective, outperforming established techniques, such as the reduced
basis method, when dealing with complex nonlinear problems. However, despite
the empirical success of CNN-based autoencoders, there are only a few
theoretical results supporting these architectures, usually stated in the form
of universal approximation theorems. In particular, although the existing
literature provides users with guidelines for designing convolutional
autoencoders, the subsequent challenge of learning the latent features has been
barely investigated. Furthermore, many practical questions remain unanswered,
e.g., the number of snapshots needed for convergence or the neural network
training strategy. In this work, using recent techniques from sparse
high-dimensional function approximation, we fill some of these gaps by
providing a new practical existence theorem for CNN-based autoencoders when the
parameter-to-solution map is holomorphic. This regularity assumption arises in
many relevant classes of parametric PDEs, such as the parametric diffusion
equation, for which we discuss an explicit application of our general theory.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00438" title="Abstract">arXiv:2402.00438</a> [<a href="/pdf/2402.00438" title="Download PDF">pdf</a>, <a href="/format/2402.00438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The GREENBOT dataset: Multimodal mobile robotic dataset for a typical  Mediterranean greenhouse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ca%C3%B1adas-Ar%C3%A1nega%2C+F">Fernando Ca&#xf1;adas-Ar&#xe1;nega</a>, 
<a href="/search/cs?searchtype=author&query=Blanco-Claraco%2C+J+L">Jose Luis Blanco-Claraco</a>, 
<a href="/search/cs?searchtype=author&query=Moreno%2C+J+C">Jose Carlos Moreno</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+F">Francisco Rodriguez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper introduces an innovative dataset specifically crafted for
challenging agricultural settings (a greenhouse), where achieving precise
localization is of paramount importance. The dataset was gathered using a
mobile platform equipped with a set of sensors typically used in mobile robots,
as it was moved through all the corridors of a typical Mediterranean greenhouse
featuring tomato crop. This dataset presents a unique opportunity for
constructing detailed 3D models of plants in such indoor-like space, with
potential applications such as robotized spraying. For the first time to the
best knowledge of authors, a dataset suitable to put at test Simultaneous
Localization and Mapping (SLAM) methods is presented in a greenhouse
environment, which poses unique challenges. The suitability of the dataset for
such goal is assessed by presenting SLAM results with state-of-the-art
algorithms. The dataset is available online in
\url{https://arm.ual.es/arm-group/dataset-greenhouse-2024/}.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00442" title="Abstract">arXiv:2402.00442</a> [<a href="/pdf/2402.00442" title="Download PDF">pdf</a>, <a href="/format/2402.00442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Responsible developments and networking research: a reflection beyond a  paper ethical statement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tuncer%2C+D">Daphne Tuncer</a>, 
<a href="/search/cs?searchtype=author&query=Bruyere%2C+M">Marc Bruyere</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Several recent initiatives have proposed new directions for research
practices and their operations in the computer science community, from updated
codes of conduct that clarify the use of AI-assisted tools to the inclusion of
ethical statements and the organization of working groups on the environmental
footprint of digitalization. In this position paper, we focus on the specific
case of networking research. We reflect on the technical realization of the
community and its incidence beyond techno-centric contributions. In particular,
we structure the discussion around two frameworks that were recently developed
in different contexts to describe the sense of engagement and responsibilities
to which the practitioner of a computing-related area may be confronted.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00444" title="Abstract">arXiv:2402.00444</a> [<a href="/pdf/2402.00444" title="Download PDF">pdf</a>, <a href="/ps/2402.00444" title="Download PostScript">ps</a>, <a href="/format/2402.00444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Genetic Algorithms through the Approximability Hierarchy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mu%C3%B1oz%2C+A">Alba Mu&#xf1;oz</a>, 
<a href="/search/cs?searchtype=author&query=Rubio%2C+F">Fernando Rubio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 1 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Elsevier, Journal of Computational Science 2021,
  https://www.sciencedirect.com/science/article/pii/S1877750321000764
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Optimization problems frequently appear in any scientific domain. Most of the
times, the corresponding decision problem turns out to be NP-hard, and in these
cases genetic algorithms are often used to obtain approximated solutions.
However, the difficulty to approximate different NP-hard problems can vary a
lot. In this paper, we analyze the usefulness of using genetic algorithms
depending on the approximation class the problem belongs to. In particular, we
use the standard approximability hierarchy, showing that genetic algorithms are
especially useful for the most pessimistic classes of the hierarchy
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00446" title="Abstract">arXiv:2402.00446</a> [<a href="/pdf/2402.00446" title="Download PDF">pdf</a>, <a href="/format/2402.00446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Dialog Safety using Socially Aware Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Souvik Das</a>, 
<a href="/search/cs?searchtype=author&query=Srihari%2C+R+K">Rohini K. Srihari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SCI-CHAT@EACL2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">State-of-the-art conversational AI systems raise concerns due to their
potential risks of generating unsafe, toxic, unethical, or dangerous content.
Previous works have developed datasets to teach conversational agents the
appropriate social paradigms to respond effectively to specifically designed
hazardous content. However, models trained on these adversarial datasets still
struggle to recognize subtle unsafe situations that appear naturally in
conversations or introduce an inappropriate response in a casual context. To
understand the extent of this problem, we study prosociality in both
adversarial and casual dialog contexts and audit the response quality of
general-purpose language models in terms of propensity to produce unsafe
content. We propose a dual-step fine-tuning process to address these issues
using a socially aware n-pair contrastive loss. Subsequently, we train a base
model that integrates prosocial behavior by leveraging datasets like Moral
Integrity Corpus (MIC) and ProsocialDialog. Experimental results on several
dialog datasets demonstrate the effectiveness of our approach in generating
socially appropriate responses.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00447" title="Abstract">arXiv:2402.00447</a> [<a href="/pdf/2402.00447" title="Download PDF">pdf</a>, <a href="/ps/2402.00447" title="Download PostScript">ps</a>, <a href="/format/2402.00447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Data-Efficient Graph Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ju%2C+W">Wei Ju</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+S">Siyu Yi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+Q">Qingqing Long</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Junyu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zhiping Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph-structured data, prevalent in domains ranging from social networks to
biochemical analysis, serve as the foundation for diverse real-world systems.
While graph neural networks demonstrate proficiency in modeling this type of
data, their success is often reliant on significant amounts of labeled data,
posing a challenge in practical scenarios with limited annotation resources. To
tackle this problem, tremendous efforts have been devoted to enhancing graph
machine learning performance under low-resource settings by exploring various
approaches to minimal supervision. In this paper, we introduce a novel concept
of Data-Efficient Graph Learning (DEGL) as a research frontier, and present the
first survey that summarizes the current progress of DEGL. We initiate by
highlighting the challenges inherent in training models with large labeled
data, paving the way for our exploration into DEGL. Next, we systematically
review recent advances on this topic from several key aspects, including
self-supervised graph learning, semi-supervised graph learning, and few-shot
graph learning. Also, we state promising directions for future research,
contributing to the evolution of graph machine learning.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00448" title="Abstract">arXiv:2402.00448</a> [<a href="/pdf/2402.00448" title="Download PDF">pdf</a>, <a href="/format/2402.00448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-Student Knowledge Distillation Networks for Unsupervised Anomaly  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Liyi Yao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shaobing Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Due to the data imbalance and the diversity of defects, student-teacher
networks (S-T) are favored in unsupervised anomaly detection, which explores
the discrepancy in feature representation derived from the knowledge
distillation process to recognize anomalies. However, vanilla S-T network is
not stable. Employing identical structures to construct the S-T network may
weaken the representative discrepancy on anomalies. But using different
structures can increase the likelihood of divergent performance on normal data.
To address this problem, we propose a novel dual-student knowledge distillation
(DSKD) architecture. Different from other S-T networks, we use two student
networks a single pre-trained teacher network, where the students have the same
scale but inverted structures. This framework can enhance the distillation
effect to improve the consistency in recognition of normal data, and
simultaneously introduce diversity for anomaly representation. To explore
high-dimensional semantic information to capture anomaly clues, we employ two
strategies. First, a pyramid matching mode is used to perform knowledge
distillation on multi-scale feature maps in the intermediate layers of
networks. Second, an interaction is facilitated between the two student
networks through a deep feature embedding module, which is inspired by
real-world group discussions. In terms of classification, we obtain pixel-wise
anomaly segmentation maps by measuring the discrepancy between the output
feature maps of the teacher and student networks, from which an anomaly score
is computed for sample-wise determination. We evaluate DSKD on three benchmark
datasets and probe the effects of internal modules through ablation
experiments. The results demonstrate that DSKD can achieve exceptional
performance on small models like ResNet18 and effectively improve vanilla S-T
networks.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00449" title="Abstract">arXiv:2402.00449</a> [<a href="/pdf/2402.00449" title="Download PDF">pdf</a>, <a href="/format/2402.00449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Training Spiking Neural Networks with Parallel Spiking Unit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yinqian Sun</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiang He</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yiting Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongcheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yi Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Efficient parallel computing has become a pivotal element in advancing
artificial intelligence. Yet, the deployment of Spiking Neural Networks (SNNs)
in this domain is hampered by their inherent sequential computational
dependency. This constraint arises from the need for each time step's
processing to rely on the preceding step's outcomes, significantly impeding the
adaptability of SNN models to massively parallel computing environments.
Addressing this challenge, our paper introduces the innovative Parallel Spiking
Unit (PSU) and its two derivatives, the Input-aware PSU (IPSU) and Reset-aware
PSU (RPSU). These variants skillfully decouple the leaky integration and firing
mechanisms in spiking neurons while probabilistically managing the reset
process. By preserving the fundamental computational attributes of the spiking
neuron model, our approach enables the concurrent computation of all membrane
potential instances within the SNN, facilitating parallel spike output
generation and substantially enhancing computational efficiency. Comprehensive
testing across various datasets, including static and sequential images,
Dynamic Vision Sensor (DVS) data, and speech datasets, demonstrates that the
PSU and its variants not only significantly boost performance and simulation
speed but also augment the energy efficiency of SNNs through enhanced sparsity
in neural activity. These advancements underscore the potential of our method
in revolutionizing SNN deployment for high-performance parallel computing
applications.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00450" title="Abstract">arXiv:2402.00450</a> [<a href="/pdf/2402.00450" title="Download PDF">pdf</a>, <a href="/format/2402.00450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CPT: Competence-progressive Training Strategy for Few-shot Node  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qilong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yufeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinghao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Jingpu Duan</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jian Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2206.11972">arXiv:2206.11972</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph Neural Networks (GNNs) have made significant advancements in node
classification, but their success relies on sufficient labeled nodes per class
in the training data. Real-world graph data often exhibits a long-tail
distribution with sparse labels, emphasizing the importance of GNNs' ability in
few-shot node classification, which entails categorizing nodes with limited
data. Traditional episodic meta-learning approaches have shown promise in this
domain, but they face an inherent limitation: it might lead the model to
converge to suboptimal solutions because of random and uniform task assignment,
ignoring task difficulty levels. This could lead the meta-learner to face
complex tasks too soon, hindering proper learning. Ideally, the meta-learner
should start with simple concepts and advance to more complex ones, like human
learning. So, we introduce CPT, a novel two-stage curriculum learning method
that aligns task difficulty with the meta-learner's progressive competence,
enhancing overall performance. Specifically, in CPT's initial stage, the focus
is on simpler tasks, fostering foundational skills for engaging with complex
tasks later. Importantly, the second stage dynamically adjusts task difficulty
based on the meta-learner's growing competence, aiming for optimal knowledge
acquisition. Extensive experiments on popular node classification datasets
demonstrate significant improvements of our strategy over existing methods.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00452" title="Abstract">arXiv:2402.00452</a> [<a href="/pdf/2402.00452" title="Download PDF">pdf</a>, <a href="/ps/2402.00452" title="Download PostScript">ps</a>, <a href="/format/2402.00452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hoare Logic for Domain Specification (Full Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kamburjan%2C+E">Eduard Kamburjan</a>, 
<a href="/search/cs?searchtype=author&query=Gurov%2C+D">Dilian Gurov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Programs must be correct with respect to their application domain. Yet, the
program specification and verification approaches so far only consider
correctness in terms of computations. In this work, we present a two-tier Hoare
Logic that integrates assertions for both implementation and domain. For domain
specification, we use description logics and semantic lifting, a recently
proposed approach to interpret a program as a knowledge graph. We present a
calculus that uses translations between both kinds of assertions, thus
separating the concerns in specification, but enabling the use of description
logic in verification.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00453" title="Abstract">arXiv:2402.00453</a> [<a href="/pdf/2402.00453" title="Download PDF">pdf</a>, <a href="/format/2402.00453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instruction Makes a Difference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adewumi%2C+T">Tosin Adewumi</a>, 
<a href="/search/cs?searchtype=author&query=Habib%2C+N">Nudrat Habib</a>, 
<a href="/search/cs?searchtype=author&query=Alkhaled%2C+L">Lama Alkhaled</a>, 
<a href="/search/cs?searchtype=author&query=Barney%2C+E">Elisa Barney</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">We introduce Instruction Document Visual Question Answering (iDocVQA) dataset
and Large Language Document (LLaDoc) model, for training Language-Vision (LV)
models for document analysis and predictions on document images, respectively.
Usually, deep neural networks for the DocVQA task are trained on datasets
lacking instructions. We show that using instruction-following datasets
improves performance. We compare performance across document-related datasets
using the recent state-of-the-art (SotA) Large Language and Vision Assistant
(LLaVA)1.5 as the base model. We also evaluate the performance of the derived
models for object hallucination using the Polling-based Object Probing
Evaluation (POPE) dataset. The results show that instruction-tuning performance
ranges from 11X to 32X of zero-shot performance and from 0.1% to 4.2% over
non-instruction (traditional task) finetuning. Despite the gains, these still
fall short of human performance (94.36%), implying there's much room for
improvement.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00454" title="Abstract">arXiv:2402.00454</a> [<a href="/pdf/2402.00454" title="Download PDF">pdf</a>, <a href="/format/2402.00454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Crowdfunding of Public Projects Under Dynamic Beliefs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Damle%2C+S">Sankarshan Damle</a>, 
<a href="/search/cs?searchtype=author&query=Gujar%2C+S">Sujit Gujar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAMAS '24 (Extended Abstract)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">In the last decade, social planners have used crowdfunding to raise funds for
public projects. As these public projects are non-excludable, the beneficiaries
may free-ride. Thus, there is a need to design incentive mechanisms for such
strategic agents to contribute to the project. The existing mechanisms, like
PPR or PPRx, assume that the agent's beliefs about the project getting funded
do not change over time, i.e., their beliefs are static. Researchers highlight
that unless appropriately incentivized, the agents defer their contributions in
static settings, leading to a ``race'' to contribute at the deadline. In this
work, we model the evolution of agents' beliefs as a random walk. We study PPRx
-- an existing mechanism for the static belief setting -- in this dynamic
belief setting and refer to it as PPRx-DB for readability. We prove that in
PPRx-DB, the project is funded at equilibrium. More significantly, we prove
that under certain conditions on agent's belief evolution, agents will
contribute as soon as they arrive at the mechanism. Thus, we believe that by
incorporating dynamic belief evolution in analysis, the social planner can
mitigate the concern of race conditions in many mechanisms.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00455" title="Abstract">arXiv:2402.00455</a> [<a href="/pdf/2402.00455" title="Download PDF">pdf</a>, <a href="/ps/2402.00455" title="Download PostScript">ps</a>, <a href="/format/2402.00455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Lower Bounds on Aperiodic Ambiguity Function of Unimodular Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+L">Lingsheng Meng</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Y+L">Yong Liang Guan</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zilong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+P">Pingzhi Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper presents new aperiodic ambiguity function (AF) lower bounds of
unimodular sequences under certain low ambiguity zone. Our key idea, motivated
by the Levenshtein correlation bound, is to introduce two weight vectors
associated to the delay and Doppler shifts, respectively, and then exploit the
upper and lower bounds on the Frobenius norm of the weighted auto- and cross-AF
matrices to derive these bounds. Furthermore, the inherent structure properties
of aperiodic AF are also utilized in our derivation. The derived bounds are
useful design guidelines for optimal AF shaping in modern communication and
radar systems.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00459" title="Abstract">arXiv:2402.00459</a> [<a href="/pdf/2402.00459" title="Download PDF">pdf</a>, <a href="/format/2402.00459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Genetic-based Constraint Programming for Resource Constrained Job  Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+S">Su Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Thiruvady%2C+D">Dhananjay Thiruvady</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengjie Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Resource constrained job scheduling is a hard combinatorial optimisation
problem that originates in the mining industry. Off-the-shelf solvers cannot
solve this problem satisfactorily in reasonable timeframes, while other
solution methods such as many evolutionary computation methods and
matheuristics cannot guarantee optimality and require low-level customisation
and specialised heuristics to be effective. This paper addresses this gap by
proposing a genetic programming algorithm to discover efficient search
strategies of constraint programming for resource-constrained job scheduling.
In the proposed algorithm, evolved programs represent variable selectors to be
used in the search process of constraint programming, and their fitness is
determined by the quality of solutions obtained for training instances. The
novelties of this algorithm are (1) a new representation of variable selectors,
(2) a new fitness evaluation scheme, and (3) a pre-selection mechanism. Tests
with a large set of random and benchmark instances, the evolved variable
selectors can significantly improve the efficiency of constraining programming.
Compared to highly customised metaheuristics and hybrid algorithms, evolved
variable selectors can help constraint programming identify quality solutions
faster and proving optimality is possible if sufficiently large run-times are
allowed. The evolved variable selectors are especially helpful when solving
instances with large numbers of machines.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00462" title="Abstract">arXiv:2402.00462</a> [<a href="/pdf/2402.00462" title="Download PDF">pdf</a>, <a href="/format/2402.00462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Management Challenges in Agile Software Projects: A Systematic  Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fawzy%2C+A">Ahmed Fawzy</a>, 
<a href="/search/cs?searchtype=author&query=Tahir%2C+A">Amjed Tahir</a>, 
<a href="/search/cs?searchtype=author&query=Galster%2C+M">Matthias Galster</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Peng Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 3 images, 6 tables, Manuscript submitted to a Journal (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Agile software development follows an adaptive and iterative approach.
However, the management of data (e.g., development data or product data) can
pose significant challenges for projects and agile teams. We aim to identify
and characterize key challenges faced in data management within agile projects
and to examine potential solutions proposed in the literature. We used a
Systematic Literature Review (SLR) to collect and analyse relevant studies. We
identified 45 studies related to data management in agile software development.
We then manually analysed and mapped data from these studies to categorise
different data management aspects and identify challenges and solutions as
identified in those studies. Our findings reveal major challenges such as data
integration and quality assurance. We found implications of challenges on team
members and the product delivery process. We found that teams frequently
struggle to integrate heterogeneous data sources, ensuring data reliability and
real-time analytics. Additionally, fragmented data collection and a lack of
standardized practices can impede team collaboration and project transparency.
The studies have also proposed various solutions to address those challenges,
including the use of ontologies, diverse data management strategies, automated
tools, and the adoption of quality-focused development methods. Solutions also
include training to enhance data quality and analysis. This SLR provides
in-depth insights and recommendations for practitioners, emphasizing the
importance of robust data management strategies. It suggests integrating
advanced data management techniques into agile frameworks to enhance
decision-making and improve software project outcomes. The study highlights the
need for a more focused approach to data management in agile environments,
advocating tailored solutions to meet the unique demands of agile software
development.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00463" title="Abstract">arXiv:2402.00463</a> [<a href="/pdf/2402.00463" title="Download PDF">pdf</a>, <a href="/format/2402.00463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding gender differences in experiences and concerns surrounding  online harms: A short report on a nationally representative survey of UK  adults
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Enock%2C+F+E">Florence E. Enock</a>, 
<a href="/search/cs?searchtype=author&query=Stevens%2C+F">Francesca Stevens</a>, 
<a href="/search/cs?searchtype=author&query=Bright%2C+J">Jonathan Bright</a>, 
<a href="/search/cs?searchtype=author&query=Cross%2C+M">Miranda Cross</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+P">Pica Johansson</a>, 
<a href="/search/cs?searchtype=author&query=Wajcman%2C+J">Judy Wajcman</a>, 
<a href="/search/cs?searchtype=author&query=Margetts%2C+H+Z">Helen Z. Margetts</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Online harms, such as hate speech, misinformation, harassment and self-harm
promotion, continue to be widespread. While some work suggests that women are
disproportionately affected by such harms, other studies find little evidence
for gender differences in overall exposure. Here, we present preliminary
results from a large, nationally representative survey of UK adults (N = 2000).
We asked about exposure to 15 specific harms, along with fears surrounding
exposure and comfort engaging in certain online behaviours. While men and women
report seeing online harms to a roughly equal extent overall, we find that
women are significantly more fearful of experiencing every type of harm that we
asked about, and are significantly less comfortable partaking in several online
behaviours. Strikingly, just 24% of women report being comfortable expressing
political opinions online compared with almost 40% of men, with similar overall
proportions for challenging certain content. Our work suggests that women may
suffer an additional psychological burden in response to the proliferation of
harmful online content, doing more 'safety work' to protect themselves. With
much public discourse happening online, gender inequality in public voice is
likely to be perpetuated if women feel too fearful to participate. Our results
are important because to establish greater equality in society, we must take
measures to ensure all members feel safe and able to participate in the online
space.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00465" title="Abstract">arXiv:2402.00465</a> [<a href="/pdf/2402.00465" title="Download PDF">pdf</a>, <a href="/ps/2402.00465" title="Download PostScript">ps</a>, <a href="/format/2402.00465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coded Multi-User Information Retrieval with a Multi-Antenna Helper Node
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abolpour%2C+M">Milad Abolpour</a>, 
<a href="/search/cs?searchtype=author&query=Salehi%2C+M">MohammadJavad Salehi</a>, 
<a href="/search/cs?searchtype=author&query=Mohajer%2C+S">Soheil Mohajer</a>, 
<a href="/search/cs?searchtype=author&query=Shariatpanahi%2C+S+P">Seyed Pooya Shariatpanahi</a>, 
<a href="/search/cs?searchtype=author&query=T%C3%B6lli%2C+A">Antti T&#xf6;lli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">A novel coding design is proposed to enhance information retrieval in a
wireless network of users with partial access to the data, in the sense of
observation, measurement, computation, or storage. Information exchange in the
network is assisted by a multi-antenna base station (BS), with no direct access
to the data. Accordingly, the missing parts of data are exchanged among users
through an uplink (UL) step followed by a downlink (DL) step. In this paper,
new coding strategies, inspired by coded caching (CC) techniques, are devised
to enhance both UL and DL steps. In the UL step, users transmit encoded and
properly combined parts of their accessible data to the BS. Then, during the DL
step, the BS carries out the required processing on its received signals and
forwards a proper combination of the resulting signal terms back to the users,
enabling each user to retrieve the desired information. Using the devised coded
data retrieval strategy, the data exchange in both UL and DL steps requires the
same communication delay, measured by normalized delivery time (NDT).
Furthermore, the NDT of the UL/DL step is shown to coincide with the optimal
NDT of the original DL multi-input single-output CC scheme, in which the BS is
connected to a centralized data library.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00466" title="Abstract">arXiv:2402.00466</a> [<a href="/pdf/2402.00466" title="Download PDF">pdf</a>, <a href="/format/2402.00466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a GPU-Parallelization of the neXtSIM-DG Dynamical Core
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jendersie%2C+R">Robert Jendersie</a>, 
<a href="/search/cs?searchtype=author&query=Lessig%2C+C">Christian Lessig</a>, 
<a href="/search/cs?searchtype=author&query=Richter%2C+T">Thomas Richter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to PASC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">The cryosphere plays a significant role in Earth's climate system. Therefore,
an accurate simulation of sea ice is of great importance to improve climate
projections. To enable higher resolution simulations, graphics processing units
(GPUs) have become increasingly attractive as they offer higher floating point
peak performance and better energy efficiency compared to CPUs. However, making
use of the theoretical peak performance usually requires more care and effort
in the implementation. In recent years, a number of frameworks have become
available that promise to simplify general purpose GPU programming. In this
work, we compare multiple such frameworks, including CUDA, SYCL, Kokkos and
PyTorch, for the parallelization of \nextsim, a finite-element based dynamical
core for sea ice. We evaluate the different approaches according to their
usability and performance.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00467" title="Abstract">arXiv:2402.00467</a> [<a href="/pdf/2402.00467" title="Download PDF">pdf</a>, <a href="/format/2402.00467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can you see me now? Blind spot estimation for autonomous vehicles using  scenario-based simulation with random reference sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uecker%2C+M">Marc Uecker</a>, 
<a href="/search/cs?searchtype=author&query=Z%C3%B6llner%2C+J+M">J.Marius Z&#xf6;llner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this paper, we introduce a method for estimating blind spots for sensor
setups of autonomous or automated vehicles and/or robotics applications. In
comparison to previous methods that rely on geometric approximations, our
presented approach provides more realistic coverage estimates by utilizing
accurate and detailed 3D simulation environments. Our method leverages point
clouds from LiDAR sensors or camera depth images from high-fidelity simulations
of target scenarios to provide accurate and actionable visibility estimates. A
Monte Carlo-based reference sensor simulation enables us to accurately estimate
blind spot size as a metric of coverage, as well as detection probabilities of
objects at arbitrary positions.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00468" title="Abstract">arXiv:2402.00468</a> [<a href="/pdf/2402.00468" title="Download PDF">pdf</a>, <a href="/format/2402.00468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RadDQN: a Deep Q Learning-based Architecture for Finding Time-efficient  Minimum Radiation Exposure Pathway
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sadhu%2C+B">Biswajit Sadhu</a>, 
<a href="/search/cs?searchtype=author&query=Sadhu%2C+T">Trijit Sadhu</a>, 
<a href="/search/cs?searchtype=author&query=Anand%2C+S">S. Anand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 main figures, code link (GitHub)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Recent advancements in deep reinforcement learning (DRL) techniques have
sparked its multifaceted applications in the automation sector. Managing
complex decision-making problems with DRL encourages its use in the nuclear
industry for tasks such as optimizing radiation exposure to the personnel
during normal operating conditions and potential accidental scenarios. However,
the lack of efficient reward function and effective exploration strategy
thwarted its implementation in the development of radiation-aware autonomous
unmanned aerial vehicle (UAV) for achieving maximum radiation protection. Here,
in this article, we address these intriguing issues and introduce a deep
Q-learning based architecture (RadDQN) that operates on a radiation-aware
reward function to provide time-efficient minimum radiation-exposure pathway in
a radiation zone. We propose a set of unique exploration strategies that
fine-tune the extent of exploration and exploitation based on the state-wise
variation in radiation exposure during training. Further, we benchmark the
predicted path with grid-based deterministic method. We demonstrate that the
formulated reward function in conjugation with adequate exploration strategy is
effective in handling several scenarios with drastically different radiation
field distributions. When compared to vanilla DQN, our model achieves a
superior convergence rate and higher training stability.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00474" title="Abstract">arXiv:2402.00474</a> [<a href="/pdf/2402.00474" title="Download PDF">pdf</a>, <a href="/format/2402.00474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SA-MDKIF: A Scalable and Adaptable Medical Domain Knowledge Injection  Framework for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tianhan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhe Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Ling Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent advances in large language models (LLMs) have demonstrated exceptional
performance in various natural language processing (NLP) tasks. However, their
effective application in the medical domain is hampered by a lack of medical
domain knowledge. In this study, we present SA-MDKIF, a scalable and adaptable
framework that aims to inject medical knowledge into general-purpose LLMs
through instruction tuning, thereby enabling adaptability for various
downstream tasks. SA-MDKIF consists of two stages: skill training and skill
adaptation. In the first stage, we define 12 basic medical skills and use
AdaLoRA to train these skills based on uniformly formatted instructional
datasets that we have constructed. In the next stage, we train the skill router
using task-specific downstream data and use this router to integrate the
acquired skills with LLMs during inference. Experimental results on 9 different
medical tasks show that SA-MDKIF improves performance by 10-20% compared to the
original LLMs. Notably, this improvement is particularly pronounced for unseen
medical tasks, showing an improvement of up to 30%.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00477" title="Abstract">arXiv:2402.00477</a> [<a href="/pdf/2402.00477" title="Download PDF">pdf</a>, <a href="/ps/2402.00477" title="Download PostScript">ps</a>, <a href="/format/2402.00477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HERITRACE: Tracing Evolution and Bridging Data for Streamlined  Curatorial Work in the GLAM Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Massari%2C+A">Arcangelo Massari</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Peroni%2C+S">Silvio Peroni</a> (1 and 2) ((1) Digital Humanities Advanced Research Centre (/DH.arc), Department of Classical Philology and Italian Studies, University of Bologna, Bologna, Italy, (2) Research Centre for Open Scholarly Metadata, Department of Classical Philology and Italian Studies, University of Bologna, Bologna, Italy)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, submitted to AIUCD 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">HERITRACE is a semantic data management system tailored for the GLAM sector.
It is engineered to streamline data curation for non-technical users while also
offering an efficient administrative interface for technical staff. The paper
compares HERITRACE with other established platforms such as OmekaS, Semantic
MediaWiki, Research Space, and CLEF, emphasizing its advantages in user
friendliness, provenance management, change tracking, customization
capabilities, and data integration. The system leverages SHACL for data
modeling and employs the OpenCitations Data Model (OCDM) for provenance and
change tracking, ensuring a harmonious blend of advanced technical features and
user accessibility. Future developments include the integration of a robust
authentication system and the expansion of data compatibility via the RDF
Mapping Language (RML), enhancing HERITRACE's utility in digital heritage
management.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00480" title="Abstract">arXiv:2402.00480</a> [<a href="/pdf/2402.00480" title="Download PDF">pdf</a>, <a href="/format/2402.00480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symmetric unisolvent equations for linear elasticity in pure stresses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sky%2C+A">Adam Sky</a>, 
<a href="/search/math?searchtype=author&query=Zilian%2C+A">Andreas Zilian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this work we introduce novel stress-only formulations of linear elasticity
with special attention to their approximate solution using weighted residual
methods. We present four sets of boundary value problems for a pure stress
formulation of three-dimensional solids, and in two dimensions for plane stress
and plane strain. The associated governing equations are derived by
modifications and combinations of the Beltrami-Michell equations and the
Navier-Cauchy equations. The corresponding variational forms of dimension $d
\in \{2,3\}$ allow to directly approximate the stress tensor without any
presupposed potential stress functions, and are shown to be well-posed in
$\mathit{H}^1 \otimes \mathrm{Sym}(d)$ in the framework of functional analysis
via the Lax-Milgram theorem, making their finite element implementation using
$\mathit{C}^0$-continuous elements straightforward. Further, in the finite
element setting we provide a treatment for constant and piece-wise constant
body forces via distributions. The operators and differential identities in
this work are provided in modern tensor notation and rely on exact sequences,
making the resulting equations and differential relations directly
comprehensible. Finally, numerical benchmarks for convergence as well as
spectral analysis are used to test the limits and identify viable use-cases of
the equations.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00481" title="Abstract">arXiv:2402.00481</a> [<a href="/pdf/2402.00481" title="Download PDF">pdf</a>, <a href="/format/2402.00481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bias Mitigating Few-Shot Class-Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Li-Jun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhen-Duo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zi-Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xin-Shun Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages (not including references and checklist)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Few-shot class-incremental learning (FSCIL) aims at recognizing novel classes
continually with limited novel class samples. A mainstream baseline for FSCIL
is first to train the whole model in the base session, then freeze the feature
extractor in the incremental sessions. Despite achieving high overall accuracy,
most methods exhibit notably low accuracy for incremental classes. Some recent
methods somewhat alleviate the accuracy imbalance between base and incremental
classes by fine-tuning the feature extractor in the incremental sessions, but
they further cause the accuracy imbalance between past and current incremental
classes. In this paper, we study the causes of such classification accuracy
imbalance for FSCIL, and abstract them into a unified model bias problem. Based
on the analyses, we propose a novel method to mitigate model bias of the FSCIL
problem during training and inference processes, which includes mapping ability
stimulation, separately dual-feature classification, and self-optimizing
classifiers. Extensive experiments on three widely-used FSCIL benchmark
datasets show that our method significantly mitigates the model bias problem
and achieves state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00485" title="Abstract">arXiv:2402.00485</a> [<a href="/pdf/2402.00485" title="Download PDF">pdf</a>, <a href="/format/2402.00485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Personalized Framework for Consumer and Producer Group Fairness  Optimization in Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahmani%2C+H+A">Hossein A. Rahmani</a>, 
<a href="/search/cs?searchtype=author&query=Naghiaei%2C+M">Mohammadmehdi Naghiaei</a>, 
<a href="/search/cs?searchtype=author&query=Deldjoo%2C+Y">Yashar Deldjoo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TORS. arXiv admin note: substantial text overlap with <a href="/abs/2204.08085">arXiv:2204.08085</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Information Retrieval (cs.IR)

</div>
<p class="mathjax">In recent years, there has been an increasing recognition that when machine
learning (ML) algorithms are used to automate decisions, they may mistreat
individuals or groups, with legal, ethical, or economic implications.
Recommender systems are prominent examples of these machine learning (ML)
systems that aid users in making decisions. The majority of past literature
research on RS fairness treats user and item fairness concerns independently,
ignoring the fact that recommender systems function in a two-sided marketplace.
In this paper, we propose CP-FairRank, an optimization-based re-ranking
algorithm that seamlessly integrates fairness constraints from both the
consumer and producer side in a joint objective framework. The framework is
generalizable and may take into account varied fairness settings based on group
segmentation, recommendation model selection, and domain, which is one of its
key characteristics. For instance, we demonstrate that the system may jointly
increase consumer and producer fairness when (un)protected consumer groups are
defined on the basis of their activity level and main-streamness, while
producer groups are defined according to their popularity level. For empirical
validation, through large-scale on eight datasets and four mainstream
collaborative filtering (CF) recommendation models, we demonstrate that our
proposed strategy is able to improve both consumer and producer fairness
without compromising or very little overall recommendation quality,
demonstrating the role algorithms may play in avoiding data biases.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00491" title="Abstract">arXiv:2402.00491</a> [<a href="/pdf/2402.00491" title="Download PDF">pdf</a>, <a href="/format/2402.00491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EXMOS: Explanatory Model Steering Through Multifaceted Explanations and  Data Configurations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+A">Aditya Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Stumpf%2C+S">Simone Stumpf</a>, 
<a href="/search/cs?searchtype=author&query=Gosak%2C+L">Lucija Gosak</a>, 
<a href="/search/cs?searchtype=author&query=Stiglic%2C+G">Gregor Stiglic</a>, 
<a href="/search/cs?searchtype=author&query=Verbert%2C+K">Katrien Verbert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a pre-print version only for early release. Please view the conference published version from ACM CHI 2024 to get the latest version of the paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the CHI Conference on Human Factors in Computing
  Systems (CHI '24), May 11--16, 2024, Honolulu, HI, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Explanations in interactive machine-learning systems facilitate debugging and
improving prediction models. However, the effectiveness of various global
model-centric and data-centric explanations in aiding domain experts to detect
and resolve potential data issues for model improvement remains unexplored.
This research investigates the influence of data-centric and model-centric
global explanations in systems that support healthcare experts in optimising
models through automated and manual data configurations. We conducted
quantitative (n=70) and qualitative (n=30) studies with healthcare experts to
explore the impact of different explanations on trust, understandability and
model improvement. Our results reveal the insufficiency of global model-centric
explanations for guiding users during data configuration. Although data-centric
explanations enhanced understanding of post-configuration system changes, a
hybrid fusion of both explanation types demonstrated the highest effectiveness.
Based on our study results, we also present design implications for effective
explanation-driven interactive machine-learning systems.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00496" title="Abstract">arXiv:2402.00496</a> [<a href="/pdf/2402.00496" title="Download PDF">pdf</a>, <a href="/format/2402.00496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization of a Line Detection Algorithm for Autonomous Vehicles on a  RISC-V with Accelerator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belda%2C+M+J">Mar&#xed;a Jos&#xe9; Belda</a>, 
<a href="/search/cs?searchtype=author&query=Olcoz%2C+K">Katzalin Olcoz</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+F">Fernando Castro</a>, 
<a href="/search/cs?searchtype=author&query=Tirado%2C+F">Francisco Tirado</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Computer Science &amp; Technology, 22(2), 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">In recent years, autonomous vehicles have attracted the attention of many
research groups, both in academia and business, including researchers from
leading companies such as Google, Uber and Tesla. This type of vehicles are
equipped with systems that are subject to very strict requirements, essentially
aimed at performing safe operations -- both for potential passengers and
pedestrians -- as well as carrying out the processing needed for decision
making in real time. In many instances, general-purpose processors alone cannot
ensure that these safety, reliability and real-time requirements are met, so it
is common to implement heterogeneous systems by including accelerators. This
paper explores the acceleration of a line detection application in the
autonomous car environment using a heterogeneous system consisting of a
general-purpose RISC-V core and a domain-specific accelerator. In particular,
the application is analyzed to identify the most computationally intensive
parts of the code and it is adapted accordingly for more efficient processing.
Furthermore, the code is executed on the aforementioned hardware platform to
verify that the execution effectively meets the existing requirements in
autonomous vehicles, experiencing a 3.7x speedup with respect to running
without accelerator.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00502" title="Abstract">arXiv:2402.00502</a> [<a href="/pdf/2402.00502" title="Download PDF">pdf</a>, <a href="/ps/2402.00502" title="Download PostScript">ps</a>, <a href="/format/2402.00502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Axiomatizing NFAs Generated by Regular Grammars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gorrieri%2C+R">Roberto Gorrieri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2301.03435">arXiv:2301.03435</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">A subclass of nondeterministic Finite Automata generated by means of regular
Grammars (GFAs, for short) is introduced. A process algebra is proposed, whose
semantics maps a term to a GFA. We prove a representability theorem: for each
GFA $N$, there exists a process algebraic term $p$ such that its semantics is a
GFA isomorphic to $N$. Moreover, we provide a concise axiomatization of
language equivalence: two GFAs $N_1$ and $N_2$ recognize the same regular
language if and only if the associated terms $p_1$ and $p_2$, respectively, can
be equated by means of a set of axioms, comprising 6 axioms plus 2 conditional
axioms, only.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00518" title="Abstract">arXiv:2402.00518</a> [<a href="/pdf/2402.00518" title="Download PDF">pdf</a>, <a href="/format/2402.00518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EE-Tuning: An Economical yet Scalable Solution for Tuning Early-Exit  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xuchen Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yanxi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+B">Bolin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">This work introduces EE-Tuning, a lightweight and economical solution to
training/tuning early-exit large language models (LLMs). In contrast to the
common approach of full-parameter pre-training, EE-Tuning augments any
pre-trained (and possibly fine-tuned) standard LLM with additional early-exit
layers that are tuned in a parameter-efficient manner, which requires
significantly less computational resources and training data. Our
implementation of EE-Tuning achieves outstanding training efficiency via
extensive performance optimizations, as well as scalability due to its full
compatibility with 3D parallelism. Results of systematic experiments validate
the efficacy of EE-Tuning, confirming that effective early-exit LLM inference
can be achieved with a limited training budget. In hope of making early-exit
LLMs accessible to the community, we release the source code of our
implementation of EE-Tuning at https://github.com/pan-x-c/EE-LLM.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00519" title="Abstract">arXiv:2402.00519</a> [<a href="/pdf/2402.00519" title="Download PDF">pdf</a>, <a href="/format/2402.00519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Summarizing Code Snippets Using Pre-Trained Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mastropaolo%2C+A">Antonio Mastropaolo</a>, 
<a href="/search/cs?searchtype=author&query=Ciniselli%2C+M">Matteo Ciniselli</a>, 
<a href="/search/cs?searchtype=author&query=Pascarella%2C+L">Luca Pascarella</a>, 
<a href="/search/cs?searchtype=author&query=Tufano%2C+R">Rosalia Tufano</a>, 
<a href="/search/cs?searchtype=author&query=Aghajani%2C+E">Emad Aghajani</a>, 
<a href="/search/cs?searchtype=author&query=Bavota%2C+G">Gabriele Bavota</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">When comprehending code, a helping hand may come from the natural language
comments documenting it that, unfortunately, are not always there. To support
developers in such a scenario, several techniques have been presented to
automatically generate natural language summaries for a given code. Most recent
approaches exploit deep learning (DL) to automatically document classes or
functions, while little effort has been devoted to more fine-grained
documentation (e.g., documenting code snippets or even a single statement).
Such a design choice is dictated by the availability of training data: For
example, in the case of Java, it is easy to create datasets composed of pairs
&lt;Method, Javadoc&gt; that can be fed to DL models to teach them how to summarize a
method. Such a comment-to-code linking is instead non-trivial when it comes to
inner comments documenting a few statements. In this work, we take all the
steps needed to train a DL model to document code snippets. First, we manually
built a dataset featuring 6.6k comments that have been (i) classified based on
their type (e.g., code summary, TODO), and (ii) linked to the code statements
they document. Second, we used such a dataset to train a multi-task DL model,
taking as input a comment and being able to (i) classify whether it represents
a "code summary" or not and (ii) link it to the code statements it documents.
Our model identifies code summaries with 84% accuracy and is able to link them
to the documented lines of code with recall and precision higher than 80%.
Third, we run this model on 10k projects, identifying and linking code
summaries to the documented code. This unlocked the possibility of building a
large-scale dataset of documented code snippets that have then been used to
train a new DL model able to document code snippets. A comparison with
state-of-the-art baselines shows the superiority of the proposed approach.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00522" title="Abstract">arXiv:2402.00522</a> [<a href="/pdf/2402.00522" title="Download PDF">pdf</a>, <a href="/ps/2402.00522" title="Download PostScript">ps</a>, <a href="/format/2402.00522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Expressive Power and Mechanisms of Transformer for  Sequence Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mingze Wang</a>, 
<a href="/search/cs?searchtype=author&query=E%2C+W">Weinan E</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 65 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We conduct a systematic study of the approximation properties of Transformer
for sequence modeling with long, sparse and complicated memory. We investigate
the mechanisms through which different components of Transformer, such as the
dot-product self-attention, positional encoding and feed-forward layer, affect
its expressive power, and we study their combined effects through establishing
explicit approximation rates. Our study reveals the roles of critical
parameters in the Transformer, such as the number of layers and the number of
attention heads, and these insights also provide natural suggestions for
alternative architectures.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00525" title="Abstract">arXiv:2402.00525</a> [<a href="/pdf/2402.00525" title="Download PDF">pdf</a>, <a href="/format/2402.00525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StopThePop: Sorted Gaussian Splatting for View-Consistent Real-time  Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Radl%2C+L">Lukas Radl</a>, 
<a href="/search/cs?searchtype=author&query=Steiner%2C+M">Michael Steiner</a>, 
<a href="/search/cs?searchtype=author&query=Parger%2C+M">Mathias Parger</a>, 
<a href="/search/cs?searchtype=author&query=Weinrauch%2C+A">Alexander Weinrauch</a>, 
<a href="/search/cs?searchtype=author&query=Kerbl%2C+B">Bernhard Kerbl</a>, 
<a href="/search/cs?searchtype=author&query=Steinberger%2C+M">Markus Steinberger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Video: <a href="https://youtu.be/RJQlSORNkr0">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Gaussian Splatting has emerged as a prominent model for constructing 3D
representations from images across diverse domains. However, the efficiency of
the 3D Gaussian Splatting rendering pipeline relies on several simplifications.
Notably, reducing Gaussian to 2D splats with a single view-space depth
introduces popping and blending artifacts during view rotation. Addressing this
issue requires accurate per-pixel depth computation, yet a full per-pixel sort
proves excessively costly compared to a global sort operation. In this paper,
we present a novel hierarchical rasterization approach that systematically
resorts and culls splats with minimal processing overhead. Our software
rasterizer effectively eliminates popping artifacts and view inconsistencies,
as demonstrated through both quantitative and qualitative measurements.
Simultaneously, our method mitigates the potential for cheating view-dependent
effects with popping, ensuring a more authentic representation. Despite the
elimination of cheating, our approach achieves comparable quantitative results
for test images, while increasing the consistency for novel view synthesis in
motion. Due to its design, our hierarchical approach is only 4% slower on
average than the original Gaussian Splatting. Notably, enforcing consistency
enables a reduction in the number of Gaussians by approximately half with
nearly identical quality and view-consistency. Consequently, rendering
performance is nearly doubled, making our approach 1.6x faster than the
original Gaussian Splatting, with a 50% reduction in memory requirements.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00530" title="Abstract">arXiv:2402.00530</a> [<a href="/pdf/2402.00530" title="Download PDF">pdf</a>, <a href="/format/2402.00530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Superfiltering: Weak-to-Strong Data Filtering for Fast  Instruction-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shwai He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhitao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hongyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianzong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+N">Ning Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Instruction tuning is critical to improve LLMs but usually suffers from
low-quality and redundant data. Data filtering for instruction tuning has
proved important in improving both the efficiency and performance of the tuning
process. But it also leads to extra cost and computation due to the involvement
of LLMs in this process. To reduce the filtering cost, we study Superfiltering:
Can we use a smaller and weaker model to select data for finetuning a larger
and stronger model? Despite the performance gap between weak and strong
language models, we find their highly consistent capability to perceive
instruction difficulty and data selection results. This enables us to use a
much smaller and more efficient model to filter the instruction data used to
train a larger language model. Not only does it largely speed up the data
filtering, but the filtered-data-finetuned LLM achieves even better performance
on standard benchmarks. Extensive experiments validate the efficacy and
efficiency of our approach.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00531" title="Abstract">arXiv:2402.00531</a> [<a href="/pdf/2402.00531" title="Download PDF">pdf</a>, <a href="/format/2402.00531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preconditioning for Physics-Informed Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Songming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+C">Chang Su</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiachen Yao</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Z">Zhongkai Hao</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hang Su</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Youjia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Physics-informed neural networks (PINNs) have shown promise in solving
various partial differential equations (PDEs). However, training pathologies
have negatively affected the convergence and prediction accuracy of PINNs,
which further limits their practical applications. In this paper, we propose to
use condition number as a metric to diagnose and mitigate the pathologies in
PINNs. Inspired by classical numerical analysis, where the condition number
measures sensitivity and stability, we highlight its pivotal role in the
training dynamics of PINNs. We prove theorems to reveal how condition number is
related to both the error control and convergence of PINNs. Subsequently, we
present an algorithm that leverages preconditioning to improve the condition
number. Evaluations of 18 PDE problems showcase the superior performance of our
method. Significantly, in 7 of these problems, our method reduces errors by an
order of magnitude. These empirical findings verify the critical role of the
condition number in PINNs' training.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00533" title="Abstract">arXiv:2402.00533</a> [<a href="/pdf/2402.00533" title="Download PDF">pdf</a>, <a href="/ps/2402.00533" title="Download PostScript">ps</a>, <a href="/format/2402.00533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reuse Detector: Improving the Management of STT-RAM SLLCs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rodr%C3%8Dguez-Rodr%C3%8Dguez%2C+R">Roberto Rodr&#xcd;guez-Rodr&#xcd;guez</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%8Daz%2C+J">Javier D&#xcd;az</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+F">Fernando Castro</a>, 
<a href="/search/cs?searchtype=author&query=Ib%C3%81%C3%91ez%2C+P">Pablo Ib&#xc1;&#xd1;ez</a>, 
<a href="/search/cs?searchtype=author&query=Chaver%2C+D">Daniel Chaver</a>, 
<a href="/search/cs?searchtype=author&query=Vi%C3%91als%2C+V">V&#xed;ctor Vi&#xd1;als</a>, 
<a href="/search/cs?searchtype=author&query=Saez%2C+J+C">Juan Carlos Saez</a>, 
<a href="/search/cs?searchtype=author&query=Prieto-Matias%2C+M">Manuel Prieto-Matias</a>, 
<a href="/search/cs?searchtype=author&query=Pinuel%2C+L">Luis Pinuel</a>, 
<a href="/search/cs?searchtype=author&query=Monreal%2C+T">Teresa Monreal</a>, 
<a href="/search/cs?searchtype=author&query=Llaber%C3%8Da%2C+J+M">Jose Mar&#xed;a Llaber&#xcd;a</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The Computer Journal, 61(6), 2018, pp. 856-880
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Various constraints of Static Random Access Memory (SRAM) are leading to
consider new memory technologies as candidates for building on-chip shared
last-level caches (SLLCs). Spin-Transfer Torque RAM (STT-RAM) is currently
postulated as the prime contender due to its better energy efficiency, smaller
die footprint and higher scalability. However, STT-RAM also exhibits some
drawbacks, like slow and energy-hungry write operations, that need to be
mitigated. In this work we address these shortcomings by leveraging a new
management mechanism for STT-RAM SLLCs. This approach is based on the previous
observation that the stream of references arriving at the SLLC of a Chip
MultiProcessor (CMP) exhibits reuse locality, i.e., those blocks referenced
several times manifest high probability of forthcoming reuse. In this paper, we
employ a cache management mechanism that selects the contents of the SLLC aimed
to exploit reuse locality instead of temporal locality. Specifically, our
proposal consists in the inclusion of a Reuse Detector between private cache
levels and the STT-RAM SLLC to detect blocks that do not exhibit reuse, in
order to avoid their insertion in the SLLC, hence reducing the number of write
operations and the energy consumption in the STT-RAM. Our evaluation reveals
that our scheme reports on average, energy reductions in the SLLC in the range
of 37-30\%, additional energy savings in the main memory in the range of 6-8\%
and performance improvements of 3\% up to 14\% (16-core) compared to an STT-RAM
SLLC baseline where no reuse detector is employed. More importantly, our
approach outperforms DASCA, the state-of-the-art STT-RAM SLLC management,
reporting SLLC energy savings in the range of 4-11\% higher than those of
DASCA, delivering higher performance in the range of 1.5-14\%, and additional
improvements in DRAM energy consumption in the range of 2-9\% higher than
DASCA.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00534" title="Abstract">arXiv:2402.00534</a> [<a href="/pdf/2402.00534" title="Download PDF">pdf</a>, <a href="/format/2402.00534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Manifold Representation of the Key in Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+L">Li Meng</a>, 
<a href="/search/cs?searchtype=author&query=Goodwin%2C+M">Morten Goodwin</a>, 
<a href="/search/cs?searchtype=author&query=Yazidi%2C+A">Anis Yazidi</a>, 
<a href="/search/cs?searchtype=author&query=Engelstad%2C+P">Paal Engelstad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Vision Transformers implement multi-head self-attention (MSA) via stacking
multiple attention blocks. The query, key, and value are often intertwined and
generated within those blocks via a single, shared linear transformation. This
paper explores the concept of disentangling the key from the query and value,
and adopting a manifold representation for the key. Our experiments reveal that
decoupling and endowing the key with a manifold structure can enhance the model
performance. Specifically, ViT-B exhibits a 0.87% increase in top-1 accuracy,
while Swin-T sees a boost of 0.52% in top-1 accuracy on the ImageNet-1K
dataset, with eight charts in the manifold key. Our approach also yields
positive results in object detection and instance segmentation tasks on the
COCO dataset. Through detailed ablation studies, we establish that these
performance gains are not merely due to the simplicity of adding more
parameters and computations. Future research may investigate strategies for
cutting the budget of such representations and aim for further performance
improvements based on our findings.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00537" title="Abstract">arXiv:2402.00537</a> [<a href="/pdf/2402.00537" title="Download PDF">pdf</a>, <a href="/format/2402.00537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Path Planning via Learning from Demonstrations for Robotic  Catheters in Deformable Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhen Li</a>, 
<a href="/search/cs?searchtype=author&query=Lambranzi%2C+C">Chiara Lambranzi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Di Wu</a>, 
<a href="/search/cs?searchtype=author&query=Segato%2C+A">Alice Segato</a>, 
<a href="/search/cs?searchtype=author&query=De+Marco%2C+F">Federico De Marco</a>, 
<a href="/search/cs?searchtype=author&query=Poorten%2C+E+V">Emmanuel Vander Poorten</a>, 
<a href="/search/cs?searchtype=author&query=Dankelman%2C+J">Jenny Dankelman</a>, 
<a href="/search/cs?searchtype=author&query=De+Momi%2C+E">Elena De Momi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review in IEEE Transactions on Biomedical Engineering (TBME)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Navigation through tortuous and deformable vessels using catheters with
limited steering capability underscores the need for reliable path planning.
State-of-the-art path planners do not fully account for the deformable nature
of the environment. This work proposes a robust path planner via a learning
from demonstrations method, named Curriculum Generative Adversarial Imitation
Learning (C-GAIL). This path planning framework takes into account the
interaction between steerable catheters and vessel walls and the deformable
property of vessels. In-silico comparative experiments show that the proposed
network achieves smaller targeting errors, and a higher success rate, compared
to a state-of-the-art approach based on GAIL. The in-vitro validation
experiments demonstrate that the path generated by the proposed C-GAIL path
planner aligns better with the actual steering capability of the pneumatic
artificial muscle-driven catheter utilized in this study. Therefore, the
proposed approach can provide enhanced support to the user in navigating the
catheter towards the target with greater precision, in contrast to the
conventional centerline-following technique. The targeting and tracking errors
are 1.26$\pm$0.55mm and 5.18$\pm$3.48mm, respectively. The proposed path
planning framework exhibits superior performance in managing uncertainty
associated with vessel deformation, thereby resulting in lower tracking errors.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00540" title="Abstract">arXiv:2402.00540</a> [<a href="/pdf/2402.00540" title="Download PDF">pdf</a>, <a href="/format/2402.00540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental Evaluation of Interactive Edge/Cloud Virtual Reality Gaming  over Wi-Fi using Unity Render Streaming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Casasnovas%2C+M">Miguel Casasnovas</a>, 
<a href="/search/cs?searchtype=author&query=Michaelides%2C+C">Costas Michaelides</a>, 
<a href="/search/cs?searchtype=author&query=Carrascosa-Zamacois%2C+M">Marc Carrascosa-Zamacois</a>, 
<a href="/search/cs?searchtype=author&query=Bellalta%2C+B">Boris Bellalta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 22 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Virtual Reality (VR) streaming enables end-users to seamlessly immerse
themselves in interactive virtual environments using even low-end devices.
However, the quality of the VR experience heavily relies on Wi-Fi performance,
since it serves as the last hop in the network chain. Our study delves into the
intricate interplay between Wi-Fi and VR traffic, drawing upon empirical data
and leveraging a simulator tailored to VR traffic patterns. In this work we
further evaluate Wi-Fi's suitability for VR streaming in terms of the quality
of service it provides. In particular, we employ Unity Render Streaming to
remotely stream real-time VR gaming content over Wi-Fi 6 using WebRTC,
leveraging a server physically located at the network's edge, near the end
user. Our findings demonstrate the system's sustained network performance,
showcasing minimal round-trip time and jitter at 60 and 90 fps. In addition, we
uncover the characteristics and patterns of the generated traffic streams,
unveiling a surprising video transmission approach inherent to WebRTC-based
services. This approach involves the fragmentation of video frames into
discrete batches of packets, transmitted at regular intervals regardless of the
targeted frame rate.This segmentation mechanism maintains consistent video
packet delays across video frame rates but leads to increased Wi-Fi airtime
consumption at higher frame rates. The presented results demonstrate that
shortening the interval between batches is advantageous as it improves Wi-Fi
efficiency and reduces delays in delivering complete frames.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00541" title="Abstract">arXiv:2402.00541</a> [<a href="/pdf/2402.00541" title="Download PDF">pdf</a>, <a href="/format/2402.00541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Conditional Diffusion Model for Enhancing Deepfake Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tiewen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shanmin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhenghan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Ying Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent studies on deepfake detection have achieved promising results when
training and testing faces are from the same dataset. However, their results
severely degrade when confronted with forged samples that the model has not yet
seen during training. In this paper, deepfake data to help detect deepfakes.
this paper present we put a new insight into diffusion model-based data
augmentation, and propose a Masked Conditional Diffusion Model (MCDM) for
enhancing deepfake detection. It generates a variety of forged faces from a
masked pristine one, encouraging the deepfake detection model to learn generic
and robust representations without overfitting to special artifacts. Extensive
experiments demonstrate that forgery images generated with our method are of
high quality and helpful to improve the performance of deepfake detection
models.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00542" title="Abstract">arXiv:2402.00542</a> [<a href="/pdf/2402.00542" title="Download PDF">pdf</a>, <a href="/ps/2402.00542" title="Download PostScript">ps</a>, <a href="/format/2402.00542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hardness of Random Reordered Encodings of Parity for Resolution and CDCL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chew%2C+L">Leroy Chew</a>, 
<a href="/search/cs?searchtype=author&query=de+Colnet%2C+A">Alexis de Colnet</a>, 
<a href="/search/cs?searchtype=author&query=Slivovsky%2C+F">Friedrich Slivovsky</a>, 
<a href="/search/cs?searchtype=author&query=Szeider%2C+S">Stefan Szeider</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">Parity reasoning is challenging for Conflict-Driven Clause Learning (CDCL)
SAT solvers. This has been observed even for simple formulas encoding two
contradictory parity constraints with different variable orders (Chew and Heule
2020). We provide an analytical explanation for their hardness by showing that
they require exponential resolution refutations with high probability when the
variable order is chosen at random. We obtain this result by proving that these
formulas, which are known to be Tseitin formulas, have Tseitin graphs of linear
treewidth with high probability. Since such Tseitin formulas require
exponential resolution proofs, our result follows. We generalize this argument
to a new class of formulas that capture a basic form of parity reasoning
involving a sum of two random parity constraints with random orders. Even when
the variable order for the sum is chosen favorably, these formulas remain hard
for resolution. In contrast, we prove that they have short DRAT refutations. We
show experimentally that the running time of CDCL SAT solvers on both classes
of formulas grows exponentially with their treewidth.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00550" title="Abstract">arXiv:2402.00550</a> [<a href="/pdf/2402.00550" title="Download PDF">pdf</a>, <a href="/format/2402.00550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical simulation of endovascular treatment options for cerebral  aneurysms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Frank%2C+M">Martin Frank</a>, 
<a href="/search/math?searchtype=author&query=Holzberger%2C+F">Fabian Holzberger</a>, 
<a href="/search/math?searchtype=author&query=Horvat%2C+M">Medeea Horvat</a>, 
<a href="/search/math?searchtype=author&query=Kirschke%2C+J">Jan Kirschke</a>, 
<a href="/search/math?searchtype=author&query=Mayr%2C+M">Matthias Mayr</a>, 
<a href="/search/math?searchtype=author&query=Muhr%2C+M">Markus Muhr</a>, 
<a href="/search/math?searchtype=author&query=Nebulishvili%2C+N">Natalia Nebulishvili</a>, 
<a href="/search/math?searchtype=author&query=Popp%2C+A">Alexander Popp</a>, 
<a href="/search/math?searchtype=author&query=Schwarting%2C+J">Julian Schwarting</a>, 
<a href="/search/math?searchtype=author&query=Wohlmuth%2C+B">Barbara Wohlmuth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Predicting the long-term success of endovascular interventions in the
clinical management of cerebral aneurysms requires detailed insight into the
patient-specific physiological conditions. In this work, we not only propose
numerical representations of endovascular medical devices such as coils, flow
diverters or Woven EndoBridge but also outline numerical models for the
prediction of blood flow patterns in the aneurysm cavity right after a surgical
intervention. Detailed knowledge about the post-surgical state then lays the
basis to assess the chances of a stable occlusion of the aneurysm required for
a long-term treatment success. To this end, we propose mathematical and
mechanical models of endovascular medical devices made out of thin metal wires.
These can then be used for fully resolved flow simulations of the post-surgical
blood flow, which in this work will be performed by means of a Lattice
Boltzmann method applied to the incompressible Navier-Stokes equations and
patient-specific geometries. To probe the suitability of homogenized models, we
also investigate poro-elastic models to represent such medical devices. In
particular, we examine the validity of this modeling approach for flow diverter
placement across the opening of the aneurysm cavity. For both approaches,
physiologically meaningful boundary conditions are provided from reduced-order
models of the vascular system. The present study demonstrates our capabilities
to predict the post-surgical state and lays a solid foundation to tackle the
prediction of thrombus formation and, thus, the aneurysm occlusion in a next
step.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00559" title="Abstract">arXiv:2402.00559</a> [<a href="/pdf/2402.00559" title="Download PDF">pdf</a>, <a href="/format/2402.00559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Chain-of-Thought Is as Strong as Its Weakest Link: A Benchmark for  Verifiers of Reasoning Chains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jacovi%2C+A">Alon Jacovi</a>, 
<a href="/search/cs?searchtype=author&query=Bitton%2C+Y">Yonatan Bitton</a>, 
<a href="/search/cs?searchtype=author&query=Bohnet%2C+B">Bernd Bohnet</a>, 
<a href="/search/cs?searchtype=author&query=Herzig%2C+J">Jonathan Herzig</a>, 
<a href="/search/cs?searchtype=author&query=Honovich%2C+O">Or Honovich</a>, 
<a href="/search/cs?searchtype=author&query=Tseng%2C+M">Michael Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Collins%2C+M">Michael Collins</a>, 
<a href="/search/cs?searchtype=author&query=Aharoni%2C+R">Roee Aharoni</a>, 
<a href="/search/cs?searchtype=author&query=Geva%2C+M">Mor Geva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://huggingface.co/datasets/google/reveal">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Prompting language models to provide step-by-step answers (e.g.,
"Chain-of-Thought") is the prominent approach for complex reasoning tasks,
where more accurate reasoning chains typically improve downstream task
performance. Recent literature discusses automatic methods to verify reasoning
steps to evaluate and improve their correctness. However, no fine-grained
step-level datasets are available to enable thorough evaluation of such
verification methods, hindering progress in this direction. We introduce
Reveal: Reasoning Verification Evaluation, a new dataset to benchmark automatic
verifiers of complex Chain-of-Thought reasoning in open-domain question
answering settings. Reveal includes comprehensive labels for the relevance,
attribution to evidence passages, and logical correctness of each reasoning
step in a language model's answer, across a wide variety of datasets and
state-of-the-art language models.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00562" title="Abstract">arXiv:2402.00562</a> [<a href="/pdf/2402.00562" title="Download PDF">pdf</a>, <a href="/ps/2402.00562" title="Download PostScript">ps</a>, <a href="/format/2402.00562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Endomorphisms of Linear Block Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mandelbaum%2C+J">Jonathan Mandelbaum</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+S">Sisi Miao</a>, 
<a href="/search/cs?searchtype=author&query=J%C3%A4kel%2C+H">Holger J&#xe4;kel</a>, 
<a href="/search/cs?searchtype=author&query=Schmalen%2C+L">Laurent Schmalen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The automorphism groups of various linear codes are well-studied yielding
valuable insights into the respective code structure. This knowledge is
successfully applied in, e.g., theoretical analysis and in improving decoding
performance motivating the analyses of endomorphisms of linear codes. In this
work, we discuss the structure of the set of transformation matrices of code
endomorphisms, defined as a generalization of code automorphisms, and provide
an explicit construction of a bijective mapping between the image of an
endomorphism and its canonical quotient space. Furthermore, we introduce a
one-to-one mapping between the set of transformation matrices of endomorphisms
and a larger linear block code enabling the use of well-known algorithms for
the search for suitable endomorphisms. Additionally, we propose an approach to
obtain unknown code endomorphisms based on automorphisms of the code.
Furthermore, we consider ensemble decoding as a possible use case for
endomorphisms by introducing endomorphism ensemble decoding. Interestingly, EED
can improve decoding performance when other ensemble decoding schemes are not
applicable.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00564" title="Abstract">arXiv:2402.00564</a> [<a href="/pdf/2402.00564" title="Download PDF">pdf</a>, <a href="/format/2402.00564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Single Graph Convolution Is All You Need: Efficient Grayscale Image  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fein-Ashley%2C+J">Jacob Fein-Ashley</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+T">Tian Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wickramasinghe%2C+S">Sachini Wickramasinghe</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bingyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kannan%2C+R">Rajgopal Kannan</a>, 
<a href="/search/cs?searchtype=author&query=Prasanna%2C+V">Viktor Prasanna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages of content, 1 page of references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Image classifiers often rely on convolutional neural networks (CNN) for their
tasks, which are inherently more heavyweight than multilayer perceptrons
(MLPs), which can be problematic in real-time applications. Additionally, many
image classification models work on both RGB and grayscale datasets.
Classifiers that operate solely on grayscale images are much less common.
Grayscale image classification has diverse applications, including but not
limited to medical image classification and synthetic aperture radar (SAR)
automatic target recognition (ATR). Thus, we present a novel grayscale (single
channel) image classification approach using a vectorized view of images. We
exploit the lightweightness of MLPs by viewing images as a vector and reducing
our problem setting to the grayscale image classification setting. We find that
using a single graph convolutional layer batch-wise increases accuracy and
reduces variance in the performance of our model. Moreover, we develop a
customized accelerator on FPGA for the proposed model with several
optimizations to improve its performance. Our experimental results on benchmark
grayscale image datasets demonstrate the effectiveness of the proposed model,
achieving vastly lower latency (up to 16$\times$ less) and competitive or
leading performance compared to other state-of-the-art image classification
models on various domain-specific grayscale image classification datasets.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00565" title="Abstract">arXiv:2402.00565</a> [<a href="/pdf/2402.00565" title="Download PDF">pdf</a>, <a href="/format/2402.00565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review of Carsickness Mitigation: Navigating Challenges and Exploiting  Opportunities in the Era of Intelligent Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+D">Daofei Li</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+T">Tingzhe Yu</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+B">Binbin Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 5 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Motion sickness (MS) has long been a common complaint in road transportation.
However, in the era of driving automation, MS has become an increasingly
significant issue. The future intelligent vehicle is envisioned as a mobile
space for work or entertainment, but unfortunately passengers' engagement in
non-driving tasks may exacerbate MS. Finding effective MS countermeasures is
crucial to ensure a pleasant passenger experience. Nevertheless, due to the
complex mechanism of MS, there are numerous challenges in mitigating it,
hindering the development of practical countermeasures. To address this, we
first review two prevalent theories explaining the mechanism of MS.
Subsequently, this paper provides a summary of current subjective and objective
approaches for quantifying motion sickness levels. Then, it surveys existing
methods for alleviating MS, including passenger adjustment, intelligent vehicle
solutions, and motion cues of various modalities. Furthermore, we outline the
limitations and remaining challenges of current research and highlight novel
opportunities in the context of intelligent vehicles. Finally, we propose an
integrated framework for alleviating MS. The findings of this review will
enhance our understanding of carsickness and offer valuable insights for future
research and practice in MS mitigation within modern vehicles.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00568" title="Abstract">arXiv:2402.00568</a> [<a href="/pdf/2402.00568" title="Download PDF">pdf</a>, <a href="/ps/2402.00568" title="Download PostScript">ps</a>, <a href="/format/2402.00568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Supervised Learning-Based Smart Home Authentication Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sudha%2C+K+S">K. Swapna Sudha</a>, 
<a href="/search/cs?searchtype=author&query=Jeyanthi%2C+N">N. Jeyanthi</a>, 
<a href="/search/cs?searchtype=author&query=Iwendi%2C+C">Celestine Iwendi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The Smart home possesses the capability of facilitating home services to
their users with the systematic advance in The Internet of Things (IoT) and
information and communication technologies (ICT) in recent decades. The home
service offered by the smart devices helps the users in utilize maximized level
of comfort for the objective of improving life quality. As the user and smart
devices communicate through an insecure channel, the smart home environment is
prone to security and privacy problems. A secure authentication protocol needs
to be established between the smart devices and the user, such that a situation
for device authentication can be made feasible in smart home environments. Most
of the existing smart home authentication protocols were identified to fail in
facilitating a secure mutual authentication and increases the possibility of
lunching the attacks of session key disclosure, impersonation and stolen smart
device. In this paper, Secure Supervised Learning-based Smart Home
Authentication Framework (SSL-SHAF) is proposed as are liable mutual
authentication that can be contextually imposed for better security. The formal
analysis of the proposed SSL-SHAF confirmed better resistance against session
key disclosure, impersonation and stolen smart device attacks. The results of
SSL-SHAF confirmed minimized computational costs and security compared to the
baseline protocols considered for investigation.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00575" title="Abstract">arXiv:2402.00575</a> [<a href="/pdf/2402.00575" title="Download PDF">pdf</a>, <a href="/format/2402.00575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-based Light Field Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Ruisheng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yutong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zeyu Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zhiwei Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages,9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Light fields (LFs), conducive to comprehensive scene radiance recorded across
angular dimensions, find wide applications in 3D reconstruction, virtual
reality, and computational photography.However, the LF acquisition is
inevitably time-consuming and resource-intensive due to the mainstream
acquisition strategy involving manual capture or laborious software
synthesis.Given such a challenge, we introduce LFdiff, a straightforward yet
effective diffusion-based generative framework tailored for LF synthesis, which
adopts only a single RGB image as input.LFdiff leverages disparity estimated by
a monocular depth estimation network and incorporates two distinctive
components: a novel condition scheme and a noise estimation network tailored
for LF data.Specifically, we design a position-aware warping condition scheme,
enhancing inter-view geometry learning via a robust conditional signal.We then
propose DistgUnet, a disentanglement-based noise estimation network, to harness
comprehensive LF representations.Extensive experiments demonstrate that LFdiff
excels in synthesizing visually pleasing and disparity-controllable light
fields with enhanced generalization capability.Additionally, comprehensive
results affirm the broad applicability of the generated LF data, spanning
applications like LF super-resolution and refocusing.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00576" title="Abstract">arXiv:2402.00576</a> [<a href="/pdf/2402.00576" title="Download PDF">pdf</a>, <a href="/format/2402.00576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tropical Decision Boundaries for Neural Networks Are Robust Against  Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pasque%2C+K">Kurt Pasque</a>, 
<a href="/search/cs?searchtype=author&query=Teska%2C+C">Christopher Teska</a>, 
<a href="/search/cs?searchtype=author&query=Yoshida%2C+R">Ruriko Yoshida</a>, 
<a href="/search/cs?searchtype=author&query=Miura%2C+K">Keiji Miura</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jefferson Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV); Combinatorics (math.CO)

</div>
<p class="mathjax">We introduce a simple, easy to implement, and computationally efficient
tropical convolutional neural network architecture that is robust against
adversarial attacks. We exploit the tropical nature of piece-wise linear neural
networks by embedding the data in the tropical projective torus in a single
hidden layer which can be added to any model. We study the geometry of its
decision boundary theoretically and show its robustness against adversarial
attacks on image datasets using computational experiments.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00580" title="Abstract">arXiv:2402.00580</a> [<a href="/pdf/2402.00580" title="Download PDF">pdf</a>, <a href="/format/2402.00580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous Unsupervised Domain Adaptation Using Stabilized  Representations and Experience Replay
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rostami%2C+M">Mohammad Rostami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We introduce an algorithm for tackling the problem of unsupervised domain
adaptation (UDA) in continual learning (CL) scenarios. The primary objective is
to maintain model generalization under domain shift when new domains arrive
continually through updating a base model when only unlabeled data is
accessible in subsequent tasks. While there are many existing UDA algorithms,
they typically require access to both the source and target domain datasets
simultaneously. Conversely, existing CL approaches can handle tasks that all
have labeled data. Our solution is based on stabilizing the learned internal
distribution to enhances the model generalization on new domains. The internal
distribution is modeled by network responses in hidden layer. We model this
internal distribution using a Gaussian mixture model (GMM ) and update the
model by matching the internally learned distribution of new domains to the
estimated GMM. Additionally, we leverage experience replay to overcome the
problem of catastrophic forgetting, where the model loses previously acquired
knowledge when learning new tasks. We offer theoretical analysis to explain why
our algorithm would work. We also offer extensive comparative and analytic
experiments to demonstrate that our method is effective. We perform experiments
on four benchmark datasets to demonstrate that our approach is effective.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00585" title="Abstract">arXiv:2402.00585</a> [<a href="/pdf/2402.00585" title="Download PDF">pdf</a>, <a href="/format/2402.00585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SATac: A Thermoluminescence Enabled Tactile Sensor for Concurrent  Perception of Temperature, Pressure, and Shear
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Ziwu Song</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+R">Ran Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sou%2C+K+W">Kit Wa Sou</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+S">Shilong Mu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+D">Dengfeng Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiao-Ping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Wenbo Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Most vision-based tactile sensors use elastomer deformation to infer tactile
information, which can not sense some modalities, like temperature. As an
important part of human tactile perception, temperature sensing can help robots
better interact with the environment. In this work, we propose a novel
multimodal vision-based tactile sensor, SATac, which can simultaneously
perceive information of temperature, pressure, and shear. SATac utilizes
thermoluminescence of strontium aluminate (SA) to sense a wide range of
temperatures with exceptional resolution. Additionally, the pressure and shear
can also be perceived by analyzing Voronoi diagram. A series of experiments are
conducted to verify the performance of our proposed sensor. We also discuss the
possible application scenarios and demonstrate how SATac could benefit robot
perception capabilities.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00588" title="Abstract">arXiv:2402.00588</a> [<a href="/pdf/2402.00588" title="Download PDF">pdf</a>, <a href="/format/2402.00588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BrainSLAM: SLAM on Neural Population Activity Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Freud%2C+K">Kipp Freud</a>, 
<a href="/search/cs?searchtype=author&query=Lepora%2C+N">Nathan Lepora</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+M+W">Matt W. Jones</a>, 
<a href="/search/cs?searchtype=author&query=O%27Donnell%2C+C">Cian O&#x27;Donnell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 23rd International Conference on Autonomous Agents and Multiagent Systems. 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Simultaneous localisation and mapping (SLAM) algorithms are commonly used in
robotic systems for learning maps of novel environments. Brains also appear to
learn maps, but the mechanisms are not known and it is unclear how to infer
these maps from neural activity data. We present BrainSLAM; a method for
performing SLAM using only population activity (local field potential, LFP)
data simultaneously recorded from three brain regions in rats: hippocampus,
prefrontal cortex, and parietal cortex. This system uses a convolutional neural
network (CNN) to decode velocity and familiarity information from wavelet
scalograms of neural local field potential data recorded from rats as they
navigate a 2D maze. The CNN's output drives a RatSLAM-inspired architecture,
powering an attractor network which performs path integration plus a separate
system which performs `loop closure' (detecting previously visited locations
and correcting map aliasing errors). Together, these three components can
construct faithful representations of the environment while simultaneously
tracking the animal's location. This is the first demonstration of inference of
a spatial map from brain recordings. Our findings expand SLAM to a new
modality, enabling a new method of mapping environments and facilitating a
better understanding of the role of cognitive maps in navigation and decision
making.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00591" title="Abstract">arXiv:2402.00591</a> [<a href="/pdf/2402.00591" title="Download PDF">pdf</a>, <a href="/format/2402.00591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sandra -- A Neuro-Symbolic Reasoner Based On Descriptions And Situations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lazzari%2C+N">Nicolas Lazzari</a>, 
<a href="/search/cs?searchtype=author&query=De+Giorgis%2C+S">Stefano De Giorgis</a>, 
<a href="/search/cs?searchtype=author&query=Gangemi%2C+A">Aldo Gangemi</a>, 
<a href="/search/cs?searchtype=author&query=Presutti%2C+V">Valentina Presutti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This paper presents sandra, a neuro-symbolic reasoner combining vectorial
representations with deductive reasoning. Sandra builds a vector space
constrained by an ontology and performs reasoning over it. The geometric nature
of the reasoner allows its combination with neural networks, bridging the gap
with symbolic knowledge representations. Sandra is based on the Description and
Situation (DnS) ontology design pattern, a formalization of frame semantics.
Given a set of facts (a situation) it allows to infer all possible perspectives
(descriptions) that can provide a plausible interpretation for it, even in
presence of incomplete information. We prove that our method is correct with
respect to the DnS model. We experiment with two different tasks and their
standard benchmarks, demonstrating that, without increasing complexity, sandra
(i) outperforms all the baselines (ii) provides interpretability in the
classification process, and (iii) allows control over the vector space, which
is designed a priori.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00592" title="Abstract">arXiv:2402.00592</a> [<a href="/pdf/2402.00592" title="Download PDF">pdf</a>, <a href="/format/2402.00592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-Aware Partial-Label Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fuchs%2C+T">Tobias Fuchs</a>, 
<a href="/search/cs?searchtype=author&query=Kalinke%2C+F">Florian Kalinke</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%B6hm%2C+K">Klemens B&#xf6;hm</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">In real-world applications, one often encounters ambiguously labeled data,
where different annotators assign conflicting class labels. Partial-label
learning allows training classifiers in this weakly supervised setting. While
state-of-the-art methods already feature good predictive performance, they
often suffer from miscalibrated uncertainty estimates. However, having
well-calibrated uncertainty estimates is important, especially in
safety-critical domains like medicine and autonomous driving. In this article,
we propose a novel nearest-neighbor-based partial-label-learning algorithm that
leverages Dempster-Shafer theory. Extensive experiments on artificial and
real-world datasets show that the proposed method provides a well-calibrated
uncertainty estimate and achieves competitive prediction performance.
Additionally, we prove that our algorithm is risk-consistent.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00594" title="Abstract">arXiv:2402.00594</a> [<a href="/pdf/2402.00594" title="Download PDF">pdf</a>, <a href="/format/2402.00594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying relevant Factors of Requirements Quality: an industrial Case  Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frattini%2C+J">Julian Frattini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">[Context and Motivation]: The quality of requirements specifications impacts
subsequent, dependent software engineering activities. Requirements quality
defects like ambiguous statements can result in incomplete or wrong features
and even lead to budget overrun or project failure. [Problem]: Attempts at
measuring the impact of requirements quality have been held back by the vast
amount of interacting factors. Requirements quality research lacks an
understanding of which factors are relevant in practice. [Principal Ideas and
Results]: We conduct a case study considering data from both interview
transcripts and issue reports to identify relevant factors of requirements
quality. The results include 17 factors and 11 interaction effects relevant to
the case company. [Contribution]: The results contribute empirical evidence
that (1) strengthens existing requirements engineering theories and (2)
advances industry-relevant requirements quality research.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00595" title="Abstract">arXiv:2402.00595</a> [<a href="/pdf/2402.00595" title="Download PDF">pdf</a>, <a href="/format/2402.00595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Group Related Phenomena in Wikipedia Edits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Burgess%2C+M">M. Burgess</a>, 
<a href="/search/cs?searchtype=author&query=Dunbar%2C+R+I+M">R.I.M. Dunbar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Multiagent Systems (cs.MA); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Human communities have self-organizing properties that give rise to very
specific natural grouping patterns, reflected in the Dunbar Number and its
layered structure (a Dunbar Graph). Since work-groups are necessarily also
social groups, we might expect the same principles to apply here as well. One
factor likely to be important in limiting the size of groups is that conflicts
typically escalate with the number of people involved. Here we analyse
Wikipedia editing histories across a wide range of topics to show that there is
an emergent coherence in the size of groups formed transiently to edit the
content of subject texts, with two peaks averaging at around $N=8$ for the size
corresponding to maximal contention, and at around $N=4$ as a regular team.
These values are consistent with the observed sizes of conversational groups,
as well as the hierarchical structuring of Dunbar graphs. We use the Promise
Theory of trust to suggest a scaling law that may apply to all group
distributions based on seeded attraction. In addition to providing further
evidence that even natural communities of strangers are self-organising, the
results have important implications for the governance of the Wikipedia commons
and for the security of all online social platforms and associations.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00598" title="Abstract">arXiv:2402.00598</a> [<a href="/pdf/2402.00598" title="Download PDF">pdf</a>, <a href="/format/2402.00598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Promise Theory Perspective on the Role of Intent in Group Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Burgess%2C+M">M. Burgess</a>, 
<a href="/search/cs?searchtype=author&query=Dunbar%2C+R+I+M">R.I.M. Dunbar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Multiagent Systems (cs.MA); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">We present a simple argument using Promise Theory and dimensional analysis
for the Dunbar scaling hierarchy, supported by recent data from group formation
in Wikipedia editing. We show how the assumption of a common priority seeds
group alignment until the costs associated with attending to the group outweigh
the benefits in a detailed balance scenario. Subject to partial efficiency of
implementing promised intentions, we can reproduce a series of compatible rates
that balance growth with entropy.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00606" title="Abstract">arXiv:2402.00606</a> [<a href="/pdf/2402.00606" title="Download PDF">pdf</a>, <a href="/format/2402.00606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Texture Transfer using PatchMatch and Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pu%2C+G">Guo Pu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shiyao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xixin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+Z">Zhouhui Lian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">How to automatically transfer the dynamic texture of a given video to the
target still image is a challenging and ongoing problem. In this paper, we
propose to handle this task via a simple yet effective model that utilizes both
PatchMatch and Transformers. The key idea is to decompose the task of dynamic
texture transfer into two stages, where the start frame of the target video
with the desired dynamic texture is synthesized in the first stage via a
distance map guided texture transfer module based on the PatchMatch algorithm.
Then, in the second stage, the synthesized image is decomposed into
structure-agnostic patches, according to which their corresponding subsequent
patches can be predicted by exploiting the powerful capability of Transformers
equipped with VQ-VAE for processing long discrete sequences. After getting all
those patches, we apply a Gaussian weighted average merging strategy to
smoothly assemble them into each frame of the target stylized video.
Experimental results demonstrate the effectiveness and superiority of the
proposed method in dynamic texture transfer compared to the state of the art.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00607" title="Abstract">arXiv:2402.00607</a> [<a href="/pdf/2402.00607" title="Download PDF">pdf</a>, <a href="/format/2402.00607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Synthetic Time-series Data Really not as Good as Real Data?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+F">Fanzhe Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junru Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Carl Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lvbin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Time-series data presents limitations stemming from data quality issues, bias
and vulnerabilities, and generalization problem. Integrating universal data
synthesis methods holds promise in improving generalization. However, current
methods cannot guarantee that the generator's output covers all unseen real
data. In this paper, we introduce InfoBoost -- a highly versatile cross-domain
data synthesizing framework with time series representation learning
capability. We have developed a method based on synthetic data that enables
model training without the need for real data, surpassing the performance of
models trained with real data. Additionally, we have trained a universal
feature extractor based on our synthetic data that is applicable to all
time-series data. Our approach overcomes interference from multiple sources
rhythmic signal, noise interference, and long-period features that exceed
sampling window capabilities. Through experiments, our non-deep-learning
synthetic data enables models to achieve superior reconstruction performance
and universal explicit representation extraction without the need for real
data.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00608" title="Abstract">arXiv:2402.00608</a> [<a href="/pdf/2402.00608" title="Download PDF">pdf</a>, <a href="/format/2402.00608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Clustering Using the Soft Silhouette Score: Towards Compact and  Well-Separated Clusters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vardakas%2C+G">Georgios Vardakas</a>, 
<a href="/search/cs?searchtype=author&query=Papakostas%2C+I">Ioannis Papakostas</a>, 
<a href="/search/cs?searchtype=author&query=Likas%2C+A">Aristidis Likas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Unsupervised learning has gained prominence in the big data era, offering a
means to extract valuable insights from unlabeled datasets. Deep clustering has
emerged as an important unsupervised category, aiming to exploit the non-linear
mapping capabilities of neural networks in order to enhance clustering
performance. The majority of deep clustering literature focuses on minimizing
the inner-cluster variability in some embedded space while keeping the learned
representation consistent with the original high-dimensional dataset. In this
work, we propose soft silhoutte, a probabilistic formulation of the silhouette
coefficient. Soft silhouette rewards compact and distinctly separated
clustering solutions like the conventional silhouette coefficient. When
optimized within a deep clustering framework, soft silhouette guides the
learned representations towards forming compact and well-separated clusters. In
addition, we introduce an autoencoder-based deep learning architecture that is
suitable for optimizing the soft silhouette objective function. The proposed
deep clustering method has been tested and compared with several well-studied
deep clustering methods on various benchmark datasets, yielding very
satisfactory clustering results.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00612" title="Abstract">arXiv:2402.00612</a> [<a href="/pdf/2402.00612" title="Download PDF">pdf</a>, <a href="/format/2402.00612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rhoban Football Club: RoboCup Humanoid Kid-Size 2023 Champion Team Paper
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Allali%2C+J">Julien Allali</a>, 
<a href="/search/cs?searchtype=author&query=Boussicault%2C+A">Adrien Boussicault</a>, 
<a href="/search/cs?searchtype=author&query=Brocaire%2C+C">Cyprien Brocaire</a>, 
<a href="/search/cs?searchtype=author&query=Dobigeon%2C+C">C&#xe9;line Dobigeon</a>, 
<a href="/search/cs?searchtype=author&query=Duclusaud%2C+M">Marc Duclusaud</a>, 
<a href="/search/cs?searchtype=author&query=Gaspard%2C+C">Cl&#xe9;ment Gaspard</a>, 
<a href="/search/cs?searchtype=author&query=Gimbert%2C+H">Hugo Gimbert</a>, 
<a href="/search/cs?searchtype=author&query=Gondry%2C+L">Lo&#xef;c Gondry</a>, 
<a href="/search/cs?searchtype=author&query=Ly%2C+O">Olivier Ly</a>, 
<a href="/search/cs?searchtype=author&query=Passault%2C+G">Gr&#xe9;goire Passault</a>, 
<a href="/search/cs?searchtype=author&query=Pirrone%2C+A">Antoine Pirrone</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> RoboCup Symposium 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In 2023, Rhoban Football Club reached the first place of the KidSize soccer
competition for the fifth time, and received the best humanoid award. This
paper presents and reviews important points in robots architecture and
workflow, with hindsights from the competition.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00620" title="Abstract">arXiv:2402.00620</a> [<a href="/pdf/2402.00620" title="Download PDF">pdf</a>, <a href="/format/2402.00620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Actor Identification in Discourse: A Challenge for LLMs?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bari%C4%87%2C+A">Ana Bari&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Papay%2C+S">Sean Papay</a>, 
<a href="/search/cs?searchtype=author&query=Pad%C3%B3%2C+S">Sebastian Pad&#xf3;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the EACL 2024 workshop on Computational Models of Discourse (St. Julian's, Malta)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The identification of political actors who put forward claims in public
debate is a crucial step in the construction of discourse networks, which are
helpful to analyze societal debates. Actor identification is, however, rather
challenging: Often, the locally mentioned speaker of a claim is only a pronoun
("He proposed that [claim]"), so recovering the canonical actor name requires
discourse understanding. We compare a traditional pipeline of dedicated NLP
components (similar to those applied to the related task of coreference) with a
LLM, which appears a good match for this generation task. Evaluating on a
corpus of German actors in newspaper reports, we find surprisingly that the LLM
performs worse. Further analysis reveals that the LLM is very good at
identifying the right reference, but struggles to generate the correct
canonical form. This points to an underlying issue in LLMs with controlling
generated output. Indeed, a hybrid model combining the LLM with a classifier to
normalize its output substantially outperforms both initial models.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00622" title="Abstract">arXiv:2402.00622</a> [<a href="/pdf/2402.00622" title="Download PDF">pdf</a>, <a href="/format/2402.00622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gain of Grain: A Film Grain Handling Toolchain for VVC-based Open  Implementations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Menon%2C+V+V">Vignesh V Menon</a>, 
<a href="/search/cs?searchtype=author&query=Wieckowski%2C+A">Adam Wieckowski</a>, 
<a href="/search/cs?searchtype=author&query=Brandenburg%2C+J">Jens Brandenburg</a>, 
<a href="/search/cs?searchtype=author&query=Bross%2C+B">Benjamin Bross</a>, 
<a href="/search/cs?searchtype=author&query=Schierl%2C+T">Thomas Schierl</a>, 
<a href="/search/cs?searchtype=author&query=Marpe%2C+D">Detlev Marpe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024 Mile High Video (MHV)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">Film grain is a distinctive visual characteristic cherished by filmmakers and
cinephiles for its ability to evoke nostalgia and artistic aesthetics. However,
faithful preservation of film grain during encoding poses unique challenges.
Film grain introduces random noise, complicating traditional compression
techniques. Consequently, specialized algorithms and encoding strategies have
emerged, aiming to strike a harmonious equilibrium. This paper delves into the
nuanced realm of film grain handling in Versatile Video Coding (VVC) encoding.
We explore the delicate balance between retaining the cinematic charm of film
grain and achieving efficient compression. Moreover, we discuss the importance
of perceptual quality assessment and adaptive encoding techniques in preserving
film grain fidelity. Additionally, we delve into the impact of film grain
handling on bitrate control and compression efficiency using VVenC, an open and
optimized VVC encoder. Understanding the role of film grain and its nuanced
treatment within encoders becomes increasingly pivotal for delivering
high-quality, grain-inclusive content in the digital age.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00625" title="Abstract">arXiv:2402.00625</a> [<a href="/pdf/2402.00625" title="Download PDF">pdf</a>, <a href="/ps/2402.00625" title="Download PostScript">ps</a>, <a href="/format/2402.00625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bialgebraic Reasoning on Higher-Order Program Equivalence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goncharov%2C+S">Sergey Goncharov</a>, 
<a href="/search/cs?searchtype=author&query=Milius%2C+S">Stefan Milius</a>, 
<a href="/search/cs?searchtype=author&query=Tsampas%2C+S">Stelios Tsampas</a>, 
<a href="/search/cs?searchtype=author&query=Urbat%2C+H">Henning Urbat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Logical relations constitute a key method for reasoning about contextual
equivalence of programs in higher-order languages. They are usually developed
on a per-case basis, with a new theory required for each variation of the
language or of the desired notion of equivalence. In the present paper we
introduce a general construction of (step-indexed) logical relations at the
level of Higher-Order Mathematical Operational Semantics, a highly parametric
categorical framework for modeling the operational semantics of higher-order
languages. Our main result asserts that for languages whose weak operational
model forms a lax bialgebra, the logical relation is automatically sound for
contextual equivalence. Our abstract theory is shown to instantiate to
combinatory logics and $\lambda$-calculi with recursive types, and to different
flavours of contextual equivalence.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00626" title="Abstract">arXiv:2402.00626</a> [<a href="/pdf/2402.00626" title="Download PDF">pdf</a>, <a href="/format/2402.00626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision-LLMs Can Fool Themselves with Self-Generated Typographic Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qraitem%2C+M">Maan Qraitem</a>, 
<a href="/search/cs?searchtype=author&query=Tasnim%2C+N">Nazia Tasnim</a>, 
<a href="/search/cs?searchtype=author&query=Saenko%2C+K">Kate Saenko</a>, 
<a href="/search/cs?searchtype=author&query=Plummer%2C+B+A">Bryan A. Plummer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, significant progress has been made on Large Vision-Language Models
(LVLMs); a new class of VL models that make use of large pre-trained language
models. Yet, their vulnerability to Typographic attacks, which involve
superimposing misleading text onto an image remain unstudied. Furthermore,
prior work typographic attacks rely on sampling a random misleading class from
a predefined set of classes. However, the random chosen class might not be the
most effective attack. To address these issues, we first introduce a novel
benchmark uniquely designed to test LVLMs vulnerability to typographic attacks.
Furthermore, we introduce a new and more effective typographic attack:
Self-Generated typographic attacks. Indeed, our method, given an image, make
use of the strong language capabilities of models like GPT-4V by simply
prompting them to recommend a typographic attack. Using our novel benchmark, we
uncover that typographic attacks represent a significant threat against
LVLM(s). Furthermore, we uncover that typographic attacks recommended by GPT-4V
using our new method are not only more effective against GPT-4V itself compared
to prior work attacks, but also against a host of less capable yet popular open
source models like LLaVA, InstructBLIP, and MiniGPT4.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00627" title="Abstract">arXiv:2402.00627</a> [<a href="/pdf/2402.00627" title="Download PDF">pdf</a>, <a href="/format/2402.00627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CapHuman: Capture Your Moments in Parallel Universes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+C">Chao Liang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+F">Fan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Linchao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yingying Deng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://caphuman.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We concentrate on a novel human-centric image synthesis task, that is, given
only one reference facial photograph, it is expected to generate specific
individual images with diverse head positions, poses, and facial expressions in
different contexts. To accomplish this goal, we argue that our generative model
should be capable of the following favorable characteristics: (1) a strong
visual and semantic understanding of our world and human society for basic
object and human image generation. (2) generalizable identity preservation
ability. (3) flexible and fine-grained head control. Recently, large
pre-trained text-to-image diffusion models have shown remarkable results,
serving as a powerful generative foundation. As a basis, we aim to unleash the
above two capabilities of the pre-trained model. In this work, we present a new
framework named CapHuman. We embrace the ``encode then learn to align"
paradigm, which enables generalizable identity preservation for new individuals
without cumbersome tuning at inference. CapHuman encodes identity features and
then learns to align them into the latent space. Moreover, we introduce the 3D
facial prior to equip our model with control over the human head in a flexible
and 3D-consistent manner. Extensive qualitative and quantitative analyses
demonstrate our CapHuman can produce well-identity-preserved, photo-realistic,
and high-fidelity portraits with content-rich representations and various head
renditions, superior to established baselines. Code and checkpoint will be
released at https://github.com/VamosC/CapHuman.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00629" title="Abstract">arXiv:2402.00629</a> [<a href="/pdf/2402.00629" title="Download PDF">pdf</a>, <a href="/format/2402.00629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cocco: Hardware-Mapping Co-Exploration towards Memory  Capacity-Communication Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhanhong Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zijian Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kaisheng Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Memory is a critical design consideration in current data-intensive DNN
accelerators, as it profoundly determines energy consumption, bandwidth
requirements, and area costs. As DNN structures become more complex, a larger
on-chip memory capacity is required to reduce data movement overhead, but at
the expense of silicon costs. Some previous works have proposed memory-oriented
optimizations, such as different data reuse and layer fusion schemes. However,
these methods are not general and potent enough to cope with various graph
structures.
<br />In this paper, we explore the intrinsic connection between network structures
and memory features to optimize both hardware and mapping. First, we introduce
a graph-level execution scheme with a corresponding dataflow and memory
management method. This scheme enables the execution of arbitrary graph
patterns with high data reuse and low hardware overhead. Subsequently, we
propose Cocco, a hardware-mapping co-exploration framework leveraging
graph-level features of networks. It aims to minimize communication overhead,
such as energy consumption and bandwidth requirements, with a smaller memory
capacity. We formulate the graph-partition scheduling and memory configuration
search as an optimization problem and employ a genetic-based method to achieve
efficient co-exploration for large and irregular networks. Experiments
demonstrate that Cocco obtains lower external memory access, lower bandwidth
requirements, and more stable optimization for graph partition compared to the
greedy algorithm and dynamic programming introduced in prior works. Cocco also
reduces the costs by 1.89% to 50.33% using co-exploration compared to other
typical methods.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00631" title="Abstract">arXiv:2402.00631</a> [<a href="/pdf/2402.00631" title="Download PDF">pdf</a>, <a href="/format/2402.00631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeFi-IDE: Semantic-Fidelity Identity Embedding for Personalized  Diffusion-Based Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Songlin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jing Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Advanced diffusion-based Text-to-Image (T2I) models, such as the Stable
Diffusion Model, have made significant progress in generating diverse and
high-quality images using text prompts alone. However, T2I models are unable to
accurately map identities (IDs) when non-famous users require personalized
image generation. The main problem is that existing T2I models do not learn the
ID-image alignments of new users. The previous methods either failed to
accurately fit the face region or lost the interactive generative ability with
other existing concepts in T2I models (i.e., unable to generate other concepts
described in given prompts such as scenes, actions, and facial attributes). In
this paper, we focus on accurate and semantic-fidelity ID embedding into the
Stable Diffusion Model for personalized generation. We address this challenge
from two perspectives: face-wise region fitting, and semantic-fidelity token
optimization. Specifically, we first visualize the attention overfit problem,
and propose a face-wise attention loss to fit the face region instead of the
whole target image. This key trick significantly enhances the ID accuracy and
interactive generative ability with other existing concepts. Then, we optimize
one ID representation as multiple per-stage tokens where each token contains
two disentangled features. This expansion of the textual conditioning space
enhances semantic-fidelity control. Extensive experiments validate that our
results exhibit superior ID accuracy and manipulation ability compared to
previous methods.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00632" title="Abstract">arXiv:2402.00632</a> [<a href="/pdf/2402.00632" title="Download PDF">pdf</a>, <a href="/format/2402.00632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prosody in Cascade and Direct Speech-to-Text Translation: a case study  on Korean Wh-Phrases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Giulio Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+T+K">Tsz Kin Lam</a>, 
<a href="/search/cs?searchtype=author&query=Birch%2C+A">Alexandra Birch</a>, 
<a href="/search/cs?searchtype=author&query=Haddow%2C+B">Barry Haddow</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Findings of EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Speech-to-Text Translation (S2TT) has typically been addressed with cascade
systems, where speech recognition systems generate a transcription that is
subsequently passed to a translation model. While there has been a growing
interest in developing direct speech translation systems to avoid propagating
errors and losing non-verbal content, prior work in direct S2TT has struggled
to conclusively establish the advantages of integrating the acoustic signal
directly into the translation process. This work proposes using contrastive
evaluation to quantitatively measure the ability of direct S2TT systems to
disambiguate utterances where prosody plays a crucial role. Specifically, we
evaluated Korean-English translation systems on a test set containing
wh-phrases, for which prosodic features are necessary to produce translations
with the correct intent, whether it's a statement, a yes/no question, a
wh-question, and more. Our results clearly demonstrate the value of direct
translation systems over cascade translation models, with a notable 12.9%
improvement in overall accuracy in ambiguous cases, along with up to a 15.6%
increase in F1 scores for one of the major intent categories. To the best of
our knowledge, this work stands as the first to provide quantitative evidence
that direct S2TT models can effectively leverage prosody. The code for our
evaluation is openly accessible and freely available for review and
utilisation.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00637" title="Abstract">arXiv:2402.00637</a> [<a href="/pdf/2402.00637" title="Download PDF">pdf</a>, <a href="/format/2402.00637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fisheye Camera and Ultrasonic Sensor Fusion For Near-Field Obstacle  Perception in Bird&#x27;s-Eye-View
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Arindam Das</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+S">Sudarshan Paul</a>, 
<a href="/search/cs?searchtype=author&query=Scholz%2C+N">Niko Scholz</a>, 
<a href="/search/cs?searchtype=author&query=Malviya%2C+A+K">Akhilesh Kumar Malviya</a>, 
<a href="/search/cs?searchtype=author&query=Sistu%2C+G">Ganesh Sistu</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+U">Ujjwal Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Eising%2C+C">Ciar&#xe1;n Eising</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 12 Figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurate obstacle identification represents a fundamental challenge within
the scope of near-field perception for autonomous driving. Conventionally,
fisheye cameras are frequently employed for comprehensive surround-view
perception, including rear-view obstacle localization. However, the performance
of such cameras can significantly deteriorate in low-light conditions, during
nighttime, or when subjected to intense sun glare. Conversely, cost-effective
sensors like ultrasonic sensors remain largely unaffected under these
conditions. Therefore, we present, to our knowledge, the first end-to-end
multimodal fusion model tailored for efficient obstacle perception in a
bird's-eye-view (BEV) perspective, utilizing fisheye cameras and ultrasonic
sensors. Initially, ResNeXt-50 is employed as a set of unimodal encoders to
extract features specific to each modality. Subsequently, the feature space
associated with the visible spectrum undergoes transformation into BEV. The
fusion of these two modalities is facilitated via concatenation. At the same
time, the ultrasonic spectrum-based unimodal feature maps pass through
content-aware dilated convolution, applied to mitigate the sensor misalignment
between two sensors in the fused feature space. Finally, the fused features are
utilized by a two-stage semantic occupancy decoder to generate grid-wise
predictions for precise obstacle perception. We conduct a systematic
investigation to determine the optimal strategy for multimodal fusion of both
sensors. We provide insights into our dataset creation procedures, annotation
guidelines, and perform a thorough data analysis to ensure adequate coverage of
all scenarios. When applied to our dataset, the experimental results underscore
the robustness and effectiveness of our proposed multimodal fusion approach.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00638" title="Abstract">arXiv:2402.00638</a> [<a href="/pdf/2402.00638" title="Download PDF">pdf</a>, <a href="/ps/2402.00638" title="Download PostScript">ps</a>, <a href="/format/2402.00638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random Forest-Based Prediction of Stroke Outcome
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fernandez-Lozano%2C+C">Carlos Fernandez-Lozano</a>, 
<a href="/search/cs?searchtype=author&query=Hervella%2C+P">Pablo Hervella</a>, 
<a href="/search/cs?searchtype=author&query=Mato-Abad%2C+V">Virginia Mato-Abad</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez-Yanez%2C+M">Manuel Rodriguez-Yanez</a>, 
<a href="/search/cs?searchtype=author&query=Suarez-Garaboa%2C+S">Sonia Suarez-Garaboa</a>, 
<a href="/search/cs?searchtype=author&query=Lopez-Dequidt%2C+I">Iria Lopez-Dequidt</a>, 
<a href="/search/cs?searchtype=author&query=Estany-Gestal%2C+A">Ana Estany-Gestal</a>, 
<a href="/search/cs?searchtype=author&query=Sobrino%2C+T">Tomas Sobrino</a>, 
<a href="/search/cs?searchtype=author&query=Campos%2C+F">Francisco Campos</a>, 
<a href="/search/cs?searchtype=author&query=Castillo%2C+J">Jose Castillo</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez-Yanez%2C+S">Santiago Rodriguez-Yanez</a>, 
<a href="/search/cs?searchtype=author&query=Iglesias-Rey%2C+R">Ramon Iglesias-Rey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We research into the clinical, biochemical and neuroimaging factors
associated with the outcome of stroke patients to generate a predictive model
using machine learning techniques for prediction of mortality and morbidity 3
months after admission. The dataset consisted of patients with ischemic stroke
(IS) and non-traumatic intracerebral hemorrhage (ICH) admitted to Stroke Unit
of a European Tertiary Hospital prospectively registered. We identified the
main variables for machine learning Random Forest (RF), generating a predictive
model that can estimate patient mortality/morbidity. In conclusion, machine
learning algorithms RF can be effectively used in stroke patients for long-term
outcome prediction of mortality and morbidity.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00641" title="Abstract">arXiv:2402.00641</a> [<a href="/pdf/2402.00641" title="Download PDF">pdf</a>, <a href="/format/2402.00641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing side-channel security of cryptographic implementations against  future microarchitectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barthe%2C+G">Gilles Barthe</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%B6hme%2C+M">Marcel B&#xf6;hme</a>, 
<a href="/search/cs?searchtype=author&query=Cauligi%2C+S">Sunjay Cauligi</a>, 
<a href="/search/cs?searchtype=author&query=Chuengsatiansup%2C+C">Chitchanok Chuengsatiansup</a>, 
<a href="/search/cs?searchtype=author&query=Genkin%2C+D">Daniel Genkin</a>, 
<a href="/search/cs?searchtype=author&query=Guarnieri%2C+M">Marco Guarnieri</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+D+M">David Mateos Romero</a>, 
<a href="/search/cs?searchtype=author&query=Schwabe%2C+P">Peter Schwabe</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">David Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yarom%2C+Y">Yuval Yarom</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">How will future microarchitectures impact the security of existing
cryptographic implementations? As we cannot keep reducing the size of
transistors, chip vendors have started developing new microarchitectural
optimizations to speed up computation. A recent study (Sanchez Vicarte et al.,
ISCA 2021) suggests that these optimizations might open the Pandora's box of
microarchitectural attacks. However, there is little guidance on how to
evaluate the security impact of future optimization proposals.
<br />To help chip vendors explore the impact of microarchitectural optimizations
on cryptographic implementations, we develop (i) an expressive domain-specific
language, called LmSpec, that allows them to specify the leakage model for the
given optimization and (ii) a testing framework, called LmTest, to
automatically detect leaks under the specified leakage model within the given
implementation. Using this framework, we conduct an empirical study of 18
proposed microarchitectural optimizations on 25 implementations of eight
cryptographic primitives in five popular libraries. We find that every
implementation would contain secret-dependent leaks, sometimes sufficient to
recover a victim's secret key, if these optimizations were realized.
Ironically, some leaks are possible only because of coding idioms used to
prevent leaks under the standard constant-time model.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00646" title="Abstract">arXiv:2402.00646</a> [<a href="/pdf/2402.00646" title="Download PDF">pdf</a>, <a href="/ps/2402.00646" title="Download PostScript">ps</a>, <a href="/format/2402.00646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cell-Free Massive MIMO SWIPT with Beyond Diagonal Reconfigurable  Intelligent Surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hua%2C+T+D">Thien Duc Hua</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadi%2C+M">Mohammadali Mohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Ngo%2C+H+Q">Hien Quoc Ngo</a>, 
<a href="/search/cs?searchtype=author&query=Matthaiou%2C+M">Michail Matthaiou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper investigates the integration of beyond-diagonal reconfigurable
intelligent surfaces (BD-RISs) into cell-free massive multiple-input
multiple-output (CF-mMIMO) systems, focusing on applications involving
simultaneous wireless information and power transfer (SWIPT). The system
supports concurrently two user groups: information users (IUs) and energy users
(EUs). A BD-RIS is employed to enhance the wireless power transfer (WPT)
directed towards the EUs. To comprehensively evaluate the system's performance,
we present an analytical framework for the spectral efficiency (SE) of IUs and
the average harvested energy (HE) of EUs in the presence of spatial correlation
among the BD-RIS elements and for a non-linear energy harvesting circuit. Our
findings offer important insights into the transformative potential of BD-RIS,
setting the stage for the development of more efficient and effective SWIPT
networks. Finally, incorporating a heuristic scattering matrix design at the
BD-RIS results in a substantial improvement compared to the scenario with
random scattering matrix design.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00649" title="Abstract">arXiv:2402.00649</a> [<a href="/pdf/2402.00649" title="Download PDF">pdf</a>, <a href="/format/2402.00649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the Representativeness of Simulation Intervals for the Cache  Memory System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bueno%2C+N">Nicolas Bueno</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+F">Fernando Castro</a>, 
<a href="/search/cs?searchtype=author&query=Pinuel%2C+L">Luis Pinuel</a>, 
<a href="/search/cs?searchtype=author&query=Gomez-Perez%2C+J+I">Jose Ignacio Gomez-Perez</a>, 
<a href="/search/cs?searchtype=author&query=Catthoor%2C+F">Francky Catthoor</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Access, vol. 12, pp. 5973-5985, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Accurate simulation techniques are indispensable to efficiently propose new
memory or architectural organizations. As implementing new hardware concepts in
real systems is often not feasible, cycle-accurate simulators employed together
with certain benchmarks are commonly used. However, detailed simulators may
take too much time to execute these programs until completion. Therefore,
several techniques aimed at reducing this time are usually employed. These
schemes select fragments of the source code considered as representative of the
entire application's behaviour -- mainly in terms of performance, but not
plenty considering the behaviour of cache memory levels -- and only these
intervals are simulated. Our hypothesis is that the different simulation
windows currently employed when evaluating microarchitectural proposals,
especially those involving the last level cache (LLC), do not reproduce the
overall cache behaviour during the entire execution, potentially leading to
wrong conclusions on the real performance of the proposals assessed. In this
work, we first demonstrate this hypothesis by evaluating different cache
replacement policies using various typical simulation approaches. Consequently,
we also propose a simulation strategy, based on the applications' LLC activity,
which mimics the overall behaviour of the cache much closer than conventional
simulation intervals. Our proposal allows a fairer comparison between
cache-related approaches as it reports, on average, a number of changes in the
relative order among the policies assessed -- with respect to the full
simulation -- more than 30\% lower than that of conventional strategies,
maintaining the simulation time largely unchanged and without losing accuracy
on performance terms, especially for memory-intensive applications.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00652" title="Abstract">arXiv:2402.00652</a> [<a href="/pdf/2402.00652" title="Download PDF">pdf</a>, <a href="/format/2402.00652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polycube Layouts via Iterative Dual Loops
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Snoep%2C+M">Maxim Snoep</a>, 
<a href="/search/cs?searchtype=author&query=Speckmann%2C+B">Bettina Speckmann</a>, 
<a href="/search/cs?searchtype=author&query=Verbeek%2C+K">Kevin Verbeek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">Polycube layouts for 3D models effectively support a wide variety of methods
such as hex-mesh construction, seamless texture mapping, spline fitting, and
multi-block grid generation. Our study of polycube layouts is motivated by
conformal mesh generation for aerospace modelling. In this setting, quality and
correctness guarantees are of the utmost importance. However, currently the
fully automatic construction of valid polycube layouts still poses significant
challenges: state-of-the-art methods are generally not guaranteed to return a
proper solution, even after post-processing, or they use a prohibitively large
number of voxels that add detail indiscriminately.
<br />In this paper we present a robust, flexible, and efficient method to generate
polycube layouts. Our approach is based on a dual representation for polycube
layouts and builds a layout by iteratively adding dual loops. Our construction
is robust by design: at any iterative step we maintain a valid polycube layout.
We offer the flexibility of manual intervention if the user so desires: while
our method is able to compute a complete polycube layout without user
intervention, the user can interrupt after each iteration and target further
refinement on both the local and the global level. Last but not least, our
method is efficient and can be implemented using comparatively simple
algorithmic building blocks. Our implementation is publicly available and we
present its output for numerous benchmark models.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00654" title="Abstract">arXiv:2402.00654</a> [<a href="/pdf/2402.00654" title="Download PDF">pdf</a>, <a href="/ps/2402.00654" title="Download PostScript">ps</a>, <a href="/format/2402.00654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the accuracy of freight mode choice models: A case study using  the 2017 CFS PUF data set and ensemble learning techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Diyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+H">Hyeonsup Lim</a>, 
<a href="/search/cs?searchtype=author&query=Uddin%2C+M">Majbah Uddin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuandong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L+D">Lee D. Han</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+H">Ho-ling Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Chin%2C+S">Shih-Miao Chin</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Expert Systems with Applications, 240, 122478 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The US Census Bureau has collected two rounds of experimental data from the
Commodity Flow Survey, providing shipment-level characteristics of nationwide
commodity movements, published in 2012 (i.e., Public Use Microdata) and in 2017
(i.e., Public Use File). With this information, data-driven methods have become
increasingly valuable for understanding detailed patterns in freight logistics.
In this study, we used the 2017 Commodity Flow Survey Public Use File data set
to explore building a high-performance freight mode choice model, considering
three main improvements: (1) constructing local models for each separate
commodity/industry category; (2) extracting useful geographical features,
particularly the derived distance of each freight mode between
origin/destination zones; and (3) applying additional ensemble learning methods
such as stacking or voting to combine results from local and unified models for
improved performance. The proposed method achieved over 92% accuracy without
incorporating external information, an over 19% increase compared to directly
fitting Random Forests models over 10,000 samples. Furthermore, SHAP (Shapely
Additive Explanations) values were computed to explain the outputs and major
patterns obtained from the proposed model. The model framework could enhance
the performance and interpretability of existing freight mode choice models.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00657" title="Abstract">arXiv:2402.00657</a> [<a href="/pdf/2402.00657" title="Download PDF">pdf</a>, <a href="/format/2402.00657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-training by Predicting Program Dependencies for Vulnerability  Analysis Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhongxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhijie Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaohu Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICSE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Vulnerability analysis is crucial for software security. This work focuses on
using pre-training techniques to enhance the understanding of vulnerable code
and boost vulnerability analysis. The code understanding ability of a
pre-trained model is highly related to its pre-training objectives. The
semantic structure, e.g., control and data dependencies, of code is important
for vulnerability analysis. However, existing pre-training objectives either
ignore such structure or focus on learning to use it. The feasibility and
benefits of learning the knowledge of analyzing semantic structure have not
been investigated. To this end, this work proposes two novel pre-training
objectives, namely Control Dependency Prediction (CDP) and Data Dependency
Prediction (DDP), which aim to predict the statement-level control dependencies
and token-level data dependencies, respectively, in a code snippet only based
on its source code. During pre-training, CDP and DDP can guide the model to
learn the knowledge required for analyzing fine-grained dependencies in code.
After pre-training, the pre-trained model can boost the understanding of
vulnerable code during fine-tuning and can directly be used to perform
dependence analysis for both partial and complete functions. To demonstrate the
benefits of our pre-training objectives, we pre-train a Transformer model named
PDBERT with CDP and DDP, fine-tune it on three vulnerability analysis tasks,
i.e., vulnerability detection, vulnerability classification, and vulnerability
assessment, and also evaluate it on program dependence analysis. Experimental
results show that PDBERT benefits from CDP and DDP, leading to state-of-the-art
performance on the three downstream tasks. Also, PDBERT achieves F1-scores of
over 99% and 94% for predicting control and data dependencies, respectively, in
partial and complete functions.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00658" title="Abstract">arXiv:2402.00658</a> [<a href="/pdf/2402.00658" title="Download PDF">pdf</a>, <a href="/format/2402.00658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Planning-based Reasoning by Trajectories Collection and Process  Reward Synthesizing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiao%2C+F">Fangkai Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+C">Chengwei Qin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N+F">Nancy F. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Joty%2C+S">Shafiq Joty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Language Models (LLMs) have demonstrated significant potential in
handling complex reasoning tasks through step-by-step rationale generation.
However, recent studies have raised concerns regarding the hallucination and
flaws in their reasoning process. Substantial efforts are being made to improve
the reliability and faithfulness of the generated rationales. Some approaches
model reasoning as planning, while others focus on annotating for process
supervision. Nevertheless, the planning-based search process often results in
high latency due to the frequent assessment of intermediate reasoning states
and the extensive exploration space. Additionally, supervising the reasoning
process with human annotation is costly and challenging to scale for LLM
training. To address these issues, in this paper, we propose a framework to
learn planning-based reasoning through direct preference optimization (DPO) on
collected trajectories, which are ranked according to synthesized process
rewards. Our results on challenging logical reasoning benchmarks demonstrate
the effectiveness of our learning framework, showing that our 7B model can
surpass the strong counterparts like GPT-3.5-Turbo.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00659" title="Abstract">arXiv:2402.00659</a> [<a href="/pdf/2402.00659" title="Download PDF">pdf</a>, <a href="/ps/2402.00659" title="Download PostScript">ps</a>, <a href="/format/2402.00659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Freight Mode Choice Using Machine Learning Classifiers: A  Comparative Study Using the Commodity Flow Survey (CFS) Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uddin%2C+M">Majbah Uddin</a>, 
<a href="/search/cs?searchtype=author&query=Anowar%2C+S">Sabreena Anowar</a>, 
<a href="/search/cs?searchtype=author&query=Eluru%2C+N">Naveen Eluru</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transportation Planning and Technology, 44(5), 543-559 (2021)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This study explores the usefulness of machine learning classifiers for
modeling freight mode choice. We investigate eight commonly used machine
learning classifiers, namely Naive Bayes, Support Vector Machine, Artificial
Neural Network, K-Nearest Neighbors, Classification and Regression Tree, Random
Forest, Boosting and Bagging, along with the classical Multinomial Logit model.
US 2012 Commodity Flow Survey data are used as the primary data source; we
augment it with spatial attributes from secondary data sources. The performance
of the classifiers is compared based on prediction accuracy results. The
current research also examines the role of sample size and training-testing
data split ratios on the predictive ability of the various approaches. In
addition, the importance of variables is estimated to determine how the
variables influence freight mode choice. The results show that the tree-based
ensemble classifiers perform the best. Specifically, Random Forest produces the
most accurate predictions, closely followed by Boosting and Bagging. With
regard to variable importance, shipment characteristics, such as shipment
distance, industry classification of the shipper and shipment size, are the
most significant factors for freight mode choice decisions.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00663" title="Abstract">arXiv:2402.00663</a> [<a href="/pdf/2402.00663" title="Download PDF">pdf</a>, <a href="/ps/2402.00663" title="Download PostScript">ps</a>, <a href="/format/2402.00663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transferring human emotions to robot motions using Neural Policy Style  Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fernandez-Fernandez%2C+R">Raul Fernandez-Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=%C5%81ukawski%2C+B">Bartek &#x141;ukawski</a>, 
<a href="/search/cs?searchtype=author&query=Victores%2C+J+G">Juan G. Victores</a>, 
<a href="/search/cs?searchtype=author&query=Pacchierotti%2C+C">Claudio Pacchierotti</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Cognitive Systems Research, Volume 82, December 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Neural Style Transfer (NST) was originally proposed to use feature extraction
capabilities of Neural Networks as a way to perform Style Transfer with images.
Pre-trained image classification architectures were selected for feature
extraction, leading to new images showing the same content as the original but
with a different style. In robotics, Style Transfer can be employed to transfer
human motion styles to robot motions. The challenge lies in the lack of
pre-trained classification architectures for robot motions that could be used
for feature extraction. Neural Policy Style Transfer TD3 (NPST3) is proposed
for the transfer of human motion styles to robot motions. This framework allows
the same robot motion to be executed in different human-centered motion styles,
such as in an angry, happy, calm, or sad fashion. The Twin Delayed Deep
Deterministic Policy Gradient (TD3) network is introduced for the generation of
control policies. An autoencoder network is in charge of feature extraction for
the Style Transfer step. The Style Transfer step can be performed both offline
and online: offline for the autonomous executions of human-style robot motions,
and online for adapting at runtime the style of e.g., a teleoperated robot. The
framework is tested using two different robotic platforms: a robotic
manipulator designed for telemanipulation tasks, and a humanoid robot designed
for social interaction. The proposed approach was evaluated for both platforms,
performing a total of 147 questionnaires asking human subjects to recognize the
human motion style transferred to the robot motion for a predefined set of
actions.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00665" title="Abstract">arXiv:2402.00665</a> [<a href="/pdf/2402.00665" title="Download PDF">pdf</a>, <a href="/format/2402.00665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revising Apetrei&#x27;s bounding volume hierarchy construction algorithm to  allow stackless traversal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prokopenko%2C+A">Andrey Prokopenko</a>, 
<a href="/search/cs?searchtype=author&query=Lebrun-Grandi%C3%A9%2C+D">Damien Lebrun-Grandi&#xe9;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Stackless traversal is a technique to speed up range queries by avoiding
usage of a stack during the tree traversal. One way to achieve that is to
transform a given binary tree to store a left child and a skip-connection (also
called an escape index). In general, this operation requires an additional tree
traversal during the tree construction. For some tree structures, however, it
is possible achieve the same result at a reduced cost. We propose one such
algorithm for a GPU hierarchy construction algorithm proposed by Karras in
[Karras, 2012]. Furthermore, we show that our algorithm also works with the
improved algorithm proposed by Apetrei in [Apetrei, 2014], despite a different
ordering of the internal nodes. We achieve that by modifying the Apetrei's
algorithm to restore the original Karras' ordering of the internal nodes. Using
the modified algorithm, we show how to construct a hierarchy suitable for a
stackless traversal in a single bottom-up pass.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00667" title="Abstract">arXiv:2402.00667</a> [<a href="/pdf/2402.00667" title="Download PDF">pdf</a>, <a href="/format/2402.00667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Weak-to-Strong Generalization with Scalable Oversight and  Ensemble Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sang%2C+J">Jitao Sang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuhang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yanxu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+C">Chao Kong</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Junhong Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Shuyu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jinlin Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper presents a follow-up study to OpenAI's recent superalignment work
on Weak-to-Strong Generalization (W2SG). Superalignment focuses on ensuring
that high-level AI systems remain consistent with human values and intentions
when dealing with complex, high-risk tasks. The W2SG framework has opened new
possibilities for empirical research in this evolving field. Our study
simulates two phases of superalignment under the W2SG framework: the
development of general superhuman models and the progression towards
superintelligence. In the first phase, based on human supervision, the quality
of weak supervision is enhanced through a combination of scalable oversight and
ensemble learning, reducing the capability gap between weak teachers and strong
students. In the second phase, an automatic alignment evaluator is employed as
the weak supervisor. By recursively updating this auto aligner, the
capabilities of the weak teacher models are synchronously enhanced, achieving
weak-to-strong supervision over stronger student models.We also provide an
initial validation of the proposed approach for the first phase. Using the SciQ
task as example, we explore ensemble learning for weak teacher models through
bagging and boosting. Scalable oversight is explored through two auxiliary
settings: human-AI interaction and AI-AI debate. Additionally, the paper
discusses the impact of improved weak supervision on enhancing weak-to-strong
generalization based on in-context learning. Experiment code and dataset will
be released at https://github.com/ADaM-BJTU/W2SG.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00670" title="Abstract">arXiv:2402.00670</a> [<a href="/pdf/2402.00670" title="Download PDF">pdf</a>, <a href="/format/2402.00670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECALL: Expectation-calibrated learning for unsupervised blind  deconvolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Haltmeier%2C+M">Markus Haltmeier</a>, 
<a href="/search/math?searchtype=author&query=Hwang%2C+G">Gyeongha Hwang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Blind deconvolution aims to recover an original image from a blurred version
in the case where the blurring kernel is unknown. It has wide applications in
diverse fields such as astronomy, microscopy, and medical imaging. Blind
deconvolution is a challenging ill-posed problem that suffers from significant
non-uniqueness. Solution methods therefore require the integration of
appropriate prior information. Early approaches rely on hand-crafted priors for
the original image and the kernel. Recently, deep learning methods have shown
excellent performance in addressing this challenge. However, most existing
learning methods for blind deconvolution require a paired dataset of original
and blurred images, which is often difficult to obtain. In this paper, we
present a novel unsupervised learning approach named ECALL
(Expectation-CALibrated Learning) that uses separate unpaired collections of
original and blurred images. Key features of the proposed loss function are
cycle consistency involving the kernel and associated reconstruction operator,
and terms that use expectation values of data distributions to obtain
information about the kernel. Numerical results are used to support ECALL.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00671" title="Abstract">arXiv:2402.00671</a> [<a href="/pdf/2402.00671" title="Download PDF">pdf</a>, <a href="/format/2402.00671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-Aware Guidance for Target Tracking subject to Intermittent  Measurements using Motion Model Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pulido%2C+A">Andres Pulido</a>, 
<a href="/search/eess?searchtype=author&query=Volle%2C+K">Kyle Volle</a>, 
<a href="/search/eess?searchtype=author&query=Waters%2C+K">Kristy Waters</a>, 
<a href="/search/eess?searchtype=author&query=Bell%2C+Z+I">Zachary I. Bell</a>, 
<a href="/search/eess?searchtype=author&query=Ganesh%2C+P">Prashant Ganesh</a>, 
<a href="/search/eess?searchtype=author&query=Shin%2C+J">Jane Shin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This letter presents a novel guidance law for target tracking applications
where the target motion model is unknown and sensor measurements are
intermittent due to unknown environmental conditions and low measurement update
rate. In this work, the target motion model is represented by a
transformer-based neural network and trained by previous target position
measurements. This neural network (NN)-based motion model serves as the
prediction step in a particle filter for target state estimation and
uncertainty quantification. Then this estimation uncertainty is utilized in the
information-driven guidance law to compute a path for the mobile agent to
travel to a position with maximum expected entropy reduction (EER). The
computation of EER is performed in real-time by approximating the probability
distribution of the state using the particle representation from particle
filter. Simulation and hardware experiments are performed with a quadcopter
agent and TurtleBot target to demonstrate that the presented guidance law
outperforms two other baseline guidance methods.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00672" title="Abstract">arXiv:2402.00672</a> [<a href="/pdf/2402.00672" title="Download PDF">pdf</a>, <a href="/format/2402.00672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Homogeneous and Heterogeneous Consistent Label Associations  for Unsupervised Visible-Infrared Person ReID
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lingfeng He</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+D">De Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Nannan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Unsupervised visible-infrared person re-identification (USL-VI-ReID) aims to
retrieve pedestrian images of the same identity from different modalities
without annotations. While prior work focuses on establishing cross-modality
pseudo-label associations to bridge the modality-gap, they ignore maintaining
the instance-level homogeneous and heterogeneous consistency in pseudo-label
space, resulting in coarse associations. In response, we introduce a
Modality-Unified Label Transfer (MULT) module that simultaneously accounts for
both homogeneous and heterogeneous fine-grained instance-level structures,
yielding high-quality cross-modality label associations. It models both
homogeneous and heterogeneous affinities, leveraging them to define the
inconsistency for the pseudo-labels and then minimize it, leading to
pseudo-labels that maintain alignment across modalities and consistency within
intra-modality structures. Additionally, a straightforward plug-and-play Online
Cross-memory Label Refinement (OCLR) module is proposed to further mitigate the
impact of noisy pseudo-labels while simultaneously aligning different
modalities, coupled with a Modality-Invariant Representation Learning (MIRL)
framework. Experiments demonstrate that our proposed method outperforms
existing USL-VI-ReID methods, highlighting the superiority of our MULT in
comparison to other cross-modality association methods. The code will be
available.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00675" title="Abstract">arXiv:2402.00675</a> [<a href="/pdf/2402.00675" title="Download PDF">pdf</a>, <a href="/ps/2402.00675" title="Download PostScript">ps</a>, <a href="/format/2402.00675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Modular Algorithms and Butterfly Operations in Number Theoretic  Transform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yanze Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yiran Jia</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guangwu Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Number theoretic transform (NTT) has been a very useful tool in computations
for number theory, algebra and cryptography. Its performance affects some
post-quantum cryptosystems. In this paper, we discuss the butterfly operation
of NTT. This basic module of NTT requires heavy modular arithmetics. Montgomery
reduction is commonly used in this setting. Recently several variants of
Montgomery algorithm have been proposed for the purpose of speeding up NTT. We
observe that the Chinese remainder theorem (CRT) can be involved in this type
of algorithms in nature and transparent ways. In this paper, a framework of
using CRT to model Montgomery type algorithms is described. The derivation of
these algorithms as well as their correctness are all treated in the CRT
framework. Under our approach, some problems of a modular reduction algorithm
(published in IACR Transactions on Cryptographic Hardware and Embedded Systems,
doi:10.46586/tches.v2022.i4.614-636 ) are identified, and a counterexample is
generated to show that the algorithm is incorrect.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00676" title="Abstract">arXiv:2402.00676</a> [<a href="/pdf/2402.00676" title="Download PDF">pdf</a>, <a href="/ps/2402.00676" title="Download PostScript">ps</a>, <a href="/format/2402.00676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Robot Sketching: An application of Deep Q-Learning Networks for  human-like sketching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fernandez-Fernandez%2C+R">Raul Fernandez-Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=Victores%2C+J+G">Juan G. Victores</a>, 
<a href="/search/cs?searchtype=author&query=Balaguer%2C+C">Carlos Balaguer</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Cognitive Systems Research, Volume 81, September 2023, pages 57 to
  63
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">The current success of Reinforcement Learning algorithms for its performance
in complex environments has inspired many recent theoretical approaches to
cognitive science. Artistic environments are studied within the cognitive
science community as rich, natural, multi-sensory, multi-cultural environments.
In this work, we propose the introduction of Reinforcement Learning for
improving the control of artistic robot applications. Deep Q-learning Neural
Networks (DQN) is one of the most successful algorithms for the implementation
of Reinforcement Learning in robotics. DQN methods generate complex control
policies for the execution of complex robot applications in a wide set of
environments. Current art painting robot applications use simple control laws
that limits the adaptability of the frameworks to a set of simple environments.
In this work, the introduction of DQN within an art painting robot application
is proposed. The goal is to study how the introduction of a complex control
policy impacts the performance of a basic art painting robot application. The
main expected contribution of this work is to serve as a first baseline for
future works introducing DQN methods for complex art painting robot frameworks.
Experiments consist of real world executions of human drawn sketches using the
DQN generated policy and TEO, the humanoid robot. Results are compared in terms
of similarity and obtained reward with respect to the reference inputs
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00677" title="Abstract">arXiv:2402.00677</a> [<a href="/pdf/2402.00677" title="Download PDF">pdf</a>, <a href="/format/2402.00677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Policy Style Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fernandez-Fernandez%2C+R">Raul Fernandez-Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=Victores%2C+J+G">Juan G. Victores</a>, 
<a href="/search/cs?searchtype=author&query=Gago%2C+J+J">Jennifer J. Gago</a>, 
<a href="/search/cs?searchtype=author&query=Estevez%2C+D">David Estevez</a>, 
<a href="/search/cs?searchtype=author&query=Balaguer%2C+C">Carlos Balaguer</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Cognitive Systems Research, Volume 72, March 2022, Pages 23 to 32
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Style Transfer has been proposed in a number of fields: fine arts, natural
language processing, and fixed trajectories. We scale this concept up to
control policies within a Deep Reinforcement Learning infrastructure. Each
network is trained to maximize the expected reward, which typically encodes the
goal of an action, and can be described as the content. The expressive power of
deep neural networks enables encoding a secondary task, which can be described
as the style. The Neural Policy Style Transfer (NPST) algorithm is proposed to
transfer the style of one policy to another, while maintaining the content of
the latter. Different policies are defined via Deep Q-Network architectures.
These models are trained using demonstrations through Inverse Reinforcement
Learning. Two different sets of user demonstrations are performed, one for
content and other for style. Different styles are encoded as defined by user
demonstrations. The generated policy is the result of feeding a content policy
and a style policy to the NPST algorithm. Experiments are performed in a
catch-ball game inspired by the Deep Reinforcement Learning classical Atari
games; and a real-world painting scenario with a full-sized humanoid robot,
based on previous works of the authors. The implementation of three different
Q-Network architectures (Shallow, Deep and Deep Recurrent Q-Network) to encode
the policies within the NPST framework is proposed and the results obtained in
the experiments with each of these architectures compared.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00678" title="Abstract">arXiv:2402.00678</a> [<a href="/pdf/2402.00678" title="Download PDF">pdf</a>, <a href="/ps/2402.00678" title="Download PostScript">ps</a>, <a href="/format/2402.00678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real Evaluations Tractability using Continuous Goal-Directed Actions in  Smart City Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fernandez-Fernandez%2C+R">Raul Fernandez-Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=Victores%2C+J+G">Juan G. Victores</a>, 
<a href="/search/cs?searchtype=author&query=Estevez%2C+D">David Estevez</a>, 
<a href="/search/cs?searchtype=author&query=Balaguer%2C+C">Carlos Balaguer</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sensors, Volume 18, Issue 11, 2018
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">One of the most important challenges of Smart City Applications is to adapt
the system to interact with non-expert users. Robot imitation frameworks aim to
simplify and reduce times of robot programming by allowing users to program
directly through demonstrations. In classical frameworks, actions are modeled
using joint or Cartesian space trajectories. Other features, such as visual
ones, are not always well represented with these pure geometrical approaches.
Continuous Goal-Directed Actions (CGDA) is an alternative to these methods, as
it encodes actions as changes of any feature that can be extracted from the
environment. As a consequence of this, the robot joint trajectories for
execution must be fully computed to comply with this feature-agnostic encoding.
This is achieved using Evolutionary Algorithms (EA), which usually requires too
many evaluations to perform this evolution step in the actual robot. Current
strategies involve performing evaluations in a simulation, transferring the
final joint trajectory to the actual robot. Smart City applications involve
working in highly dynamic and complex environments, where having a precise
model is not always achievable. Our goal is to study the tractability of
performing these evaluations directly in a real-world scenario. Two different
approaches to reduce the number of evaluations using EA, are proposed and
compared. In the first approach, Particle Swarm Optimization (PSO)-based
methods have been studied and compared within CGDA: naive PSO, Fitness
Inheritance PSO (FI-PSO), and Adaptive Fuzzy Fitness Granulation with PSO
(AFFG-PSO). The second approach studied the introduction of geometrical and
velocity constraints within CGDA. The effects of both approaches were analyzed
and compared in the wax and paint actions, two CGDA commonly studied use cases.
Results from this paper depict an important reduction in the number of
evaluations.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00681" title="Abstract">arXiv:2402.00681</a> [<a href="/pdf/2402.00681" title="Download PDF">pdf</a>, <a href="/ps/2402.00681" title="Download PostScript">ps</a>, <a href="/format/2402.00681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling-based Stochastic Data-driven Predictive Control under Data  Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Teutsch%2C+J">Johannes Teutsch</a>, 
<a href="/search/eess?searchtype=author&query=Kerz%2C+S">Sebastian Kerz</a>, 
<a href="/search/eess?searchtype=author&query=Wollherr%2C+D">Dirk Wollherr</a>, 
<a href="/search/eess?searchtype=author&query=Leibold%2C+M">Marion Leibold</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">We present a stochastic output-feedback data-driven predictive control scheme
for linear time-invariant systems subject to bounded additive disturbances and
probabilistic chance constraints. The approach uses data-driven predictors
based on an extension of Willems' fundamental lemma from behavioral systems
theory and a single persistently exciting input-output data trajectory.
Compared to current state-of-the-art approaches that rely on availability of
exact disturbance data, we deterministically approximate the chance constraints
in a sampling-based fashion by leveraging a novel parameterization of the
unknown disturbance data trajectory, considering consistency with the measured
data and the system class. A robust constraint on the first predicted step
guarantees recursive feasibility of the proposed controller as well as
constraint satisfaction in closed-loop. We show robust asymptotic stability in
expectation under further standard assumptions. A numerical example
demonstrates the efficiency of the proposed control scheme.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00683" title="Abstract">arXiv:2402.00683</a> [<a href="/pdf/2402.00683" title="Download PDF">pdf</a>, <a href="/format/2402.00683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WayFASTER: a Self-Supervised Traversability Prediction for Increased  Navigation Awareness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gasparino%2C+M+V">Mateus Valverde Gasparino</a>, 
<a href="/search/cs?searchtype=author&query=Sivakumar%2C+A+N">Arun Narenthiran Sivakumar</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhary%2C+G">Girish Chowdhary</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for the 2024 IEEE International Conference on Robotics and Automation (ICRA 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Accurate and robust navigation in unstructured environments requires fusing
data from multiple sensors. Such fusion ensures that the robot is better aware
of its surroundings, including areas of the environment that are not
immediately visible, but were visible at a different time. To solve this
problem, we propose a method for traversability prediction in challenging
outdoor environments using a sequence of RGB and depth images fused with pose
estimations. Our method, termed WayFASTER (Waypoints-Free Autonomous System for
Traversability with Enhanced Robustness), uses experience data recorded from a
receding horizon estimator to train a self-supervised neural network for
traversability prediction, eliminating the need for heuristics. Our experiments
demonstrate that our method excels at avoiding geometric obstacles, and
correctly detects that traversable terrains, such as tall grass, can be
navigable. By using a sequence of images, WayFASTER significantly enhances the
robot's awareness of its surroundings, enabling it to predict the
traversability of terrains that are not immediately visible. This enhanced
awareness contributes to better navigation performance in environments where
such predictive capabilities are essential.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00684" title="Abstract">arXiv:2402.00684</a> [<a href="/pdf/2402.00684" title="Download PDF">pdf</a>, <a href="/format/2402.00684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Investigation of Hardware Security Bug Characteristics in Open-Source  Projects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ah-kiow%2C+J">Joey Ah-kiow</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+B">Benjamin Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Hardware security is an important concern of system security as
vulnerabilities can arise from design errors introduced throughout the
development lifecycle. Recent works have proposed techniques to detect hardware
security bugs, such as static analysis, fuzzing, and symbolic execution.
However, the fundamental properties of hardware security bugs remain relatively
unexplored. To gain a better understanding of hardware security bugs, we
perform a deep dive into the popular OpenTitan project, including its bug
reports and bug fixes. We manually classify the bugs as relevant to
functionality or security and analyze characteristics, such as the impact and
location of security bugs, and the size of their bug fixes. We also investigate
relationships between security impact and bug management during development.
Finally, we propose an abstract syntax tree-based analysis to identify the
syntactic characteristics of bug fixes. Our results show that 53% of the bugs
in OpenTitan have potential security implications and that 55% of all bug fixes
modify only one file. Our findings underscore the importance of security-aware
development practices and tools and motivate the development of techniques that
leverage the highly localized nature of hardware bugs.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00685" title="Abstract">arXiv:2402.00685</a> [<a href="/pdf/2402.00685" title="Download PDF">pdf</a>, <a href="/ps/2402.00685" title="Download PostScript">ps</a>, <a href="/format/2402.00685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near and full quasi-optimality of finite element approximations of  stationary second-order mean field games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Osborne%2C+Y+A+P">Yohance A. P. Osborne</a>, 
<a href="/search/math?searchtype=author&query=Smears%2C+I">Iain Smears</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We establish a priori error bounds for monotone stabilized finite element
discretizations of stationary second-order mean field games (MFG) on Lipschitz
polytopal domains. Under suitable hypotheses, we prove that the approximation
is asymptotically nearly quasi-optimal in the $H^1$-norm in the sense that, on
sufficiently fine meshes, the error between exact and computed solutions is
bounded by the best approximation error of the corresponding finite element
space, plus possibly an additional term, due to the stabilization, that is of
optimal order with respect to the mesh size. We thereby deduce optimal rates of
convergence of the error with respect to the mesh-size for solutions with
sufficient regularity. We further show full asymptotic quasi-optimality of the
approximation error in the more restricted case of sequences of strictly acute
meshes. Our third main contribution is to further show, in the case where the
domain is convex, that the convergence rate for the $H^1$-norm error of the
value function approximation remains optimal even if the density function only
has minimal regularity in $H^1$.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00687" title="Abstract">arXiv:2402.00687</a> [<a href="/pdf/2402.00687" title="Download PDF">pdf</a>, <a href="/ps/2402.00687" title="Download PostScript">ps</a>, <a href="/format/2402.00687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review on the Use of Blockchain for the Internet of Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fernandez-Carames%2C+T+M">Tiago M. Fernandez-Carames</a>, 
<a href="/search/cs?searchtype=author&query=Fraga-Lamas%2C+P">Paula Fraga-Lamas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted version of IEEE Access journal paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> T. M. Fernandez-Carames and P. Fraga-Lamas, "A Review on the Use
  of Blockchain for the Internet of Things," in IEEE Access, vol. 6, pp.
  32979-33001, 2018
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The paradigm of Internet of Things (IoT) is paving the way for a world, where
many of our daily objects will be interconnected and will interact with their
environment in order to collect information and automate certain tasks. Such a
vision requires, among other things, seamless authentication, data privacy,
security, robustness against attacks, easy deployment, and self-maintenance.
Such features can be brought by blockchain, a technology born with a
cryptocurrency called Bitcoin. In this paper, a thorough review on how to adapt
blockchain to the specific needs of IoT in order to develop Blockchain-based
IoT (BIoT) applications is presented. After describing the basics of
blockchain, the most relevant BIoT applications are described with the
objective of emphasizing how blockchain can impact traditional cloud-centered
IoT applications. Then, the current challenges and possible optimizations are
detailed regarding many aspects that affect the design, development, and
deployment of a BIoT application. Finally, some recommendations are enumerated
with the aim of guiding future BIoT researchers and developers on some of the
issues that will have to be tackled before deploying the next generation of
BIoT applications.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00689" title="Abstract">arXiv:2402.00689</a> [<a href="/pdf/2402.00689" title="Download PDF">pdf</a>, <a href="/format/2402.00689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ocassionally Secure: A Comparative Analysis of Code Generation  Assistants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elgedawy%2C+R">Ran Elgedawy</a>, 
<a href="/search/cs?searchtype=author&query=Sadik%2C+J">John Sadik</a>, 
<a href="/search/cs?searchtype=author&query=Dutta%2C+S">Senjuti Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Gautam%2C+A">Anuj Gautam</a>, 
<a href="/search/cs?searchtype=author&query=Georgiou%2C+K">Konstantinos Georgiou</a>, 
<a href="/search/cs?searchtype=author&query=Gholamrezae%2C+F">Farzin Gholamrezae</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+F">Fujiao Ji</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+K">Kyungchan Lim</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ruoti%2C+S">Scott Ruoti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">$ $Large Language Models (LLMs) are being increasingly utilized in various
applications, with code generations being a notable example. While previous
research has shown that LLMs have the capability to generate both secure and
insecure code, the literature does not take into account what factors help
generate secure and effective code. Therefore in this paper we focus on
identifying and understanding the conditions and contexts in which LLMs can be
effectively and safely deployed in real-world scenarios to generate quality
code. We conducted a comparative analysis of four advanced LLMs--GPT-3.5 and
GPT-4 using ChatGPT and Bard and Gemini from Google--using 9 separate tasks to
assess each model's code generation capabilities. We contextualized our study
to represent the typical use cases of a real-life developer employing LLMs for
everyday tasks as work. Additionally, we place an emphasis on security
awareness which is represented through the use of two distinct versions of our
developer persona. In total, we collected 61 code outputs and analyzed them
across several aspects: functionality, security, performance, complexity, and
reliability. These insights are crucial for understanding the models'
capabilities and limitations, guiding future development and practical
applications in the field of automated code generation.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00691" title="Abstract">arXiv:2402.00691</a> [<a href="/pdf/2402.00691" title="Download PDF">pdf</a>, <a href="/format/2402.00691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Study of Large Language Model Architectures on Frontier
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Junqi Yin</a>, 
<a href="/search/cs?searchtype=author&query=Bose%2C+A">Avishek Bose</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+G">Guojing Cong</a>, 
<a href="/search/cs?searchtype=author&query=Lyngaas%2C+I">Isaac Lyngaas</a>, 
<a href="/search/cs?searchtype=author&query=Anthony%2C+Q">Quentin Anthony</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Large language models (LLMs) have garnered significant attention in both the
AI community and beyond. Among these, the Generative Pre-trained Transformer
(GPT) has emerged as the dominant architecture, spawning numerous variants.
However, these variants have undergone pre-training under diverse conditions,
including variations in input data, data preprocessing, and training
methodologies, resulting in a lack of controlled comparative studies. Here we
meticulously examine two prominent open-sourced GPT architectures, GPT-NeoX and
LLaMA, leveraging the computational power of Frontier, the world's first
Exascale supercomputer. Employing the same materials science text corpus and a
comprehensive end-to-end pipeline, we conduct a comparative analysis of their
training and downstream performance. Our efforts culminate in achieving
state-of-the-art performance on a challenging materials science benchmark.
Furthermore, we investigate the computation and energy efficiency, and propose
a computationally efficient method for architecture design. To our knowledge,
these pre-trained models represent the largest available for materials science.
Our findings provide practical guidance for building LLMs on HPC platforms.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00692" title="Abstract">arXiv:2402.00692</a> [<a href="/pdf/2402.00692" title="Download PDF">pdf</a>, <a href="/format/2402.00692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Framework for Building Point Cloud Cleaning, Plane Detection and  Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abouelaziz%2C+I">Ilyass Abouelaziz</a>, 
<a href="/search/cs?searchtype=author&query=Mourchid%2C+Y">Youssef Mourchid</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents a framework to address the challenges involved in
building point cloud cleaning, plane detection, and semantic segmentation, with
the ultimate goal of enhancing building modeling. We focus in the cleaning
stage on removing outliers from the acquired point cloud data by employing an
adaptive threshold technique based on z-score measure. Following the cleaning
process, we perform plane detection using the robust RANSAC paradigm. The goal
is to carry out multiple plane segmentations, and to classify segments into
distinct categories, such as floors, ceilings, and walls. The resulting
segments can generate accurate and detailed point clouds representing the
building's architectural elements. Moreover, we address the problem of semantic
segmentation, which plays a vital role in the identification and classification
of different components within the building, such as walls, windows, doors,
roofs, and objects. Inspired by the PointNet architecture, we propose a deep
learning architecture for efficient semantic segmentation in buildings. The
results demonstrate the effectiveness of the proposed framework in handling
building modeling tasks, paving the way for improved accuracy and efficiency in
the field of building modelization.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00695" title="Abstract">arXiv:2402.00695</a> [<a href="/pdf/2402.00695" title="Download PDF">pdf</a>, <a href="/format/2402.00695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximating Optimal Morphing Attacks using Template Inversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Colbois%2C+L">Laurent Colbois</a>, 
<a href="/search/cs?searchtype=author&query=Shahreza%2C+H+O">Hatef Otroshi Shahreza</a>, 
<a href="/search/cs?searchtype=author&query=Marcel%2C+S">S&#xe9;bastien Marcel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at the IEEE International Joint Conference on Biometrics (IJCB) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent works have demonstrated the feasibility of inverting face recognition
systems, enabling to recover convincing face images using only their
embeddings. We leverage such template inversion models to develop a novel type
ofdeep morphing attack based on inverting a theoretical optimal morph
embedding, which is obtained as an average of the face embeddings of source
images. We experiment with two variants of this approach: the first one
exploits a fully self-contained embedding-to-image inversion model, while the
second leverages the synthesis network of a pretrained StyleGAN network for
increased morph realism. We generate morphing attacks from several source
datasets and study the effectiveness of those attacks against several face
recognition networks. We showcase that our method can compete with and
regularly beat the previous state of the art for deep-learning based morph
generation in terms of effectiveness, both in white-box and black-box attack
scenarios, and is additionally much faster to run. We hope this might
facilitate the development of large scale deep morph datasets for training
detection models.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00697" title="Abstract">arXiv:2402.00697</a> [<a href="/pdf/2402.00697" title="Download PDF">pdf</a>, <a href="/format/2402.00697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combining Belief Function Theory and Stochastic Model Predictive Control  for Multi-Modal Uncertainty in Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Benciolini%2C+T">Tommaso Benciolini</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+Y">Yuntian Yan</a>, 
<a href="/search/eess?searchtype=author&query=Wollherr%2C+D">Dirk Wollherr</a>, 
<a href="/search/eess?searchtype=author&query=Leibold%2C+M">Marion Leibold</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In automated driving, predicting and accommodating the uncertain future
motion of other traffic participants is challenging, especially in unstructured
environments in which the high-level intention of traffic participants is
difficult to predict. Several possible uncertain future behaviors of traffic
participants must be considered, resulting in multi-modal uncertainty. We
propose a novel combination of Belief Function Theory and Stochastic Model
Predictive Control for trajectory planning of the autonomous vehicle in
presence of significant uncertainty about the intention estimation of traffic
participants. A misjudgment of the intention of traffic participants may result
in dangerous situations. At the same time, excessive conservatism must be
avoided. Therefore, the measure of reliability of the estimation provided by
Belief Function Theory is used in the design of collision-avoidance safety
constraints, in particular to increase safety when the intention of traffic
participants is not clear. We discuss two methods to leverage on Belief
Function Theory: we introduce a novel belief-to-probability transformation
designed not to underestimate unlikely events if the information is uncertain,
and a constraint tightening mechanism using the reliability of the estimation.
We evaluate our proposal through simulations comparing to state-of-the-art
approaches.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00698" title="Abstract">arXiv:2402.00698</a> [<a href="/pdf/2402.00698" title="Download PDF">pdf</a>, <a href="/ps/2402.00698" title="Download PostScript">ps</a>, <a href="/format/2402.00698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Series Analysis Approach for Improving Energy Efficiency of a  Fixed-Route Vessel in Short-Sea Shipping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abuella%2C+M">Mohamed Abuella</a>, 
<a href="/search/cs?searchtype=author&query=Fanaee%2C+H">Hadi Fanaee</a>, 
<a href="/search/cs?searchtype=author&query=Nowaczyk%2C+S">Slawomir Nowaczyk</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+S">Simon Johansson</a>, 
<a href="/search/cs?searchtype=author&query=Faghani%2C+E">Ethan Faghani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures and four tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Several approaches have been developed for improving the ship energy
efficiency, thereby reducing operating costs and ensuring compliance with
climate change mitigation regulations. Many of these approaches will heavily
depend on measured data from onboard IoT devices, including operational and
environmental information, as well as external data sources for additional
navigational data. In this paper, we develop a framework that implements
time-series analysis techniques to optimize the vessel's speed profile for
improving the vessel's energy efficiency. We present a case study involving a
real-world data from a passenger vessel that was collected over a span of 15
months in the south of Sweden. The results indicate that the implemented models
exhibit a range of outcomes and adaptability across different scenarios. The
findings highlight the effectiveness of time-series analysis approach for
optimizing vessel voyages within the context of constrained landscapes, as
often seen in short-sea shipping.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00699" title="Abstract">arXiv:2402.00699</a> [<a href="/pdf/2402.00699" title="Download PDF">pdf</a>, <a href="/format/2402.00699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PeaTMOSS: A Dataset and Initial Analysis of Pre-Trained Models in  Open-Source Software
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wenxin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yasmin%2C+J">Jerin Yasmin</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+J">Jason Jones</a>, 
<a href="/search/cs?searchtype=author&query=Synovic%2C+N">Nicholas Synovic</a>, 
<a href="/search/cs?searchtype=author&query=Kuo%2C+J">Jiashen Kuo</a>, 
<a href="/search/cs?searchtype=author&query=Bielanski%2C+N">Nathaniel Bielanski</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Thiruvathukal%2C+G+K">George K. Thiruvathukal</a>, 
<a href="/search/cs?searchtype=author&query=Davis%2C+J+C">James C. Davis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at MSR'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB); Machine Learning (cs.LG)

</div>
<p class="mathjax">The development and training of deep learning models have become increasingly
costly and complex. Consequently, software engineers are adopting pre-trained
models (PTMs) for their downstream applications. The dynamics of the PTM supply
chain remain largely unexplored, signaling a clear need for structured datasets
that document not only the metadata but also the subsequent applications of
these models. Without such data, the MSR community cannot comprehensively
understand the impact of PTM adoption and reuse. This paper presents the
PeaTMOSS dataset, which comprises metadata for 281,638 PTMs and detailed
snapshots for all PTMs with over 50 monthly downloads (14,296 PTMs), along with
28,575 open-source software repositories from GitHub that utilize these models.
Additionally, the dataset includes 44,337 mappings from 15,129 downstream
GitHub repositories to the 2,530 PTMs they use. To enhance the dataset's
comprehensiveness, we developed prompts for a large language model to
automatically extract model metadata, including the model's training datasets,
parameters, and evaluation metrics. Our analysis of this dataset provides the
first summary statistics for the PTM supply chain, showing the trend of PTM
development and common shortcomings of PTM package documentation. Our example
application reveals inconsistencies in software licenses across PTMs and their
dependent projects. PeaTMOSS lays the foundation for future research, offering
rich opportunities to investigate the PTM supply chain. We outline mining
opportunities on PTMs, their downstream usage, and cross-cutting questions.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00700" title="Abstract">arXiv:2402.00700</a> [<a href="/pdf/2402.00700" title="Download PDF">pdf</a>, <a href="/format/2402.00700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Bed Pose Estimation: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yaz%C4%B1c%C4%B1%2C+Z+A">Ziya Ata Yaz&#x131;c&#x131;</a>, 
<a href="/search/cs?searchtype=author&query=Colantonio%2C+S">Sara Colantonio</a>, 
<a href="/search/cs?searchtype=author&query=Ekenel%2C+H+K">Haz&#x131;m Kemal Ekenel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at HCCS24 Workshop @ International Conference on Pervasive Computing and Communications (PerCom 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human pose estimation, the process of identifying joint positions in a
person's body from images or videos, represents a widely utilized technology
across diverse fields, including healthcare. One such healthcare application
involves in-bed pose estimation, where the body pose of an individual lying
under a blanket is analyzed. This task, for instance, can be used to monitor a
person's sleep behavior and detect symptoms early for potential disease
diagnosis in homes and hospitals. Several studies have utilized unimodal and
multimodal methods to estimate in-bed human poses. The unimodal studies
generally employ RGB images, whereas the multimodal studies use modalities
including RGB, long-wavelength infrared, pressure map, and depth map.
Multimodal studies have the advantage of using modalities in addition to RGB
that might capture information useful to cope with occlusions. Moreover, some
multimodal studies exclude RGB and, this way, better suit privacy preservation.
To expedite advancements in this domain, we conduct a review of existing
datasets and approaches. Our objectives are to show the limitations of the
previous studies, current challenges, and provide insights for future works on
the in-bed human pose estimation field.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00703" title="Abstract">arXiv:2402.00703</a> [<a href="/pdf/2402.00703" title="Download PDF">pdf</a>, <a href="/format/2402.00703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vehicle Perception from Satellite
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+P">Pengfei Han</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuelong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Satellites are capable of capturing high-resolution videos. It makes vehicle
perception from satellite become possible. Compared to street surveillance,
drive recorder or other equipments, satellite videos provide a much broader
city-scale view, so that the global dynamic scene of the traffic are captured
and displayed. Traffic monitoring from satellite is a new task with great
potential applications, including traffic jams prediction, path planning,
vehicle dispatching, \emph{etc.}. Practically, limited by the resolution and
view, the captured vehicles are very tiny (a few pixels) and move slowly. Worse
still, these satellites are in Low Earth Orbit (LEO) to capture such
high-resolution videos, so the background is also moving. Under this
circumstance, traffic monitoring from the satellite view is an extremely
challenging task. To attract more researchers into this field, we build a
large-scale benchmark for traffic monitoring from satellite. It supports
several tasks, including tiny object detection, counting and density
estimation. The dataset is constructed based on 12 satellite videos and 14
synthetic videos recorded from GTA-V. They are separated into 408 video clips,
which contain 7,336 real satellite images and 1,960 synthetic images. 128,801
vehicles are annotated totally, and the number of vehicles in each image varies
from 0 to 101. Several classic and state-of-the-art approaches in traditional
computer vision are evaluated on the datasets, so as to compare the performance
of different approaches, analyze the challenges in this task, and discuss the
future prospects. The dataset is available at:
https://github.com/Chenxi1510/Vehicle-Perception-from-Satellite-Videos.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00705" title="Abstract">arXiv:2402.00705</a> [<a href="/pdf/2402.00705" title="Download PDF">pdf</a>, <a href="/ps/2402.00705" title="Download PostScript">ps</a>, <a href="/format/2402.00705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combining the Strengths of Dutch Survey and Register Data in a Data  Challenge to Predict Fertility (PreFer)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sivak%2C+E">Elizaveta Sivak</a>, 
<a href="/search/cs?searchtype=author&query=Pankowska%2C+P">Paulina Pankowska</a>, 
<a href="/search/cs?searchtype=author&query=Mendrik%2C+A">Adrienne Mendrik</a>, 
<a href="/search/cs?searchtype=author&query=Emery%2C+T">Tom Emery</a>, 
<a href="/search/cs?searchtype=author&query=Garcia-Bernardo%2C+J">Javier Garcia-Bernardo</a>, 
<a href="/search/cs?searchtype=author&query=Hocuk%2C+S">Seyit Hocuk</a>, 
<a href="/search/cs?searchtype=author&query=Karpinska%2C+K">Kasia Karpinska</a>, 
<a href="/search/cs?searchtype=author&query=Maineri%2C+A">Angelica Maineri</a>, 
<a href="/search/cs?searchtype=author&query=Mulder%2C+J">Joris Mulder</a>, 
<a href="/search/cs?searchtype=author&query=Nissim%2C+M">Malvina Nissim</a>, 
<a href="/search/cs?searchtype=author&query=Stulp%2C+G">Gert Stulp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB)

</div>
<p class="mathjax">The social sciences have produced an impressive body of research on
determinants of fertility outcomes, or whether and when people have children.
However, the strength of these determinants and underlying theories are rarely
evaluated on their predictive ability on new data. This prevents us from
systematically comparing studies, hindering the evaluation and accumulation of
knowledge. In this paper, we present two datasets which can be used to study
the predictability of fertility outcomes in the Netherlands. One dataset is
based on the LISS panel, a longitudinal survey which includes thousands of
variables on a wide range of topics, including individual preferences and
values. The other is based on the Dutch register data which lacks attitudinal
data but includes detailed information about the life courses of millions of
Dutch residents. We provide information about the datasets and the samples, and
describe the fertility outcome of interest. We also introduce the fertility
prediction data challenge PreFer which is based on these datasets and will
start in Spring 2024. We outline the ways in which measuring the predictability
of fertility outcomes using these datasets and combining their strengths in the
data challenge can advance our understanding of fertility behaviour and
computational social science. We further provide details for participants on
how to take part in the data challenge.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00707" title="Abstract">arXiv:2402.00707</a> [<a href="/pdf/2402.00707" title="Download PDF">pdf</a>, <a href="/format/2402.00707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Exchangeable Conformal Language Generation with Nearest Neighbors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ulmer%2C+D">Dennis Ulmer</a>, 
<a href="/search/cs?searchtype=author&query=Zerva%2C+C">Chrysoula Zerva</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+A+F+T">Andr&#xe9; F.T. Martins</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantifying uncertainty in automatically generated text is important for
letting humans check potential hallucinations and making systems more reliable.
Conformal prediction is an attractive framework to provide predictions imbued
with statistical guarantees, however, its application to text generation is
challenging since any i.i.d. assumptions are not realistic. In this paper, we
bridge this gap by leveraging recent results on non-exchangeable conformal
prediction, which still ensures bounds on coverage. The result,
non-exchangeable conformal nucleus sampling, is a novel extension of the
conformal prediction framework to generation based on nearest neighbors. Our
method can be used post-hoc for an arbitrary model without extra training and
supplies token-level, calibrated prediction sets equipped with statistical
guarantees. Experiments in machine translation and language modeling show
encouraging results in generation quality. By also producing tighter prediction
sets with good coverage, we thus give a more theoretically principled way to
perform sampling with conformal guarantees.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00708" title="Abstract">arXiv:2402.00708</a> [<a href="/pdf/2402.00708" title="Download PDF">pdf</a>, <a href="/format/2402.00708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking human-robot collaborative assembly tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duarte%2C+L">Laura Duarte</a>, 
<a href="/search/cs?searchtype=author&query=Neves%2C+M">Miguel Neves</a>, 
<a href="/search/cs?searchtype=author&query=Neto%2C+P">Pedro Neto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Manufacturing assembly tasks can vary in complexity and level of automation.
Yet, achieving full automation can be challenging and inefficient, particularly
due to the complexity of certain assembly operations. Human-robot collaborative
work, leveraging the strengths of human labor alongside the capabilities of
robots, can be a solution for enhancing efficiency. This paper introduces the
CT benchmark, a benchmark and model set designed to facilitate the testing and
evaluation of human-robot collaborative assembly scenarios. It was designed to
compare manual and automatic processes using metrics such as the assembly time
and human workload. The components of the model set can be assembled through
the most common assembly tasks, each with varying levels of difficulty. The CT
benchmark was designed with a focus on its applicability in human-robot
collaborative environments, with the aim of ensuring the reproducibility and
replicability of experiments. Experiments were carried out to assess assembly
performance in three different setups (manual, automatic and collaborative),
measuring metrics related to the assembly time and the workload on human
operators. The results suggest that the collaborative approach takes longer
than the fully manual assembly, with an increase of 70.8%. However, users
reported a lower overall workload, as well as reduced mental demand, physical
demand, and effort according to the NASA-TLX questionnaire.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00709" title="Abstract">arXiv:2402.00709</a> [<a href="/pdf/2402.00709" title="Download PDF">pdf</a>, <a href="/ps/2402.00709" title="Download PostScript">ps</a>, <a href="/format/2402.00709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards an autonomous industry 4.0 warehouse: A UAV and blockchain-based  system for inventory and traceability applications in big data-driven supply  chain management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fernandez-Carames%2C+T+M">Tiago M. Fernandez-Carames</a>, 
<a href="/search/cs?searchtype=author&query=Blanco-Novoa%2C+O">Oscar Blanco-Novoa</a>, 
<a href="/search/cs?searchtype=author&query=Froiz-Miguez%2C+I">Ivan Froiz-Miguez</a>, 
<a href="/search/cs?searchtype=author&query=Fraga-Lamas%2C+P">Paula Fraga-Lamas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted version of Sensors journal article
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sensors, 19, 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">In this paper we present the design and evaluation of a UAV-based system
aimed at automating inventory tasks and keeping the traceability of industrial
items attached to Radio-Frequency IDentification (RFID) tags. To confront
current shortcomings, such a system is developed under a versatile, modular and
scalable architecture aimed to reinforce cyber security and decentralization
while fostering external audits and big data analytics. Therefore, the system
uses a blockchain and a distributed ledger to store certain inventory data
collected by UAVs, validate them, ensure their trustworthiness and make them
available to the interested parties. In order to show the performance of the
proposed system, different tests were performed in a real industrial warehouse,
concluding that the system is able to obtain the inventory data really fast in
comparison to traditional manual tasks, while being also able to estimate the
position of the items when hovering over them thanks to their tag's signal
strength. In addition, the performance of the proposed blockchain-based
architecture was evaluated in different scenarios.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00711" title="Abstract">arXiv:2402.00711</a> [<a href="/pdf/2402.00711" title="Download PDF">pdf</a>, <a href="/format/2402.00711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explaining Text Classifiers with Counterfactual Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lemberger%2C+P">Pirmin Lemberger</a>, 
<a href="/search/cs?searchtype=author&query=Saillenfest%2C+A">Antoine Saillenfest</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">One well motivated explanation method for classifiers leverages
counterfactuals which are hypothetical events identical to real observations in
all aspects except for one categorical feature. Constructing such
counterfactual poses specific challenges for texts, however, as some attribute
values may not necessarily align with plausible real-world events. In this
paper we propose a simple method for generating counterfactuals by intervening
in the space of text representations which bypasses this limitation. We argue
that our interventions are minimally disruptive and that they are theoretically
sound as they align with counterfactuals as defined in Pearl's causal inference
framework. To validate our method, we first conduct experiments on a synthetic
dataset of counterfactuals, allowing for a direct comparison between classifier
predictions based on ground truth counterfactuals (obtained through explicit
text interventions) and our counterfactuals, derived through interventions in
the representation space. Second, we study a real world scenario where our
counterfactuals can be leveraged both for explaining a classifier and for bias
mitigation.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00712" title="Abstract">arXiv:2402.00712</a> [<a href="/pdf/2402.00712" title="Download PDF">pdf</a>, <a href="/format/2402.00712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChaosBench: A Multi-Channel, Physics-Based Benchmark for  Subseasonal-to-Seasonal Climate Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nathaniel%2C+J">Juan Nathaniel</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yongquan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Tung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Sungduk Yu</a>, 
<a href="/search/cs?searchtype=author&query=Busecke%2C+J">Julius Busecke</a>, 
<a href="/search/cs?searchtype=author&query=Grover%2C+A">Aditya Grover</a>, 
<a href="/search/cs?searchtype=author&query=Gentine%2C+P">Pierre Gentine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages, 39 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Accurate prediction of climate in the subseasonal-to-seasonal scale is
crucial for disaster readiness, reduced economic risk, and improved
policy-making amidst climate change. Yet, S2S prediction remains challenging
due to the chaotic nature of the system. At present, existing benchmarks for
weather and climate applications, tend to (1) have shorter forecasting range of
up-to 14 days, (2) do not include a wide range of operational baseline
forecasts, and (3) lack physics-based constraints for explainability. Thus, we
propose ChaosBench, a large-scale, multi-channel, physics-based benchmark for
S2S prediction. ChaosBench has over 460K frames of real-world observations and
simulations, each with 60 variable-channels and spanning for up-to 45 years. We
also propose several physics-based, in addition to vision-based metrics, that
enables for a more physically-consistent model. Furthermore, we include a
diverse set of physics-based forecasts from 4 national weather agencies as
baselines to our data-driven counterpart. We establish two tasks that vary in
complexity: full and sparse dynamics prediction. Our benchmark is one of the
first to perform large-scale evaluation on existing models including
PanguWeather, FourCastNetV2, GraphCast, and ClimaX, and finds methods
originally developed for weather-scale applications fails on S2S task. We
release our benchmark code and datasets at
https://leap-stc.github.io/ChaosBench.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00715" title="Abstract">arXiv:2402.00715</a> [<a href="/pdf/2402.00715" title="Download PDF">pdf</a>, <a href="/format/2402.00715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intent Assurance using LLMs guided by Intent Drift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dzeparoska%2C+K">Kristina Dzeparoska</a>, 
<a href="/search/cs?searchtype=author&query=Tizghadam%2C+A">Ali Tizghadam</a>, 
<a href="/search/cs?searchtype=author&query=Leon-Garcia%2C+A">Alberto Leon-Garcia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Networking and Internet Architecture (cs.NI); Methodology (stat.ME)

</div>
<p class="mathjax">Intent-Based Networking (IBN) presents a paradigm shift for network
management, by promising to align intents and business objectives with network
operations--in an automated manner. However, its practical realization is
challenging: 1) processing intents, i.e., translate, decompose and identify the
logic to fulfill the intent, and 2) intent conformance, that is, considering
dynamic networks, the logic should be adequately adapted to assure intents. To
address the latter, intent assurance is tasked with continuous verification and
validation, including taking the necessary actions to align the operational and
target states. In this paper, we define an assurance framework that allows us
to detect and act when intent drift occurs. To do so, we leverage AI-driven
policies, generated by Large Language Models (LLMs) which can quickly learn the
necessary in-context requirements, and assist with the fulfillment and
assurance of intents.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00719" title="Abstract">arXiv:2402.00719</a> [<a href="/pdf/2402.00719" title="Download PDF">pdf</a>, <a href="/format/2402.00719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orientation-aware Incremental Potential Contact
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zizhou Huang</a>, 
<a href="/search/cs?searchtype=author&query=Paik%2C+M">Max Paik</a>, 
<a href="/search/cs?searchtype=author&query=Ferguson%2C+Z">Zachary Ferguson</a>, 
<a href="/search/cs?searchtype=author&query=Panozzo%2C+D">Daniele Panozzo</a>, 
<a href="/search/cs?searchtype=author&query=Zorin%2C+D">Denis Zorin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">The Incremental Potential Contact (IPC) method enables robust complex
simulations of deformable objects with contact and friction. The key to IPC's
robustness is its strict adherence to geometric constraints, avoiding
intersections, which are a common cause of robustness issues in contact
mechanics. A key element of the IPC approach to contact is a geometric barrier
function, which is defined directly in the discrete setting. While IPC achieves
its main goal of providing guarantees for contact constraints, its parameters
need to be chosen carefully to avoid significant simulation artifacts and
inaccuracies. We present a systematic derivation of an IPC-like continuum
potential defined for smooth and piecewise smooth surfaces, starting from
identifying a set of natural requirements for contact potentials, including the
barrier property, locality, differentiable dependence of shape, and absence of
forces in rest configurations, based on the idea of candidate sets. Our
potential is formulated in a way independent of surface discretization.
<br />This new potential is suitable for piecewise-linear surfaces and its
efficiency is similar to standard IPC. We demonstrate its behavior and compare
it to IPC on a range of challenging contact examples.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00722" title="Abstract">arXiv:2402.00722</a> [<a href="/pdf/2402.00722" title="Download PDF">pdf</a>, <a href="/format/2402.00722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Style Transfer with Twin-Delayed DDPG for Shared Control of  Robotic Manipulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fernandez-Fernandez%2C+R">Raul Fernandez-Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=Aggravi%2C+M">Marco Aggravi</a>, 
<a href="/search/cs?searchtype=author&query=Giordano%2C+P+R">Paolo Robuffo Giordano</a>, 
<a href="/search/cs?searchtype=author&query=Victores%2C+J+G">Juan G. Victores</a>, 
<a href="/search/cs?searchtype=author&query=Pacchierotti%2C+C">Claudio Pacchierotti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Neural Style Transfer (NST) refers to a class of algorithms able to
manipulate an element, most often images, to adopt the appearance or style of
another one. Each element is defined as a combination of Content and Style: the
Content can be conceptually defined as the what and the Style as the how of
said element. In this context, we propose a custom NST framework for
transferring a set of styles to the motion of a robotic manipulator, e.g., the
same robotic task can be carried out in an angry, happy, calm, or sad way. An
autoencoder architecture extracts and defines the Content and the Style of the
target robot motions. A Twin Delayed Deep Deterministic Policy Gradient (TD3)
network generates the robot control policy using the loss defined by the
autoencoder. The proposed Neural Policy Style Transfer TD3 (NPST3) alters the
robot motion by introducing the trained style. Such an approach can be
implemented either offline, for carrying out autonomous robot motions in
dynamic environments, or online, for adapting at runtime the style of a
teleoperated robot. The considered styles can be learned online from human
demonstrations. We carried out an evaluation with human subjects enrolling 73
volunteers, asking them to recognize the style behind some representative
robotic motions. Results show a good recognition rate, proving that it is
possible to convey different styles to a robot using this approach.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00723" title="Abstract">arXiv:2402.00723</a> [<a href="/pdf/2402.00723" title="Download PDF">pdf</a>, <a href="/format/2402.00723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Semantic Control in Discrete Latent Spaces with Transformer  Quantized Variational Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Carvalho%2C+D+S">Danilo S. Carvalho</a>, 
<a href="/search/cs?searchtype=author&query=Valentino%2C+M">Marco Valentino</a>, 
<a href="/search/cs?searchtype=author&query=Pratt-Hartmann%2C+I">Ian Pratt-Hartmann</a>, 
<a href="/search/cs?searchtype=author&query=Freitas%2C+A">Andre Freitas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Achieving precise semantic control over the latent spaces of Variational
AutoEncoders (VAEs) holds significant value for downstream tasks in NLP as the
underlying generative mechanisms could be better localised, explained and
improved upon. Recent research, however, has struggled to achieve consistent
results, primarily due to the inevitable loss of semantic information in the
variational bottleneck and limited control over the decoding mechanism. To
overcome these challenges, we investigate discrete latent spaces in Vector
Quantized Variational AutoEncoders (VQVAEs) to improve semantic control and
generation in Transformer-based VAEs. In particular, We propose T5VQVAE, a
novel model that leverages the controllability of VQVAEs to guide the
self-attention mechanism in T5 at the token-level, exploiting its full
generalization capabilities. Experimental results indicate that T5VQVAE
outperforms existing state-of-the-art VAE models, including Optimus, in terms
of controllability and preservation of semantic information across different
tasks such as auto-encoding of sentences and mathematical expressions, text
transfer, and inference. Moreover, T5VQVAE exhibits improved inference
capabilities, suggesting potential applications for downstream natural language
and symbolic reasoning tasks.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00724" title="Abstract">arXiv:2402.00724</a> [<a href="/pdf/2402.00724" title="Download PDF">pdf</a>, <a href="/ps/2402.00724" title="Download PostScript">ps</a>, <a href="/format/2402.00724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Segmentation of the Spinal Cord Nerve Rootlets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valosek%2C+J">Jan Valosek</a>, 
<a href="/search/cs?searchtype=author&query=Mathieu%2C+T">Theo Mathieu</a>, 
<a href="/search/cs?searchtype=author&query=Schlienger%2C+R">Raphaelle Schlienger</a>, 
<a href="/search/cs?searchtype=author&query=Kowalczyk%2C+O+S">Olivia S. Kowalczyk</a>, 
<a href="/search/cs?searchtype=author&query=Cohen-Adad%2C+J">Julien Cohen-Adad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Precise identification of spinal nerve rootlets is relevant to delineate
spinal levels for the study of functional activity in the spinal cord. The goal
of this study was to develop an automatic method for the semantic segmentation
of spinal nerve rootlets from T2-weighted magnetic resonance imaging (MRI)
scans. Images from two open-access MRI datasets were used to train a 3D
multi-class convolutional neural network using an active learning approach to
segment C2-C8 dorsal nerve rootlets. Each output class corresponds to a spinal
level. The method was tested on 3T T2-weighted images from datasets unseen
during training to assess inter-site, inter-session, and inter-resolution
variability. The test Dice score was 0.67 +- 0.16 (mean +- standard deviation
across rootlets levels), suggesting a good performance. The method also
demonstrated low inter-vendor and inter-site variability (coefficient of
variation &lt;= 1.41 %), as well as low inter-session variability (coefficient of
variation &lt;= 1.30 %) indicating stable predictions across different MRI
vendors, sites, and sessions. The proposed methodology is open-source and
readily available in the Spinal Cord Toolbox (SCT) v6.2 and higher.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00728" title="Abstract">arXiv:2402.00728</a> [<a href="/pdf/2402.00728" title="Download PDF">pdf</a>, <a href="/format/2402.00728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dropout-Based Rashomon Set Exploration for Efficient Predictive  Multiplicity Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hsu%2C+H">Hsiang Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guihong Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shaohan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chun-Fu">Chun-Fu</a> (Richard)
<a href="/search/cs?searchtype=author&query=Chen">Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Predictive multiplicity refers to the phenomenon in which classification
tasks may admit multiple competing models that achieve almost-equally-optimal
performance, yet generate conflicting outputs for individual samples. This
presents significant concerns, as it can potentially result in systemic
exclusion, inexplicable discrimination, and unfairness in practical
applications. Measuring and mitigating predictive multiplicity, however, is
computationally challenging due to the need to explore all such
almost-equally-optimal models, known as the Rashomon set, in potentially huge
hypothesis spaces. To address this challenge, we propose a novel framework that
utilizes dropout techniques for exploring models in the Rashomon set. We
provide rigorous theoretical derivations to connect the dropout parameters to
properties of the Rashomon set, and empirically evaluate our framework through
extensive experimentation. Numerical results show that our technique
consistently outperforms baselines in terms of the effectiveness of predictive
multiplicity metric estimation, with runtime speedup up to $20\times \sim
5000\times$. With efficient Rashomon set exploration and metric estimation,
mitigation of predictive multiplicity is then achieved through dropout ensemble
and model selection.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00729" title="Abstract">arXiv:2402.00729</a> [<a href="/pdf/2402.00729" title="Download PDF">pdf</a>, <a href="/format/2402.00729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Profiling and Modeling of Power Characteristics of Leadership-Scale HPC  System Workloads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karimi%2C+A+M">Ahmad Maroof Karimi</a>, 
<a href="/search/cs?searchtype=author&query=Sattar%2C+N+S">Naw Safrin Sattar</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+W">Woong Shin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feiyi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">In the exascale era in which application behavior has large power &amp; energy
footprints, per-application job-level awareness of such impression is crucial
in taking steps towards achieving efficiency goals beyond performance, such as
energy efficiency, and sustainability.
<br />To achieve these goals, we have developed a novel low-latency job power
profiling machine learning pipeline that can group job-level power profiles
based on their shapes as they complete. This pipeline leverages a comprehensive
feature extraction and clustering pipeline powered by a generative adversarial
network (GAN) model to handle the feature-rich time series of job-level power
measurements. The output is then used to train a classification model that can
predict whether an incoming job power profile is similar to a known group of
profiles or is completely new. With extensive evaluations, we demonstrate the
effectiveness of each component in our pipeline. Also, we provide a preliminary
analysis of the resulting clusters that depict the power profile landscape of
the Summit supercomputer from more than 60K jobs sampled from the year 2021.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00732" title="Abstract">arXiv:2402.00732</a> [<a href="/pdf/2402.00732" title="Download PDF">pdf</a>, <a href="/format/2402.00732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MobilityDL: A Review of Deep Learning From Trajectory Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Graser%2C+A">Anita Graser</a>, 
<a href="/search/cs?searchtype=author&query=Jalali%2C+A">Anahid Jalali</a>, 
<a href="/search/cs?searchtype=author&query=Lampert%2C+J">Jasmin Lampert</a>, 
<a href="/search/cs?searchtype=author&query=Wei%C3%9Fenfeld%2C+A">Axel Wei&#xdf;enfeld</a>, 
<a href="/search/cs?searchtype=author&query=Janowicz%2C+K">Krzysztof Janowicz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Geoinformatica
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Trajectory data combines the complexities of time series, spatial data, and
(sometimes irrational) movement behavior. As data availability and computing
power have increased, so has the popularity of deep learning from trajectory
data. This review paper provides the first comprehensive overview of deep
learning approaches for trajectory data. We have identified eight specific
mobility use cases which we analyze with regards to the deep learning models
and the training data used. Besides a comprehensive quantitative review of the
literature since 2018, the main contribution of our work is the data-centric
analysis of recent work in this field, placing it along the mobility data
continuum which ranges from detailed dense trajectories of individual movers
(quasi-continuous tracking data), to sparse trajectories (such as check-in
data), and aggregated trajectories (crowd information).
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00734" title="Abstract">arXiv:2402.00734</a> [<a href="/pdf/2402.00734" title="Download PDF">pdf</a>, <a href="/ps/2402.00734" title="Download PostScript">ps</a>, <a href="/format/2402.00734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BIOMERO: BioImage analysis in OMERO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luik%2C+T+T">Torec T. Luik</a>, 
<a href="/search/cs?searchtype=author&query=Rosas-Bertolini%2C+R">Rodrigo Rosas-Bertolini</a>, 
<a href="/search/cs?searchtype=author&query=Reits%2C+E+A+J">Eric A.J. Reits</a>, 
<a href="/search/cs?searchtype=author&query=Hoebe%2C+R+A">Ron A. Hoebe</a>, 
<a href="/search/cs?searchtype=author&query=Krawczyk%2C+P+M">Przemek M. Krawczyk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 3 figures, 4 pages supplemental information; submitted to Cell Patterns; for software, see <a href="https://github.com/NL-BioImaging/biomero">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">In the rapidly evolving field of bioimaging, the integration and
orchestration of Findable, Accessible, Interoperable, and Reusable (FAIR) image
analysis workflows remains a challenge. We introduce BIOMERO, a bridge
connecting OMERO, a renowned bioimaging data management platform, FAIR
workflows and high-performance computing (HPC) environments. BIOMERO, featuring
our opensource Python library "OMERO Slurm Client", facilitates seamless
execution of FAIR workflows, particularly for large datasets from High Content
or High Throughput Screening. BIOMERO empowers researchers by eliminating the
need for specialized knowledge, enabling scalable image processing directly
from OMERO. BIOMERO notably supports the sharing and utilization of FAIR
workflows between OMERO, Cytomine/BIAFLOWS, and other bioimaging communities.
BIOMERO will promote the widespread adoption of FAIR workflows, emphasizing
reusability, across the realm of bioimaging research. Its user-friendly
interface will empower users, including those without technical expertise, to
seamlessly apply these workflows to their datasets, democratizing the
utilization of AI by the broader research community.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00737" title="Abstract">arXiv:2402.00737</a> [<a href="/pdf/2402.00737" title="Download PDF">pdf</a>, <a href="/format/2402.00737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Localization of point scatterers via sparse optimization on measures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Alberti%2C+G+S">Giovanni S. Alberti</a>, 
<a href="/search/math?searchtype=author&query=Petit%2C+R">Romain Petit</a>, 
<a href="/search/math?searchtype=author&query=Santacesaria%2C+M">Matteo Santacesaria</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider the inverse scattering problem for time-harmonic acoustic waves
in a medium with pointwise inhomogeneities. In the Foldy-Lax model, the
estimation of the scatterers' locations and intensities from far field
measurements can be recast as the recovery of a discrete measure from nonlinear
observations. We propose a "linearize and locally optimize" approach to perform
this reconstruction. We first solve a convex program in the space of measures
(known as the Beurling LASSO), which involves a linearization of the forward
operator (the far field pattern in the Born approximation). Then, we locally
minimize a second functional involving the nonlinear forward map, using the
output of the first step as initialization. We provide guarantees that the
output of the first step is close to the sought-after measure when the
scatterers have small intensities and are sufficiently separated. We also
provide numerical evidence that the second step still allows for accurate
recovery in settings that are more involved.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00738" title="Abstract">arXiv:2402.00738</a> [<a href="/pdf/2402.00738" title="Download PDF">pdf</a>, <a href="/format/2402.00738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FM3Q: Factorized Multi-Agent MiniMax Q-Learning for Two-Team Zero-Sum  Markov Game
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+G">Guangzheng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuanheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoran Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongbin Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Many real-world applications involve some agents that fall into two teams,
with payoffs that are equal within the same team but of opposite sign across
the opponent team. The so-called two-team zero-sum Markov games (2t0sMGs) can
be resolved with reinforcement learning in recent years. However, existing
methods are thus inefficient in light of insufficient consideration of
intra-team credit assignment, data utilization and computational
intractability. In this paper, we propose the individual-global-minimax (IGMM)
principle to ensure the coherence between two-team minimax behaviors and the
individual greedy behaviors through Q functions in 2t0sMGs. Based on it, we
present a novel multi-agent reinforcement learning framework, Factorized
Multi-Agent MiniMax Q-Learning (FM3Q), which can factorize the joint minimax Q
function into individual ones and iteratively solve for the IGMM-satisfied
minimax Q functions for 2t0sMGs. Moreover, an online learning algorithm with
neural networks is proposed to implement FM3Q and obtain the deterministic and
decentralized minimax policies for two-team players. A theoretical analysis is
provided to prove the convergence of FM3Q. Empirically, we use three
environments to evaluate the learning efficiency and final performance of FM3Q
and show its superiority on 2t0sMGs.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00740" title="Abstract">arXiv:2402.00740</a> [<a href="/pdf/2402.00740" title="Download PDF">pdf</a>, <a href="/format/2402.00740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DRSM: efficient neural 4d decomposition for dynamic reconstruction in  stationary monocular cameras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weixing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xiao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qiqin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingze Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Junfeng Yao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiaohu Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the popularity of monocular videos generated by video sharing and live
broadcasting applications, reconstructing and editing dynamic scenes in
stationary monocular cameras has become a special but anticipated technology.
In contrast to scene reconstructions that exploit multi-view observations, the
problem of modeling a dynamic scene from a single view is significantly more
under-constrained and ill-posed. Inspired by recent progress in neural
rendering, we present a novel framework to tackle 4D decomposition problem for
dynamic scenes in monocular cameras. Our framework utilizes decomposed static
and dynamic feature planes to represent 4D scenes and emphasizes the learning
of dynamic regions through dense ray casting. Inadequate 3D clues from a
single-view and occlusion are also particular challenges in scene
reconstruction. To overcome these difficulties, we propose deep supervised
optimization and ray casting strategies. With experiments on various videos,
our method generates higher-fidelity results than existing methods for
single-view dynamic scene representation.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00742" title="Abstract">arXiv:2402.00742</a> [<a href="/pdf/2402.00742" title="Download PDF">pdf</a>, <a href="/format/2402.00742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transforming and Combining Rewards for Aligning Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Nagpal%2C+C">Chirag Nagpal</a>, 
<a href="/search/cs?searchtype=author&query=Berant%2C+J">Jonathan Berant</a>, 
<a href="/search/cs?searchtype=author&query=Eisenstein%2C+J">Jacob Eisenstein</a>, 
<a href="/search/cs?searchtype=author&query=D%27Amour%2C+A">Alex D&#x27;Amour</a>, 
<a href="/search/cs?searchtype=author&query=Koyejo%2C+S">Sanmi Koyejo</a>, 
<a href="/search/cs?searchtype=author&query=Veitch%2C+V">Victor Veitch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A common approach for aligning language models to human preferences is to
first learn a reward model from preference data, and then use this reward model
to update the language model. We study two closely related problems that arise
in this approach. First, any monotone transformation of the reward model
preserves preference ranking; is there a choice that is ``better'' than others?
Second, we often wish to align language models to multiple properties: how
should we combine multiple reward models? Using a probabilistic interpretation
of the alignment procedure, we identify a natural choice for transformation for
(the common case of) rewards learned from Bradley-Terry preference models. This
derived transformation has two important properties. First, it emphasizes
improving poorly-performing outputs, rather than outputs that already score
well. This mitigates both underfitting (where some prompts are not improved)
and reward hacking (where the model learns to exploit misspecification of the
reward model). Second, it enables principled aggregation of rewards by linking
summation to logical conjunction: the sum of transformed rewards corresponds to
the probability that the output is ``good'' in all measured properties, in a
sense we make precise. Experiments aligning language models to be both helpful
and harmless using RLHF show substantial improvements over the baseline
(non-transformed) approach.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00743" title="Abstract">arXiv:2402.00743</a> [<a href="/pdf/2402.00743" title="Download PDF">pdf</a>, <a href="/format/2402.00743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benefits of Transformer: In-Context Learning in Linear Regression Tasks  with Unstructured Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+Y">Yue Xing</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiaofeng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+N">Namjoon Suh</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Q">Qifan Song</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+G">Guang Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
<p class="mathjax">In practice, it is observed that transformer-based models can learn concepts
in context in the inference stage. While existing literature, e.g.,
\citet{zhang2023trained,huang2023context}, provide theoretical explanations on
this in-context learning ability, they assume the input $x_i$ and the output
$y_i$ for each sample are embedded in the same token (i.e., structured data).
However, in reality, they are presented in two tokens (i.e., unstructured data
\cite{wibisono2023role}). In this case, this paper conducts experiments in
linear regression tasks to study the benefits of the architecture of
transformers and provides some corresponding theoretical intuitions to explain
why the transformer can learn from unstructured data. We study the exact
components in a transformer that facilitate the in-context learning. In
particular, we observe that (1) a transformer with two layers of softmax
(self-)attentions with look-ahead attention mask can learn from the prompt if
$y_i$ is in the token next to $x_i$ for each example; (2) positional encoding
can further improve the performance; and (3) multi-head attention with a high
input embedding dimension has a better prediction performance than single-head
attention.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00744" title="Abstract">arXiv:2402.00744</a> [<a href="/pdf/2402.00744" title="Download PDF">pdf</a>, <a href="/format/2402.00744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BATON: Aligning Text-to-Audio Model with Human Preference Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+H">Huan Liao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+H">Haonan Han</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+T">Tianjiao Du</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Rui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zunnan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qinmei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingquan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiasheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiu Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">With the development of AI-Generated Content (AIGC), text-to-audio models are
gaining widespread attention. However, it is challenging for these models to
generate audio aligned with human preference due to the inherent information
density of natural language and limited model understanding ability. To
alleviate this issue, we formulate the BATON, a framework designed to enhance
the alignment between generated audio and text prompt using human preference
feedback. Our BATON comprises three key stages: Firstly, we curated a dataset
containing both prompts and the corresponding generated audio, which was then
annotated based on human feedback. Secondly, we introduced a reward model using
the constructed dataset, which can mimic human preference by assigning rewards
to input text-audio pairs. Finally, we employed the reward model to fine-tune
an off-the-shelf text-to-audio model. The experiment results demonstrate that
our BATON can significantly improve the generation quality of the original
text-to-audio models, concerning audio integrity, temporal relationship, and
alignment with human preference.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00745" title="Abstract">arXiv:2402.00745</a> [<a href="/pdf/2402.00745" title="Download PDF">pdf</a>, <a href="/format/2402.00745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Ethical Explanations of Large Language Models through  Iterative Symbolic Refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quan%2C+X">Xin Quan</a>, 
<a href="/search/cs?searchtype=author&query=Valentino%2C+M">Marco Valentino</a>, 
<a href="/search/cs?searchtype=author&query=Dennis%2C+L+A">Louise A. Dennis</a>, 
<a href="/search/cs?searchtype=author&query=Freitas%2C+A">Andr&#xe9; Freitas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera-ready for EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">An increasing amount of research in Natural Language Inference (NLI) focuses
on the application and evaluation of Large Language Models (LLMs) and their
reasoning capabilities. Despite their success, however, LLMs are still prone to
factual errors and inconsistencies in their explanations, offering limited
control and interpretability for inference in complex domains. In this paper,
we focus on ethical NLI, investigating how hybrid neuro-symbolic techniques can
enhance the logical validity and alignment of ethical explanations produced by
LLMs. Specifically, we present an abductive-deductive framework named
Logic-Explainer, which integrates LLMs with an external backward-chaining
solver to refine step-wise natural language explanations and jointly verify
their correctness, reduce incompleteness and minimise redundancy. An extensive
empirical analysis demonstrates that Logic-Explainer can improve explanations
generated via in-context learning methods and Chain-of-Thought (CoT) on
challenging ethical NLI tasks, while, at the same time, producing formal proofs
describing and supporting models' reasoning. As ethical NLI requires
commonsense reasoning to identify underlying moral violations, our results
suggest the effectiveness of neuro-symbolic methods for multi-step NLI more
broadly, opening new opportunities to enhance the logical consistency,
reliability, and alignment of LLMs.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00746" title="Abstract">arXiv:2402.00746</a> [<a href="/pdf/2402.00746" title="Download PDF">pdf</a>, <a href="/format/2402.00746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Health-LLM: Personalized Retrieval-Augmented Disease Prediction Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Mingyu Jin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qinkai Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+D">Dong Shu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Suiyuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+M">Mengnan Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Y">Yanda Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Artificial intelligence (AI) in healthcare has significantly advanced
intelligent medical treatment. However, traditional intelligent healthcare is
limited by static data and unified standards, preventing full integration with
individual situations and other challenges. Hence, a more professional and
detailed intelligent healthcare method is needed for development. To this end,
we propose an innovative framework named Heath-LLM, which combines large-scale
feature extraction and medical knowledge trade-off scoring. Compared to
traditional health management methods, our approach has three main advantages.
First, our method integrates health reports into a large model to provide
detailed task information. Second, professional medical expertise is used to
adjust the weighted scores of health characteristics. Third, we use a
semi-automated feature extraction framework to enhance the analytical power of
language models and incorporate expert insights to improve the accuracy of
disease prediction. We have conducted disease prediction experiments on a large
number of health reports to assess the effectiveness of Health-LLM. The results
of the experiments indicate that the proposed method surpasses traditional
methods and has the potential to revolutionize disease prediction and
personalized health management. The code is available at
https://github.com/jmyissb/HealthLLM.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00751" title="Abstract">arXiv:2402.00751</a> [<a href="/pdf/2402.00751" title="Download PDF">pdf</a>, <a href="/format/2402.00751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlearnable Algorithms for In-context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muresanu%2C+A">Andrei Muresanu</a>, 
<a href="/search/cs?searchtype=author&query=Thudi%2C+A">Anvith Thudi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M+R">Michael R. Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Papernot%2C+N">Nicolas Papernot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Machine unlearning is a desirable operation as models get increasingly
deployed on data with unknown provenance. However, achieving exact unlearning
-- obtaining a model that matches the model distribution when the data to be
forgotten was never used -- is challenging or inefficient, often requiring
significant retraining. In this paper, we focus on efficient unlearning methods
for the task adaptation phase of a pretrained large language model (LLM). We
observe that an LLM's ability to do in-context learning for task adaptation
allows for efficient exact unlearning of task adaptation training data. We
provide an algorithm for selecting few-shot training examples to prepend to the
prompt given to an LLM (for task adaptation), ERASE, whose unlearning operation
cost is independent of model and dataset size, meaning it scales to large
models and datasets. We additionally compare our approach to fine-tuning
approaches and discuss the trade-offs between the two approaches. This leads us
to propose a new holistic measure of unlearning cost which accounts for varying
inference costs, and conclude that in-context learning can often be more
favourable than fine-tuning for deployments involving unlearning requests.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00752" title="Abstract">arXiv:2402.00752</a> [<a href="/pdf/2402.00752" title="Download PDF">pdf</a>, <a href="/format/2402.00752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GS++: Error Analyzing and Optimal Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Letian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jiayang Bai</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jie Guo</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yanwen Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">3D Gaussian Splatting has garnered extensive attention and application in
real-time neural rendering. Concurrently, concerns have been raised about the
limitations of this technology in aspects such as point cloud storage,
performance , and robustness in sparse viewpoints , leading to various
improvements. However, there has been a notable lack of attention to the
projection errors introduced by the local affine approximation inherent in the
splatting itself, and the consequential impact of these errors on the quality
of photo-realistic rendering. This paper addresses the projection error
function of 3D Gaussian Splatting, commencing with the residual error from the
first-order Taylor expansion of the projection function $\phi$. The analysis
establishes a correlation between the error and the Gaussian mean position.
Subsequently, leveraging function optimization theory, this paper analyzes the
function's minima to provide an optimal projection strategy for Gaussian
Splatting referred to Optimal Gaussian Splatting. Experimental validation
further confirms that this projection methodology reduces artifacts, resulting
in a more convincingly realistic rendering.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00759" title="Abstract">arXiv:2402.00759</a> [<a href="/pdf/2402.00759" title="Download PDF">pdf</a>, <a href="/ps/2402.00759" title="Download PostScript">ps</a>, <a href="/format/2402.00759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Expressive and Tractable Probabilistic Generative Models: A  Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sidheekh%2C+S">Sahil Sidheekh</a>, 
<a href="/search/cs?searchtype=author&query=Natarajan%2C+S">Sriraam Natarajan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present a comprehensive survey of the advancements and techniques in the
field of tractable probabilistic generative modeling, primarily focusing on
Probabilistic Circuits (PCs). We provide a unified perspective on the inherent
trade-offs between expressivity and the tractability, highlighting the design
principles and algorithmic extensions that have enabled building expressive and
efficient PCs, and provide a taxonomy of the field. We also discuss recent
efforts to build deep and hybrid PCs by fusing notions from deep neural models,
and outline the challenges and open questions that can guide future research in
this evolving field.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00761" title="Abstract">arXiv:2402.00761</a> [<a href="/pdf/2402.00761" title="Download PDF">pdf</a>, <a href="/ps/2402.00761" title="Download PostScript">ps</a>, <a href="/format/2402.00761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control-Theoretic Techniques for Online Adaptation of Deep Neural  Networks in Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elkins%2C+J+G">Jacob G. Elkins</a>, 
<a href="/search/cs?searchtype=author&query=Fahimi%2C+F">Farbod Fahimi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Robotics (cs.RO); Systems and Control (eess.SY)

</div>
<p class="mathjax">Deep neural networks (DNNs), trained with gradient-based optimization and
backpropagation, are currently the primary tool in modern artificial
intelligence, machine learning, and data science. In many applications, DNNs
are trained offline, through supervised learning or reinforcement learning, and
deployed online for inference. However, training DNNs with standard
backpropagation and gradient-based optimization gives no intrinsic performance
guarantees or bounds on the DNN, which is essential for applications such as
controls. Additionally, many offline-training and online-inference problems,
such as sim2real transfer of reinforcement learning policies, experience domain
shift from the training distribution to the real-world distribution. To address
these stability and transfer learning issues, we propose using techniques from
control theory to update DNN parameters online. We formulate the
fully-connected feedforward DNN as a continuous-time dynamical system, and we
propose novel last-layer update laws that guarantee desirable error convergence
under various conditions on the time derivative of the DNN input vector. We
further show that training the DNN under spectral normalization controls the
upper bound of the error trajectories of the online DNN predictions, which is
desirable when numerically differentiated quantities or noisy state
measurements are input to the DNN. The proposed online DNN adaptation laws are
validated in simulation to learn the dynamics of the Van der Pol system under
domain shift, where parameters are varied in inference from the training
dataset. The simulations demonstrate the effectiveness of using
control-theoretic techniques to derive performance improvements and guarantees
in DNN-based learning systems.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00763" title="Abstract">arXiv:2402.00763</a> [<a href="/pdf/2402.00763" title="Download PDF">pdf</a>, <a href="/format/2402.00763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 360-GS: Layout-guided Panoramic Gaussian Splatting For Indoor Roaming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jiayang Bai</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Letian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jie Guo</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+W">Wen Gong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yanwen Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">3D Gaussian Splatting (3D-GS) has recently attracted great attention with
real-time and photo-realistic renderings. This technique typically takes
perspective images as input and optimizes a set of 3D elliptical Gaussians by
splatting them onto the image planes, resulting in 2D Gaussians. However,
applying 3D-GS to panoramic inputs presents challenges in effectively modeling
the projection onto the spherical surface of ${360^\circ}$ images using 2D
Gaussians. In practical applications, input panoramas are often sparse, leading
to unreliable initialization of 3D Gaussians and subsequent degradation of
3D-GS quality. In addition, due to the under-constrained geometry of
texture-less planes (e.g., walls and floors), 3D-GS struggles to model these
flat regions with elliptical Gaussians, resulting in significant floaters in
novel views. To address these issues, we propose 360-GS, a novel $360^{\circ}$
Gaussian splatting for a limited set of panoramic inputs. Instead of splatting
3D Gaussians directly onto the spherical surface, 360-GS projects them onto the
tangent plane of the unit sphere and then maps them to the spherical
projections. This adaptation enables the representation of the projection using
Gaussians. We guide the optimization of 360-GS by exploiting layout priors
within panoramas, which are simple to obtain and contain strong structural
information about the indoor scene. Our experimental results demonstrate that
360-GS allows panoramic rendering and outperforms state-of-the-art methods with
fewer artifacts in novel view synthesis, thus providing immersive roaming in
indoor scenarios.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00764" title="Abstract">arXiv:2402.00764</a> [<a href="/pdf/2402.00764" title="Download PDF">pdf</a>, <a href="/format/2402.00764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To Search or To Gen? Exploring the Synergy between Generative AI and Web  Search in Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yen%2C+R">Ryan Yen</a>, 
<a href="/search/cs?searchtype=author&query=Sultanum%2C+N">Nicole Sultanum</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jian Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The convergence of generative AI and web search is reshaping problem-solving
for programmers. However, the lack of understanding regarding their interplay
in the information-seeking process often leads programmers to perceive them as
alternatives rather than complementary tools. To analyze this interaction and
explore their synergy, we conducted an interview study with eight experienced
programmers. Drawing from the results and literature, we have identified three
major challenges and proposed three decision-making stages, each with its own
relevant factors. Additionally, we present a comprehensive process model that
captures programmers' interaction patterns. This model encompasses
decision-making stages, the information-foraging loop, and cognitive activities
during system interaction, offering a holistic framework to comprehend and
optimize the use of these convergent tools in programming.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00769" title="Abstract">arXiv:2402.00769</a> [<a href="/pdf/2402.00769" title="Download PDF">pdf</a>, <a href="/format/2402.00769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnimateLCM: Accelerating the Animation of Personalized Diffusion Models  and Adapters with Decoupled Consistency Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fu-Yun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhaoyang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xiaoyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+W">Weikang Bian</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+G">Guanglu Song</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://animatelcm.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Video diffusion models has been gaining increasing attention for its ability
to produce videos that are both coherent and of high fidelity. However, the
iterative denoising process makes it computationally intensive and
time-consuming, thus limiting its applications. Inspired by the Consistency
Model (CM) that distills pretrained image diffusion models to accelerate the
sampling with minimal steps and its successful extension Latent Consistency
Model (LCM) on conditional image generation, we propose AnimateLCM, allowing
for high-fidelity video generation within minimal steps. Instead of directly
conducting consistency learning on the raw video dataset, we propose a
decoupled consistency learning strategy that decouples the distillation of
image generation priors and motion generation priors, which improves the
training efficiency and enhance the generation visual quality. Additionally, to
enable the combination of plug-and-play adapters in stable diffusion community
to achieve various functions (e.g., ControlNet for controllable generation). we
propose an efficient strategy to adapt existing adapters to our distilled
text-conditioned video consistency model or train adapters from scratch without
harming the sampling speed. We validate the proposed strategy in
image-conditioned video generation and layout-conditioned video generation, all
achieving top-performing results. Experimental results validate the
effectiveness of our proposed method. Code and weights will be made public.
More details are available at https://github.com/G-U-N/AnimateLCM.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00771" title="Abstract">arXiv:2402.00771</a> [<a href="/pdf/2402.00771" title="Download PDF">pdf</a>, <a href="/format/2402.00771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed Static and Reconfigurable Metasurface Deployment in Indoor Dense  Spaces: How Much Reconfigurability is Needed?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Topal%2C+O+A">Ozan Alp Topal</a>, 
<a href="/search/cs?searchtype=author&query=Demir%2C+%C3%96+T">&#xd6;zlem Tu&#x11f;fe Demir</a>, 
<a href="/search/cs?searchtype=author&query=Bj%C3%B6rnson%2C+E">Emil Bj&#xf6;rnson</a>, 
<a href="/search/cs?searchtype=author&query=Cavdar%2C+C">Cicek Cavdar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures, Accepted to be presented in IEEE WCNC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we investigate how metasurfaces can be deployed to deliver
high data rates in a millimeter-wave (mmWave) indoor dense space with many
blocking objects. These surfaces can either be static metasurfaces (SMSs) that
reflect with fixed phase-shifts or reconfigurable intelligent surfaces (RISs)
that can reconfigure their phase-shifts to the currently served user. The
latter comes with an increased power, cabling, and signaling cost. To see how
reconfigurability affects the network performance, we propose an iterative
algorithm based on the feasible point pursuit successive convex approximation
method. We jointly optimize the types and phase-shifts of the surfaces and the
time portion allocated to each user equipment to maximize the minimum data rate
achieved by the network. Our numerical results demonstrate that the minimum
data rate improves as more RISs are introduced but the gain diminishes after
some point. Therefore, introducing more reconfigurability is not always
necessary. Another result shows that to reach the same data rate achieved by
using 22 SMSs, at least 18 RISs are needed. This suggests that when it is
costly to deploy many RISs, as an inexpensive alternative solution, one can
reach the same data rate just by densely deploying more SMSs.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00773" title="Abstract">arXiv:2402.00773</a> [<a href="/pdf/2402.00773" title="Download PDF">pdf</a>, <a href="/format/2402.00773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Choice of Loss Function in Learning-based Optimal Power Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+G">Ge Chen</a>, 
<a href="/search/eess?searchtype=author&query=Qin%2C+J">Junjie Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, Accepted by PESGM2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We analyze and contrast two ways to train machine learning models for solving
AC optimal power flow (OPF) problems, distinguished with the loss functions
used. The first trains a mapping from the loads to the optimal dispatch
decisions, utilizing mean square error (MSE) between predicted and optimal
dispatch decisions as the loss function. The other intends to learn the same
mapping, but directly uses the OPF cost of the predicted decisions, referred to
as decision loss, as the loss function. In addition to better aligning with the
OPF cost which results in reduced suboptimality, the use of decision loss can
circumvent feasibility issues that arise with MSE when the underlying mapping
from loads to optimal dispatch is discontinuous. Since decision loss does not
capture the OPF constraints, we further develop a neural network with a
specific structure and introduce a modified training algorithm incorporating
Lagrangian duality to improve feasibility.} This result in an improved
performance measured by feasibility and suboptimality as demonstrated with an
IEEE 39-bus case study.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00774" title="Abstract">arXiv:2402.00774</a> [<a href="/pdf/2402.00774" title="Download PDF">pdf</a>, <a href="/format/2402.00774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mesh motion in fluid-structure interaction with deep operator networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hellan%2C+O">Ottar Hellan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, submitted to proceedings of ENUMATH 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">A mesh motion model based on deep operator networks is presented. The model
is trained on and evaluated against a biharmonic mesh motion model on a
fluid-structure interaction benchmark problem and further evaluated in a
setting where biharmonic mesh motion fails. The performance of the proposed
mesh motion model is comparable to the biharmonic mesh motion on the test
problems.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00775" title="Abstract">arXiv:2402.00775</a> [<a href="/pdf/2402.00775" title="Download PDF">pdf</a>, <a href="/format/2402.00775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Control for Triadic Human-Robot-FES Collaboration in Gait  Rehabilitation: A Pilot Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Christou%2C+A">Andreas Christou</a>, 
<a href="/search/cs?searchtype=author&query=del-Ama%2C+A+J">Antonio J. del-Ama</a>, 
<a href="/search/cs?searchtype=author&query=Moreno%2C+J+C">Juan C. Moreno</a>, 
<a href="/search/cs?searchtype=author&query=Vijayakumar%2C+S">Sethu Vijayakumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The hybridisation of robot-assisted gait training and functional electrical
stimulation (FES) can provide numerous physiological benefits to neurological
patients. However, the design of an effective hybrid controller poses
significant challenges. In this over-actuated system, it is extremely difficult
to find the right balance between robotic assistance and FES that will provide
personalised assistance, prevent muscle fatigue and encourage the patient's
active participation in order to accelerate recovery. In this paper, we present
an adaptive hybrid robot-FES controller to do this and enable the triadic
collaboration between the patient, the robot and FES. A patient-driven
controller is designed where the voluntary movement of the patient is
prioritised and assistance is provided using FES and the robot in a
hierarchical order depending on the patient's performance and their muscles'
fitness. The performance of this hybrid adaptive controller is tested in
simulation and on one healthy subject. Our results indicate an increase in
tracking performance with lower overall assistance, and less muscle fatigue
when the hybrid adaptive controller is used, compared to its non adaptive
equivalent. This suggests that our hybrid adaptive controller may be able to
adapt to the behaviour of the user to provide assistance as needed and prevent
the early termination of physical therapy due to muscle fatigue.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00782" title="Abstract">arXiv:2402.00782</a> [<a href="/pdf/2402.00782" title="Download PDF">pdf</a>, <a href="/format/2402.00782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dense Reward for Free in Reinforcement Learning from Human Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chan%2C+A+J">Alex J. Chan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Holt%2C+S">Samuel Holt</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Reinforcement Learning from Human Feedback (RLHF) has been credited as the
key advance that has allowed Large Language Models (LLMs) to effectively follow
instructions and produce useful assistance. Classically, this involves
generating completions from the LLM in response to a query before using a
separate reward model to assign a score to the full completion. As an
auto-regressive process, the LLM has to take many "actions" (selecting
individual tokens) and only receives a single, sparse reward at the end of an
episode, a setup that is known to be difficult to optimise in traditional
reinforcement learning. In this work we leverage the fact that the reward model
contains more information than just its scalar output, in particular, it
calculates an attention map over tokens as part of the transformer
architecture. We use these attention weights to redistribute the reward along
the whole completion, effectively densifying the signal and highlighting the
most important tokens, all without incurring extra computational cost or
requiring any additional modelling. We demonstrate that, theoretically, this
approach is equivalent to potential-based reward shaping, ensuring that the
optimal policy remains unchanged. Empirically, we show that it stabilises
training, accelerates the rate of learning, and, in practical cases, may lead
to better local optima.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00786" title="Abstract">arXiv:2402.00786</a> [<a href="/pdf/2402.00786" title="Download PDF">pdf</a>, <a href="/format/2402.00786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CroissantLLM: A Truly Bilingual French-English Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faysse%2C+M">Manuel Faysse</a>, 
<a href="/search/cs?searchtype=author&query=Fernandes%2C+P">Patrick Fernandes</a>, 
<a href="/search/cs?searchtype=author&query=Guerreiro%2C+N">Nuno Guerreiro</a>, 
<a href="/search/cs?searchtype=author&query=Loison%2C+A">Ant&#xf3;nio Loison</a>, 
<a href="/search/cs?searchtype=author&query=Alves%2C+D">Duarte Alves</a>, 
<a href="/search/cs?searchtype=author&query=Corro%2C+C">Caio Corro</a>, 
<a href="/search/cs?searchtype=author&query=Boizard%2C+N">Nicolas Boizard</a>, 
<a href="/search/cs?searchtype=author&query=Alves%2C+J">Jo&#xe3;o Alves</a>, 
<a href="/search/cs?searchtype=author&query=Rei%2C+R">Ricardo Rei</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+P">Pedro Martins</a>, 
<a href="/search/cs?searchtype=author&query=Casademunt%2C+A+B">Antoni Bigata Casademunt</a>, 
<a href="/search/cs?searchtype=author&query=Yvon%2C+F">Fran&#xe7;ois Yvon</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+A">Andr&#xe9; Martins</a>, 
<a href="/search/cs?searchtype=author&query=Viaud%2C+G">Gautier Viaud</a>, 
<a href="/search/cs?searchtype=author&query=Hudelot%2C+C">C&#xe9;line Hudelot</a>, 
<a href="/search/cs?searchtype=author&query=Colombo%2C+P">Pierre Colombo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce CroissantLLM, a 1.3B language model pretrained on a set of 3T
English and French tokens, to bring to the research and industrial community a
high-performance, fully open-sourced bilingual model that runs swiftly on
consumer-grade local hardware. To that end, we pioneer the approach of training
an intrinsically bilingual model with a 1:1 English-to-French pretraining data
ratio, a custom tokenizer, and bilingual finetuning datasets. We release the
training dataset, notably containing a French split with manually curated,
high-quality, and varied data sources. To assess performance outside of
English, we craft a novel benchmark, FrenchBench, consisting of an array of
classification and generation tasks, covering various orthogonal aspects of
model performance in the French Language. Additionally, rooted in transparency
and to foster further Large Language Model research, we release codebases, and
dozens of checkpoints across various model sizes, training data distributions,
and training steps, as well as fine-tuned Chat models, and strong translation
models. We evaluate our model through the FMTI framework, and validate 81 % of
the transparency criteria, far beyond the scores of even most open initiatives.
This work enriches the NLP landscape, breaking away from previous
English-centric work in order to strengthen our understanding of
multilinguality in language models.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00787" title="Abstract">arXiv:2402.00787</a> [<a href="/pdf/2402.00787" title="Download PDF">pdf</a>, <a href="/format/2402.00787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning and Calibrating Heterogeneous Bounded Rational Market Behaviour  with Multi-Agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Evans%2C+B+P">Benjamin Patrick Evans</a>, 
<a href="/search/cs?searchtype=author&query=Ganesh%2C+S">Sumitra Ganesh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a full paper at AAMAS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Computational Engineering, Finance, and Science (cs.CE); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG); General Economics (econ.GN)

</div>
<p class="mathjax">Agent-based models (ABMs) have shown promise for modelling various real world
phenomena incompatible with traditional equilibrium analysis. However, a
critical concern is the manual definition of behavioural rules in ABMs. Recent
developments in multi-agent reinforcement learning (MARL) offer a way to
address this issue from an optimisation perspective, where agents strive to
maximise their utility, eliminating the need for manual rule specification.
This learning-focused approach aligns with established economic and financial
models through the use of rational utility-maximising agents. However, this
representation departs from the fundamental motivation for ABMs: that realistic
dynamics emerging from bounded rationality and agent heterogeneity can be
modelled. To resolve this apparent disparity between the two approaches, we
propose a novel technique for representing heterogeneous processing-constrained
agents within a MARL framework. The proposed approach treats agents as
constrained optimisers with varying degrees of strategic skills, permitting
departure from strict utility maximisation. Behaviour is learnt through
repeated simulations with policy gradients to adjust action likelihoods. To
allow efficient computation, we use parameterised shared policy learning with
distributions of agent skill levels. Shared policy learning avoids the need for
agents to learn individual policies yet still enables a spectrum of bounded
rational behaviours. We validate our model's effectiveness using real-world
data on a range of canonical $n$-agent settings, demonstrating significantly
improved predictive capability.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00789" title="Abstract">arXiv:2402.00789</a> [<a href="/pdf/2402.00789" title="Download PDF">pdf</a>, <a href="/format/2402.00789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph-Mamba: Towards Long-Range Graph Sequence Modeling with Selective  State Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chloe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tsepa%2C+O">Oleksii Tsepa</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Attention mechanisms have been widely used to capture long-range dependencies
among nodes in Graph Transformers. Bottlenecked by the quadratic computational
cost, attention mechanisms fail to scale in large graphs. Recent improvements
in computational efficiency are mainly achieved by attention sparsification
with random or heuristic-based graph subsampling, which falls short in
data-dependent context reasoning. State space models (SSMs), such as Mamba,
have gained prominence for their effectiveness and efficiency in modeling
long-range dependencies in sequential data. However, adapting SSMs to
non-sequential graph data presents a notable challenge. In this work, we
introduce Graph-Mamba, the first attempt to enhance long-range context modeling
in graph networks by integrating a Mamba block with the input-dependent node
selection mechanism. Specifically, we formulate graph-centric node
prioritization and permutation strategies to enhance context-aware reasoning,
leading to a substantial improvement in predictive performance. Extensive
experiments on ten benchmark datasets demonstrate that Graph-Mamba outperforms
state-of-the-art methods in long-range graph prediction tasks, with a fraction
of the computational cost in both FLOPs and GPU memory consumption. The code
and models are publicly available at https://github.com/bowang-lab/Graph-Mamba.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00790" title="Abstract">arXiv:2402.00790</a> [<a href="/pdf/2402.00790" title="Download PDF">pdf</a>, <a href="/ps/2402.00790" title="Download PostScript">ps</a>, <a href="/format/2402.00790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Pre-Quantum to Post-Quantum IoT Security: A Survey on  Quantum-Resistant Cryptosystems for the Internet of Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fernandez-Carames%2C+T+M">Tiago M. Fernandez-Carames</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> T. M. Fernandez-Carames, "From Pre-Quantum to Post-Quantum IoT
  Security: A Survey on Quantum-Resistant Cryptosystems for the Internet of
  Things," in IEEE Internet of Things Journal, vol. 7, no. 7, pp. 6457-6480,
  July 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">This article provides a survey on what can be called post-quantum IoT systems
(IoT systems protected from the currently known quantum computing attacks): the
main post-quantum cryptosystems and initiatives are reviewed, the most relevant
IoT architectures and challenges are analyzed, and the expected future trends
are indicated. Thus, this paper is aimed at providing a wide view of
post-quantum IoT security and give useful guidelines to the future post-quantum
IoT developers.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00791" title="Abstract">arXiv:2402.00791</a> [<a href="/pdf/2402.00791" title="Download PDF">pdf</a>, <a href="/format/2402.00791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hausdorff Reductions and the Exponential Hierarchies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malizia%2C+E">Enrico Malizia</a> (University of Bologna, Italy)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ii + 100 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">The Strong Exponential Hierarchy $SEH$ was shown to collapse to $P^{NExp}$ by
Hemachandra by proving $P^{NExp} = NP^{NExp}$ via a census argument.
Nonetheless, Hemachandra also asked for certificate-based and alternating
Turing machine characterizations of the $SEH$ levels, in the hope that these
might have revealed deeper structural reasons behind the collapse. These open
questions have thus far remained unanswered.
<br />To close them, by building upon the notion of Hausdorff reductions, we
investigate a natural normal form for the intermediate levels of the
(generalized) exponential hierarchies, i.e., the single-, the
double-Exponential Hierarchy, and so on. Although the two characterizations
asked for derive from our Hausdorff characterization, it is nevertheless from
the latter that a surprising structural reason behind the collapse of $SEH$ is
uncovered as a consequence of a very general result: the intermediate levels of
the exponential hierarchies are precisely characterized by specific "Hausdorff
classes", which define these levels without resorting to oracle machines. By
this, contrarily to oracle classes, which may have different shapes for a same
class (e.g., $P^{NP}_{||} = P^{NP[Log]} = LogSpace^{NP}$), hierarchy
intermediate levels are univocally identified by Hausdorff classes (under the
hypothesis of no hierarchy collapse). In fact, we show that the rather simple
reason behind many equivalences of oracle classes is that they just refer to
different ways of deciding the languages of a same Hausdorff class, and this
happens also for $P^{NExp}$ and $NP^{NExp}$.
<br />In addition, via Hausdorff classes, we define complete problems for various
intermediate levels of the exponential hierarchies. Through these, we obtain
matching lower-bounds for problems known to be in $P^{NExp[Log]}$, but whose
hardness was left open due to the lack of known $P^{NExp[Log]}$-complete
problems.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00793" title="Abstract">arXiv:2402.00793</a> [<a href="/pdf/2402.00793" title="Download PDF">pdf</a>, <a href="/format/2402.00793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distinguishing the Indistinguishable: Human Expertise in Algorithmic  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alur%2C+R">Rohan Alur</a>, 
<a href="/search/cs?searchtype=author&query=Raghavan%2C+M">Manish Raghavan</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+D">Devavrat Shah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">We introduce a novel framework for incorporating human expertise into
algorithmic predictions. Our approach focuses on the use of human judgment to
distinguish inputs which `look the same' to any feasible predictive algorithm.
We argue that this framing clarifies the problem of human/AI collaboration in
prediction tasks, as experts often have access to information -- particularly
subjective information -- which is not encoded in the algorithm's training
data. We use this insight to develop a set of principled algorithms for
selectively incorporating human feedback only when it improves the performance
of any feasible predictor. We find empirically that although algorithms often
outperform their human counterparts on average, human judgment can
significantly improve algorithmic predictions on specific instances (which can
be identified ex-ante). In an X-ray classification task, we find that this
subset constitutes nearly 30% of the patient population. Our approach provides
a natural way of uncovering this heterogeneity and thus enabling effective
human-AI collaboration.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00794" title="Abstract">arXiv:2402.00794</a> [<a href="/pdf/2402.00794" title="Download PDF">pdf</a>, <a href="/format/2402.00794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReAGent: Towards A Model-agnostic Feature Attribution Method for  Generative Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhixue Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+B">Boxuan Shan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Feature attribution methods (FAs), such as gradients and attention, are
widely employed approaches to derive the importance of all input features to
the model predictions. Existing work in natural language processing has mostly
focused on developing and testing FAs for encoder-only language models (LMs) in
classification tasks. However, it is unknown if it is faithful to use these FAs
for decoder-only models on text generation, due to the inherent differences
between model architectures and task settings respectively. Moreover, previous
work has demonstrated that there is no `one-wins-all' FA across models and
tasks. This makes the selection of a FA computationally expensive for large LMs
since input importance derivation often requires multiple forward and backward
passes including gradient computations that might be prohibitive even with
access to large compute. To address these issues, we present a model-agnostic
FA for generative LMs called Recursive Attribution Generator (ReAGent). Our
method updates the token importance distribution in a recursive manner. For
each update, we compute the difference in the probability distribution over the
vocabulary for predicting the next token between using the original input and
using a modified version where a part of the input is replaced with RoBERTa
predictions. Our intuition is that replacing an important token in the context
should have resulted in a larger change in the model's confidence in predicting
the token than replacing an unimportant token. Our method can be universally
applied to any generative LM without accessing internal model weights or
additional training and fine-tuning, as most other FAs require. We extensively
compare the faithfulness of ReAGent with seven popular FAs across six
decoder-only LMs of various sizes. The results show that our method
consistently provides more faithful token importance distributions.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00795" title="Abstract">arXiv:2402.00795</a> [<a href="/pdf/2402.00795" title="Download PDF">pdf</a>, <a href="/format/2402.00795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMs learn governing principles of dynamical systems, revealing an  in-context neural scaling law
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T+J+B">Toni J.B. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Boull%C3%A9%2C+N">Nicolas Boull&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Sarfati%2C+R">Rapha&#xeb;l Sarfati</a>, 
<a href="/search/cs?searchtype=author&query=Earls%2C+C+J">Christopher J. Earls</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Pretrained large language models (LLMs) are surprisingly effective at
performing zero-shot tasks, including time-series forecasting. However,
understanding the mechanisms behind such capabilities remains highly
challenging due to the complexity of the models. In this paper, we study LLMs'
ability to extrapolate the behavior of dynamical systems whose evolution is
governed by principles of physical interest. Our results show that LLaMA 2, a
language model trained primarily on texts, achieves accurate predictions of
dynamical system time series without fine-tuning or prompt engineering.
Moreover, the accuracy of the learned physical rules increases with the length
of the input context window, revealing an in-context version of neural scaling
law. Along the way, we present a flexible and efficient algorithm for
extracting probability density functions of multi-digit numbers directly from
LLMs.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00798" title="Abstract">arXiv:2402.00798</a> [<a href="/pdf/2402.00798" title="Download PDF">pdf</a>, <a href="/format/2402.00798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formal-LLM: Integrating Formal Language and Natural Language for  Controllable LLM-based Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zelong Li</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+W">Wenyue Hua</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">He Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongfeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 6 figures; working in process, suggestions are welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">Recent advancements on Large Language Models (LLMs) enable AI Agents to
automatically generate and execute multi-step plans to solve complex tasks.
However, since LLM's content generation process is hardly controllable, current
LLM-based agents frequently generate invalid or non-executable plans, which
jeopardizes the performance of the generated plans and corrupts users' trust in
LLM-based agents. In response, this paper proposes a novel ``Formal-LLM''
framework for LLM-based agents by integrating the expressiveness of natural
language and the precision of formal language. Specifically, the framework
allows human users to express their requirements or constraints for the
planning process as an automaton. A stack-based LLM plan generation process is
then conducted under the supervision of the automaton to ensure that the
generated plan satisfies the constraints, making the planning process
controllable. We conduct experiments on both benchmark tasks and practical
real-life tasks, and our framework achieves over 50% overall performance
increase, which validates the feasibility and effectiveness of employing
Formal-LLM to guide the plan generation of agents, preventing the agents from
generating invalid and unsuccessful plans. Further, more controllable LLM-based
agents can facilitate the broader utilization of LLM in application scenarios
where high validity of planning is essential. The work is open-sourced at
https://github.com/agiresearch/Formal-LLM.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00803" title="Abstract">arXiv:2402.00803</a> [<a href="/pdf/2402.00803" title="Download PDF">pdf</a>, <a href="/format/2402.00803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Signal Quality Auditing for Time-series Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chufan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Gisolfi%2C+N">Nicholas Gisolfi</a>, 
<a href="/search/cs?searchtype=author&query=Dubrawski%2C+A">Artur Dubrawski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Signal quality assessment (SQA) is required for monitoring the reliability of
data acquisition systems, especially in AI-driven Predictive Maintenance (PMx)
application contexts. SQA is vital for addressing "silent failures" of data
acquisition hardware and software, which when unnoticed, misinform the users of
data, creating the risk for incorrect decisions with unintended or even
catastrophic consequences. We have developed an open-source software
implementation of signal quality indices (SQIs) for the analysis of time-series
data. We codify a range of SQIs, demonstrate them using established benchmark
data, and show that they can be effective for signal quality assessment. We
also study alternative approaches to denoising time-series data in an attempt
to improve the quality of the already degraded signal, and evaluate them
empirically on relevant real-world data. To our knowledge, our software toolkit
is the first to provide an open source implementation of a broad range of
signal quality assessment and improvement techniques validated on publicly
available benchmark data for ease of reproducibility. The generality of our
framework can be easily extended to assessing reliability of arbitrary
time-series measurements in complex systems, especially when morphological
patterns of the waveform shapes and signal periodicity are of key interest in
downstream analyses.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00807" title="Abstract">arXiv:2402.00807</a> [<a href="/pdf/2402.00807" title="Download PDF">pdf</a>, <a href="/format/2402.00807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distilling Conditional Diffusion Models for Offline Reinforcement  Learning through Trajectory Stitching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shangzhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinhua Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep generative models have recently emerged as an effective approach to
offline reinforcement learning. However, their large model size poses
challenges in computation. We address this issue by proposing a knowledge
distillation method based on data augmentation. In particular, high-return
trajectories are generated from a conditional diffusion model, and they are
blended with the original trajectories through a novel stitching algorithm that
leverages a new reward generator. Applying the resulting dataset to behavioral
cloning, the learned shallow policy whose size is much smaller outperforms or
nearly matches deep generative planners on several D4RL benchmarks.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00808" title="Abstract">arXiv:2402.00808</a> [<a href="/pdf/2402.00808" title="Download PDF">pdf</a>, <a href="/format/2402.00808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Dynamics between Cobot&#x27;s Production Rhythm, Locus of  Control and Emotional State in a Collaborative Assembly Scenario
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mondellini%2C+M">Marta Mondellini</a>, 
<a href="/search/cs?searchtype=author&query=Nicora%2C+M+L">Matteo Lavit Nicora</a>, 
<a href="/search/cs?searchtype=author&query=Prajod%2C+P">Pooja Prajod</a>, 
<a href="/search/cs?searchtype=author&query=Andr%C3%A9%2C+E">Elisabeth Andr&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Vertechy%2C+R">Rocco Vertechy</a>, 
<a href="/search/cs?searchtype=author&query=Antonietti%2C+A">Alessandro Antonietti</a>, 
<a href="/search/cs?searchtype=author&query=Malosio%2C+M">Matteo Malosio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to 4th IEEE International Conference on Human-Machine Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In industrial scenarios, there is widespread use of collaborative robots
(cobots), and growing interest is directed at evaluating and measuring the
impact of some characteristics of the cobot on the human factor. In the present
pilot study, the effect that the production rhythm (C1 - Slow, C2 - Fast, C3 -
Adapted to the participant's pace) of a cobot has on the Experiential Locus of
Control (ELoC) and the emotional state of 31 participants has been examined.
The operators' performance, the degree of basic internal Locus of Control, and
the attitude towards the robots were also considered. No difference was found
regarding the emotional state and the ELoC in the three conditions, but
considering the other psychological variables, a more complex situation
emerges. Overall, results seem to indicate a need to consider the person's
psychological characteristics to offer a differentiated and optimal interaction
experience.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00809" title="Abstract">arXiv:2402.00809</a> [<a href="/pdf/2402.00809" title="Download PDF">pdf</a>, <a href="/format/2402.00809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Position Paper: Bayesian Deep Learning in the Age of Large-Scale AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papamarkou%2C+T">Theodore Papamarkou</a>, 
<a href="/search/cs?searchtype=author&query=Skoularidou%2C+M">Maria Skoularidou</a>, 
<a href="/search/cs?searchtype=author&query=Palla%2C+K">Konstantina Palla</a>, 
<a href="/search/cs?searchtype=author&query=Aitchison%2C+L">Laurence Aitchison</a>, 
<a href="/search/cs?searchtype=author&query=Arbel%2C+J">Julyan Arbel</a>, 
<a href="/search/cs?searchtype=author&query=Dunson%2C+D">David Dunson</a>, 
<a href="/search/cs?searchtype=author&query=Filippone%2C+M">Maurizio Filippone</a>, 
<a href="/search/cs?searchtype=author&query=Fortuin%2C+V">Vincent Fortuin</a>, 
<a href="/search/cs?searchtype=author&query=Hennig%2C+P">Philipp Hennig</a>, 
<a href="/search/cs?searchtype=author&query=Hubin%2C+A">Aliaksandr Hubin</a>, 
<a href="/search/cs?searchtype=author&query=Immer%2C+A">Alexander Immer</a>, 
<a href="/search/cs?searchtype=author&query=Karaletsos%2C+T">Theofanis Karaletsos</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+E">Mohammad Emtiyaz Khan</a>, 
<a href="/search/cs?searchtype=author&query=Kristiadi%2C+A">Agustinus Kristiadi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingzhen Li</a>, 
<a href="/search/cs?searchtype=author&query=Lobato%2C+J+M+H">Jose Miguel Hernandez Lobato</a>, 
<a href="/search/cs?searchtype=author&query=Mandt%2C+S">Stephan Mandt</a>, 
<a href="/search/cs?searchtype=author&query=Nemeth%2C+C">Christopher Nemeth</a>, 
<a href="/search/cs?searchtype=author&query=Osborne%2C+M+A">Michael A. Osborne</a>, 
<a href="/search/cs?searchtype=author&query=Rudner%2C+T+G+J">Tim G. J. Rudner</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%BCgamer%2C+D">David R&#xfc;gamer</a>, 
<a href="/search/cs?searchtype=author&query=Teh%2C+Y+W">Yee Whye Teh</a>, 
<a href="/search/cs?searchtype=author&query=Welling%2C+M">Max Welling</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+A+G">Andrew Gordon Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruqi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">In the current landscape of deep learning research, there is a predominant
emphasis on achieving high predictive accuracy in supervised tasks involving
large image and language datasets. However, a broader perspective reveals a
multitude of overlooked metrics, tasks, and data types, such as uncertainty,
active and continual learning, and scientific data, that demand attention.
Bayesian deep learning (BDL) constitutes a promising avenue, offering
advantages across these diverse settings. This paper posits that BDL can
elevate the capabilities of deep learning. It revisits the strengths of BDL,
acknowledges existing challenges, and highlights some exciting research avenues
aimed at addressing these obstacles. Looking ahead, the discussion focuses on
possible ways to combine large-scale foundation models with BDL to unlock their
full potential.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00816" title="Abstract">arXiv:2402.00816</a> [<a href="/pdf/2402.00816" title="Download PDF">pdf</a>, <a href="/format/2402.00816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Approximate Model-based Shielding for Probabilistic Safety  Guarantees in Continuous Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goodall%2C+A+W">Alexander W. Goodall</a>, 
<a href="/search/cs?searchtype=author&query=Belardinelli%2C+F">Francesco Belardinelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as an Extended Abstract at AAMAS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Shielding is a popular technique for achieving safe reinforcement learning
(RL). However, classical shielding approaches come with quite restrictive
assumptions making them difficult to deploy in complex environments,
particularly those with continuous state or action spaces. In this paper we
extend the more versatile approximate model-based shielding (AMBS) framework to
the continuous setting. In particular we use Safety Gym as our test-bed,
allowing for a more direct comparison of AMBS with popular constrained RL
algorithms. We also provide strong probabilistic safety guarantees for the
continuous setting. In addition, we propose two novel penalty techniques that
directly modify the policy gradient, which empirically provide more stable
convergence in our experiments.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00822" title="Abstract">arXiv:2402.00822</a> [<a href="/pdf/2402.00822" title="Download PDF">pdf</a>, <a href="/format/2402.00822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WiOpen: A Robust Wi-Fi-based Open-set Gesture Recognition Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jingyang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Huan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Peng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+G">Guohang Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent years have witnessed a growing interest in Wi-Fi-based gesture
recognition. However, existing works have predominantly focused on closed-set
paradigms, where all testing gestures are predefined during training. This
poses a significant challenge in real-world applications, as unseen gestures
might be misclassified as known classes during testing. To address this issue,
we propose WiOpen, a robust Wi-Fi-based Open-Set Gesture Recognition (OSGR)
framework. Implementing OSGR requires addressing challenges caused by the
unique uncertainty in Wi-Fi sensing. This uncertainty, resulting from noise and
domains, leads to widely scattered and irregular data distributions in
collected Wi-Fi sensing data. Consequently, data ambiguity between classes and
challenges in defining appropriate decision boundaries to identify unknowns
arise. To tackle these challenges, WiOpen adopts a two-fold approach to
eliminate uncertainty and define precise decision boundaries. Initially, it
addresses uncertainty induced by noise during data preprocessing by utilizing
the CSI ratio. Next, it designs the OSGR network based on an uncertainty
quantification method. Throughout the learning process, this network
effectively mitigates uncertainty stemming from domains. Ultimately, the
network leverages relationships among samples' neighbors to dynamically define
open-set decision boundaries, successfully realizing OSGR. Comprehensive
experiments on publicly accessible datasets confirm WiOpen's effectiveness.
Notably, WiOpen also demonstrates superiority in cross-domain tasks when
compared to state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00823" title="Abstract">arXiv:2402.00823</a> [<a href="/pdf/2402.00823" title="Download PDF">pdf</a>, <a href="/format/2402.00823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SLIM: Skill Learning with Multiple Critics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Emukpere%2C+D">David Emukpere</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bingbing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Perez%2C+J">Julien Perez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Self-supervised skill learning aims to acquire useful behaviors that leverage
the underlying dynamics of the environment. Latent variable models, based on
mutual information maximization, have been particularly successful in this task
but still struggle in the context of robotic manipulation. As it requires
impacting a possibly large set of degrees of freedom composing the environment,
mutual information maximization fails alone in producing useful manipulation
behaviors. To address this limitation, we introduce SLIM, a multi-critic
learning approach for skill discovery with a particular focus on robotic
manipulation. Our main insight is that utilizing multiple critics in an
actor-critic framework to gracefully combine multiple reward functions leads to
a significant improvement in latent-variable skill discovery for robotic
manipulation while overcoming possible interference occurring among rewards
which hinders convergence to useful skills. Furthermore, in the context of
tabletop manipulation, we demonstrate the applicability of our novel skill
discovery approach to acquire safe and efficient motor primitives in a
hierarchical reinforcement learning fashion and leverage them through planning,
surpassing the state-of-the-art approaches for skill discovery by a large
margin.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00825" title="Abstract">arXiv:2402.00825</a> [<a href="/pdf/2402.00825" title="Download PDF">pdf</a>, <a href="/format/2402.00825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resolution invariant deep operator network for PDEs with complex  geometries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Huang%2C+J">Jianguo Huang</a>, 
<a href="/search/math?searchtype=author&query=Qiu%2C+Y">Yue Qiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Neural operators (NO) are discretization invariant deep learning methods with
functional output and can approximate any continuous operator. NO have
demonstrated the superiority of solving partial differential equations (PDEs)
over other deep learning methods. However, the spatial domain of its input
function needs to be identical to its output, which limits its applicability.
For instance, the widely used Fourier neural operator (FNO) fails to
approximate the operator that maps the boundary condition to the PDE solution.
To address this issue, we propose a novel framework called resolution-invariant
deep operator (RDO) that decouples the spatial domain of the input and output.
RDO is motivated by the Deep operator network (DeepONet) and it does not
require retraining the network when the input/output is changed compared with
DeepONet. RDO takes functional input and its output is also functional so that
it keeps the resolution invariant property of NO. It can also resolve PDEs with
complex geometries whereas NO fail. Various numerical experiments demonstrate
the advantage of our method over DeepONet and FNO.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00827" title="Abstract">arXiv:2402.00827</a> [<a href="/pdf/2402.00827" title="Download PDF">pdf</a>, <a href="/format/2402.00827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emo-Avatar: Efficient Monocular Video Style Avatar through Texture  Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Pinxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Luchuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Daoan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+H">Hang Hua</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yunlong Tang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+H">Huaijin Tu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiebo Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenliang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Artistic video portrait generation is a significant and sought-after task in
the fields of computer graphics and vision. While various methods have been
developed that integrate NeRFs or StyleGANs with instructional editing models
for creating and editing drivable portraits, these approaches face several
challenges. They often rely heavily on large datasets, require extensive
customization processes, and frequently result in reduced image quality. To
address the above problems, we propose the Efficient Monotonic Video Style
Avatar (Emo-Avatar) through deferred neural rendering that enhances StyleGAN's
capacity for producing dynamic, drivable portrait videos. We proposed a
two-stage deferred neural rendering pipeline. In the first stage, we utilize
few-shot PTI initialization to initialize the StyleGAN generator through
several extreme poses sampled from the video to capture the consistent
representation of aligned faces from the target portrait. In the second stage,
we propose a Laplacian pyramid for high-frequency texture sampling from UV maps
deformed by dynamic flow of expression for motion-aware texture prior
integration to provide torso features to enhance StyleGAN's ability to generate
complete and upper body for portrait video rendering. Emo-Avatar reduces style
customization time from hours to merely 5 minutes compared with existing
methods. In addition, Emo-Avatar requires only a single reference image for
editing and employs region-aware contrastive learning with semantic invariant
CLIP guidance, ensuring consistent high-resolution output and identity
preservation. Through both quantitative and qualitative assessments, Emo-Avatar
demonstrates superior performance over existing methods in terms of training
efficiency, rendering quality and editability in self- and cross-reenactment.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00829" title="Abstract">arXiv:2402.00829</a> [<a href="/pdf/2402.00829" title="Download PDF">pdf</a>, <a href="/format/2402.00829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The En Route Truck-Drone Delivery Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krizanc%2C+D">Danny Krizanc</a>, 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+L">Lata Narayanan</a>, 
<a href="/search/cs?searchtype=author&query=Opatrny%2C+J">Jaroslav Opatrny</a>, 
<a href="/search/cs?searchtype=author&query=Pankratov%2C+D">Denis Pankratov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study the truck-drone cooperative delivery problem in a setting where a
single truck carrying a drone travels at constant speed on a straight-line
trajectory/street. Delivery to clients located in the plane and not on the
truck's trajectory is performed by the drone, which has limited carrying
capacity and flying range, and whose battery can be recharged when on the
truck. We show that the problem of maximizing the number of deliveries is
strongly NP-hard even in this simple setting. We present a 2-approximation
algorithm for the problem, and an optimal algorithm for a non-trivial family of
instances.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00830" title="Abstract">arXiv:2402.00830</a> [<a href="/pdf/2402.00830" title="Download PDF">pdf</a>, <a href="/ps/2402.00830" title="Download PostScript">ps</a>, <a href="/format/2402.00830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Common errors in Generative AI systems used for knowledge extraction in  the climate action domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Havlik%2C+D">Denis Havlik</a>, 
<a href="/search/cs?searchtype=author&query=Pias%2C+M">Marcelo Pias</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) and, more specifically, the Generative
Pre-Trained Transformers (GPT) can help stakeholders in climate action explore
digital knowledge bases and extract and utilize climate action knowledge in a
sustainable manner. However, LLMs are "probabilistic models of knowledge bases"
that excel at generating convincing texts but cannot be entirely relied upon
due to the probabilistic nature of the information produced. This brief report
illustrates the problem space with examples of LLM responses to some of the
questions of relevance to climate action.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00831" title="Abstract">arXiv:2402.00831</a> [<a href="/pdf/2402.00831" title="Download PDF">pdf</a>, <a href="/format/2402.00831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A YANG-aided Unified Strategy for Black Hole Detection for Backbone  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ak%2C+E">Elif Ak</a>, 
<a href="/search/cs?searchtype=author&query=Kaya%2C+K">Kiymet Kaya</a>, 
<a href="/search/cs?searchtype=author&query=Ozaltun%2C+E">Eren Ozaltun</a>, 
<a href="/search/cs?searchtype=author&query=Oguducu%2C+S+G">Sule Gunduz Oguducu</a>, 
<a href="/search/cs?searchtype=author&query=Canberk%2C+B">Berk Canberk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite the crucial importance of addressing Black Hole failures in Internet
backbone networks, effective detection strategies in backbone networks are
lacking. This is largely because previous research has been centered on Mobile
Ad-hoc Networks (MANETs), which operate under entirely different dynamics,
protocols, and topologies, making their findings not directly transferable to
backbone networks. Furthermore, detecting Black Hole failures in backbone
networks is particularly challenging. It requires a comprehensive range of
network data due to the wide variety of conditions that need to be considered,
making data collection and analysis far from straightforward. Addressing this
gap, our study introduces a novel approach for Black Hole detection in backbone
networks using specialized Yet Another Next Generation (YANG) data models with
Black Hole-sensitive Metric Matrix (BHMM) analysis. This paper details our
method of selecting and analyzing four YANG models relevant to Black Hole
detection in ISP networks, focusing on routing protocols and ISP-specific
configurations. Our BHMM approach derived from these models demonstrates a 10%
improvement in detection accuracy and a 13% increase in packet delivery rate,
highlighting the efficiency of our approach. Additionally, we evaluate the
Machine Learning approach leveraged with BHMM analysis in two different network
settings, a commercial ISP network, and a scientific research-only network
topology. This evaluation also demonstrates the practical applicability of our
method, yielding significantly improved prediction outcomes in both
environments.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00834" title="Abstract">arXiv:2402.00834</a> [<a href="/pdf/2402.00834" title="Download PDF">pdf</a>, <a href="/format/2402.00834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximating maximum-size properly colored forests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yuhang Bai</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%A9rczi%2C+K">Krist&#xf3;f B&#xe9;rczi</a>, 
<a href="/search/cs?searchtype=author&query=Cs%C3%A1ji%2C+G">Gergely Cs&#xe1;ji</a>, 
<a href="/search/cs?searchtype=author&query=Schwarcz%2C+T">Tam&#xe1;s Schwarcz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">In the Properly Colored Spanning Tree problem, we are given an edge-colored
undirected graph and the goal is to find a properly colored spanning tree,
i.e., a spanning tree in which any two adjacent edges have distinct colors. The
problem is interesting not only from a graph coloring point of view, but is
also closely related to the Degree Bounded Spanning Tree and (1,2)-Traveling
Salesman problems, two classical questions that have attracted considerable
interest in combinatorial optimization and approximation theory. Previous work
on properly colored spanning trees has mainly focused on determining the
existence of such a tree and hence has not considered the question from an
algorithmic perspective. We propose an optimization version called Maximum-size
Properly Colored Forest problem, which aims to find a properly colored forest
with as many edges as possible. We consider the problem in different graph
classes and for different numbers of colors, and present polynomial-time
approximation algorithms as well as inapproximability results for these
settings. Our proof technique relies on the sum of matching matroids defined by
the color classes, a connection that might be of independent combinatorial
interest.
<br />We also consider the Maximum-size Properly Colored Tree problem, which asks
for the maximum size of a properly colored tree not necessarily spanning all
the vertices. We show that the optimum is significantly more difficult to
approximate than in the forest case, and provide an approximation algorithm for
complete multigraphs.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00835" title="Abstract">arXiv:2402.00835</a> [<a href="/pdf/2402.00835" title="Download PDF">pdf</a>, <a href="/format/2402.00835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ALISON: Fast and Effective Stylometric Authorship Obfuscation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+E">Eric Xing</a>, 
<a href="/search/cs?searchtype=author&query=Venkatraman%2C+S">Saranya Venkatraman</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Thai Le</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongwon Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures, 4 tables. To be published in the Proceedings of the 38th Annual AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Authorship Attribution (AA) and Authorship Obfuscation (AO) are two competing
tasks of increasing importance in privacy research. Modern AA leverages an
author's consistent writing style to match a text to its author using an AA
classifier. AO is the corresponding adversarial task, aiming to modify a text
in such a way that its semantics are preserved, yet an AA model cannot
correctly infer its authorship. To address privacy concerns raised by
state-of-the-art (SOTA) AA methods, new AO methods have been proposed but
remain largely impractical to use due to their prohibitively slow training and
obfuscation speed, often taking hours. To this challenge, we propose a
practical AO method, ALISON, that (1) dramatically reduces training/obfuscation
time, demonstrating more than 10x faster obfuscation than SOTA AO methods, (2)
achieves better obfuscation success through attacking three transformer-based
AA methods on two benchmark datasets, typically performing 15% better than
competing methods, (3) does not require direct signals from a target AA
classifier during obfuscation, and (4) utilizes unique stylometric features,
allowing sound model interpretation for explainable obfuscation. We also
demonstrate that ALISON can effectively prevent four SOTA AA methods from
accurately determining the authorship of ChatGPT-generated texts, all while
minimally changing the original text semantics. To ensure the reproducibility
of our findings, our code and data are available at:
https://github.com/EricX003/ALISON.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00838" title="Abstract">arXiv:2402.00838</a> [<a href="/pdf/2402.00838" title="Download PDF">pdf</a>, <a href="/format/2402.00838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OLMo: Accelerating the Science of Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Groeneveld%2C+D">Dirk Groeneveld</a>, 
<a href="/search/cs?searchtype=author&query=Beltagy%2C+I">Iz Beltagy</a>, 
<a href="/search/cs?searchtype=author&query=Walsh%2C+P">Pete Walsh</a>, 
<a href="/search/cs?searchtype=author&query=Bhagia%2C+A">Akshita Bhagia</a>, 
<a href="/search/cs?searchtype=author&query=Kinney%2C+R">Rodney Kinney</a>, 
<a href="/search/cs?searchtype=author&query=Tafjord%2C+O">Oyvind Tafjord</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+A+H">Ananya Harsh Jha</a>, 
<a href="/search/cs?searchtype=author&query=Ivison%2C+H">Hamish Ivison</a>, 
<a href="/search/cs?searchtype=author&query=Magnusson%2C+I">Ian Magnusson</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yizhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+S">Shane Arora</a>, 
<a href="/search/cs?searchtype=author&query=Atkinson%2C+D">David Atkinson</a>, 
<a href="/search/cs?searchtype=author&query=Authur%2C+R">Russell Authur</a>, 
<a href="/search/cs?searchtype=author&query=Chandu%2C+K+R">Khyathi Raghavi Chandu</a>, 
<a href="/search/cs?searchtype=author&query=Cohan%2C+A">Arman Cohan</a>, 
<a href="/search/cs?searchtype=author&query=Dumas%2C+J">Jennifer Dumas</a>, 
<a href="/search/cs?searchtype=author&query=Elazar%2C+Y">Yanai Elazar</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuling Gu</a>, 
<a href="/search/cs?searchtype=author&query=Hessel%2C+J">Jack Hessel</a>, 
<a href="/search/cs?searchtype=author&query=Khot%2C+T">Tushar Khot</a>, 
<a href="/search/cs?searchtype=author&query=Merrill%2C+W">William Merrill</a>, 
<a href="/search/cs?searchtype=author&query=Morrison%2C+J">Jacob Morrison</a>, 
<a href="/search/cs?searchtype=author&query=Muennighoff%2C+N">Niklas Muennighoff</a>, 
<a href="/search/cs?searchtype=author&query=Naik%2C+A">Aakanksha Naik</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+C">Crystal Nam</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+M+E">Matthew E. Peters</a>, 
<a href="/search/cs?searchtype=author&query=Pyatkin%2C+V">Valentina Pyatkin</a>, 
<a href="/search/cs?searchtype=author&query=Ravichander%2C+A">Abhilasha Ravichander</a>, 
<a href="/search/cs?searchtype=author&query=Schwenk%2C+D">Dustin Schwenk</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+S">Saurabh Shah</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+W">Will Smith</a>, 
<a href="/search/cs?searchtype=author&query=Strubell%2C+E">Emma Strubell</a>, 
<a href="/search/cs?searchtype=author&query=Subramani%2C+N">Nishant Subramani</a>, 
<a href="/search/cs?searchtype=author&query=Wortsman%2C+M">Mitchell Wortsman</a>, 
<a href="/search/cs?searchtype=author&query=Dasigi%2C+P">Pradeep Dasigi</a>, 
<a href="/search/cs?searchtype=author&query=Lambert%2C+N">Nathan Lambert</a>, 
<a href="/search/cs?searchtype=author&query=Richardson%2C+K">Kyle Richardson</a>, 
<a href="/search/cs?searchtype=author&query=Zettlemoyer%2C+L">Luke Zettlemoyer</a>, 
<a href="/search/cs?searchtype=author&query=Dodge%2C+J">Jesse Dodge</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+K">Kyle Lo</a>, 
<a href="/search/cs?searchtype=author&query=Soldaini%2C+L">Luca Soldaini</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+N+A">Noah A. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Hajishirzi%2C+H">Hannaneh Hajishirzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Language models (LMs) have become ubiquitous in both NLP research and in
commercial product offerings. As their commercial importance has surged, the
most powerful models have become closed off, gated behind proprietary
interfaces, with important details of their training data, architectures, and
development undisclosed. Given the importance of these details in
scientifically studying these models, including their biases and potential
risks, we believe it is essential for the research community to have access to
powerful, truly open LMs. To this end, this technical report details the first
release of OLMo, a state-of-the-art, truly Open Language Model and its
framework to build and study the science of language modeling. Unlike most
prior efforts that have only released model weights and inference code, we
release OLMo and the whole framework, including training data and training and
evaluation code. We hope this release will empower and strengthen the open
research community and inspire a new wave of innovation.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00839" title="Abstract">arXiv:2402.00839</a> [<a href="/pdf/2402.00839" title="Download PDF">pdf</a>, <a href="/format/2402.00839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> X-CBA: Explainability Aided CatBoosted Anomal-E for Intrusion Detection  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaya%2C+K">Kiymet Kaya</a>, 
<a href="/search/cs?searchtype=author&query=Ak%2C+E">Elif Ak</a>, 
<a href="/search/cs?searchtype=author&query=Bas%2C+S">Sumeyye Bas</a>, 
<a href="/search/cs?searchtype=author&query=Canberk%2C+B">Berk Canberk</a>, 
<a href="/search/cs?searchtype=author&query=Oguducu%2C+S+G">Sule Gunduz Oguducu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">The effectiveness of Intrusion Detection Systems (IDS) is critical in an era
where cyber threats are becoming increasingly complex. Machine learning (ML)
and deep learning (DL) models provide an efficient and accurate solution for
identifying attacks and anomalies in computer networks. However, using ML and
DL models in IDS has led to a trust deficit due to their non-transparent
decision-making. This transparency gap in IDS research is significant,
affecting confidence and accountability. To address, this paper introduces a
novel Explainable IDS approach, called X-CBA, that leverages the structural
advantages of Graph Neural Networks (GNNs) to effectively process network
traffic data, while also adapting a new Explainable AI (XAI) methodology.
Unlike most GNN-based IDS that depend on labeled network traffic and node
features, thereby overlooking critical packet-level information, our approach
leverages a broader range of traffic data through network flows, including edge
attributes, to improve detection capabilities and adapt to novel threats.
Through empirical testing, we establish that our approach not only achieves
high accuracy with 99.47% in threat detection but also advances the field by
providing clear, actionable explanations of its analytical outcomes. This
research also aims to bridge the current gap and facilitate the broader
integration of ML/DL technologies in cybersecurity defenses by offering a local
and global explainability solution that is both precise and interpretable.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00841" title="Abstract">arXiv:2402.00841</a> [<a href="/pdf/2402.00841" title="Download PDF">pdf</a>, <a href="/format/2402.00841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tiny Titans: Can Smaller Large Language Models Punch Above Their Weight  in the Real World for Meeting Summarization?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xue-Yong Fu</a>, 
<a href="/search/cs?searchtype=author&query=Laskar%2C+M+T+R">Md Tahmid Rahman Laskar</a>, 
<a href="/search/cs?searchtype=author&query=Khasanova%2C+E">Elena Khasanova</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=TN%2C+S+B">Shashi Bhushan TN</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have demonstrated impressive capabilities to
solve a wide range of tasks without being explicitly fine-tuned on
task-specific datasets. However, deploying LLMs in the real world is not
trivial, as it requires substantial computing resources. In this paper, we
investigate whether smaller, compact LLMs are a good alternative to the
comparatively Larger LLMs2 to address significant costs associated with
utilizing LLMs in the real world. In this regard, we study the meeting
summarization task in a real-world industrial environment and conduct extensive
experiments by comparing the performance of fine-tuned compact LLMs (e.g.,
FLAN-T5, TinyLLaMA, LiteLLaMA) with zero-shot larger LLMs (e.g., LLaMA-2,
GPT-3.5, PaLM-2). We observe that most smaller LLMs, even after fine-tuning,
fail to outperform larger zero-shot LLMs in meeting summarization datasets.
However, a notable exception is FLAN-T5 (780M parameters), which performs on
par or even better than many zero-shot Larger LLMs (from 7B to above 70B
parameters), while being significantly smaller. This makes compact LLMs like
FLAN-T5 a suitable cost-efficient solution for real-world industrial
deployment.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00845" title="Abstract">arXiv:2402.00845</a> [<a href="/pdf/2402.00845" title="Download PDF">pdf</a>, <a href="/ps/2402.00845" title="Download PostScript">ps</a>, <a href="/format/2402.00845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When to Preempt in a Status Update System?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Subhankar Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Ulukus%2C+S">Sennur Ulukus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Computer Science and Game Theory (cs.GT); Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
<p class="mathjax">We consider a time slotted status update system with an error-free preemptive
queue. The goal of the sampler-scheduler pair is to minimize the age of
information at the monitor by sampling and transmitting the freshly sampled
update packets to the monitor. The sampler-scheduler pair also has a choice to
preempt an old update packet from the server and transmit a new update packet
to the server. We formulate this problem as a Markov decision process and find
the optimal sampling policy. We show that it is optimal for the
sampler-scheduler pair to sample a new packet immediately upon the reception of
an update packet at the monitor. We also show that the optimal choice for the
scheduler is to preempt an update packet in the server, if the age of that
packet crosses a fixed threshold. Finally, we find the optimal preemption
threshold when the range of the service time of the server is finite, otherwise
we find the $\epsilon$-optimal preemption threshold.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00846" title="Abstract">arXiv:2402.00846</a> [<a href="/pdf/2402.00846" title="Download PDF">pdf</a>, <a href="/format/2402.00846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing scattering resonances of rough obstacles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=R%C3%B6sler%2C+F">Frank R&#xf6;sler</a>, 
<a href="/search/math?searchtype=author&query=Stepanenko%2C+A">Alexei Stepanenko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP); Spectral Theory (math.SP)

</div>
<p class="mathjax">This paper is concerned with the numerical computation of scattering
resonances of the Laplacian for Dirichlet obstacles with rough boundary. We
prove that under mild geometric assumptions on the obstacle there exists an
algorithm whose output is guaranteed to converge to the set of resonances of
the problem. The result is formulated using the framework of Solvability
Complexity Indices. The proof is constructive and provides an efficient
numerical method. The algorithm is based on a combination of a Glazman
decomposition, a polygonal approximation of the obstacle and a finite element
method. Our result applies in particular to obstacles with fractal boundary,
such as the Koch Snowflake and certain filled Julia sets. Finally, we provide
numerical experiments in MATLAB for a range of interesting obstacle domains.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00847" title="Abstract">arXiv:2402.00847</a> [<a href="/pdf/2402.00847" title="Download PDF">pdf</a>, <a href="/format/2402.00847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BootsTAP: Bootstrapped Training for Tracking-Any-Point
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doersch%2C+C">Carl Doersch</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gokay%2C+D">Dilara Gokay</a>, 
<a href="/search/cs?searchtype=author&query=Luc%2C+P">Pauline Luc</a>, 
<a href="/search/cs?searchtype=author&query=Koppula%2C+S">Skanda Koppula</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Ankush Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Heyward%2C+J">Joseph Heyward</a>, 
<a href="/search/cs?searchtype=author&query=Goroshin%2C+R">Ross Goroshin</a>, 
<a href="/search/cs?searchtype=author&query=Carreira%2C+J">Jo&#xe3;o Carreira</a>, 
<a href="/search/cs?searchtype=author&query=Zisserman%2C+A">Andrew Zisserman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">To endow models with greater understanding of physics and motion, it is
useful to enable them to perceive how solid surfaces move and deform in real
scenes. This can be formalized as Tracking-Any-Point (TAP), which requires the
algorithm to be able to track any point corresponding to a solid surface in a
video, potentially densely in space and time. Large-scale ground-truth training
data for TAP is only available in simulation, which currently has limited
variety of objects and motion. In this work, we demonstrate how large-scale,
unlabeled, uncurated real-world data can improve a TAP model with minimal
architectural changes, using a self-supervised student-teacher setup. We
demonstrate state-of-the-art performance on the TAP-Vid benchmark surpassing
previous results by a wide margin: for example, TAP-Vid-DAVIS performance
improves from 61.3% to 66.4%, and TAP-Vid-Kinetics from 57.2% to 61.5%.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00848" title="Abstract">arXiv:2402.00848</a> [<a href="/pdf/2402.00848" title="Download PDF">pdf</a>, <a href="/ps/2402.00848" title="Download PostScript">ps</a>, <a href="/format/2402.00848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-sided discretization inequalities and sampling recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Limonova%2C+I">Irina Limonova</a>, 
<a href="/search/math?searchtype=author&query=Malykhin%2C+Y">Yuri Malykhin</a>, 
<a href="/search/math?searchtype=author&query=Temlyakov%2C+V">Vladimir Temlyakov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Functional Analysis (math.FA)

</div>
<p class="mathjax">Recently, in a number of papers it was understood that results on sampling
discretization and on the universal sampling discretization can be successfully
used in the problem of sampling recovery. Moreover, it turns out that it is
sufficient to only have a one-sided discretization inequality for some of those
applications. This motivates us to write the present paper as a survey/research
paper with the focus on the one-sided discretization inequalities and their
applications in the sampling recovery. In this sense the paper complements the
two existing survey papers on sampling discretization.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00849" title="Abstract">arXiv:2402.00849</a> [<a href="/pdf/2402.00849" title="Download PDF">pdf</a>, <a href="/format/2402.00849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Score-based Causal Representation Learning: Linear and General  Transformations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Var%C4%B1c%C4%B1%2C+B">Burak Var&#x131;c&#x131;</a>, 
<a href="/search/cs?searchtype=author&query=Acart%C3%BCrk%2C+E">Emre Acart&#xfc;rk</a>, 
<a href="/search/cs?searchtype=author&query=Shanmugam%2C+K">Karthikeyan Shanmugam</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Abhishek Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Tajer%2C+A">Ali Tajer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Linear transformations: stronger results for hard and soft interventions than our previous paper Score-based Causal Representation Learning with Interventions (<a href="https://arxiv.org/abs/2301.08230">this https URL</a>). General transformations: results also appear in our paper General Identifiability and Achievability for Causal Representation Learning (<a href="/abs/2310.15450">arXiv:2310.15450</a>) accepted to AISTATS 2024 (oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper addresses intervention-based causal representation learning (CRL)
under a general nonparametric latent causal model and an unknown transformation
that maps the latent variables to the observed variables. Linear and general
transformations are investigated. The paper addresses both the
\emph{identifiability} and \emph{achievability} aspects. Identifiability refers
to determining algorithm-agnostic conditions that ensure recovering the true
latent causal variables and the latent causal graph underlying them.
Achievability refers to the algorithmic aspects and addresses designing
algorithms that achieve identifiability guarantees. By drawing novel
connections between \emph{score functions} (i.e., the gradients of the
logarithm of density functions) and CRL, this paper designs a \emph{score-based
class of algorithms} that ensures both identifiability and achievability.
First, the paper focuses on \emph{linear} transformations and shows that one
stochastic hard intervention per node suffices to guarantee identifiability. It
also provides partial identifiability guarantees for soft interventions,
including identifiability up to ancestors for general causal models and perfect
latent graph recovery for sufficiently non-linear causal models. Secondly, it
focuses on \emph{general} transformations and shows that two stochastic hard
interventions per node suffice for identifiability. Notably, one does
\emph{not} need to know which pair of interventional environments have the same
node intervened.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00850" title="Abstract">arXiv:2402.00850</a> [<a href="/pdf/2402.00850" title="Download PDF">pdf</a>, <a href="/format/2402.00850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constant Degree Direct Product Testers with Small Soundness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bafna%2C+M">Mitali Bafna</a>, 
<a href="/search/cs?searchtype=author&query=Lifshitz%2C+N">Noam Lifshitz</a>, 
<a href="/search/cs?searchtype=author&query=Minzer%2C+D">Dor Minzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">Let $X$ be a $d$-dimensional simplicial complex. A function $F\colon X(k)\to
\{0,1\}^k$ is said to be a direct product function if there exists a function
$f\colon X(1)\to \{0,1\}$ such that $F(\sigma) = (f(\sigma_1), \ldots,
f(\sigma_k))$ for each $k$-face $\sigma$. In an effort to simplify components
of the PCP theorem, Goldreich and Safra introduced the problem of direct
product testing, which asks whether one can test if $F\colon X(k)\to \{0,1\}^k$
is correlated with a direct product function by querying $F$ on only $2$
inputs. Dinur and Kaufman conjectured that there exist bounded degree complexes
with a direct product test in the small soundness regime. We resolve their
conjecture by showing that for all $\delta&gt;0$, there exists a family of
high-dimensional expanders with degree $O_{\delta}(1)$ and a $2$-query direct
product tester with soundness $\delta$.
<br />We use the characterization given by a subset of the authors and
independently by Dikstein and Dinur, who showed that some form of non-Abelian
coboundary expansion (which they called "Unique-Games coboundary expansion") is
a necessary and sufficient condition for a complex to admit such direct product
testers. Our main technical contribution is a general technique for showing
coboundary expansion of complexes with coefficients in a non-Abelian group.
This allows us to prove that the high dimensional expanders constructed by
Chapman and Lubotzky satisfies the necessary conditions, thus admitting a
2-query direct product tester with small soundness.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00851" title="Abstract">arXiv:2402.00851</a> [<a href="/pdf/2402.00851" title="Download PDF">pdf</a>, <a href="/format/2402.00851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Augmentation Scheme for Raman Spectra with Highly Correlated  Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lange%2C+C">Christoph Lange</a>, 
<a href="/search/cs?searchtype=author&query=Thiele%2C+I">Isabel Thiele</a>, 
<a href="/search/cs?searchtype=author&query=Santolin%2C+L">Lara Santolin</a>, 
<a href="/search/cs?searchtype=author&query=Riedel%2C+S+L">Sebastian L. Riedel</a>, 
<a href="/search/cs?searchtype=author&query=Borisyak%2C+M">Maxim Borisyak</a>, 
<a href="/search/cs?searchtype=author&query=Neubauer%2C+P">Peter Neubauer</a>, 
<a href="/search/cs?searchtype=author&query=Bournazou%2C+M+N+C">M. Nicolas Cruz Bournazou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">In biotechnology Raman Spectroscopy is rapidly gaining popularity as a
process analytical technology (PAT) that measures cell densities, substrate-
and product concentrations. As it records vibrational modes of molecules it
provides that information non-invasively in a single spectrum. Typically,
partial least squares (PLS) is the model of choice to infer information about
variables of interest from the spectra. However, biological processes are known
for their complexity where convolutional neural networks (CNN) present a
powerful alternative. They can handle non-Gaussian noise and account for beam
misalignment, pixel malfunctions or the presence of additional substances.
However, they require a lot of data during model training, and they pick up
non-linear dependencies in the process variables. In this work, we exploit the
additive nature of spectra in order to generate additional data points from a
given dataset that have statistically independent labels so that a network
trained on such data exhibits low correlations between the model predictions.
We show that training a CNN on these generated data points improves the
performance on datasets where the annotations do not bear the same correlation
as the dataset that was used for model training. This data augmentation
technique enables us to reuse spectra as training data for new contexts that
exhibit different correlations. The additional data allows for building a
better and more robust model. This is of interest in scenarios where large
amounts of historical data are available but are currently not used for model
training. We demonstrate the capabilities of the proposed method using
synthetic spectra of Ralstonia eutropha batch cultivations to monitor
substrate, biomass and polyhydroxyalkanoate (PHA) biopolymer concentrations
during of the experiments.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00853" title="Abstract">arXiv:2402.00853</a> [<a href="/pdf/2402.00853" title="Download PDF">pdf</a>, <a href="/format/2402.00853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LTAU-FF: Loss Trajectory Analysis for Uncertainty in Atomistic Force  Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vita%2C+J+A">Joshua A. Vita</a>, 
<a href="/search/cs?searchtype=author&query=Samanta%2C+A">Amit Samanta</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Fei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lordi%2C+V">Vincenzo Lordi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Materials Science (cond-mat.mtrl-sci)

</div>
<p class="mathjax">Model ensembles are simple and effective tools for estimating the prediction
uncertainty of deep learning atomistic force fields. Despite this, widespread
adoption of ensemble-based uncertainty quantification (UQ) techniques is
limited by the high computational costs incurred by ensembles during both
training and inference. In this work we leverage the cumulative distribution
functions (CDFs) of per-sample errors obtained over the course of training to
efficiently represent the model ensemble, and couple them with a distance-based
similarity search in the model latent space. Using these tools, we develop a
simple UQ metric (which we call LTAU) that leverages the strengths of
ensemble-based techniques without requiring the evaluation of multiple models
during either training or inference. As an initial test, we apply our method
towards estimating the epistemic uncertainty in atomistic force fields
(LTAU-FF) and demonstrate that it can be easily calibrated to accurately
predict test errors on multiple datasets from the literature. We then
illustrate the utility of LTAU-FF in two practical applications: 1) tuning the
training-validation gap for an example dataset, and 2) predicting errors in
relaxation trajectories on the OC20 IS2RS task. Though in this work we focus on
the use of LTAU with deep learning atomistic force fields, we emphasize that it
can be readily applied to any regression task, or any ensemble-generation
technique, to provide a reliable and easy-to-implement UQ metric.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00854" title="Abstract">arXiv:2402.00854</a> [<a href="/pdf/2402.00854" title="Download PDF">pdf</a>, <a href="/format/2402.00854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SymbolicAI: A framework for logic-based approaches combining generative  models and solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dinu%2C+M">Marius-Constantin Dinu</a>, 
<a href="/search/cs?searchtype=author&query=Leoveanu-Condrei%2C+C">Claudiu Leoveanu-Condrei</a>, 
<a href="/search/cs?searchtype=author&query=Holzleitner%2C+M">Markus Holzleitner</a>, 
<a href="/search/cs?searchtype=author&query=Zellinger%2C+W">Werner Zellinger</a>, 
<a href="/search/cs?searchtype=author&query=Hochreiter%2C+S">Sepp Hochreiter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 12 figures, external resources: framework is available at <a href="https://github.com/ExtensityAI/symbolicai">this https URL</a> and benchmark at <a href="https://github.com/ExtensityAI/benchmark">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Symbolic Computation (cs.SC); Software Engineering (cs.SE)

</div>
<p class="mathjax">We introduce SymbolicAI, a versatile and modular framework employing a
logic-based approach to concept learning and flow management in generative
processes. SymbolicAI enables the seamless integration of generative models
with a diverse range of solvers by treating large language models (LLMs) as
semantic parsers that execute tasks based on both natural and formal language
instructions, thus bridging the gap between symbolic reasoning and generative
AI. We leverage probabilistic programming principles to tackle complex tasks,
and utilize differentiable and classical programming paradigms with their
respective strengths. The framework introduces a set of polymorphic,
compositional, and self-referential operations for data stream manipulation,
aligning LLM outputs with user objectives. As a result, we can transition
between the capabilities of various foundation models endowed with zero- and
few-shot learning capabilities and specialized, fine-tuned models or solvers
proficient in addressing specific problems. In turn, the framework facilitates
the creation and evaluation of explainable computational graphs. We conclude by
introducing a quality measure and its empirical score for evaluating these
computational graphs, and propose a benchmark that compares various
state-of-the-art LLMs across a set of complex workflows. We refer to the
empirical score as the "Vector Embedding for Relational Trajectory Evaluation
through Cross-similarity", or VERTEX score for short. The framework codebase
and benchmark are linked below.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00856" title="Abstract">arXiv:2402.00856</a> [<a href="/pdf/2402.00856" title="Download PDF">pdf</a>, <a href="/format/2402.00856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Efficient and Exact Optimization of Language Model Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Haozhe Ji</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yilin Niu</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+P">Pei Ke</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jie Tang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Minlie Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The alignment of language models with human preferences is vital for their
application in real-world tasks. The problem is formulated as optimizing the
model's policy to maximize the expected reward that reflects human preferences
with minimal deviation from the initial policy. While considered as a
straightforward solution, reinforcement learning (RL) suffers from high
variance in policy updates, which impedes efficient policy improvement.
Recently, direct preference optimization (DPO) was proposed to directly
optimize the policy from preference data. Though simple to implement, DPO is
derived based on the optimal policy that is not assured to be achieved in
practice, which undermines its convergence to the intended solution.
<br />In this paper, we propose efficient exact optimization (EXO) of the alignment
objective. We prove that EXO is guaranteed to optimize in the same direction as
the RL algorithms asymptotically for arbitary parametrization of the policy,
while enables efficient optimization by circumventing the complexities
associated with RL algorithms. We compare our method to DPO with both
theoretical and empirical analyses, and further demonstrate the advantages of
our method over existing approaches on realistic human preference data.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00857" title="Abstract">arXiv:2402.00857</a> [<a href="/pdf/2402.00857" title="Download PDF">pdf</a>, <a href="/format/2402.00857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Early Time Classification with Accumulated Accuracy Gap Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ringel%2C+L">Liran Ringel</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+R">Regev Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Freedman%2C+D">Daniel Freedman</a>, 
<a href="/search/cs?searchtype=author&query=Elad%2C+M">Michael Elad</a>, 
<a href="/search/cs?searchtype=author&query=Romano%2C+Y">Yaniv Romano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Early time classification algorithms aim to label a stream of features
without processing the full input stream, while maintaining accuracy comparable
to that achieved by applying the classifier to the entire input. In this paper,
we introduce a statistical framework that can be applied to any sequential
classifier, formulating a calibrated stopping rule. This data-driven rule
attains finite-sample, distribution-free control of the accuracy gap between
full and early-time classification. We start by presenting a novel method that
builds on the Learn-then-Test calibration framework to control this gap
marginally, on average over i.i.d. instances. As this algorithm tends to yield
an excessively high accuracy gap for early halt times, our main contribution is
the proposal of a framework that controls a stronger notion of error, where the
accuracy gap is controlled conditionally on the accumulated halt times.
Numerical experiments demonstrate the effectiveness, applicability, and
usefulness of our method. We show that our proposed early stopping mechanism
reduces up to 94% of timesteps used for classification while achieving rigorous
accuracy gap control.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00858" title="Abstract">arXiv:2402.00858</a> [<a href="/pdf/2402.00858" title="Download PDF">pdf</a>, <a href="/format/2402.00858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Large Language Models Understand Context?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yilun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Moniz%2C+J+R+A">Joel Ruben Antony Moniz</a>, 
<a href="/search/cs?searchtype=author&query=Bhargava%2C+S">Shruti Bhargava</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiarui Lu</a>, 
<a href="/search/cs?searchtype=author&query=Piraviperumal%2C+D">Dhivya Piraviperumal</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Site Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Tseng%2C+B">Bo-Hsiang Tseng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Understanding context is key to understanding human language, an ability
which Large Language Models (LLMs) have been increasingly seen to demonstrate
to an impressive extent. However, though the evaluation of LLMs encompasses
various domains within the realm of Natural Language Processing, limited
attention has been paid to probing their linguistic capability of understanding
contextual features. This paper introduces a context understanding benchmark by
adapting existing datasets to suit the evaluation of generative models. This
benchmark comprises of four distinct tasks and nine datasets, all featuring
prompts designed to assess the models' ability to understand context. First, we
evaluate the performance of LLMs under the in-context learning pretraining
scenario. Experimental results indicate that pre-trained dense models struggle
with understanding more nuanced contextual features when compared to
state-of-the-art fine-tuned models. Second, as LLM compression holds growing
significance in both research and real-world applications, we assess the
context understanding of quantized models under in-context-learning settings.
We find that 3-bit post-training quantization leads to varying degrees of
performance reduction on our benchmark. We conduct an extensive analysis of
these scenarios to substantiate our experimental results.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00861" title="Abstract">arXiv:2402.00861</a> [<a href="/pdf/2402.00861" title="Download PDF">pdf</a>, <a href="/format/2402.00861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Large Language Models for Generalization and Robustness via  Data Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yucheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yunhao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Guerin%2C+F">Frank Guerin</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenghua Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Existing methods for evaluating large language models face challenges such as
data contamination, sensitivity to prompts, and the high cost of benchmark
creation. To address this, we propose a lossless data compression based
evaluation approach that tests how models' predictive abilities generalize
after their training cutoff. Specifically, we collect comprehensive test data
spanning 83 months from 2017 to 2023 and split the data into training and
testing periods according to models' training data cutoff. We measure: 1) the
compression performance on the testing period as a measure of generalization on
unseen data; and 2) the performance gap between the training and testing period
as a measure of robustness. Our experiments test 14 representative large
language models with various sizes on sources including Wikipedia, news
articles, code, arXiv papers, and multi-modal data. We find that the
compression rate of many models reduces significantly after their cutoff date,
but models such as Mistral and Llama-2 demonstrate a good balance between
performance and robustness. Results also suggest that models struggle to
generalize on news and code data, but work especially well on arXiv papers. We
also find the context size and tokenization implementation have a big impact of
on the overall compression performance.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00863" title="Abstract">arXiv:2402.00863</a> [<a href="/pdf/2402.00863" title="Download PDF">pdf</a>, <a href="/format/2402.00863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometry Transfer for Stylizing Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jung%2C+H">Hyunyoung Jung</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+S">Seonghyeon Nam</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+N+S">Nikolaos SarafianosSungjoo Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Sorkine-Hornung%2C+A">Alexander Sorkine-Hornung</a>, 
<a href="/search/cs?searchtype=author&query=Ranjan%2C+R">Rakesh Ranjan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page: <a href="https://hyblue.github.io/geo-srf/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Shape and geometric patterns are essential in defining stylistic identity.
However, current 3D style transfer methods predominantly focus on transferring
colors and textures, often overlooking geometric aspects. In this paper, we
introduce Geometry Transfer, a novel method that leverages geometric
deformation for 3D style transfer. This technique employs depth maps to extract
a style guide, subsequently applied to stylize the geometry of radiance fields.
Moreover, we propose new techniques that utilize geometric cues from the 3D
scene, thereby enhancing aesthetic expressiveness and more accurately
reflecting intended styles. Our extensive experiments show that Geometry
Transfer enables a broader and more expressive range of stylizations, thereby
significantly expanding the scope of 3D style transfer.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00864" title="Abstract">arXiv:2402.00864</a> [<a href="/pdf/2402.00864" title="Download PDF">pdf</a>, <a href="/format/2402.00864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViCA-NeRF: View-Consistency-Aware 3D Editing of Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jiahua Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Xiong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Neurips2023; project page: <a href="https://github.com/Dongjiahua/VICA-NeRF">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce ViCA-NeRF, the first view-consistency-aware method for 3D
editing with text instructions. In addition to the implicit neural radiance
field (NeRF) modeling, our key insight is to exploit two sources of
regularization that explicitly propagate the editing information across
different views, thus ensuring multi-view consistency. For geometric
regularization, we leverage the depth information derived from NeRF to
establish image correspondences between different views. For learned
regularization, we align the latent codes in the 2D diffusion model between
edited and unedited images, enabling us to edit key views and propagate the
update throughout the entire scene. Incorporating these two strategies, our
ViCA-NeRF operates in two stages. In the initial stage, we blend edits from
different views to create a preliminary 3D edit. This is followed by a second
stage of NeRF training, dedicated to further refining the scene's appearance.
Experimental results demonstrate that ViCA-NeRF provides more flexible,
efficient (3 times faster) editing with higher levels of consistency and
details, compared with the state of the art. Our code is publicly available.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00865" title="Abstract">arXiv:2402.00865</a> [<a href="/pdf/2402.00865" title="Download PDF">pdf</a>, <a href="/format/2402.00865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Optimal Feature-Shaping Methods for Out-of-Distribution  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qinyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Ming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+K">Kartik Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Asthana%2C+A">Akshay Asthana</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Liang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Gould%2C+S">Stephen Gould</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024. Project page: <a href="https://github.com/Qinyu-Allen-Zhao/OptFSOOD">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Feature shaping refers to a family of methods that exhibit state-of-the-art
performance for out-of-distribution (OOD) detection. These approaches
manipulate the feature representation, typically from the penultimate layer of
a pre-trained deep learning model, so as to better differentiate between
in-distribution (ID) and OOD samples. However, existing feature-shaping methods
usually employ rules manually designed for specific model architectures and OOD
datasets, which consequently limit their generalization ability. To address
this gap, we first formulate an abstract optimization framework for studying
feature-shaping methods. We then propose a concrete reduction of the framework
with a simple piecewise constant shaping function and show that existing
feature-shaping methods approximate the optimal solution to the concrete
optimization problem. Further, assuming that OOD data is inaccessible, we
propose a formulation that yields a closed-form solution for the piecewise
constant shaping function, utilizing solely the ID data. Through extensive
experiments, we show that the feature-shaping function optimized by our method
improves the generalization ability of OOD detection across a large variety of
datasets and model architectures.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00867" title="Abstract">arXiv:2402.00867</a> [<a href="/pdf/2402.00867" title="Download PDF">pdf</a>, <a href="/format/2402.00867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AToM: Amortized Text-to-Mesh using 2D Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+G">Guocheng Qian</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Junli Cao</a>, 
<a href="/search/cs?searchtype=author&query=Siarohin%2C+A">Aliaksandr Siarohin</a>, 
<a href="/search/cs?searchtype=author&query=Kant%2C+Y">Yash Kant</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chaoyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Vasilkovsky%2C+M">Michael Vasilkovsky</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hsin-Ying Lee</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuwei Fang</a>, 
<a href="/search/cs?searchtype=author&query=Skorokhodov%2C+I">Ivan Skorokhodov</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+P">Peiye Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Gilitschenski%2C+I">Igor Gilitschenski</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jian Ren</a>, 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+B">Bernard Ghanem</a>, 
<a href="/search/cs?searchtype=author&query=Aberman%2C+K">Kfir Aberman</a>, 
<a href="/search/cs?searchtype=author&query=Tulyakov%2C+S">Sergey Tulyakov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages with appendix and references. Webpage: <a href="https://snap-research.github.io/AToM/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce Amortized Text-to-Mesh (AToM), a feed-forward text-to-mesh
framework optimized across multiple text prompts simultaneously. In contrast to
existing text-to-3D methods that often entail time-consuming per-prompt
optimization and commonly output representations other than polygonal meshes,
AToM directly generates high-quality textured meshes in less than 1 second with
around 10 times reduction in the training cost, and generalizes to unseen
prompts. Our key idea is a novel triplane-based text-to-mesh architecture with
a two-stage amortized optimization strategy that ensures stable training and
enables scalability. Through extensive experiments on various prompt
benchmarks, AToM significantly outperforms state-of-the-art amortized
approaches with over 4 times higher accuracy (in DF415 dataset) and produces
more distinguishable and higher-quality 3D outputs. AToM demonstrates strong
generalizability, offering finegrained 3D assets for unseen interpolated
prompts without further optimization during inference, unlike per-prompt
solutions.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00868" title="Abstract">arXiv:2402.00868</a> [<a href="/pdf/2402.00868" title="Download PDF">pdf</a>, <a href="/format/2402.00868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> We&#x27;re Not Using Videos Effectively: An Updated Domain Adaptive Video  Segmentation Baseline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kareer%2C+S">Simar Kareer</a>, 
<a href="/search/cs?searchtype=author&query=Vijaykumar%2C+V">Vivek Vijaykumar</a>, 
<a href="/search/cs?searchtype=author&query=Maheshwari%2C+H">Harsh Maheshwari</a>, 
<a href="/search/cs?searchtype=author&query=Chattopadhyay%2C+P">Prithvijit Chattopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Hoffman%2C+J">Judy Hoffman</a>, 
<a href="/search/cs?searchtype=author&query=Prabhu%2C+V">Viraj Prabhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TMLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">There has been abundant work in unsupervised domain adaptation for semantic
segmentation (DAS) seeking to adapt a model trained on images from a labeled
source domain to an unlabeled target domain. While the vast majority of prior
work has studied this as a frame-level Image-DAS problem, a few Video-DAS works
have sought to additionally leverage the temporal signal present in adjacent
frames. However, Video-DAS works have historically studied a distinct set of
benchmarks from Image-DAS, with minimal cross-benchmarking. In this work, we
address this gap. Surprisingly, we find that (1) even after carefully
controlling for data and model architecture, state-of-the-art Image-DAS methods
(HRDA and HRDA+MIC)} outperform Video-DAS methods on established Video-DAS
benchmarks (+14.5 mIoU on Viper$\rightarrow$CityscapesSeq, +19.0 mIoU on
Synthia$\rightarrow$CityscapesSeq), and (2) naive combinations of Image-DAS and
Video-DAS techniques only lead to marginal improvements across datasets. To
avoid siloed progress between Image-DAS and Video-DAS, we open-source our
codebase with support for a comprehensive set of Video-DAS and Image-DAS
methods on a common benchmark. Code available at
https://github.com/SimarKareer/UnifiedVideoDA
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Fri,  2 Feb 24</h3>
<dl>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00014" title="Abstract">arXiv:2402.00014</a> (cross-list from q-bio.BM) [<a href="/pdf/2402.00014" title="Download PDF">pdf</a>, <a href="/format/2402.00014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid quantum cycle generative adversarial network for small molecule  generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Anoshin%2C+M">Matvei Anoshin</a>, 
<a href="/search/q-bio?searchtype=author&query=Sagingalieva%2C+A">Asel Sagingalieva</a>, 
<a href="/search/q-bio?searchtype=author&query=Mansell%2C+C">Christopher Mansell</a>, 
<a href="/search/q-bio?searchtype=author&query=Shete%2C+V">Vishal Shete</a>, 
<a href="/search/q-bio?searchtype=author&query=Pflitsch%2C+M">Markus Pflitsch</a>, 
<a href="/search/q-bio?searchtype=author&query=Melnikov%2C+A">Alexey Melnikov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Emerging Technologies (cs.ET); Machine Learning (cs.LG); Biological Physics (physics.bio-ph); Quantum Physics (quant-ph)

</div>
<p class="mathjax">The contemporary drug design process demands considerable time and resources
to develop each new compound entering the market. Generating small molecules is
a pivotal aspect of drug discovery, essential for developing innovative
pharmaceuticals. Uniqueness, validity, diversity, druglikeliness,
synthesizability, and solubility molecular pharmacokinetic properties, however,
are yet to be maximized. This work introduces several new generative
adversarial network models based on engineering integration of parametrized
quantum circuits into known molecular generative adversarial networks. The
introduced machine learning models incorporate a new multi-parameter reward
function grounded in reinforcement learning principles. Through extensive
experimentation on benchmark drug design datasets, QM9 and PC9, the introduced
models are shown to outperform scores achieved previously. Most prominently,
the new scores indicate an increase of up to 30% in the druglikeness
quantitative estimation. The new hybrid quantum machine learning algorithms, as
well as the achieved scores of pharmacokinetic properties, contribute to the
development of fast and accurate drug discovery processes.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00019" title="Abstract">arXiv:2402.00019</a> (cross-list from eess.IV) [<a href="/pdf/2402.00019" title="Download PDF">pdf</a>, <a href="/ps/2402.00019" title="Download PostScript">ps</a>, <a href="/format/2402.00019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion MRI with Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Karimi%2C+D">Davood Karimi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion-weighted magnetic resonance imaging (dMRI) offers unique
capabilities such as noninvasive assessment of brain's micro-structure and
structural connectivity. However, analyzing the dMRI data to extract useful
information for clinical and scientific purposes is challenging. The dMRI
measurements often suffer from strong noise and artifacts, there is usually
high inter-session and inter-scanner heterogeneity in the data and considerable
inter-subject variability in brain structure, and the relationship between
measurements and the phenomena of interest can be highly complex. Recent years
have witnessed increasing use of machine learning methods for dMRI analysis.
This manuscript aims to assess these efforts, with a focus on methods that have
addressed micro-structure mapping, tractography, white matter tract analysis,
as well as data preprocessing and harmonization. We summarize the main
findings, strengths, and weaknesses of the existing methods and suggest topics
for future research. We find that machine learning may be exceptionally suited
to tackle some of the difficult tasks in dMRI analysis. However, for this to
happen, several shortcomings of existing methods and critical unresolved issues
need to be addressed. These include deficient evaluation practices, lack of
rich training datasets and validation benchmarks, as well as model
generalizability, reliability, and explainability concerns.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00024" title="Abstract">arXiv:2402.00024</a> (cross-list from q-bio.BM) [<a href="/pdf/2402.00024" title="Download PDF">pdf</a>, <a href="/format/2402.00024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Analysis of LLaMA and ChatGPT Embeddings for Molecule  Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Sadeghi%2C+S">Shaghayegh Sadeghi</a>, 
<a href="/search/q-bio?searchtype=author&query=Bui%2C+A">Alan Bui</a>, 
<a href="/search/q-bio?searchtype=author&query=Forooghi%2C+A">Ali Forooghi</a>, 
<a href="/search/q-bio?searchtype=author&query=Lu%2C+J">Jianguo Lu</a>, 
<a href="/search/q-bio?searchtype=author&query=Ngom%2C+A">Alioune Ngom</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Purpose: Large Language Models (LLMs) like ChatGPT and LLaMA are increasingly
recognized for their potential in the field of cheminformatics, particularly in
interpreting Simplified Molecular Input Line Entry System (SMILES), a standard
method for representing chemical structures. These LLMs can decode SMILES
strings into vector representations, providing a novel approach to
understanding chemical graphs.
<br />Methods: We investigate the performance of ChatGPT and LLaMA in embedding
SMILES strings. Our evaluation focuses on two key applications: molecular
property (MP) prediction and drug-drug interaction (DDI) prediction, both
essential in drug development and healthcare.
<br />Results: We find that SMILES embeddings generated using LLaMA outperform
those from ChatGPT in both MP and DDI prediction tasks. Notably, LLaMA-based
SMILES embeddings show results comparable to existing methods in both
prediction tasks.
<br />Conclusion: The application of LLMs in cheminformatics, particularly in
utilizing SMILES embeddings, shows significant promise for advancing drug
development. This includes improving the prediction of chemical properties and
facilitating the drug discovery process. GitHub:
https://github.com/sshaghayeghs/LLaMA-VS-ChatGPT
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00038" title="Abstract">arXiv:2402.00038</a> (cross-list from eess.IV) [<a href="/pdf/2402.00038" title="Download PDF">pdf</a>, <a href="/format/2402.00038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Brain Tumors through Multimodal Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Curci%2C+A">Antonio Curci</a>, 
<a href="/search/eess?searchtype=author&query=Esposito%2C+A">Andrea Esposito</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-print of a manuscript submitted to NeroPRAI 2024. This version did not undergo peer review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Tumors can manifest in various forms and in different areas of the human
body. Brain tumors are specifically hard to diagnose and treat because of the
complexity of the organ in which they develop. Detecting them in time can lower
the chances of death and facilitate the therapy process for patients. The use
of Artificial Intelligence (AI) and, more specifically, deep learning, has the
potential to significantly reduce costs in terms of time and resources for the
discovery and identification of tumors from images obtained through imaging
techniques. This research work aims to assess the performance of a multimodal
model for the classification of Magnetic Resonance Imaging (MRI) scans
processed as grayscale images. The results are promising, and in line with
similar works, as the model reaches an accuracy of around 98\%. We also
highlight the need for explainability and transparency to ensure human control
and safety.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00054" title="Abstract">arXiv:2402.00054</a> (cross-list from q-bio.GN) [<a href="/pdf/2402.00054" title="Download PDF">pdf</a>, <a href="/format/2402.00054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting loss-of-function impact of genetic mutations: a machine  learning approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Kaur%2C+A">Arshmeet Kaur</a>, 
<a href="/search/q-bio?searchtype=author&query=Sarmadi%2C+M">Morteza Sarmadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Index Terms: Machine Learning, Prediction Algorithms, Supervised Learning, Support vector machines, K-Nearest Neighbors, RANSAC, Decision Trees, Random Forest, Ge- netic mutations, LoFtool, Next Generation Sequencing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">The innovation of next-generation sequencing (NGS) techniques has
significantly reduced the price of genome sequencing, lowering barriers to
future medical research; it is now feasible to apply genome sequencing to
studies where it would have previously been cost-inefficient. Identifying
damaging or pathogenic mutations in vast amounts of complex, high-dimensional
genome sequencing data may be of particular interest to researchers. Thus, this
paper's aims were to train machine learning models on the attributes of a
genetic mutation to predict LoFtool scores (which measure a gene's intolerance
to loss-of-function mutations). These attributes included, but were not limited
to, the position of a mutation on a chromosome, changes in amino acids, and
changes in codons caused by the mutation. Models were built using the
univariate feature selection technique f-regression combined with K-nearest
neighbors (KNN), Support Vector Machine (SVM), Random Sample Consensus
(RANSAC), Decision Trees, Random Forest, and Extreme Gradient Boosting
(XGBoost). These models were evaluated using five-fold cross-validated averages
of r-squared, mean squared error, root mean squared error, mean absolute error,
and explained variance. The findings of this study include the training of
multiple models with testing set r-squared values of 0.97.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00067" title="Abstract">arXiv:2402.00067</a> (cross-list from eess.AS) [<a href="/pdf/2402.00067" title="Download PDF">pdf</a>, <a href="/format/2402.00067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online speaker diarization of meetings guided by speech separation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gruttadauria%2C+E">Elio Gruttadauria</a> (IP Paris, LTCI, IDS, S2A), 
<a href="/search/eess?searchtype=author&query=Fontaine%2C+M">Mathieu Fontaine</a> (LTCI, IP Paris), 
<a href="/search/eess?searchtype=author&query=Essid%2C+S">Slim Essid</a> (IDS, S2A, LTCI)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICASSP 2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE International Conference on Acoustics, Speech, and Signal
  Processing, Apr 2024, Seoul (Korea), South Korea
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">Overlapped speech is notoriously problematic for speaker diarization systems.
Consequently, the use of speech separation has recently been proposed to
improve their performance. Although promising, speech separation models
struggle with realistic data because they are trained on simulated mixtures
with a fixed number of speakers. In this work, we introduce a new speech
separation-guided diarization scheme suitable for the online speaker
diarization of long meeting recordings with a variable number of speakers, as
present in the AMI corpus. We envisage ConvTasNet and DPRNN as alternatives for
the separation networks, with two or three output sources. To obtain the
speaker diarization result, voice activity detection is applied on each
estimated source. The final model is fine-tuned end-to-end, after first
adapting the separation to real data using AMI. The system operates on short
segments, and inference is performed by stitching the local predictions using
speaker embeddings and incremental clustering. The results show that our system
improves the state-of-the-art on the AMI headset mix, using no oracle
information and under full evaluation (no collar and including overlapped
speech). Finally, we show the strength of our system particularly on overlapped
speech sections.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00077" title="Abstract">arXiv:2402.00077</a> (cross-list from q-bio.GN) [<a href="/pdf/2402.00077" title="Download PDF">pdf</a>, <a href="/format/2402.00077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlocking the Power of Multi-institutional Data: Integrating and  Harmonizing Genomic Data Across Institutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+Y">Yuan Chen</a>, 
<a href="/search/q-bio?searchtype=author&query=Shen%2C+R">Ronglai Shen</a>, 
<a href="/search/q-bio?searchtype=author&query=Feng%2C+X">Xiwen Feng</a>, 
<a href="/search/q-bio?searchtype=author&query=Panageas%2C+K">Katherine Panageas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Cancer is a complex disease driven by genomic alterations, and tumor
sequencing is becoming a mainstay of clinical care for cancer patients. The
emergence of multi-institution sequencing data presents a powerful resource for
learning real-world evidence to enhance precision oncology. GENIE BPC, led by
the American Association for Cancer Research, establishes a unique database
linking genomic data with clinical information for patients treated at multiple
cancer centers. However, leveraging such multi-institutional sequencing data
presents significant challenges. Variations in gene panels result in loss of
information when the analysis is conducted on common gene sets. Additionally,
differences in sequencing techniques and patient heterogeneity across
institutions add complexity. High data dimensionality, sparse gene mutation
patterns, and weak signals at the individual gene level further complicate
matters. Motivated by these real-world challenges, we introduce the Bridge
model. It uses a quantile-matched latent variable approach to derive integrated
features to preserve information beyond common genes and maximize the
utilization of all available data while leveraging information sharing to
enhance both learning efficiency and the model's capacity to generalize. By
extracting harmonized and noise-reduced lower-dimensional latent variables, the
true mutation pattern unique to each individual is captured. We assess the
model's performance and parameter estimation through extensive simulation
studies. The extracted latent features from the Bridge model consistently excel
in predicting patient survival across six cancer types in GENIE BPC data.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00082" title="Abstract">arXiv:2402.00082</a> (cross-list from quant-ph) [<a href="/pdf/2402.00082" title="Download PDF">pdf</a>, <a href="/ps/2402.00082" title="Download PostScript">ps</a>, <a href="/format/2402.00082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Grover&#x27;s Search Algorithm: A Modified Approach to Increase the  Probability of Good States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Abdulrahman%2C+I">Ismael Abdulrahman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Databases (cs.DB); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">This article introduces an enhancement to the Grover search algorithm to
increase the probability of finding good states in the early iterations of the
algorithm. It suggests incorporating a rotation gate around the (y+z)-axis,
with its phase determined mathematically from the derivative of the diffuser
output during the initial iteration. Furthermore, the phase angles are
optimized through adjustments based on the estimated increasing ratio of
amplitudes between consecutive iterations. The findings indicate a noteworthy
decrease, around 25%, in the required number of iterations to attain a high
probability of identifying target states resulting in a faster overall process.
This is observed across various scenarios, including instances with up to eight
qubits considering the computational capabilities of the computer used for
simulation.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00090" title="Abstract">arXiv:2402.00090</a> (cross-list from q-bio.NC) [<a href="/pdf/2402.00090" title="Download PDF">pdf</a>, <a href="/ps/2402.00090" title="Download PostScript">ps</a>, <a href="/format/2402.00090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification of attention performance post-longitudinal tDCS via  functional connectivity and machine learning methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Rao%2C+A+K">Akash K Rao</a>, 
<a href="/search/q-bio?searchtype=author&query=Menon%2C+V+K">Vishnu K Menon</a>, 
<a href="/search/q-bio?searchtype=author&query=Bhavsar%2C+A">Arnav Bhavsar</a>, 
<a href="/search/q-bio?searchtype=author&query=Chowdhury%2C+S+R">Shubhajit Roy Chowdhury</a>, 
<a href="/search/q-bio?searchtype=author&query=Negi%2C+R">Ramsingh Negi</a>, 
<a href="/search/q-bio?searchtype=author&query=Dutt%2C+V">Varun Dutt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, to be presented in the IEEE 9th International Conference for Convergence in Technology (I2CT),Pune, April 2024. arXiv admin note: substantial text overlap with <a href="/abs/2401.17700">arXiv:2401.17700</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Attention is the brain's mechanism for selectively processing specific
stimuli while filtering out irrelevant information. Characterizing changes in
attention following long-term interventions (such as transcranial direct
current stimulation (tDCS)) has seldom been emphasized in the literature. To
classify attention performance post-tDCS, this study uses functional
connectivity and machine learning algorithms. Fifty individuals were split into
experimental and control conditions. On Day 1, EEG data was obtained as
subjects executed an attention task. From Day 2 through Day 8, the experimental
group was administered 1mA tDCS, while the control group received sham tDCS. On
Day 10, subjects repeated the task mentioned on Day 1. Functional connectivity
metrics were used to classify attention performance using various machine
learning methods. Results revealed that combining the Adaboost model and
recursive feature elimination yielded a classification accuracy of 91.84%. We
discuss the implications of our results in developing neurofeedback frameworks
to assess attention.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00168" title="Abstract">arXiv:2402.00168</a> (cross-list from stat.ML) [<a href="/pdf/2402.00168" title="Download PDF">pdf</a>, <a href="/format/2402.00168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous Treatment Effects with Surrogate Outcomes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zeng%2C+Z">Zhenghao Zeng</a>, 
<a href="/search/stat?searchtype=author&query=Arbour%2C+D">David Arbour</a>, 
<a href="/search/stat?searchtype=author&query=Feller%2C+A">Avi Feller</a>, 
<a href="/search/stat?searchtype=author&query=Addanki%2C+R">Raghavendra Addanki</a>, 
<a href="/search/stat?searchtype=author&query=Rossi%2C+R">Ryan Rossi</a>, 
<a href="/search/stat?searchtype=author&query=Sinha%2C+R">Ritwik Sinha</a>, 
<a href="/search/stat?searchtype=author&query=Kennedy%2C+E+H">Edward H. Kennedy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">In many real-world causal inference applications, the primary outcomes
(labels) are often partially missing, especially if they are expensive or
difficult to collect. If the missingness depends on covariates (i.e.,
missingness is not completely at random), analyses based on fully-observed
samples alone may be biased. Incorporating surrogates, which are fully observed
post-treatment variables related to the primary outcome, can improve estimation
in this case. In this paper, we study the role of surrogates in estimating
continuous treatment effects and propose a doubly robust method to efficiently
incorporate surrogates in the analysis, which uses both labeled and unlabeled
data and does not suffer from the above selection bias problem. Importantly, we
establish asymptotic normality of the proposed estimator and show possible
improvements on the variance compared with methods that solely use labeled
data. Extensive simulations show our methods enjoy appealing empirical
performance.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00175" title="Abstract">arXiv:2402.00175</a> (cross-list from eess.IV) [<a href="/pdf/2402.00175" title="Download PDF">pdf</a>, <a href="/format/2402.00175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly-Supervised Detection of Bone Lesions in CT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sheng%2C+T">Tao Sheng</a>, 
<a href="/search/eess?searchtype=author&query=Mathai%2C+T+S">Tejas Sudharshan Mathai</a>, 
<a href="/search/eess?searchtype=author&query=Shieh%2C+A">Alexander Shieh</a>, 
<a href="/search/eess?searchtype=author&query=Summers%2C+R+M">Ronald M. Summers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at SPIE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The skeletal region is one of the common sites of metastatic spread of cancer
in the breast and prostate. CT is routinely used to measure the size of lesions
in the bones. However, they can be difficult to spot due to the wide variations
in their sizes, shapes, and appearances. Precise localization of such lesions
would enable reliable tracking of interval changes (growth, shrinkage, or
unchanged status). To that end, an automated technique to detect bone lesions
is highly desirable. In this pilot work, we developed a pipeline to detect bone
lesions (lytic, blastic, and mixed) in CT volumes via a proxy segmentation
task. First, we used the bone lesions that were prospectively marked by
radiologists in a few 2D slices of CT volumes and converted them into weak 3D
segmentation masks. Then, we trained a 3D full-resolution nnUNet model using
these weak 3D annotations to segment the lesions and thereby detected them. Our
automated method detected bone lesions in CT with a precision of 96.7% and
recall of 47.3% despite the use of incomplete and partial training data. To the
best of our knowledge, we are the first to attempt the direct detection of bone
lesions in CT via a proxy segmentation task.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00176" title="Abstract">arXiv:2402.00176</a> (cross-list from quant-ph) [<a href="/pdf/2402.00176" title="Download PDF">pdf</a>, <a href="/format/2402.00176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Quantum Machine Learning: An Information-Theoretic  Generalization Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Georgiou%2C+P">Petros Georgiou</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jose%2C+S+T">Sharu Theresa Jose</a>, 
<a href="/search/quant-ph?searchtype=author&query=Simeone%2C+O">Osvaldo Simeone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET); Machine Learning (cs.LG)

</div>
<p class="mathjax">In a manner analogous to their classical counterparts, quantum classifiers
are vulnerable to adversarial attacks that perturb their inputs. A promising
countermeasure is to train the quantum classifier by adopting an attack-aware,
or adversarial, loss function. This paper studies the generalization properties
of quantum classifiers that are adversarially trained against bounded-norm
white-box attacks. Specifically, a quantum adversary maximizes the classifier's
loss by transforming an input state $\rho(x)$ into a state $\lambda$ that is
$\epsilon$-close to the original state $\rho(x)$ in $p$-Schatten distance.
Under suitable assumptions on the quantum embedding $\rho(x)$, we derive novel
information-theoretic upper bounds on the generalization error of adversarially
trained quantum classifiers for $p = 1$ and $p = \infty$. The derived upper
bounds consist of two terms: the first is an exponential function of the
2-R\'enyi mutual information between classical data and quantum embedding,
while the second term scales linearly with the adversarial perturbation size
$\epsilon$. Both terms are shown to decrease as $1/\sqrt{T}$ over the training
set size $T$ . An extension is also considered in which the adversary assumed
during training has different parameters $p$ and $\epsilon$ as compared to the
adversary affecting the test inputs. Finally, we validate our theoretical
findings with numerical experiments for a synthetic setting.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00206" title="Abstract">arXiv:2402.00206</a> (cross-list from math.CT) [<a href="/pdf/2402.00206" title="Download PDF">pdf</a>, <a href="/ps/2402.00206" title="Download PostScript">ps</a>, <a href="/format/2402.00206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Unified Theory of Time-varying Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bumpus%2C+B+M">Benjamin Merlin Bumpus</a>, 
<a href="/search/math?searchtype=author&query=Fairbanks%2C+J">James Fairbanks</a>, 
<a href="/search/math?searchtype=author&query=Karvonen%2C+M">Martti Karvonen</a>, 
<a href="/search/math?searchtype=author&query=Leal%2C+W">Wilmer Leal</a>, 
<a href="/search/math?searchtype=author&query=Simard%2C+F">Fr&#xe9;d&#xe9;ric Simard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">What is a time-varying graph, or a time-varying topological space and more
generally what does it mean for a mathematical structure to vary over time?
Here we introduce categories of narratives: powerful tools for studying
temporal graphs and other time-varying data structures. Narratives are sheaves
on posets of intervals of time which specify snapshots of a temporal object as
well as relationships between snapshots over the course of any given interval
of time. This approach offers two significant advantages. First, when
restricted to the base category of graphs, the theory is consistent with the
well-established theory of temporal graphs, enabling the reproduction of
results in this field. Second, the theory is general enough to extend results
to a wide range of categories used in data analysis, such as groups,
topological spaces, databases, Petri nets, simplicial complexes and many more.
The approach overcomes the challenge of relating narratives of different types
to each other and preserves the structure over time in a compositional sense.
Furthermore our approach allows for the systematic relation of different kinds
of narratives. In summary, this theory provides a consistent and general
framework for analyzing dynamic systems, offering an essential tool for
mathematicians and data scientists alike.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00222" title="Abstract">arXiv:2402.00222</a> (cross-list from physics.soc-ph) [<a href="/pdf/2402.00222" title="Download PDF">pdf</a>, <a href="/format/2402.00222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncover the nature of overlapping community in cities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Luo%2C+P">Peng Luo</a>, 
<a href="/search/physics?searchtype=author&query=Zhu%2C+D">Di Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Urban spaces, though often perceived as discrete communities, are shared by
various functional and social groups. Our study introduces a graph-based
physics-aware deep learning framework, illuminating the intricate overlapping
nature inherent in urban communities. Through analysis of individual mobile
phone positioning data at Twin Cities metro area (TCMA) in Minnesota, USA, our
findings reveal that 95.7 % of urban functional complexity stems from the
overlapping structure of communities during weekdays. Significantly, our
research not only quantifies these overlaps but also reveals their compelling
correlations with income and racial indicators, unraveling the complex
segregation patterns in U.S. cities. As the first to elucidate the overlapping
nature of urban communities, this work offers a unique geospatial perspective
on looking at urban structures, highlighting the nuanced interplay of
socioeconomic dynamics within cities.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00231" title="Abstract">arXiv:2402.00231</a> (cross-list from math.GT) [<a href="/pdf/2402.00231" title="Download PDF">pdf</a>, <a href="/format/2402.00231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uniformly polynomial-time classification of surface homeomorphisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Baroni%2C+F">Filippo Baroni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 47 pages, 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geometric Topology (math.GT)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">We describe an algorithm which, given two essential curves on a surface $S$,
computes their distance in the curve graph of $S$, up to multiplicative and
additive errors. As an application, we present an algorithm to decide the
Nielsen-Thurston type (periodic, reducible, or pseudo-Anosov) of a mapping
class of $S$. The novelty of our algorithms lies in the fact that their running
time is polynomial in the size of the input and in the complexity of $S$ --
say, its Euler characteristic. This is in contrast with previously known
algorithms, which run in polynomial time in the size of the input for any fixed
surface $S$.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00242" title="Abstract">arXiv:2402.00242</a> (cross-list from quant-ph) [<a href="/pdf/2402.00242" title="Download PDF">pdf</a>, <a href="/format/2402.00242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Advantage in Non-Interactive Source Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Salehi%2C+H+A">Hojat Allah Salehi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shirani%2C+F">Farhad Shirani</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pradhan%2C+S+S">S. Sandeep Pradhan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">This work considers the non-interactive source simulation problem (NISS). In
the standard NISS scenario, a pair of distributed agents, Alice and Bob,
observe a distributed binary memoryless source $(X^d,Y^d)$ generated based on
joint distribution $P_{X,Y}$. The agents wish to produce a pair of discrete
random variables $(U_d,V_d)$ with joint distribution $P_{U_d,V_d}$, such that
$P_{U_d,V_d}$ converges in total variation distance to a target distribution
$Q_{U,V}$. Two variations of the standard NISS scenario are considered. In the
first variation, in addition to $(X^d,Y^d)$ the agents have access to a shared
Bell state. The agents each measure their respective state, using a measurement
of their choice, and use its classical output along with $(X^d,Y^d)$ to
simulate the target distribution. This scenario is called the
entanglement-assisted NISS (EA-NISS). In the second variation, the agents have
access to a classical common random bit $Z$, in addition to $(X^d,Y^d)$. This
scenario is called the classical common randomness NISS (CR-NISS). It is shown
that for binary-output NISS scenarios, the set of feasible distributions for
EA-NISS and CR-NISS are equal with each other. Hence, there is not quantum
advantage in these EA-NISS scenarios. For non-binary output NISS scenarios, it
is shown through an example that there are distributions that are feasible in
EA-NISS but not in CR-NISS. This shows that there is a quantum advantage in
non-binary output EA-NISS.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00282" title="Abstract">arXiv:2402.00282</a> (cross-list from eess.AS) [<a href="/pdf/2402.00282" title="Download PDF">pdf</a>, <a href="/format/2402.00282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PAM: Prompting Audio-Language Models for Audio Quality Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Deshmukh%2C+S">Soham Deshmukh</a>, 
<a href="/search/eess?searchtype=author&query=Alharthi%2C+D">Dareen Alharthi</a>, 
<a href="/search/eess?searchtype=author&query=Elizalde%2C+B">Benjamin Elizalde</a>, 
<a href="/search/eess?searchtype=author&query=Gamper%2C+H">Hannes Gamper</a>, 
<a href="/search/eess?searchtype=author&query=Ismail%2C+M+A">Mahmoud Al Ismail</a>, 
<a href="/search/eess?searchtype=author&query=Singh%2C+R">Rita Singh</a>, 
<a href="/search/eess?searchtype=author&query=Raj%2C+B">Bhiksha Raj</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Huaming Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">While audio quality is a key performance metric for various audio processing
tasks, including generative modeling, its objective measurement remains a
challenge. Audio-Language Models (ALMs) are pre-trained on audio-text pairs
that may contain information about audio quality, the presence of artifacts, or
noise. Given an audio input and a text prompt related to quality, an ALM can be
used to calculate a similarity score between the two. Here, we exploit this
capability and introduce PAM, a no-reference metric for assessing audio quality
for different audio processing tasks. Contrary to other "reference-free"
metrics, PAM does not require computing embeddings on a reference dataset nor
training a task-specific model on a costly set of human listening scores. We
extensively evaluate the reliability of PAM against established metrics and
human listening scores on four tasks: text-to-audio (TTA), text-to-music
generation (TTM), text-to-speech (TTS), and deep noise suppression (DNS). We
perform multiple ablation studies with controlled distortions, in-the-wild
setups, and prompt choices. Our evaluation shows that PAM correlates well with
existing metrics and human listening scores. These results demonstrate the
potential of ALMs for computing a general-purpose audio quality metric.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00288" title="Abstract">arXiv:2402.00288</a> (cross-list from eess.AS) [<a href="/pdf/2402.00288" title="Download PDF">pdf</a>, <a href="/format/2402.00288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frame-Wise Breath Detection with Self-Training: An Exploration of  Enhancing Breath Naturalness in Text-to-Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+D">Dong Yang</a>, 
<a href="/search/eess?searchtype=author&query=Koriyama%2C+T">Tomoki Koriyama</a>, 
<a href="/search/eess?searchtype=author&query=Saito%2C+Y">Yuki Saito</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Developing Text-to-Speech (TTS) systems that can synthesize natural breath is
essential for human-like voice agents but requires extensive manual annotation
of breath positions in training data. To this end, we propose a self-training
method for training a breath detection model that can automatically detect
breath positions in speech. Our method trains the model using a large speech
corpus and involves: 1) annotation of limited breath sounds utilizing a
rule-based approach, and 2) iterative augmentation of these annotations through
pseudo-labeling based on the model's predictions. Our detection model employs
Conformer blocks with down-/up-sampling layers, enabling accurate frame-wise
breath detection. We investigate its effectiveness in multi-speaker TTS using
text transcripts with detected breath marks. The results indicate that using
our proposed model for breath detection and breath mark insertion synthesizes
breath-contained speech more naturally than a baseline model.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00298" title="Abstract">arXiv:2402.00298</a> (cross-list from quant-ph) [<a href="/pdf/2402.00298" title="Download PDF">pdf</a>, <a href="/format/2402.00298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Oracle separation of QMA and QCMA with bounded adaptivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ben-David%2C+S">Shalev Ben-David</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kundu%2C+S">Srijita Kundu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">We give an oracle separation between QMA and QCMA for quantum algorithms that
have bounded adaptivity in their oracle queries; that is, the number of rounds
of oracle calls is small, though each round may involve polynomially many
queries in parallel. Our oracle construction is a simplified version of the
construction used recently by Li, Liu, Pelecanos, and Yamakawa (2023), who
showed an oracle separation between QMA and QCMA when the quantum algorithms
are only allowed to access the oracle classically. To prove our results, we
introduce a property of relations called \emph{slipperiness}, which may be
useful for getting a fully general classical oracle separation between QMA and
QCMA.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00299" title="Abstract">arXiv:2402.00299</a> (cross-list from q-fin.GN) [<a href="/pdf/2402.00299" title="Download PDF">pdf</a>, <a href="/format/2402.00299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-based Dynamic Multilayer Graph Neural Networks for Loan  Default Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Zandi%2C+S">Sahab Zandi</a>, 
<a href="/search/q-fin?searchtype=author&query=Korangi%2C+K">Kamesh Korangi</a>, 
<a href="/search/q-fin?searchtype=author&query=%C3%93skarsd%C3%B3ttir%2C+M">Mar&#xed;a &#xd3;skarsd&#xf3;ttir</a>, 
<a href="/search/q-fin?searchtype=author&query=Mues%2C+C">Christophe Mues</a>, 
<a href="/search/q-fin?searchtype=author&query=Bravo%2C+C">Cristi&#xe1;n Bravo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Finance (q-fin.GN)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Whereas traditional credit scoring tends to employ only individual borrower-
or loan-level predictors, it has been acknowledged for some time that
connections between borrowers may result in default risk propagating over a
network. In this paper, we present a model for credit risk assessment
leveraging a dynamic multilayer network built from a Graph Neural Network and a
Recurrent Neural Network, each layer reflecting a different source of network
connection. We test our methodology in a behavioural credit scoring context
using a dataset provided by U.S. mortgage financier Freddie Mac, in which
different types of connections arise from the geographical location of the
borrower and their choice of mortgage provider. The proposed model considers
both types of connections and the evolution of these connections over time. We
enhance the model by using a custom attention mechanism that weights the
different time snapshots according to their importance. After testing multiple
configurations, a model with GAT, LSTM, and the attention mechanism provides
the best results. Empirical results demonstrate that, when it comes to
predicting probability of default for the borrowers, our proposed model brings
both better results and novel insights for the analysis of the importance of
connections and timestamps, compared to traditional methods.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00305" title="Abstract">arXiv:2402.00305</a> (cross-list from math.ST) [<a href="/pdf/2402.00305" title="Download PDF">pdf</a>, <a href="/ps/2402.00305" title="Download PostScript">ps</a>, <a href="/format/2402.00305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information-Theoretic Thresholds for Planted Dense Cycles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mao%2C+C">Cheng Mao</a>, 
<a href="/search/math?searchtype=author&query=Wein%2C+A+S">Alexander S. Wein</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+S">Shenduo Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Information Theory (cs.IT); Social and Information Networks (cs.SI); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study a random graph model for small-world networks which are ubiquitous
in social and biological sciences. In this model, a dense cycle of expected
bandwidth $n \tau$, representing the hidden one-dimensional geometry of
vertices, is planted in an ambient random graph on $n$ vertices. For both
detection and recovery of the planted dense cycle, we characterize the
information-theoretic thresholds in terms of $n$, $\tau$, and an edge-wise
signal-to-noise ratio $\lambda$. In particular, the information-theoretic
thresholds differ from the computational thresholds established in a recent
work for low-degree polynomial algorithms, thereby justifying the existence of
statistical-to-computational gaps for this problem.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00310" title="Abstract">arXiv:2402.00310</a> (cross-list from physics.geo-ph) [<a href="/pdf/2402.00310" title="Download PDF">pdf</a>, <a href="/format/2402.00310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seismic Traveltime Tomography with Label-free Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Wang%2C+F">Feng Wang</a>, 
<a href="/search/physics?searchtype=author&query=Yang%2C+B">Bo Yang</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+R">Renfang Wang</a>, 
<a href="/search/physics?searchtype=author&query=Qiu%2C+H">Hong Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 19 figures. Submitted to IEEE Transactions on Geoscience and Remote Sensing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning techniques have been used to build velocity models (VMs) for
seismic traveltime tomography and have shown encouraging performance in recent
years. However, they need to generate labeled samples (i.e., pairs of input and
label) to train the deep neural network (NN) with end-to-end learning, and the
real labels for field data inversion are usually missing or very expensive.
Some traditional tomographic methods can be implemented quickly, but their
effectiveness is often limited by prior assumptions. To avoid generating
labeled samples, we propose a novel method by integrating deep learning and
dictionary learning to enhance the VMs with low resolution by using the
traditional tomography-least square method (LSQR). We first design a type of
shallow and simple NN to reduce computational cost followed by proposing a
two-step strategy to enhance the VMs with low resolution: (1) Warming up. An
initial dictionary is trained from the estimation by LSQR through dictionary
learning method; (2) Dictionary optimization. The initial dictionary obtained
in the warming-up step will be optimized by the NN, and then it will be used to
reconstruct high-resolution VMs with the reference slowness and the estimation
by LSQR. Furthermore, we design a loss function to minimize traveltime misfit
to ensure that NN training is label-free, and the optimized dictionary can be
obtained after each epoch of NN training. We demonstrate the effectiveness of
the proposed method through numerical tests.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00312" title="Abstract">arXiv:2402.00312</a> (cross-list from q-bio.OT) [<a href="/pdf/2402.00312" title="Download PDF">pdf</a>, <a href="/ps/2402.00312" title="Download PostScript">ps</a>, <a href="/format/2402.00312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The whack-a-mole governance challenge for AI-enabled synthetic biology:  literature review and emerging frameworks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Undheim%2C+T+A">Trond Arne Undheim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Other Quantitative Biology (q-bio.OT)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">AI-enabled synthetic biology has tremendous potential but also significantly
increases biorisks and brings about a new set of dual use concerns. The picture
is complicated given the vast innovations envisioned to emerge by combining
emerging technologies, as AI-enabled synthetic biology potentially scales up
bioengineering into industrial biomanufacturing. However, the literature review
indicates that goals such as maintaining a reasonable scope for innovation, or
more ambitiously to foster a huge bioeconomy don't necessarily contrast with
biosafety, but need to go hand in hand. This paper presents a literature review
of the issues and describes emerging frameworks for policy and practice that
transverse the options of command-and control, stewardship, bottom-up, and
laissez-faire governance. How to achieve early warning systems that enable
prevention and mitigation of future AI-enabled biohazards from the lab, from
deliberate misuse, or from the public realm, will constantly need to evolve,
and adaptive, interactive approaches should emerge. Although biorisk is subject
to an established governance regime, and scientists generally adhere to
biosafety protocols, even experimental, but legitimate use by scientists could
lead to unexpected developments. Recent advances in chatbots enabled by
generative AI have revived fears that advanced biological insight can more
easily get into the hands of malignant individuals or organizations. Given
these sets of issues, society needs to rethink how AI-enabled synthetic biology
should be governed. The suggested way to visualize the challenge at hand is
whack-a-mole governance, although the emerging solutions are perhaps not so
different either.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00331" title="Abstract">arXiv:2402.00331</a> (cross-list from math.CT) [<a href="/pdf/2402.00331" title="Download PDF">pdf</a>, <a href="/ps/2402.00331" title="Download PostScript">ps</a>, <a href="/format/2402.00331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smooth and Proper Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Anel%2C+M">Mathieu Anel</a>, 
<a href="/search/math?searchtype=author&query=Weinberger%2C+J">Jonathan Weinberger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Dedicated to Andr\'e Joyal to his 80th birthday; 13 pages, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Logic in Computer Science (cs.LO); Algebraic Geometry (math.AG); Logic (math.LO)

</div>
<p class="mathjax">This is an expository note explaining how the geometric notions of local
connectedness and properness are related to the $\Sigma$-type and $\Pi$-type
constructors of dependent type theory.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00362" title="Abstract">arXiv:2402.00362</a> (cross-list from physics.ao-ph) [<a href="/pdf/2402.00362" title="Download PDF">pdf</a>, <a href="/ps/2402.00362" title="Download PostScript">ps</a>, <a href="/format/2402.00362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Climate Trends of Tropical Cyclone Intensity and Energy Extremes  Revealed by Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Chen%2C+B">Buo-Fu Chen</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+B">Boyo Chen</a>, 
<a href="/search/physics?searchtype=author&query=Hsiao%2C+C">Chun-Min Hsiao</a>, 
<a href="/search/physics?searchtype=author&query=Teng%2C+H">Hsu-Feng Teng</a>, 
<a href="/search/physics?searchtype=author&query=Lee%2C+C">Cheng-Shang Lee</a>, 
<a href="/search/physics?searchtype=author&query=Kuo%2C+H">Hung-Chi Kuo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Anthropogenic influences have been linked to tropical cyclone (TC) poleward
migration, TC extreme precipitation, and an increased proportion of major
hurricanes [1, 2, 3, 4]. Understanding past TC trends and variability is
critical for projecting future TC impacts on human society considering the
changing climate [5]. However, past trends of TC structure/energy remain
uncertain due to limited observations; subjective-analyzed and
spatiotemporal-heterogeneous "best-track" datasets lead to reduced confidence
in the assessed TC repose to climate change [6, 7]. Here, we use deep learning
to reconstruct past "observations" and yield an objective global TC wind
profile dataset during 1981 to 2020, facilitating a comprehensive examination
of TC structure/energy. By training with uniquely labeled data integrating best
tracks and numerical model analysis of 2004 to 2018 TCs, our model converts
multichannel satellite imagery to a 0-750-km wind profile of axisymmetric
surface winds. The model performance is verified to be sufficient for climate
studies by comparing it to independent satellite-radar surface winds. Based on
the new homogenized dataset, the major TC proportion has increased by ~13% in
the past four decades. Moreover, the proportion of extremely high-energy TCs
has increased by ~25%, along with an increasing trend (&gt; one standard deviation
of the 40-y variability) of the mean total energy of high-energy TCs. Although
the warming ocean favors TC intensification, the TC track migration to higher
latitudes and altered environments further affect TC structure/energy. This new
deep learning method/dataset reveals novel trends regarding TC structure
extremes and may help verify simulations/studies regarding TCs in the changing
climate.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00375" title="Abstract">arXiv:2402.00375</a> (cross-list from eess.IV) [<a href="/pdf/2402.00375" title="Download PDF">pdf</a>, <a href="/format/2402.00375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangled Multimodal Brain MR Image Translation via Transformer-based  Modality Infuser
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cho%2C+J">Jihoon Cho</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+X">Xiaofeng Liu</a>, 
<a href="/search/eess?searchtype=author&query=Xing%2C+F">Fangxu Xing</a>, 
<a href="/search/eess?searchtype=author&query=Ouyang%2C+J">Jinsong Ouyang</a>, 
<a href="/search/eess?searchtype=author&query=Fakhri%2C+G+E">Georges El Fakhri</a>, 
<a href="/search/eess?searchtype=author&query=Park%2C+J">Jinah Park</a>, 
<a href="/search/eess?searchtype=author&query=Woo%2C+J">Jonghye Woo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Multimodal Magnetic Resonance (MR) Imaging plays a crucial role in disease
diagnosis due to its ability to provide complementary information by analyzing
a relationship between multimodal images on the same subject. Acquiring all MR
modalities, however, can be expensive, and, during a scanning session, certain
MR images may be missed depending on the study protocol. The typical solution
would be to synthesize the missing modalities from the acquired images such as
using generative adversarial networks (GANs). Yet, GANs constructed with
convolutional neural networks (CNNs) are likely to suffer from a lack of global
relationships and mechanisms to condition the desired modality. To address
this, in this work, we propose a transformer-based modality infuser designed to
synthesize multimodal brain MR images. In our method, we extract
modality-agnostic features from the encoder and then transform them into
modality-specific features using the modality infuser. Furthermore, the
modality infuser captures long-range relationships among all brain structures,
leading to the generation of more realistic images. We carried out experiments
on the BraTS 2018 dataset, translating between four MR modalities, and our
experimental results demonstrate the superiority of our proposed method in
terms of synthesis quality. In addition, we conducted experiments on a brain
tumor segmentation task and different conditioning methods.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00376" title="Abstract">arXiv:2402.00376</a> (cross-list from eess.IV) [<a href="/pdf/2402.00376" title="Download PDF">pdf</a>, <a href="/ps/2402.00376" title="Download PostScript">ps</a>, <a href="/format/2402.00376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image2Points:A 3D Point-based Context Clusters GAN for High-Quality PET  Image Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cui%2C+J">Jiaqi Cui</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wen%2C+L">Lu Wen</a>, 
<a href="/search/eess?searchtype=author&query=Zeng%2C+P">Pinxian Zeng</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+X">Xi Wu</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+J">Jiliu Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+D">Dinggang Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">To obtain high-quality Positron emission tomography (PET) images while
minimizing radiation exposure, numerous methods have been proposed to
reconstruct standard-dose PET (SPET) images from the corresponding low-dose PET
(LPET) images. However, these methods heavily rely on voxel-based
representations, which fall short of adequately accounting for the precise
structure and fine-grained context, leading to compromised reconstruction. In
this paper, we propose a 3D point-based context clusters GAN, namely PCC-GAN,
to reconstruct high-quality SPET images from LPET. Specifically, inspired by
the geometric representation power of points, we resort to a point-based
representation to enhance the explicit expression of the image structure, thus
facilitating the reconstruction with finer details. Moreover, a context
clustering strategy is applied to explore the contextual relationships among
points, which mitigates the ambiguities of small structures in the
reconstructed images. Experiments on both clinical and phantom datasets
demonstrate that our PCC-GAN outperforms the state-of-the-art reconstruction
methods qualitatively and quantitatively. Code is available at
https://github.com/gluucose/PCCGAN.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00389" title="Abstract">arXiv:2402.00389</a> (cross-list from math.OC) [<a href="/pdf/2402.00389" title="Download PDF">pdf</a>, <a href="/ps/2402.00389" title="Download PostScript">ps</a>, <a href="/format/2402.00389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the $O(\frac{\sqrt{d}}{T^{1/4}})$ Convergence Rate of RMSProp and Its  Momentum Extension Measured by $\ell_1$ Norm: Better Dependence on the  Dimension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+H">Huan Li</a>, 
<a href="/search/math?searchtype=author&query=Lin%2C+Z">Zhouchen Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Although adaptive gradient methods have been extensively used in deep
learning, their convergence rates have not been thoroughly studied,
particularly with respect to their dependence on the dimension. This paper
considers the classical RMSProp and its momentum extension and establishes the
convergence rate of $\frac{1}{T}\sum_{k=1}^TE\left[\|\nabla
f(x^k)\|_1\right]\leq O(\frac{\sqrt{d}}{T^{1/4}})$ measured by $\ell_1$ norm
without the bounded gradient assumption, where $d$ is the dimension of the
optimization variable and $T$ is the iteration number. Since
$\|x\|_2\ll\|x\|_1\leq\sqrt{d}\|x\|_2$ for problems with extremely large $d$,
our convergence rate can be considered to be analogous to the
$\frac{1}{T}\sum_{k=1}^TE\left[\|\nabla f(x^k)\|_2\right]\leq
O(\frac{1}{T^{1/4}})$ one of SGD measured by $\ell_1$ norm.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00394" title="Abstract">arXiv:2402.00394</a> (cross-list from econ.TH) [<a href="/pdf/2402.00394" title="Download PDF">pdf</a>, <a href="/ps/2402.00394" title="Download PostScript">ps</a>, <a href="/format/2402.00394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random partitions, potential of the Shapley value, and games with  externalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Casajus%2C+A">Andr&#xe9; Casajus</a>, 
<a href="/search/econ?searchtype=author&query=Funaki%2C+Y">Yukihiko Funaki</a>, 
<a href="/search/econ?searchtype=author&query=Huettner%2C+F">Frank Huettner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT); Combinatorics (math.CO)

</div>
<p class="mathjax">The Shapley value equals a player's contribution to the potential of a game.
The potential is a most natural one-number summary of a game, which can be
computed as the expected accumulated worth of a random partition of the
players. This computation integrates the coalition formation of all players and
readily extends to games with externalities. We investigate those potential
functions for games with externalities that can be computed this way. It turns
out that the potential that corresponds to the MPW solution introduced by
Macho-Stadler et al. (2007, J. Econ. Theory 135, 339-356), is unique in the
following sense. It is obtained as a the expected accumulated worth of a random
partition, it generalizes the potential for games without externalities, and it
induces a solution that satisfies the null player property even in the presence
of externalities.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00406" title="Abstract">arXiv:2402.00406</a> (cross-list from math.AP) [<a href="/pdf/2402.00406" title="Download PDF">pdf</a>, <a href="/format/2402.00406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A rigorous integrator and global existence for higher-dimensional  semilinear parabolic PDEs via semigroup theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Duchesne%2C+G+W">Gabriel William Duchesne</a>, 
<a href="/search/math?searchtype=author&query=Lessard%2C+J">Jean-Philippe Lessard</a>, 
<a href="/search/math?searchtype=author&query=Takayasu%2C+A">Akitoshi Takayasu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Dynamical Systems (math.DS); Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this paper, we introduce a general constructive method to compute
solutions of initial value problems of semilinear parabolic partial
differential equations via semigroup theory and computer-assisted proofs. Once
a numerical candidate for the solution is obtained via a finite dimensional
projection, Chebyshev series expansions are used to solve the linearized
equations about the approximation from which a solution map operator is
constructed. Using the solution operator (which exists from semigroup theory),
we define an infinite dimensional contraction operator whose unique fixed point
together with its rigorous bounds provide the local inclusion of the solution.
Applying this technique for multiple time steps leads to constructive proofs of
existence of solutions over long time intervals. As applications, we study the
3D/2D Swift-Hohenberg, where we combine our method with explicit constructions
of trapping regions to prove global existence of solutions of initial value
problems converging asymptotically to nontrivial equilibria. A second
application consists of the 2D Ohta-Kawasaki equation, providing a framework
for handling derivatives in nonlinear terms.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00415" title="Abstract">arXiv:2402.00415</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2402.00415" title="Download PDF">pdf</a>, <a href="/format/2402.00415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A two-phase Volume of Fluid approach to model rigid-perfectly plastic  granular materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=D%C3%BCsterh%C3%B6ft-Wriggers%2C+W">Wibke D&#xfc;sterh&#xf6;ft-Wriggers</a>, 
<a href="/search/physics?searchtype=author&query=Schubert%2C+S">Svenja Schubert</a>, 
<a href="/search/physics?searchtype=author&query=Rung%2C+T">Thomas Rung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Discrete Mathematics (cs.DM); Geophysics (physics.geo-ph)

</div>
<p class="mathjax">Granular flow problems characterized by large deformations are widespread in
various applications, including coastal and geotechnical engineering. The paper
deals with the application of a rigid-perfectly plastic two-phase model
extended by the Drucker-Prager yield criterion to simulate granular media with
a finite volume flow solver (FV). The model refers to the combination of a
Bingham fluid and an Eulerian strain measure to assess the failure region of
granular dam slides. A monolithic volume-of-fluid (VoF) method is used to
distinguish between the air and granular phases, both governed by the
incompressible Navier-Stokes equations. The numerical framework enables
modeling of large displacements and arbitrary shapes for large-scale
applications. The displayed validation and verification focuses on the
rigid-perfectly plastic material model for non-cohesive and cohesive materials
with varying angles of repose. Results indicate a good agreement of the
predicted soil surface and strain results with experimental and numerical data.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00417" title="Abstract">arXiv:2402.00417</a> (cross-list from math.GR) [<a href="/pdf/2402.00417" title="Download PDF">pdf</a>, <a href="/ps/2402.00417" title="Download PostScript">ps</a>, <a href="/format/2402.00417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Presentation of monoids generated by a projection and an involution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Caron%2C+P">Pascal Caron</a>, 
<a href="/search/math?searchtype=author&query=Luque%2C+J">Jean-Gabriel Luque</a>, 
<a href="/search/math?searchtype=author&query=Patrou%2C+B">Bruno Patrou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Group Theory (math.GR)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">Monoids generated by elements of order two appear in numerous places in the
literature. For example, Coxeter reflection groups in geometry, Kuratowski
monoids in topology, various monoids generated by regular operations in
language theory and so on. In order to initiate a classification of these
monoids, we are interested in the subproblem of monoids, called strict 2-PIMs,
generated by an involution and an idempotent. In this case we show, when the
monoid is finite, that it is generated by a single equation (in addition to the
two defining the involution and the idempotent). We then describe the exact
possible forms of this equation and classify them. We recover Kuratowski's
theorem as a special case of our study.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00501" title="Abstract">arXiv:2402.00501</a> (cross-list from stat.ML) [<a href="/pdf/2402.00501" title="Download PDF">pdf</a>, <a href="/ps/2402.00501" title="Download PostScript">ps</a>, <a href="/format/2402.00501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equivalence of the Empirical Risk Minimization to Regularization on the  Family of f-Divergences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Daunas%2C+F">Francisco Daunas</a>, 
<a href="/search/stat?searchtype=author&query=Esnaola%2C+I">I&#xf1;aki Esnaola</a>, 
<a href="/search/stat?searchtype=author&query=Perlaza%2C+S+M">Samir M. Perlaza</a>, 
<a href="/search/stat?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the IEEE Symposium in Information Theory 2024. arXiv admin note: text overlap with <a href="/abs/2306.07123">arXiv:2306.07123</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">The solution to empirical risk minimization with $f$-divergence
regularization (ERM-$f$DR) is presented under mild conditions on $f$. Under
such conditions, the optimal measure is shown to be unique. Examples of the
solution for particular choices of the function $f$ are presented. Previously
known solutions to common regularization choices are obtained by leveraging the
flexibility of the family of $f$-divergences. These include the unique
solutions to empirical risk minimization with relative entropy regularization
(Type-I and Type-II). The analysis of the solution unveils the following
properties of $f$-divergences when used in the ERM-$f$DR problem: $i\bigl)$
$f$-divergence regularization forces the support of the solution to coincide
with the support of the reference measure, which introduces a strong inductive
bias that dominates the evidence provided by the training data; and $ii\bigl)$
any $f$-divergence regularization is equivalent to a different $f$-divergence
regularization with an appropriate transformation of the empirical risk
function.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00515" title="Abstract">arXiv:2402.00515</a> (cross-list from q-fin.PM) [<a href="/pdf/2402.00515" title="Download PDF">pdf</a>, <a href="/format/2402.00515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developing A Multi-Agent and Self-Adaptive Framework with Deep  Reinforcement Learning for Dynamic Portfolio Risk Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Li%2C+Z">Zhenglong Li</a>, 
<a href="/search/q-fin?searchtype=author&query=Tam%2C+V">Vincent Tam</a>, 
<a href="/search/q-fin?searchtype=author&query=Yeung%2C+K+L">Kwan L. Yeung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by The 23rd International Conference on Autonomous Agents and Multi-Agent Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Portfolio Management (q-fin.PM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep or reinforcement learning (RL) approaches have been adapted as reactive
agents to quickly learn and respond with new investment strategies for
portfolio management under the highly turbulent financial market environments
in recent years. In many cases, due to the very complex correlations among
various financial sectors, and the fluctuating trends in different financial
markets, a deep or reinforcement learning based agent can be biased in
maximising the total returns of the newly formulated investment portfolio while
neglecting its potential risks under the turmoil of various market conditions
in the global or regional sectors. Accordingly, a multi-agent and self-adaptive
framework namely the MASA is proposed in which a sophisticated multi-agent
reinforcement learning (RL) approach is adopted through two cooperating and
reactive agents to carefully and dynamically balance the trade-off between the
overall portfolio returns and their potential risks. Besides, a very flexible
and proactive agent as the market observer is integrated into the MASA
framework to provide some additional information on the estimated market trends
as valuable feedbacks for multi-agent RL approach to quickly adapt to the
ever-changing market conditions. The obtained empirical results clearly reveal
the potential strengths of our proposed MASA framework based on the multi-agent
RL approach against many well-known RL-based approaches on the challenging data
sets of the CSI 300, Dow Jones Industrial Average and S&amp;P 500 indexes over the
past 10 years. More importantly, our proposed MASA framework shed lights on
many possible directions for future investigation.
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00544" title="Abstract">arXiv:2402.00544</a> (cross-list from stat.CO) [<a href="/pdf/2402.00544" title="Download PDF">pdf</a>, <a href="/format/2402.00544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum-Assisted Hilbert-Space Gaussian Process Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Farooq%2C+A">Ahmad Farooq</a>, 
<a href="/search/stat?searchtype=author&query=Galvis-Florez%2C+C+A">Cristian A. Galvis-Florez</a>, 
<a href="/search/stat?searchtype=author&query=S%C3%A4rkk%C3%A4%2C+S">Simo S&#xe4;rkk&#xe4;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation (stat.CO)</span>; Machine Learning (cs.LG); Quantum Physics (quant-ph)

</div>
<p class="mathjax">Gaussian processes are probabilistic models that are commonly used as
functional priors in machine learning. Due to their probabilistic nature, they
can be used to capture the prior information on the statistics of noise,
smoothness of the functions, and training data uncertainty. However, their
computational complexity quickly becomes intractable as the size of the data
set grows. We propose a Hilbert space approximation-based quantum algorithm for
Gaussian process regression to overcome this limitation. Our method consists of
a combination of classical basis function expansion with quantum computing
techniques of quantum principal component analysis, conditional rotations, and
Hadamard and Swap tests. The quantum principal component analysis is used to
estimate the eigenvalues while the conditional rotations and the Hadamard and
Swap tests are employed to evaluate the posterior mean and variance of the
Gaussian process. Our method provides polynomial computational complexity
reduction over the classical method.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00570" title="Abstract">arXiv:2402.00570</a> (cross-list from eess.IV) [<a href="/pdf/2402.00570" title="Download PDF">pdf</a>, <a href="/format/2402.00570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CADICA: a new dataset for coronary artery disease detection by using  invasive coronary angiography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jim%C3%A9nez-Partinen%2C+A">Ariadna Jim&#xe9;nez-Partinen</a>, 
<a href="/search/eess?searchtype=author&query=Molina-Cabello%2C+M+A">Miguel A. Molina-Cabello</a>, 
<a href="/search/eess?searchtype=author&query=Thurnhofer-Hemsi%2C+K">Karl Thurnhofer-Hemsi</a>, 
<a href="/search/eess?searchtype=author&query=Palomo%2C+E+J">Esteban J. Palomo</a>, 
<a href="/search/eess?searchtype=author&query=Rodr%C3%ADguez-Capit%C3%A1n%2C+J">Jorge Rodr&#xed;guez-Capit&#xe1;n</a>, 
<a href="/search/eess?searchtype=author&query=Molina-Ramos%2C+A+I">Ana I. Molina-Ramos</a>, 
<a href="/search/eess?searchtype=author&query=Jim%C3%A9nez-Navarro%2C+M">Manuel Jim&#xe9;nez-Navarro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Coronary artery disease (CAD) remains the leading cause of death globally and
invasive coronary angiography (ICA) is considered the gold standard of
anatomical imaging evaluation when CAD is suspected. However, risk evaluation
based on ICA has several limitations, such as visual assessment of stenosis
severity, which has significant interobserver variability. This motivates to
development of a lesion classification system that can support specialists in
their clinical procedures. Although deep learning classification methods are
well-developed in other areas of medical imaging, ICA image classification is
still at an early stage. One of the most important reasons is the lack of
available and high-quality open-access datasets. In this paper, we reported a
new annotated ICA images dataset, CADICA, to provide the research community
with a comprehensive and rigorous dataset of coronary angiography consisting of
a set of acquired patient videos and associated disease-related metadata. This
dataset can be used by clinicians to train their skills in angiographic
assessment of CAD severity and by computer scientists to create computer-aided
diagnostic systems to help in such assessment. In addition, baseline
classification methods are proposed and analyzed, validating the functionality
of CADICA and giving the scientific community a starting point to improve CAD
detection.
</p>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00593" title="Abstract">arXiv:2402.00593</a> (cross-list from eess.IV) [<a href="/pdf/2402.00593" title="Download PDF">pdf</a>, <a href="/format/2402.00593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coronary Artery Disease Classification with Different Lesion Degree  Ranges based on Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jim%C3%A9nez-Partinen%2C+A">Ariadna Jim&#xe9;nez-Partinen</a>, 
<a href="/search/eess?searchtype=author&query=Thurnhofer-Hemsi%2C+K">Karl Thurnhofer-Hemsi</a>, 
<a href="/search/eess?searchtype=author&query=Palomo%2C+E+J">Esteban J. Palomo</a>, 
<a href="/search/eess?searchtype=author&query=Rodr%C3%ADguez-Capit%C3%A1n%2C+J">Jorge Rodr&#xed;guez-Capit&#xe1;n</a>, 
<a href="/search/eess?searchtype=author&query=Molina-Ramos%2C+A+I">Ana I. Molina-Ramos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Invasive Coronary Angiography (ICA) images are considered the gold standard
for assessing the state of the coronary arteries. Deep learning classification
methods are widely used and well-developed in different areas where medical
imaging evaluation has an essential impact due to the development of
computer-aided diagnosis systems that can support physicians in their clinical
procedures. In this paper, a new performance analysis of deep learning methods
for binary ICA classification with different lesion degrees is reported. To
reach this goal, an annotated dataset of ICA images that contains the ground
truth, the location of lesions and seven possible severity degrees ranging
between 0% and 100% was employed. The ICA images were divided into 'lesion' or
'non-lesion' patches. We aim to study how binary classification performance is
affected by the different lesion degrees considered in the positive class.
Therefore, five known convolutional neural network architectures were trained
with different input images where different lesion degree ranges were gradually
incorporated until considering the seven lesion degrees. Besides, four types of
experiments with and without data augmentation were designed, whose F-measure
and Area Under Curve (AUC) were computed. Reported results achieved an
F-measure and AUC of 92.7% and 98.1%, respectively. However, lesion
classification is highly affected by the degree of the lesion intended to
classify, with 15% less accuracy when &lt;99% lesion patches are present.
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00623" title="Abstract">arXiv:2402.00623</a> (cross-list from stat.ML) [<a href="/pdf/2402.00623" title="Download PDF">pdf</a>, <a href="/format/2402.00623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Causal Inference with Gaussian Process Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Giudice%2C+E">Enrico Giudice</a>, 
<a href="/search/stat?searchtype=author&query=Kuipers%2C+J">Jack Kuipers</a>, 
<a href="/search/stat?searchtype=author&query=Moffa%2C+G">Giusi Moffa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Causal discovery and inference from observational data is an essential
problem in statistics posing both modeling and computational challenges. These
are typically addressed by imposing strict assumptions on the joint
distribution such as linearity. We consider the problem of the Bayesian
estimation of the effects of hypothetical interventions in the Gaussian Process
Network (GPN) model, a flexible causal framework which allows describing the
causal relationships nonparametrically. We detail how to perform causal
inference on GPNs by simulating the effect of an intervention across the whole
network and propagating the effect of the intervention on downstream variables.
We further derive a simpler computational approximation by estimating the
intervention distribution as a function of local variables only, modeling the
conditional distributions via additive Gaussian processes. We extend both
frameworks beyond the case of a known causal graph, incorporating uncertainty
about the causal structure via Markov chain Monte Carlo methods. Simulation
studies show that our approach is able to identify the effects of hypothetical
interventions with non-Gaussian, non-linear observational data and accurately
reflect the posterior uncertainty of the causal estimates. Finally we compare
the results of our GPN-based causal inference approach to existing methods on a
dataset of $A.~thaliana$ gene expressions.
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00645" title="Abstract">arXiv:2402.00645</a> (cross-list from stat.ML) [<a href="/pdf/2402.00645" title="Download PDF">pdf</a>, <a href="/format/2402.00645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectrally Transformed Kernel Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhai%2C+R">Runtian Zhai</a>, 
<a href="/search/stat?searchtype=author&query=Pukdee%2C+R">Rattana Pukdee</a>, 
<a href="/search/stat?searchtype=author&query=Jin%2C+R">Roger Jin</a>, 
<a href="/search/stat?searchtype=author&query=Balcan%2C+M">Maria-Florina Balcan</a>, 
<a href="/search/stat?searchtype=author&query=Ravikumar%2C+P">Pradeep Ravikumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024 spotlight. 36 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Unlabeled data is a key component of modern machine learning. In general, the
role of unlabeled data is to impose a form of smoothness, usually from the
similarity information encoded in a base kernel, such as the
$\epsilon$-neighbor kernel or the adjacency matrix of a graph. This work
revisits the classical idea of spectrally transformed kernel regression (STKR),
and provides a new class of general and scalable STKR estimators able to
leverage unlabeled data. Intuitively, via spectral transformation, STKR
exploits the data distribution for which unlabeled data can provide additional
information. First, we show that STKR is a principled and general approach, by
characterizing a universal type of "target smoothness", and proving that any
sufficiently smooth function can be learned by STKR. Second, we provide
scalable STKR implementations for the inductive setting and a general
transformation function, while prior work is mostly limited to the transductive
setting. Third, we derive statistical guarantees for two scenarios: STKR with a
known polynomial transformation, and STKR with kernel PCA when the
transformation is unknown. Overall, we believe that this work helps deepen our
understanding of how to work with unlabeled data, and its generality makes it
easier to inspire new methods.
</p>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00653" title="Abstract">arXiv:2402.00653</a> (cross-list from quant-ph) [<a href="/pdf/2402.00653" title="Download PDF">pdf</a>, <a href="/format/2402.00653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coherent Feed Forward Quantum Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Singh%2C+U">Utkarsh Singh</a>, 
<a href="/search/quant-ph?searchtype=author&query=Goldberg%2C+A+Z">Aaron Z. Goldberg</a>, 
<a href="/search/quant-ph?searchtype=author&query=Heshami%2C+K">Khabat Heshami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures. Comments welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantum machine learning, focusing on quantum neural networks (QNNs), remains
a vastly uncharted field of study. Current QNN models primarily employ
variational circuits on an ansatz or a quantum feature map, often requiring
multiple entanglement layers. This methodology not only increases the
computational cost of the circuit beyond what is practical on near-term quantum
devices but also misleadingly labels these models as neural networks, given
their divergence from the structure of a typical feed-forward neural network
(FFNN). Moreover, the circuit depth and qubit needs of these models scale
poorly with the number of data features, resulting in an efficiency challenge
for real-world machine-learning tasks. We introduce a bona fide QNN model,
which seamlessly aligns with the versatility of a traditional FFNN in terms of
its adaptable intermediate layers and nodes, absent from intermediate
measurements such that our entire model is coherent. This model stands out with
its reduced circuit depth and number of requisite C-NOT gates to outperform
prevailing QNN models. Furthermore, the qubit count in our model remains
unaffected by the data's feature quantity. We test our proposed model on
various benchmarking datasets such as the diagnostic breast cancer (Wisconsin)
and credit card fraud detection datasets. We compare the outcomes of our model
with the existing QNN methods to showcase the advantageous efficacy of our
approach, even with a reduced requirement on quantum resources. Our model paves
the way for application of quantum neural networks to real relevant machine
learning problems.
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00680" title="Abstract">arXiv:2402.00680</a> (cross-list from eess.IV) [<a href="/pdf/2402.00680" title="Download PDF">pdf</a>, <a href="/format/2402.00680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LVC-LGMC: Joint Local and Global Motion Compensation for Learned Video  Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Junru Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Li Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICASSP 2024. The first attempt to use cross attention for bits-free motion estimation and motion compensation
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICASSP (International Conference on Acoustics, Speech, and Signal
  Processing) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Existing learned video compression models employ flow net or deformable
convolutional networks (DCN) to estimate motion information. However, the
limited receptive fields of flow net and DCN inherently direct their
attentiveness towards the local contexts. Global contexts, such as large-scale
motions and global correlations among frames are ignored, presenting a
significant bottleneck for capturing accurate motions. To address this issue,
we propose a joint local and global motion compensation module (LGMC) for
leaned video coding. More specifically, we adopt flow net for local motion
compensation. To capture global context, we employ the cross attention in
feature domain for motion compensation. In addition, to avoid the quadratic
complexity of vanilla cross attention, we divide the softmax operations in
attention into two independent softmax operations, leading to linear
complexity. To validate the effectiveness of our proposed LGMC, we integrate it
with DCVC-TCM and obtain learned video compression with joint local and global
motion compensation (LVC-LGMC). Extensive experiments demonstrate that our
LVC-LGMC has significant rate-distortion performance improvements over baseline
DCVC-TCM.
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00686" title="Abstract">arXiv:2402.00686</a> (cross-list from math.ST) [<a href="/pdf/2402.00686" title="Download PDF">pdf</a>, <a href="/format/2402.00686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum a posteriori testing in statistical inverse problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kretschmann%2C+R">Remo Kretschmann</a>, 
<a href="/search/math?searchtype=author&query=Werner%2C+F">Frank Werner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">This paper is concerned with a Bayesian approach to testing hypotheses in
statistical inverse problems. Based on the posterior distribution $\Pi
\left(\cdot |Y = y\right)$, we want to infer whether a feature
$\left\langle\varphi, u^\dagger\right\rangle$ of the unknown quantity of
interest $u^\dagger$ is positive. This can be done by the so-called maximum a
posteriori test. We provide a frequentistic analysis of this test's properties
such as level and power, and prove that it is a regularized test in the sense
of Kretschmann et al. (2024). Furthermore we provide lower bounds for its power
under classical spectral source conditions in case of Gaussian priors.
Numerical simulations illustrate its superior performance both in moderately
and severely ill-posed situations.
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00760" title="Abstract">arXiv:2402.00760</a> (cross-list from physics.plasm-ph) [<a href="/pdf/2402.00760" title="Download PDF">pdf</a>, <a href="/format/2402.00760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EuroPED-NN: Uncertainty aware surrogate model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Alvarez%2C+A+P">A. Panera Alvarez</a>, 
<a href="/search/physics?searchtype=author&query=Ho%2C+A">A. Ho</a>, 
<a href="/search/physics?searchtype=author&query=Jarvinen%2C+A">A. Jarvinen</a>, 
<a href="/search/physics?searchtype=author&query=Saarelma%2C+S">S. Saarelma</a>, 
<a href="/search/physics?searchtype=author&query=Wiesen%2C+S">S. Wiesen</a>, 
<a href="/search/physics?searchtype=author&query=Contributors%2C+J">JET Contributors</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Plasma Physics (physics.plasm-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This work successfully generates uncertainty aware surrogate models, via the
Bayesian neural network with noise contrastive prior (BNN-NCP) technique, of
the EuroPED plasma pedestal model using data from the JET-ILW pedestal database
and subsequent model evaluations. All this conform EuroPED-NN. The BNN-NCP
technique is proven to be a good fit for uncertainty aware surrogate models,
matching the output results as a regular neural network, providing prediction's
confidence as uncertainties, and highlighting the out of distribution (OOD)
regions using surrogate model uncertainties. This provides critical insights
into model robustness and reliability. EuroPED-NN has been physically
validated, first, analyzing electron density
$n_e\!\left(\psi_{\text{pol}}=0.94\right)$ with respect to increasing plasma
current, $I_p$, and second, validating the $\Delta-\beta_{p,ped}$ relation
associated with the EuroPED model. Affirming the robustness of the underlying
physics learned by the surrogate model.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00772" title="Abstract">arXiv:2402.00772</a> (cross-list from math.OC) [<a href="/pdf/2402.00772" title="Download PDF">pdf</a>, <a href="/format/2402.00772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Risk Limiting Dispatch in Power Networks: Formulation and  Generalization Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+G">Ge Chen</a>, 
<a href="/search/math?searchtype=author&query=Qin%2C+J">Junjie Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Risk limiting dispatch (RLD) has been proposed as an approach that
effectively trades off economic costs with operational risks for power dispatch
under uncertainty. However, how to solve the RLD problem with provably
near-optimal performance still remains an open problem. This paper presents a
learning-based solution to this challenge. We first design a data-driven
formulation for the RLD problem, which aims to construct a decision rule that
directly maps day-ahead observable information to cost-effective dispatch
decisions for the future delivery interval. Unlike most existing works that
follow a predict-then-optimize paradigm, this end-to-end rule bypasses the
additional suboptimality introduced by separately handling prediction and
optimization. We then propose neural RLD, a novel solution method to the
data-driven formulation. This method leverages an L2-regularized neural network
to learn the decision rule, thereby transforming the data-driven formulation
into a neural network training task that can be efficiently completed by
stochastic gradient descent. A theoretical performance guarantee is further
established to bound the suboptimality of our method, which implies that its
suboptimality approaches to zero with high probability as more samples are
utilized. Simulation tests across various systems demonstrate our method's
superior performance in convergence, suboptimality, and computational
efficiency compared with benchmarks.
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00776" title="Abstract">arXiv:2402.00776</a> (cross-list from quant-ph) [<a href="/pdf/2402.00776" title="Download PDF">pdf</a>, <a href="/format/2402.00776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Quantum Vision Transformers for Event Classification in High  Energy Physics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Unlu%2C+E+B">Eyup B. Unlu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cara%2C+M+C">Mar&#xe7;al Comajoan Cara</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dahale%2C+G+R">Gopal Ramesh Dahale</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dong%2C+Z">Zhongtian Dong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Forestano%2C+R+T">Roy T. Forestano</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gleyzer%2C+S">Sergei Gleyzer</a>, 
<a href="/search/quant-ph?searchtype=author&query=Justice%2C+D">Daniel Justice</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kong%2C+K">Kyoungchul Kong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Magorsch%2C+T">Tom Magorsch</a>, 
<a href="/search/quant-ph?searchtype=author&query=Matchev%2C+K+T">Konstantin T. Matchev</a>, 
<a href="/search/quant-ph?searchtype=author&query=Matcheva%2C+K">Katia Matcheva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); High Energy Physics - Phenomenology (hep-ph); Machine Learning (stat.ML)

</div>
<p class="mathjax">Models based on vision transformer architectures are considered
state-of-the-art when it comes to image classification tasks. However, they
require extensive computational resources both for training and deployment. The
problem is exacerbated as the amount and complexity of the data increases.
Quantum-based vision transformer models could potentially alleviate this issue
by reducing the training and operating time while maintaining the same
predictive power. Although current quantum computers are not yet able to
perform high-dimensional tasks yet, they do offer one of the most efficient
solutions for the future. In this work, we construct several variations of a
quantum hybrid vision transformer for a classification problem in high energy
physics (distinguishing photons and electrons in the electromagnetic
calorimeter). We test them against classical vision transformer architectures.
Our findings indicate that the hybrid models can achieve comparable performance
to their classical analogues with a similar number of parameters.
</p>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00811" title="Abstract">arXiv:2402.00811</a> (cross-list from eess.AS) [<a href="/pdf/2402.00811" title="Download PDF">pdf</a>, <a href="/format/2402.00811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Analysis of the Variance of Diffusion-based Speech Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lay%2C+B">Bunlong Lay</a>, 
<a href="/search/eess?searchtype=author&query=Gerkmann%2C+T">Timo Gerkmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Diffusion models proved to be powerful models for generative speech
enhancement. In recent SGMSE+ approaches, training involves a stochastic
differential equation for the diffusion process, adding both Gaussian and
environmental noise to the clean speech signal gradually. The speech
enhancement performance varies depending on the choice of the stochastic
differential equation that controls the evolution of the mean and the variance
along the diffusion processes when adding environmental and Gaussian noise. In
this work, we highlight that the scale of the variance is a dominant parameter
for speech enhancement performance and show that it controls the tradeoff
between noise attenuation and speech distortions. More concretely, we show that
a larger variance increases the noise attenuation and allows for reducing the
computational footprint, as fewer function evaluations for generating the
estimate are required.
</p>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00812" title="Abstract">arXiv:2402.00812</a> (cross-list from physics.med-ph) [<a href="/pdf/2402.00812" title="Download PDF">pdf</a>, <a href="/format/2402.00812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Examining the Influence of Digital Phantom Models in Virtual Imaging  Trials for Tomographic Breast Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kavuri%2C+A">Amar Kavuri</a>, 
<a href="/search/physics?searchtype=author&query=Das%2C+M">Mini Das</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Human-Computer Interaction (cs.HC); Image and Video Processing (eess.IV); Signal Processing (eess.SP); Applied Physics (physics.app-ph)

</div>
<p class="mathjax">Purpose: Digital phantoms are one of the key components of virtual imaging
trials (VITs) that aim to assess and optimize new medical imaging systems and
algorithms. However, these phantoms vary in their voxel resolution, appearance,
and structural details. This study aims to examine whether and how variations
between digital phantoms influence system optimization with digital breast
tomosynthesis (DBT) as a chosen modality. Methods: We selected widely used and
open-access digital breast phantoms generated with different methods. For each
phantom type, we created an ensemble of DBT images to test acquisition
strategies. Human observer localization ROC (LROC) was used to assess observer
performance studies for each case. Noise power spectrum (NPS) was estimated to
compare the phantom structural components. Further, we computed several gaze
metrics to quantify the gaze pattern when viewing images generated from
different phantom types. Results: Our LROC results show that the arc samplings
for peak performance were approximately 2.5 degrees and 6 degrees in Bakic and
XCAT breast phantoms respectively for 3-mm lesion detection tasks and indicate
that system optimization outcomes from VITs can vary with phantom types and
structural frequency components. Additionally, a significant correlation (p=
0.01) between gaze metrics and diagnostic performance suggests that gaze
analysis can be used to understand and evaluate task difficulty in VITs.
</p>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00828" title="Abstract">arXiv:2402.00828</a> (cross-list from eess.AS) [<a href="/pdf/2402.00828" title="Download PDF">pdf</a>, <a href="/format/2402.00828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Fine-tuning of Audio Spectrogram Transformers via Soft Mixture  of Adapters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cappellazzo%2C+U">Umberto Cappellazzo</a>, 
<a href="/search/eess?searchtype=author&query=Falavigna%2C+D">Daniele Falavigna</a>, 
<a href="/search/eess?searchtype=author&query=Brutti%2C+A">Alessio Brutti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code will be released ad: \url{<a href="https://github.com/umbertocappellazzo/PETL_AST">this https URL</a>}
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Mixture of Experts (MoE) architectures have recently started burgeoning due
to their ability to scale model's capacity while maintaining the computational
cost affordable. Furthermore, they can be applied to both Transformers and
State Space Models, the current state-of-the-art models in numerous fields.
While MoE has been mostly investigated for the pre-training stage, its use in
parameter-efficient transfer learning settings is under-explored. To narrow
this gap, this paper attempts to demystify the use of MoE for
parameter-efficient fine-tuning of Audio Spectrogram Transformers to audio and
speech downstream tasks. Specifically, we propose Soft Mixture of Adapters
(Soft-MoA). It exploits adapters as the experts and, leveraging the recent Soft
MoE method, it relies on a soft assignment between the input tokens and experts
to keep the computational time limited. Extensive experiments across 4
benchmarks demonstrate that Soft-MoA outperforms the single adapter method and
performs on par with the dense MoA counterpart. We finally present ablation
studies on key elements of Soft-MoA, showing for example that Soft-MoA achieves
better scaling with more experts, as well as ensuring that all experts
contribute to the computation of the output tokens, thus dispensing with the
expert imbalance issue.
</p>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00833" title="Abstract">arXiv:2402.00833</a> (cross-list from math.PR) [<a href="/pdf/2402.00833" title="Download PDF">pdf</a>, <a href="/format/2402.00833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orthogonal gamma-based expansion for the CIR&#x27;s first passage time  distribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Di+Nardo%2C+E">Elvira Di Nardo</a>, 
<a href="/search/math?searchtype=author&query=D%27Onofrio%2C+G">Giuseppe D&#x27;Onofrio</a>, 
<a href="/search/math?searchtype=author&query=Martini%2C+T">Tommaso Martini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Numerical Analysis (math.NA); Computation (stat.CO)

</div>
<p class="mathjax">In this paper we analyze a method for approximating the first-passage time
density and the corresponding distribution function for a CIR process. This
approximation is obtained by truncating a series expansion involving the
generalized Laguerre polynomials and the gamma probability density. The
suggested approach involves a number of numerical issues which depend strongly
on the coefficient of variation of the first passage time random variable.
These issues are examined and solutions are proposed also involving the first
passage time distribution function. Numerical results and comparisons with
alternative approximation methods show the strengths and weaknesses of the
proposed method. A general acceptance-rejection-like procedure, that makes use
of the approximation, is presented. It allows the generation of first passage
time data, even if its distribution is unknown.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Fri,  2 Feb 24</h3>
<dl>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1902.09604" title="Abstract">arXiv:1902.09604</a> (replaced) [<a href="/pdf/1902.09604" title="Download PDF">pdf</a>, <a href="/ps/1902.09604" title="Download PostScript">ps</a>, <a href="/format/1902.09604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review on the Application of Blockchain for the Next Generation of  Cybersecure Industry 4.0 Smart Factories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fernandez-Carames%2C+T+M">Tiago M. Fernandez-Carames</a>, 
<a href="/search/cs?searchtype=author&query=Fraga-Lamas%2C+P">Paula Fraga-Lamas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted version of the IEEE Access paper with the same name
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Access, vol. 7, pp. 45201-45218, 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Cryptography and Security (cs.CR); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2001.04086" title="Abstract">arXiv:2001.04086</a> (replaced) [<a href="/pdf/2001.04086" title="Download PDF">pdf</a>, <a href="/format/2001.04086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GridMask Data Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pengguang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hengshuang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingquan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jiaya Jia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.10859" title="Abstract">arXiv:2010.10859</a> (replaced) [<a href="/pdf/2010.10859" title="Download PDF">pdf</a>, <a href="/ps/2010.10859" title="Download PostScript">ps</a>, <a href="/format/2010.10859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Semantic Expressiveness of Iso- and Equi-Recursive Types
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Devriese%2C+D">Dominique Devriese</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+E+M">Eric Mark Martin</a>, 
<a href="/search/cs?searchtype=author&query=Patrignani%2C+M">Marco Patrignani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.04828" title="Abstract">arXiv:2105.04828</a> (replaced) [<a href="/pdf/2105.04828" title="Download PDF">pdf</a>, <a href="/format/2105.04828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptotically Optimal Procedures for Sequential Joint Detection and  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Reinhard%2C+D">Dominik Reinhard</a>, 
<a href="/search/eess?searchtype=author&query=Fau%C3%9F%2C+M">Michael Fau&#xdf;</a>, 
<a href="/search/eess?searchtype=author&query=Zoubir%2C+A+M">Abdelhak M. Zoubir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 3 figures, 1 table, 8 pages supplementing material. Accepted for publication in Signal Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.08020" title="Abstract">arXiv:2107.08020</a> (replaced) [<a href="/pdf/2107.08020" title="Download PDF">pdf</a>, <a href="/format/2107.08020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Graph Topology Learning from Matrix-valued Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Jiang%2C+Y">Yiye Jiang</a>, 
<a href="/search/stat?searchtype=author&query=Bigot%2C+J">J&#xe9;r&#xe9;mie Bigot</a>, 
<a href="/search/stat?searchtype=author&query=Maabout%2C+S">Sofian Maabout</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.04567" title="Abstract">arXiv:2108.04567</a> (replaced) [<a href="/pdf/2108.04567" title="Download PDF">pdf</a>, <a href="/format/2108.04567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust and Dexterous Dual-arm Tele-Cooperation using Adaptable Impedance  Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Babarahmati%2C+K+K">Keyhan Kouhkiloui Babarahmati</a>, 
<a href="/search/cs?searchtype=author&query=Kasaei%2C+M">Mohammadreza Kasaei</a>, 
<a href="/search/cs?searchtype=author&query=Tiseo%2C+C">Carlo Tiseo</a>, 
<a href="/search/cs?searchtype=author&query=Mistry%2C+M">Michael Mistry</a>, 
<a href="/search/cs?searchtype=author&query=Vijayakumar%2C+S">Sethu Vijayakumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.08531" title="Abstract">arXiv:2110.08531</a> (replaced) [<a href="/pdf/2110.08531" title="Download PDF">pdf</a>, <a href="/format/2110.08531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A theoretical and empirical study of new adaptive algorithms with  additional momentum steps and shifted updates for stochastic non-convex  optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Alecsa%2C+C+D">Cristian Daniel Alecsa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 6 figures, 7 tables, 43 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.12782" title="Abstract">arXiv:2110.12782</a> (replaced) [<a href="/pdf/2110.12782" title="Download PDF">pdf</a>, <a href="/format/2110.12782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SketchNE: Embedding Billion-Scale Networks Accurately in One Hour
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuyang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuxiao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jiezhong Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenjian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xu Feng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jie Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.00365" title="Abstract">arXiv:2112.00365</a> (replaced) [<a href="/pdf/2112.00365" title="Download PDF">pdf</a>, <a href="/format/2112.00365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probability-Generating Function Kernels for Spherical Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Papamarkou%2C+T">Theodore Papamarkou</a>, 
<a href="/search/stat?searchtype=author&query=Lindo%2C+A">Alexey Lindo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.05149" title="Abstract">arXiv:2201.05149</a> (replaced) [<a href="/pdf/2201.05149" title="Download PDF">pdf</a>, <a href="/format/2201.05149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The curse of overparametrization in adversarial training: Precise  analysis of robust generalization for random features regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hassani%2C+H">Hamed Hassani</a>, 
<a href="/search/cs?searchtype=author&query=Javanmard%2C+A">Adel Javanmard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 86 pages (main file: 25 pages and supplementary: 61 pages). To appear in the Annals of Statistics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.07119" title="Abstract">arXiv:2201.07119</a> (replaced) [<a href="/pdf/2201.07119" title="Download PDF">pdf</a>, <a href="/ps/2201.07119" title="Download PostScript">ps</a>, <a href="/format/2201.07119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Code-Based Cryptography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weger%2C+V">Violetta Weger</a>, 
<a href="/search/cs?searchtype=author&query=Gassner%2C+N">Niklas Gassner</a>, 
<a href="/search/cs?searchtype=author&query=Rosenthal%2C+J">Joachim Rosenthal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This book chapter is a part of the Springer Lecture Notes in Mathematics: Coding Theory and Applications V, Applications of Coding Theory in Quantum Computing and Cryptography
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.13140" title="Abstract">arXiv:2201.13140</a> (replaced) [<a href="/pdf/2201.13140" title="Download PDF">pdf</a>, <a href="/format/2201.13140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial kernels for edge modification problems towards block and  strictly chordal graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dumas%2C+M">Ma&#xeb;l Dumas</a>, 
<a href="/search/cs?searchtype=author&query=Perez%2C+A">Anthony Perez</a>, 
<a href="/search/cs?searchtype=author&query=Rocton%2C+M">Mathis Rocton</a>, 
<a href="/search/cs?searchtype=author&query=Todinca%2C+I">Ioan Todinca</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.02759" title="Abstract">arXiv:2202.02759</a> (replaced) [<a href="/pdf/2202.02759" title="Download PDF">pdf</a>, <a href="/format/2202.02759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Node-wise monotone barrier coupling law for formation control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lee%2C+J+G">Jin Gyu Lee</a>, 
<a href="/search/eess?searchtype=author&query=Mostajeran%2C+C">Cyrus Mostajeran</a>, 
<a href="/search/eess?searchtype=author&query=Van+Goffrier%2C+G">Graham Van Goffrier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.04995" title="Abstract">arXiv:2203.04995</a> (replaced) [<a href="/pdf/2203.04995" title="Download PDF">pdf</a>, <a href="/format/2203.04995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CUBES: A Parallel Synthesizer for SQL Using Examples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brancas%2C+R">Ricardo Brancas</a>, 
<a href="/search/cs?searchtype=author&query=Terra-Neves%2C+M">Miguel Terra-Neves</a>, 
<a href="/search/cs?searchtype=author&query=Ventura%2C+M">Miguel Ventura</a>, 
<a href="/search/cs?searchtype=author&query=Manquinho%2C+V">Vasco Manquinho</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+R">Ruben Martins</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Databases (cs.DB); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.03256" title="Abstract">arXiv:2205.03256</a> (replaced) [<a href="/pdf/2205.03256" title="Download PDF">pdf</a>, <a href="/format/2205.03256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OROS: Online Operation and Orchestration of Collaborative Robots using  5G
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Romero%2C+A">Arnau Romero</a>, 
<a href="/search/cs?searchtype=author&query=Delgado%2C+C">Carmen Delgado</a>, 
<a href="/search/cs?searchtype=author&query=Zanzi%2C+L">Lanfranco Zanzi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xi Li</a>, 
<a href="/search/cs?searchtype=author&query=Costa-P%C3%A9rez%2C+X">Xavier Costa-P&#xe9;rez</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Network and Service Management 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.14461" title="Abstract">arXiv:2205.14461</a> (replaced) [<a href="/pdf/2205.14461" title="Download PDF">pdf</a>, <a href="/format/2205.14461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative likelihood-ratio estimation over graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=de+la+Concha%2C+A">Alejandro de la Concha</a>, 
<a href="/search/stat?searchtype=author&query=Vayatis%2C+N">Nicolas Vayatis</a>, 
<a href="/search/stat?searchtype=author&query=Kalogeratos%2C+A">Argyris Kalogeratos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.14397" title="Abstract">arXiv:2206.14397</a> (replaced) [<a href="/pdf/2206.14397" title="Download PDF">pdf</a>, <a href="/format/2206.14397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Machine Learning in Healthcare: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Q">Qizhang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+M">Mengnan Du</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+N">Na Zou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xia Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.07624" title="Abstract">arXiv:2207.07624</a> (replaced) [<a href="/pdf/2207.07624" title="Download PDF">pdf</a>, <a href="/format/2207.07624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feed-Forward Latent Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bohdal%2C+O">Ondrej Bohdal</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Da Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S+X">Shell Xu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Hospedales%2C+T">Timothy Hospedales</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024. Project page: <a href="https://ondrejbohdal.github.io/cxda">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.00750" title="Abstract">arXiv:2209.00750</a> (replaced) [<a href="/pdf/2209.00750" title="Download PDF">pdf</a>, <a href="/format/2209.00750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dumbo-NG: Fast Asynchronous BFT Consensus with Throughput-Oblivious  Latency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yingzi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhenliang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Q">Qiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenfeng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.02628" title="Abstract">arXiv:2209.02628</a> (replaced) [<a href="/pdf/2209.02628" title="Download PDF">pdf</a>, <a href="/format/2209.02628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weak Collocation Regression method: fast reveal hidden stochastic  dynamics from high-dimensional aggregate data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lu%2C+L">Liwei Lu</a>, 
<a href="/search/math?searchtype=author&query=Zeng%2C+Z">Zhijun Zeng</a>, 
<a href="/search/math?searchtype=author&query=Jiang%2C+Y">Yan Jiang</a>, 
<a href="/search/math?searchtype=author&query=Zhu%2C+Y">Yi Zhu</a>, 
<a href="/search/math?searchtype=author&query=Hu%2C+P">Pipi Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Artificial Intelligence (cs.AI); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.06458" title="Abstract">arXiv:2209.06458</a> (replaced) [<a href="/pdf/2209.06458" title="Download PDF">pdf</a>, <a href="/ps/2209.06458" title="Download PostScript">ps</a>, <a href="/format/2209.06458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design space exploration of a poultry fillet processing system using  discrete-event simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Paape%2C+N">N. Paape</a>, 
<a href="/search/eess?searchtype=author&query=van+Eekelen%2C+J+A+W+M">J.A.W.M. van Eekelen</a>, 
<a href="/search/eess?searchtype=author&query=Reniers%2C+M+A">M.A. Reniers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> FOODOPS 2022
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 8th International Food Operations &amp; Processing
  Simulation Workshop (FoodOPS 2022), 001
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.12644" title="Abstract">arXiv:2209.12644</a> (replaced) [<a href="/pdf/2209.12644" title="Download PDF">pdf</a>, <a href="/format/2209.12644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FORESEE: Prediction with Expansion-Compression Unscented Transform for  Online Policy Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parwana%2C+H">Hardik Parwana</a>, 
<a href="/search/cs?searchtype=author&query=Panagou%2C+D">Dimitra Panagou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.00953" title="Abstract">arXiv:2211.00953</a> (replaced) [<a href="/pdf/2211.00953" title="Download PDF">pdf</a>, <a href="/format/2211.00953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards understanding CG and GMRES through examples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Carson%2C+E">Erin Carson</a>, 
<a href="/search/math?searchtype=author&query=Liesen%2C+J">J&#xf6;rg Liesen</a>, 
<a href="/search/math?searchtype=author&query=Strako%C5%A1%2C+Z">Zden&#x11b;k Strako&#x161;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 56 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01345" title="Abstract">arXiv:2211.01345</a> (replaced) [<a href="/pdf/2211.01345" title="Download PDF">pdf</a>, <a href="/format/2211.01345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative machine learning methods for multivariate ensemble  post-processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Chen%2C+J">Jieyu Chen</a>, 
<a href="/search/physics?searchtype=author&query=Janke%2C+T">Tim Janke</a>, 
<a href="/search/physics?searchtype=author&query=Steinke%2C+F">Florian Steinke</a>, 
<a href="/search/physics?searchtype=author&query=Lerch%2C+S">Sebastian Lerch</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Annals of Applied Statistics (2024), 18, 159-183
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.04125" title="Abstract">arXiv:2211.04125</a> (replaced) [<a href="/pdf/2211.04125" title="Download PDF">pdf</a>, <a href="/ps/2211.04125" title="Download PostScript">ps</a>, <a href="/format/2211.04125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficacy of MRI data harmonization in the age of machine learning. A  multicenter study across 36 datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marzi%2C+C">Chiara Marzi</a>, 
<a href="/search/cs?searchtype=author&query=Giannelli%2C+M">Marco Giannelli</a>, 
<a href="/search/cs?searchtype=author&query=Barucci%2C+A">Andrea Barucci</a>, 
<a href="/search/cs?searchtype=author&query=Tessa%2C+C">Carlo Tessa</a>, 
<a href="/search/cs?searchtype=author&query=Mascalchi%2C+M">Mario Mascalchi</a>, 
<a href="/search/cs?searchtype=author&query=Diciotti%2C+S">Stefano Diciotti</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sci Data 11, 115 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Image and Video Processing (eess.IV); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10819" title="Abstract">arXiv:2211.10819</a> (replaced) [<a href="/pdf/2211.10819" title="Download PDF">pdf</a>, <a href="/ps/2211.10819" title="Download PostScript">ps</a>, <a href="/format/2211.10819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Block size estimation for data partitioning in HPC applications using  machine learning techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cantini%2C+R">Riccardo Cantini</a>, 
<a href="/search/cs?searchtype=author&query=Marozzo%2C+F">Fabrizio Marozzo</a>, 
<a href="/search/cs?searchtype=author&query=Orsino%2C+A">Alessio Orsino</a>, 
<a href="/search/cs?searchtype=author&query=Talia%2C+D">Domenico Talia</a>, 
<a href="/search/cs?searchtype=author&query=Trunfio%2C+P">Paolo Trunfio</a>, 
<a href="/search/cs?searchtype=author&query=Badia%2C+R+M">Rosa M. Badia</a>, 
<a href="/search/cs?searchtype=author&query=Ejarque%2C+J">Jorge Ejarque</a>, 
<a href="/search/cs?searchtype=author&query=Vazquez%2C+F">Fernando Vazquez</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Big Data, vol. 11, n. 19, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.11133" title="Abstract">arXiv:2211.11133</a> (replaced) [<a href="/pdf/2211.11133" title="Download PDF">pdf</a>, <a href="/format/2211.11133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Accuracy and Robustness of Steering Angle Prediction with  Attention Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nadella%2C+S">Swetha Nadella</a>, 
<a href="/search/cs?searchtype=author&query=Barua%2C+P">Pramiti Barua</a>, 
<a href="/search/cs?searchtype=author&query=Hagler%2C+J+C">Jeremy C. Hagler</a>, 
<a href="/search/cs?searchtype=author&query=Lamb%2C+D+J">David J. Lamb</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qing Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14659" title="Abstract">arXiv:2211.14659</a> (replaced) [<a href="/pdf/2211.14659" title="Download PDF">pdf</a>, <a href="/format/2211.14659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sharp bounds on Helmholtz impedance-to-impedance maps and application to  overlapping domain decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lafontaine%2C+D">David Lafontaine</a>, 
<a href="/search/math?searchtype=author&query=Spence%2C+E+A">Euan A. Spence</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Pure Appl. Analysis 5 (2023) 927-972
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08414" title="Abstract">arXiv:2212.08414</a> (replaced) [<a href="/pdf/2212.08414" title="Download PDF">pdf</a>, <a href="/format/2212.08414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Methods for Calibrated Photometric Stereo and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ju%2C+Y">Yakun Ju</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+K">Kin-Man Lam</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Wuyuan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Huiyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Junyu Dong</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Boxin Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 11 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.11880" title="Abstract">arXiv:2212.11880</a> (replaced) [<a href="/pdf/2212.11880" title="Download PDF">pdf</a>, <a href="/ps/2212.11880" title="Download PostScript">ps</a>, <a href="/format/2212.11880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter Inference based on Gaussian Processes Informed by Nonlinear  Partial Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+Z">Zhaohui Li</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+S">Shihao Yang</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+J">Jeff Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03182" title="Abstract">arXiv:2301.03182</a> (replaced) [<a href="/pdf/2301.03182" title="Download PDF">pdf</a>, <a href="/format/2301.03182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure-Informed Shadow Removal Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+L">Lan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+Z">Zhanghan Ke</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Ke Xu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Wei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Tsang%2C+I+W">Ivor W. Tsang</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+R+W+H">Rynson W.H. Lau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE TIP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03435" title="Abstract">arXiv:2301.03435</a> (replaced) [<a href="/pdf/2301.03435" title="Download PDF">pdf</a>, <a href="/ps/2301.03435" title="Download PostScript">ps</a>, <a href="/format/2301.03435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Algebra of Nondeterministic Finite Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gorrieri%2C+R">Roberto Gorrieri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01658" title="Abstract">arXiv:2302.01658</a> (replaced) [<a href="/pdf/2302.01658" title="Download PDF">pdf</a>, <a href="/format/2302.01658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A space-time adaptive low-rank method for high-dimensional parabolic  partial differential equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bachmayr%2C+M">Markus Bachmayr</a>, 
<a href="/search/math?searchtype=author&query=Faldum%2C+M">Manfred Faldum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 67 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03983" title="Abstract">arXiv:2302.03983</a> (replaced) [<a href="/pdf/2302.03983" title="Download PDF">pdf</a>, <a href="/format/2302.03983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> X-Mesh: A new approach for the simulation of two-phase flow with sharp  interface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quiriny%2C+A">Antoine Quiriny</a>, 
<a href="/search/cs?searchtype=author&query=Lambrechts%2C+J">Jonathan Lambrechts</a>, 
<a href="/search/cs?searchtype=author&query=Mo%C3%ABs%2C+N">Nicolas Mo&#xeb;s</a>, 
<a href="/search/cs?searchtype=author&query=Remacle%2C+J">Jean-Fran&#xe7;ois Remacle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05087" title="Abstract">arXiv:2302.05087</a> (replaced) [<a href="/pdf/2302.05087" title="Download PDF">pdf</a>, <a href="/format/2302.05087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Video Anomaly Event Detection: Systematic Taxonomy and  Comparison of Deep Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Dingkang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Boukerche%2C+A">Azzedine Boukerche</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+P">Peng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Liang Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM Computing Surveys. For more information, please see our project page: <a href="https://github.com/fudanyliu/GVAED">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05327" title="Abstract">arXiv:2302.05327</a> (replaced) [<a href="/pdf/2302.05327" title="Download PDF">pdf</a>, <a href="/format/2302.05327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constraint Automata on Infinite Data Trees: From CTL(Z)/CTL*(Z) To  Decision Procedures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Demri%2C+S">Stephane Demri</a>, 
<a href="/search/cs?searchtype=author&query=Quaas%2C+K">Karin Quaas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07558" title="Abstract">arXiv:2302.07558</a> (replaced) [<a href="/pdf/2302.07558" title="Download PDF">pdf</a>, <a href="/format/2302.07558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Initialisation from lattice Boltzmann to multi-step Finite Difference  methods: modified equations and discrete observability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bellotti%2C+T">Thomas Bellotti</a> (CMAP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09031" title="Abstract">arXiv:2302.09031</a> (replaced) [<a href="/pdf/2302.09031" title="Download PDF">pdf</a>, <a href="/ps/2302.09031" title="Download PostScript">ps</a>, <a href="/format/2302.09031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Categorical Proof-Theoretic Semantics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pym%2C+D">David Pym</a>, 
<a href="/search/math?searchtype=author&query=Ritter%2C+E">Eike Ritter</a>, 
<a href="/search/math?searchtype=author&query=Robinson%2C+E">Edmund Robinson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO); Category Theory (math.CT)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09624" title="Abstract">arXiv:2302.09624</a> (replaced) [<a href="/pdf/2302.09624" title="Download PDF">pdf</a>, <a href="/ps/2302.09624" title="Download PostScript">ps</a>, <a href="/format/2302.09624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breaking the Communication-Privacy-Accuracy Tradeoff with  $f$-Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+R">Richeng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Z">Zhonggen Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+C">Caijun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Quek%2C+T">Tony Quek</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Huaiyu Dai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11891" title="Abstract">arXiv:2302.11891</a> (replaced) [<a href="/pdf/2302.11891" title="Download PDF">pdf</a>, <a href="/format/2302.11891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sequential Hierarchical Least-Squares Programming for Prioritized  Non-Linear Optimal Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pfeiffer%2C+K">Kai Pfeiffer</a>, 
<a href="/search/math?searchtype=author&query=Kheddar%2C+A">Abderrahmane Kheddar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Robotics (cs.RO); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13081" title="Abstract">arXiv:2302.13081</a> (replaced) [<a href="/pdf/2302.13081" title="Download PDF">pdf</a>, <a href="/format/2302.13081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Isolated Suborders and their Application to Counting Closure Operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gl%C3%BCck%2C+R">Roland Gl&#xfc;ck</a> (1) ((1) German Aerospace Center)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13144" title="Abstract">arXiv:2302.13144</a> (replaced) [<a href="/pdf/2302.13144" title="Download PDF">pdf</a>, <a href="/format/2302.13144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting LQR Control from the Perspective of Receding-Horizon Policy  Gradient
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+X">Xiangyuan Zhang</a>, 
<a href="/search/math?searchtype=author&query=Ba%C5%9Far%2C+T">Tamer Ba&#x15f;ar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13880" title="Abstract">arXiv:2302.13880</a> (replaced) [<a href="/pdf/2302.13880" title="Download PDF">pdf</a>, <a href="/format/2302.13880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Privacy-Preserving Approximation of the Kidney Exchange  Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Breuer%2C+M">Malte Breuer</a>, 
<a href="/search/cs?searchtype=author&query=Meyer%2C+U">Ulrike Meyer</a>, 
<a href="/search/cs?searchtype=author&query=Wetzel%2C+S">Susanne Wetzel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ACM Asia Conference on Computer and Communications Security (ASIA CCS 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06021" title="Abstract">arXiv:2303.06021</a> (replaced) [<a href="/pdf/2303.06021" title="Download PDF">pdf</a>, <a href="/format/2303.06021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine learning for sports betting: should model selection be based on  accuracy or calibration?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Walsh%2C+C">Conor Walsh</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+A">Alok Joshi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 5 Figures. Paper submitted to Elsevier's Machine Learning with Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09117" title="Abstract">arXiv:2303.09117</a> (replaced) [<a href="/pdf/2303.09117" title="Download PDF">pdf</a>, <a href="/format/2303.09117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Modal Causal Intervention for Medical Report Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weixing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Ce Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiarui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11098" title="Abstract">arXiv:2303.11098</a> (replaced) [<a href="/pdf/2303.11098" title="Download PDF">pdf</a>, <a href="/format/2303.11098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Role of the Projector in Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miles%2C+R">Roy Miles</a>, 
<a href="/search/cs?searchtype=author&query=Mikolajczyk%2C+K">Krystian Mikolajczyk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024. Code available at <a href="https://github.com/roymiles/Simple-Recipe-Distillation">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00759" title="Abstract">arXiv:2304.00759</a> (replaced) [<a href="/pdf/2304.00759" title="Download PDF">pdf</a>, <a href="/format/2304.00759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedIN: Federated Intermediate Layers Learning for Model Heterogeneity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chan%2C+Y">Yun-Hin Chan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhihan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jing Deng</a>, 
<a href="/search/cs?searchtype=author&query=Ngai%2C+E+C+-">Edith C.-H. Ngai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01035" title="Abstract">arXiv:2304.01035</a> (replaced) [<a href="/pdf/2304.01035" title="Download PDF">pdf</a>, <a href="/format/2304.01035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reproducing the results for NICER observation of PSR J0030+0451
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Afle%2C+C">Chaitanya Afle</a>, 
<a href="/search/astro-ph?searchtype=author&query=Miles%2C+P+R">Patrick R. Miles</a>, 
<a href="/search/astro-ph?searchtype=author&query=Caino-Lores%2C+S">Silvina Caino-Lores</a>, 
<a href="/search/astro-ph?searchtype=author&query=Capano%2C+C+D">Collin D. Capano</a>, 
<a href="/search/astro-ph?searchtype=author&query=Tews%2C+I">Ingo Tews</a>, 
<a href="/search/astro-ph?searchtype=author&query=Vahi%2C+K">Karan Vahi</a>, 
<a href="/search/astro-ph?searchtype=author&query=Deelman%2C+E">Ewa Deelman</a>, 
<a href="/search/astro-ph?searchtype=author&query=Taufer%2C+M">Michela Taufer</a>, 
<a href="/search/astro-ph?searchtype=author&query=Brown%2C+D+A">Duncan A. Brown</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures, 2 tables. Final version accepted for publication in Computing in Science &amp; Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Astrophysical Phenomena (astro-ph.HE)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08652" title="Abstract">arXiv:2304.08652</a> (replaced) [<a href="/pdf/2304.08652" title="Download PDF">pdf</a>, <a href="/format/2304.08652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mechanical Intelligence Simplifies Control in Terrestrial Limbless  Locomotion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pierce%2C+C">Christopher Pierce</a>, 
<a href="/search/cs?searchtype=author&query=Kojouharov%2C+V">Velin Kojouharov</a>, 
<a href="/search/cs?searchtype=author&query=Chong%2C+B">Baxi Chong</a>, 
<a href="/search/cs?searchtype=author&query=Diaz%2C+K">Kelimar Diaz</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Goldman%2C+D+I">Daniel I. Goldman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Science Robotics
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sci. Robot. 8, eadi2243 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12588" title="Abstract">arXiv:2304.12588</a> (replaced) [<a href="/pdf/2304.12588" title="Download PDF">pdf</a>, <a href="/format/2304.12588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperproperty Verification as CHC Satisfiability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Itzhaky%2C+S">Shachar Itzhaky</a> (1), 
<a href="/search/cs?searchtype=author&query=Shoham%2C+S">Sharon Shoham</a> (2), 
<a href="/search/cs?searchtype=author&query=Vizel%2C+Y">Yakir Vizel</a> (1) ((1) Technion, (2) Tel-Aviv University)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13445" title="Abstract">arXiv:2304.13445</a> (replaced) [<a href="/pdf/2304.13445" title="Download PDF">pdf</a>, <a href="/format/2304.13445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural-PBIR Reconstruction of Shape, Material, and Illumination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Cheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+G">Guangyan Cai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhengqin Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+K">Kai Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Marshall%2C+C">Carl Marshall</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jia-Bin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shuang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhao Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023. Project page at <a href="https://neural-pbir.github.io/">this https URL</a> Update Stanford-ORB results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01710" title="Abstract">arXiv:2305.01710</a> (replaced) [<a href="/pdf/2305.01710" title="Download PDF">pdf</a>, <a href="/format/2305.01710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stars Are All You Need: A Distantly Supervised Pyramid Network for  Unified Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenchang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yixing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shuang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lalor%2C+J+P">John P. Lalor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 3 figures, 5 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> W-NUT 2024: The 9th Workshop on Noisy and User-generated Text (at
  EACL)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02930" title="Abstract">arXiv:2305.02930</a> (replaced) [<a href="/pdf/2305.02930" title="Download PDF">pdf</a>, <a href="/format/2305.02930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Piecewise Normalizing Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bevins%2C+H">Harry Bevins</a>, 
<a href="/search/stat?searchtype=author&query=Handley%2C+W">Will Handley</a>, 
<a href="/search/stat?searchtype=author&query=Gessey-Jones%2C+T">Thomas Gessey-Jones</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07181" title="Abstract">arXiv:2305.07181</a> (replaced) [<a href="/pdf/2305.07181" title="Download PDF">pdf</a>, <a href="/format/2305.07181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entropy-split multidimensional summation-by-parts discretization of the  Euler and compressible Navier-Stokes equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Worku%2C+Z+A">Zelalem Arega Worku</a>, 
<a href="/search/math?searchtype=author&query=Zingg%2C+D+W">David W. Zingg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07303" title="Abstract">arXiv:2305.07303</a> (replaced) [<a href="/pdf/2305.07303" title="Download PDF">pdf</a>, <a href="/format/2305.07303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Relational Hyperbolic Word Embeddings from Natural Language  Definitions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valentino%2C+M">Marco Valentino</a>, 
<a href="/search/cs?searchtype=author&query=Carvalho%2C+D+S">Danilo S. Carvalho</a>, 
<a href="/search/cs?searchtype=author&query=Freitas%2C+A">Andr&#xe9; Freitas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 18th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13514" title="Abstract">arXiv:2305.13514</a> (replaced) [<a href="/pdf/2305.13514" title="Download PDF">pdf</a>, <a href="/format/2305.13514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Small Language Models Improve Giants by Rewriting Their Outputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vernikos%2C+G">Giorgos Vernikos</a>, 
<a href="/search/cs?searchtype=author&query=Bra%C5%BEinskas%2C+A">Arthur Bra&#x17e;inskas</a>, 
<a href="/search/cs?searchtype=author&query=Adamek%2C+J">Jakub Adamek</a>, 
<a href="/search/cs?searchtype=author&query=Mallinson%2C+J">Jonathan Mallinson</a>, 
<a href="/search/cs?searchtype=author&query=Severyn%2C+A">Aliaksei Severyn</a>, 
<a href="/search/cs?searchtype=author&query=Malmi%2C+E">Eric Malmi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14163" title="Abstract">arXiv:2305.14163</a> (replaced) [<a href="/pdf/2305.14163" title="Download PDF">pdf</a>, <a href="/format/2305.14163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Open Information Extraction for More Robust Domain Transfer  of Event Trigger Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duki%C4%87%2C+D">David Duki&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Gashteovski%2C+K">Kiril Gashteovski</a>, 
<a href="/search/cs?searchtype=author&query=Glava%C5%A1%2C+G">Goran Glava&#x161;</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0najder%2C+J">Jan &#x160;najder</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EACL 2024 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16590" title="Abstract">arXiv:2305.16590</a> (replaced) [<a href="/pdf/2305.16590" title="Download PDF">pdf</a>, <a href="/format/2305.16590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seeding with Differentially Private Network Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahimian%2C+M+A">M. Amin Rahimian</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Fang-Yi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Hurtado%2C+C">Carlos Hurtado</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preliminary version in AAMAS 2023: <a href="https://dl.acm.org/doi/10.5555/3545946.3599081">this https URL</a> -- Code and data: <a href="https://github.com/aminrahimian/dp-inf-max">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computational Complexity (cs.CC); Multiagent Systems (cs.MA); Probability (math.PR); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17665" title="Abstract">arXiv:2305.17665</a> (replaced) [<a href="/pdf/2305.17665" title="Download PDF">pdf</a>, <a href="/format/2305.17665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Acceleration of stochastic gradient descent with momentum by averaging:  finite-sample rates and asymptotic normality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+K">Kejie Tang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weidong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yichen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18460" title="Abstract">arXiv:2305.18460</a> (replaced) [<a href="/pdf/2305.18460" title="Download PDF">pdf</a>, <a href="/format/2305.18460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimum Width of Leaky-ReLU Neural Networks for Uniform Universal  Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li&#x27;ang Li</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yifei Duan</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+G">Guanghua Ji</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yongqiang Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Include errata of the previous versions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00083" title="Abstract">arXiv:2306.00083</a> (replaced) [<a href="/pdf/2306.00083" title="Download PDF">pdf</a>, <a href="/format/2306.00083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bell sampling from quantum circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Hangleiter%2C+D">Dominik Hangleiter</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gullans%2C+M+J">Michael J. Gullans</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7+15 pages, 2 figures. Comments welcome. v2: corrected typos, added references v3: added results, improved proofs v4: extended noise analysis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Quantum Gases (cond-mat.quant-gas); Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00307" title="Abstract">arXiv:2306.00307</a> (replaced) [<a href="/pdf/2306.00307" title="Download PDF">pdf</a>, <a href="/format/2306.00307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Mini-Batch Method for Solving Nonlinear PDEs with Gaussian Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yang%2C+X">Xianjin Yang</a>, 
<a href="/search/math?searchtype=author&query=Owhadi%2C+H">Houman Owhadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01697" title="Abstract">arXiv:2306.01697</a> (replaced) [<a href="/pdf/2306.01697" title="Download PDF">pdf</a>, <a href="/format/2306.01697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MutateNN: Mutation Testing of Image Recognition Models Deployed on  Hardware Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Louloudakis%2C+N">Nikolaos Louloudakis</a>, 
<a href="/search/cs?searchtype=author&query=Gibson%2C+P">Perry Gibson</a>, 
<a href="/search/cs?searchtype=author&query=Cano%2C+J">Jos&#xe9; Cano</a>, 
<a href="/search/cs?searchtype=author&query=Rajan%2C+A">Ajitha Rajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Software Engineering (cs.SE); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01879" title="Abstract">arXiv:2306.01879</a> (replaced) [<a href="/pdf/2306.01879" title="Download PDF">pdf</a>, <a href="/format/2306.01879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting the Role of Language Priors in Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhiqiu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyue Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+D">Deepak Pathak</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengchuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ramanan%2C+D">Deva Ramanan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website: <a href="https://linzhiqiu.github.io/papers/visual_gpt_score/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03894" title="Abstract">arXiv:2306.03894</a> (replaced) [<a href="/pdf/2306.03894" title="Download PDF">pdf</a>, <a href="/format/2306.03894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fractals from Regular Behaviours
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmid%2C+T">Todd Schmid</a>, 
<a href="/search/cs?searchtype=author&query=Noquez%2C+V">Victoria Noquez</a>, 
<a href="/search/cs?searchtype=author&query=Moss%2C+L+S">Lawrence S. Moss</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Expanded and edited into a journal version. Submitted to the CALCO 2023 special issue of LMCS. (31 pages, 5 figures.)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04072" title="Abstract">arXiv:2306.04072</a> (replaced) [<a href="/pdf/2306.04072" title="Download PDF">pdf</a>, <a href="/format/2306.04072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Simple, High Quality Out-of-Distribution Detection with L2  Normalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haas%2C+J">Jarrod Haas</a>, 
<a href="/search/cs?searchtype=author&query=Yolland%2C+W">William Yolland</a>, 
<a href="/search/cs?searchtype=author&query=Rabus%2C+B">Bernhard Rabus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04817" title="Abstract">arXiv:2306.04817</a> (replaced) [<a href="/pdf/2306.04817" title="Download PDF">pdf</a>, <a href="/format/2306.04817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SiBBlInGS: Similarity-driven Building-Block Inference using Graphs  across States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Mudrik%2C+N">Noga Mudrik</a>, 
<a href="/search/stat?searchtype=author&query=Mishne%2C+G">Gal Mishne</a>, 
<a href="/search/stat?searchtype=author&query=Charles%2C+A+S">Adam S. Charles</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05028" title="Abstract">arXiv:2306.05028</a> (replaced) [<a href="/pdf/2306.05028" title="Download PDF">pdf</a>, <a href="/format/2306.05028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Condorcet Markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Airiau%2C+S">St&#xe9;phane Airiau</a>, 
<a href="/search/cs?searchtype=author&query=Dupuis%2C+N+K">Nicholas Kees Dupuis</a>, 
<a href="/search/cs?searchtype=author&query=Grossi%2C+D">Davide Grossi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05587" title="Abstract">arXiv:2306.05587</a> (replaced) [<a href="/pdf/2306.05587" title="Download PDF">pdf</a>, <a href="/format/2306.05587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MC-NN: An End-to-End Multi-Channel Neural Network Approach for  Predicting Influenza A Virus Hosts and Antigenic Types
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yanhua Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wojtczak%2C+D">Dominik Wojtczak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted version submitted to the SN Computer Science; Published in the SN Computer Science 2023; V1: minor updates were made to the Results section; V2: minor updates regarding data description
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08670" title="Abstract">arXiv:2306.08670</a> (replaced) [<a href="/pdf/2306.08670" title="Download PDF">pdf</a>, <a href="/format/2306.08670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Power of Populations in Decentralized Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lazarsfeld%2C+J">John Lazarsfeld</a>, 
<a href="/search/cs?searchtype=author&query=Alistarh%2C+D">Dan Alistarh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08731" title="Abstract">arXiv:2306.08731</a> (replaced) [<a href="/pdf/2306.08731" title="Download PDF">pdf</a>, <a href="/format/2306.08731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EPIC Fields: Marrying 3D Geometry and Video Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tschernezki%2C+V">Vadim Tschernezki</a>, 
<a href="/search/cs?searchtype=author&query=Darkhalil%2C+A">Ahmad Darkhalil</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhifan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Fouhey%2C+D">David Fouhey</a>, 
<a href="/search/cs?searchtype=author&query=Laina%2C+I">Iro Laina</a>, 
<a href="/search/cs?searchtype=author&query=Larlus%2C+D">Diane Larlus</a>, 
<a href="/search/cs?searchtype=author&query=Damen%2C+D">Dima Damen</a>, 
<a href="/search/cs?searchtype=author&query=Vedaldi%2C+A">Andrea Vedaldi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at NeurIPS 2023. 24 pages, 15 figures. Project Webpage: <a href="http://epic-kitchens.github.io/epic-fields">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11872" title="Abstract">arXiv:2306.11872</a> (replaced) [<a href="/pdf/2306.11872" title="Download PDF">pdf</a>, <a href="/format/2306.11872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Strategic Energy Storage Behaviors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bian%2C+Y">Yuexin Bian</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+N">Ningkun Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+Y">Yang Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+B">Bolun Xu</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+Y">Yuanyuan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by IEEE Transactions on Smart Grid, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13042" title="Abstract">arXiv:2306.13042</a> (replaced) [<a href="/pdf/2306.13042" title="Download PDF">pdf</a>, <a href="/format/2306.13042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysing Mechanisms for Virtual Channel Management in Low-Diameter  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cano%2C+A">Alejandro Cano</a>, 
<a href="/search/cs?searchtype=author&query=Camarero%2C+C">Crist&#xf3;bal Camarero</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez%2C+C">Carmen Mart&#xed;nez</a>, 
<a href="/search/cs?searchtype=author&query=Beivide%2C+R">Ram&#xf3;n Beivide</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15880" title="Abstract">arXiv:2306.15880</a> (replaced) [<a href="/pdf/2306.15880" title="Download PDF">pdf</a>, <a href="/format/2306.15880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Open Vocabulary Learning: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jianzong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangtai Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shilin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Haobo Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Henghui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yibo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xia Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiangning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+Y">Yunhai Tong</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xudong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+B">Bernard Ghanem</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE T-PAMI. Project page: <a href="https://github.com/jianzongwu/Awesome-Open-Vocabulary">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16958" title="Abstract">arXiv:2306.16958</a> (replaced) [<a href="/pdf/2306.16958" title="Download PDF">pdf</a>, <a href="/ps/2306.16958" title="Download PostScript">ps</a>, <a href="/format/2306.16958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifiability of Direct Effects from Summary Causal Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferreira%2C+S">Simon Ferreira</a>, 
<a href="/search/cs?searchtype=author&query=Assaad%2C+C+K">Charles K. Assaad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17658" title="Abstract">arXiv:2306.17658</a> (replaced) [<a href="/pdf/2306.17658" title="Download PDF">pdf</a>, <a href="/format/2306.17658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ODE Transformations of Nonlinear DAE Power Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kazma%2C+M+H">Mohamad H. Kazma</a>, 
<a href="/search/eess?searchtype=author&query=Taha%2C+A+F">Ahmad F. Taha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00373" title="Abstract">arXiv:2307.00373</a> (replaced) [<a href="/pdf/2307.00373" title="Download PDF">pdf</a>, <a href="/format/2307.00373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the notion of polynomial reach: a statistical application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cholaquidis%2C+A">Alejandro Cholaquidis</a>, 
<a href="/search/math?searchtype=author&query=Cuevas%2C+A">Antonio Cuevas</a>, 
<a href="/search/math?searchtype=author&query=Moreno%2C+L">Leonardo Moreno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03503" title="Abstract">arXiv:2307.03503</a> (replaced) [<a href="/pdf/2307.03503" title="Download PDF">pdf</a>, <a href="/format/2307.03503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A variant of the Raviart-Thomas method to handle smooth domains with  straight-edged triangles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bertrand%2C+F">Fleurianne Bertrand</a>, 
<a href="/search/math?searchtype=author&query=Ruas%2C+V">Vitoriano Ruas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The article being replaced was the first part of the same work, whose second part was another arXiv paper being removed. This version is a more compact one of the whole work, assembling both parts
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04308" title="Abstract">arXiv:2307.04308</a> (replaced) [<a href="/pdf/2307.04308" title="Download PDF">pdf</a>, <a href="/format/2307.04308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Cross-Table Masked Pretraining for Web Data Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+C">Chao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+G">Guoshan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haobo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Sai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Gang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Junbo Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WWW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07515" title="Abstract">arXiv:2307.07515</a> (replaced) [<a href="/pdf/2307.07515" title="Download PDF">pdf</a>, <a href="/ps/2307.07515" title="Download PostScript">ps</a>, <a href="/format/2307.07515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artificial intelligence is algorithmic mimicry: why artificial &quot;agents&quot;  are not (and won&#x27;t be) proper agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jaeger%2C+J">Johannes Jaeger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10034" title="Abstract">arXiv:2307.10034</a> (replaced) [<a href="/pdf/2307.10034" title="Download PDF">pdf</a>, <a href="/format/2307.10034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Validation of Modern JSON Schema: Formalization and Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Attouche%2C+L">Lyes Attouche</a>, 
<a href="/search/cs?searchtype=author&query=Baazizi%2C+M">Mohamed-Amine Baazizi</a>, 
<a href="/search/cs?searchtype=author&query=Colazzo%2C+D">Dario Colazzo</a>, 
<a href="/search/cs?searchtype=author&query=Ghelli%2C+G">Giorgio Ghelli</a>, 
<a href="/search/cs?searchtype=author&query=Sartiani%2C+C">Carlo Sartiani</a>, 
<a href="/search/cs?searchtype=author&query=Scherzinger%2C+S">Stefanie Scherzinger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11865" title="Abstract">arXiv:2307.11865</a> (replaced) [<a href="/pdf/2307.11865" title="Download PDF">pdf</a>, <a href="/format/2307.11865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CARTIER: Cartographic lAnguage Reasoning Targeted at Instruction  Execution for Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rivkin%2C+D">Dmitriy Rivkin</a>, 
<a href="/search/cs?searchtype=author&query=Kakodkar%2C+N">Nikhil Kakodkar</a>, 
<a href="/search/cs?searchtype=author&query=Hogan%2C+F">Francois Hogan</a>, 
<a href="/search/cs?searchtype=author&query=Baghi%2C+B+H">Bobak H. Baghi</a>, 
<a href="/search/cs?searchtype=author&query=Dudek%2C+G">Gregory Dudek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12233" title="Abstract">arXiv:2307.12233</a> (replaced) [<a href="/pdf/2307.12233" title="Download PDF">pdf</a>, <a href="/format/2307.12233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Consensus-based Reference Generation for the Regulation of  Open-Channel Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fabris%2C+M">Marco Fabris</a>, 
<a href="/search/eess?searchtype=author&query=Bellinazzi%2C+M+D">Marco D. Bellinazzi</a>, 
<a href="/search/eess?searchtype=author&query=Furlanetto%2C+A">Andrea Furlanetto</a>, 
<a href="/search/eess?searchtype=author&query=Cenedese%2C+A">Angelo Cenedese</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Access, vol. 12, pp. 14423-14436, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13149" title="Abstract">arXiv:2307.13149</a> (replaced) [<a href="/pdf/2307.13149" title="Download PDF">pdf</a>, <a href="/format/2307.13149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering interpretable elastoplasticity models via the neural  polynomial method enabled symbolic regressions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bahmani%2C+B">Bahador Bahmani</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+H+S">Hyoung Suk Suh</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">WaiChing Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13831" title="Abstract">arXiv:2307.13831</a> (replaced) [<a href="/pdf/2307.13831" title="Download PDF">pdf</a>, <a href="/format/2307.13831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relationship between Batch Size and Number of Steps Needed for Nonconvex  Optimization of Stochastic Gradient Descent using Armijo Line Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsukada%2C+Y">Yuki Tsukada</a>, 
<a href="/search/cs?searchtype=author&query=Iiduka%2C+H">Hideaki Iiduka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13903" title="Abstract">arXiv:2307.13903</a> (replaced) [<a href="/pdf/2307.13903" title="Download PDF">pdf</a>, <a href="/ps/2307.13903" title="Download PostScript">ps</a>, <a href="/format/2307.13903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Corruption-Robust Lipschitz Contextual Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuo%2C+S">Shiliang Zuo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ALT 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14117" title="Abstract">arXiv:2307.14117</a> (replaced) [<a href="/pdf/2307.14117" title="Download PDF">pdf</a>, <a href="/format/2307.14117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Implicit Feedback from Deployment Data in Dialogue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pang%2C+R+Y">Richard Yuanzhe Pang</a>, 
<a href="/search/cs?searchtype=author&query=Roller%2C+S">Stephen Roller</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+K">Kyunghyun Cho</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">He He</a>, 
<a href="/search/cs?searchtype=author&query=Weston%2C+J">Jason Weston</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00206" title="Abstract">arXiv:2308.00206</a> (replaced) [<a href="/pdf/2308.00206" title="Download PDF">pdf</a>, <a href="/format/2308.00206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthetic Skull CT Generation with Generative Adversarial Networks to  Train Deep Learning Models for Clinical Transcranial Ultrasound
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Naftchi-Ardebili%2C+K">Kasra Naftchi-Ardebili</a>, 
<a href="/search/eess?searchtype=author&query=Singh%2C+K">Karanpartap Singh</a>, 
<a href="/search/eess?searchtype=author&query=Pourabolghasem%2C+R">Reza Pourabolghasem</a>, 
<a href="/search/eess?searchtype=author&query=Ghanouni%2C+P">Pejman Ghanouni</a>, 
<a href="/search/eess?searchtype=author&query=Popelka%2C+G+R">Gerald R. Popelka</a>, 
<a href="/search/eess?searchtype=author&query=Pauly%2C+K+B">Kim Butts Pauly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02594" title="Abstract">arXiv:2308.02594</a> (replaced) [<a href="/pdf/2308.02594" title="Download PDF">pdf</a>, <a href="/format/2308.02594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SMARLA: A Safety Monitoring Approach for Deep Reinforcement Learning  Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zolfagharian%2C+A">Amirhossein Zolfagharian</a>, 
<a href="/search/cs?searchtype=author&query=Abdellatif%2C+M">Manel Abdellatif</a>, 
<a href="/search/cs?searchtype=author&query=Briand%2C+L+C">Lionel C. Briand</a>, 
<a href="/search/cs?searchtype=author&query=S%2C+R">Ramesh S</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05061" title="Abstract">arXiv:2308.05061</a> (replaced) [<a href="/pdf/2308.05061" title="Download PDF">pdf</a>, <a href="/format/2308.05061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Tune Language Models as Multi-Modal Differential Equation Solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Siting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Osher%2C+S+J">Stanley J. Osher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06377" title="Abstract">arXiv:2308.06377</a> (replaced) [<a href="/pdf/2308.06377" title="Download PDF">pdf</a>, <a href="/format/2308.06377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CATS v2: Hybrid encoders for robust medical segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+H">Han Liu</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+D">Dewei Hu</a>, 
<a href="/search/eess?searchtype=author&query=Yao%2C+X">Xing Yao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jiacheng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Oguz%2C+I">Ipek Oguz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07816" title="Abstract">arXiv:2308.07816</a> (replaced) [<a href="/pdf/2308.07816" title="Download PDF">pdf</a>, <a href="/format/2308.07816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedCache: A Knowledge Cache-driven Federated Learning Architecture for  Personalized Edge Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Sheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Min Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Ke Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xuefeng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+B">Bo Gao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jinda Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Mobile Computing (TMC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09668" title="Abstract">arXiv:2308.09668</a> (replaced) [<a href="/pdf/2308.09668" title="Download PDF">pdf</a>, <a href="/ps/2308.09668" title="Download PostScript">ps</a>, <a href="/format/2308.09668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing Direct Product Testing via Coboundary Expansion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bafna%2C+M">Mitali Bafna</a>, 
<a href="/search/cs?searchtype=author&query=Minzer%2C+D">Dor Minzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10263" title="Abstract">arXiv:2308.10263</a> (replaced) [<a href="/pdf/2308.10263" title="Download PDF">pdf</a>, <a href="/format/2308.10263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling up Discovery of Latent Concepts in Deep NLP Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hawasly%2C+M">Majd Hawasly</a>, 
<a href="/search/cs?searchtype=author&query=Dalvi%2C+F">Fahim Dalvi</a>, 
<a href="/search/cs?searchtype=author&query=Durrani%2C+N">Nadir Durrani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, accepted to The 18th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10974" title="Abstract">arXiv:2308.10974</a> (replaced) [<a href="/pdf/2308.10974" title="Download PDF">pdf</a>, <a href="/format/2308.10974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Guinea Pig Trials&quot; Utilizing GPT: A Novel Smart Agent-Based Modeling  Approach for Studying Firm Competition and Collusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xu Han</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zengqing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chuan Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Source code is available at: <a href="https://github.com/Roihn/SABM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computational Engineering, Finance, and Science (cs.CE); Multiagent Systems (cs.MA); General Economics (econ.GN)

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12063" title="Abstract">arXiv:2308.12063</a> (replaced) [<a href="/pdf/2308.12063" title="Download PDF">pdf</a>, <a href="/format/2308.12063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning the Plasticity: Plasticity-Driven Learning Framework in Spiking  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+G">Guobin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongcheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yiting Dong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Feifei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yi Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12264" title="Abstract">arXiv:2308.12264</a> (replaced) [<a href="/pdf/2308.12264" title="Download PDF">pdf</a>, <a href="/format/2308.12264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Energy-Awareness in Deep Learning through Fine-Grained Energy  Measurement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajput%2C+S">Saurabhsingh Rajput</a>, 
<a href="/search/cs?searchtype=author&query=Widmayer%2C+T">Tim Widmayer</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+Z">Ziyuan Shang</a>, 
<a href="/search/cs?searchtype=author&query=Kechagia%2C+M">Maria Kechagia</a>, 
<a href="/search/cs?searchtype=author&query=Sarro%2C+F">Federica Sarro</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+T">Tushar Sharma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Performance (cs.PF); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12950" title="Abstract">arXiv:2308.12950</a> (replaced) [<a href="/pdf/2308.12950" title="Download PDF">pdf</a>, <a href="/format/2308.12950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Code Llama: Open Foundation Models for Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rozi%C3%A8re%2C+B">Baptiste Rozi&#xe8;re</a>, 
<a href="/search/cs?searchtype=author&query=Gehring%2C+J">Jonas Gehring</a>, 
<a href="/search/cs?searchtype=author&query=Gloeckle%2C+F">Fabian Gloeckle</a>, 
<a href="/search/cs?searchtype=author&query=Sootla%2C+S">Sten Sootla</a>, 
<a href="/search/cs?searchtype=author&query=Gat%2C+I">Itai Gat</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X+E">Xiaoqing Ellen Tan</a>, 
<a href="/search/cs?searchtype=author&query=Adi%2C+Y">Yossi Adi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sauvestre%2C+R">Romain Sauvestre</a>, 
<a href="/search/cs?searchtype=author&query=Remez%2C+T">Tal Remez</a>, 
<a href="/search/cs?searchtype=author&query=Rapin%2C+J">J&#xe9;r&#xe9;my Rapin</a>, 
<a href="/search/cs?searchtype=author&query=Kozhevnikov%2C+A">Artyom Kozhevnikov</a>, 
<a href="/search/cs?searchtype=author&query=Evtimov%2C+I">Ivan Evtimov</a>, 
<a href="/search/cs?searchtype=author&query=Bitton%2C+J">Joanna Bitton</a>, 
<a href="/search/cs?searchtype=author&query=Bhatt%2C+M">Manish Bhatt</a>, 
<a href="/search/cs?searchtype=author&query=Ferrer%2C+C+C">Cristian Canton Ferrer</a>, 
<a href="/search/cs?searchtype=author&query=Grattafiori%2C+A">Aaron Grattafiori</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+W">Wenhan Xiong</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%A9fossez%2C+A">Alexandre D&#xe9;fossez</a>, 
<a href="/search/cs?searchtype=author&query=Copet%2C+J">Jade Copet</a>, 
<a href="/search/cs?searchtype=author&query=Azhar%2C+F">Faisal Azhar</a>, 
<a href="/search/cs?searchtype=author&query=Touvron%2C+H">Hugo Touvron</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+L">Louis Martin</a>, 
<a href="/search/cs?searchtype=author&query=Usunier%2C+N">Nicolas Usunier</a>, 
<a href="/search/cs?searchtype=author&query=Scialom%2C+T">Thomas Scialom</a>, 
<a href="/search/cs?searchtype=author&query=Synnaeve%2C+G">Gabriel Synnaeve</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00300" title="Abstract">arXiv:2309.00300</a> (replaced) [<a href="/pdf/2309.00300" title="Download PDF">pdf</a>, <a href="/format/2309.00300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards the Identifiability and Explainability for Personalized Learner  Modeling: An Inductive Paradigm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiatong Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiayu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhenya Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+F">Fangzhou Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Linbo Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yu Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Proceedings of the ACM Web Conference 2024 (WWW '24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02445" title="Abstract">arXiv:2309.02445</a> (replaced) [<a href="/e-print/2309.02445" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A fixed point approach for finding approximate solutions to second order  non-instantaneous impulsive abstract differential equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ansari%2C+S">Shahin Ansari</a>, 
<a href="/search/math?searchtype=author&query=Malik%2C+M">Muslim Malik</a>, 
<a href="/search/math?searchtype=author&query=Ali%2C+J">Javid Ali</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Significant changes have been made
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05915" title="Abstract">arXiv:2309.05915</a> (replaced) [<a href="/pdf/2309.05915" title="Download PDF">pdf</a>, <a href="/format/2309.05915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ACT: Empowering Decision Transformer with Dynamic Programming via  Advantage Conditioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chen-Xiao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+M">Mingjun Cao</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+R">Rui Kong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zongzhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yang Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07921" title="Abstract">arXiv:2309.07921</a> (replaced) [<a href="/pdf/2309.07921" title="Download PDF">pdf</a>, <a href="/format/2309.07921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenIllumination: A Multi-Illumination Dataset for Inverse Rendering  Evaluation on Real Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+I">Isabella Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Linghao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Z">Ziyang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Liwen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Haian Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+C+M+R">Chin Ming Ryan Wong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ramamoorthi%2C+R">Ravi Ramamoorthi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zexiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hao Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07973" title="Abstract">arXiv:2309.07973</a> (replaced) [<a href="/pdf/2309.07973" title="Download PDF">pdf</a>, <a href="/format/2309.07973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M3Dsynth: A dataset of medical 3D images with AI-generated local  manipulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zingarini%2C+G">Giada Zingarini</a>, 
<a href="/search/eess?searchtype=author&query=Cozzolino%2C+D">Davide Cozzolino</a>, 
<a href="/search/eess?searchtype=author&query=Corvi%2C+R">Riccardo Corvi</a>, 
<a href="/search/eess?searchtype=author&query=Poggi%2C+G">Giovanni Poggi</a>, 
<a href="/search/eess?searchtype=author&query=Verdoliva%2C+L">Luisa Verdoliva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11019" title="Abstract">arXiv:2309.11019</a> (replaced) [<a href="/pdf/2309.11019" title="Download PDF">pdf</a>, <a href="/ps/2309.11019" title="Download PostScript">ps</a>, <a href="/format/2309.11019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extractors for Polynomial Sources over $\mathbb{F}_2$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chattopadhyay%2C+E">Eshan Chattopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Goodman%2C+J">Jesse Goodman</a>, 
<a href="/search/cs?searchtype=author&query=Gurumukhani%2C+M">Mohit Gurumukhani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11268" title="Abstract">arXiv:2309.11268</a> (replaced) [<a href="/pdf/2309.11268" title="Download PDF">pdf</a>, <a href="/format/2309.11268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StructChart: Perception, Structuring, Reasoning for Visual Chart  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+R">Renqiu Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Haoyang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+N">Ning Liao</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+P">Peng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Botian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SimChart9K is available for downloading at: <a href="https://github.com/UniModal4Reasoning/SimChart9K">this https URL</a> 26 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13063" title="Abstract">arXiv:2309.13063</a> (replaced) [<a href="/pdf/2309.13063" title="Download PDF">pdf</a>, <a href="/format/2309.13063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Large Language Models to Generate, Validate, and Apply User Intent  Taxonomies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+C">Chirag Shah</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+R+W">Ryen W. White</a>, 
<a href="/search/cs?searchtype=author&query=Andersen%2C+R">Reid Andersen</a>, 
<a href="/search/cs?searchtype=author&query=Buscher%2C+G">Georg Buscher</a>, 
<a href="/search/cs?searchtype=author&query=Counts%2C+S">Scott Counts</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S+S+S">Sarkar Snigdha Sarathi Das</a>, 
<a href="/search/cs?searchtype=author&query=Montazer%2C+A">Ali Montazer</a>, 
<a href="/search/cs?searchtype=author&query=Manivannan%2C+S">Sathish Manivannan</a>, 
<a href="/search/cs?searchtype=author&query=Neville%2C+J">Jennifer Neville</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+X">Xiaochuan Ni</a>, 
<a href="/search/cs?searchtype=author&query=Rangan%2C+N">Nagu Rangan</a>, 
<a href="/search/cs?searchtype=author&query=Safavi%2C+T">Tara Safavi</a>, 
<a href="/search/cs?searchtype=author&query=Suri%2C+S">Siddharth Suri</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+M">Mengting Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Leijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Longqi Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13223" title="Abstract">arXiv:2309.13223</a> (replaced) [<a href="/pdf/2309.13223" title="Download PDF">pdf</a>, <a href="/format/2309.13223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Reasoning: Charting a Revolutionary Course for Next-Generation  AI-Native Wireless Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thomas%2C+C+K">Christo Kurisummoottil Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Chaccour%2C+C">Christina Chaccour</a>, 
<a href="/search/cs?searchtype=author&query=Saad%2C+W">Walid Saad</a>, 
<a href="/search/cs?searchtype=author&query=Debbah%2C+M">Merouane Debbah</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+C+S">Choong Seon Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14976" title="Abstract">arXiv:2309.14976</a> (replaced) [<a href="/pdf/2309.14976" title="Download PDF">pdf</a>, <a href="/format/2309.14976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoCaE: Mixture of Calibrated Experts Significantly Improves Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oksuz%2C+K">Kemal Oksuz</a>, 
<a href="/search/cs?searchtype=author&query=Kuzucu%2C+S">Selim Kuzucu</a>, 
<a href="/search/cs?searchtype=author&query=Joy%2C+T">Tom Joy</a>, 
<a href="/search/cs?searchtype=author&query=Dokania%2C+P+K">Puneet K. Dokania</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00113" title="Abstract">arXiv:2310.00113</a> (replaced) [<a href="/pdf/2310.00113" title="Download PDF">pdf</a>, <a href="/format/2310.00113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperMask: Adaptive Hypernetwork-based Masks for Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ksi%C4%85%C5%BCek%2C+K">Kamil Ksi&#x105;&#x17c;ek</a>, 
<a href="/search/cs?searchtype=author&query=Spurek%2C+P">Przemys&#x142;aw Spurek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00533" title="Abstract">arXiv:2310.00533</a> (replaced) [<a href="/pdf/2310.00533" title="Download PDF">pdf</a>, <a href="/format/2310.00533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SELF: Self-Evolution with Language Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jianqiao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+W">Wanjun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenyong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+F">Fei Mi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baojun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weichao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xingshan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+L">Lifeng Shang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qun Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 4 figures, 11 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00692" title="Abstract">arXiv:2310.00692</a> (replaced) [<a href="/pdf/2310.00692" title="Download PDF">pdf</a>, <a href="/format/2310.00692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Theoretical Analysis of Noise Geometry in Stochastic Gradient Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mingze Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lei Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01796" title="Abstract">arXiv:2310.01796</a> (replaced) [<a href="/pdf/2310.01796" title="Download PDF">pdf</a>, <a href="/format/2310.01796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LILAC: Log Parsing using LLMs with Adaptive Parsing Cache
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhihan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuangbin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yichen Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Junjie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+Y">Yintong Huo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+P">Pinjia He</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiazhen Gu</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+M+R">Michael R. Lyu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted by The ACM International Conference on the Foundations of Software Engineering (FSE 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01967" title="Abstract">arXiv:2310.01967</a> (replaced) [<a href="/pdf/2310.01967" title="Download PDF">pdf</a>, <a href="/format/2310.01967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Active SLAM: Synchronous and Asynchronous Coordination  Among Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maragliano%2C+M">Matteo Maragliano</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+M+F">Muhammad Farhan Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Recchiuto%2C+C+T">Carmine Tommaso Recchiuto</a>, 
<a href="/search/cs?searchtype=author&query=Sgorbissa%2C+A">Antonio Sgorbissa</a>, 
<a href="/search/cs?searchtype=author&query=Fremont%2C+V">Vincent Fremont</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02592" title="Abstract">arXiv:2310.02592</a> (replaced) [<a href="/pdf/2310.02592" title="Download PDF">pdf</a>, <a href="/ps/2310.02592" title="Download PostScript">ps</a>, <a href="/format/2310.02592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Faster Deterministic Approximation Algorithm for TTP-2
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanaya%2C+Y">Yuga Kanaya</a>, 
<a href="/search/cs?searchtype=author&query=Takazawa%2C+K">Kenjiro Takazawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 42 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02982" title="Abstract">arXiv:2310.02982</a> (replaced) [<a href="/pdf/2310.02982" title="Download PDF">pdf</a>, <a href="/format/2310.02982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are LLMs Useful in the Poorest Schools? TheTeacher.AI in Sierra Leone
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+J+H">Jun Ho Choi</a>, 
<a href="/search/cs?searchtype=author&query=Garrod%2C+O">Oliver Garrod</a>, 
<a href="/search/cs?searchtype=author&query=Atherton%2C+P">Paul Atherton</a>, 
<a href="/search/cs?searchtype=author&query=Joyce-Gibbons%2C+A">Andrew Joyce-Gibbons</a>, 
<a href="/search/cs?searchtype=author&query=Mason-Sesay%2C+M">Miriam Mason-Sesay</a>, 
<a href="/search/cs?searchtype=author&query=Bj%C3%B6rkegren%2C+D">Daniel Bj&#xf6;rkegren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04915" title="Abstract">arXiv:2310.04915</a> (replaced) [<a href="/e-print/2310.04915" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Accelerating Diffusion-based Molecular Conformation Generation in  SE(3)-invariant Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Zhou%2C+Z">Zihan Zhou</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+R">Ruiying Liu</a>, 
<a href="/search/physics?searchtype=author&query=Yu%2C+T">Tianshu Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We are currently developing a new manuscript that significantly expands upon and integrates the research presented here. The forthcoming paper includes broader analyses and more comprehensive findings, rendering the current version obsolete. We believe this decision will contribute to a clearer and more consolidated presentation of our research findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05866" title="Abstract">arXiv:2310.05866</a> (replaced) [<a href="/pdf/2310.05866" title="Download PDF">pdf</a>, <a href="/format/2310.05866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative quantum machine learning via denoising diffusion  probabilistic models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+B">Bingzhi Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Xu%2C+P">Peng Xu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+X">Xiaohui Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhuang%2C+Q">Quntao Zhuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5+10 pages, 16 figures. PRL accepted version. Code available at: <a href="https://github.com/francis-hsu/quantgenmdl">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05873" title="Abstract">arXiv:2310.05873</a> (replaced) [<a href="/pdf/2310.05873" title="Download PDF">pdf</a>, <a href="/format/2310.05873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Concept Removal of Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhili Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jianhua Han</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Lanqing Hong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+D">Dit-Yan Yeung</a>, 
<a href="/search/cs?searchtype=author&query=Kwok%2C+J">James Kwok</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07713" title="Abstract">arXiv:2310.07713</a> (replaced) [<a href="/pdf/2310.07713" title="Download PDF">pdf</a>, <a href="/format/2310.07713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Boxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ping%2C+W">Wei Ping</a>, 
<a href="/search/cs?searchtype=author&query=McAfee%2C+L">Lawrence McAfee</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Peng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Shoeybi%2C+M">Mohammad Shoeybi</a>, 
<a href="/search/cs?searchtype=author&query=Catanzaro%2C+B">Bryan Catanzaro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09971" title="Abstract">arXiv:2310.09971</a> (replaced) [<a href="/pdf/2310.09971" title="Download PDF">pdf</a>, <a href="/format/2310.09971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AMAGO: Scalable In-Context Reinforcement Learning for Adaptive Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grigsby%2C+J">Jake Grigsby</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Linxi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuke Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10688" title="Abstract">arXiv:2310.10688</a> (replaced) [<a href="/pdf/2310.10688" title="Download PDF">pdf</a>, <a href="/format/2310.10688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A decoder-only foundation model for time-series forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Abhimanyu Das</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+W">Weihao Kong</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+R">Rajat Sen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yichen Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10899" title="Abstract">arXiv:2310.10899</a> (replaced) [<a href="/pdf/2310.10899" title="Download PDF">pdf</a>, <a href="/format/2310.10899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instilling Inductive Biases with Subnetworks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Enyan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lepori%2C+M+A">Michael A. Lepori</a>, 
<a href="/search/cs?searchtype=author&query=Pavlick%2C+E">Ellie Pavlick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11798" title="Abstract">arXiv:2310.11798</a> (replaced) [<a href="/pdf/2310.11798" title="Download PDF">pdf</a>, <a href="/format/2310.11798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auction-Based Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Avni%2C+G">Guy Avni</a>, 
<a href="/search/cs?searchtype=author&query=Mallik%2C+K">Kaushik Mallik</a>, 
<a href="/search/cs?searchtype=author&query=Sadhukhan%2C+S">Suman Sadhukhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of a paper accepted at TACAS'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Formal Languages and Automata Theory (cs.FL); Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13167" title="Abstract">arXiv:2310.13167</a> (replaced) [<a href="/pdf/2310.13167" title="Download PDF">pdf</a>, <a href="/format/2310.13167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visualizing Causality in Mixed Reality for Manual Task Learning: An  Exploratory Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+R">Rahul Jain</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jingyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Benton%2C+A">Andrew Benton</a>, 
<a href="/search/cs?searchtype=author&query=Rasheed%2C+M">Moiz Rasheed</a>, 
<a href="/search/cs?searchtype=author&query=Doh%2C+H">Hyungjun Doh</a>, 
<a href="/search/cs?searchtype=author&query=Chidambaram%2C+S">Subramanian Chidambaram</a>, 
<a href="/search/cs?searchtype=author&query=Ramani%2C+K">Karthik Ramani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17496" title="Abstract">arXiv:2310.17496</a> (replaced) [<a href="/pdf/2310.17496" title="Download PDF">pdf</a>, <a href="/format/2310.17496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tackling Interference Induced by Data Training Loops in A/B Tests: A  Weighted Training Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Si%2C+N">Nian Si</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Econometrics (econ.EM)

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18001" title="Abstract">arXiv:2310.18001</a> (replaced) [<a href="/pdf/2310.18001" title="Download PDF">pdf</a>, <a href="/format/2310.18001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DP-SGD with weight clipping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barczewski%2C+A">Antoine Barczewski</a>, 
<a href="/search/cs?searchtype=author&query=Ramon%2C+J">Jan Ramon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18043" title="Abstract">arXiv:2310.18043</a> (replaced) [<a href="/pdf/2310.18043" title="Download PDF">pdf</a>, <a href="/format/2310.18043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interior Eigensolver Based on Rational Filter with Composite rule
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+Y">Yuer Chen</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+Y">Yingzhou Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages,20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19390" title="Abstract">arXiv:2310.19390</a> (replaced) [<a href="/pdf/2310.19390" title="Download PDF">pdf</a>, <a href="/format/2310.19390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Manifold Gaussian Process Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Fichera%2C+B">Bernardo Fichera</a>, 
<a href="/search/stat?searchtype=author&query=Borovitskiy%2C+V">Viacheslav Borovitskiy</a>, 
<a href="/search/stat?searchtype=author&query=Krause%2C+A">Andreas Krause</a>, 
<a href="/search/stat?searchtype=author&query=Billard%2C+A">Aude Billard</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Advances in Neural Information Processing Systems, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20008" title="Abstract">arXiv:2310.20008</a> (replaced) [<a href="/pdf/2310.20008" title="Download PDF">pdf</a>, <a href="/format/2310.20008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolutionary Tabletop Game Design: A Case Study in the Risk Game
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rossato%2C+L+B">Lana Bertoldo Rossato</a>, 
<a href="/search/cs?searchtype=author&query=Bombardelli%2C+L+B">Leonardo Boaventura Bombardelli</a>, 
<a href="/search/cs?searchtype=author&query=Tavares%2C+A+R">Anderson Rocha Tavares</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in the 22nd Brazilian Symposium on Games and Digital Entertainment (SBGames 2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 22nd Brazilian Symposium on Computer Games and Digital
  Entertainment (SBGames 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00241" title="Abstract">arXiv:2311.00241</a> (replaced) [<a href="/pdf/2311.00241" title="Download PDF">pdf</a>, <a href="/format/2311.00241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 1DFormer: a Transformer Architecture Learning 1D Landmark  Representations for Facial Landmark Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+S">Shi Yin</a>, 
<a href="/search/cs?searchtype=author&query=Huan%2C+S">Shijie Huan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shangfei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jinshui Hu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Tao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+B">Bing Yin</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+B">Baocai Yin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02546" title="Abstract">arXiv:2311.02546</a> (replaced) [<a href="/pdf/2311.02546" title="Download PDF">pdf</a>, <a href="/ps/2311.02546" title="Download PostScript">ps</a>, <a href="/format/2311.02546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Second-Order Convergence of Biased Policy Gradient Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mu%2C+S">Siqiao Mu</a>, 
<a href="/search/cs?searchtype=author&query=Klabjan%2C+D">Diego Klabjan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03076" title="Abstract">arXiv:2311.03076</a> (replaced) [<a href="/pdf/2311.03076" title="Download PDF">pdf</a>, <a href="/format/2311.03076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SugarViT -- Multi-objective Regression of UAV Images with Vision  Transformers and Deep Label Distribution Learning Demonstrated on Disease  Severity Prediction in Sugar Beet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C3%BCnder%2C+M">Maurice G&#xfc;nder</a>, 
<a href="/search/cs?searchtype=author&query=Yamati%2C+F+R+I">Facundo Ram&#xf3;n Ispizua Yamati</a>, 
<a href="/search/cs?searchtype=author&query=Alc%C3%A1ntara%2C+A+A+B">Abel Andree Barreto Alc&#xe1;ntara</a>, 
<a href="/search/cs?searchtype=author&query=Mahlein%2C+A">Anne-Katrin Mahlein</a>, 
<a href="/search/cs?searchtype=author&query=Sifa%2C+R">Rafet Sifa</a>, 
<a href="/search/cs?searchtype=author&query=Bauckhage%2C+C">Christian Bauckhage</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to Computers and Electronics in Agriculture
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05085" title="Abstract">arXiv:2311.05085</a> (replaced) [<a href="/pdf/2311.05085" title="Download PDF">pdf</a>, <a href="/format/2311.05085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing Large Language Models as Rationalizers of  Knowledge-intensive Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+A">Aditi Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+S">Sajjadur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hannah Kim</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+K">Kushan Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Hruschka%2C+E">Estevam Hruschka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05739" title="Abstract">arXiv:2311.05739</a> (replaced) [<a href="/pdf/2311.05739" title="Download PDF">pdf</a>, <a href="/format/2311.05739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Compression-Aware Split Learning and Inference for Enhanced  Network Efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mudvari%2C+A">Akrit Mudvari</a>, 
<a href="/search/cs?searchtype=author&query=Vainio%2C+A">Antero Vainio</a>, 
<a href="/search/cs?searchtype=author&query=Ofeidis%2C+I">Iason Ofeidis</a>, 
<a href="/search/cs?searchtype=author&query=Tarkoma%2C+S">Sasu Tarkoma</a>, 
<a href="/search/cs?searchtype=author&query=Tassiulas%2C+L">Leandros Tassiulas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06861" title="Abstract">arXiv:2311.06861</a> (replaced) [<a href="/pdf/2311.06861" title="Download PDF">pdf</a>, <a href="/format/2311.06861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-efficient Beamforming for RISs-aided Communications: Gradient  Based Meta Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinquan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Fenghao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qianyun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qihao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chongwen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Alhammadi%2C+A">Ahmed Alhammadi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yuen%2C+C">Chau Yuen</a>, 
<a href="/search/cs?searchtype=author&query=Debbah%2C+M">M&#xe9;rouane Debbah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 8 figures. Accepted in IEEE ICC 2024 (GCSN symposium)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09680" title="Abstract">arXiv:2311.09680</a> (replaced) [<a href="/pdf/2311.09680" title="Download PDF">pdf</a>, <a href="/format/2311.09680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trustworthy Large Models in Vision: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Ziyan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Li Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10776" title="Abstract">arXiv:2311.10776</a> (replaced) [<a href="/pdf/2311.10776" title="Download PDF">pdf</a>, <a href="/format/2311.10776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chemist-X: Large Language Model-empowered Agent for Reaction Condition  Recommendation in Chemical Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kexin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junyou Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kunyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yuyang Du</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiahui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiamin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lanqing Li</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jiezhong Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jianzhang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Q">Qun Fang</a>, 
<a href="/search/cs?searchtype=author&query=Heng%2C+P+A">Pheng Ann Heng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guangyong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11482" title="Abstract">arXiv:2311.11482</a> (replaced) [<a href="/pdf/2311.11482" title="Download PDF">pdf</a>, <a href="/format/2311.11482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta Prompting for AGI Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+A+C">Andrew Chi-Chih Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13209" title="Abstract">arXiv:2311.13209</a> (replaced) [<a href="/pdf/2311.13209" title="Download PDF">pdf</a>, <a href="/format/2311.13209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Test-time Adaptive Vision-and-Language Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Junyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xuan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Changsheng Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13590" title="Abstract">arXiv:2311.13590</a> (replaced) [<a href="/pdf/2311.13590" title="Download PDF">pdf</a>, <a href="/format/2311.13590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Triangle-free $2$-matchings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paluch%2C+K">Katarzyna Paluch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A more polished version and a clearer explanation of \Delta-diminishing hinges and 1-vulnerable triangles
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16136" title="Abstract">arXiv:2311.16136</a> (replaced) [<a href="/pdf/2311.16136" title="Download PDF">pdf</a>, <a href="/format/2311.16136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ERASER: Machine Unlearning in MLaaS via an Inference Serving-Aware  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yuke Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+J">Jian Lou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+W">Wangze Ni</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+F">Feng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+K">Kui Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18826" title="Abstract">arXiv:2311.18826</a> (replaced) [<a href="/pdf/2311.18826" title="Download PDF">pdf</a>, <a href="/format/2311.18826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometry-Aware Normalizing Wasserstein Flows for Optimal Causal  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+K">Kaiwen Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00134" title="Abstract">arXiv:2312.00134</a> (replaced) [<a href="/pdf/2312.00134" title="Download PDF">pdf</a>, <a href="/format/2312.00134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Markovian Embeddings of Non-Markovian Quantum Systems: Coupled  Stochastic and Quantum Master Equations for Non-Markovian Quantum Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Nurdin%2C+H+I">Hendra I. Nurdin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures. Minor typo corrected on p. 2 column 1 para 3: need should be need not. Published in Proceedings of the 62nd IEEE Conference on Decision and Control (Singapore, Dec. 12-15) pp. 5939-5944 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00526" title="Abstract">arXiv:2312.00526</a> (replaced) [<a href="/pdf/2312.00526" title="Download PDF">pdf</a>, <a href="/ps/2312.00526" title="Download PostScript">ps</a>, <a href="/format/2312.00526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated design space exploration for poultry processing systems using  discrete-event simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Paape%2C+N">Nick Paape</a>, 
<a href="/search/eess?searchtype=author&query=van+Eekelen%2C+J">Joost van Eekelen</a>, 
<a href="/search/eess?searchtype=author&query=Reniers%2C+M">Michel Reniers</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Food Engineering, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01057" title="Abstract">arXiv:2312.01057</a> (replaced) [<a href="/pdf/2312.01057" title="Download PDF">pdf</a>, <a href="/format/2312.01057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RLHF and IIA: Perverse Incentives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wanqiao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Shi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiuyuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+G">Grace Lam</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Zheng Wen</a>, 
<a href="/search/cs?searchtype=author&query=Van+Roy%2C+B">Benjamin Van Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01804" title="Abstract">arXiv:2312.01804</a> (replaced) [<a href="/pdf/2312.01804" title="Download PDF">pdf</a>, <a href="/ps/2312.01804" title="Download PostScript">ps</a>, <a href="/format/2312.01804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimizing Maximum Dissatisfaction in the Allocation of Indivisible  Items under a Common Preference Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chiarelli%2C+N">Nina Chiarelli</a>, 
<a href="/search/cs?searchtype=author&query=Dallard%2C+C">Cl&#xe9;ment Dallard</a>, 
<a href="/search/cs?searchtype=author&query=Darmann%2C+A">Andreas Darmann</a>, 
<a href="/search/cs?searchtype=author&query=Lendl%2C+S">Stefan Lendl</a>, 
<a href="/search/cs?searchtype=author&query=Milani%C4%8D%2C+M">Martin Milani&#x10d;</a>, 
<a href="/search/cs?searchtype=author&query=Mur%C5%A1i%C4%8D%2C+P">Peter Mur&#x161;i&#x10d;</a>, 
<a href="/search/cs?searchtype=author&query=Pferschy%2C+U">Ulrich Pferschy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04916" title="Abstract">arXiv:2312.04916</a> (replaced) [<a href="/pdf/2312.04916" title="Download PDF">pdf</a>, <a href="/format/2312.04916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EE-LLM: Large-Scale Training and Inference of Early-Exit Large Language  Models with 3D Parallelism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yanxi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xuchen Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+B">Bolin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv v2 update: extended related works and formal analysis of training efficiency. We will continuously update the codebase and arXiv version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06643" title="Abstract">arXiv:2312.06643</a> (replaced) [<a href="/pdf/2312.06643" title="Download PDF">pdf</a>, <a href="/format/2312.06643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaze Detection and Analysis for Initiating Joint Activity in Industrial  Human-Robot Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prajod%2C+P">Pooja Prajod</a>, 
<a href="/search/cs?searchtype=author&query=Nicora%2C+M+L">Matteo Lavit Nicora</a>, 
<a href="/search/cs?searchtype=author&query=Mondellini%2C+M">Marta Mondellini</a>, 
<a href="/search/cs?searchtype=author&query=Tauro%2C+G">Giovanni Tauro</a>, 
<a href="/search/cs?searchtype=author&query=Vertechy%2C+R">Rocco Vertechy</a>, 
<a href="/search/cs?searchtype=author&query=Malosio%2C+M">Matteo Malosio</a>, 
<a href="/search/cs?searchtype=author&query=Andr%C3%A9%2C+E">Elisabeth Andr&#xe9;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First draft for a paper submitted to Frontiers in Robotics and AI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08984" title="Abstract">arXiv:2312.08984</a> (replaced) [<a href="/pdf/2312.08984" title="Download PDF">pdf</a>, <a href="/format/2312.08984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CL2CM: Improving Cross-Lingual Cross-Modal Retrieval via Cross-Lingual  Knowledge Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yabing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jianfeng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Hao Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09098" title="Abstract">arXiv:2312.09098</a> (replaced) [<a href="/e-print/2312.09098" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A variant of the Raviart-Thomas method to handle smooth domains using  straight-edged triangles. Part II -- Approximation results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bertrand%2C+F">Fleurianne Bertrand</a>, 
<a href="/search/math?searchtype=author&query=Ruas%2C+V">Vitoriano Ruas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article is Part II of the same work together with Part I thereof, namely, <a href="/abs/2307.03503">arXiv:2307.03503</a>. It is being withdrawn because we authors decided to assemble both parts into a single article, which is being posted to this platform as a replacement of the latter (Part I)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12677" title="Abstract">arXiv:2312.12677</a> (replaced) [<a href="/pdf/2312.12677" title="Download PDF">pdf</a>, <a href="/format/2312.12677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synchronous Consensus in Partial Synchrony
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klianev%2C+I">Ivan Klianev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12839" title="Abstract">arXiv:2312.12839</a> (replaced) [<a href="/pdf/2312.12839" title="Download PDF">pdf</a>, <a href="/format/2312.12839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Machine Learning Algorithms by Union-Free Generic Depth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blocher%2C+H">Hannah Blocher</a>, 
<a href="/search/cs?searchtype=author&query=Schollmeyer%2C+G">Georg Schollmeyer</a>, 
<a href="/search/cs?searchtype=author&query=Nalenz%2C+M">Malte Nalenz</a>, 
<a href="/search/cs?searchtype=author&query=Jansen%2C+C">Christoph Jansen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2304.09872">arXiv:2304.09872</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13527" title="Abstract">arXiv:2312.13527</a> (replaced) [<a href="/pdf/2312.13527" title="Download PDF">pdf</a>, <a href="/format/2312.13527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MindOpt Adapter for CPLEX Benchmarking Performance Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mou Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tao Li</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wotao Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Software (cs.MS)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13649" title="Abstract">arXiv:2312.13649</a> (replaced) [<a href="/pdf/2312.13649" title="Download PDF">pdf</a>, <a href="/format/2312.13649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Smart Highway to Babel: the coexistence of different generations of  Intelligent Transport Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amador%2C+O">Oscar Amador</a>, 
<a href="/search/cs?searchtype=author&query=Soto%2C+I">Ignacio Soto</a>, 
<a href="/search/cs?searchtype=author&query=Calderon%2C+M">Maria Calderon</a>, 
<a href="/search/cs?searchtype=author&query=Urue%C3%B1a%2C+M">Manuel Urue&#xf1;a</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted version to Vehicular 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14232" title="Abstract">arXiv:2312.14232</a> (replaced) [<a href="/pdf/2312.14232" title="Download PDF">pdf</a>, <a href="/format/2312.14232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parrot Captions Teach CLIP to Spot Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yiqi Lin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A+J">Alex Jinpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weijia Li</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page: <a href="https://linyq17.github.io/CLIP-Parrot-Bias/.">this https URL</a> Add more analysis and ablation studies. Update Figure 3 with a more precise metric
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15488" title="Abstract">arXiv:2312.15488</a> (replaced) [<a href="/pdf/2312.15488" title="Download PDF">pdf</a>, <a href="/format/2312.15488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Zeta ($&#x3b6;$) Notation for Complex Asymptotes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dutta%2C+A">Anurag Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Lakshmanan%2C+K">K. Lakshmanan</a>, 
<a href="/search/cs?searchtype=author&query=Harshith%2C+J">John Harshith</a>, 
<a href="/search/cs?searchtype=author&query=Ramamoorthy%2C+A">A. Ramamoorthy</a>, 
<a href="/search/cs?searchtype=author&query=Pradeep%2C+C">C. Pradeep</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+P+K">Pijush Kanti Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16815" title="Abstract">arXiv:2312.16815</a> (replaced) [<a href="/pdf/2312.16815" title="Download PDF">pdf</a>, <a href="/format/2312.16815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergence and Causality in Complex Systems: A Survey on Causal Emergence  and Related Quantitative Studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Yuan%2C+B">Bing Yuan</a>, 
<a href="/search/physics?searchtype=author&query=Jiang%2C+Z">Zhang Jiang</a>, 
<a href="/search/physics?searchtype=author&query=Lyu%2C+A">Aobo Lyu</a>, 
<a href="/search/physics?searchtype=author&query=Wu%2C+J">Jiayun Wu</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+Z">Zhipeng Wang</a>, 
<a href="/search/physics?searchtype=author&query=Yang%2C+M">Mingzhe Yang</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+K">Kaiwei Liu</a>, 
<a href="/search/physics?searchtype=author&query=Mou%2C+M">Muyun Mou</a>, 
<a href="/search/physics?searchtype=author&query=Cui%2C+P">Peng Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 57 pages, 17 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Artificial Intelligence (cs.AI); Adaptation and Self-Organizing Systems (nlin.AO)

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16868" title="Abstract">arXiv:2312.16868</a> (replaced) [<a href="/pdf/2312.16868" title="Download PDF">pdf</a>, <a href="/format/2312.16868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pareto-based Multi-Objective Recommender System with Forgetting Curve
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jipeng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoxiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiaofeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiongwen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Lei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jie Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17429" title="Abstract">arXiv:2312.17429</a> (replaced) [<a href="/pdf/2312.17429" title="Download PDF">pdf</a>, <a href="/format/2312.17429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Commonsense for Zero-Shot Natural Language Video Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Holla%2C+M">Meghana Holla</a>, 
<a href="/search/cs?searchtype=author&query=Lourentzou%2C+I">Ismini Lourentzou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01472" title="Abstract">arXiv:2401.01472</a> (replaced) [<a href="/pdf/2401.01472" title="Download PDF">pdf</a>, <a href="/format/2401.01472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A First Look at Information Highlighting in Stack Overflow Answers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S+S">Shahla Shaan Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shaowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Tse-Hsun">Tse-Hsun</a> (Peter)
<a href="/search/cs?searchtype=author&query=Chen">Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoxiang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is submitted to Information and Software Technology Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02265" title="Abstract">arXiv:2401.02265</a> (replaced) [<a href="/pdf/2401.02265" title="Download PDF">pdf</a>, <a href="/format/2401.02265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breeding protocols are advantageous for finite-length entanglement  distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Matsumoto%2C+R">Ryutaroh Matsumoto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, latex2e, no figure, 1 table, v2 added the two important citations (see the acknowledgment)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02814" title="Abstract">arXiv:2401.02814</a> (replaced) [<a href="/pdf/2401.02814" title="Download PDF">pdf</a>, <a href="/format/2401.02814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object-Centric Instruction Augmentation for Robotic Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Junjie Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yichen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Minjie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinming Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiyuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+Z">Zhengping Che</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chaomin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yaxin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Feifei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jian Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to ICRA2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03140" title="Abstract">arXiv:2401.03140</a> (replaced) [<a href="/pdf/2401.03140" title="Download PDF">pdf</a>, <a href="/format/2401.03140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Sampling in Diffusion Models through Switching Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yujin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jinseong Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hoki Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaewook Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Saeroom Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03661" title="Abstract">arXiv:2401.03661</a> (replaced) [<a href="/pdf/2401.03661" title="Download PDF">pdf</a>, <a href="/format/2401.03661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GrainGNN: A dynamic graph neural network for predicting 3D grain  microstructure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yigong Qin</a>, 
<a href="/search/cs?searchtype=author&query=DeWitt%2C+S">Stephen DeWitt</a>, 
<a href="/search/cs?searchtype=author&query=Radhakrishnan%2C+B">Balasubramaniam Radhakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Biros%2C+G">George Biros</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04181" title="Abstract">arXiv:2401.04181</a> (replaced) [<a href="/pdf/2401.04181" title="Download PDF">pdf</a>, <a href="/format/2401.04181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language-Conditioned Robotic Manipulation with Fast and Slow Thinking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Minjie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yichen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinming Li</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Junjie Wen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiyuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+Z">Zhengping Che</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chaomin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yaxin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Feifei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jian Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to ICRA2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04964" title="Abstract">arXiv:2401.04964</a> (replaced) [<a href="/pdf/2401.04964" title="Download PDF">pdf</a>, <a href="/ps/2401.04964" title="Download PostScript">ps</a>, <a href="/format/2401.04964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised speech representation and contextual text embedding for  match-mismatch classification with EEG recording
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+B">Bo Wang</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+X">Xiran Xu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zechen Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+H">Haolin Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+Y">YuJie Yan</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+X">Xihong Wu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jing Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages, 2 figures, accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05578" title="Abstract">arXiv:2401.05578</a> (replaced) [<a href="/e-print/2401.05578" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Cerebral Blood Flow Analysis via Extreme Learning Machine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zang%2C+Z">Zhenya Zang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingda Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Not ready to submission. Need further correction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05580" title="Abstract">arXiv:2401.05580</a> (replaced) [<a href="/e-print/2401.05580" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Blood Flow Assessment in Diffuse Correlation Spectroscopy: A  Transfer Learning Approach with Noise Robustness Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingda Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Not ready for submission. Need further changes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05821" title="Abstract">arXiv:2401.05821</a> (replaced) [<a href="/pdf/2401.05821" title="Download PDF">pdf</a>, <a href="/format/2401.05821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable Concept Bottlenecks to Align Reinforcement Learning Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delfosse%2C+Q">Quentin Delfosse</a>, 
<a href="/search/cs?searchtype=author&query=Sztwiertnia%2C+S">Sebastian Sztwiertnia</a>, 
<a href="/search/cs?searchtype=author&query=Rothermel%2C+M">Mark Rothermel</a>, 
<a href="/search/cs?searchtype=author&query=Stammer%2C+W">Wolfgang Stammer</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 8 of main text, 8 of appendix, 3 main figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Symbolic Computation (cs.SC)

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06034" title="Abstract">arXiv:2401.06034</a> (replaced) [<a href="/pdf/2401.06034" title="Download PDF">pdf</a>, <a href="/format/2401.06034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LinguAlchemy: Fusing Typological and Geographical Elements for Unseen  Language Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adilazuarda%2C+M+F">Muhammad Farid Adilazuarda</a>, 
<a href="/search/cs?searchtype=author&query=Cahyawijaya%2C+S">Samuel Cahyawijaya</a>, 
<a href="/search/cs?searchtype=author&query=Aji%2C+A+F">Alham Fikri Aji</a>, 
<a href="/search/cs?searchtype=author&query=Winata%2C+G+I">Genta Indra Winata</a>, 
<a href="/search/cs?searchtype=author&query=Purwarianti%2C+A">Ayu Purwarianti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06203" title="Abstract">arXiv:2401.06203</a> (replaced) [<a href="/pdf/2401.06203" title="Download PDF">pdf</a>, <a href="/ps/2401.06203" title="Download PostScript">ps</a>, <a href="/format/2401.06203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Remixing Music for Hearing Aids Using Ensemble of Fine-Tuned Source  Separators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Daly%2C+M">Matthew Daly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages, ICASSP 2024, Cadenza Grand Challenge
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06320" title="Abstract">arXiv:2401.06320</a> (replaced) [<a href="/pdf/2401.06320" title="Download PDF">pdf</a>, <a href="/format/2401.06320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot Generative Large Language Models for Systematic Review  Screening Automation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Scells%2C+H">Harrisen Scells</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+S">Shengyao Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Potthast%2C+M">Martin Potthast</a>, 
<a href="/search/cs?searchtype=author&query=Koopman%2C+B">Bevan Koopman</a>, 
<a href="/search/cs?searchtype=author&query=Zuccon%2C+G">Guido Zuccon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ECIR2024 full paper (findings)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07324" title="Abstract">arXiv:2401.07324</a> (replaced) [<a href="/pdf/2401.07324" title="Download PDF">pdf</a>, <a href="/format/2401.07324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Small LLMs Are Weak Tool Learners: A Multi-LLM Agent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Weizhou Shen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongzhan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Ming Yan</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+X">Xiaojun Quan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hehong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Ji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> On progress, github repo: <a href="https://github.com/X-PLUG/Multi-LLM-Agent">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07359" title="Abstract">arXiv:2401.07359</a> (replaced) [<a href="/pdf/2401.07359" title="Download PDF">pdf</a>, <a href="/ps/2401.07359" title="Download PostScript">ps</a>, <a href="/format/2401.07359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reliability and Interpretability in Science and Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scorzato%2C+L">Luigi Scorzato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Minor clarifications in Sec. 4.1. Misleading table removed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); History and Philosophy of Physics (physics.hist-ph)

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08083" title="Abstract">arXiv:2401.08083</a> (replaced) [<a href="/pdf/2401.08083" title="Download PDF">pdf</a>, <a href="/format/2401.08083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UV-SAM: Adapting Segment Anything Model for Urban Village Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuming Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Q">Qingmin Liao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08224" title="Abstract">arXiv:2401.08224</a> (replaced) [<a href="/pdf/2401.08224" title="Download PDF">pdf</a>, <a href="/format/2401.08224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy Preserving Adaptive Experiment Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Li%2C+J">Jiachun Li</a>, 
<a href="/search/stat?searchtype=author&query=Shi%2C+K">Kaining Shi</a>, 
<a href="/search/stat?searchtype=author&query=Simchi-Levi%2C+D">David Simchi-Levi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Update an algorithm and the title of our paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08426" title="Abstract">arXiv:2401.08426</a> (replaced) [<a href="/pdf/2401.08426" title="Download PDF">pdf</a>, <a href="/format/2401.08426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GD doesn&#x27;t make the cut: Three ways that non-differentiability affects  neural network training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S+K">Siddharth Krishna Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09761" title="Abstract">arXiv:2401.09761</a> (replaced) [<a href="/pdf/2401.09761" title="Download PDF">pdf</a>, <a href="/format/2401.09761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ISAC with Backscattering RFID Tags: Joint Beamforming Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Luo%2C+H">Hao Luo</a>, 
<a href="/search/eess?searchtype=author&query=Demirhan%2C+U">Umut Demirhan</a>, 
<a href="/search/eess?searchtype=author&query=Alkhateeb%2C+A">Ahmed Alkhateeb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures. To appear in IEEE ICC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09769" title="Abstract">arXiv:2401.09769</a> (replaced) [<a href="/pdf/2401.09769" title="Download PDF">pdf</a>, <a href="/format/2401.09769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning from Graphs with Heterophily: Progress and Future
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+C">Chenghua Gong</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+C">Caihua Shan</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Siqiang Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09923" title="Abstract">arXiv:2401.09923</a> (replaced) [<a href="/pdf/2401.09923" title="Download PDF">pdf</a>, <a href="/format/2401.09923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAMBA: Multi-level Aggregation via Memory Bank for Video Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Guanxiong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+Y">Yang Hua</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+G">Guosheng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Robertson%2C+N">Neil Robertson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> update code url <a href="https://github.com/guanxiongsun/vfe.pytorch">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the AAAI Conference on Artificial Intelligence
  2021 (Vol. 35, No. 3, pp. 2620-2627)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10306" title="Abstract">arXiv:2401.10306</a> (replaced) [<a href="/pdf/2401.10306" title="Download PDF">pdf</a>, <a href="/format/2401.10306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-constrained convolutional neural networks for inverse problems  in spatiotemporal partial differential equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kelshaw%2C+D">Daniel Kelshaw</a>, 
<a href="/search/physics?searchtype=author&query=Magri%2C+L">Luca Magri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2306.04600">arXiv:2306.04600</a>, <a href="/abs/2306.10990">arXiv:2306.10990</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10371" title="Abstract">arXiv:2401.10371</a> (replaced) [<a href="/pdf/2401.10371" title="Download PDF">pdf</a>, <a href="/format/2401.10371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Langevin Unlearning: A New Perspective of Noisy Gradient Descent for  Machine Unlearning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chien%2C+E">Eli Chien</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ziang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pan Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11261" title="Abstract">arXiv:2401.11261</a> (replaced) [<a href="/pdf/2401.11261" title="Download PDF">pdf</a>, <a href="/format/2401.11261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Model Conditioning on Gaussian Mixture Model and Negative  Gaussian Mixture Gradient
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Weiguo Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+D">Deng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Jinqiao Duan</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+J">Jirong Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+G">Gangnan Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11864" title="Abstract">arXiv:2401.11864</a> (replaced) [<a href="/pdf/2401.11864" title="Download PDF">pdf</a>, <a href="/format/2401.11864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distilling Mathematical Reasoning Capabilities into Small Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xunyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jian Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Can Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiping Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12212" title="Abstract">arXiv:2401.12212</a> (replaced) [<a href="/pdf/2401.12212" title="Download PDF">pdf</a>, <a href="/ps/2401.12212" title="Download PostScript">ps</a>, <a href="/format/2401.12212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Genericity Through Stratification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arrial%2C+V">Victor Arrial</a>, 
<a href="/search/cs?searchtype=author&query=Guerrieri%2C+G">Giulio Guerrieri</a>, 
<a href="/search/cs?searchtype=author&query=Kesner%2C+D">Delia Kesner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12258" title="Abstract">arXiv:2401.12258</a> (replaced) [<a href="/pdf/2401.12258" title="Download PDF">pdf</a>, <a href="/format/2401.12258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergent Dominance Hierarchies in Reinforcement Learning Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rachum%2C+R">Ram Rachum</a>, 
<a href="/search/cs?searchtype=author&query=Nakar%2C+Y">Yonatan Nakar</a>, 
<a href="/search/cs?searchtype=author&query=Tomlinson%2C+B">Bill Tomlinson</a>, 
<a href="/search/cs?searchtype=author&query=Alon%2C+N">Nitay Alon</a>, 
<a href="/search/cs?searchtype=author&query=Mirsky%2C+R">Reuth Mirsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12557" title="Abstract">arXiv:2401.12557</a> (replaced) [<a href="/pdf/2401.12557" title="Download PDF">pdf</a>, <a href="/ps/2401.12557" title="Download PostScript">ps</a>, <a href="/format/2401.12557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balancing the AI Strength of Roles in Self-Play Training with Regret  Matching+
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoxi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12639" title="Abstract">arXiv:2401.12639</a> (replaced) [<a href="/pdf/2401.12639" title="Download PDF">pdf</a>, <a href="/format/2401.12639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Matching with Memoization for Regexes with Look-around and  Atomic Grouping (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fujinami%2C+H">Hiroya Fujinami</a>, 
<a href="/search/cs?searchtype=author&query=Hasuo%2C+I">Ichiro Hasuo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in ESOP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13325" title="Abstract">arXiv:2401.13325</a> (replaced) [<a href="/pdf/2401.13325" title="Download PDF">pdf</a>, <a href="/format/2401.13325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory Consistency Guided Divide-and-Conquer Learning for Generalized  Category Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tu%2C+Y">Yuanpeng Tu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zhun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuxi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hengshuang Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13346" title="Abstract">arXiv:2401.13346</a> (replaced) [<a href="/pdf/2401.13346" title="Download PDF">pdf</a>, <a href="/format/2401.13346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Past, Present, Future: A Comprehensive Exploration of AI Use Cases in  the UMBRELLA IoT Testbed
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peizheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Mavromatis%2C+I">Ioannis Mavromatis</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Aftab Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pgaes, 4 figures. This work has been accepted by PerCom TrustSense workshop 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13366" title="Abstract">arXiv:2401.13366</a> (replaced) [<a href="/pdf/2401.13366" title="Download PDF">pdf</a>, <a href="/format/2401.13366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating System Bias in Resource Constrained Asynchronous Federated  Learning Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jikun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Mavromatis%2C+I">Ioannis Mavromatis</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peizheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Carnelli%2C+P">Pietro Carnelli</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Aftab Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures. This work has been accepted by PerCom PerconAI workshop 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13744" title="Abstract">arXiv:2401.13744</a> (replaced) [<a href="/pdf/2401.13744" title="Download PDF">pdf</a>, <a href="/format/2401.13744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conformal Prediction Sets Improve Human Decision Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cresswell%2C+J+C">Jesse C. Cresswell</a>, 
<a href="/search/cs?searchtype=author&query=Sui%2C+Y">Yi Sui</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+B">Bhargava Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Vouitsis%2C+N">No&#xeb;l Vouitsis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code available at <a href="https://github.com/layer6ai-labs/hitl-conformal-prediction">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14113" title="Abstract">arXiv:2401.14113</a> (replaced) [<a href="/pdf/2401.14113" title="Download PDF">pdf</a>, <a href="/format/2401.14113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Affinity, Rationality, and Diversity of Hierarchical Topic  Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaobao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+F">Fengjun Pan</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yichao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chaoqun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+C">Cong-Duy Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+A+T">Anh Tuan Luu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI2024 conference. Our code is available at <a href="https://github.com/bobxwu/TraCo">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14895" title="Abstract">arXiv:2401.14895</a> (replaced) [<a href="/pdf/2401.14895" title="Download PDF">pdf</a>, <a href="/format/2401.14895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MPTQ-ViT: Mixed-Precision Post-Training Quantization for Vision  Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tai%2C+Y">Yu-Shan Tai</a>, 
<a href="/search/cs?searchtype=author&query=An-Yeu">An-Yeu</a> (Andy)Wu
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15098" title="Abstract">arXiv:2401.15098</a> (replaced) [<a href="/pdf/2401.15098" title="Download PDF">pdf</a>, <a href="/format/2401.15098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Continual Reinforcement Learning via Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Chaofan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianrui Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15122" title="Abstract">arXiv:2401.15122</a> (replaced) [<a href="/pdf/2401.15122" title="Download PDF">pdf</a>, <a href="/format/2401.15122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-Grained Symmetric Differential Equation Model for Learning  Protein-Ligand Binding Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shengchao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Weitao Du</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanjing Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuoxinran Li</a>, 
<a href="/search/cs?searchtype=author&query=Bhethanabotla%2C+V">Vignesh Bhethanabotla</a>, 
<a href="/search/cs?searchtype=author&query=Rampal%2C+N">Nakul Rampal</a>, 
<a href="/search/cs?searchtype=author&query=Yaghi%2C+O">Omar Yaghi</a>, 
<a href="/search/cs?searchtype=author&query=Borgs%2C+C">Christian Borgs</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hongyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chayes%2C+J">Jennifer Chayes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Biomolecules (q-bio.BM); Quantitative Methods (q-bio.QM); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15140" title="Abstract">arXiv:2401.15140</a> (replaced) [<a href="/pdf/2401.15140" title="Download PDF">pdf</a>, <a href="/format/2401.15140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Link Prediction Accuracy on Real-World Networks Under Non-Uniform  Missing Edge Patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=He%2C+X">Xie He</a>, 
<a href="/search/math?searchtype=author&query=Ghasemian%2C+A">Amir Ghasemian</a>, 
<a href="/search/math?searchtype=author&query=Lee%2C+E">Eun Lee</a>, 
<a href="/search/math?searchtype=author&query=Schwarze%2C+A">Alice Schwarze</a>, 
<a href="/search/math?searchtype=author&query=Clauset%2C+A">Aaron Clauset</a>, 
<a href="/search/math?searchtype=author&query=Mucha%2C+P+J">Peter J. Mucha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transaction on Network Science and Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15166" title="Abstract">arXiv:2401.15166</a> (replaced) [<a href="/pdf/2401.15166" title="Download PDF">pdf</a>, <a href="/format/2401.15166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Design of Multi-Dimensional Spatially-Coupled Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C4%B0rima%C4%9Fz%C4%B1%2C+C">Canberk &#x130;rima&#x11f;z&#x131;</a>, 
<a href="/search/cs?searchtype=author&query=Tanr%C4%B1kulu%2C+A">Ata Tanr&#x131;kulu</a>, 
<a href="/search/cs?searchtype=author&query=Hareedy%2C+A">Ahmed Hareedy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages (double column), 5 figures, the short version has been submitted to the IEEE International Symposium on Information Theory (ISIT)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15316" title="Abstract">arXiv:2401.15316</a> (replaced) [<a href="/pdf/2401.15316" title="Download PDF">pdf</a>, <a href="/format/2401.15316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UNSEE: Unsupervised Non-contrastive Sentence Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%87a%C4%9Fatan%2C+%C3%96+V">&#xd6;mer Veysel &#xc7;a&#x11f;atan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15583" title="Abstract">arXiv:2401.15583</a> (replaced) [<a href="/pdf/2401.15583" title="Download PDF">pdf</a>, <a href="/format/2401.15583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCTransNet: Spatial-channel Cross Transformer Network for Infrared Small  Target Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+S">Shuai Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Hanlin Qin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=AKhtar%2C+N">Naveed AKhtar</a>, 
<a href="/search/cs?searchtype=author&query=Mian%2C+A">Ajmal Mian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15857" title="Abstract">arXiv:2401.15857</a> (replaced) [<a href="/pdf/2401.15857" title="Download PDF">pdf</a>, <a href="/format/2401.15857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leadership Dynamics in Social Multiplex Networks with Mono and  Bi-directional Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Talebi%2C+A">Amirreza Talebi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15940" title="Abstract">arXiv:2401.15940</a> (replaced) [<a href="/pdf/2401.15940" title="Download PDF">pdf</a>, <a href="/format/2401.15940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge-Aware Code Generation with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhihong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Ge Li</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+C">Chen Lyu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICPC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16013" title="Abstract">arXiv:2401.16013</a> (replaced) [<a href="/pdf/2401.16013" title="Download PDF">pdf</a>, <a href="/format/2401.16013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SERL: A Software Suite for Sample-Efficient Robotic Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jianlan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zheyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Charles Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y+L">You Liang Tan</a>, 
<a href="/search/cs?searchtype=author&query=Berg%2C+J">Jacob Berg</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Archit Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Schaal%2C+S">Stefan Schaal</a>, 
<a href="/search/cs?searchtype=author&query=Finn%2C+C">Chelsea Finn</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhishek Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16637" title="Abstract">arXiv:2401.16637</a> (replaced) [<a href="/pdf/2401.16637" title="Download PDF">pdf</a>, <a href="/format/2401.16637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IRCoCo: Immediate Rewards-Guided Deep Reinforcement Learning for Code  Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bolun Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhihong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yao Wan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Ge Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+C">Chen Lyu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for the 32nd ACM Symposium on the Foundations of Software Engineering (FSE 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16661" title="Abstract">arXiv:2401.16661</a> (replaced) [<a href="/pdf/2401.16661" title="Download PDF">pdf</a>, <a href="/ps/2401.16661" title="Download PostScript">ps</a>, <a href="/format/2401.16661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalization of LiNGAM that allows confounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+J">Joe Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tian-Le Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16719" title="Abstract">arXiv:2401.16719</a> (replaced) [<a href="/pdf/2401.16719" title="Download PDF">pdf</a>, <a href="/format/2401.16719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OptiState: State Estimation of Legged Robots using Gated Networks with  Transformer-based Vision and Kalman Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schperberg%2C+A">Alexander Schperberg</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+Y">Yusuke Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Mowlavi%2C+S">Saviz Mowlavi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Feng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Balaji%2C+B">Bharathan Balaji</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+D">Dennis Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 2024 IEEE International Conference on Robotics and Automation (ICRA), May 13-17, in Yokohama, Japan. 7 pages, 5 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16736" title="Abstract">arXiv:2401.16736</a> (replaced) [<a href="/pdf/2401.16736" title="Download PDF">pdf</a>, <a href="/format/2401.16736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Engineering A Large Language Model From Scratch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oketunji%2C+A+F">Abiodun Finbarrs Oketunji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16797" title="Abstract">arXiv:2401.16797</a> (replaced) [<a href="/pdf/2401.16797" title="Download PDF">pdf</a>, <a href="/format/2401.16797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Translation Validation of Compiler Transformations with Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanzhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+F">Fei Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.17163" title="Abstract">arXiv:2401.17163</a> (replaced) [<a href="/pdf/2401.17163" title="Download PDF">pdf</a>, <a href="/format/2401.17163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Agent-based Modeling with LLM Companions: Experiences of  Novices and Experts Using ChatGPT &amp; NetLogo Chat
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">John Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xi Lu</a>, 
<a href="/search/cs?searchtype=author&query=Rejtig%2C+M">Michael Rejtig</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+D">David Du</a>, 
<a href="/search/cs?searchtype=author&query=Bagley%2C+R">Ruth Bagley</a>, 
<a href="/search/cs?searchtype=author&query=Horn%2C+M+S">Michael S. Horn</a>, 
<a href="/search/cs?searchtype=author&query=Wilensky%2C+U+J">Uri J. Wilensky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conditionally accepted (with minor revisions) by Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.17187" title="Abstract">arXiv:2401.17187</a> (replaced) [<a href="/pdf/2401.17187" title="Download PDF">pdf</a>, <a href="/format/2401.17187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formal Synthesis of Uncertainty Reduction Controllers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carwehl%2C+M">Marc Carwehl</a>, 
<a href="/search/cs?searchtype=author&query=Imrie%2C+C">Calum Imrie</a>, 
<a href="/search/cs?searchtype=author&query=Vogel%2C+T">Thomas Vogel</a>, 
<a href="/search/cs?searchtype=author&query=Rodrigues%2C+G">Gena&#xed;na Rodrigues</a>, 
<a href="/search/cs?searchtype=author&query=Calinescu%2C+R">Radu Calinescu</a>, 
<a href="/search/cs?searchtype=author&query=Grunske%2C+L">Lars Grunske</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.17434" title="Abstract">arXiv:2401.17434</a> (replaced) [<a href="/pdf/2401.17434" title="Download PDF">pdf</a>, <a href="/ps/2401.17434" title="Download PostScript">ps</a>, <a href="/format/2401.17434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Generative AI in Hackathons: Opportunities, Challenges, and  Educational Implications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sajja%2C+R">Ramteja Sajja</a>, 
<a href="/search/cs?searchtype=author&query=Ramirez%2C+C+E">Carlos Erazo Ramirez</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhouyayan Li</a>, 
<a href="/search/cs?searchtype=author&query=Demiray%2C+B+Z">Bekir Z. Demiray</a>, 
<a href="/search/cs?searchtype=author&query=Sermet%2C+Y">Yusuf Sermet</a>, 
<a href="/search/cs?searchtype=author&query=Demir%2C+I">Ibrahim Demir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8491 words, 23 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.17759" title="Abstract">arXiv:2401.17759</a> (replaced) [<a href="/pdf/2401.17759" title="Download PDF">pdf</a>, <a href="/ps/2401.17759" title="Download PostScript">ps</a>, <a href="/format/2401.17759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tiered approach for rapid damage characterisation of infrastructure  enabled by remote sensing and deep learning technologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kopiika%2C+N">Nadiia Kopiika</a>, 
<a href="/search/cs?searchtype=author&query=Karavias%2C+A">Andreas Karavias</a>, 
<a href="/search/cs?searchtype=author&query=Krassakis%2C+P">Pavlos Krassakis</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zehao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ninic%2C+J">Jelena Ninic</a>, 
<a href="/search/cs?searchtype=author&query=Shakhovska%2C+N">Nataliya Shakhovska</a>, 
<a href="/search/cs?searchtype=author&query=Koukouzas%2C+N">Nikolaos Koukouzas</a>, 
<a href="/search/cs?searchtype=author&query=Argyroudis%2C+S">Sotirios Argyroudis</a>, 
<a href="/search/cs?searchtype=author&query=Mitoulis%2C+S">Stergios-Aristoteles Mitoulis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main text (34 pages,18 figures); Supplementary materials (13 pages)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.17814" title="Abstract">arXiv:2401.17814</a> (replaced) [<a href="/pdf/2401.17814" title="Download PDF">pdf</a>, <a href="/format/2401.17814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detection of Critical Events in Renewable Energy Production Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Stoop%2C+L+P">Laurens P. Stoop</a>, 
<a href="/search/physics?searchtype=author&query=Duijm%2C+E">Erik Duijm</a>, 
<a href="/search/physics?searchtype=author&query=Feelders%2C+A+J">Ad J. Feelders</a>, 
<a href="/search/physics?searchtype=author&query=van+den+Broek%2C+M">Machteld van den Broek</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In: AALTD 2021. Lecture Notes in Computer Science(), vol 13114
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.17857" title="Abstract">arXiv:2401.17857</a> (replaced) [<a href="/pdf/2401.17857" title="Download PDF">pdf</a>, <a href="/format/2401.17857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment Anything in 3D Gaussians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lue Fan</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Junsong Fan</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Junran Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Z">Zhen Lei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoxiang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.17910" title="Abstract">arXiv:2401.17910</a> (replaced) [<a href="/pdf/2401.17910" title="Download PDF">pdf</a>, <a href="/format/2401.17910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllable Dense Captioner with Multimodal Embedding Bridging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuzhong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zonghao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Weijia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+C">Chen Gong</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+F">Fang Wan</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qixiang Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/callsys/ControlCap">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item380">Cross-lists</a></li>
<li><a href="#item429">Replacements</a></li>
</ul>
<small>[ total of 643 entries:  <b>1-643</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2402">2402</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
