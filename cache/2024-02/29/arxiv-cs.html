<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Tue 27 Feb 24  to  Wed 28 Feb 24, announced Thu, 29 Feb 24</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item357">Cross-lists</a></li>
<li><a href="#item406">Replacements</a></li>
</ul>
<small>[ total of 667 entries:  <b>1-667</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Thu, 29 Feb 24</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17785" title="Abstract">arXiv:2402.17785</a> [<a href="/pdf/2402.17785" title="Download PDF">pdf</a>, <a href="/format/2402.17785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ByteComposer: a Human-like Melody Composition Method based on Language  Model Agent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xia Liang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiaju Lin</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xinjian Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Large Language Models (LLM) have shown encouraging progress in multimodal
understanding and generation tasks. However, how to design a human-aligned and
interpretable melody composition system is still under-explored. To solve this
problem, we propose ByteComposer, an agent framework emulating a human's
creative pipeline in four separate steps : "Conception Analysis - Draft
Composition - Self-Evaluation and Modification - Aesthetic Selection". This
framework seamlessly blends the interactive and knowledge-understanding
features of LLMs with existing symbolic music generation models, thereby
achieving a melody composition agent comparable to human creators. We conduct
extensive experiments on GPT4 and several open-source large language models,
which substantiate our framework's effectiveness. Furthermore, professional
music composers were engaged in multi-dimensional evaluations, the final
results demonstrated that across various facets of music composition,
ByteComposer agent attains the level of a novice melody composer.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17786" title="Abstract">arXiv:2402.17786</a> [<a href="/pdf/2402.17786" title="Download PDF">pdf</a>, <a href="/format/2402.17786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stepwise Self-Consistent Mathematical Reasoning with Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zilong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+Y">Yao Rong</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Dongyang Guo</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B6zl%C3%BCkl%C3%BC%2C+E">Emek G&#xf6;zl&#xfc;kl&#xfc;</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BClboy%2C+E">Emir G&#xfc;lboy</a>, 
<a href="/search/cs?searchtype=author&query=Kasneci%2C+E">Enkelejda Kasneci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Using Large Language Models for complex mathematical reasoning is difficult,
primarily due to the complexity of multi-step reasoning. The main challenges of
this process include (1) selecting critical intermediate results to advance the
procedure, and (2) limited exploration of potential solutions. To address these
issues, we introduce a novel algorithm, namely Stepwise Self-Consistent
Chain-of-Thought (SSC-CoT). SSC-CoT employs a strategy of selecting
intermediate steps based on the intersection of various reasoning chains.
Additionally, SSC-CoT enables the model to discover critical intermediate steps
by querying a knowledge graph comprising relevant domain knowledge. To validate
SSC-CoT, we present a new dataset, TriMaster100, tailored for complex
trigonometry problems. This dataset contains 100 questions, with each solution
broken down into scored intermediate steps, facilitating a comprehensive
evaluation of the mathematical reasoning process. On TriMaster100, SSC-CoT
triples the effectiveness of the state-of-the-art methods. Furthermore, we
benchmark SSC-CoT on the widely recognized complex mathematical question
dataset, MATH level 5, and it surpasses the second-best method by 7.2% in
accuracy. Code and the TriMaster100 dataset can be found at:
https://github.com/zhao-zilong/ssc-cot.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17791" title="Abstract">arXiv:2402.17791</a> [<a href="/pdf/2402.17791" title="Download PDF">pdf</a>, <a href="/format/2402.17791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Label Informed Contrastive Pretraining for Node Importance Estimation on  Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+C">Chengbin Hou</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+R">Rui Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuegong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chenghu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+K">Ke Tang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+H">Hairong Lv</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE TNNLS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Node Importance Estimation (NIE) is a task of inferring importance scores of
the nodes in a graph. Due to the availability of richer data and knowledge,
recent research interests of NIE have been dedicating to knowledge graphs for
predicting future or missing node importance scores. Existing state-of-the-art
NIE methods train the model by available labels, and they consider every
interested node equally before training. However, the nodes with higher
importance often require or receive more attention in real-world scenarios,
e.g., people may care more about the movies or webpages with higher importance.
To this end, we introduce Label Informed ContrAstive Pretraining (LICAP) to the
NIE problem for being better aware of the nodes with high importance scores.
Specifically, LICAP is a novel type of contrastive learning framework that aims
to fully utilize the continuous labels to generate contrastive samples for
pretraining embeddings. Considering the NIE problem, LICAP adopts a novel
sampling strategy called top nodes preferred hierarchical sampling to first
group all interested nodes into a top bin and a non-top bin based on node
importance scores, and then divide the nodes within top bin into several finer
bins also based on the scores. The contrastive samples are generated from those
bins, and are then used to pretrain node embeddings of knowledge graphs via a
newly proposed Predicate-aware Graph Attention Networks (PreGAT), so as to
better separate the top nodes from non-top nodes, and distinguish the top nodes
within top bin by keeping the relative order among finer bins. Extensive
experiments demonstrate that the LICAP pretrained embeddings can further boost
the performance of existing NIE methods and achieve the new state-of-the-art
performance regarding both regression and ranking metrics. The source code for
reproducibility is available at https://github.com/zhangtia16/LICAP
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17793" title="Abstract">arXiv:2402.17793</a> [<a href="/pdf/2402.17793" title="Download PDF">pdf</a>, <a href="/format/2402.17793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Surprising Failure? Multimodal LLMs and the NLVR Challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+A">Anne Wu</a>, 
<a href="/search/cs?searchtype=author&query=Brantley%2C+K">Kiant&#xe9; Brantley</a>, 
<a href="/search/cs?searchtype=author&query=Artzi%2C+Y">Yoav Artzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">This study evaluates three state-of-the-art MLLMs -- GPT-4V, Gemini Pro, and
the open-source model IDEFICS -- on the compositional natural language vision
reasoning task NLVR. Given a human-written sentence paired with a synthetic
image, this task requires the model to determine the truth value of the
sentence with respect to the image. Despite the strong performance demonstrated
by these models, we observe they perform poorly on NLVR, which was constructed
to require compositional and spatial reasoning, and to be robust for semantic
and systematic biases.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17802" title="Abstract">arXiv:2402.17802</a> [<a href="/pdf/2402.17802" title="Download PDF">pdf</a>, <a href="/format/2402.17802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time Series Analysis in Compressor-Based Machines: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Forbicini%2C+F">Francesca Forbicini</a>, 
<a href="/search/cs?searchtype=author&query=Vago%2C+N+O+P">Nicol&#xf2; Oreste Pinciroli Vago</a>, 
<a href="/search/cs?searchtype=author&query=Fraternali%2C+P">Piero Fraternali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In both industrial and residential contexts, compressor-based machines, such
as refrigerators, HVAC systems, heat pumps and chillers, are essential to
fulfil production and consumers' needs. The diffusion of sensors and IoT
connectivity supports the development of monitoring systems able to detect and
predict faults, identify behavioural shifts and forecast the operational status
of machines and of their components. The focus of this paper is to survey the
recent research on such tasks as Fault Detection, Fault Prediction, Forecasting
and Change Point Detection applied to multivariate time series characterizing
the operations of compressor-based machines. Specifically, Fault Detection
detects and diagnoses faults, Fault Prediction predicts such occurrences,
forecasting anticipates the future value of characteristic variables of
machines and Change Point Detection identifies significant variations in the
behaviour of the appliances, such as a change in the working regime. We
identify and classify the approaches to the above-mentioned tasks, compare the
algorithms employed, highlight the gaps in the current status of the art and
discuss the most promising future research directions in the field.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17804" title="Abstract">arXiv:2402.17804</a> [<a href="/pdf/2402.17804" title="Download PDF">pdf</a>, <a href="/format/2402.17804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting machine failures from multivariate time series: an industrial  case study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vago%2C+N+O+P">Nicol&#xf2; Oreste Pinciroli Vago</a>, 
<a href="/search/cs?searchtype=author&query=Forbicini%2C+F">Francesca Forbicini</a>, 
<a href="/search/cs?searchtype=author&query=Fraternali%2C+P">Piero Fraternali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Non-neural Machine Learning (ML) and Deep Learning (DL) models are often used
to predict system failures in the context of industrial maintenance. However,
only a few researches jointly assess the effect of varying the amount of past
data used to make a prediction and the extension in the future of the forecast.
This study evaluates the impact of the size of the reading window and of the
prediction window on the performances of models trained to forecast failures in
three data sets concerning the operation of (1) an industrial wrapping machine
working in discrete sessions, (2) an industrial blood refrigerator working
continuously, and (3) a nitrogen generator working continuously. The problem is
formulated as a binary classification task that assigns the positive label to
the prediction window based on the probability of a failure to occur in such an
interval. Six algorithms (logistic regression, random forest, support vector
machine, LSTM, ConvLSTM, and Transformers) are compared using multivariate
telemetry time series. The results indicate that, in the considered scenarios,
the dimension of the prediction windows plays a crucial role and highlight the
effectiveness of DL approaches at classifying data with diverse time-dependent
patterns preceding a failure and the effectiveness of ML approaches at
classifying similar and repetitive patterns preceding a failure.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17805" title="Abstract">arXiv:2402.17805</a> [<a href="/pdf/2402.17805" title="Download PDF">pdf</a>, <a href="/ps/2402.17805" title="Download PostScript">ps</a>, <a href="/format/2402.17805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Neural Networks and Arithmetic Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barlag%2C+T">Timon Barlag</a>, 
<a href="/search/cs?searchtype=author&query=Holzapfel%2C+V">Vivian Holzapfel</a>, 
<a href="/search/cs?searchtype=author&query=Strieker%2C+L">Laura Strieker</a>, 
<a href="/search/cs?searchtype=author&query=Virtema%2C+J">Jonni Virtema</a>, 
<a href="/search/cs?searchtype=author&query=Vollmer%2C+H">Heribert Vollmer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Complexity (cs.CC)

</div>
<p class="mathjax">We characterize the computational power of neural networks that follow the
graph neural network (GNN) architecture, not restricted to aggregate-combine
GNNs or other particular types. We establish an exact correspondence between
the expressivity of GNNs using diverse activation functions and arithmetic
circuits over real numbers. In our results the activation function of the
network becomes a gate type in the circuit. Our result holds for families of
constant depth circuits and networks, both uniformly and non-uniformly, for all
common activation functions.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17806" title="Abstract">arXiv:2402.17806</a> [<a href="/pdf/2402.17806" title="Download PDF">pdf</a>, <a href="/format/2402.17806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Material Microstructure Design Using VAE-Regression with Multimodal  Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sardeshmukh%2C+A">Avadhut Sardeshmukh</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+S">Sreedhar Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Gautham%2C+B">BP Gautham</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharyya%2C+P">Pushpak Bhattacharyya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages main paper, 9 pages appendix. 10 tables and 11 figures. Accepted for publication in PAKDD 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Materials Science (cond-mat.mtrl-sci); Machine Learning (stat.ML)

</div>
<p class="mathjax">We propose a variational autoencoder (VAE)-based model for building forward
and inverse structure-property linkages, a problem of paramount importance in
computational materials science. Our model systematically combines VAE with
regression, linking the two models through a two-level prior conditioned on the
regression variables. The regression loss is optimized jointly with the
reconstruction loss of the variational autoencoder, learning microstructure
features relevant for property prediction and reconstruction. The resultant
model can be used for both forward and inverse prediction i.e., for predicting
the properties of a given microstructure as well as for predicting the
microstructure required to obtain given properties. Since the inverse problem
is ill-posed (one-to-many), we derive the objective function using a
multi-modal Gaussian mixture prior enabling the model to infer multiple
microstructures for a target set of properties. We show that for forward
prediction, our model is as accurate as state-of-the-art forward-only models.
Additionally, our method enables direct inverse inference. We show that the
microstructures inferred using our model achieve desired properties reasonably
accurately, avoiding the need for expensive optimization loops.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17811" title="Abstract">arXiv:2402.17811</a> [<a href="/pdf/2402.17811" title="Download PDF">pdf</a>, <a href="/format/2402.17811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TruthX: Alleviating Hallucinations by Editing Large Language Models in  Truthful Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaolei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yang Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/ictnlp/TruthX">this https URL</a>, A Llama-2-7B-Chat model with baked-in TruthX: https:// huggingface.co/ICTNLP/Llama-2-7b-chat-TruthX
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) have demonstrated remarkable capabilities across
various tasks. However, they sometimes suffer from producing hallucinations,
particularly in cases where they may generate untruthful responses despite
possessing the correct knowledge. In this paper, we propose TruthX, an
inference-time method to elicit the truthfulness of LLMs by editing their
internal representations in truthful space. TruthX employs an auto-encoder to
map LLM's representations into semantic and truthful latent spaces
respectively, and applies contrastive learning to identify a truthful editing
direction within the truthful space. During inference, by editing LLM's
internal representations in truthful space, TruthX effectively enhances the
truthfulness of LLMs. Experiments show that TruthX effectively improves the
truthfulness of 13 advanced LLMs by an average of 20% on TruthfulQA benchmark.
Further analyses suggest that the truthful space acquired by TruthX plays a
pivotal role in controlling LLM to produce truthful or hallucinatory responses.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17812" title="Abstract">arXiv:2402.17812</a> [<a href="/pdf/2402.17812" title="Download PDF">pdf</a>, <a href="/format/2402.17812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DropBP: Accelerating Fine-Tuning of Large Language Models by Dropping  Backward Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Woo%2C+S">Sunghyeon Woo</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+B">Baeseong Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Byeongwook Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jo%2C+M">Minjung Jo</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+S">Sejung Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+D">Dongsuk Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongsoo Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Training deep neural networks typically involves substantial computational
costs during both forward and backward propagation. The conventional layer
dropping techniques drop certain layers during training for reducing the
computations burden. However, dropping layers during forward propagation
adversely affects the training process by degrading accuracy. In this paper, we
propose Dropping Backward Propagation (DropBP), a novel approach designed to
reduce computational costs while maintaining accuracy. DropBP randomly drops
layers during the backward propagation, which does not deviate forward
propagation. Moreover, DropBP calculates the sensitivity of each layer to
assign appropriate drop rate, thereby stabilizing the training process. DropBP
is designed to enhance the efficiency of the training process with
backpropagation, thereby enabling the acceleration of both full fine-tuning and
parameter-efficient fine-tuning using backpropagation. Specifically, utilizing
DropBP in QLoRA reduces training time by 44%, increases the convergence speed
to the identical loss level by 1.5$\times$, and enables training with a
6.2$\times$ larger sequence length on a single NVIDIA-A100 80GiB GPU in
LLaMA2-70B. The code is available at https://github.com/WooSunghyeon/dropbp.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17826" title="Abstract">arXiv:2402.17826</a> [<a href="/pdf/2402.17826" title="Download PDF">pdf</a>, <a href="/ps/2402.17826" title="Download PostScript">ps</a>, <a href="/format/2402.17826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prediction-Powered Ranking of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatzi%2C+I">Ivi Chatzi</a>, 
<a href="/search/cs?searchtype=author&query=Straitouri%2C+E">Eleni Straitouri</a>, 
<a href="/search/cs?searchtype=author&query=Thejaswi%2C+S">Suhas Thejaswi</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+M+G">Manuel Gomez Rodriguez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Large language models are often ranked according to their level of alignment
with human preferences -- a model is better than other models if its outputs
are more frequently preferred by humans. One of the most popular ways to elicit
human preferences utilizes pairwise comparisons between the outputs provided by
different models to the same inputs. However, since gathering pairwise
comparisons by humans is costly and time-consuming, it has become a very common
practice to gather pairwise comparisons by a strong large language model -- a
model strongly aligned with human preferences. Surprisingly, practitioners
cannot currently measure the uncertainty that any mismatch between human and
model preferences may introduce in the constructed rankings. In this work, we
develop a statistical framework to bridge this gap. Given a small set of
pairwise comparisons by humans and a large set of pairwise comparisons by a
model, our framework provides a rank-set -- a set of possible ranking positions
-- for each of the models under comparison. Moreover, it guarantees that, with
a probability greater than or equal to a user-specified value, the rank-sets
cover the true ranking consistent with (the distribution of) human pairwise
preferences. Our framework is computationally efficient, easy to use, and does
not make any assumption about the distribution of human preferences nor about
the degree of alignment between the pairwise comparisons by the humans and the
strong large language model.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17834" title="Abstract">arXiv:2402.17834</a> [<a href="/pdf/2402.17834" title="Download PDF">pdf</a>, <a href="/format/2402.17834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable LM 2 1.6B Technical Report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bellagente%2C+M">Marco Bellagente</a>, 
<a href="/search/cs?searchtype=author&query=Tow%2C+J">Jonathan Tow</a>, 
<a href="/search/cs?searchtype=author&query=Mahan%2C+D">Dakota Mahan</a>, 
<a href="/search/cs?searchtype=author&query=Phung%2C+D">Duy Phung</a>, 
<a href="/search/cs?searchtype=author&query=Zhuravinskyi%2C+M">Maksym Zhuravinskyi</a>, 
<a href="/search/cs?searchtype=author&query=Adithyan%2C+R">Reshinth Adithyan</a>, 
<a href="/search/cs?searchtype=author&query=Baicoianu%2C+J">James Baicoianu</a>, 
<a href="/search/cs?searchtype=author&query=Brooks%2C+B">Ben Brooks</a>, 
<a href="/search/cs?searchtype=author&query=Cooper%2C+N">Nathan Cooper</a>, 
<a href="/search/cs?searchtype=author&query=Datta%2C+A">Ashish Datta</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Meng Lee</a>, 
<a href="/search/cs?searchtype=author&query=Mostaque%2C+E">Emad Mostaque</a>, 
<a href="/search/cs?searchtype=author&query=Pieler%2C+M">Michael Pieler</a>, 
<a href="/search/cs?searchtype=author&query=Pinnaparju%2C+N">Nikhil Pinnaparju</a>, 
<a href="/search/cs?searchtype=author&query=Rocha%2C+P">Paulo Rocha</a>, 
<a href="/search/cs?searchtype=author&query=Saini%2C+H">Harry Saini</a>, 
<a href="/search/cs?searchtype=author&query=Teufel%2C+H">Hannah Teufel</a>, 
<a href="/search/cs?searchtype=author&query=Zanichelli%2C+N">Niccolo Zanichelli</a>, 
<a href="/search/cs?searchtype=author&query=Riquelme%2C+C">Carlos Riquelme</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We introduce StableLM 2 1.6B, the first in a new generation of our language
model series. In this technical report, we present in detail the data and
training procedure leading to the base and instruction-tuned versions of
StableLM 2 1.6B. The weights for both models are available via Hugging Face for
anyone to download and use. The report contains thorough evaluations of these
models, including zero- and few-shot benchmarks, multilingual benchmarks, and
the MT benchmark focusing on multi-turn dialogues. At the time of publishing
this report, StableLM 2 1.6B was the state-of-the-art open model under 2B
parameters by a significant margin. Given its appealing small size, we also
provide throughput measurements on a number of edge devices. In addition, we
open source several quantized checkpoints and provide their performance metrics
compared to the original model.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17836" title="Abstract">arXiv:2402.17836</a> [<a href="/pdf/2402.17836" title="Download PDF">pdf</a>, <a href="/format/2402.17836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Considerations for End-User Development in the Caregiving Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stegner%2C+L">Laura Stegner</a>, 
<a href="/search/cs?searchtype=author&query=Porfirio%2C+D">David Porfirio</a>, 
<a href="/search/cs?searchtype=author&query=Roberts%2C+M">Mark Roberts</a>, 
<a href="/search/cs?searchtype=author&query=Hiatt%2C+L+M">Laura M. Hiatt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at AAAI Fall Symposium Series 2023 UR-RAD
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">As service robots become more capable of autonomous behaviors, it becomes
increasingly important to consider how people communicate with a robot what
task it should perform and how to do the task. Accordingly, there has been a
rise in attention to end-user development (EUD) interfaces, which enable
non-roboticist end users to specify tasks for autonomous robots to perform.
However, state-of-the-art EUD interfaces are often constrained through
simplified domains or restrictive end-user interaction. Motivated by prior
qualitative design work that explores how to integrate a care robot in an
assisted living community, we discuss the challenges of EUD in this complex
domain. One set of challenges stems from different user-facing representations,
e.g., certain tasks may lend themselves better to rule-based trigger-action
representations, whereas other tasks may be easier to specify via sequences of
actions. The other stems from considering the needs of multiple stakeholders,
e.g., caregivers and residents of the facility may all create tasks for the
robot, but the robot may not be able to share information about all tasks with
all residents due to privacy concerns. We present scenarios that illustrate
these challenges and also discuss possible solutions.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17838" title="Abstract">arXiv:2402.17838</a> [<a href="/pdf/2402.17838" title="Download PDF">pdf</a>, <a href="/ps/2402.17838" title="Download PostScript">ps</a>, <a href="/format/2402.17838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalizing Smart Home Privacy Protection With Individuals&#x27; Regulatory  Focus: Would You Preserve or Enhance Your Information Privacy?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anaraky%2C+R+G">Reza Ghaiumy Anaraky</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yao Li</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+H">Hichang Cho</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D+Y">Danny Yuxing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Byrne%2C+K+A">Kaileigh A. Byrne</a>, 
<a href="/search/cs?searchtype=author&query=Knijnenburg%2C+B">Bart Knijnenburg</a>, 
<a href="/search/cs?searchtype=author&query=Nov%2C+O">Oded Nov</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Conference on Human Factors in Computing Systems (CHI2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In this study, we explore the effectiveness of persuasive messages endorsing
the adoption of a privacy protection technology (IoT Inspector) tailored to
individuals' regulatory focus (promotion or prevention). We explore if and how
regulatory fit (i.e., tuning the goal-pursuit mechanism to individuals'
internal regulatory focus) can increase persuasion and adoption. We conducted a
between-subject experiment (N = 236) presenting participants with the IoT
Inspector in gain ("Privacy Enhancing Technology" -- PET) or loss ("Privacy
Preserving Technology" -- PPT) framing. Results show that the effect of
regulatory fit on adoption is mediated by trust and privacy calculus processes:
prevention-focused users who read the PPT message trust the tool more.
Furthermore, privacy calculus favors using the tool when promotion-focused
individuals read the PET message. We discuss the contribution of understanding
the cognitive mechanisms behind regulatory fit in privacy decision-making to
support privacy protection.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17840" title="Abstract">arXiv:2402.17840</a> [<a href="/pdf/2402.17840" title="Download PDF">pdf</a>, <a href="/format/2402.17840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Follow My Instruction and Spill the Beans: Scalable Data Extraction from  Retrieval-Augmented Generation Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zhenting Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanlin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+E">Eric Xing</a>, 
<a href="/search/cs?searchtype=author&query=Kakade%2C+S">Sham Kakade</a>, 
<a href="/search/cs?searchtype=author&query=Lakkaraju%2C+H">Himabindu Lakkaraju</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Retrieval-Augmented Generation (RAG) improves pre-trained models by
incorporating external knowledge at test time to enable customized adaptation.
We study the risk of datastore leakage in Retrieval-In-Context RAG Language
Models (LMs). We show that an adversary can exploit LMs' instruction-following
capabilities to easily extract text data verbatim from the datastore of RAG
systems built with instruction-tuned LMs via prompt injection. The
vulnerability exists for a wide range of modern LMs that span Llama2,
Mistral/Mixtral, Vicuna, SOLAR, WizardLM, Qwen1.5, and Platypus2, and the
exploitability exacerbates as the model size scales up. Extending our study to
production RAG models GPTs, we design an attack that can cause datastore
leakage with a 100% success rate on 25 randomly selected customized GPTs with
at most 2 queries, and we extract text data verbatim at a rate of 41% from a
book of 77,000 words and 3% from a corpus of 1,569,000 words by prompting the
GPTs with only 100 queries generated by themselves.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17846" title="Abstract">arXiv:2402.17846</a> [<a href="/pdf/2402.17846" title="Download PDF">pdf</a>, <a href="/format/2402.17846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Parameterized Complexity of Motion Planning for Rectangular  Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanj%2C+I">Iyad Kanj</a>, 
<a href="/search/cs?searchtype=author&query=Parsa%2C+S">Salman Parsa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">We study computationally-hard fundamental motion planning problems where the
goal is to translate $k$ axis-aligned rectangular robots from their initial
positions to their final positions without collision, and with the minimum
number of translation moves. Our aim is to understand the interplay between the
number of robots and the geometric complexity of the input instance measured by
the input size, which is the number of bits needed to encode the coordinates of
the rectangles' vertices. We focus on axis-aligned translations, and more
generally, translations restricted to a given set of directions, and we study
the two settings where the robots move in the free plane, and where they are
confined to a bounding box. We obtain fixed-parameter tractable (FPT)
algorithms parameterized by $k$ for all the settings under consideration. In
the case where the robots move serially (i.e., one in each time step) and
axis-aligned, we prove a structural result stating that every problem instance
admits an optimal solution in which the moves are along a grid, whose size is a
function of $k$, that can be defined based on the input instance. This
structural result implies that the problem is fixed-parameter tractable
parameterized by $k$. We also consider the case in which the robots move in
parallel (i.e., multiple robots can move during the same time step), and which
falls under the category of Coordinated Motion Planning problems. Finally, we
show that, when the robots move in the free plane, the FPT results for the
serial motion case carry over to the case where the translations are restricted
to any given set of directions.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17847" title="Abstract">arXiv:2402.17847</a> [<a href="/pdf/2402.17847" title="Download PDF">pdf</a>, <a href="/ps/2402.17847" title="Download PostScript">ps</a>, <a href="/format/2402.17847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Barriers to Public Social Interaction with Meronymous  Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soliman%2C+N">Nouran Soliman</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+H+B">Hyeonsu B Kang</a>, 
<a href="/search/cs?searchtype=author&query=Latzke%2C+M">Matthew Latzke</a>, 
<a href="/search/cs?searchtype=author&query=Bragg%2C+J">Jonathan Bragg</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+J+C">Joseph Chee Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A+X">Amy X. Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Karger%2C+D+R">David R Karger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '24), May 11--16, 2024, Honolulu, HI, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In communities with social hierarchies, fear of judgment can discourage
communication. While anonymity may alleviate some social pressure, fully
anonymous spaces enable toxic behavior and hide the social context that
motivates people to participate and helps them tailor their communication. We
explore a design space of meronymous communication, where people can reveal
carefully chosen aspects of their identity and also leverage trusted endorsers
to gain credibility. We implemented these ideas in a system for scholars to
meronymously seek and receive paper recommendations on Twitter and Mastodon. A
formative study with 20 scholars confirmed that scholars see benefits to
participating but are deterred due to social anxiety. From a month-long public
deployment, we found that with meronymity, junior scholars could comfortably
ask ``newbie'' questions and get responses from senior scholars who they
normally found intimidating. Responses were also tailored to the aspects about
themselves that junior scholars chose to reveal.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17853" title="Abstract">arXiv:2402.17853</a> [<a href="/pdf/2402.17853" title="Download PDF">pdf</a>, <a href="/format/2402.17853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Neural PDE Solver: a reduced-order modelling framework for  partial differential equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zijie Li</a>, 
<a href="/search/cs?searchtype=author&query=Patil%2C+S">Saurabh Patil</a>, 
<a href="/search/cs?searchtype=author&query=Ogoke%2C+F">Francis Ogoke</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+D">Dule Shu</a>, 
<a href="/search/cs?searchtype=author&query=Zhen%2C+W">Wilson Zhen</a>, 
<a href="/search/cs?searchtype=author&query=Schneier%2C+M">Michael Schneier</a>, 
<a href="/search/cs?searchtype=author&query=Buchanan%2C+J+R">John R. Buchanan, Jr.</a>, 
<a href="/search/cs?searchtype=author&query=Farimani%2C+A+B">Amir Barati Farimani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Analysis of PDEs (math.AP)

</div>
<p class="mathjax">Neural networks have shown promising potential in accelerating the numerical
simulation of systems governed by partial differential equations (PDEs).
Different from many existing neural network surrogates operating on
high-dimensional discretized fields, we propose to learn the dynamics of the
system in the latent space with much coarser discretizations. In our proposed
framework - Latent Neural PDE Solver (LNS), a non-linear autoencoder is first
trained to project the full-order representation of the system onto the
mesh-reduced space, then a temporal model is trained to predict the future
state in this mesh-reduced space. This reduction process simplifies the
training of the temporal model by greatly reducing the computational cost
accompanying a fine discretization. We study the capability of the proposed
framework and several other popular neural PDE solvers on various types of
systems including single-phase and multi-phase flows along with varying system
parameters. We showcase that it has competitive accuracy and efficiency
compared to the neural PDE solver that operates on full-order space.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17861" title="Abstract">arXiv:2402.17861</a> [<a href="/pdf/2402.17861" title="Download PDF">pdf</a>, <a href="/format/2402.17861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards AI Accountability Infrastructure: Gaps and Opportunities in AI  Audit Tooling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ojewale%2C+V">Victor Ojewale</a>, 
<a href="/search/cs?searchtype=author&query=Steed%2C+R">Ryan Steed</a>, 
<a href="/search/cs?searchtype=author&query=Vecchione%2C+B">Briana Vecchione</a>, 
<a href="/search/cs?searchtype=author&query=Birhane%2C+A">Abeba Birhane</a>, 
<a href="/search/cs?searchtype=author&query=Raji%2C+I+D">Inioluwa Deborah Raji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Audits are critical mechanisms for identifying the risks and limitations of
deployed artificial intelligence (AI) systems. However, the effective execution
of AI audits remains incredibly difficult. As a result, practitioners make use
of various tools to support their efforts. Drawing on interviews with 35 AI
audit practitioners and a landscape analysis of 390 tools, we map the current
ecosystem of available AI audit tools. While there are many tools designed to
assist practitioners with setting standards and evaluating AI systems, these
tools often fell short of supporting the accountability goals of AI auditing in
practice. We thus highlight areas for future tool development beyond evaluation
-- from harms discovery to advocacy -- and outline challenges practitioners
faced in their efforts to use AI audit tools. We conclude that resources are
lacking to adequately support the full scope of needs for many AI audit
practitioners and recommend that the field move beyond tools for just
evaluation, towards more comprehensive infrastructure for AI accountability.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17862" title="Abstract">arXiv:2402.17862</a> [<a href="/pdf/2402.17862" title="Download PDF">pdf</a>, <a href="/format/2402.17862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> REPrune: Channel Pruning via Kernel Representative Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+M">Mincheol Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dongjin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+C">Cheonjun Park</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+Y">Yuna Park</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+G+E">Gyeong Eun Gong</a>, 
<a href="/search/cs?searchtype=author&query=Ro%2C+W+W">Won Woo Ro</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Suhyun Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Channel pruning is widely accepted to accelerate modern convolutional neural
networks (CNNs). The resulting pruned model benefits from its immediate
deployment on general-purpose software and hardware resources. However, its
large pruning granularity, specifically at the unit of a convolution filter,
often leads to undesirable accuracy drops due to the inflexibility of deciding
how and where to introduce sparsity to the CNNs. In this paper, we propose
REPrune, a novel channel pruning technique that emulates kernel pruning, fully
exploiting the finer but structured granularity. REPrune identifies similar
kernels within each channel using agglomerative clustering. Then, it selects
filters that maximize the incorporation of kernel representatives while
optimizing the maximum cluster coverage problem. By integrating with a
simultaneous training-pruning paradigm, REPrune promotes efficient, progressive
pruning throughout training CNNs, avoiding the conventional
train-prune-finetune sequence. Experimental results highlight that REPrune
performs better in computer vision tasks than existing methods, effectively
achieving a balance between acceleration ratio and performance retention.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17863" title="Abstract">arXiv:2402.17863</a> [<a href="/pdf/2402.17863" title="Download PDF">pdf</a>, <a href="/format/2402.17863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision Transformers with Natural Language Semantics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y+K">Young Kyung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Di+Martino%2C+J+M">J. Mat&#xed;as Di Martino</a>, 
<a href="/search/cs?searchtype=author&query=Sapiro%2C+G">Guillermo Sapiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Tokens or patches within Vision Transformers (ViT) lack essential semantic
information, unlike their counterparts in natural language processing (NLP).
Typically, ViT tokens are associated with rectangular image patches that lack
specific semantic context, making interpretation difficult and failing to
effectively encapsulate information. We introduce a novel transformer model,
Semantic Vision Transformers (sViT), which leverages recent progress on
segmentation models to design novel tokenizer strategies. sViT effectively
harnesses semantic information, creating an inductive bias reminiscent of
convolutional neural networks while capturing global dependencies and
contextual information within images that are characteristic of transformers.
Through validation using real datasets, sViT demonstrates superiority over ViT,
requiring less training data while maintaining similar or superior performance.
Furthermore, sViT demonstrates significant superiority in out-of-distribution
generalization and robustness to natural distribution shifts, attributed to its
scale invariance semantic characteristic. Notably, the use of semantic tokens
significantly enhances the model's interpretability. Lastly, the proposed
paradigm facilitates the introduction of new and powerful augmentation
techniques at the token (or segment) level, increasing training data diversity
and generalization capabilities. Just as sentences are made of words, images
are formed by semantic objects; our proposed methodology leverages recent
progress in object segmentation and takes an important and natural step toward
interpretable and robust vision transformers.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17866" title="Abstract">arXiv:2402.17866</a> [<a href="/pdf/2402.17866" title="Download PDF">pdf</a>, <a href="/format/2402.17866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards spatiotemporal integration of bus transit with data-driven  approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borges%2C+J">J&#xfa;lio Borges</a>, 
<a href="/search/cs?searchtype=author&query=Peixoto%2C+A+M">Altieris M. Peixoto</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+T+H">Thiago H. Silva</a>, 
<a href="/search/cs?searchtype=author&query=Munaretto%2C+A">Anelise Munaretto</a>, 
<a href="/search/cs?searchtype=author&query=Luders%2C+R">Ricardo Luders</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 16 FIGURES
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">This study aims to propose an approach for spatiotemporal integration of bus
transit, which enables users to change bus lines by paying a single fare. This
could increase bus transit efficiency and, consequently, help to make this mode
of transportation more attractive. Usually, this strategy is allowed for a few
hours in a non-restricted area; thus, certain walking distance areas behave
like "virtual terminals." For that, two data-driven algorithms are proposed in
this work. First, a new algorithm for detecting itineraries based on bus GPS
data and the bus stop location. The proposed algorithm's results show that 90%
of the database detected valid itineraries by excluding invalid markings and
adding times at missing bus stops through temporal interpolation. Second, this
study proposes a bus stop clustering algorithm to define suitable areas for
these virtual terminals where it would be possible to make bus transfers
outside the physical terminals. Using real-world origin-destination trips, the
bus network, including clusters, can reduce traveled distances by up to 50%,
making twice as many connections on average.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17868" title="Abstract">arXiv:2402.17868</a> [<a href="/pdf/2402.17868" title="Download PDF">pdf</a>, <a href="/format/2402.17868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SmartQC: An Extensible DLT-Based Framework for Trusted Data Workflows in  Smart Manufacturing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McGibney%2C+A">Alan McGibney</a>, 
<a href="/search/cs?searchtype=author&query=Ranathunga%2C+T">Tharindu Ranathunga</a>, 
<a href="/search/cs?searchtype=author&query=Pospisil%2C+R">Roman Pospisil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 Pages, 9 Figures, Under Peer Review Process
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Recent developments in Distributed Ledger Technology (DLT), including
Blockchain offer new opportunities in the manufacturing domain, by providing
mechanisms to automate trust services (digital identity, trusted interactions,
and auditable transactions) and when combined with other advanced digital
technologies (e.g. machine learning) can provide a secure backbone for trusted
data flows between independent entities. This paper presents an DLT-based
architectural pattern and technology solution known as SmartQC that aims to
provide an extensible and flexible approach to integrating DLT technology into
existing workflows and processes. SmartQC offers an opportunity to make
processes more time efficient, reliable, and robust by providing two key
features i) data integrity through immutable ledgers and ii) automation of
business workflows leveraging smart contracts. The paper will present the
system architecture, extensible data model and the application of SmartQC in
the context of example smart manufacturing applications.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17873" title="Abstract">arXiv:2402.17873</a> [<a href="/pdf/2402.17873" title="Download PDF">pdf</a>, <a href="/format/2402.17873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Randomized matrix computations: Themes and variations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kireeva%2C+A">Anastasia Kireeva</a>, 
<a href="/search/math?searchtype=author&query=Tropp%2C+J+A">Joel A. Tropp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 53 pages. Lectures July 3-7, 2023 in Cetraro, Calabria. To appear in CIME Lecture Notes series
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
<p class="mathjax">This short course offers a new perspective on randomized algorithms for
matrix computations. It explores the distinct ways in which probability can be
used to design algorithms for numerical linear algebra. Each design template is
illustrated by its application to several computational problems. This
treatment establishes conceptual foundations for randomized numerical linear
algebra, and it forges links between algorithms that may initially seem
unrelated.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17874" title="Abstract">arXiv:2402.17874</a> [<a href="/pdf/2402.17874" title="Download PDF">pdf</a>, <a href="/format/2402.17874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed Strategy Constraints in Continuous Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krusniak%2C+M">Mel Krusniak</a>, 
<a href="/search/cs?searchtype=author&query=Laine%2C+F">Forrest Laine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Equilibrium problems representing interaction in physical environments
typically require continuous strategies which satisfy opponent-dependent
constraints, such as those modeling collision avoidance. However, as with
finite games, mixed strategies are often desired, both from an equilibrium
existence perspective as well as a competitive perspective. To that end, this
work investigates a chance-constraint-based approach to coupled constraints in
generalized Nash equilibrium problems which are solved over pure strategies and
mixing weights simultaneously. We motivate these constraints in a discrete
setting, placing them on tensor games ($n$-player bimatrix games) as a
justifiable approach to handling the probabilistic nature of mixing. Then, we
describe a numerical solution method for these chance constrained tensor games
with simultaneous pure strategy optimization. Finally, using a modified
pursuit-evasion game as a motivating examples, we demonstrate the actual
behavior of this solution method in terms of its fidelity, parameter
sensitivity, and efficiency.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17878" title="Abstract">arXiv:2402.17878</a> [<a href="/pdf/2402.17878" title="Download PDF">pdf</a>, <a href="/ps/2402.17878" title="Download PostScript">ps</a>, <a href="/format/2402.17878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-User Development for Human-Robot Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stegner%2C+L">Laura Stegner</a>, 
<a href="/search/cs?searchtype=author&query=Porfirio%2C+D">David Porfirio</a>, 
<a href="/search/cs?searchtype=author&query=Hiatt%2C+L+M">Laura M. Hiatt</a>, 
<a href="/search/cs?searchtype=author&query=Lemaignan%2C+S">S&#xe9;verin Lemaignan</a>, 
<a href="/search/cs?searchtype=author&query=Mead%2C+R">Ross Mead</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+B">Bilge Mutlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction (HRI '24 Companion), March 11--14, 2024, Boulder, CO, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">End-user development (EUD) represents a key step towards making robotics
accessible for experts and nonexperts alike. Within academia, researchers
investigate novel ways that EUD tools can capture, represent, visualize,
analyze, and test developer intent. At the same time, industry researchers
increasingly build and ship programming tools that enable customers to interact
with their robots. However, despite this growing interest, the role of EUD
within HRI is not well defined. EUD struggles to situate itself within a
growing array of alternative approaches to application development, such as
robot learning and teleoperation. EUD further struggles due to the wide range
of individuals who can be considered end users, such as independent third-party
application developers, consumers, hobbyists, or even employees of the robot
manufacturer. Key questions remain such as how EUD is justified over alternate
approaches to application development, which contexts EUD is most suited for,
who the target users of an EUD system are, and where interaction between a
human and a robot takes place, amongst many other questions. We seek to address
these challenges and questions by organizing the first End-User Development for
Human-Robot Interaction (EUD4HRI) workshop at the 2024 International Conference
of Human-Robot Interaction. The workshop will bring together researchers with a
wide range of expertise across academia and industry, spanning perspectives
from multiple subfields of robotics, with the primary goal being a consensus of
perspectives about the role that EUD must play within human-robot interaction.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17879" title="Abstract">arXiv:2402.17879</a> [<a href="/pdf/2402.17879" title="Download PDF">pdf</a>, <a href="/format/2402.17879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Statistical Model Discovery with Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M+Y">Michael Y. Li</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+E+B">Emily B. Fox</a>, 
<a href="/search/cs?searchtype=author&query=Goodman%2C+N+D">Noah D. Goodman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Statistical model discovery involves a challenging search over a vast space
of models subject to domain-specific modeling constraints. Efficiently
searching over this space requires human expertise in modeling and the problem
domain. Motivated by the domain knowledge and programming capabilities of large
language models (LMs), we introduce a method for language model driven
automated statistical model discovery. We cast our automated procedure within
the framework of Box's Loop: the LM iterates between proposing statistical
models represented as probabilistic programs, acting as a modeler, and
critiquing those models, acting as a domain expert. By leveraging LMs, we do
not have to define a domain-specific language of models or design a handcrafted
search procedure, key restrictions of previous systems. We evaluate our method
in three common settings in probabilistic modeling: searching within a
restricted space of models, searching over an open-ended space, and improving
classic models under natural language constraints (e.g., this model should be
interpretable to an ecologist). Our method matches the performance of previous
systems, identifies models on par with human expert designed models, and
extends classic models in interpretable ways. Our results highlight the promise
of LM driven model discovery.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17880" title="Abstract">arXiv:2402.17880</a> [<a href="/pdf/2402.17880" title="Download PDF">pdf</a>, <a href="/format/2402.17880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges in Restructuring Community-based Moderation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+C">Chau Tran</a>, 
<a href="/search/cs?searchtype=author&query=Take%2C+K">Kejsi Take</a>, 
<a href="/search/cs?searchtype=author&query=Champion%2C+K">Kaylea Champion</a>, 
<a href="/search/cs?searchtype=author&query=Hill%2C+B+M">Benjamin Mako Hill</a>, 
<a href="/search/cs?searchtype=author&query=Greenstadt%2C+R">Rachel Greenstadt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Content moderation practices and technologies need to change over time as
requirements and community expectations shift. However, attempts to restructure
existing moderation practices can be difficult, especially for platforms that
rely on their communities to conduct moderation activities, because changes can
transform the workflow and workload of moderators and contributors' reward
systems. Through the study of extensive archival discussions around a
prepublication moderation technology on Wikipedia named Flagged Revisions,
complemented by seven semi-structured interviews, we identify various
challenges in restructuring community-based moderation practices. We learn that
while a new system might sound good in theory and perform well in terms of
quantitative metrics, it may conflict with existing social norms. Our findings
also highlight how the intricate relationship between platforms and
self-governed communities can hinder the ability to assess the performance of
any new system and introduce considerable costs related to maintaining,
overhauling, or scrapping any piece of infrastructure.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17882" title="Abstract">arXiv:2402.17882</a> [<a href="/pdf/2402.17882" title="Download PDF">pdf</a>, <a href="/format/2402.17882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BlendSQL: A Scalable Dialect for Unifying Hybrid Question Answering in  Relational Algebra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Glenn%2C+P">Parker Glenn</a>, 
<a href="/search/cs?searchtype=author&query=Dakle%2C+P+P">Parag Pravin Dakle</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Raghavan%2C+P">Preethi Raghavan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For associated codebase, see <a href="https://github.com/parkervg/blendsql">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Many existing end-to-end systems for hybrid question answering tasks can
often be boiled down to a "prompt-and-pray" paradigm, where the user has
limited control and insight into the intermediate reasoning steps used to
achieve the final result. Additionally, due to the context size limitation of
many transformer-based LLMs, it is often not reasonable to expect that the full
structured and unstructured context will fit into a given prompt in a zero-shot
setting, let alone a few-shot setting. We introduce BlendSQL, a superset of
SQLite to act as a unified dialect for orchestrating reasoning across both
unstructured and structured data. For hybrid question answering tasks involving
multi-hop reasoning, we encode the full decomposed reasoning roadmap into a
single interpretable BlendSQL query. Notably, we show that BlendSQL can scale
to massive datasets and improve the performance of end-to-end systems while
using 35% fewer tokens. Our code is available and installable as a package at
https://github.com/parkervg/blendsql.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17885" title="Abstract">arXiv:2402.17885</a> [<a href="/pdf/2402.17885" title="Download PDF">pdf</a>, <a href="/format/2402.17885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Independent Learning in Constrained Markov Potential Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jordan%2C+P">Philip Jordan</a>, 
<a href="/search/cs?searchtype=author&query=Barakat%2C+A">Anas Barakat</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+N">Niao He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Constrained Markov games offer a formal mathematical framework for modeling
multi-agent reinforcement learning problems where the behavior of the agents is
subject to constraints. In this work, we focus on the recently introduced class
of constrained Markov Potential Games. While centralized algorithms have been
proposed for solving such constrained games, the design of converging
independent learning algorithms tailored for the constrained setting remains an
open question. We propose an independent policy gradient algorithm for learning
approximate constrained Nash equilibria: Each agent observes their own actions
and rewards, along with a shared state. Inspired by the optimization
literature, our algorithm performs proximal-point-like updates augmented with a
regularized constraint set. Each proximal step is solved inexactly using a
stochastic switching gradient algorithm. Notably, our algorithm can be
implemented independently without a centralized coordination mechanism
requiring turn-based agent updates. Under some technical constraint
qualification conditions, we establish convergence guarantees towards
constrained approximate Nash equilibria. We perform simulations to illustrate
our results.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17887" title="Abstract">arXiv:2402.17887</a> [<a href="/pdf/2402.17887" title="Download PDF">pdf</a>, <a href="/format/2402.17887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JMLR: Joint Medical LLM and Retrieval Training for Enhancing Reasoning  and Professional Question Answering Capability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junda Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhichao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zonghai Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hong Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">With the explosive growth of medical data and the rapid development of
artificial intelligence technology, precision medicine has emerged as a key to
enhancing the quality and efficiency of healthcare services. In this context,
Large Language Models (LLMs) play an increasingly vital role in medical
knowledge acquisition and question-answering systems. To further improve the
performance of these systems in the medical domain, we introduce an innovative
method that jointly trains an Information Retrieval (IR) system and an LLM
during the fine-tuning phase. This approach, which we call Joint Medical LLM
and Retrieval Training (JMLR), is designed to overcome the challenges faced by
traditional models in handling medical question-answering tasks. By employing a
synchronized training mechanism, JMLR reduces the demand for computational
resources and enhances the model's ability to leverage medical knowledge for
reasoning and answering questions. Our experimental results demonstrate that
JMLR-13B (81.2% on Amboos, 61.3% on MedQA) outperforms models using
conventional pre-training and fine-tuning Meditron-70B (76.4% on AMBOSS, 60.3%
on MedQA). For models of the same 7B scale, JMLR-7B(68.7% on Amboos, 51.7% on
MedQA) significantly outperforms other public models (Meditron-7B: 50.1%,
47.9%), proving its superiority in terms of cost (our training time: 37 hours,
traditional method: 144 hours), efficiency, and effectiveness in medical
question-answering tasks. Through this work, we provide a new and efficient
knowledge enhancement tool for healthcare, demonstrating the great potential of
integrating IR and LLM training in precision medical information retrieval and
question-answering systems.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17888" title="Abstract">arXiv:2402.17888</a> [<a href="/pdf/2402.17888" title="Download PDF">pdf</a>, <a href="/format/2402.17888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConjNorm: Tractable Density Estimation for Out-of-Distribution Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Bo Peng</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yadan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yonggang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yixuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhen Fang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR24 poster
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Post-hoc out-of-distribution (OOD) detection has garnered intensive attention
in reliable machine learning. Many efforts have been dedicated to deriving
score functions based on logits, distances, or rigorous data distribution
assumptions to identify low-scoring OOD samples. Nevertheless, these estimate
scores may fail to accurately reflect the true data density or impose
impractical constraints. To provide a unified perspective on density-based
score design, we propose a novel theoretical framework grounded in Bregman
divergence, which extends distribution considerations to encompass an
exponential family of distributions. Leveraging the conjugation constraint
revealed in our theorem, we introduce a \textsc{ConjNorm} method, reframing
density function design as a search for the optimal norm coefficient $p$
against the given dataset. In light of the computational challenges of
normalization, we devise an unbiased and analytically tractable estimator of
the partition function using the Monte Carlo-based importance sampling
technique. Extensive experiments across OOD detection benchmarks empirically
demonstrate that our proposed \textsc{ConjNorm} has established a new
state-of-the-art in a variety of OOD detection setups, outperforming the
current best method by up to 13.25$\%$ and 28.19$\%$ (FPR95) on CIFAR-100 and
ImageNet-1K, respectively.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17890" title="Abstract">arXiv:2402.17890</a> [<a href="/pdf/2402.17890" title="Download PDF">pdf</a>, <a href="/format/2402.17890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Inverse Optimization to Feasibility to ERM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Saurabh Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Raj%2C+A">Anant Raj</a>, 
<a href="/search/cs?searchtype=author&query=Vaswani%2C+S">Sharan Vaswani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Inverse optimization involves inferring unknown parameters of an optimization
problem from known solutions, and is widely used in fields such as
transportation, power systems and healthcare. We study the contextual inverse
optimization setting that utilizes additional contextual information to better
predict the unknown problem parameters. We focus on contextual inverse linear
programming (CILP), addressing the challenges posed by the non-differentiable
nature of LPs. For a linear prediction model, we reduce CILP to a convex
feasibility problem allowing the use of standard algorithms such as alternating
projections. The resulting algorithm for CILP is equipped with a linear
convergence guarantee without additional assumptions such as degeneracy or
interpolation. Next, we reduce CILP to empirical risk minimization (ERM) on a
smooth, convex loss that satisfies the Polyak-Lojasiewicz condition. This
reduction enables the use of scalable first-order optimization methods to solve
large non-convex problems, while maintaining theoretical guarantees in the
convex setting. Finally, we experimentally validate our approach on both
synthetic and real-world problems, and demonstrate improved performance
compared to existing methods.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17891" title="Abstract">arXiv:2402.17891</a> [<a href="/pdf/2402.17891" title="Download PDF">pdf</a>, <a href="/format/2402.17891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly Supervised Co-training with Swapping Assignments for Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Rahmani%2C+H">Hossein Rahmani</a>, 
<a href="/search/cs?searchtype=author&query=Black%2C+S">Sue Black</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+B+M">Bryan M. Williams</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Class activation maps (CAMs) are commonly employed in weakly supervised
semantic segmentation (WSSS) to produce pseudo-labels. Due to incomplete or
excessive class activation, existing studies often resort to offline CAM
refinement, introducing additional stages or proposing offline modules. This
can cause optimization difficulties for single-stage methods and limit
generalizability. In this study, we aim to reduce the observed CAM
inconsistency and error to mitigate reliance on refinement processes. We
propose an end-to-end WSSS model incorporating guided CAMs, wherein our
segmentation model is trained while concurrently optimizing CAMs online. Our
method, Co-training with Swapping Assignments (CoSA), leverages a dual-stream
framework, where one sub-network learns from the swapped assignments generated
by the other. We introduce three techniques: i) soft perplexity-based
regularization to penalize uncertain regions; ii) a threshold-searching
approach to dynamically revise the confidence threshold; and iii) contrastive
separation to address the coexistence problem. CoSA demonstrates exceptional
performance, achieving mIoU of 76.2\% and 51.0\% on VOC and COCO validation
datasets, respectively, surpassing existing baselines by a substantial margin.
Notably, CoSA is the first single-stage approach to outperform all existing
multi-stage methods including those with additional supervision. Code is
avilable at \url{https://github.com/youshyee/CoSA}.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17892" title="Abstract">arXiv:2402.17892</a> [<a href="/pdf/2402.17892" title="Download PDF">pdf</a>, <a href="/format/2402.17892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SWTrack: Multiple Hypothesis Sliding Window 3D Multi-Object Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papais%2C+S">Sandro Papais</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+R">Robert Ren</a>, 
<a href="/search/cs?searchtype=author&query=Waslander%2C+S">Steven Waslander</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Modern robotic systems are required to operate in dense dynamic environments,
requiring highly accurate real-time track identification and estimation. For 3D
multi-object tracking, recent approaches process a single measurement frame
recursively with greedy association and are prone to errors in ambiguous
association decisions. Our method, Sliding Window Tracker (SWTrack), yields
more accurate association and state estimation by batch processing many frames
of sensor data while being capable of running online in real-time. The most
probable track associations are identified by evaluating all possible track
hypotheses across the temporal sliding window. A novel graph optimization
approach is formulated to solve the multidimensional assignment problem with
lifted graph edges introduced to account for missed detections and graph
sparsity enforced to retain real-time efficiency. We evaluate our SWTrack
implementation$^{2}$ on the NuScenes autonomous driving dataset to demonstrate
improved tracking performance.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17896" title="Abstract">arXiv:2402.17896</a> [<a href="/pdf/2402.17896" title="Download PDF">pdf</a>, <a href="/format/2402.17896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Researchy Questions: A Dataset of Multi-Perspective, Decompositional  Questions for LLM Web Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rosset%2C+C">Corby Rosset</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+H">Ho-Lam Chung</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+G">Guanghui Qin</a>, 
<a href="/search/cs?searchtype=author&query=Chau%2C+E+C">Ethan C. Chau</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhuo Feng</a>, 
<a href="/search/cs?searchtype=author&query=Awadallah%2C+A">Ahmed Awadallah</a>, 
<a href="/search/cs?searchtype=author&query=Neville%2C+J">Jennifer Neville</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+N">Nikhil Rao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Existing question answering (QA) datasets are no longer challenging to most
powerful Large Language Models (LLMs). Traditional QA benchmarks like TriviaQA,
NaturalQuestions, ELI5 and HotpotQA mainly study ``known unknowns'' with clear
indications of both what information is missing, and how to find it to answer
the question. Hence, good performance on these benchmarks provides a false
sense of security. A yet unmet need of the NLP community is a bank of
non-factoid, multi-perspective questions involving a great deal of unclear
information needs, i.e. ``unknown uknowns''. We claim we can find such
questions in search engine logs, which is surprising because most
question-intent queries are indeed factoid. We present Researchy Questions, a
dataset of search engine queries tediously filtered to be non-factoid,
``decompositional'' and multi-perspective. We show that users spend a lot of
``effort'' on these questions in terms of signals like clicks and session
length, and that they are also challenging for GPT-4. We also show that ``slow
thinking'' answering techniques, like decomposition into sub-questions shows
benefit over answering directly. We release $\sim$ 100k Researchy Questions,
along with the Clueweb22 URLs that were clicked.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17897" title="Abstract">arXiv:2402.17897</a> [<a href="/pdf/2402.17897" title="Download PDF">pdf</a>, <a href="/format/2402.17897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Language Model based Framework for New Concept Placement in Ontologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaoyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuan He</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yongsheng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Horrocks%2C+I">Ian Horrocks</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 3 figures, accepted for ESWC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">We investigate the task of inserting new concepts extracted from texts into
an ontology using language models. We explore an approach with three steps:
edge search which is to find a set of candidate locations to insert (i.e.,
subsumptions between concepts), edge formation and enrichment which leverages
the ontological structure to produce and enhance the edge candidates, and edge
selection which eventually locates the edge to be placed into. In all steps, we
propose to leverage neural methods, where we apply embedding-based methods and
contrastive learning with Pre-trained Language Models (PLMs) such as BERT for
edge search, and adapt a BERT fine-tuning-based multi-label Edge-Cross-encoder,
and Large Language Models (LLMs) such as GPT series, FLAN-T5, and Llama 2, for
edge selection. We evaluate the methods on recent datasets created using the
SNOMED CT ontology and the MedMentions entity linking benchmark. The best
settings in our framework use fine-tuned PLM for search and a multi-label
Cross-encoder for selection. Zero-shot prompting of LLMs is still not adequate
for the task, and we proposed explainable instruction tuning of LLMs for
improved performance. Our study shows the advantages of PLMs and highlights the
encouraging performance of LLMs that motivates future studies.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17902" title="Abstract">arXiv:2402.17902</a> [<a href="/pdf/2402.17902" title="Download PDF">pdf</a>, <a href="/format/2402.17902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SequentialAttention++ for Block Sparsification: Differentiable Pruning  Meets Combinatorial Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yasuda%2C+T">Taisuke Yasuda</a>, 
<a href="/search/cs?searchtype=author&query=Axiotis%2C+K">Kyriakos Axiotis</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+G">Gang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Bateni%2C+M">MohammadHossein Bateni</a>, 
<a href="/search/cs?searchtype=author&query=Mirrokni%2C+V">Vahab Mirrokni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Neural network pruning is a key technique towards engineering large yet
scalable, interpretable, and generalizable models. Prior work on the subject
has developed largely along two orthogonal directions: (1) differentiable
pruning for efficiently and accurately scoring the importance of parameters,
and (2) combinatorial optimization for efficiently searching over the space of
sparse models. We unite the two approaches, both theoretically and empirically,
to produce a coherent framework for structured neural network pruning in which
differentiable pruning guides combinatorial optimization algorithms to select
the most important sparse set of parameters. Theoretically, we show how many
existing differentiable pruning techniques can be understood as nonconvex
regularization for group sparse optimization, and prove that for a wide class
of nonconvex regularizers, the global optimum is unique, group-sparse, and
provably yields an approximate solution to a sparse convex optimization
problem. The resulting algorithm that we propose, SequentialAttention++,
advances the state of the art in large-scale neural network block-wise pruning
tasks on the ImageNet and Criteo datasets.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17903" title="Abstract">arXiv:2402.17903</a> [<a href="/pdf/2402.17903" title="Download PDF">pdf</a>, <a href="/format/2402.17903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Surgment: Segmentation-enabled Semantic Search and Creation of Visual  Question and Feedback to Support Video-Based Surgery Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingying Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Haoran Tang</a>, 
<a href="/search/cs?searchtype=author&query=Kantor%2C+T">Taylor Kantor</a>, 
<a href="/search/cs?searchtype=author&query=Soltani%2C+T">Tandis Soltani</a>, 
<a href="/search/cs?searchtype=author&query=Popov%2C+V">Vitaliy Popov</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Videos are prominent learning materials to prepare surgical trainees before
they enter the operating room (OR). In this work, we explore techniques to
enrich the video-based surgery learning experience. We propose Surgment, a
system that helps expert surgeons create exercises with feedback based on
surgery recordings. Surgment is powered by a few-shot-learning-based pipeline
(SegGPT+SAM) to segment surgery scenes, achieving an accuracy of 92\%. The
segmentation pipeline enables functionalities to create visual questions and
feedback desired by surgeons from a formative study. Surgment enables surgeons
to 1) retrieve frames of interest through sketches, and 2) design exercises
that target specific anatomical components and offer visual feedback. In an
evaluation study with 11 surgeons, participants applauded the search-by-sketch
approach for identifying frames of interest and found the resulting image-based
questions and feedback to be of high educational value.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17904" title="Abstract">arXiv:2402.17904</a> [<a href="/pdf/2402.17904" title="Download PDF">pdf</a>, <a href="/ps/2402.17904" title="Download PostScript">ps</a>, <a href="/format/2402.17904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 4CNet: A Confidence-Aware, Contrastive, Conditional, Consistency Model  for Robot Map Prediction in Multi-Robot Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+A+H">Aaron Hao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Narasimhan%2C+S">Siddarth Narasimhan</a>, 
<a href="/search/cs?searchtype=author&query=Nejat%2C+G">Goldie Nejat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Mobile robots in unknown cluttered environments with irregularly shaped
obstacles often face sensing, energy, and communication challenges which
directly affect their ability to explore these environments. In this paper, we
introduce a novel deep learning method, Confidence-Aware Contrastive
Conditional Consistency Model (4CNet), for mobile robot map prediction during
resource-limited exploration in multi-robot environments. 4CNet uniquely
incorporates: 1) a conditional consistency model for map prediction in
irregularly shaped unknown regions, 2) a contrastive map-trajectory pretraining
framework for a trajectory encoder that extracts spatial information from the
trajectories of nearby robots during map prediction, and 3) a confidence
network to measure the uncertainty of map prediction for effective exploration
under resource constraints. We incorporate 4CNet within our proposed robot
exploration with map prediction architecture, 4CNet-E. We then conduct
extensive comparison studies with 4CNet-E and state-of-the-art heuristic and
learning methods to investigate both map prediction and exploration performance
in environments consisting of uneven terrain and irregularly shaped obstacles.
Results showed that 4CNet-E obtained statistically significant higher
prediction accuracy and area coverage with varying environment sizes, number of
robots, energy budgets, and communication limitations. Real-world mobile robot
experiments were performed and validated the feasibility and generalizability
of 4CNet-E for mobile robot map prediction and exploration.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17905" title="Abstract">arXiv:2402.17905</a> [<a href="/pdf/2402.17905" title="Download PDF">pdf</a>, <a href="/format/2402.17905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Graph Neural Networks to Predict Local Culture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Silva%2C+T+H">Thiago H Silva</a>, 
<a href="/search/cs?searchtype=author&query=Silver%2C+D">Daniel Silver</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Urban research has long recognized that neighbourhoods are dynamic and
relational. However, lack of data, methodologies, and computer processing power
have hampered a formal quantitative examination of neighbourhood relational
dynamics. To make progress on this issue, this study proposes a graph neural
network (GNN) approach that permits combining and evaluating multiple sources
of information about internal characteristics of neighbourhoods, their past
characteristics, and flows of groups among them, potentially providing greater
expressive power in predictive models. By exploring a public large-scale
dataset from Yelp, we show the potential of our approach for considering
structural connectedness in predicting neighbourhood attributes, specifically
to predict local culture. Results are promising from a substantive and
methodologically point of view. Substantively, we find that either local area
information (e.g. area demographics) or group profiles (tastes of Yelp
reviewers) give the best results in predicting local culture, and they are
nearly equivalent in all studied cases. Methodologically, exploring group
profiles could be a helpful alternative where finding local information for
specific areas is challenging, since they can be extracted automatically from
many forms of online data. Thus, our approach could empower researchers and
policy-makers to use a range of data sources when other local area information
is lacking.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17906" title="Abstract">arXiv:2402.17906</a> [<a href="/pdf/2402.17906" title="Download PDF">pdf</a>, <a href="/format/2402.17906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representation learning in multiplex graphs: Where and how to fuse  information?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bielak%2C+P">Piotr Bielak</a>, 
<a href="/search/cs?searchtype=author&query=Kajdanowicz%2C+T">Tomasz Kajdanowicz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In recent years, unsupervised and self-supervised graph representation
learning has gained popularity in the research community. However, most
proposed methods are focused on homogeneous networks, whereas real-world graphs
often contain multiple node and edge types. Multiplex graphs, a special type of
heterogeneous graphs, possess richer information, provide better modeling
capabilities and integrate more detailed data from potentially different
sources. The diverse edge types in multiplex graphs provide more context and
insights into the underlying processes of representation learning. In this
paper, we tackle the problem of learning representations for nodes in multiplex
networks in an unsupervised or self-supervised manner. To that end, we explore
diverse information fusion schemes performed at different levels of the graph
processing pipeline. The detailed analysis and experimental evaluation of
various scenarios inspired us to propose improvements in how to construct GNN
architectures that deal with multiplex graphs.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17910" title="Abstract">arXiv:2402.17910</a> [<a href="/pdf/2402.17910" title="Download PDF">pdf</a>, <a href="/format/2402.17910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Box It to Bind It: Unified Layout Control and Attribute Binding in T2I  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taghipour%2C+A">Ashkan Taghipour</a>, 
<a href="/search/cs?searchtype=author&query=Ghahremani%2C+M">Morteza Ghahremani</a>, 
<a href="/search/cs?searchtype=author&query=Bennamoun%2C+M">Mohammed Bennamoun</a>, 
<a href="/search/cs?searchtype=author&query=Rekavandi%2C+A+M">Aref Miri Rekavandi</a>, 
<a href="/search/cs?searchtype=author&query=Laga%2C+H">Hamid Laga</a>, 
<a href="/search/cs?searchtype=author&query=Boussaid%2C+F">Farid Boussaid</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While latent diffusion models (LDMs) excel at creating imaginative images,
they often lack precision in semantic fidelity and spatial control over where
objects are generated. To address these deficiencies, we introduce the
Box-it-to-Bind-it (B2B) module - a novel, training-free approach for improving
spatial control and semantic accuracy in text-to-image (T2I) diffusion models.
B2B targets three key challenges in T2I: catastrophic neglect, attribute
binding, and layout guidance. The process encompasses two main steps: i) Object
generation, which adjusts the latent encoding to guarantee object generation
and directs it within specified bounding boxes, and ii) attribute binding,
guaranteeing that generated objects adhere to their specified attributes in the
prompt. B2B is designed as a compatible plug-and-play module for existing T2I
models, markedly enhancing model performance in addressing the key challenges.
We evaluate our technique using the established CompBench and TIFA score
benchmarks, demonstrating significant performance improvements compared to
existing methods. The source code will be made publicly available at
https://github.com/nextaistudio/BoxIt2BindIt.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17914" title="Abstract">arXiv:2402.17914</a> [<a href="/pdf/2402.17914" title="Download PDF">pdf</a>, <a href="/format/2402.17914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extracting Lexical Features from Dialects via Interpretable Dialect  Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+R">Roy Xie</a>, 
<a href="/search/cs?searchtype=author&query=Ahia%2C+O">Orevaoghene Ahia</a>, 
<a href="/search/cs?searchtype=author&query=Tsvetkov%2C+Y">Yulia Tsvetkov</a>, 
<a href="/search/cs?searchtype=author&query=Anastasopoulos%2C+A">Antonios Anastasopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at <a href="https://github.com/ruoyuxie/interpretable_dialect_classifier">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Identifying linguistic differences between dialects of a language often
requires expert knowledge and meticulous human analysis. This is largely due to
the complexity and nuance involved in studying various dialects. We present a
novel approach to extract distinguishing lexical features of dialects by
utilizing interpretable dialect classifiers, even in the absence of human
experts. We explore both post-hoc and intrinsic approaches to interpretability,
conduct experiments on Mandarin, Italian, and Low Saxon, and experimentally
demonstrate that our method successfully identifies key language-specific
lexical features that contribute to dialectal variations.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17916" title="Abstract">arXiv:2402.17916</a> [<a href="/pdf/2402.17916" title="Download PDF">pdf</a>, <a href="/format/2402.17916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-Resistant Math Word Problem Generation via Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+R">Roy Xie</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chengxuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junlin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dhingra%2C+B">Bhuwan Dhingra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at <a href="https://github.com/ruoyuxie/adversarial_mwps_generation">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have significantly transformed the educational
landscape. As current plagiarism detection tools struggle to keep pace with
LLMs' rapid advancements, the educational community faces the challenge of
assessing students' true problem-solving abilities in the presence of LLMs. In
this work, we explore a new paradigm for ensuring fair evaluation -- generating
adversarial examples which preserve the structure and difficulty of the
original questions aimed for assessment, but are unsolvable by LLMs. Focusing
on the domain of math word problems, we leverage abstract syntax trees to
structurally generate adversarial examples that cause LLMs to produce incorrect
answers by simply editing the numeric values in the problems. We conduct
experiments on various open- and closed-source LLMs, quantitatively and
qualitatively demonstrating that our method significantly degrades their math
problem-solving ability. We identify shared vulnerabilities among LLMs and
propose a cost-effective approach to attack high-cost models. Additionally, we
conduct automatic analysis on math problems and investigate the cause of
failure to guide future research on LLM's mathematical capability.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17917" title="Abstract">arXiv:2402.17917</a> [<a href="/pdf/2402.17917" title="Download PDF">pdf</a>, <a href="/format/2402.17917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative learning of common latent representations in routinely  collected multivariate ICU physiological signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haule%2C+H">Hollan Haule</a>, 
<a href="/search/cs?searchtype=author&query=Piper%2C+I">Ian Piper</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+P">Patricia Jones</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+T+M">Tsz-Yan Milly Lo</a>, 
<a href="/search/cs?searchtype=author&query=Escudero%2C+J">Javier Escudero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In Intensive Care Units (ICU), the abundance of multivariate time series
presents an opportunity for machine learning (ML) to enhance patient
phenotyping. In contrast to previous research focused on electronic health
records (EHR), here we propose an ML approach for phenotyping using routinely
collected physiological time series data. Our new algorithm integrates Long
Short-Term Memory (LSTM) networks with collaborative filtering concepts to
identify common physiological states across patients. Tested on real-world ICU
clinical data for intracranial hypertension (IH) detection in patients with
brain injury, our method achieved an area under the curve (AUC) of 0.889 and
average precision (AP) of 0.725. Moreover, our algorithm outperforms
autoencoders in learning more structured latent representations of the
physiological signals. These findings highlight the promise of our methodology
for patient phenotyping, leveraging routinely collected multivariate time
series to improve clinical care practices.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17918" title="Abstract">arXiv:2402.17918</a> [<a href="/pdf/2402.17918" title="Download PDF">pdf</a>, <a href="/format/2402.17918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Seeker&#x27;s Dilemma: Realistic Formulation and Benchmarking for  Hardware Trojan Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarihi%2C+A">Amin Sarihi</a>, 
<a href="/search/cs?searchtype=author&query=Patooghy%2C+A">Ahmad Patooghy</a>, 
<a href="/search/cs?searchtype=author&query=Badawy%2C+A+A">Abdel-Hameed A. Badawy</a>, 
<a href="/search/cs?searchtype=author&query=Jamieson%2C+P">Peter Jamieson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR); Machine Learning (cs.LG)

</div>
<p class="mathjax">This work focuses on advancing security research in the hardware design space
by formally defining the realistic problem of Hardware Trojan (HT) detection.
The goal is to model HT detection more closely to the real world, i.e.,
describing the problem as "The Seeker's Dilemma" (an extension of Hide&amp;Seek on
a graph), where a detecting agent is unaware of whether circuits are infected
by HTs or not. Using this theoretical problem formulation, we create a
benchmark that consists of a mixture of HT-free and HT-infected restructured
circuits while preserving their original functionalities. The restructured
circuits are randomly infected by HTs, causing a situation where the defender
is uncertain if a circuit is infected or not. We believe that our innovative
dataset will help the community better judge the detection quality of different
methods by comparing their success rates in circuit classification. We use our
developed benchmark to evaluate three state-of-the-art HT detection tools to
show baseline results for this approach. We use Principal Component Analysis to
assess the strength of our benchmark, where we observe that some restructured
HT-infected circuits are mapped closely to HT-free circuits, leading to
significant label misclassification by detectors.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17925" title="Abstract">arXiv:2402.17925</a> [<a href="/pdf/2402.17925" title="Download PDF">pdf</a>, <a href="/format/2402.17925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> [RE] Modeling Personalized Item Frequency Information for Next-basket  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garcarz%2C+S">S&#x142;awomir Garcarz</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+A">Avik Pal</a>, 
<a href="/search/cs?searchtype=author&query=Praat%2C+P">Pim Praat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">This paper focuses on reproducing and extending the results of the paper:
"Modeling Personalized Item Frequency Information for Next-basket
Recommendation" which introduced the TIFU-KNN model and proposed to utilize
Personalized Item Frequency (PIF) for Next Basket Recommendation (NBR). We
utilized publicly available grocery shopping datasets used in the original
paper and incorporated additional datasets to assess the generalizability of
the findings. We evaluated the performance of the models using metrics such as
Recall@K, NDCG@K, personalized-hit ratio (PHR), and Mean Reciprocal Rank (MRR).
Furthermore, we conducted a thorough examination of fairness by considering
user characteristics such as average basket size, item popularity, and novelty.
Lastly, we introduced novel $\beta$-VAE architecture to model NBR. The
experimental results confirmed that the reproduced model, TIFU-KNN, outperforms
the baseline model, Personal Top Frequency, on various datasets and metrics.
The findings also highlight the challenges posed by smaller basket sizes in
some datasets and suggest avenues for future research to improve NBR
performance.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17927" title="Abstract">arXiv:2402.17927</a> [<a href="/pdf/2402.17927" title="Download PDF">pdf</a>, <a href="/ps/2402.17927" title="Download PostScript">ps</a>, <a href="/format/2402.17927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MCSat-based Finite Field Reasoning in the Yices2 SMT Solver
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hader%2C+T">Thomas Hader</a>, 
<a href="/search/cs?searchtype=author&query=Kaufmann%2C+D">Daniela Kaufmann</a>, 
<a href="/search/cs?searchtype=author&query=Irfan%2C+A">Ahmed Irfan</a>, 
<a href="/search/cs?searchtype=author&query=Graham-Lengrand%2C+S">St&#xe9;phane Graham-Lengrand</a>, 
<a href="/search/cs?searchtype=author&query=Kov%C3%A1cs%2C+L">Laura Kov&#xe1;cs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">This system description introduces an enhancement to the Yices2 SMT solver,
enabling it to reason over non-linear polynomial systems over finite fields.
Our reasoning approach fits into the model-constructing satisfiability (MCSat)
framework and is based on zero decomposition techniques, which find finite
basis explanations for theory conflicts over finite fields. As the MCSat solver
within Yices2 can support (and combine) several theories via theory plugins, we
implemented our reasoning approach as a new plugin for finite fields and
extended Yices2's frontend to parse finite field problems, making our
implementation the first MCSat-based reasoning engine for finite fields. We
present its evaluation on finite field benchmarks, comparing it against cvc5.
Additionally, our work leverages the modular architecture of the MCSat solver
in Yices2 to provide a foundation for the rapid implementation of further
reasoning techniques for this theory.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17929" title="Abstract">arXiv:2402.17929</a> [<a href="/pdf/2402.17929" title="Download PDF">pdf</a>, <a href="/ps/2402.17929" title="Download PostScript">ps</a>, <a href="/format/2402.17929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decremental $(1+&#x3b5;)$-Approximate Maximum Eigenvector: Dynamic  Power Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adil%2C+D">Deeksha Adil</a>, 
<a href="/search/cs?searchtype=author&query=Saranurak%2C+T">Thatchaphol Saranurak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We present a dynamic algorithm for maintaining $(1+\epsilon)$-approximate
maximum eigenvector and eigenvalue of a positive semi-definite matrix $A$
undergoing \emph{decreasing} updates, i.e., updates which may only decrease
eigenvalues. Given a vector $v$ updating $A\gets A-vv^{\top}$, our algorithm
takes $\tilde{O}(\mathrm{nnz}(v))$ amortized update time, i.e., polylogarithmic
per non-zeros in the update vector.
<br />Our technique is based on a novel analysis of the influential power method in
the dynamic setting. The two previous sets of techniques have the following
drawbacks (1) algebraic techniques can maintain exact solutions but their
update time is at least polynomial per non-zeros, and (2) sketching techniques
admit polylogarithmic update time but suffer from a crude additive
approximation.
<br />Our algorithm exploits an oblivious adversary. Interestingly, we show that
any algorithm with polylogarithmic update time per non-zeros that works against
an adaptive adversary and satisfies an additional natural property would imply
a breakthrough for checking psd-ness of matrices in $\tilde{O}(n^{2})$ time,
instead of $O(n^{\omega})$ time.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17930" title="Abstract">arXiv:2402.17930</a> [<a href="/pdf/2402.17930" title="Download PDF">pdf</a>, <a href="/format/2402.17930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pragmatic Instruction Following and Goal Assistance via Cooperative  Language-Guided Inverse Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhi-Xuan%2C+T">Tan Zhi-Xuan</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+L">Lance Ying</a>, 
<a href="/search/cs?searchtype=author&query=Mansinghka%2C+V">Vikash Mansinghka</a>, 
<a href="/search/cs?searchtype=author&query=Tenenbaum%2C+J+B">Joshua B. Tenenbaum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAMAS 2024. 8 pages (excl. references), 5 figures/tables. (Appendix: 8 pages, 8 figures/tables). Code available at: <a href="https://github.com/probcomp/CLIPS.jl">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">People often give instructions whose meaning is ambiguous without further
context, expecting that their actions or goals will disambiguate their
intentions. How can we build assistive agents that follow such instructions in
a flexible, context-sensitive manner? This paper introduces cooperative
language-guided inverse plan search (CLIPS), a Bayesian agent architecture for
pragmatic instruction following and goal assistance. Our agent assists a human
by modeling them as a cooperative planner who communicates joint plans to the
assistant, then performs multimodal Bayesian inference over the human's goal
from actions and language, using large language models (LLMs) to evaluate the
likelihood of an instruction given a hypothesized plan. Given this posterior,
our assistant acts to minimize expected goal achievement cost, enabling it to
pragmatically follow ambiguous instructions and provide effective assistance
even when uncertain about the goal. We evaluate these capabilities in two
cooperative planning domains (Doors, Keys &amp; Gems and VirtualHome), finding that
CLIPS significantly outperforms GPT-4V, LLM-based literal instruction following
and unimodal inverse planning in both accuracy and helpfulness, while closely
matching the inferences and assistive judgments provided by human raters.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17932" title="Abstract">arXiv:2402.17932</a> [<a href="/pdf/2402.17932" title="Download PDF">pdf</a>, <a href="/format/2402.17932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Heterogeneous Agent Model of Mortgage Servicing: An Income-based  Relief Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garg%2C+D">Deepeka Garg</a>, 
<a href="/search/cs?searchtype=author&query=Evans%2C+B+P">Benjamin Patrick Evans</a>, 
<a href="/search/cs?searchtype=author&query=Ardon%2C+L">Leo Ardon</a>, 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+A+L">Annapoorani Lakshmi Narayanan</a>, 
<a href="/search/cs?searchtype=author&query=Vann%2C+J">Jared Vann</a>, 
<a href="/search/cs?searchtype=author&query=Madhushani%2C+U">Udari Madhushani</a>, 
<a href="/search/cs?searchtype=author&query=Henry-Nickie%2C+M">Makada Henry-Nickie</a>, 
<a href="/search/cs?searchtype=author&query=Ganesh%2C+S">Sumitra Ganesh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 - AI in Finance for Social Impact
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; General Finance (q-fin.GN)

</div>
<p class="mathjax">Mortgages account for the largest portion of household debt in the United
States, totaling around \$12 trillion nationwide. In times of financial
hardship, alleviating mortgage burdens is essential for supporting affected
households. The mortgage servicing industry plays a vital role in offering this
assistance, yet there has been limited research modelling the complex
relationship between households and servicers. To bridge this gap, we developed
an agent-based model that explores household behavior and the effectiveness of
relief measures during financial distress.
<br />Our model represents households as adaptive learning agents with realistic
financial attributes. These households experience exogenous income shocks,
which may influence their ability to make mortgage payments. Mortgage servicers
provide relief options to these households, who then choose the most suitable
relief based on their unique financial circumstances and individual
preferences. We analyze the impact of various external shocks and the success
of different mortgage relief strategies on specific borrower subgroups.
<br />Through this analysis, we show that our model can not only replicate
real-world mortgage studies but also act as a tool for conducting a broad range
of what-if scenario analyses. Our approach offers fine-grained insights that
can inform the development of more effective and inclusive mortgage relief
solutions.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17933" title="Abstract">arXiv:2402.17933</a> [<a href="/pdf/2402.17933" title="Download PDF">pdf</a>, <a href="/format/2402.17933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ICAT: An Indoor Connected and Autonomous Testbed for Vehicle Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhaofeng Tian</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">William He</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+B">Boyang Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+R">Ren Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Foorginejad%2C+E">Erfan Foorginejad</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Weisong Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Indoor autonomous driving testbeds have emerged to complement expensive
outdoor testbeds and virtual simulations, offering scalable and cost-effective
solutions for research in navigation, traffic optimization, and swarm
intelligence. However, they often lack the robust sensing and computing
infrastructure for advanced research. Addressing these limitations, we
introduce the Indoor Connected Autonomous Testbed (ICAT), a platform that not
only tackles the unique challenges of indoor autonomous driving but also
innovates vehicle computing and V2X communication. Moreover, ICAT leverages
digital twins through CARLA and SUMO simulations, facilitating both centralized
and decentralized autonomy deployments.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17934" title="Abstract">arXiv:2402.17934</a> [<a href="/pdf/2402.17934" title="Download PDF">pdf</a>, <a href="/format/2402.17934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multitask Multilingual Model Adaptation with Featurized Low-Rank  Mixtures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chu-Cheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+J+H">Jonathan H. Clark</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Han Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Whitehouse%2C+C">Chenxi Whitehouse</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hongkun Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Adapting pretrained large language models (LLMs) to various downstream tasks
in tens or hundreds of human languages is computationally expensive.
Parameter-efficient fine-tuning (PEFT) significantly reduces the adaptation
cost, by tuning only a small amount of parameters. However, directly applying
PEFT methods such as LoRA (Hu et al., 2022) on diverse dataset mixtures could
lead to suboptimal performance due to limited parameter capacity and negative
interference among different datasets. In this work, we propose Featurized
Low-rank Mixtures (FLix), a novel PEFT method designed for effective multitask
multilingual tuning. FLix associates each unique dataset feature, such as the
dataset's language or task, with its own low-rank weight update parameters. By
composing feature-specific parameters for each dataset, FLix can accommodate
diverse dataset mixtures and generalize better to unseen datasets. Our
experiments show that FLix leads to significant improvements over a variety of
tasks for both supervised learning and zero-shot settings using different
training data mixtures.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17936" title="Abstract">arXiv:2402.17936</a> [<a href="/pdf/2402.17936" title="Download PDF">pdf</a>, <a href="/format/2402.17936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Acquiring Linguistic Knowledge from Multimodal Input
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amariucai%2C+T">Theodor Amariucai</a>, 
<a href="/search/cs?searchtype=author&query=Warstadt%2C+A">Alex Warstadt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In contrast to children, language models (LMs) exhibit considerably inferior
data efficiency when acquiring language. In this submission to the BabyLM
Challenge (Warstadt et al., 2023), we test the hypothesis that this data
efficiency gap is partly caused by a lack of multimodal input and grounding in
the learning environment of typical language models. Although previous work
looking into this question found that multimodal training can even harm
language-only performance, we speculate that these findings can be attributed
to catastrophic forgetting of complex language due to fine-tuning on captions
data. To test our hypothesis, we perform an ablation study on FLAVA (Singh et
al., 2022), a multimodal vision-and-language model, independently varying the
volume of text and vision input to quantify how much text data (if any) can be
offset by vision at different data scales. We aim to limit catastrophic
forgetting through a multitask pretraining regime that includes unimodal
text-only tasks and data sampled from WiT, the relatively diverse
Wikipedia-based dataset (Srinivasan et al., 2021). Our results are largely
negative: Multimodal pretraining does not harm our models' language performance
but does not consistently help either. That said, our conclusions are limited
by our having been able to conduct only a small number of runs. While we must
leave open the possibility that multimodal input explains some of the gap in
data efficiency between LMs and humans, positive evidence for this hypothesis
will require better architectures and techniques for multimodal training.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17937" title="Abstract">arXiv:2402.17937</a> [<a href="/pdf/2402.17937" title="Download PDF">pdf</a>, <a href="/format/2402.17937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can an LLM-Powered Socially Assistive Robot Effectively and Safely  Deliver Cognitive Behavioral Therapy? A Study With University Students
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kian%2C+M+J">Mina J. Kian</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+M">Mingyu Zong</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+K">Katrin Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Abhyuday Singh</a>, 
<a href="/search/cs?searchtype=author&query=Velentza%2C+A">Anna-Maria Velentza</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+P">Pau Sang</a>, 
<a href="/search/cs?searchtype=author&query=Upadhyay%2C+S">Shriya Upadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Anika Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Faruki%2C+M+A">Misha A. Faruki</a>, 
<a href="/search/cs?searchtype=author&query=Browning%2C+W">Wallace Browning</a>, 
<a href="/search/cs?searchtype=author&query=Arnold%2C+S+M+R">Sebastien M. R. Arnold</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamachari%2C+B">Bhaskar Krishnamachari</a>, 
<a href="/search/cs?searchtype=author&query=Mataric%2C+M+J">Maja J. Mataric</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Cognitive behavioral therapy (CBT) is a widely used therapeutic method for
guiding individuals toward restructuring their thinking patterns as a means of
addressing anxiety, depression, and other challenges. We developed a large
language model (LLM)-powered prompt-engineered socially assistive robot (SAR)
that guides participants through interactive CBT at-home exercises. We
evaluated the performance of the SAR through a 15-day study with 38 university
students randomly assigned to interact daily with the robot or a chatbot (using
the same LLM), or complete traditional CBT worksheets throughout the duration
of the study. We measured weekly therapeutic outcomes, changes in
pre-/post-session anxiety measures, and adherence to completing CBT exercises.
We found that self-reported measures of general psychological distress
significantly decreased over the study period in the robot and worksheet
conditions but not the chatbot condition. Furthermore, the SAR enabled
significant single-session improvements for more sessions than the other two
conditions combined. Our findings suggest that SAR-guided LLM-powered CBT may
be as effective as traditional worksheet methods in supporting therapeutic
progress from the beginning to the end of the study and superior in decreasing
user anxiety immediately after completing the CBT exercise.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17938" title="Abstract">arXiv:2402.17938</a> [<a href="/pdf/2402.17938" title="Download PDF">pdf</a>, <a href="/format/2402.17938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EmMark: Robust Watermarks for IP Protection of Embedded Quantized Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruisi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Koushanfar%2C+F">Farinaz Koushanfar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accept to DAC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">This paper introduces EmMark,a novel watermarking framework for protecting
the intellectual property (IP) of embedded large language models deployed on
resource-constrained edge devices. To address the IP theft risks posed by
malicious end-users, EmMark enables proprietors to authenticate ownership by
querying the watermarked model weights and matching the inserted signatures.
EmMark's novelty lies in its strategic watermark weight parameters selection,
nsuring robustness and maintaining model quality. Extensive proof-of-concept
evaluations of models from OPT and LLaMA-2 families demonstrate EmMark's
fidelity, achieving 100% success in watermark extraction with model performance
preservation. EmMark also showcased its resilience against watermark removal
and forging attacks.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17940" title="Abstract">arXiv:2402.17940</a> [<a href="/pdf/2402.17940" title="Download PDF">pdf</a>, <a href="/format/2402.17940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly Private Information Retrieval from Heterogeneously Trusted  Servers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y+S">Yu Shin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Ruida Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+C">Chao Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages 3 figures. arXiv admin note: text overlap with <a href="/abs/2205.01611">arXiv:2205.01611</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We study the problem of weakly private information retrieval (PIR) when there
is heterogeneity in servers' trustfulness under the maximal leakage (Max-L)
metric and mutual information (MI) metric. A user wishes to retrieve a desired
message from N non-colluding servers efficiently, such that the identity of the
desired message is not leaked in a significant manner; however, some servers
can be more trustworthy than others. We propose a code construction for this
setting and optimize the probability distribution for this construction. For
the Max-L metric, it is shown that the optimal probability allocation for the
proposed scheme essentially separates the delivery patterns into two parts: a
completely private part that has the same download overhead as the
capacity-achieving PIR code, and a non-private part that allows complete
privacy leakage but has no download overhead by downloading only from the most
trustful server. The optimal solution is established through a sophisticated
analysis of the underlying convex optimization problem, and a reduction between
the homogeneous setting and the heterogeneous setting. For the MI metric, the
homogeneous case is studied first for which the code can be optimized with an
explicit probability assignment, while a closed-form solution becomes
intractable for the heterogeneous case. Numerical results are provided for both
cases to corroborate the theoretical analysis.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17944" title="Abstract">arXiv:2402.17944</a> [<a href="/pdf/2402.17944" title="Download PDF">pdf</a>, <a href="/format/2402.17944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models on Tabular Data -- A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+X">Xi Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weijie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+F+A">Fiona Anting Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiani Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Ziqing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yanjun Qi</a>, 
<a href="/search/cs?searchtype=author&query=Nickleach%2C+S">Scott Nickleach</a>, 
<a href="/search/cs?searchtype=author&query=Socolinsky%2C+D">Diego Socolinsky</a>, 
<a href="/search/cs?searchtype=author&query=Sengamedu%2C+S">Srinivasan Sengamedu</a>, 
<a href="/search/cs?searchtype=author&query=Faloutsos%2C+C">Christos Faloutsos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 3 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent breakthroughs in large language modeling have facilitated rigorous
exploration of their application in diverse tasks related to tabular data
modeling, such as prediction, tabular data synthesis, question answering, and
table understanding. Each task presents unique challenges and opportunities.
However, there is currently a lack of comprehensive review that summarizes and
compares the key techniques, metrics, datasets, models, and optimization
approaches in this research domain. This survey aims to address this gap by
consolidating recent progress in these areas, offering a thorough survey and
taxonomy of the datasets, metrics, and methodologies utilized. It identifies
strengths, limitations, unexplored territories, and gaps in the existing
literature, while providing some insights for future research directions in
this vital and rapidly evolving field. It also provides relevant code and
datasets references. Through this comprehensive review, we hope to provide
interested readers with pertinent references and insightful perspectives,
empowering them with the necessary tools and knowledge to effectively navigate
and address the prevailing challenges in the field.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17946" title="Abstract">arXiv:2402.17946</a> [<a href="/pdf/2402.17946" title="Download PDF">pdf</a>, <a href="/format/2402.17946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient-Free Adaptive Global Pruning for Pre-trained Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+G">Guangji Bai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yijiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+C">Chen Ling</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kibaek Kim</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The transformative impact of large language models (LLMs) like LLaMA and GPT
on natural language processing is countered by their prohibitive computational
demands. Pruning has emerged as a pivotal compression strategy, introducing
sparsity to enhance both memory and computational efficiency. Yet, traditional
global pruning is impractical for LLMs due to scalability issues, while local
pruning, despite its efficiency, leads to suboptimal solutions. Addressing
these challenges, we propose Adaptive Global Pruning (AdaGP), a novel framework
that redefines the global pruning process into manageable, coordinated
subproblems, allowing for resource-efficient optimization with global
optimality. AdaGP's approach, which conceptualizes LLMs as a chain of modular
functions and leverages auxiliary variables for problem decomposition, not only
facilitates a pragmatic application on LLMs but also demonstrates significant
performance improvements, particularly in high-sparsity regimes where it
surpasses current state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17954" title="Abstract">arXiv:2402.17954</a> [<a href="/pdf/2402.17954" title="Download PDF">pdf</a>, <a href="/format/2402.17954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilingual Speech Models for Automatic Speech Recognition Exhibit  Gender Performance Gaps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Attanasio%2C+G">Giuseppe Attanasio</a>, 
<a href="/search/cs?searchtype=author&query=Savoldi%2C+B">Beatrice Savoldi</a>, 
<a href="/search/cs?searchtype=author&query=Fucci%2C+D">Dennis Fucci</a>, 
<a href="/search/cs?searchtype=author&query=Hovy%2C+D">Dirk Hovy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages. Code and artifacts at <a href="https://github.com/g8a9/multilingual-asr-gender-gap">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Current voice recognition approaches use multi-task, multilingual models for
speech tasks like Automatic Speech Recognition (ASR) to make them applicable to
many languages without substantial changes. However, broad language coverage
can still mask performance gaps within languages, for example, across genders.
We systematically evaluate multilingual ASR systems on gendered performance
gaps. Using two popular models on three datasets in 19 languages across seven
language families, we find clear gender disparities. However, the advantaged
group varies between languages. While there are no significant differences
across groups in phonetic variables (pitch, speaking rate, etc.), probing the
model's internal states reveals a negative correlation between probe
performance and the gendered performance gap. I.e., the easier to distinguish
speaker gender in a language, the more the models favor female speakers. Our
results show that group disparities remain unsolved despite great progress on
multi-tasking and multilinguality. We provide first valuable insights for
evaluating gender gaps in multilingual ASR systems. We release all code and
artifacts at https://github.com/g8a9/multilingual-asr-gender-gap.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17959" title="Abstract">arXiv:2402.17959</a> [<a href="/pdf/2402.17959" title="Download PDF">pdf</a>, <a href="/format/2402.17959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Iterative Associative Memory Model for Empathetic Response Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhou Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhaochun Ren</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haizhou Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaofei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+X">Xiangwen Liao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Empathetic response generation is to comprehend the cognitive and emotional
states in dialogue utterances and generate proper responses. Psychological
theories posit that comprehending emotional and cognitive states necessitates
iteratively capturing and understanding associated words across dialogue
utterances. However, existing approaches regard dialogue utterances as either a
long sequence or independent utterances for comprehension, which are prone to
overlook the associated words between them. To address this issue, we propose
an Iterative Associative Memory Model (IAMM) for empathetic response
generation. Specifically, we employ a novel second-order interaction attention
mechanism to iteratively capture vital associated words between dialogue
utterances and situations, dialogue history, and a memory module (for storing
associated words), thereby accurately and nuancedly comprehending the
utterances. We conduct experiments on the Empathetic-Dialogue dataset. Both
automatic and human evaluations validate the efficacy of the model. Meanwhile,
variant experiments on LLMs also demonstrate that attending to associated words
improves empathetic comprehension and expression.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17960" title="Abstract">arXiv:2402.17960</a> [<a href="/pdf/2402.17960" title="Download PDF">pdf</a>, <a href="/format/2402.17960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rapid hyperspectral photothermal mid-infrared spectroscopic imaging from  sparse data for gynecologic cancer tissue subtyping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reihanisaransari%2C+R">Reza Reihanisaransari</a>, 
<a href="/search/cs?searchtype=author&query=Gajjela%2C+C+C">Chalapathi Charan Gajjela</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xinyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ishrak%2C+R">Ragib Ishrak</a>, 
<a href="/search/cs?searchtype=author&query=Corvigno%2C+S">Sara Corvigno</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yanping Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinsong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sood%2C+A+K">Anil K. Sood</a>, 
<a href="/search/cs?searchtype=author&query=Mayerich%2C+D">David Mayerich</a>, 
<a href="/search/cs?searchtype=author&query=Berisha%2C+S">Sebastian Berisha</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+R">Rohith Reddy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Biomolecules (q-bio.BM); Quantitative Methods (q-bio.QM); Tissues and Organs (q-bio.TO)

</div>
<p class="mathjax">Ovarian cancer detection has traditionally relied on a multi-step process
that includes biopsy, tissue staining, and morphological analysis by
experienced pathologists. While widely practiced, this conventional approach
suffers from several drawbacks: it is qualitative, time-intensive, and heavily
dependent on the quality of staining. Mid-infrared (MIR) hyperspectral
photothermal imaging is a label-free, biochemically quantitative technology
that, when combined with machine learning algorithms, can eliminate the need
for staining and provide quantitative results comparable to traditional
histology. However, this technology is slow. This work presents a novel
approach to MIR photothermal imaging that enhances its speed by an order of
magnitude. Our method significantly accelerates data collection by capturing a
combination of high-resolution and interleaved, lower-resolution infrared band
images and applying computational techniques for data interpolation. We
effectively minimize data collection requirements by leveraging sparse data
acquisition and employing curvelet-based reconstruction algorithms. This method
enables the reconstruction of high-quality, high-resolution images from
undersampled datasets and achieving a 10X improvement in data acquisition time.
We assessed the performance of our sparse imaging methodology using a variety
of quantitative metrics, including mean squared error (MSE), structural
similarity index (SSIM), and tissue subtype classification accuracies,
employing both random forest and convolutional neural network (CNN) models,
accompanied by ROC curves. Our statistically robust analysis, based on data
from 100 ovarian cancer patient samples and over 65 million data points,
demonstrates the method's capability to produce superior image quality and
accurately distinguish between different gynecological tissue types with
segmentation accuracy exceeding 95%.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17963" title="Abstract">arXiv:2402.17963</a> [<a href="/pdf/2402.17963" title="Download PDF">pdf</a>, <a href="/format/2402.17963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Design and Implementation of a High-Performance Log-Structured RAID  System for ZNS SSDs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiuping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shujie Han</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+P+P+C">Patrick P. C. Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Zoned Namespace (ZNS) defines a new abstraction for host software to flexibly
manage storage in flash-based SSDs as append-only zones. It also provides a
Zone Append primitive to further boost the write performance of ZNS SSDs by
exploiting intra-zone parallelism. However, making Zone Append effective for
reliable and scalable storage, in the form of a RAID array of multiple ZNS
SSDs, is non-trivial since Zone Append offloads address management to ZNS SSDs
and requires hosts to dedicatedly manage RAID stripes across multiple drives.
We propose ZapRAID, a high-performance log-structured RAID system for ZNS SSDs
by carefully exploiting Zone Append to achieve high write parallelism and
lightweight stripe management. ZapRAID adopts a group-based data layout with a
coarse-grained ordering across multiple groups of stripes, such that it can use
small-size metadata for stripe management on a per-group basis under Zone
Append. It further adopts hybrid data management to simultaneously achieve
intra-zone and inter-zone parallelism through a careful combination of both
Zone Append and Zone Write primitives. We evaluate ZapRAID using
microbenchmarks, trace-driven experiments, and real-application experiments.
Our evaluation results show that ZapRAID achieves high write throughput and
maintains high performance in normal reads, degraded reads, crash recovery, and
full-drive recovery.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17966" title="Abstract">arXiv:2402.17966</a> [<a href="/pdf/2402.17966" title="Download PDF">pdf</a>, <a href="/format/2402.17966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conformer: Embedding Continuous Attention in Vision Transformer for  Weather Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saleem%2C+H">Hira Saleem</a>, 
<a href="/search/cs?searchtype=author&query=Salim%2C+F">Flora Salim</a>, 
<a href="/search/cs?searchtype=author&query=Purcell%2C+C">Cormac Purcell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Operational weather forecasting system relies on computationally expensive
physics-based models. Although Transformers-based models have shown remarkable
potential in weather forecasting, Transformers are discrete models which limit
their ability to learn the continuous spatio-temporal features of the dynamical
weather system. We address this issue with Conformer, a spatio-temporal
Continuous Vision Transformer for weather forecasting. Conformer is designed to
learn the continuous weather evolution over time by implementing continuity in
the multi-head attention mechanism. The attention mechanism is encoded as a
differentiable function in the transformer architecture to model the complex
weather dynamics. We evaluate Conformer against a state-of-the-art Numerical
Weather Prediction (NWP) model and several deep learning based weather
forecasting models. Conformer outperforms some of the existing data-driven
models at all lead times while only being trained at lower resolution data.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17967" title="Abstract">arXiv:2402.17967</a> [<a href="/pdf/2402.17967" title="Download PDF">pdf</a>, <a href="/format/2402.17967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imitation-regularized Optimal Transport on Networks: Provable Robustness  and Application to Logistics Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oishi%2C+K">Koshi Oishi</a>, 
<a href="/search/cs?searchtype=author&query=Hashizume%2C+Y">Yota Hashizume</a>, 
<a href="/search/cs?searchtype=author&query=Jimbo%2C+T">Tomohiko Jimbo</a>, 
<a href="/search/cs?searchtype=author&query=Kaji%2C+H">Hirotaka Kaji</a>, 
<a href="/search/cs?searchtype=author&query=Kashima%2C+K">Kenji Kashima</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Network systems form the foundation of modern society, playing a critical
role in various applications. However, these systems are at significant risk of
being adversely affected by unforeseen circumstances, such as disasters.
Considering this, there is a pressing need for research to enhance the
robustness of network systems. Recently, in reinforcement learning, the
relationship between acquiring robustness and regularizing entropy has been
identified. Additionally, imitation learning is used within this framework to
reflect experts' behavior. However, there are no comprehensive studies on the
use of a similar imitation framework for optimal transport on networks.
Therefore, in this study, imitation-regularized optimal transport (I-OT) on
networks was investigated. It encodes prior knowledge on the network by
imitating a given prior distribution. The I-OT solution demonstrated robustness
in terms of the cost defined on the network. Moreover, we applied the I-OT to a
logistics planning problem using real data. We also examined the imitation and
apriori risk information scenarios to demonstrate the usefulness and
implications of the proposed method.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17969" title="Abstract">arXiv:2402.17969</a> [<a href="/pdf/2402.17969" title="Download PDF">pdf</a>, <a href="/format/2402.17969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision Language Model-based Caption Evaluation Method Leveraging Visual  Context Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maeda%2C+K">Koki Maeda</a>, 
<a href="/search/cs?searchtype=author&query=Kurita%2C+S">Shuhei Kurita</a>, 
<a href="/search/cs?searchtype=author&query=Miyanishi%2C+T">Taiki Miyanishi</a>, 
<a href="/search/cs?searchtype=author&query=Okazaki%2C+N">Naoaki Okazaki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Given the accelerating progress of vision and language modeling, accurate
evaluation of machine-generated image captions remains critical. In order to
evaluate captions more closely to human preferences, metrics need to
discriminate between captions of varying quality and content. However,
conventional metrics fail short of comparing beyond superficial matches of
words or embedding similarities; thus, they still need improvement. This paper
presents VisCE$^2$, a vision language model-based caption evaluation method.
Our method focuses on visual context, which refers to the detailed content of
images, including objects, attributes, and relationships. By extracting and
organizing them into a structured format, we replace the human-written
references with visual contexts and help VLMs better understand the image,
enhancing evaluation performance. Through meta-evaluation on multiple datasets,
we validated that VisCE$^2$ outperforms the conventional pre-trained metrics in
capturing caption quality and demonstrates superior consistency with human
judgment.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17970" title="Abstract">arXiv:2402.17970</a> [<a href="/pdf/2402.17970" title="Download PDF">pdf</a>, <a href="/format/2402.17970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Advanced Methodologies in Security Evaluation for LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiawei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+W">Weihong Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanchun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) represent an advanced evolution of earlier,
simpler language models. They boast enhanced abilities to handle complex
language patterns and generate coherent text, images, audios, and videos.
Furthermore, they can be fine-tuned for specific tasks. This versatility has
led to the proliferation and extensive use of numerous commercialized large
models. However, the rapid expansion of LLMs has raised security and ethical
concerns within the academic community. This emphasizes the need for ongoing
research into security evaluation during their development and deployment. Over
the past few years, a substantial body of research has been dedicated to the
security evaluation of large-scale models. This article an in-depth review of
the most recent advancements in this field, providing a comprehensive analysis
of commonly used evaluation metrics, advanced evaluation frameworks, and the
routine evaluation processes for LLMs. Furthermore, we also discuss the future
directions for advancing the security evaluation of LLMs.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17971" title="Abstract">arXiv:2402.17971</a> [<a href="/pdf/2402.17971" title="Download PDF">pdf</a>, <a href="/format/2402.17971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> All in a Single Image: Large Multimodal Models are In-Image Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wanyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhiqiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yihuai Lan</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Shan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+R+K">Roy Ka-Wei Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+E">Ee-Peng Lim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WIP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">This paper introduces a new in-context learning (ICL) mechanism called
In-Image Learning (I$^2$L) that combines demonstration examples, visual cues,
and instructions into a single image to enhance the capabilities of GPT-4V.
Unlike previous approaches that rely on converting images to text or
incorporating visual input into language models, I$^2$L consolidates all
information into one image and primarily leverages image processing,
understanding, and reasoning abilities. This has several advantages: it avoids
inaccurate textual descriptions of complex images, provides flexibility in
positioning demonstration examples, reduces the input burden, and avoids
exceeding input limits by eliminating the need for multiple images and lengthy
text. To further combine the strengths of different ICL methods, we introduce
an automatic strategy to select the appropriate ICL method for a data example
in a given task. We conducted experiments on MathVista and Hallusionbench to
test the effectiveness of I$^2$L in complex multimodal reasoning tasks and
mitigating language hallucination and visual illusion. Additionally, we
explored the impact of image resolution, the number of demonstration examples,
and their positions on the effectiveness of I$^2$L. Our code is publicly
available at https://github.com/AGI-Edgerunners/IIL.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17972" title="Abstract">arXiv:2402.17972</a> [<a href="/pdf/2402.17972" title="Download PDF">pdf</a>, <a href="/format/2402.17972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Generalization to Precision: Exploring SAM for Tool Segmentation in  Surgical Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oguine%2C+K+J">Kanyifeechukwu J. Oguine</a>, 
<a href="/search/cs?searchtype=author&query=Soberanis-Mukul%2C+R+D">Roger D. Soberanis-Mukul</a>, 
<a href="/search/cs?searchtype=author&query=Drenkow%2C+N">Nathan Drenkow</a>, 
<a href="/search/cs?searchtype=author&query=Unberath%2C+M">Mathias Unberath</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Purpose: Accurate tool segmentation is essential in computer-aided
procedures. However, this task conveys challenges due to artifacts' presence
and the limited training data in medical scenarios. Methods that generalize to
unseen data represent an interesting venue, where zero-shot segmentation
presents an option to account for data limitation. Initial exploratory works
with the Segment Anything Model (SAM) show that bounding-box-based prompting
presents notable zero-short generalization. However, point-based prompting
leads to a degraded performance that further deteriorates under image
corruption. We argue that SAM drastically over-segment images with high
corruption levels, resulting in degraded performance when only a single
segmentation mask is considered, while the combination of the masks overlapping
the object of interest generates an accurate prediction. Method: We use SAM to
generate the over-segmented prediction of endoscopic frames. Then, we employ
the ground-truth tool mask to analyze the results of SAM when the best single
mask is selected as prediction and when all the individual masks overlapping
the object of interest are combined to obtain the final predicted mask. We
analyze the Endovis18 and Endovis17 instrument segmentation datasets using
synthetic corruptions of various strengths and an In-House dataset featuring
counterfactually created real-world corruptions. Results: Combining the
over-segmented masks contributes to improvements in the IoU. Furthermore,
selecting the best single segmentation presents a competitive IoU score for
clean images. Conclusions: Combined SAM predictions present improved results
and robustness up to a certain corruption level. However, appropriate prompting
strategies are fundamental for implementing these models in the medical domain.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17975" title="Abstract">arXiv:2402.17975</a> [<a href="/pdf/2402.17975" title="Download PDF">pdf</a>, <a href="/format/2402.17975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample-Efficient Preference-based Reinforcement Learning with Dynamics  Aware Rewards
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Metcalf%2C+K">Katherine Metcalf</a>, 
<a href="/search/cs?searchtype=author&query=Sarabia%2C+M">Miguel Sarabia</a>, 
<a href="/search/cs?searchtype=author&query=Mackraz%2C+N">Natalie Mackraz</a>, 
<a href="/search/cs?searchtype=author&query=Theobald%2C+B">Barry-John Theobald</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CoRL 2023. arXiv admin note: substantial text overlap with <a href="/abs/2211.06527">arXiv:2211.06527</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Preference-based reinforcement learning (PbRL) aligns a robot behavior with
human preferences via a reward function learned from binary feedback over agent
behaviors. We show that dynamics-aware reward functions improve the sample
efficiency of PbRL by an order of magnitude. In our experiments we iterate
between: (1) learning a dynamics-aware state-action representation (z^{sa}) via
a self-supervised temporal consistency task, and (2) bootstrapping the
preference-based reward function from (z^{sa}), which results in faster policy
learning and better final policy performance. For example, on quadruped-walk,
walker-walk, and cheetah-run, with 50 preference labels we achieve the same
performance as existing approaches with 500 preference labels, and we recover
83\% and 66\% of ground truth reward policy performance versus only 38\% and
21\%. The performance gains demonstrate the benefits of explicitly learning a
dynamics-aware reward model. Repo: \texttt{https://github.com/apple/ml-reed}.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17976" title="Abstract">arXiv:2402.17976</a> [<a href="/pdf/2402.17976" title="Download PDF">pdf</a>, <a href="/format/2402.17976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Tracking Robustness with Auxiliary Adversarial Defense  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhewei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+R">Ruilong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qihe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Shuying Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+S">Shilin Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shijie Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Adversarial attacks in visual object tracking have significantly degraded the
performance of advanced trackers by introducing imperceptible perturbations
into images. These attack methods have garnered considerable attention from
researchers in recent years. However, there is still a lack of research on
designing adversarial defense methods specifically for visual object tracking.
To address these issues, we propose an effective additional pre-processing
network called DuaLossDef that eliminates adversarial perturbations during the
tracking process. DuaLossDef is deployed ahead of the search branche or
template branche of the tracker to apply defensive transformations to the input
images. Moreover, it can be seamlessly integrated with other visual trackers as
a plug-and-play module without requiring any parameter adjustments. We train
DuaLossDef using adversarial training, specifically employing Dua-Loss to
generate adversarial samples that simultaneously attack the classification and
regression branches of the tracker. Extensive experiments conducted on the
OTB100, LaSOT, and VOT2018 benchmarks demonstrate that DuaLossDef maintains
excellent defense robustness against adversarial attack methods in both
adaptive and non-adaptive attack scenarios. Moreover, when transferring the
defense network to other trackers, it exhibits reliable transferability.
Finally, DuaLossDef achieves a processing time of up to 5ms/frame, allowing
seamless integration with existing high-speed trackers without introducing
significant computational overhead. We will make our code publicly available
soon.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17978" title="Abstract">arXiv:2402.17978</a> [<a href="/pdf/2402.17978" title="Download PDF">pdf</a>, <a href="/format/2402.17978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imagine, Initialize, and Explore: An Effective Exploration Method in  Multi-Agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zeyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+L">Lipeng Wan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinrui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuoran Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xingyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+X">Xuguang Lan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 38th Annual AAAI Conference on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Effective exploration is crucial to discovering optimal strategies for
multi-agent reinforcement learning (MARL) in complex coordination tasks.
Existing methods mainly utilize intrinsic rewards to enable committed
exploration or use role-based learning for decomposing joint action spaces
instead of directly conducting a collective search in the entire
action-observation space. However, they often face challenges obtaining
specific joint action sequences to reach successful states in long-horizon
tasks. To address this limitation, we propose Imagine, Initialize, and Explore
(IIE), a novel method that offers a promising solution for efficient
multi-agent exploration in complex scenarios. IIE employs a transformer model
to imagine how the agents reach a critical state that can influence each
other's transition functions. Then, we initialize the environment at this state
using a simulator before the exploration phase. We formulate the imagination as
a sequence modeling problem, where the states, observations, prompts, actions,
and rewards are predicted autoregressively. The prompt consists of
timestep-to-go, return-to-go, influence value, and one-shot demonstration,
specifying the desired state and trajectory as well as guiding the action
generation. By initializing agents at the critical states, IIE significantly
increases the likelihood of discovering potentially important under-explored
regions. Despite its simplicity, empirical results demonstrate that our method
outperforms multi-agent exploration baselines on the StarCraft Multi-Agent
Challenge (SMAC) and SMACv2 environments. Particularly, IIE shows improved
performance in the sparse-reward SMAC tasks and produces more effective
curricula over the initialized states than other generative methods, such as
CVAE-GAN and diffusion models.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17979" title="Abstract">arXiv:2402.17979</a> [<a href="/pdf/2402.17979" title="Download PDF">pdf</a>, <a href="/format/2402.17979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble Methodology:Innovations in Credit Default Prediction Using  LightGBM, XGBoost, and LocalEnsemble
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Mengran Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ye Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yulu Gong</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+K">Kaijuan Xing</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jintong Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the realm of consumer lending, accurate credit default prediction stands
as a critical element in risk mitigation and lending decision optimization.
Extensive research has sought continuous improvement in existing models to
enhance customer experiences and ensure the sound economic functioning of
lending institutions. This study responds to the evolving landscape of credit
default prediction, challenging conventional models and introducing innovative
approaches. By building upon foundational research and recent innovations, our
work aims to redefine the standards of accuracy in credit default prediction,
setting a new benchmark for the industry. To overcome these challenges, we
present an Ensemble Methods framework comprising LightGBM, XGBoost, and
LocalEnsemble modules, each making unique contributions to amplify diversity
and improve generalization. By utilizing distinct feature sets, our methodology
directly tackles limitations identified in previous studies, with the
overarching goal of establishing a novel standard for credit default prediction
accuracy. Our experimental findings validate the effectiveness of the ensemble
model on the dataset, signifying substantial contributions to the field. This
innovative approach not only addresses existing obstacles but also sets a
precedent for advancing the accuracy and robustness of credit default
prediction models.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17982" title="Abstract">arXiv:2402.17982</a> [<a href="/pdf/2402.17982" title="Download PDF">pdf</a>, <a href="/format/2402.17982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative decoding of critical tokens for boosting factuality of  large language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lifeng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Baolin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Linfeng Song</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+H">Haitao Mi</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Ye Tian</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The most common training pipeline for large language models includes
pretraining, finetuning and aligning phases, with their respective resulting
models, such as the pretrained model and the finetuned model. Finetuned and
aligned models show improved abilities of instruction following and safe
generation, however their abilities to stay factual about the world are
impacted by the finetuning process. Furthermore, the common practice of using
sampling during generation also increases chances of hallucination. In this
work, we introduce a collaborative decoding framework to harness the high
factuality within pretrained models through the concept of critical tokens. We
first design a critical token classifier to decide which model to use for the
next token, and subsequently generates the next token using different decoding
strategies. Experiments with different models and datasets show that our
decoding framework is able to reduce model hallucination significantly,
showcasing the importance of the collaborative decoding framework.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17983" title="Abstract">arXiv:2402.17983</a> [<a href="/pdf/2402.17983" title="Download PDF">pdf</a>, <a href="/format/2402.17983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M3-VRD: Multimodal Multi-task Multi-teacher Visually-Rich Form Document  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yihao Ding</a>, 
<a href="/search/cs?searchtype=author&query=Vaiani%2C+L">Lorenzo Vaiani</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Caren Han</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jean Lee</a>, 
<a href="/search/cs?searchtype=author&query=Garza%2C+P">Paolo Garza</a>, 
<a href="/search/cs?searchtype=author&query=Poon%2C+J">Josiah Poon</a>, 
<a href="/search/cs?searchtype=author&query=Cagliero%2C+L">Luca Cagliero</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper presents a groundbreaking multimodal, multi-task, multi-teacher
joint-grained knowledge distillation model for visually-rich form document
understanding. The model is designed to leverage insights from both
fine-grained and coarse-grained levels by facilitating a nuanced correlation
between token and entity representations, addressing the complexities inherent
in form documents. Additionally, we introduce new inter-grained and
cross-grained loss functions to further refine diverse multi-teacher knowledge
distillation transfer process, presenting distribution gaps and a harmonised
understanding of form documents. Through a comprehensive evaluation across
publicly available form document understanding datasets, our proposed model
consistently outperforms existing baselines, showcasing its efficacy in
handling the intricate structures and content of visually complex form
documents.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17985" title="Abstract">arXiv:2402.17985</a> [<a href="/pdf/2402.17985" title="Download PDF">pdf</a>, <a href="/format/2402.17985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlattenQuant: Breaking Through the Inference Compute-bound for Large  Language Models with Per-tensor Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Shuang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fangyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+A">Aimin Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated state-of-the-art performance
across various tasks. However, the latency of inference and the large GPU
memory consumption of LLMs restrict their deployment performance. Recently,
there have been some efficient attempts to quantize LLMs, yet inference with
large batch size or long sequence still has the issue of being compute-bound.
Fine-grained quantization methods have showcased their proficiency in achieving
low-bit quantization for LLMs, while requiring FP16 data type for linear layer
computations, which is time-consuming when dealing with large batch size or
long sequence. In this paper, we introduce a method called FlattenQuant, which
significantly reduces the maximum value of the tensor by flattening the large
channels in the tensor, to achieve low bit per-tensor quantization with minimal
accuracy loss. Our experiments show that FlattenQuant can directly use 4 bits
to achieve 48.29% of the linear layer calculation in LLMs, with the remaining
layers using 8 bits. The 4-bit matrix multiplication introduced in the
FlattenQuant method can effectively address the compute-bound caused by large
matrix calculation. Our work achieves up to 2$\times$ speedup and 2.3$\times$
memory reduction for LLMs with negligible loss in accuracy.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17986" title="Abstract">arXiv:2402.17986</a> [<a href="/pdf/2402.17986" title="Download PDF">pdf</a>, <a href="/format/2402.17986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PolyOculus: Simultaneous Multi-view Image-based Novel View Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+J+J">Jason J. Yu</a>, 
<a href="/search/cs?searchtype=author&query=Aumentado-Armstrong%2C+T">Tristan Aumentado-Armstrong</a>, 
<a href="/search/cs?searchtype=author&query=Forghani%2C+F">Fereshteh Forghani</a>, 
<a href="/search/cs?searchtype=author&query=Derpanis%2C+K+G">Konstantinos G. Derpanis</a>, 
<a href="/search/cs?searchtype=author&query=Brubaker%2C+M+A">Marcus A. Brubaker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper considers the problem of generative novel view synthesis (GNVS),
generating novel, plausible views of a scene given a limited number of known
views. Here, we propose a set-based generative model that can simultaneously
generate multiple, self-consistent new views, conditioned on any number of
known views. Our approach is not limited to generating a single image at a time
and can condition on zero, one, or more views. As a result, when generating a
large number of views, our method is not restricted to a low-order
autoregressive generation approach and is better able to maintain generated
image quality over large sets of images. We evaluate the proposed model on
standard NVS datasets and show that it outperforms the state-of-the-art
image-based GNVS baselines. Further, we show that the model is capable of
generating sets of camera views that have no natural sequential ordering, like
loops and binocular trajectories, and significantly outperforms other methods
on such tasks.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17988" title="Abstract">arXiv:2402.17988</a> [<a href="/pdf/2402.17988" title="Download PDF">pdf</a>, <a href="/format/2402.17988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained Decoding for Code Language Models via Efficient Left and  Right Quotienting of Context-Sensitive Grammars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Melcer%2C+D">Daniel Melcer</a>, 
<a href="/search/cs?searchtype=author&query=Fulton%2C+N">Nathan Fulton</a>, 
<a href="/search/cs?searchtype=author&query=Gouda%2C+S+K">Sanjay Krishna Gouda</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+H">Haifeng Qian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, Code available at <a href="https://github.com/amazon-science/incremental-parsing">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
<p class="mathjax">Large Language Models are powerful tools for program synthesis and advanced
auto-completion, but come with no guarantee that their output code is
syntactically correct. This paper contributes an incremental parser that allows
early rejection of syntactically incorrect code, as well as efficient detection
of complete programs for fill-in-the-middle (FItM) tasks. We develop
Earley-style parsers that operate over left and right quotients of arbitrary
context-free grammars, and we extend our incremental parsing and quotient
operations to several context-sensitive features present in the grammars of
many common programming languages. The result of these contributions is an
efficient, general, and well-grounded method for left and right quotient
parsing.
<br />To validate our theoretical contributions -- and the practical effectiveness
of certain design decisions -- we evaluate our method on the particularly
difficult case of FItM completion for Python 3. Our results demonstrate that
constrained generation can significantly reduce the incidence of syntax errors
in recommended code.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18002" title="Abstract">arXiv:2402.18002</a> [<a href="/pdf/2402.18002" title="Download PDF">pdf</a>, <a href="/format/2402.18002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symmetry-aware Reinforcement Learning for Robotic Assembly under Partial  Observability with a Soft Wrist
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Hai Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Kozuno%2C+T">Tadashi Kozuno</a>, 
<a href="/search/cs?searchtype=author&query=Beltran-Hernandez%2C+C+C">Cristian C. Beltran-Hernandez</a>, 
<a href="/search/cs?searchtype=author&query=Hamaya%2C+M">Masashi Hamaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICRA-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This study tackles the representative yet challenging contact-rich
peg-in-hole task of robotic assembly, using a soft wrist that can operate more
safely and tolerate lower-frequency control signals than a rigid one. Previous
studies often use a fully observable formulation, requiring external setups or
estimators for the peg-to-hole pose. In contrast, we use a partially observable
formulation and deep reinforcement learning from demonstrations to learn a
memory-based agent that acts purely on haptic and proprioceptive signals.
Moreover, previous works do not incorporate potential domain symmetry and thus
must search for solutions in a bigger space. Instead, we propose to leverage
the symmetry for sample efficiency by augmenting the training data and
constructing auxiliary losses to force the agent to adhere to the symmetry.
Results in simulation with five different symmetric peg shapes show that our
proposed agent can be comparable to or even outperform a state-based agent. In
particular, the sample efficiency also allows us to learn directly on the real
robot within 3 hours.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18003" title="Abstract">arXiv:2402.18003</a> [<a href="/pdf/2402.18003" title="Download PDF">pdf</a>, <a href="/format/2402.18003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Infrared Small Target Detection via tensor $L_{2,1}$ norm minimization  and ASSTV regularization: A Novel Tensor Recovery Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhao%2C+J">Jiqian Zhao</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+A">An-Bao Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 38 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In recent years, there has been a noteworthy focus on infrared small target
detection, given its vital importance in processing signals from infrared
remote sensing. The considerable computational cost incurred by prior methods,
relying excessively on nuclear norm for noise separation, necessitates the
exploration of efficient alternatives. The aim of this research is to identify
a swift and resilient tensor recovery method for the efficient extraction of
infrared small targets from image sequences. Theoretical validation indicates
that smaller singular values predominantly contribute to constructing noise
information. In the exclusion process, tensor QR decomposition is employed to
reasonably reduce the size of the target tensor. Subsequently, we address a
tensor $L_{2,1}$ Norm Minimization via T-QR (TLNMTQR) based method to
effectively isolate the noise, markedly improving computational speed without
compromising accuracy. Concurrently, by integrating the asymmetric
spatial-temporal total variation regularization method (ASSTV), our objective
is to augment the flexibility and efficacy of our algorithm in handling time
series data. Ultimately, our method underwent rigorous testing with real-world
data, affirmatively showcasing the superiority of our algorithm in terms of
speed, precision, and robustness.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18005" title="Abstract">arXiv:2402.18005</a> [<a href="/pdf/2402.18005" title="Download PDF">pdf</a>, <a href="/format/2402.18005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Multi-Document Information Consolidation for Scientific  Sentiment Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Miao Li</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+J+H">Jey Han Lau</a>, 
<a href="/search/cs?searchtype=author&query=Hovy%2C+E">Eduard Hovy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Modern natural language generation systems with LLMs exhibit the capability
to generate a plausible summary of multiple documents; however, it is uncertain
if models truly possess the ability of information consolidation to generate
summaries, especially on those source documents with opinionated information.
To make scientific sentiment summarization more grounded, we hypothesize that
in peer review human meta-reviewers follow a three-layer framework of sentiment
consolidation to write meta-reviews and it represents the logic of summarizing
scientific sentiments in meta-review generation. The framework is validated via
human annotation. Based on the framework, we propose evaluation metrics to
assess the quality of generated meta-reviews, and we find that the hypothesis
of the sentiment consolidation framework works out empirically when we
incorporate it as prompts for LLMs to generate meta-reviews in extensive
experiments.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18007" title="Abstract">arXiv:2402.18007</a> [<a href="/pdf/2402.18007" title="Download PDF">pdf</a>, <a href="/format/2402.18007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixer is more than just a model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+Q">Qingfeng Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Letong Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recently, MLP structures have regained popularity, with MLP-Mixer standing
out as a prominent example. In the field of computer vision, MLP-Mixer is noted
for its ability to extract data information from both channel and token
perspectives, effectively acting as a fusion of channel and token information.
Indeed, Mixer represents a paradigm for information extraction that amalgamates
channel and token information. The essence of Mixer lies in its ability to
blend information from diverse perspectives, epitomizing the true concept of
"mixing" in the realm of neural network architectures. Beyond channel and token
considerations, it is possible to create more tailored mixers from various
perspectives to better suit specific task requirements. This study focuses on
the domain of audio recognition, introducing a novel model named Audio
Spectrogram Mixer with Roll-Time and Hermit FFT (ASM-RH) that incorporates
insights from both time and frequency domains. Experimental results demonstrate
that ASM-RH is particularly well-suited for audio data and yields promising
outcomes across multiple classification tasks.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18008" title="Abstract">arXiv:2402.18008</a> [<a href="/pdf/2402.18008" title="Download PDF">pdf</a>, <a href="/format/2402.18008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and Interpretable 2D Homography Decomposition:  Similarity-Kernel-Similarity and Affine-Core-Affine Transformations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+S">Shen Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhanhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Lingxi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiachun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Siyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Shuhan Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we present two fast and interpretable decomposition methods
for 2D homography, which are named Similarity-Kernel-Similarity (SKS) and
Affine-Core-Affine (ACA) transformations respectively. Under the minimal
$4$-point configuration, the first and the last similarity transformations in
SKS are computed by two anchor points on target and source planes,
respectively. Then, the other two point correspondences can be exploited to
compute the middle kernel transformation with only four parameters.
Furthermore, ACA uses three anchor points to compute the first and the last
affine transformations, followed by computation of the middle core
transformation utilizing the other one point correspondence. ACA can compute a
homography up to a scale with only $85$ floating-point operations (FLOPs),
without even any division operations. Therefore, as a plug-in module, ACA
facilitates the traditional feature-based Random Sample Consensus (RANSAC)
pipeline, as well as deep homography pipelines estimating $4$-point offsets. In
addition to the advantages of geometric parameterization and computational
efficiency, SKS and ACA can express each element of homography by a polynomial
of input coordinates ($7$th degree to $9$th degree), extend the existing
essential Similarity-Affine-Projective (SAP) decomposition and calculate 2D
affine transformations in a unified way. Source codes are released in
https://github.com/cscvlab/SKS-Homography.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18011" title="Abstract">arXiv:2402.18011</a> [<a href="/pdf/2402.18011" title="Download PDF">pdf</a>, <a href="/format/2402.18011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representing 3D sparse map points and lines for camera relocalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bui%2C+B">Bach-Thuan Bui</a>, 
<a href="/search/cs?searchtype=author&query=Bui%2C+H">Huy-Hoang Bui</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+D">Dinh-Tuan Tran</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Joo-Ho Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advancements in visual localization and mapping have demonstrated
considerable success in integrating point and line features. However, expanding
the localization framework to include additional mapping components frequently
results in increased demand for memory and computational resources dedicated to
matching tasks. In this study, we show how a lightweight neural network can
learn to represent both 3D point and line features, and exhibit leading pose
accuracy by harnessing the power of multiple learned mappings. Specifically, we
utilize a single transformer block to encode line features, effectively
transforming them into distinctive point-like descriptors. Subsequently, we
treat these point and line descriptor sets as distinct yet interconnected
feature sets. Through the integration of self- and cross-attention within
several graph layers, our method effectively refines each feature before
regressing 3D maps using two simple MLPs. In comprehensive experiments, our
indoor localization findings surpass those of Hloc and Limap across both
point-based and line-assisted configurations. Moreover, in outdoor scenarios,
our method secures a significant lead, marking the most considerable
enhancement over state-of-the-art learning-based methodologies. The source code
and demo videos of this work are publicly available at:
https://thpjp.github.io/pl2map/
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18012" title="Abstract">arXiv:2402.18012</a> [<a href="/pdf/2402.18012" title="Download PDF">pdf</a>, <a href="/format/2402.18012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Models as Constrained Samplers for Optimization with Unknown  Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingkai Kong</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yuanqi Du</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+W">Wenhao Mu</a>, 
<a href="/search/cs?searchtype=author&query=Neklyudov%2C+K">Kirill Neklyudov</a>, 
<a href="/search/cs?searchtype=author&query=De+Bortol%2C+V">Valentin De Bortol</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haorui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Dongxia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ferber%2C+A">Aaron Ferber</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yi-An Ma</a>, 
<a href="/search/cs?searchtype=author&query=Gomes%2C+C+P">Carla P. Gomes</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Addressing real-world optimization problems becomes particularly challenging
when analytic objective functions or constraints are unavailable. While
numerous studies have addressed the issue of unknown objectives, limited
research has focused on scenarios where feasibility constraints are not given
explicitly. Overlooking these constraints can lead to spurious solutions that
are unrealistic in practice. To deal with such unknown constraints, we propose
to perform optimization within the data manifold using diffusion models. To
constrain the optimization process to the data manifold, we reformulate the
original optimization problem as a sampling problem from the product of the
Boltzmann distribution defined by the objective function and the data
distribution learned by the diffusion model. To enhance sampling efficiency, we
propose a two-stage framework that begins with a guided diffusion process for
warm-up, followed by a Langevin dynamics stage for further correction.
Theoretical analysis shows that the initial stage results in a distribution
focused on feasible solutions, thereby providing a better initialization for
the later stage. Comprehensive experiments on a synthetic dataset, six
real-world black-box optimization datasets, and a multi-objective optimization
dataset show that our method achieves better or comparable performance with
previous state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18013" title="Abstract">arXiv:2402.18013</a> [<a href="/pdf/2402.18013" title="Download PDF">pdf</a>, <a href="/format/2402.18013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Recent Advances in LLM-Based Multi-turn Dialogue Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+Z">Zihao Yi</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+J">Jiarui Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuwen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+T">Tianhao Liao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Ying Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 10 figures, ACM Computing Surveys
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This survey provides a comprehensive review of research on multi-turn
dialogue systems, with a particular focus on multi-turn dialogue systems based
on large language models (LLMs). This paper aims to (a) give a summary of
existing LLMs and approaches for adapting LLMs to downstream tasks; (b)
elaborate recent advances in multi-turn dialogue systems, covering both
LLM-based open-domain dialogue (ODD) and task-oriented dialogue (TOD) systems,
along with datasets and evaluation metrics; (c) discuss some future emphasis
and recent research problems arising from the development of LLMs and the
increasing demands on multi-turn dialogue systems.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18016" title="Abstract">arXiv:2402.18016</a> [<a href="/pdf/2402.18016" title="Download PDF">pdf</a>, <a href="/format/2402.18016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Explanation Selection Towards Successful User-Decision Support  with Explainable AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fukuchi%2C+Y">Yosuke Fukuchi</a>, 
<a href="/search/cs?searchtype=author&query=Yamada%2C+S">Seiji Yamada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper addresses the problem of how to select explanations for XAI
(Explainable AI)-based Intelligent Decision Support Systems (IDSSs). IDSSs have
shown promise in improving user decisions through XAI-generated explanations
along with AI predictions. As the development of XAI made various explanations
available, we believe that IDSSs can be greatly improved if they can
strategically select explanations that guide users to better decisions. This
paper proposes X-Selector, a method for dynamically selecting explanations.
X-Selector aims to guide users to better decisions by predicting the impact of
different combinations of explanations on user decisions. We compared
X-Selector's performance with two naive strategies (all possible explanations
and explanations only for the most likely prediction) and two baselines (no
explanation and no AI support). The results suggest the potential of X-Selector
to guide users to recommended decisions and improve the performance when AI
accuracy is high and a challenge when it is low.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18018" title="Abstract">arXiv:2402.18018</a> [<a href="/pdf/2402.18018" title="Download PDF">pdf</a>, <a href="/ps/2402.18018" title="Download PostScript">ps</a>, <a href="/format/2402.18018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication Efficient ConFederated Learning: An Event-Triggered SAGA  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jun Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Eldar%2C+Y+C">Yonina C. Eldar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Signal Processing (eess.SP)

</div>
<p class="mathjax">Federated learning (FL) is a machine learning paradigm that targets model
training without gathering the local data dispersed over various data sources.
Standard FL, which employs a single server, can only support a limited number
of users, leading to degraded learning capability. In this work, we consider a
multi-server FL framework, referred to as \emph{Confederated Learning} (CFL),
in order to accommodate a larger number of users. A CFL system is composed of
multiple networked edge servers, with each server connected to an individual
set of users. Decentralized collaboration among servers is leveraged to harness
all users' data for model training. Due to the potentially massive number of
users involved, it is crucial to reduce the communication overhead of the CFL
system. We propose a stochastic gradient method for distributed learning in the
CFL framework. The proposed method incorporates a conditionally-triggered user
selection (CTUS) mechanism as the central component to effectively reduce
communication overhead. Relying on a delicately designed triggering condition,
the CTUS mechanism allows each server to select only a small number of users to
upload their gradients, without significantly jeopardizing the convergence
performance of the algorithm. Our theoretical analysis reveals that the
proposed algorithm enjoys a linear convergence rate. Simulation results show
that it achieves substantial improvement over state-of-the-art algorithms in
terms of communication efficiency.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18020" title="Abstract">arXiv:2402.18020</a> [<a href="/pdf/2402.18020" title="Download PDF">pdf</a>, <a href="/format/2402.18020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tighter Bounds for Local Differentially Private Core Decomposition and  Densest Subgraph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Henzinger%2C+M">Monika Henzinger</a>, 
<a href="/search/cs?searchtype=author&query=Sricharan%2C+A+R">A. R. Sricharan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Leqi Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Computing the core decomposition of a graph is a fundamental problem that has
recently been studied in the differentially private setting, motivated by
practical applications in data mining. In particular, Dhulipala et al. [FOCS
2022] gave the first mechanism for approximate core decomposition in the
challenging and practically relevant setting of local differential privacy. One
of the main open problems left by their work is whether the accuracy, i.e., the
approximation ratio and additive error, of their mechanism can be improved. We
show the first lower bounds on the additive error of approximate and exact core
decomposition mechanisms in the centralized and local model of differential
privacy, respectively. We also give mechanisms for exact and approximate core
decomposition in the local model, with almost matching additive error bounds.
Our mechanisms are based on a black-box application of continual counting. They
also yield improved mechanisms for the approximate densest subgraph problem in
the local model.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18021" title="Abstract">arXiv:2402.18021</a> [<a href="/pdf/2402.18021" title="Download PDF">pdf</a>, <a href="/format/2402.18021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Time-Optimal Trajectory Generation for Two Quadrotors with  Multi-Waypoints Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Fangguo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+J">Jiahao Mei</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuo Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The autonomous quadrotor's flying speed has kept increasing in the past 5
years, especially in the field of autonomous drone racing. However, the
majority of the research mainly focuses on the aggressive flight of a single
quadrotor. In this letter, we propose a novel method called Pairwise Model
Predictive Control (PMPC) that can guide two quadrotors online to fly through
the waypoints with minimum time without collisions. The flight task is first
modeled as a nonlinear optimization problem and then an efficient two-step mass
point velocity search method is used to provide initial values and references
to improve the solving efficiency so that the method can run online with a
frequency of 50 Hz and can handle dynamic waypoints. The simulation and
real-world experiments validate the feasibility of the proposed method and in
the real-world experiments, the two quadrotors can achieve a top speed of
8.1m/s in a 6-waypoint racing track in a compact flying arena of 6m*4m*2m.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18023" title="Abstract">arXiv:2402.18023</a> [<a href="/pdf/2402.18023" title="Download PDF">pdf</a>, <a href="/format/2402.18023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do Large Language Models Mirror Cognitive Language Processing?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yuqi Ren</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+R">Renren Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tongxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+D">Deyi Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated remarkable capabilities in
text comprehension and logical reasoning, achiving or even surpassing
human-level performance in numerous cognition tasks. As LLMs are trained from
massive textual outputs of human language cognition, it is natural to ask
whether LLMs mirror cognitive language processing. Or to what extend LLMs
resemble cognitive language processing? In this paper, we propose a novel
method that bridge between LLM representations and human cognition signals to
evaluate how effectively LLMs simulate cognitive language processing. We employ
Representational Similarity Analysis (RSA) to mearsure the alignment between 16
mainstream LLMs and fMRI signals of the brain. We empirically investigate the
impact of a variety of factors (e.g., model scaling, alignment training,
instruction appending) on such LLM-brain alignment. Experimental results
indicate that model scaling is positively correlated with LLM-brain similarity,
and alignment training can significantly improve LLM-brain similarity.
Additionally, the performance of a wide range of LLM evaluations (e.g., MMLU,
Chatbot Arena) is highly correlated with the LLM-brain similarity.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18025" title="Abstract">arXiv:2402.18025</a> [<a href="/pdf/2402.18025" title="Download PDF">pdf</a>, <a href="/format/2402.18025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hire a Linguist!: Learning Endangered Languages with In-Context  Linguistic Descriptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kexun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y+M">Yee Man Choi</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhenqiao Song</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Taiqi He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W+Y">William Yang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">How can large language models (LLMs) process and translate endangered
languages? Many languages lack a large corpus to train a decent LLM; therefore
existing LLMs rarely perform well in unseen, endangered languages. On the
contrary, we observe that 2000 endangered languages, though without a large
corpus, have a grammar book or a dictionary. We propose LINGOLLM, a
training-free approach to enable an LLM to process unseen languages that hardly
occur in its pre-training. Our key insight is to demonstrate linguistic
knowledge of an unseen language in an LLM's prompt, including a dictionary, a
grammar book, and morphologically analyzed input text. We implement LINGOLLM on
top of two models, GPT-4 and Mixtral, and evaluate their performance on 5 tasks
across 8 endangered or low-resource languages. Our results show that LINGOLLM
elevates translation capability from GPT-4's 0 to 10.5 BLEU for 10 language
directions. Our findings demonstrate the tremendous value of linguistic
knowledge in the age of LLMs for endangered languages. Our data, code, and
model generations can be found at https://github.com/LLiLab/llm4endangeredlang.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18027" title="Abstract">arXiv:2402.18027</a> [<a href="/pdf/2402.18027" title="Download PDF">pdf</a>, <a href="/format/2402.18027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breaking the Black-Box: Confidence-Guided Model Inversion Attack for  Distribution Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yingzhao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zetao Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8pages,5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Model inversion attacks (MIAs) seek to infer the private training data of a
target classifier by generating synthetic images that reflect the
characteristics of the target class through querying the model. However, prior
studies have relied on full access to the target model, which is not practical
in real-world scenarios. Additionally, existing black-box MIAs assume that the
image prior and target model follow the same distribution. However, when
confronted with diverse data distribution settings, these methods may result in
suboptimal performance in conducting attacks. To address these limitations,
this paper proposes a \textbf{C}onfidence-\textbf{G}uided \textbf{M}odel
\textbf{I}nversion attack method called CG-MI, which utilizes the latent space
of a pre-trained publicly available generative adversarial network (GAN) as
prior information and gradient-free optimizer, enabling high-resolution MIAs
across different data distributions in a black-box setting. Our experiments
demonstrate that our method significantly \textbf{outperforms the SOTA
black-box MIA by more than 49\% for Celeba and 58\% for Facescrub in different
distribution settings}. Furthermore, our method exhibits the ability to
generate high-quality images \textbf{comparable to those produced by white-box
attacks}. Our method provides a practical and effective solution for black-box
model inversion attacks.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18028" title="Abstract">arXiv:2402.18028</a> [<a href="/pdf/2402.18028" title="Download PDF">pdf</a>, <a href="/format/2402.18028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenMEDLab: An Open-source Platform for Multi-modality Foundation Models  in Medicine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaosong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaofan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guotai Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junjun He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhongyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wentao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Q">Qi Dou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoxiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dequan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Liang Hong</a>, 
<a href="/search/cs?searchtype=author&query=Lao%2C+Q">Qicheng Lao</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+T">Tong Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yukun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yixue Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kang Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lifeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaoting Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report. Visit <a href="https://github.com/openmedlab">this https URL</a> for more details
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The emerging trend of advancing generalist artificial intelligence, such as
GPTv4 and Gemini, has reshaped the landscape of research (academia and
industry) in machine learning and many other research areas. However,
domain-specific applications of such foundation models (e.g., in medicine)
remain untouched or often at their very early stages. It will require an
individual set of transfer learning and model adaptation techniques by further
expanding and injecting these models with domain knowledge and data. The
development of such technologies could be largely accelerated if the bundle of
data, algorithms, and pre-trained foundation models were gathered together and
open-sourced in an organized manner. In this work, we present OpenMEDLab, an
open-source platform for multi-modality foundation models. It encapsulates not
only solutions of pioneering attempts in prompting and fine-tuning large
language and vision models for frontline clinical and bioinformatic
applications but also building domain-specific foundation models with
large-scale multi-modal medical data. Importantly, it opens access to a group
of pre-trained foundation models for various medical image modalities, clinical
text, protein engineering, etc. Inspiring and competitive results are also
demonstrated for each collected approach and model in a variety of benchmarks
for downstream tasks. We welcome researchers in the field of medical artificial
intelligence to continuously contribute cutting-edge methods and models to
OpenMEDLab, which can be accessed via https://github.com/openmedlab.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18031" title="Abstract">arXiv:2402.18031</a> [<a href="/pdf/2402.18031" title="Download PDF">pdf</a>, <a href="/format/2402.18031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Corpus-Steered Query Expansion with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+Y">Yibin Lei</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+T">Tao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yates%2C+A">Andrew Yates</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EACL 2024 (Short)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Recent studies demonstrate that query expansions generated by large language
models (LLMs) can considerably enhance information retrieval systems by
generating hypothetical documents that answer the queries as expansions.
However, challenges arise from misalignments between the expansions and the
retrieval corpus, resulting in issues like hallucinations and outdated
information due to the limited intrinsic knowledge of LLMs. Inspired by Pseudo
Relevance Feedback (PRF), we introduce Corpus-Steered Query Expansion (CSQE) to
promote the incorporation of knowledge embedded within the corpus. CSQE
utilizes the relevance assessing capability of LLMs to systematically identify
pivotal sentences in the initially-retrieved documents. These corpus-originated
texts are subsequently used to expand the query together with LLM-knowledge
empowered expansions, improving the relevance prediction between the query and
the target documents. Extensive experiments reveal that CSQE exhibits strong
performance without necessitating any training, especially with queries for
which LLMs lack knowledge.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18032" title="Abstract">arXiv:2402.18032</a> [<a href="/pdf/2402.18032" title="Download PDF">pdf</a>, <a href="/format/2402.18032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Shape and Clothing Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Aayush Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Gulati%2C+A">Aditya Gulati</a>, 
<a href="/search/cs?searchtype=author&query=Himanshu">Himanshu</a>, 
<a href="/search/cs?searchtype=author&query=LNU%2C+L">Lakshya LNU</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human shape and clothing estimation has gained significant prominence in
various domains, including online shopping, fashion retail, augmented reality
(AR), virtual reality (VR), and gaming. The visual representation of human
shape and clothing has become a focal point for computer vision researchers in
recent years. This paper presents a comprehensive survey of the major works in
the field, focusing on four key aspects: human shape estimation, fashion
generation, landmark detection, and attribute recognition. For each of these
tasks, the survey paper examines recent advancements, discusses their strengths
and limitations, and qualitative differences in approaches and outcomes. By
exploring the latest developments in human shape and clothing estimation, this
survey aims to provide a comprehensive understanding of the field and inspire
future research in this rapidly evolving domain.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18033" title="Abstract">arXiv:2402.18033</a> [<a href="/pdf/2402.18033" title="Download PDF">pdf</a>, <a href="/format/2402.18033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Fault Detection Architectures for Modular Exponentiation  Targeting Cryptographic Applications Benchmarked on FPGAs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aghapour%2C+S">Saeed Aghapour</a>, 
<a href="/search/cs?searchtype=author&query=Ahmadi%2C+K">Kasra Ahmadi</a>, 
<a href="/search/cs?searchtype=author&query=Kermani%2C+M+M">Mehran Mozaffari Kermani</a>, 
<a href="/search/cs?searchtype=author&query=Azarderakhsh%2C+R">Reza Azarderakhsh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Whether stemming from malicious intent or natural occurrences, faults and
errors can significantly undermine the reliability of any architecture. In
response to this challenge, fault detection assumes a pivotal role in ensuring
the secure deployment of cryptosystems. Even when a cryptosystem boasts
mathematical security, its practical implementation may remain susceptible to
exploitation through side-channel attacks. In this paper, we propose a
lightweight fault detection architecture tailored for modular exponentiation, a
building block of numerous cryptographic applications spanning from classical
cryptography to post quantum cryptography. Based on our simulation and
implementation results on ARM Cortex-A72 processor, and AMD/Xilinx Zynq
Ultrascale+, and Artix-7 FPGAs, our approach achieves an error detection rate
close to 100%, all while introducing a modest computational overhead of
approximately 7% and area overhead of less than 1% compared to the unprotected
architecture. To the best of our knowledge, such an approach benchmarked on ARM
processor and FPGA has not been proposed and assessed to date.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18039" title="Abstract">arXiv:2402.18039</a> [<a href="/pdf/2402.18039" title="Download PDF">pdf</a>, <a href="/format/2402.18039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ResLoRA: Identity Residual Mapping in Low-Rank Adaption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuhua Shi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shaohan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Minghui Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhoujun Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zihan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haizhen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Furu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Weiwei Deng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Feng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As one of the most popular parameter-efficient fine-tuning (PEFT) methods,
low-rank adaptation (LoRA) is commonly applied to fine-tune large language
models (LLMs). However, updating the weights of LoRA blocks effectively and
expeditiously is challenging due to the long calculation path in the original
model. To address this, we propose ResLoRA, an improved framework of LoRA. By
adding residual paths during training and using merging approaches to eliminate
these extra paths during inference, our method can achieve better results in
fewer training steps without any extra trainable parameters or inference cost
compared to LoRA. The experiments on NLG, NLU, and text-to-image tasks
demonstrate the effectiveness of our method. To the best of our knowledge,
ResLoRA is the first work that combines the residual path with LoRA. The code
of our method is available at
https://github.com/microsoft/LMOps/tree/main/reslora .
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18040" title="Abstract">arXiv:2402.18040</a> [<a href="/pdf/2402.18040" title="Download PDF">pdf</a>, <a href="/format/2402.18040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Discovery of Integral with Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xiaoxin Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advancements in the realm of deep learning, particularly in the
development of large language models (LLMs), have demonstrated AI's ability to
tackle complex mathematical problems or solving programming challenges.
However, the capability to solve well-defined problems based on extensive
training data differs significantly from the nuanced process of making
scientific discoveries. Trained on almost all human knowledge available,
today's sophisticated LLMs basically learn to predict sequences of tokens. They
generate mathematical derivations and write code in a similar way as writing an
essay, and do not have the ability to pioneer scientific discoveries in the
manner a human scientist would do.
<br />In this study we delve into the potential of using deep learning to
rediscover a fundamental mathematical concept: integrals. By defining integrals
as area under the curve, we illustrate how AI can deduce the integral of a
given function, exemplified by inferring $\int_{0}^{x} t^2 dt = \frac{x^3}{3}$
and $\int_{0}^{x} ae^{bt} dt = \frac{a}{b} e^{bx} - \frac{a}{b}$. Our
experiments show that deep learning models can approach the task of inferring
integrals either through a sequence-to-sequence model, akin to language
translation, or by uncovering the rudimentary principles of integration, such
as $\int_{0}^{x} t^n dt = \frac{x^{n+1}}{n+1}$.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18041" title="Abstract">arXiv:2402.18041</a> [<a href="/pdf/2402.18041" title="Download PDF">pdf</a>, <a href="/format/2402.18041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Datasets for Large Language Models: A Comprehensive Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiahuan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chongyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+K">Kai Ding</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lianwen Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 181 pages, 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper embarks on an exploration into the Large Language Model (LLM)
datasets, which play a crucial role in the remarkable advancements of LLMs. The
datasets serve as the foundational infrastructure analogous to a root system
that sustains and nurtures the development of LLMs. Consequently, examination
of these datasets emerges as a critical topic in research. In order to address
the current lack of a comprehensive overview and thorough analysis of LLM
datasets, and to gain insights into their current status and future trends,
this survey consolidates and categorizes the fundamental aspects of LLM
datasets from five perspectives: (1) Pre-training Corpora; (2) Instruction
Fine-tuning Datasets; (3) Preference Datasets; (4) Evaluation Datasets; (5)
Traditional Natural Language Processing (NLP) Datasets. The survey sheds light
on the prevailing challenges and points out potential avenues for future
investigation. Additionally, a comprehensive review of the existing available
dataset resources is also provided, including statistics from 444 datasets,
covering 8 language categories and spanning 32 domains. Information from 20
dimensions is incorporated into the dataset statistics. The total data size
surveyed surpasses 774.5 TB for pre-training corpora and 700M instances for
other datasets. We aim to present the entire landscape of LLM text datasets,
serving as a comprehensive reference for researchers in this field and
contributing to future studies. Related resources are available at:
https://github.com/lmmlzn/Awesome-LLMs-Datasets.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18043" title="Abstract">arXiv:2402.18043</a> [<a href="/pdf/2402.18043" title="Download PDF">pdf</a>, <a href="/format/2402.18043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crisis talk: analysis of the public debate around the energy crisis and  cost of living
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Panchendrarajan%2C+R">Rrubaa Panchendrarajan</a>, 
<a href="/search/cs?searchtype=author&query=Popova%2C+G">Geri Popova</a>, 
<a href="/search/cs?searchtype=author&query=Russell-Rose%2C+T">Tony Russell-Rose</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">A prominent media topic in the UK in the early 2020s is the energy crisis
affecting the UK and most of Europe. It brings into a single public debate
issues of energy dependency and sustainability, fair distribution of economic
burdens and cost of living, as well as climate change, risk, and
sustainability. In this paper, we investigate the public discourse around the
energy crisis and cost of living to identify how these pivotal and
contradictory issues are reconciled in this debate and to identify which social
actors are involved and the role they play. We analyse a document corpus
retrieved from UK newspapers from January 2014 to March 2023. We apply a
variety of natural language processing and data visualisation techniques to
identify key topics, novel trends, critical social actors, and the role they
play in the debate, along with the sentiment associated with those actors and
topics. We combine automated techniques with manual discourse analysis to
explore and validate the insights revealed in this study. The findings verify
the utility of these techniques by providing a flexible and scalable pipeline
for discourse analysis and providing critical insights for cost of living -
energy crisis nexus research.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18044" title="Abstract">arXiv:2402.18044</a> [<a href="/pdf/2402.18044" title="Download PDF">pdf</a>, <a href="/format/2402.18044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SFTformer: A Spatial-Frequency-Temporal Correlation-Decoupling  Transformer for Radar Echo Extrapolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Liangyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wanxuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hongfeng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+F">Fanglong Yao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+K">Kun Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 11 figures, TGRS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Extrapolating future weather radar echoes from past observations is a complex
task vital for precipitation nowcasting. The spatial morphology and temporal
evolution of radar echoes exhibit a certain degree of correlation, yet they
also possess independent characteristics. {Existing methods learn unified
spatial and temporal representations in a highly coupled feature space,
emphasizing the correlation between spatial and temporal features but
neglecting the explicit modeling of their independent characteristics, which
may result in mutual interference between them.} To effectively model the
spatiotemporal dynamics of radar echoes, we propose a
Spatial-Frequency-Temporal correlation-decoupling Transformer (SFTformer). The
model leverages stacked multiple SFT-Blocks to not only mine the correlation of
the spatiotemporal dynamics of echo cells but also avoid the mutual
interference between the temporal modeling and the spatial morphology
refinement by decoupling them. Furthermore, inspired by the practice that
weather forecast experts effectively review historical echo evolution to make
accurate predictions, SFTfomer incorporates a joint training paradigm for
historical echo sequence reconstruction and future echo sequence prediction.
Experimental results on the HKO-7 dataset and ChinaNorth-2021 dataset
demonstrate the superior performance of SFTfomer in short(1h), mid(2h), and
long-term(3h) precipitation nowcasting.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18045" title="Abstract">arXiv:2402.18045</a> [<a href="/pdf/2402.18045" title="Download PDF">pdf</a>, <a href="/format/2402.18045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-FAct: Assessing Multilingual LLMs&#x27; Multi-Regional Knowledge using  FActScore
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shafayat%2C+S">Sheikh Shafayat</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+E">Eunsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+J">Juhyun Oh</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+A">Alice Oh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) are prone to factuality hallucination,
generating text that contradicts established knowledge. While extensive
research has addressed this in English, little is known about multilingual
LLMs. This paper systematically evaluates multilingual LLMs' factual accuracy
across languages and geographic regions. We introduce a novel pipeline for
multilingual factuality evaluation, adapting FActScore(Min et al., 2023) for
diverse languages. Our analysis across nine languages reveals that English
consistently outperforms others in factual accuracy and quantity of generated
facts. Furthermore, multilingual models demonstrate a bias towards factual
information from Western continents. These findings highlight the need for
improved multilingual factuality assessment and underscore geographical biases
in LLMs' fact generation.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18046" title="Abstract">arXiv:2402.18046</a> [<a href="/pdf/2402.18046" title="Download PDF">pdf</a>, <a href="/format/2402.18046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data augmentation method for modeling health records with applications  to clopidogrel treatment failure detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Sunwoong Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Samuel Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2310.08757">arXiv:2310.08757</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We present a novel data augmentation method to address the challenge of data
scarcity in modeling longitudinal patterns in Electronic Health Records (EHR)
of patients using natural language processing (NLP) algorithms. The proposed
method generates augmented data by rearranging the orders of medical records
within a visit where the order of elements are not obvious, if any. Applying
the proposed method to the clopidogrel treatment failure detection task enabled
up to 5.3% absolute improvement in terms of ROC-AUC (from 0.908 without
augmentation to 0.961 with augmentation) when it was used during the
pre-training procedure. It was also shown that the augmentation helped to
improve performance during fine-tuning procedures, especially when the amount
of labeled training data is limited.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18048" title="Abstract">arXiv:2402.18048</a> [<a href="/pdf/2402.18048" title="Download PDF">pdf</a>, <a href="/format/2402.18048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing Truthfulness in Large Language Model Generations with  Local Intrinsic Dimension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+F">Fan Yin</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasa%2C+J">Jayanth Srinivasa</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint, 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We study how to characterize and predict the truthfulness of texts generated
from large language models (LLMs), which serves as a crucial step in building
trust between humans and LLMs. Although several approaches based on entropy or
verbalized uncertainty have been proposed to calibrate model predictions, these
methods are often intractable, sensitive to hyperparameters, and less reliable
when applied in generative tasks with LLMs. In this paper, we suggest
investigating internal activations and quantifying LLM's truthfulness using the
local intrinsic dimension (LID) of model activations. Through experiments on
four question answering (QA) datasets, we demonstrate the effectiveness
ohttps://info.arxiv.org/help/prep#abstractsf our proposed method. Additionally,
we study intrinsic dimensions in LLMs and their relations with model layers,
autoregressive language modeling, and the training of LLMs, revealing that
intrinsic dimensions can be a powerful approach to understanding LLMs.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18049" title="Abstract">arXiv:2402.18049</a> [<a href="/pdf/2402.18049" title="Download PDF">pdf</a>, <a href="/format/2402.18049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance modeling of public permissionless blockchains: A survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esmaili%2C+M">Molud Esmaili</a>, 
<a href="/search/cs?searchtype=author&query=Christensen%2C+K">Ken Christensen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Public permissionless blockchains facilitate peer-to-peer digital
transactions, yet face performance challenges specifically minimizing
transaction confirmation time to decrease energy and time consumption per
transaction. Performance evaluation and prediction are crucial in achieving
this objective, with performance modeling as a key solution despite the
complexities involved in assessing these blockchains. This survey examines
prior research concerning the performance modeling blockchain systems,
specifically focusing on public permissionless blockchains. Initially, it
provides foundational knowledge about these blockchains and the crucial
performance parameters for their assessment. Additionally, the study delves
into research on the performance modeling of public permissionless blockchains,
predominantly considering these systems as bulk service queues. It also
examines prior studies on workload and traffic modeling, characterization, and
analysis within these blockchain networks. By analyzing existing research, our
survey aims to provide insights and recommendations for researchers keen on
enhancing the performance of public permissionless blockchains or devising
novel mechanisms in this domain.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18050" title="Abstract">arXiv:2402.18050</a> [<a href="/pdf/2402.18050" title="Download PDF">pdf</a>, <a href="/format/2402.18050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MEGAnno+: A Human-LLM Collaborative Annotation System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hannah Kim</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+K">Kushan Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R+L">Rafael Li Chen</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+S">Sajjadur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EACL 2024 Demo
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Large language models (LLMs) can label data faster and cheaper than humans
for various NLP tasks. Despite their prowess, LLMs may fall short in
understanding of complex, sociocultural, or domain-specific context,
potentially leading to incorrect annotations. Therefore, we advocate a
collaborative approach where humans and LLMs work together to produce reliable
and high-quality labels. We present MEGAnno+, a human-LLM collaborative
annotation system that offers effective LLM agent and annotation management,
convenient and robust LLM annotation, and exploratory verification of LLM
labels by humans.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18054" title="Abstract">arXiv:2402.18054</a> [<a href="/pdf/2402.18054" title="Download PDF">pdf</a>, <a href="/format/2402.18054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextualizing Generated Citation Texts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mandal%2C+B">Biswadip Mandal</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangci Li</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+J">Jessica Ouyang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Abstractive citation text generation is usually framed as an infilling task,
where a sequence-to-sequence model is trained to generate a citation given a
reference paper and the context window around the target; the generated
citation should be a brief discussion of the reference paper as it relates to
the citing context. However, examining a recent LED-based citation generation
system, we find that many of the generated citations are generic summaries of
the reference papers main contribution, ignoring the citation contexts focus on
a different topic. To address this problem, we propose a simple modification to
the citation text generation task: the generation target is not only the
citation itself, but the entire context window, including the target citation.
This approach can be easily applied to any abstractive citation generation
system, and our experimental results show that training in this way is
preferred by human readers and allows the generation model to make use of
contextual clues about what topic to discuss and what stance to take.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18059" title="Abstract">arXiv:2402.18059</a> [<a href="/pdf/2402.18059" title="Download PDF">pdf</a>, <a href="/format/2402.18059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Token-Specific Watermarking with Enhanced Detectability and Semantic  Coherence for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huo%2C+M">Mingjia Huo</a>, 
<a href="/search/cs?searchtype=author&query=Somayajula%2C+S+A">Sai Ashish Somayajula</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Youwei Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruisi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Koushanfar%2C+F">Farinaz Koushanfar</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+P">Pengtao Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Large language models generate high-quality responses with potential
misinformation, underscoring the need for regulation by distinguishing
AI-generated and human-written texts. Watermarking is pivotal in this context,
which involves embedding hidden markers in texts during the LLM inference
phase, which is imperceptible to humans. Current watermarking algorithms,
however, face the challenge of achieving both the detectability of inserted
watermarks and the semantic integrity of generated texts, where enhancing one
aspect often undermines the other. To overcome this, we introduce a novel
multi-objective optimization (MOO) approach for watermarking that utilizes
lightweight networks to generate token-specific watermarking logits and
splitting ratios. By leveraging MOO to optimize for both detection and semantic
objective functions, our method simultaneously achieves detectability and
semantic integrity. Experimental results show that our method outperforms
current watermarking techniques in enhancing the detectability of texts
generated by LLMs while maintaining their semantic coherence. Our code is
available at https://github.com/mignonjia/TS_watermark .
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18060" title="Abstract">arXiv:2402.18060</a> [<a href="/pdf/2402.18060" title="Download PDF">pdf</a>, <a href="/format/2402.18060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Large Language Models on Answering and Explaining  Challenging Medical Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hanjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhouxiang Fang</a>, 
<a href="/search/cs?searchtype=author&query=Singla%2C+Y">Yash Singla</a>, 
<a href="/search/cs?searchtype=author&query=Dredze%2C+M">Mark Dredze</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">LLMs have demonstrated impressive performance in answering medical questions,
such as passing medical licensing examinations. However, most existing
benchmarks rely on board exam questions or general medical questions, falling
short in capturing the complexity of realistic clinical cases. Moreover, the
lack of reference explanations for answers hampers the evaluation of model
explanations, which are crucial to supporting doctors in making complex medical
decisions. To address these challenges, we construct two new datasets: JAMA
Clinical Challenge and Medbullets. JAMA Clinical Challenge consists of
questions based on challenging clinical cases, while Medbullets comprises USMLE
Step 2&amp;3 style clinical questions. Both datasets are structured as
multiple-choice question-answering tasks, where each question is accompanied by
an expert-written explanation. We evaluate four LLMs on the two datasets using
various prompts. Experiments demonstrate that our datasets are harder than
previous benchmarks. The inconsistency between automatic and human evaluations
of model-generated explanations highlights the need to develop new metrics to
support future research on explainable medical QA.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18061" title="Abstract">arXiv:2402.18061</a> [<a href="/pdf/2402.18061" title="Download PDF">pdf</a>, <a href="/format/2402.18061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the use of Silver Standard Data for Zero-shot Classification Tasks in  Information Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianyin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Ziqian Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by coling2024. arXiv admin note: substantial text overlap with <a href="/abs/2211.13883">arXiv:2211.13883</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The superior performance of supervised classification methods in the
information extraction (IE) area heavily relies on a large amount of gold
standard data. Recent zero-shot classification methods converted the task to
other NLP tasks (e.g., textual entailment) and used off-the-shelf models of
these NLP tasks to directly perform inference on the test data without using a
large amount of IE annotation data. A potentially valuable by-product of these
methods is the large-scale silver standard data, i.e., pseudo-labeled data by
the off-the-shelf models of other NLP tasks. However, there is no further
investigation into the use of these data. In this paper, we propose a new
framework, Clean-LaVe, which aims to utilize silver standard data to enhance
the zero-shot performance. Clean-LaVe includes four phases: (1) Obtaining
silver data; (2) Identifying relatively clean data from silver data; (3)
Finetuning the off-the-shelf model using clean data; (4) Inference on the test
data. The experimental results show that Clean-LaVe can outperform the baseline
by 5% and 6% on TACRED and Wiki80 dataset in the zero-shot relation
classification task, and by 3%-7% on Smile (Korean and Polish) in the zero-shot
cross-lingual relation classification task, and by 8% on ACE05-E+ in the
zero-shot event argument classification task. The code is share in
https://github.com/wjw136/Clean_LaVe.git.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18062" title="Abstract">arXiv:2402.18062</a> [<a href="/pdf/2402.18062" title="Download PDF">pdf</a>, <a href="/format/2402.18062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative AI for Unmanned Vehicle Swarms: Challenges, Applications and  Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guangyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Van+Huynh%2C+N">Nguyen Van Huynh</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Hongyang Du</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+D+T">Dinh Thai Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Kun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiawen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zehui Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Jamalipour%2C+A">Abbas Jamalipour</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D+I">Dong In Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With recent advances in artificial intelligence (AI) and robotics, unmanned
vehicle swarms have received great attention from both academia and industry
due to their potential to provide services that are difficult and dangerous to
perform by humans. However, learning and coordinating movements and actions for
a large number of unmanned vehicles in complex and dynamic environments
introduce significant challenges to conventional AI methods. Generative AI
(GAI), with its capabilities in complex data feature extraction,
transformation, and enhancement, offers great potential in solving these
challenges of unmanned vehicle swarms. For that, this paper aims to provide a
comprehensive survey on applications, challenges, and opportunities of GAI in
unmanned vehicle swarms. Specifically, we first present an overview of unmanned
vehicles and unmanned vehicle swarms as well as their use cases and existing
issues. Then, an in-depth background of various GAI techniques together with
their capabilities in enhancing unmanned vehicle swarms are provided. After
that, we present a comprehensive review on the applications and challenges of
GAI in unmanned vehicle swarms with various insights and discussions. Finally,
we highlight open issues of GAI in unmanned vehicle swarms and discuss
potential research directions.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18064" title="Abstract">arXiv:2402.18064</a> [<a href="/pdf/2402.18064" title="Download PDF">pdf</a>, <a href="/format/2402.18064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Testing of Spatially-Dependent Environmental Hypotheses  through Active Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harrison%2C+N">Nicholas Harrison</a>, 
<a href="/search/cs?searchtype=author&query=Wallace%2C+N">Nathan Wallace</a>, 
<a href="/search/cs?searchtype=author&query=Sukkarieh%2C+S">Salah Sukkarieh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The efficient collection of samples is an important factor in outdoor
information gathering applications on account of high sampling costs such as
time, energy, and potential destruction to the environment. Utilization of
available a-priori data can be a powerful tool for increasing efficiency.
However, the relationships of this data with the quantity of interest are often
not known ahead of time, limiting the ability to leverage this knowledge for
improved planning efficiency. To this end, this work combines transfer learning
and active learning through a Multi-Task Gaussian Process and an
information-based objective function. Through this combination it can explore
the space of hypothetical inter-quantity relationships and evaluate these
hypotheses in real-time, allowing this new knowledge to be immediately
exploited for future plans. The performance of the proposed method is evaluated
against synthetic data and is shown to evaluate multiple hypotheses correctly.
Its effectiveness is also demonstrated on real datasets. The technique is able
to identify and leverage hypotheses which show a medium or strong correlation
to reduce prediction error by a factor of 1.5--6 within the first 5 samples,
and poor hypotheses are quickly identified and rejected, having no adverse
effect on planning after around 3 samples.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18065" title="Abstract">arXiv:2402.18065</a> [<a href="/pdf/2402.18065" title="Download PDF">pdf</a>, <a href="/format/2402.18065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Probabilistic Motion Model for Skid-Steer Wheeled Mobile Robot  Navigation on Off-Road Terrains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trivedi%2C+A">Ananya Trivedi</a>, 
<a href="/search/cs?searchtype=author&query=Zolotas%2C+M">Mark Zolotas</a>, 
<a href="/search/cs?searchtype=author&query=Abbas%2C+A">Adeeb Abbas</a>, 
<a href="/search/cs?searchtype=author&query=Prajapati%2C+S">Sarvesh Prajapati</a>, 
<a href="/search/cs?searchtype=author&query=Bazzi%2C+S">Salah Bazzi</a>, 
<a href="/search/cs?searchtype=author&query=Pad%C4%B1r%2C+T">Task&#x131;n Pad&#x131;r</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at IEEE ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Skid-Steer Wheeled Mobile Robots (SSWMRs) are increasingly being used for
off-road autonomy applications. When turning at high speeds, these robots tend
to undergo significant skidding and slipping. In this work, using Gaussian
Process Regression (GPR) and Sigma-Point Transforms, we estimate the non-linear
effects of tire-terrain interaction on robot velocities in a probabilistic
fashion. Using the mean estimates from GPR, we propose a data-driven dynamic
motion model that is more accurate at predicting future robot poses than
conventional kinematic motion models. By efficiently solving a convex
optimization problem based on the history of past robot motion, the GPR
augmented motion model generalizes to previously unseen terrain conditions. The
output distribution from the proposed motion model can be used for local motion
planning approaches, such as stochastic model predictive control, leveraging
model uncertainty to make safe decisions. We validate our work on a benchmark
real-world multi-terrain SSWMR dataset. Our results show that the model
generalizes to three different terrains while significantly reducing errors in
linear and angular motion predictions. As shown in the attached video, we
perform a separate set of experiments on a physical robot to demonstrate the
robustness of the proposed algorithm.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18066" title="Abstract">arXiv:2402.18066</a> [<a href="/pdf/2402.18066" title="Download PDF">pdf</a>, <a href="/format/2402.18066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Six-Point Method for Multi-Camera Systems with Reduced Solution Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+B">Banglei Guan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Ji Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Kneip%2C+L">Laurent Kneip</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2102.11996">arXiv:2102.11996</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Relative pose estimation using point correspondences (PC) is a widely used
technique. A minimal configuration of six PCs is required for generalized
cameras. In this paper, we present several minimal solvers that use six PCs to
compute the 6DOF relative pose of a multi-camera system, including a minimal
solver for the generalized camera and two minimal solvers for the practical
configuration of two-camera rigs. The equation construction is based on the
decoupling of rotation and translation. Rotation is represented by Cayley or
quaternion parametrization, and translation can be eliminated by using the
hidden variable technique. Ray bundle constraints are found and proven when a
subset of PCs relate the same cameras across two views. This is the key to
reducing the number of solutions and generating numerically stable solvers.
Moreover, all configurations of six-point problems for multi-camera systems are
enumerated. Extensive experiments demonstrate that our solvers are more
accurate than the state-of-the-art six-point methods, while achieving better
performance in efficiency.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18068" title="Abstract">arXiv:2402.18068</a> [<a href="/pdf/2402.18068" title="Download PDF">pdf</a>, <a href="/format/2402.18068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SynArtifact: Classifying and Alleviating Artifacts in Synthetic Images  via Vision-Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+B">Bin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jianhao Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yexin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jian Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shuyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bo Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the rapidly evolving area of image synthesis, a serious challenge is the
presence of complex artifacts that compromise perceptual realism of synthetic
images. To alleviate artifacts and improve quality of synthetic images, we
fine-tune Vision-Language Model (VLM) as artifact classifier to automatically
identify and classify a wide range of artifacts and provide supervision for
further optimizing generative models. Specifically, we develop a comprehensive
artifact taxonomy and construct a dataset of synthetic images with artifact
annotations for fine-tuning VLM, named SynArtifact-1K. The fine-tuned VLM
exhibits superior ability of identifying artifacts and outperforms the baseline
by 25.66%. To our knowledge, this is the first time such end-to-end artifact
classification task and solution have been proposed. Finally, we leverage the
output of VLM as feedback to refine the generative model for alleviating
artifacts. Visualization results and user study demonstrate that the quality of
images synthesized by the refined diffusion model has been obviously improved.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18070" title="Abstract">arXiv:2402.18070</a> [<a href="/pdf/2402.18070" title="Download PDF">pdf</a>, <a href="/format/2402.18070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hierarchical Dataflow-Driven Heterogeneous Architecture for Wireless  Baseband Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Limin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yi Shi</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Haiqin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Q">Qingyu Deng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Siyi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yintao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+F">Feng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Si Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yihao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+F">Fangfang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Shan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhiyuan Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Wireless baseband processing (WBP) is a key element of wireless
communications, with a series of signal processing modules to improve data
throughput and counter channel fading. Conventional hardware solutions, such as
digital signal processors (DSPs) and more recently, graphic processing units
(GPUs), provide various degrees of parallelism, yet they both fail to take into
account the cyclical and consecutive character of WBP. Furthermore, the large
amount of data in WBPs cannot be processed quickly in symmetric multiprocessors
(SMPs) due to the unpredictability of memory latency. To address this issue, we
propose a hierarchical dataflow-driven architecture to accelerate WBP. A
pack-and-ship approach is presented under a non-uniform memory access (NUMA)
architecture to allow the subordinate tiles to operate in a bundled access and
execute manner. We also propose a multi-level dataflow model and the related
scheduling scheme to manage and allocate the heterogeneous hardware resources.
Experiment results demonstrate that our prototype achieves $2\times$ and
$2.3\times$ speedup in terms of normalized throughput and single-tile clock
cycles compared with GPU and DSP counterparts in several critical WBP
benchmarks. Additionally, a link-level throughput of $288$ Mbps can be achieved
with a $45$-core configuration.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18071" title="Abstract">arXiv:2402.18071</a> [<a href="/pdf/2402.18071" title="Download PDF">pdf</a>, <a href="/ps/2402.18071" title="Download PostScript">ps</a>, <a href="/format/2402.18071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved uniform error bounds for long-time dynamics of the  high-dimensional nonlinear space fractional sine-Gordon equation with weak  nonlinearity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jia%2C+J">Junqing Jia</a>, 
<a href="/search/math?searchtype=author&query=Chi%2C+X">Xiaoqing Chi</a>, 
<a href="/search/math?searchtype=author&query=Jiang%2C+X">Xiaoyun Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we derive the improved uniform error bounds for the long-time
dynamics of the $d$-dimensional $(d=2,3)$ nonlinear space fractional
sine-Gordon equation (NSFSGE). The nonlinearity strength of the NSFSGE is
characterized by $\varepsilon^2$ where $0&lt;\varepsilon \le 1$ is a dimensionless
parameter. The second-order time-splitting method is applied to the temporal
discretization and the Fourier pseudo-spectral method is used for the spatial
discretization. To obtain the explicit relation between the numerical errors
and the parameter $\varepsilon$, we introduce the regularity compensation
oscillation technique to the convergence analysis of fractional models. Then we
establish the improved uniform error bounds $O\left(\varepsilon^2
\tau^2\right)$ for the semi-discretization scheme and $O\left(h^m+\varepsilon^2
\tau^2\right)$ for the full-discretization scheme up to the long time at
$O(1/\varepsilon^2)$. Further, we extend the time-splitting Fourier
pseudo-spectral method to the complex NSFSGE as well as the oscillatory complex
NSFSGE, and the improved uniform error bounds for them are also given. Finally,
extensive numerical examples in two-dimension or three-dimension are provided
to support the theoretical analysis. The differences in dynamic behaviors
between the fractional sine-Gordon equation and classical sine-Gordon equation
are also discussed.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18073" title="Abstract">arXiv:2402.18073</a> [<a href="/pdf/2402.18073" title="Download PDF">pdf</a>, <a href="/format/2402.18073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tensor Network Space-Time Spectral Collocation Method for Time Dependent  Convection-Diffusion-Reaction Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Adak%2C+D">Dibyendu Adak</a>, 
<a href="/search/math?searchtype=author&query=Truong%2C+D+P">Duc P. Truong</a>, 
<a href="/search/math?searchtype=author&query=Manzini%2C+G">Gianmarco Manzini</a>, 
<a href="/search/math?searchtype=author&query=Rasmussen%2C+K+%C3%98">Kim &#xd8;. Rasmussen</a>, 
<a href="/search/math?searchtype=author&query=Alexandrov%2C+B+S">Boian S. Alexandrov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Emerging tensor network techniques for solutions of Partial Differential
Equations (PDEs), known for their ability to break the curse of dimensionality,
deliver new mathematical methods for ultrafast numerical solutions of
high-dimensional problems. Here, we introduce a Tensor Train (TT) Chebyshev
spectral collocation method, in both space and time, for solution of the time
dependent convection-diffusion-reaction (CDR) equation with inhomogeneous
boundary conditions, in Cartesian geometry. Previous methods for numerical
solution of time dependent PDEs often use finite difference for time, and a
spectral scheme for the spatial dimensions, which leads to slow linear
convergence. Spectral collocation space-time methods show exponential
convergence, however, for realistic problems they need to solve large
four-dimensional systems. We overcome this difficulty by using a TT approach as
its complexity only grows linearly with the number of dimensions. We show that
our TT space-time Chebyshev spectral collocation method converges
exponentially, when the solution of the CDR is smooth, and demonstrate that it
leads to very high compression of linear operators from terabytes to kilobytes
in TT-format, and tens of thousands times speedup when compared to full grid
space-time spectral method. These advantages allow us to obtain the solutions
at much higher resolutions.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18074" title="Abstract">arXiv:2402.18074</a> [<a href="/pdf/2402.18074" title="Download PDF">pdf</a>, <a href="/format/2402.18074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A One-step Image Retargeing Algorithm Based on Conformal Energy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+C">Chengyang Liu</a>, 
<a href="/search/math?searchtype=author&query=Ng%2C+M+K">Michael K. Ng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Geometry (cs.CG); Graphics (cs.GR)

</div>
<p class="mathjax">The image retargeting problem is to find a proper mapping to resize an image
to one with a prescribed aspect ratio, which is quite popular these days. In
this paper, we propose an efficient and orientation-preserving one-step image
retargeting algorithm based on minimizing the harmonic energy, which can well
preserve the regions of interest (ROIs) and line structures in the image. We
also give some mathematical proofs in the paper to ensure the well-posedness
and accuracy of our algorithm.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18076" title="Abstract">arXiv:2402.18076</a> [<a href="/pdf/2402.18076" title="Download PDF">pdf</a>, <a href="/format/2402.18076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Ecological Gearshift Strategy via Neural Network with Soft-Argmax  Operator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Luo%2C+X">Xi Luo</a>, 
<a href="/search/eess?searchtype=author&query=Dong%2C+S">Shiying Dong</a>, 
<a href="/search/eess?searchtype=author&query=Hong%2C+J">Jinlong Hong</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+B">Bingzhao Gao</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Hong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures, submitted to 8th IFAC Conference on Nonlinear Model Predictive Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents a neural network optimizer with soft-argmax operator to
achieve an ecological gearshift strategy in real-time. The strategy is
reformulated as the mixed-integer model predictive control (MIMPC) problem to
minimize energy consumption. Then the outer convexification is introduced to
transform integer variables into relaxed binary controls. To approximate binary
solutions properly within training, the soft-argmax operator is applied to the
neural network with the fact that all the operations of this scheme are
differentiable. Moreover, this operator can help push the relaxed binary
variables close to 0 or 1. To evaluate the strategy effect, we deployed it to a
2-speed electric vehicle (EV). In contrast to the mature solver Bonmin, our
proposed method not only achieves similar energy-saving effects but also
significantly reduces the solution time to meet real-time requirements. This
results in a notable energy savings of 6.02% compared to the rule-based method.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18078" title="Abstract">arXiv:2402.18078</a> [<a href="/pdf/2402.18078" title="Download PDF">pdf</a>, <a href="/format/2402.18078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coarse-to-Fine Latent Diffusion for Pose-Guided Person Image Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yanzuo Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Manlin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+A+J">Andy J Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaohua Xie</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+J">Jian-Huang Lai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion model is a promising approach to image generation and has been
employed for Pose-Guided Person Image Synthesis (PGPIS) with competitive
performance. While existing methods simply align the person appearance to the
target pose, they are prone to overfitting due to the lack of a high-level
semantic understanding on the source person image. In this paper, we propose a
novel Coarse-to-Fine Latent Diffusion (CFLD) method for PGPIS. In the absence
of image-caption pairs and textual prompts, we develop a novel training
paradigm purely based on images to control the generation process of the
pre-trained text-to-image diffusion model. A perception-refined decoder is
designed to progressively refine a set of learnable queries and extract
semantic understanding of person images as a coarse-grained prompt. This allows
for the decoupling of fine-grained appearance and pose information controls at
different stages, and thus circumventing the potential overfitting problem. To
generate more realistic texture details, a hybrid-granularity attention module
is proposed to encode multi-scale fine-grained appearance features as bias
terms to augment the coarse-grained prompt. Both quantitative and qualitative
experimental results on the DeepFashion benchmark demonstrate the superiority
of our method over the state of the arts for PGPIS. Code is available at
https://github.com/YanzuoLu/CFLD.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18084" title="Abstract">arXiv:2402.18084</a> [<a href="/pdf/2402.18084" title="Download PDF">pdf</a>, <a href="/format/2402.18084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spannotation: Enhancing Semantic Segmentation for Autonomous Navigation  with Efficient Image Annotation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Folorunsho%2C+S+O">Samuel O. Folorunsho</a>, 
<a href="/search/cs?searchtype=author&query=Norris%2C+W+R">William R. Norris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, 1 table, 1 pseudo code (algorithm), 55 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Spannotation is an open source user-friendly tool developed for image
annotation for semantic segmentation specifically in autonomous navigation
tasks. This study provides an evaluation of Spannotation, demonstrating its
effectiveness in generating accurate segmentation masks for various
environments like agricultural crop rows, off-road terrains and urban roads.
Unlike other popular annotation tools that requires about 40 seconds to
annotate an image for semantic segmentation in a typical navigation task,
Spannotation achieves similar result in about 6.03 seconds. The tools utility
was validated through the utilization of its generated masks to train a U-Net
model which achieved a validation accuracy of 98.27% and mean Intersection Over
Union (mIOU) of 96.66%. The accessibility, simple annotation process and
no-cost features have all contributed to the adoption of Spannotation evident
from its download count of 2098 (as of February 25, 2024) since its launch.
Future enhancements of Spannotation aim to broaden its application to complex
navigation scenarios and incorporate additional automation functionalities.
Given its increasing popularity and promising potential, Spannotation stands as
a valuable resource in autonomous navigation and semantic segmentation. For
detailed information and access to Spannotation, readers are encouraged to
visit the project's GitHub repository at
https://github.com/sof-danny/spannotation
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18085" title="Abstract">arXiv:2402.18085</a> [<a href="/pdf/2402.18085" title="Download PDF">pdf</a>, <a href="/format/2402.18085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-assisted Tagging of Deepfake Audio Calls using Challenge-Response
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mittal%2C+G">Govind Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Jakobsson%2C+A">Arthur Jakobsson</a>, 
<a href="/search/cs?searchtype=author&query=Marshall%2C+K+O">Kelly O. Marshall</a>, 
<a href="/search/cs?searchtype=author&query=Hegde%2C+C">Chinmay Hegde</a>, 
<a href="/search/cs?searchtype=author&query=Memon%2C+N">Nasir Memon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Dataset will be made public by end of March 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Cryptography and Security (cs.CR); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Scammers are aggressively leveraging AI voice-cloning technology for social
engineering attacks, a situation significantly worsened by the advent of audio
Real-time Deepfakes (RTDFs). RTDFs can clone a target's voice in real-time over
phone calls, making these interactions highly interactive and thus far more
convincing. Our research confidently addresses the gap in the existing
literature on deepfake detection, which has largely been ineffective against
RTDF threats. We introduce a robust challenge-response-based method to detect
deepfake audio calls, pioneering a comprehensive taxonomy of audio challenges.
Our evaluation pitches 20 prospective challenges against a leading
voice-cloning system. We have compiled a novel open-source challenge dataset
with contributions from 100 smartphone and desktop users, yielding 18,600
original and 1.6 million deepfake samples. Through rigorous machine and human
evaluations of this dataset, we achieved a deepfake detection rate of 86% and
an 80% AUC score, respectively. Notably, utilizing a set of 11 challenges
significantly enhances detection capabilities. Our findings reveal that
combining human intuition with machine precision offers complementary
advantages. Consequently, we have developed an innovative human-AI
collaborative system that melds human discernment with algorithmic accuracy,
boosting final joint accuracy to 82.9%. This system highlights the significant
advantage of AI-assisted pre-screening in call verification processes. Samples
can be heard at https://mittalgovind.github.io/autch-samples/
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18086" title="Abstract">arXiv:2402.18086</a> [<a href="/pdf/2402.18086" title="Download PDF">pdf</a>, <a href="/format/2402.18086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizable Two-Branch Framework for Image Class-Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiaobin Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruixuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages,3 figures,accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep neural networks often severely forget previously learned knowledge when
learning new knowledge. Various continual learning (CL) methods have been
proposed to handle such a catastrophic forgetting issue from different
perspectives and achieved substantial improvements.In this paper, a novel
two-branch continual learning framework is proposed to further enhance most
existing CL methods. Specifically, the main branch can be any existing CL model
and the newly introduced side branch is a lightweight convolutional network.
The output of each main branch block is modulated by the output of the
corresponding side branch block. Such a simple two-branch model can then be
easily implemented and learned with the vanilla optimization setting without
whistles and bells.Extensive experiments with various settings on multiple
image datasets show that the proposed framework yields consistent improvements
over state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18088" title="Abstract">arXiv:2402.18088</a> [<a href="/pdf/2402.18088" title="Download PDF">pdf</a>, <a href="/format/2402.18088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bimanual Manipulation of Steady Hand Eye Robots with Adaptive Sclera  Force Control: Cooperative vs. Teleoperation Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esfandiari%2C+M">Mojtaba Esfandiari</a>, 
<a href="/search/cs?searchtype=author&query=Amirkhani%2C+G">Golchehr Amirkhani</a>, 
<a href="/search/cs?searchtype=author&query=Gehlbach%2C+P">Peter Gehlbach</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+R+H">Russell H. Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Iordachita%2C+I">Iulian Iordachita</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Performing intricate eye microsurgery, such as retinal vein cannulation
(RVC), as a potential treatment for retinal vein occlusion (RVO), without the
assistance of a surgical robotic system is very challenging to do safely. The
main limitation has to do with the physiological hand tremor of surgeons.
Robot-assisted eye surgery technology may resolve the problems of hand tremors
and fatigue and improve the safety and precision of RVC. The Steady-Hand Eye
Robot (SHER) is an admittance-based robotic system that can filter out hand
tremors and enables ophthalmologists to manipulate a surgical instrument inside
the eye cooperatively. However, the admittance-based cooperative control mode
does not address crucial safety considerations, such as minimizing contact
force between the surgical instrument and the sclera surface to prevent tissue
damage. An adaptive sclera force control algorithm was proposed to address this
limitation using an FBG-based force-sensing tool to measure and minimize the
tool-sclera interaction force. Additionally, features like haptic feedback or
hand motion scaling, which can improve the safety and precision of surgery,
require a teleoperation control framework. We implemented a bimanual adaptive
teleoperation (BMAT) control mode using SHER 2.0 and SHER 2.1 and compared its
performance with a bimanual adaptive cooperative (BMAC) mode. Both BMAT and
BMAC modes were tested in sitting and standing postures during a
vessel-following experiment under a surgical microscope. It is shown, for the
first time to the best of our knowledge in robot-assisted retinal surgery, that
integrating the adaptive sclera force control algorithm with the bimanual
teleoperation framework enables surgeons to safely perform bimanual
telemanipulation of the eye without over-stretching it, even in the absence of
registration between the two robots.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18089" title="Abstract">arXiv:2402.18089</a> [<a href="/pdf/2402.18089" title="Download PDF">pdf</a>, <a href="/format/2402.18089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PIMSIM-NN: An ISA-based Simulation Framework for Processing-in-Memory  Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaotian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yinhe Han</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoming Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Processing-in-memory (PIM) has shown extraordinary potential in accelerating
neural networks. To evaluate the performance of PIM accelerators, we present an
ISA-based simulation framework including a dedicated ISA targeting neural
networks running on PIM architectures, a compiler, and a cycleaccurate
configurable simulator. Compared with prior works, this work decouples software
algorithms and hardware architectures through the proposed ISA, providing a
more convenient way to evaluate the effectiveness of software/hardware
optimizations. The simulator adopts an event-driven simulation approach and has
better support for hardware parallelism. The framework is open-sourced at
https://github.com/wangxy-2000/pimsim-nn.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18090" title="Abstract">arXiv:2402.18090</a> [<a href="/pdf/2402.18090" title="Download PDF">pdf</a>, <a href="/format/2402.18090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Minimal Absent Words and Extended Bispecial Factors with CDAWG  Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Inenaga%2C+S">Shunsuke Inenaga</a>, 
<a href="/search/cs?searchtype=author&query=Mieno%2C+T">Takuya Mieno</a>, 
<a href="/search/cs?searchtype=author&query=Arimura%2C+H">Hiroki Arimura</a>, 
<a href="/search/cs?searchtype=author&query=Funakoshi%2C+M">Mitsuru Funakoshi</a>, 
<a href="/search/cs?searchtype=author&query=Fujishige%2C+Y">Yuta Fujishige</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">A string $w$ is said to be a minimal absent word (MAW) for a string $S$ if
$w$ does not occur in $S$ and any proper substring of $w$ occurs in $S$. We
focus on non-trivial MAWs which are of length at least 2. Finding such
non-trivial MAWs for a given string is motivated for applications in
bioinformatics and data compression. Fujishige et al. [TCS 2023] proposed a
data structure of size $\Theta(n)$ that can output the set $\mathsf{MAW}(S)$ of
all MAWs for a given string $S$ of length $n$ in $O(n + |\mathsf{MAW}(S)|)$
time, based on the directed acyclic word graph (DAWG). In this paper, we
present a more space efficient data structure based on the compact DAWG
(CDAWG), which can output $\mathsf{MAW}(S)$ in $O(|\mathsf{MAW}(S)|)$ time with
$O(e)$ space, where $e$ denotes the minimum of the sizes of the CDAWGs for $S$
and for its reversal $S^R$. For any strings of length $n$, it holds that $e &lt;
2n$, and for highly repetitive strings $e$ can be sublinear (up to logarithmic)
in $n$. We also show that MAWs and their generalization minimal rare words have
close relationships with extended bispecial factors, via the CDAWG.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18091" title="Abstract">arXiv:2402.18091</a> [<a href="/pdf/2402.18091" title="Download PDF">pdf</a>, <a href="/format/2402.18091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polos: Multimodal Metric Learning from Human Feedback for Image  Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wada%2C+Y">Yuiga Wada</a>, 
<a href="/search/cs?searchtype=author&query=Kaneda%2C+K">Kanta Kaneda</a>, 
<a href="/search/cs?searchtype=author&query=Saito%2C+D">Daichi Saito</a>, 
<a href="/search/cs?searchtype=author&query=Sugiura%2C+K">Komei Sugiura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Establishing an automatic evaluation metric that closely aligns with human
judgments is essential for effectively developing image captioning models.
Recent data-driven metrics have demonstrated a stronger correlation with human
judgments than classic metrics such as CIDEr; however they lack sufficient
capabilities to handle hallucinations and generalize across diverse images and
texts partially because they compute scalar similarities merely using
embeddings learned from tasks unrelated to image captioning evaluation. In this
study, we propose Polos, a supervised automatic evaluation metric for image
captioning models. Polos computes scores from multimodal inputs, using a
parallel feature extraction mechanism that leverages embeddings trained through
large-scale contrastive learning. To train Polos, we introduce Multimodal
Metric Learning from Human Feedback (M$^2$LHF), a framework for developing
metrics based on human feedback. We constructed the Polaris dataset, which
comprises 131K human judgments from 550 evaluators, which is approximately ten
times larger than standard datasets. Our approach achieved state-of-the-art
performance on Composite, Flickr8K-Expert, Flickr8K-CF, PASCAL-50S, FOIL, and
the Polaris dataset, thereby demonstrating its effectiveness and robustness.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18092" title="Abstract">arXiv:2402.18092</a> [<a href="/pdf/2402.18092" title="Download PDF">pdf</a>, <a href="/format/2402.18092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-aware Talking Face Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xuanyuan%2C+M">Meidai Xuanyuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuwang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Honglei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Q">Qionghai Dai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we consider a novel and practical case for talking face video
generation. Specifically, we focus on the scenarios involving multi-people
interactions, where the talking context, such as audience or surroundings, is
present. In these situations, the video generation should take the context into
consideration in order to generate video content naturally aligned with driving
audios and spatially coherent to the context. To achieve this, we provide a
two-stage and cross-modal controllable video generation pipeline, taking facial
landmarks as an explicit and compact control signal to bridge the driving
audio, talking context and generated videos. Inside this pipeline, we devise a
3D video diffusion model, allowing for efficient contort of both spatial
conditions (landmarks and context video), as well as audio condition for
temporally coherent generation. The experimental results verify the advantage
of the proposed method over other baselines in terms of audio-video
synchronization, video fidelity and frame consistency.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18093" title="Abstract">arXiv:2402.18093</a> [<a href="/pdf/2402.18093" title="Download PDF">pdf</a>, <a href="/format/2402.18093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatSpamDetector: Leveraging Large Language Models for Effective  Phishing Email Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koide%2C+T">Takashi Koide</a>, 
<a href="/search/cs?searchtype=author&query=Fukushi%2C+N">Naoki Fukushi</a>, 
<a href="/search/cs?searchtype=author&query=Nakano%2C+H">Hiroki Nakano</a>, 
<a href="/search/cs?searchtype=author&query=Chiba%2C+D">Daiki Chiba</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The proliferation of phishing sites and emails poses significant challenges
to existing cybersecurity efforts. Despite advances in spam filters and email
security protocols, problems with oversight and false positives persist. Users
often struggle to understand why emails are flagged as spam, risking the
possibility of missing important communications or mistakenly trusting phishing
emails.
<br />This study introduces ChatSpamDetector, a system that uses large language
models (LLMs) to detect phishing emails. By converting email data into a prompt
suitable for LLM analysis, the system provides a highly accurate determination
of whether an email is phishing or not. Importantly, it offers detailed
reasoning for its phishing determinations, assisting users in making informed
decisions about how to handle suspicious emails. We conducted an evaluation
using a comprehensive phishing email dataset and compared our system to several
LLMs and baseline systems. We confirmed that our system using GPT-4 has
superior detection capabilities with an accuracy of 99.70%. Advanced contextual
interpretation by LLMs enables the identification of various phishing tactics
and impersonations, making them a potentially powerful tool in the fight
against email-based phishing threats.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18094" title="Abstract">arXiv:2402.18094</a> [<a href="/pdf/2402.18094" title="Download PDF">pdf</a>, <a href="/format/2402.18094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Existence of Cyclic Lattice Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Chengpin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Kurkoski%2C+B+M">Brian M. Kurkoski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, isit 2024 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">A coding lattice $\Lambda_c$ and a shaping lattice $\Lambda_s$ forms a nested
lattice code $\mathcal{C}$ if $\Lambda_s \subseteq \Lambda_c$. Under some
conditions, $\mathcal{C}$ is a finite cyclic group formed by rectangular
encoding. This paper presents the conditions for the existence of such
$\mathcal{C}$ and provides some designs. These designs correspond to solutions
to linear Diophantine equations so that a cyclic lattice code $\mathcal C$ of
arbitrary codebook size $M$ can possess group isomorphism, which is an
essential property for a nested lattice code to be applied in physical layer
network relaying techniques such as compute and forward.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18095" title="Abstract">arXiv:2402.18095</a> [<a href="/pdf/2402.18095" title="Download PDF">pdf</a>, <a href="/format/2402.18095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exergetic Port-Hamiltonian Systems for Multibody Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lohmayer%2C+M">Markus Lohmayer</a>, 
<a href="/search/eess?searchtype=author&query=Capobianco%2C+G">Giuseppe Capobianco</a>, 
<a href="/search/eess?searchtype=author&query=Leyendecker%2C+S">Sigrid Leyendecker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Mathematical Physics (math-ph); Classical Physics (physics.class-ph)

</div>
<p class="mathjax">Multibody dynamics simulation plays an important role in various fields,
including mechanical engineering, robotics, and biomechanics. Setting up
computational models however becomes increasingly challenging as systems grow
in size and complexity. Especially the consistent combination of models across
different physical domains usually demands a lot of attention. This motivates
us to study formal languages for compositional modeling of multiphysical
systems. This article shows how multibody systems, or more precisely assemblies
of rigid bodies connected by lower kinematic pairs, fit into the framework of
Exergetic Port-Hamiltonian Systems (EPHS). This approach is based on the
hierarchical decomposition of systems into their ultimately primitive
components, using a simple graphical syntax. Thereby, cognitive load can be
reduced and communication is facilitated, even with non-experts. Moreover, the
encapsulation and reuse of subsystems promotes efficient model development and
management. In contrast to established modeling languages such as Modelica, the
primitive components of EPHS are not defined by arbitrary equations. Instead,
there are four kinds of components, each defined by a particular geometric
structure with a clear physical interpretation. This higher-level approach
could make the process of building and maintaining large-scale models simpler
and also safer.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18096" title="Abstract">arXiv:2402.18096</a> [<a href="/pdf/2402.18096" title="Download PDF">pdf</a>, <a href="/format/2402.18096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> No Token Left Behind: Reliable KV Cache Compression via Importance-Aware  Mixed Precision Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J+Y">June Yong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Byeongwook Kim</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+J">Jeongin Bae</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+B">Beomseok Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+G">Gunho Park</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+E">Eunho Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+S+J">Se Jung Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongsoo Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Key-Value (KV) Caching has become an essential technique for accelerating the
inference speed and throughput of generative Large Language Models~(LLMs).
However, the memory footprint of the KV cache poses a critical bottleneck in
LLM deployment as the cache size grows with batch size and sequence length,
often surpassing even the size of the model itself. Although recent methods
were proposed to select and evict unimportant KV pairs from the cache to reduce
memory consumption, the potential ramifications of eviction on the generative
process are yet to be thoroughly examined. In this paper, we examine the
detrimental impact of cache eviction and observe that unforeseen risks arise as
the information contained in the KV pairs is exhaustively discarded, resulting
in safety breaches, hallucinations, and context loss. Surprisingly, we find
that preserving even a small amount of information contained in the evicted KV
pairs via reduced precision quantization substantially recovers the incurred
degradation. On the other hand, we observe that the important KV pairs must be
kept at a relatively higher precision to safeguard the generation quality.
Motivated by these observations, we propose \textit{Mixed-precision KV
cache}~(MiKV), a reliable cache compression method that simultaneously
preserves the context details by retaining the evicted KV pairs in
low-precision and ensure generation quality by keeping the important KV pairs
in high-precision. Experiments on diverse benchmarks and LLM backbones show
that our proposed method offers a state-of-the-art trade-off between
compression ratio and performance, compared to other baselines.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18099" title="Abstract">arXiv:2402.18099</a> [<a href="/pdf/2402.18099" title="Download PDF">pdf</a>, <a href="/format/2402.18099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Editing Factual Knowledge and Explanatory Ability of Medical Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Derong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhihong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhenxi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qidong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yefeng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Enhong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Model editing aims to precisely modify the behaviours of large language
models (LLMs) on specific knowledge while keeping irrelevant knowledge
unchanged. It has been proven effective in resolving hallucination and
out-of-date issues in LLMs. As a result, it can boost the application of LLMs
in many critical domains (e.g., medical domain), where the hallucination is not
tolerable. In this paper, we propose two model editing studies and validate
them in the medical domain: (1) directly editing the factual medical knowledge
and (2) editing the explanations to facts. Meanwhile, we observed that current
model editing methods struggle with the specialization and complexity of
medical knowledge. Therefore, we propose MedLaSA, a novel Layer-wise Scalable
Adapter strategy for medical model editing. It employs causal tracing to
identify the precise location of knowledge in neurons and then introduces
scalable adapters into the dense layers of LLMs. These adapters are assigned
scaling values based on the corresponding specific knowledge. To evaluate the
editing impact, we build two benchmark datasets and introduce a series of
challenging and comprehensive metrics. Extensive experiments on medical LLMs
demonstrate the editing efficiency of MedLaSA, without affecting irrelevant
knowledge that is not edited.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18101" title="Abstract">arXiv:2402.18101</a> [<a href="/pdf/2402.18101" title="Download PDF">pdf</a>, <a href="/ps/2402.18101" title="Download PostScript">ps</a>, <a href="/format/2402.18101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the Efficacy of Grammar Error Correction: A Human Evaluation  Approach in the Japanese Context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zheng Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this study, we evaluated the performance of the state-of-the-art sequence
tagging grammar error detection and correction model (SeqTagger) using Japanese
university students' writing samples. With an automatic annotation toolkit,
ERRANT, we first evaluated SeqTagger's performance on error correction with
human expert correction as the benchmark. Then a human-annotated approach was
adopted to evaluate Seqtagger's performance in error detection using a subset
of the writing dataset. Results indicated a precision of 63.66% and a recall of
20.19% for error correction in the full dataset. For the subset, after manual
exclusion of irrelevant errors such as semantic and mechanical ones, the model
shows an adjusted precision of 97.98% and an adjusted recall of 42.98% for
error detection, indicating the model's high accuracy but also its
conservativeness. Thematic analysis on errors undetected by the model revealed
that determiners and articles, especially the latter, were predominant.
Specifically, in terms of context-independent errors, the model occasionally
overlooked basic ones and faced challenges with overly erroneous or complex
structures. Meanwhile, context-dependent errors, notably those related to tense
and noun number, as well as those possibly influenced by the students' first
language (L1), remained particularly challenging.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18104" title="Abstract">arXiv:2402.18104</a> [<a href="/pdf/2402.18104" title="Download PDF">pdf</a>, <a href="/format/2402.18104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making Them Ask and Answer: Jailbreaking Large Language Models in Few  Queries via Disguise and Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhe Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yinpeng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+G">Guozhu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In recent years, large language models (LLMs) have demonstrated notable
success across various tasks, but the trustworthiness of LLMs is still an open
problem. One specific threat is the potential to generate toxic or harmful
responses. Attackers can craft adversarial prompts that induce harmful
responses from LLMs. In this work, we pioneer a theoretical foundation in LLMs
security by identifying bias vulnerabilities within the safety fine-tuning and
design a black-box jailbreak method named DRA (Disguise and Reconstruction
Attack), which conceals harmful instructions through disguise and prompts the
model to reconstruct the original harmful instruction within its completion. We
evaluate DRA across various open-source and close-source models, showcasing
state-of-the-art jailbreak success rates and attack efficiency. Notably, DRA
boasts a 90\% attack success rate on LLM chatbots GPT-4.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18107" title="Abstract">arXiv:2402.18107</a> [<a href="/pdf/2402.18107" title="Download PDF">pdf</a>, <a href="/format/2402.18107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Interaction Modeling via Self-Supervised Multi-Task Learning  for Review Helpfulness Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+H">HongLin Gong</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+M">Mengzhao Jia</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+L">Liqiang Jing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages,4 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">In line with the latest research, the task of identifying helpful reviews
from a vast pool of user-generated textual and visual data has become a
prominent area of study. Effective modal representations are expected to
possess two key attributes: consistency and differentiation. Current methods
designed for Multimodal Review Helpfulness Prediction (MRHP) face limitations
in capturing distinctive information due to their reliance on uniform
multimodal annotation. The process of adding varied multimodal annotations is
not only time-consuming but also labor-intensive. To tackle these challenges,
we propose an auto-generated scheme based on multi-task learning to generate
pseudo labels. This approach allows us to simultaneously train for the global
multimodal interaction task and the separate cross-modal interaction subtasks,
enabling us to learn and leverage both consistency and differentiation
effectively. Subsequently, experimental results validate the effectiveness of
pseudo labels, and our approach surpasses previous textual and multimodal
baseline models on two widely accessible benchmark datasets, providing a
solution to the MRHP problem.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18109" title="Abstract">arXiv:2402.18109</a> [<a href="/pdf/2402.18109" title="Download PDF">pdf</a>, <a href="/format/2402.18109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-Context Aggregation for Universal Image Matting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qinglin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+X">Xiaoqian Lv</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Changyong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengping Zhang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Multimed Tools Appl (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Natural image matting aims to estimate the alpha matte of the foreground from
a given image. Various approaches have been explored to address this problem,
such as interactive matting methods that use guidance such as click or trimap,
and automatic matting methods tailored to specific objects. However, existing
matting methods are designed for specific objects or guidance, neglecting the
common requirement of aggregating global and local contexts in image matting.
As a result, these methods often encounter challenges in accurately identifying
the foreground and generating precise boundaries, which limits their
effectiveness in unforeseen scenarios. In this paper, we propose a simple and
universal matting framework, named Dual-Context Aggregation Matting (DCAM),
which enables robust image matting with arbitrary guidance or without guidance.
Specifically, DCAM first adopts a semantic backbone network to extract
low-level features and context features from the input image and guidance.
Then, we introduce a dual-context aggregation network that incorporates global
object aggregators and local appearance aggregators to iteratively refine the
extracted context features. By performing both global contour segmentation and
local boundary refinement, DCAM exhibits robustness to diverse types of
guidance and objects. Finally, we adopt a matting decoder network to fuse the
low-level features and the refined context features for alpha matte estimation.
Experimental results on five matting datasets demonstrate that the proposed
DCAM outperforms state-of-the-art matting methods in both automatic matting and
interactive matting tasks, which highlights the strong universality and high
performance of DCAM. The source code is available at
\url{https://github.com/Windaway/DCAM}.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18110" title="Abstract">arXiv:2402.18110</a> [<a href="/pdf/2402.18110" title="Download PDF">pdf</a>, <a href="/ps/2402.18110" title="Download PostScript">ps</a>, <a href="/format/2402.18110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Logarithmic Random Bidding for the Parallel Roulette Wheel Selection  with Precise Probabilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nakano%2C+K">Koji Nakano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The roulette wheel selection is a critical process in heuristic algorithms,
enabling the probabilistic choice of items based on assigned fitness values. It
selects an item with a probability proportional to its fitness value. This
technique is commonly employed in ant-colony algorithms to randomly determine
the next city to visit when solving the traveling salesman problem. Our study
focuses on parallel algorithms designed to select one of multiple processors,
each associated with fitness values, using random wheel selection. We propose a
novel approach called logarithmic random bidding, which achieves an expected
runtime logarithmic to the number of processors with non-zero fitness values,
using the CRCW-PRAM model with a shared memory of constant size. Notably, the
logarithmic random bidding technique demonstrates efficient performance,
particularly in scenarios where only a few processors are assigned non-zero
fitness values.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18113" title="Abstract">arXiv:2402.18113</a> [<a href="/pdf/2402.18113" title="Download PDF">pdf</a>, <a href="/format/2402.18113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Small But Funny: A Feedback-Driven Approach to Humor Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ravi%2C+S">Sahithya Ravi</a>, 
<a href="/search/cs?searchtype=author&query=Huber%2C+P">Patrick Huber</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+A">Akshat Shrivastava</a>, 
<a href="/search/cs?searchtype=author&query=Sagar%2C+A">Aditya Sagar</a>, 
<a href="/search/cs?searchtype=author&query=Aly%2C+A">Ahmed Aly</a>, 
<a href="/search/cs?searchtype=author&query=Shwartz%2C+V">Vered Shwartz</a>, 
<a href="/search/cs?searchtype=author&query=Einolghozati%2C+A">Arash Einolghozati</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The emergence of Large Language Models (LLMs) has brought to light promising
language generation capabilities, particularly in performing tasks like complex
reasoning and creative writing. Consequently, distillation through imitation of
teacher responses has emerged as a popular technique to transfer knowledge from
LLMs to more accessible, Small Language Models (SLMs). While this works well
for simpler tasks, there is a substantial performance gap on tasks requiring
intricate language comprehension and creativity, such as humor generation. We
hypothesize that this gap may stem from the fact that creative tasks might be
hard to learn by imitation alone and explore whether an approach, involving
supplementary guidance from the teacher, could yield higher performance. To
address this, we study the effect of assigning a dual role to the LLM - as a
"teacher" generating data, as well as a "critic" evaluating the student's
performance. Our experiments on humor generation reveal that the incorporation
of feedback significantly narrows the performance gap between SLMs and their
larger counterparts compared to merely relying on imitation. As a result, our
research highlights the potential of using feedback as an additional dimension
to data when transferring complex language abilities via distillation.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18114" title="Abstract">arXiv:2402.18114</a> [<a href="/pdf/2402.18114" title="Download PDF">pdf</a>, <a href="/format/2402.18114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PIMSYN: Synthesizing Processing-in-memory CNN Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wanqian Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaotian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yinhe Han</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoming Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Processing-in-memory architectures have been regarded as a promising solution
for CNN acceleration. Existing PIM accelerator designs rely heavily on the
experience of experts and require significant manual design overhead. Manual
design cannot effectively optimize and explore architecture implementations. In
this work, we develop an automatic framework PIMSYN for synthesizing PIM-based
CNN accelerators, which greatly facilitates architecture design and helps
generate energyefficient accelerators. PIMSYN can automatically transform CNN
applications into execution workflows and hardware construction of PIM
accelerators. To systematically optimize the architecture, we embed an
architectural exploration flow into the synthesis framework, providing a more
comprehensive design space. Experiments demonstrate that PIMSYN improves the
power efficiency by several times compared with existing works. PIMSYN can be
obtained from https://github.com/lixixi-jook/PIMSYN-NN.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18115" title="Abstract">arXiv:2402.18115</a> [<a href="/pdf/2402.18115" title="Download PDF">pdf</a>, <a href="/format/2402.18115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniVS: Unified and Universal Video Segmentation with Prompts as Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Minghan Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuai Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xindong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 11 figures, 10 tabels, CVPR2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The IEEE/CVF Conference on Computer Vision and Pattern Recognition
  2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Despite the recent advances in unified image segmentation (IS), developing a
unified video segmentation (VS) model remains a challenge. This is mainly
because generic category-specified VS tasks need to detect all objects and
track them across consecutive frames, while prompt-guided VS tasks require
re-identifying the target with visual/text prompts throughout the entire video,
making it hard to handle the different tasks with the same architecture. We
make an attempt to address these issues and present a novel unified VS
architecture, namely UniVS, by using prompts as queries. UniVS averages the
prompt features of the target from previous frames as its initial query to
explicitly decode masks, and introduces a target-wise prompt cross-attention
layer in the mask decoder to integrate prompt features in the memory pool. By
taking the predicted masks of entities from previous frames as their visual
prompts, UniVS converts different VS tasks into prompt-guided target
segmentation, eliminating the heuristic inter-frame matching process. Our
framework not only unifies the different VS tasks but also naturally achieves
universal training and testing, ensuring robust performance across different
scenarios. UniVS shows a commendable balance between performance and
universality on 10 challenging VS benchmarks, covering video instance,
semantic, panoptic, object, and referring segmentation tasks. Code can be found
at \url{https://github.com/MinghanLi/UniVS}.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18116" title="Abstract">arXiv:2402.18116</a> [<a href="/pdf/2402.18116" title="Download PDF">pdf</a>, <a href="/format/2402.18116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Block and Detail: Scaffolding Sketch-to-Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarukkai%2C+V">Vishnu Sarukkai</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Lu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+M">Mia Tang</a>, 
<a href="/search/cs?searchtype=author&query=Agrawala%2C+M">Maneesh Agrawala</a>, 
<a href="/search/cs?searchtype=author&query=Fatahalian%2C+K">Kayvon Fatahalian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We introduce a novel sketch-to-image tool that aligns with the iterative
refinement process of artists. Our tool lets users sketch blocking strokes to
coarsely represent the placement and form of objects and detail strokes to
refine their shape and silhouettes. We develop a two-pass algorithm for
generating high-fidelity images from such sketches at any point in the
iterative process. In the first pass we use a ControlNet to generate an image
that strictly follows all the strokes (blocking and detail) and in the second
pass we add variation by renoising regions surrounding blocking strokes. We
also present a dataset generation scheme that, when used to train a ControlNet
architecture, allows regions that do not contain strokes to be interpreted as
not-yet-specified regions rather than empty space. We show that this
partial-sketch-aware ControlNet can generate coherent elements from partial
sketches that only contain a small number of strokes. The high-fidelity images
produced by our approach serve as scaffolds that can help the user adjust the
shape and proportions of objects or add additional elements to the composition.
We demonstrate the effectiveness of our approach with a variety of examples and
evaluative comparisons.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18117" title="Abstract">arXiv:2402.18117</a> [<a href="/pdf/2402.18117" title="Download PDF">pdf</a>, <a href="/format/2402.18117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PRCL: Probabilistic Representation Contrastive Learning for  Semi-Supervised Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Haoyu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Changqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dan%2C+J">Jun Dan</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Chong Fu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Baigui Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Tremendous breakthroughs have been developed in Semi-Supervised Semantic
Segmentation (S4) through contrastive learning. However, due to limited
annotations, the guidance on unlabeled images is generated by the model itself,
which inevitably exists noise and disturbs the unsupervised training process.
To address this issue, we propose a robust contrastive-based S4 framework,
termed the Probabilistic Representation Contrastive Learning (PRCL) framework
to enhance the robustness of the unsupervised training process. We model the
pixel-wise representation as Probabilistic Representations (PR) via
multivariate Gaussian distribution and tune the contribution of the ambiguous
representations to tolerate the risk of inaccurate guidance in contrastive
learning. Furthermore, we introduce Global Distribution Prototypes (GDP) by
gathering all PRs throughout the whole training process. Since the GDP contains
the information of all representations with the same class, it is robust from
the instant noise in representations and bears the intra-class variance of
representations. In addition, we generate Virtual Negatives (VNs) based on GDP
to involve the contrastive learning process. Extensive experiments on two
public benchmarks demonstrate the superiority of our PRCL framework.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18120" title="Abstract">arXiv:2402.18120</a> [<a href="/pdf/2402.18120" title="Download PDF">pdf</a>, <a href="/format/2402.18120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Multilingual Human Value Concepts in Large Language Models: Is  Value Alignment Consistent, Transferable and Controllable across Languages?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shaoyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+W">Weilong Dong</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zishan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xinwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+D">Deyi Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Prior research in representation engineering has revealed that LLMs encode
concepts within their representation spaces, predominantly centered around
English. In this study, we extend this philosophy to a multilingual scenario,
delving into multilingual human value concepts in LLMs. Through our
comprehensive exploration covering 7 types of human values, 16 languages and 3
LLM series with distinct multilinguality, we empirically substantiate the
existence of multilingual human values in LLMs. Further cross-lingual analysis
on these concepts discloses 3 traits arising from language resource
disparities: cross-lingual inconsistency, distorted linguistic relationships,
and unidirectional cross-lingual transfer between high- and low-resource
languages, all in terms of human value concepts. Additionally, we validate the
feasibility of cross-lingual control over value alignment capabilities of LLMs,
leveraging the dominant language as a source language. Drawing from our
findings on multilingual value alignment, we prudently provide suggestions on
the composition of multilingual data for LLMs pre-training: including a limited
number of dominant languages for cross-lingual alignment transfer while
avoiding their excessive prevalence, and keeping a balanced distribution of
non-dominant languages. We aspire that our findings would contribute to
enhancing the safety and utility of multilingual AI.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18121" title="Abstract">arXiv:2402.18121</a> [<a href="/pdf/2402.18121" title="Download PDF">pdf</a>, <a href="/format/2402.18121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Saving the legacy of Hero Ibash: Evaluating Four Language Models for  Aminoacian
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yunze Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yiyang Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study assesses four cutting-edge language models in the underexplored
Aminoacian language. Through evaluation, it scrutinizes their adaptability,
effectiveness, and limitations in text generation, semantic coherence, and
contextual understanding. Uncovering insights into these models' performance in
a low-resourced language, this research pioneers pathways to bridge linguistic
gaps. By offering benchmarks and understanding challenges, it lays groundwork
for future advancements in natural language processing, aiming to elevate the
applicability of language models in similar linguistic landscapes, marking a
significant step toward inclusivity and progress in language technology.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18122" title="Abstract">arXiv:2402.18122</a> [<a href="/pdf/2402.18122" title="Download PDF">pdf</a>, <a href="/format/2402.18122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> G4G:A Generic Framework for High Fidelity Talking Face Generation with  Fine-grained Intra-modal Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Juan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiahao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhiwang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+T">Tangquan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Di Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Despite numerous completed studies, achieving high fidelity talking face
generation with highly synchronized lip movements corresponding to arbitrary
audio remains a significant challenge in the field. The shortcomings of
published studies continue to confuse many researchers. This paper introduces
G4G, a generic framework for high fidelity talking face generation with
fine-grained intra-modal alignment. G4G can reenact the high fidelity of
original video while producing highly synchronized lip movements regardless of
given audio tones or volumes. The key to G4G's success is the use of a diagonal
matrix to enhance the ordinary alignment of audio-image intra-modal features,
which significantly increases the comparative learning between positive and
negative samples. Additionally, a multi-scaled supervision module is introduced
to comprehensively reenact the perceptional fidelity of original video across
the facial region while emphasizing the synchronization of lip movements and
the input audio. A fusion network is then used to further fuse the facial
region and the rest. Our experimental results demonstrate significant
achievements in reenactment of original video quality as well as highly
synchronized talking lips. G4G is an outperforming generic framework that can
produce talking videos competitively closer to ground truth level than current
state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18123" title="Abstract">arXiv:2402.18123</a> [<a href="/pdf/2402.18123" title="Download PDF">pdf</a>, <a href="/format/2402.18123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fixture calibration with guaranteed bounds from a few  correspondence-free surface points
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haugaard%2C+R+L">Rasmus Laurvig Haugaard</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yitaek Kim</a>, 
<a href="/search/cs?searchtype=author&query=Iversen%2C+T+M">Thorbj&#xf8;rn Mosekj&#xe6;r Iversen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Calibration of fixtures in robotic work cells is essential but also time
consuming and error-prone, and poor calibration can easily lead to wasted
debugging time in downstream tasks. Contact-based calibration methods let the
user measure points on the fixture's surface with a tool tip attached to the
robot's end effector. Most methods require the user to manually annotate
correspondences on the CAD model, however, this is error-prone and a cumbersome
user experience. We propose a correspondence-free alternative: The user simply
measures a few points from the fixture's surface, and our method provides a
tight superset of the poses which could explain the measured points. This
naturally detects ambiguities related to symmetry and uninformative points and
conveys this uncertainty to the user. Perhaps more importantly, it provides
guaranteed bounds on the pose. The computation of such bounds is made tractable
by the use of a hierarchical grid on SE(3). Our method is evaluated both in
simulation and on a real collaborative robot, showing great potential for
easier and less error-prone fixture calibration.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18127" title="Abstract">arXiv:2402.18127</a> [<a href="/pdf/2402.18127" title="Download PDF">pdf</a>, <a href="/format/2402.18127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Multi-Relational Graph Representation Learning for  Large-Scale Prediction of Drug-Drug Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Mengying Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guizhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yuanchao Su</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+W">Weiqiang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Biao Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages,10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Most existing methods for predicting drug-drug interactions (DDI)
predominantly concentrate on capturing the explicit relationships among drugs,
overlooking the valuable implicit correlations present between drug pairs
(DPs), which leads to weak predictions. To address this issue, this paper
introduces a hierarchical multi-relational graph representation learning
(HMGRL) approach. Within the framework of HMGRL, we leverage a wealth of
drug-related heterogeneous data sources to construct heterogeneous graphs,
where nodes represent drugs and edges denote clear and various associations.
The relational graph convolutional network (RGCN) is employed to capture
diverse explicit relationships between drugs from these heterogeneous graphs.
Additionally, a multi-view differentiable spectral clustering (MVDSC) module is
developed to capture multiple valuable implicit correlations between DPs.
Within the MVDSC, we utilize multiple DP features to construct graphs, where
nodes represent DPs and edges denote different implicit correlations.
Subsequently, multiple DP representations are generated through graph cutting,
each emphasizing distinct implicit correlations. The graph-cutting strategy
enables our HMGRL to identify strongly connected communities of graphs, thereby
reducing the fusion of irrelevant features. By combining every representation
view of a DP, we create high-level DP representations for predicting DDIs. Two
genuine datasets spanning three distinct tasks are adopted to gauge the
efficacy of our HMGRL. Experimental outcomes unequivocally indicate that HMGRL
surpasses several leading-edge methods in performance.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18128" title="Abstract">arXiv:2402.18128</a> [<a href="/pdf/2402.18128" title="Download PDF">pdf</a>, <a href="/format/2402.18128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Downstream Task Guided Masking Learning in Masked Autoencoders Using  Multi-Level Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Han Guo</a>, 
<a href="/search/cs?searchtype=author&query=Hosseini%2C+R">Ramtin Hosseini</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruiyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Somayajula%2C+S+A">Sai Ashish Somayajula</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+R+R">Ranak Roy Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+R+K">Rajesh K. Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+P">Pengtao Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Masked Autoencoder (MAE) is a notable method for self-supervised pretraining
in visual representation learning. It operates by randomly masking image
patches and reconstructing these masked patches using the unmasked ones. A key
limitation of MAE lies in its disregard for the varying informativeness of
different patches, as it uniformly selects patches to mask. To overcome this,
some approaches propose masking based on patch informativeness. However, these
methods often do not consider the specific requirements of downstream tasks,
potentially leading to suboptimal representations for these tasks. In response,
we introduce the Multi-level Optimized Mask Autoencoder (MLO-MAE), a novel
framework that leverages end-to-end feedback from downstream tasks to learn an
optimal masking strategy during pretraining. Our experimental findings
highlight MLO-MAE's significant advancements in visual representation learning.
Compared to existing methods, it demonstrates remarkable improvements across
diverse datasets and tasks, showcasing its adaptability and efficiency. Our
code is available at: https://github.com/Alexiland/MLOMAE
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18129" title="Abstract">arXiv:2402.18129</a> [<a href="/pdf/2402.18129" title="Download PDF">pdf</a>, <a href="/format/2402.18129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Inductive Biases of Demographic Parity-based Fair Learning  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+H">Haoyu Lei</a>, 
<a href="/search/cs?searchtype=author&query=Gohari%2C+A">Amin Gohari</a>, 
<a href="/search/cs?searchtype=author&query=Farnia%2C+F">Farzan Farnia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT)

</div>
<p class="mathjax">Fair supervised learning algorithms assigning labels with little dependence
on a sensitive attribute have attracted great attention in the machine learning
community. While the demographic parity (DP) notion has been frequently used to
measure a model's fairness in training fair classifiers, several studies in the
literature suggest potential impacts of enforcing DP in fair learning
algorithms. In this work, we analytically study the effect of standard DP-based
regularization methods on the conditional distribution of the predicted label
given the sensitive attribute. Our analysis shows that an imbalanced training
dataset with a non-uniform distribution of the sensitive attribute could lead
to a classification rule biased toward the sensitive attribute outcome holding
the majority of training data. To control such inductive biases in DP-based
fair learning, we propose a sensitive attribute-based distributionally robust
optimization (SA-DRO) method improving robustness against the marginal
distribution of the sensitive attribute. Finally, we present several numerical
results on the application of DP-based learning methods to standard centralized
and distributed learning problems. The empirical findings support our
theoretical results on the inductive biases in DP-based fair learning
algorithms and the debiasing effects of the proposed SA-DRO method.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18132" title="Abstract">arXiv:2402.18132</a> [<a href="/pdf/2402.18132" title="Download PDF">pdf</a>, <a href="/format/2402.18132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Role of Pathways in a Deep Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+L">Lei Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+C">Chen Pang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jihua Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Deep neural networks have demonstrated superior performance in artificial
intelligence applications, but the opaqueness of their inner working mechanism
is one major drawback in their application. The prevailing unit-based
interpretation is a statistical observation of stimulus-response data, which
fails to show a detailed internal process of inherent mechanisms of neural
networks. In this work, we analyze a convolutional neural network (CNN) trained
in the classification task and present an algorithm to extract the diffusion
pathways of individual pixels to identify the locations of pixels in an input
image associated with object classes. The pathways allow us to test the causal
components which are important for classification and the pathway-based
representations are clearly distinguishable between categories. We find that
the few largest pathways of an individual pixel from an image tend to cross the
feature maps in each layer that is important for classification. And the large
pathways of images of the same category are more consistent in their trends
than those of different categories. We also apply the pathways to understanding
adversarial attacks, object completion, and movement perception. Further, the
total number of pathways on feature maps in all layers can clearly discriminate
the original, deformed, and target samples.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18133" title="Abstract">arXiv:2402.18133</a> [<a href="/pdf/2402.18133" title="Download PDF">pdf</a>, <a href="/format/2402.18133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classes Are Not Equal: An Empirical Study on Image Recognition Fairness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jiequan Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Beier Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+X">Xin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xiaojuan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanwang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this paper, we present an empirical study on image recognition fairness,
i.e., extreme class accuracy disparity on balanced data like ImageNet. We
experimentally demonstrate that classes are not equal and the fairness issue is
prevalent for image classification models across various datasets, network
architectures, and model capacities. Moreover, several intriguing properties of
fairness are identified. First, the unfairness lies in problematic
representation rather than classifier bias. Second, with the proposed concept
of Model Prediction Bias, we investigate the origins of problematic
representation during optimization. Our findings reveal that models tend to
exhibit greater prediction biases for classes that are more challenging to
recognize. It means that more other classes will be confused with harder
classes. Then the False Positives (FPs) will dominate the learning in
optimization, thus leading to their poor accuracy. Further, we conclude that
data augmentation and representation learning algorithms improve overall
performance by promoting fairness to some degree in image classification.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18134" title="Abstract">arXiv:2402.18134</a> [<a href="/pdf/2402.18134" title="Download PDF">pdf</a>, <a href="/format/2402.18134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Deblur Polarized Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+M">Minggui Teng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xinyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sh%2C+B">Boxin Sh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">A polarization camera can capture four polarized images with different
polarizer angles in a single shot, which is useful in polarization-based vision
applications since the degree of polarization (DoP) and the angle of
polarization (AoP) can be directly computed from the captured polarized images.
However, since the on-chip micro-polarizers block part of the light so that the
sensor often requires a longer exposure time, the captured polarized images are
prone to motion blur caused by camera shakes, leading to noticeable degradation
in the computed DoP and AoP. Deblurring methods for conventional images often
show degenerated performance when handling the polarized images since they only
focus on deblurring without considering the polarization constrains. In this
paper, we propose a polarized image deblurring pipeline to solve the problem in
a polarization-aware manner by adopting a divide-and-conquer strategy to
explicitly decompose the problem into two less ill-posed sub-problems, and
design a two-stage neural network to handle the two sub-problems respectively.
Experimental results show that our method achieves state-of-the-art performance
on both synthetic and real-world images, and can improve the performance of
polarization-based vision applications such as image dehazing and reflection
removal.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18137" title="Abstract">arXiv:2402.18137</a> [<a href="/pdf/2402.18137" title="Download PDF">pdf</a>, <a href="/format/2402.18137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DecisionNCE: Embodied Multimodal Representations via Implicit Preference  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianxiong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jinliang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yinan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+L">Liyuan Mao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Sijie Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+H">Haoyi Niu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jihao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingjing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ya-Qin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xianyuan Zhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. 27 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Multimodal pretraining has emerged as an effective strategy for the trinity
of goals of representation learning in autonomous robots: 1) extracting both
local and global task progression information; 2) enforcing temporal
consistency of visual representation; 3) capturing trajectory-level language
grounding. Most existing methods approach these via separate objectives, which
often reach sub-optimal solutions. In this paper, we propose a universal
unified objective that can simultaneously extract meaningful task progression
information from image sequences and seamlessly align them with language
instructions. We discover that via implicit preferences, where a visual
trajectory inherently aligns better with its corresponding language instruction
than mismatched pairs, the popular Bradley-Terry model can transform into
representation learning through proper reward reparameterizations. The resulted
framework, DecisionNCE, mirrors an InfoNCE-style objective but is distinctively
tailored for decision-making tasks, providing an embodied representation
learning framework that elegantly extracts both local and global task
progression features, with temporal consistency enforced through implicit time
contrastive learning, while ensuring trajectory-level instruction grounding via
multimodal joint encoding. Evaluation on both simulated and real robots
demonstrates that DecisionNCE effectively facilitates diverse downstream policy
learning tasks, offering a versatile solution for unified representation and
reward learning. Project Page: https://2toinf.github.io/DecisionNCE/
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18139" title="Abstract">arXiv:2402.18139</a> [<a href="/pdf/2402.18139" title="Download PDF">pdf</a>, <a href="/format/2402.18139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cause and Effect: Can Large Language Models Truly Understand Causality?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ashwani%2C+S">Swagata Ashwani</a>, 
<a href="/search/cs?searchtype=author&query=Hegde%2C+K">Kshiteesh Hegde</a>, 
<a href="/search/cs?searchtype=author&query=Mannuru%2C+N+R">Nishith Reddy Mannuru</a>, 
<a href="/search/cs?searchtype=author&query=Jindal%2C+M">Mayank Jindal</a>, 
<a href="/search/cs?searchtype=author&query=Sengar%2C+D+S">Dushyant Singh Sengar</a>, 
<a href="/search/cs?searchtype=author&query=Kathala%2C+K+C+R">Krishna Chaitanya Rao Kathala</a>, 
<a href="/search/cs?searchtype=author&query=Banga%2C+D">Dishant Banga</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+V">Vinija Jain</a>, 
<a href="/search/cs?searchtype=author&query=Chadha%2C+A">Aman Chadha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18140" title="Abstract">arXiv:2402.18140</a> [<a href="/pdf/2402.18140" title="Download PDF">pdf</a>, <a href="/format/2402.18140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OccTransformer: Improving BEVFormer for 3D camera-only occupancy  prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sipeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+C">Chuixin Kong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuhang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yikang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Borun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ming%2C+R">Ruibo Ming</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+D">Donglai Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianming Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Innovation Award in the 3D Occupancy Prediction Challenge (CVPR23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This technical report presents our solution, "occTransformer" for the 3D
occupancy prediction track in the autonomous driving challenge at CVPR 2023.
Our method builds upon the strong baseline BEVFormer and improves its
performance through several simple yet effective techniques. Firstly, we
employed data augmentation to increase the diversity of the training data and
improve the model's generalization ability. Secondly, we used a strong image
backbone to extract more informative features from the input data. Thirdly, we
incorporated a 3D unet head to better capture the spatial information of the
scene. Fourthly, we added more loss functions to better optimize the model.
Additionally, we used an ensemble approach with the occ model BevDet and
SurroundOcc to further improve the performance. Most importantly, we integrated
3D detection model StreamPETR to enhance the model's ability to detect objects
in the scene. Using these methods, our solution achieved 49.23 miou on the 3D
occupancy prediction track in the autonomous driving challenge.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18144" title="Abstract">arXiv:2402.18144</a> [<a href="/pdf/2402.18144" title="Download PDF">pdf</a>, <a href="/ps/2402.18144" title="Download PostScript">ps</a>, <a href="/format/2402.18144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random Silicon Sampling: Simulating Human Sub-Population Opinion Using a  Large Language Model Based on Group-Level Demographic Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Seungjong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+E">Eungu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Nan%2C+D">Dongyan Nan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangying Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Wonbyung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jansen%2C+B+J">Bernard J. Jansen</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J+H">Jang Hyun Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 4 figures, 19 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Large language models exhibit societal biases associated with demographic
information, including race, gender, and others. Endowing such language models
with personalities based on demographic data can enable generating opinions
that align with those of humans. Building on this idea, we propose "random
silicon sampling," a method to emulate the opinions of the human population
sub-group. Our study analyzed 1) a language model that generates the survey
responses that correspond with a human group based solely on its demographic
distribution and 2) the applicability of our methodology across various
demographic subgroups and thematic questions. Through random silicon sampling
and using only group-level demographic information, we discovered that language
models can generate response distributions that are remarkably similar to the
actual U.S. public opinion polls. Moreover, we found that the replicability of
language models varies depending on the demographic group and topic of the
question, and this can be attributed to inherent societal biases in the models.
Our findings demonstrate the feasibility of mirroring a group's opinion using
only demographic distribution and elucidate the effect of social biases in
language models on such simulations.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18145" title="Abstract">arXiv:2402.18145</a> [<a href="/pdf/2402.18145" title="Download PDF">pdf</a>, <a href="/format/2402.18145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Intrinsic Dimension via Information Bottleneck for Explainable  Aspect-based Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhenxiao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qin Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Liang He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Gradient-based explanation methods are increasingly used to interpret neural
models in natural language processing (NLP) due to their high fidelity. Such
methods determine word-level importance using dimension-level gradient values
through a norm function, often presuming equal significance for all gradient
dimensions. However, in the context of Aspect-based Sentiment Analysis (ABSA),
our preliminary research suggests that only specific dimensions are pertinent.
To address this, we propose the Information Bottleneck-based Gradient
(\texttt{IBG}) explanation framework for ABSA. This framework leverages an
information bottleneck to refine word embeddings into a concise intrinsic
dimension, maintaining essential features and omitting unrelated information.
Comprehensive tests show that our \texttt{IBG} approach considerably improves
both the models' performance and interpretability by identifying
sentiment-aware features.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18146" title="Abstract">arXiv:2402.18146</a> [<a href="/pdf/2402.18146" title="Download PDF">pdf</a>, <a href="/ps/2402.18146" title="Download PostScript">ps</a>, <a href="/format/2402.18146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3DSFLabelling: Boosting 3D Scene Flow Estimation by Pseudo  Auto-labelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chaokang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guangming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiuming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hesheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhuang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenqiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zhujin Liang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Yi Shan</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+D">Dalong Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR2024! 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning 3D scene flow from LiDAR point clouds presents significant
difficulties, including poor generalization from synthetic datasets to real
scenes, scarcity of real-world 3D labels, and poor performance on real sparse
LiDAR point clouds. We present a novel approach from the perspective of
auto-labelling, aiming to generate a large number of 3D scene flow pseudo
labels for real-world LiDAR point clouds. Specifically, we employ the
assumption of rigid body motion to simulate potential object-level rigid
movements in autonomous driving scenarios. By updating different motion
attributes for multiple anchor boxes, the rigid motion decomposition is
obtained for the whole scene. Furthermore, we developed a novel 3D scene flow
data augmentation method for global and local motion. By perfectly synthesizing
target point clouds based on augmented motion parameters, we easily obtain lots
of 3D scene flow labels in point clouds highly consistent with real scenarios.
On multiple real-world datasets including LiDAR KITTI, nuScenes, and Argoverse,
our method outperforms all previous supervised and unsupervised methods without
requiring manual labelling. Impressively, our method achieves a tenfold
reduction in EPE3D metric on the LiDAR KITTI dataset, reducing it from $0.190m$
to a mere $0.008m$ error.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18148" title="Abstract">arXiv:2402.18148</a> [<a href="/pdf/2402.18148" title="Download PDF">pdf</a>, <a href="/format/2402.18148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A metamodel for confined yield stress flows and parameters&#x27; estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Berger%2C+C">Cl&#xe9;ment Berger</a> (UMPA-ENSL), 
<a href="/search/math?searchtype=author&query=Coulette%2C+D">David Coulette</a> (NUMED, UMPA-ENSL), 
<a href="/search/math?searchtype=author&query=Vigneaux%2C+P">Paul Vigneaux</a> (UMPA-ENSL, LAMFA)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Rheologica Acta, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Classical Physics (physics.class-ph)

</div>
<p class="mathjax">With the growing demand of mineral consumption, the management of the mining
waste is crucial. Cemented paste backfill (CPB) is one of the techniques
developed by the mining industry to fill the voids generated by the excavation
of underground spaces. The CPB process is the subject of various studies aimed
at optimizing its implementation in the field. In this article, we focus on the
modelling of the backfill phase where it has been shown in [Vigneaux et al.,
Cem. Concr. Res. 164 (2023) 107038] that a viscoplastic lubrication model can
be used to describe CPB experiments. The aim here is to propose an accelerated
method for performing the parameters' estimation of the properties of the paste
(typically its rheological properties), with an inverse problem procedure based
on observed height profiles of the paste. The inversion procedure is based on a
metamodel built from an initial partial differential equation model, thanks to
a Polynomial Chaos Expansion coupled with a Principal Component Analysis.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18149" title="Abstract">arXiv:2402.18149</a> [<a href="/pdf/2402.18149" title="Download PDF">pdf</a>, <a href="/ps/2402.18149" title="Download PostScript">ps</a>, <a href="/format/2402.18149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably Efficient Partially Observable Risk-Sensitive Reinforcement  Learning with Hindsight Observation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tonghe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Longbo Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">This work pioneers regret analysis of risk-sensitive reinforcement learning
in partially observable environments with hindsight observation, addressing a
gap in theoretical exploration. We introduce a novel formulation that
integrates hindsight observations into a Partially Observable Markov Decision
Process (POMDP) framework, where the goal is to optimize accumulated reward
under the entropic risk measure. We develop the first provably efficient RL
algorithm tailored for this setting. We also prove by rigorous analysis that
our algorithm achieves polynomial regret
$\tilde{O}\left(\frac{e^{|{\gamma}|H}-1}{|{\gamma}|H}H^2\sqrt{KHS^2OA}\right)$,
which outperforms or matches existing upper bounds when the model degenerates
to risk-neutral or fully observable settings. We adopt the method of
change-of-measure and develop a novel analytical tool of beta vectors to
streamline mathematical derivations. These techniques are of particular
interest to the theoretical study of reinforcement learning.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18150" title="Abstract">arXiv:2402.18150</a> [<a href="/pdf/2402.18150" title="Download PDF">pdf</a>, <a href="/format/2402.18150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Information Refinement Training of Large Language Models  for Retrieval-Augmented Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shicheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+L">Liang Pang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+M">Mo Yu</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fandong Meng</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Huawei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Retrieval-augmented generation (RAG) enhances large language models (LLMs) by
incorporating additional information from retrieval. However, studies have
shown that LLMs still face challenges in effectively using the retrieved
information, even ignoring it or being misled by it. The key reason is that the
training of LLMs does not clearly make LLMs learn how to utilize input
retrieved texts with varied quality. In this paper, we propose a novel
perspective that considers the role of LLMs in RAG as ``Information Refiner'',
which means that regardless of correctness, completeness, or usefulness of
retrieved texts, LLMs can consistently integrate knowledge within the retrieved
texts and model parameters to generate the texts that are more concise,
accurate, and complete than the retrieved texts. To this end, we propose an
information refinement training method named InFO-RAG that optimizes LLMs for
RAG in an unsupervised manner. InFO-RAG is low-cost and general across various
tasks. Extensive experiments on zero-shot prediction of 11 datasets in diverse
tasks including Question Answering, Slot-Filling, Language Modeling, Dialogue,
and Code Generation show that InFO-RAG improves the performance of LLaMA2 by an
average of 9.39\% relative points. InFO-RAG also shows advantages in in-context
learning and robustness of RAG.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18153" title="Abstract">arXiv:2402.18153</a> [<a href="/pdf/2402.18153" title="Download PDF">pdf</a>, <a href="/format/2402.18153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-based Neural Network Weights Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soro%2C+B">Bedionita Soro</a>, 
<a href="/search/cs?searchtype=author&query=Andreis%2C+B">Bruno Andreis</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hayeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Chong%2C+S">Song Chong</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+F">Frank Hutter</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S+J">Sung Ju Hwang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Transfer learning is a topic of significant interest in recent deep learning
research because it enables faster convergence and improved performance on new
tasks. While the performance of transfer learning depends on the similarity of
the source data to the target data, it is costly to train a model on a large
number of datasets. Therefore, pretrained models are generally blindly selected
with the hope that they will achieve good performance on the given task. To
tackle such suboptimality of the pretrained models, we propose an efficient and
adaptive transfer learning scheme through dataset-conditioned pretrained
weights sampling. Specifically, we use a latent diffusion model with a
variational autoencoder that can reconstruct the neural network weights, to
learn the distribution of a set of pretrained weights conditioned on each
dataset for transfer learning on unseen datasets. By learning the distribution
of a neural network on a variety pretrained models, our approach enables
adaptive sampling weights for unseen datasets achieving faster convergence and
reaching competitive performance.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18154" title="Abstract">arXiv:2402.18154</a> [<a href="/pdf/2402.18154" title="Download PDF">pdf</a>, <a href="/format/2402.18154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cutting Off the Head Ends the Conflict: A Mechanism for Interpreting and  Mitigating Knowledge Conflicts in Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhuoran Jin</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+P">Pengfei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Hongbang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yubo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiexin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huaijun Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiaojian Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 42 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Recently, retrieval augmentation and tool augmentation have demonstrated a
remarkable capability to expand the internal memory boundaries of language
models (LMs) by providing external context. However, internal memory and
external context inevitably clash, leading to knowledge conflicts within LMs.
In this paper, we aim to interpret the mechanism of knowledge conflicts through
the lens of information flow, and then mitigate conflicts by precise
interventions at the pivotal point. We find there are some attention heads with
opposite effects in the later layers, where memory heads can recall knowledge
from internal memory, and context heads can retrieve knowledge from external
context. Moreover, we reveal that the pivotal point at which knowledge
conflicts emerge in LMs is the integration of inconsistent information flows by
memory heads and context heads. Inspired by the insights, we propose a novel
method called Pruning Head via PatH PatcHing (PH3), which can efficiently
mitigate knowledge conflicts by pruning conflicting attention heads without
updating model parameters. PH3 can flexibly control eight LMs to use internal
memory ($\uparrow$ 44.0%) or external context ($\uparrow$ 38.5%). Moreover, PH3
can also improve the performance of LMs on open-domain QA tasks. We also
conduct extensive experiments to demonstrate the cross-model, cross-relation,
and cross-format generalization of our method.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18157" title="Abstract">arXiv:2402.18157</a> [<a href="/pdf/2402.18157" title="Download PDF">pdf</a>, <a href="/format/2402.18157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Summary to Action: Enhancing Large Language Models for Complex  Tasks with Open World APIs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yulong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yunlong Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chunwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jianhua Han</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yongqiang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+N">Nanning Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The distinction between humans and animals lies in the unique ability of
humans to use and create tools. Tools empower humans to overcome physiological
limitations, fostering the creation of magnificent civilizations. Similarly,
enabling foundational models like Large Language Models (LLMs) with the
capacity to learn external tool usage may serve as a pivotal step toward
realizing artificial general intelligence. Previous studies in this field have
predominantly pursued two distinct approaches to augment the tool invocation
capabilities of LLMs. The first approach emphasizes the construction of
relevant datasets for model fine-tuning. The second approach, in contrast, aims
to fully exploit the inherent reasoning abilities of LLMs through in-context
learning strategies. In this work, we introduce a novel tool invocation
pipeline designed to control massive real-world APIs. This pipeline mirrors the
human task-solving process, addressing complicated real-life user queries. At
each step, we guide LLMs to summarize the achieved results and determine the
next course of action. We term this pipeline `from Summary to action', Sum2Act
for short. Empirical evaluations of our Sum2Act pipeline on the ToolBench
benchmark show significant performance improvements, outperforming established
methods like ReAct and DFSDT. This highlights Sum2Act's effectiveness in
enhancing LLMs for complex real-world tasks.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18158" title="Abstract">arXiv:2402.18158</a> [<a href="/pdf/2402.18158" title="Download PDF">pdf</a>, <a href="/format/2402.18158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Quantized Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shiyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+X">Xuefei Ning</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Luning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tengxuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xiangsheng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shengen Yan</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+G">Guohao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Huazhong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Post-training quantization (PTQ) has emerged as a promising technique to
reduce the cost of large language models (LLMs). Specifically, PTQ can
effectively mitigate memory consumption and reduce computational overhead in
LLMs. To meet the requirements of both high efficiency and performance across
diverse scenarios, a comprehensive evaluation of quantized LLMs is essential to
guide the selection of quantization methods. This paper presents a thorough
evaluation of these factors by evaluating the effect of PTQ on Weight,
Activation, and KV Cache on 11 model families, including OPT, LLaMA2, Falcon,
Bloomz, Mistral, ChatGLM, Vicuna, LongChat, StableLM, Gemma, and Mamba, with
parameters ranging from 125M to 180B. The evaluation encompasses five types of
tasks: basic NLP, emergent ability, trustworthiness, dialogue, and long-context
tasks. Moreover, we also evaluate the state-of-the-art (SOTA) quantization
methods to demonstrate their applicability. Based on the extensive experiments,
we systematically summarize the effect of quantization, provide recommendations
to apply quantization techniques, and point out future directions.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18159" title="Abstract">arXiv:2402.18159</a> [<a href="/pdf/2402.18159" title="Download PDF">pdf</a>, <a href="/format/2402.18159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provable Risk-Sensitive Distributional Reinforcement Learning with  General Function Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangcheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Longbo Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In the realm of reinforcement learning (RL), accounting for risk is crucial
for making decisions under uncertainty, particularly in applications where
safety and reliability are paramount. In this paper, we introduce a general
framework on Risk-Sensitive Distributional Reinforcement Learning (RS-DisRL),
with static Lipschitz Risk Measures (LRM) and general function approximation.
Our framework covers a broad class of risk-sensitive RL, and facilitates
analysis of the impact of estimation functions on the effectiveness of RSRL
strategies and evaluation of their sample complexity. We design two innovative
meta-algorithms: \texttt{RS-DisRL-M}, a model-based strategy for model-based
function approximation, and \texttt{RS-DisRL-V}, a model-free approach for
general value function approximation. With our novel estimation techniques via
Least Squares Regression (LSR) and Maximum Likelihood Estimation (MLE) in
distributional RL with augmented Markov Decision Process (MDP), we derive the
first $\widetilde{\mathcal{O}}(\sqrt{K})$ dependency of the regret upper bound
for RSRL with static LRM, marking a pioneering contribution towards
statistically efficient algorithms in this domain.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18162" title="Abstract">arXiv:2402.18162</a> [<a href="/pdf/2402.18162" title="Download PDF">pdf</a>, <a href="/format/2402.18162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Out-of-Distribution Detection using Neural Activation Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+W">Weilin Wan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weizhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Cheng Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Out-of-distribution detection is a crucial technique for deploying machine
learning models in the real world to handle the unseen scenarios.In this paper,
we propose a simple but effective Neural Activation Prior (NAP) for
out-of-distribution detection (OOD). Our neural activation prior is based on a
key observation that, for a channel before the global pooling layer of a fully
trained neural network, the probability of a few of its neurons being activated
with a larger response by an in-distribution (ID) sample is significantly
higher than that by an OOD sample. An intuitive explanation is each channel in
a model fully trained on ID dataset would play a role in detecting a certain
pattern in the samples within the ID dataset, and a few neurons can be
activated with a large response when the pattern is detected in an input
sample. Thus, a new scoring function based on this prior is proposed to
highlight the role of these strongly activated neurons in OOD detection. This
approach is plug-and-play and does not lead to any performance degradation on
in-distribution data classification and requires no extra training or
statistics from training or external datasets. Notice that previous methods
primarily rely on post-global-pooling features of the neural networks, while
the within-channel distribution information we leverage would be discarded by
the global pooling operator. Consequently, our method is orthogonal to existing
approaches and can be effectively combined with them in various applications.
Experimental results show that our method achieves the state-of-the-art
performance on CIFAR-10, CIFAR-100 and ImageNet datasets, which demonstrates
the power of the proposed prior.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18163" title="Abstract">arXiv:2402.18163</a> [<a href="/pdf/2402.18163" title="Download PDF">pdf</a>, <a href="/format/2402.18163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ef-QuantFace: Streamlined Face Recognition with Small Data and Low-Bit  Precision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gazali%2C+W">William Gazali</a>, 
<a href="/search/cs?searchtype=author&query=Kho%2C+J+M">Jocelyn Michelle Kho</a>, 
<a href="/search/cs?searchtype=author&query=Santoso%2C+J">Joshua Santoso</a>, 
<a href="/search/cs?searchtype=author&query=Williem">Williem</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, model quantization for face recognition has gained
prominence. Traditionally, compressing models involved vast datasets like the
5.8 million-image MS1M dataset as well as extensive training times, raising the
question of whether such data enormity is essential. This paper addresses this
by introducing an efficiency-driven approach, fine-tuning the model with just
up to 14,000 images, 440 times smaller than MS1M. We demonstrate that effective
quantization is achievable with a smaller dataset, presenting a new paradigm.
Moreover, we incorporate an evaluation-based metric loss and achieve an
outstanding 96.15% accuracy on the IJB-C dataset, establishing a new
state-of-the-art compressed model training for face recognition. The subsequent
analysis delves into potential applications, emphasizing the transformative
power of this approach. This paper advances model quantization by highlighting
the efficiency and optimal results with small data and training time.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18164" title="Abstract">arXiv:2402.18164</a> [<a href="/pdf/2402.18164" title="Download PDF">pdf</a>, <a href="/format/2402.18164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autoencoder-based General Purpose Representation Learning for Customer  Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bertrand%2C+J+H">Jan Henrik Bertrand</a>, 
<a href="/search/cs?searchtype=author&query=Gargano%2C+J+P">Jacopo Pio Gargano</a>, 
<a href="/search/cs?searchtype=author&query=Mombaerts%2C+L">Laurent Mombaerts</a>, 
<a href="/search/cs?searchtype=author&query=Taws%2C+J">Jonathan Taws</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In recent years, exploiting the domain-specific underlying structure of data
and its generative factors for representation learning has shown success in
various use-case agnostic applications. However, the diversity and complexity
of tabular data have made it challenging to represent these structures in a
latent space through multi-dimensional vectors. We design an autoencoder-based
framework for building general purpose embeddings, we assess the performance of
different autoencoder architectures, and show simpler models outperform complex
ones in embedding highly complex tabular data. We apply our framework to
produce plug-and-play, rich, and anonymized embeddings representing AWS
customers for usage in any model, saving up to 45% of development time, and
observe significant improvements in downstream models. Moreover, we propose a
significant improvement to the calculation of reconstruction loss for
multi-layer contractive autoencoders (CAE) by calculating the Jacobian of the
entire encoder leading to a 15% improvement in reconstruction quality when
compared to a stacked CAE.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18166" title="Abstract">arXiv:2402.18166</a> [<a href="/pdf/2402.18166" title="Download PDF">pdf</a>, <a href="/format/2402.18166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sequence-level Semantic Representation Fusion for Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lanling Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhen Tian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bingqian Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+M">Mingchen Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W+X">Wayne Xin Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">With the rapid development of recommender systems, there is increasing side
information that can be employed to improve the recommendation performance.
Specially, we focus on the utilization of the associated \emph{textual data} of
items (eg product title) and study how text features can be effectively fused
with ID features in sequential recommendation. However, there exists distinct
data characteristics for the two kinds of item features, making a direct fusion
method (eg adding text and ID embeddings as item representation) become less
effective. To address this issue, we propose a novel {\ul \emph{Te}}xt-I{\ul
\emph{D}} semantic fusion approach for sequential {\ul \emph{Rec}}ommendation,
namely \textbf{\our}. The core idea of our approach is to conduct a
sequence-level semantic fusion approach by better integrating global contexts.
The key strategy lies in that we transform the text embeddings and ID
embeddings by Fourier Transform from \emph{time domain} to \emph{frequency
domain}. In the frequency domain, the global sequential characteristics of the
original sequences are inherently aggregated into the transformed
representations, so that we can employ simple multiplicative operations to
effectively fuse the two kinds of item features. Our fusion approach can be
proved to have the same effects of contextual convolution, so as to achieving
sequence-level semantic fusion. In order to further improve the fusion
performance, we propose to enhance the discriminability of the text embeddings
from the text encoder, by adaptively injecting positional information via a
mixture-of-experts~(MoE) modulation method. Our implementation is available at
this repository: \textcolor{magenta}{\url{https://github.com/RUCAIBox/TedRec}}.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18167" title="Abstract">arXiv:2402.18167</a> [<a href="/pdf/2402.18167" title="Download PDF">pdf</a>, <a href="/format/2402.18167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralised Traffic Incident Detection via Network Lasso
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qiyuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+A+K">A. K. Qin</a>, 
<a href="/search/cs?searchtype=author&query=Abeysekara%2C+P">Prabath Abeysekara</a>, 
<a href="/search/cs?searchtype=author&query=Dia%2C+H">Hussein Dia</a>, 
<a href="/search/cs?searchtype=author&query=Grzybowska%2C+H">Hanna Grzybowska</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Traffic incident detection plays a key role in intelligent transportation
systems, which has gained great attention in transport engineering. In the
past, traditional machine learning (ML) based detection methods achieved good
performance under a centralised computing paradigm, where all data are
transmitted to a central server for building ML models therein. Nowadays, deep
neural networks based federated learning (FL) has become a mainstream detection
approach to enable the model training in a decentralised manner while
warranting local data governance. Such neural networks-centred techniques,
however, have overshadowed the utility of well-established ML-based detection
methods. In this work, we aim to explore the potential of potent conventional
ML-based detection models in modern traffic scenarios featured by distributed
data. We leverage an elegant but less explored distributed optimisation
framework named Network Lasso, with guaranteed global convergence for convex
problem formulations, integrate the potent convex ML model with it, and compare
it with centralised learning, local learning, and federated learning methods
atop a well-known traffic incident detection dataset. Experimental results show
that the proposed network lasso-based approach provides a promising alternative
to the FL-based approach in data-decentralised traffic scenarios, with a strong
convergence guarantee while rekindling the significance of conventional
ML-based detection methods.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18169" title="Abstract">arXiv:2402.18169</a> [<a href="/pdf/2402.18169" title="Download PDF">pdf</a>, <a href="/ps/2402.18169" title="Download PostScript">ps</a>, <a href="/format/2402.18169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MIKO: Multimodal Intention Knowledge Distillation from Large Language  Models for Social-Media Commonsense Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+F">Feihong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yangyifei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Ziqin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qingyun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Baixuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Haochen Shi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shiqi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qian Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yangqiu Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianxin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Social media has become a ubiquitous tool for connecting with others, staying
updated with news, expressing opinions, and finding entertainment. However,
understanding the intention behind social media posts remains challenging due
to the implicitness of intentions in social media posts, the need for
cross-modality understanding of both text and images, and the presence of noisy
information such as hashtags, misspelled words, and complicated abbreviations.
To address these challenges, we present MIKO, a Multimodal Intention Kowledge
DistillatiOn framework that collaboratively leverages a Large Language Model
(LLM) and a Multimodal Large Language Model (MLLM) to uncover users'
intentions. Specifically, we use an MLLM to interpret the image and an LLM to
extract key information from the text and finally instruct the LLM again to
generate intentions. By applying MIKO to publicly available social media
datasets, we construct an intention knowledge base featuring 1,372K intentions
rooted in 137,287 posts. We conduct a two-stage annotation to verify the
quality of the generated knowledge and benchmark the performance of widely used
LLMs for intention generation. We further apply MIKO to a sarcasm detection
dataset and distill a student model to demonstrate the downstream benefits of
applying intention knowledge.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18171" title="Abstract">arXiv:2402.18171</a> [<a href="/pdf/2402.18171" title="Download PDF">pdf</a>, <a href="/format/2402.18171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digging Into Normal Incorporated Stereo Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zihua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Songyan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhicheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Okutomi%2C+M">Masatoshi Okutomi</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 30th ACM International Conference on Multimedia
  (ACMMM2022), pp.6050-6060, October 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite the remarkable progress facilitated by learning-based stereo-matching
algorithms, disparity estimation in low-texture, occluded, and bordered regions
still remains a bottleneck that limits the performance. To tackle these
challenges, geometric guidance like plane information is necessary as it
provides intuitive guidance about disparity consistency and affinity
similarity. In this paper, we propose a normal incorporated joint learning
framework consisting of two specific modules named non-local disparity
propagation(NDP) and affinity-aware residual learning(ARL). The estimated
normal map is first utilized for calculating a non-local affinity matrix and a
non-local offset to perform spatial propagation at the disparity level. To
enhance geometric consistency, especially in low-texture regions, the estimated
normal map is then leveraged to calculate a local affinity matrix, providing
the residual learning with information about where the correction should refer
and thus improving the residual learning efficiency. Extensive experiments on
several public datasets including Scene Flow, KITTI 2015, and Middlebury 2014
validate the effectiveness of our proposed method. By the time we finished this
work, our approach ranked 1st for stereo matching across foreground pixels on
the KITTI 2015 dataset and 3rd on the Scene Flow dataset among all the
published works.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18172" title="Abstract">arXiv:2402.18172</a> [<a href="/pdf/2402.18172" title="Download PDF">pdf</a>, <a href="/format/2402.18172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NiteDR: Nighttime Image De-Raining with Cross-View Sensor Cooperative  Learning for Dynamic Driving Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Cidan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+L">Lihuang Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Han Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+X">Xiaoyu Xian</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yukai Shi</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In real-world environments, outdoor imaging systems are often affected by
disturbances such as rain degradation. Especially, in nighttime driving scenes,
insufficient and uneven lighting shrouds the scenes in darkness, resulting
degradation of both the image quality and visibility. Particularly, in the
field of autonomous driving, the visual perception ability of RGB sensors
experiences a sharp decline in such harsh scenarios. Additionally, driving
assistance systems suffer from reduced capabilities in capturing and discerning
the surrounding environment, posing a threat to driving safety. Single-view
information captured by single-modal sensors cannot comprehensively depict the
entire scene. To address these challenges, we developed an image de-raining
framework tailored for rainy nighttime driving scenes. It aims to remove rain
artifacts, enrich scene representation, and restore useful information.
Specifically, we introduce cooperative learning between visible and infrared
images captured by different sensors. By cross-view fusion of these
multi-source data, the scene within the images gains richer texture details and
enhanced contrast. We constructed an information cleaning module called
CleanNet as the first stage of our framework. Moreover, we designed an
information fusion module called FusionNet as the second stage to fuse the
clean visible images with infrared images. Using this stage-by-stage learning
strategy, we obtain de-rained fusion images with higher quality and better
visual perception. Extensive experiments demonstrate the effectiveness of our
proposed Cross-View Cooperative Learning (CVCL) in adverse driving scenarios in
low-light rainy environments. The proposed approach addresses the gap in the
utilization of existing rain removal algorithms in specific low-light
conditions.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18174" title="Abstract">arXiv:2402.18174</a> [<a href="/pdf/2402.18174" title="Download PDF">pdf</a>, <a href="/format/2402.18174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generation of skill-specific maps from graph world models for robotic  systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Vos%2C+K">Koen de Vos</a>, 
<a href="/search/cs?searchtype=author&query=van+den+Brandt%2C+G">Gijs van den Brandt</a>, 
<a href="/search/cs?searchtype=author&query=Senden%2C+J">Jordy Senden</a>, 
<a href="/search/cs?searchtype=author&query=Pauwels%2C+P">Pieter Pauwels</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Molengraft%2C+R">Rene van de Molengraft</a>, 
<a href="/search/cs?searchtype=author&query=Torta%2C+E">Elena Torta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">With the increase in the availability of Building Information Models (BIM)
and (semi-) automatic tools to generate BIM from point clouds, we propose a
world model architecture and algorithms to allow the use of the semantic and
geometric knowledge encoded within these models to generate maps for robot
localization and navigation. When heterogeneous robots are deployed within an
environment, maps obtained from classical SLAM approaches might not be shared
between all agents within a team of robots, e.g. due to a mismatch in sensor
type, or a difference in physical robot dimensions. Our approach extracts the
3D geometry and semantic description of building elements (e.g. material,
element type, color) from BIM, and represents this knowledge in a graph. Based
on queries on the graph and knowledge of the skills of the robot, we can
generate skill-specific maps that can be used during the execution of
localization or navigation tasks. The approach is validated with data from
complex build environments and integrated into existing navigation frameworks.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18175" title="Abstract">arXiv:2402.18175</a> [<a href="/pdf/2402.18175" title="Download PDF">pdf</a>, <a href="/format/2402.18175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Spatially Variant PSF Estimation for Aberration-Aware  Depth-from-Defocus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhuofeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Monno%2C+Y">Yusuke Monno</a>, 
<a href="/search/cs?searchtype=author&query=Okutomi%2C+M">Masatoshi Okutomi</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on Acoustics, Speech, and Signal
  Processing (ICASSP), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">In this paper, we address the task of aberration-aware depth-from-defocus
(DfD), which takes account of spatially variant point spread functions (PSFs)
of a real camera. To effectively obtain the spatially variant PSFs of a real
camera without requiring any ground-truth PSFs, we propose a novel
self-supervised learning method that leverages the pair of real sharp and
blurred images, which can be easily captured by changing the aperture setting
of the camera. In our PSF estimation, we assume rotationally symmetric PSFs and
introduce the polar coordinate system to more accurately learn the PSF
estimation network. We also handle the focus breathing phenomenon that occurs
in real DfD situations. Experimental results on synthetic and real data
demonstrate the effectiveness of our method regarding both the PSF estimation
and the depth estimation.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18178" title="Abstract">arXiv:2402.18178</a> [<a href="/pdf/2402.18178" title="Download PDF">pdf</a>, <a href="/format/2402.18178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reflection Removal Using Recurrent Polarization-to-Polarization Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bian%2C+W">Wenjiao Bian</a>, 
<a href="/search/cs?searchtype=author&query=Monno%2C+Y">Yusuke Monno</a>, 
<a href="/search/cs?searchtype=author&query=Okutomi%2C+M">Masatoshi Okutomi</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper addresses reflection removal, which is the task of separating
reflection components from a captured image and deriving the image with only
transmission components. Considering that the existence of the reflection
changes the polarization state of a scene, some existing methods have exploited
polarized images for reflection removal. While these methods apply polarized
images as the inputs, they predict the reflection and the transmission directly
as non-polarized intensity images. In contrast, we propose a
polarization-to-polarization approach that applies polarized images as the
inputs and predicts "polarized" reflection and transmission images using two
sequential networks to facilitate the separation task by utilizing the
interrelated polarization information between the reflection and the
transmission. We further adopt a recurrent framework, where the predicted
reflection and transmission images are used to iteratively refine each other.
Experimental results on a public dataset demonstrate that our method
outperforms other state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18179" title="Abstract">arXiv:2402.18179</a> [<a href="/pdf/2402.18179" title="Download PDF">pdf</a>, <a href="/format/2402.18179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges in Pre-Training Graph Neural Networks for Context-Based Fake  News Detection: An Evaluation of Current Strategies and Resource Limitations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Donabauer%2C+G">Gregor Donabauer</a>, 
<a href="/search/cs?searchtype=author&query=Kruschwitz%2C+U">Udo Kruschwitz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint accepted at LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Pre-training of neural networks has recently revolutionized the field of
Natural Language Processing (NLP) and has before demonstrated its effectiveness
in computer vision. At the same time, advances around the detection of fake
news were mainly driven by the context-based paradigm, where different types of
signals (e.g. from social media) form graph-like structures that hold
contextual information apart from the news article to classify. We propose to
merge these two developments by applying pre-training of Graph Neural Networks
(GNNs) in the domain of context-based fake news detection. Our experiments
provide an evaluation of different pre-training strategies for graph-based
misinformation detection and demonstrate that transfer learning does currently
not lead to significant improvements over training a model from scratch in the
domain. We argue that a major current issue is the lack of suitable large-scale
resources that can be used for pre-training.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18180" title="Abstract">arXiv:2402.18180</a> [<a href="/pdf/2402.18180" title="Download PDF">pdf</a>, <a href="/format/2402.18180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Simulacra: A Step toward the Personification of Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Qiuejie Xie</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Q">Qiming Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qingqiu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuejie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+R">Rui Feng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shang Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Large language models (LLMs) are recognized as systems that closely mimic
aspects of human intelligence. This capability has attracted attention from the
social science community, who see the potential in leveraging LLMs to replace
human participants in experiments, thereby reducing research costs and
complexity. In this paper, we introduce a framework for large language models
personification, including a strategy for constructing virtual characters' life
stories from the ground up, a Multi-Agent Cognitive Mechanism capable of
simulating human cognitive processes, and a psychology-guided evaluation method
to assess human simulations from both self and observational perspectives.
Experimental results demonstrate that our constructed simulacra can produce
personified responses that align with their target characters. Our work is a
preliminary exploration which offers great potential in practical applications.
All the code and datasets will be released, with the hope of inspiring further
investigations.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18181" title="Abstract">arXiv:2402.18181</a> [<a href="/pdf/2402.18181" title="Download PDF">pdf</a>, <a href="/format/2402.18181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CFDNet: A Generalizable Foggy Stereo Matching Network with Contrastive  Feature Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zihua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yizhou Li</a>, 
<a href="/search/cs?searchtype=author&query=Okutomi%2C+M">Masatoshi Okutomi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Stereo matching under foggy scenes remains a challenging task since the
scattering effect degrades the visibility and results in less distinctive
features for dense correspondence matching. While some previous learning-based
methods integrated a physical scattering function for simultaneous
stereo-matching and dehazing, simply removing fog might not aid depth
estimation because the fog itself can provide crucial depth cues. In this work,
we introduce a framework based on contrastive feature distillation (CFD). This
strategy combines feature distillation from merged clean-fog features with
contrastive learning, ensuring balanced dependence on fog depth hints and clean
matching features. This framework helps to enhance model generalization across
both clean and foggy environments. Comprehensive experiments on synthetic and
real-world datasets affirm the superior strength and adaptability of our
method.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18182" title="Abstract">arXiv:2402.18182</a> [<a href="/pdf/2402.18182" title="Download PDF">pdf</a>, <a href="/ps/2402.18182" title="Download PostScript">ps</a>, <a href="/format/2402.18182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Handling Open Research Data within the Max Planck Society -- Looking  Closer at the Year 2020
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boosen%2C+M">Martin Boosen</a>, 
<a href="/search/cs?searchtype=author&query=Franke%2C+M">Michael Franke</a>, 
<a href="/search/cs?searchtype=author&query=Grossmann%2C+Y+V">Yves Vincent Grossmann</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+S+D">Sy Dat Ho</a>, 
<a href="/search/cs?searchtype=author&query=Leiminger%2C+L">Larissa Leiminger</a>, 
<a href="/search/cs?searchtype=author&query=Matthiesen%2C+J">Jan Matthiesen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">This paper analyses the practice of publishing research data within the Max
Planck Society in the year 2020. The central finding of the study is that up to
40\% of the empirical text publications had research data available. The
aggregation of the available data is predominantly analysed. There are
differences between the sections of the Max Planck Society but they are not as
great as one might expect. In the case of the journals, it is also apparent
that a data policy can increase the availability of data related to textual
publications. Finally, we found that the statement on data availability "upon
(reasonable) request" does not work.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18189" title="Abstract">arXiv:2402.18189</a> [<a href="/pdf/2402.18189" title="Download PDF">pdf</a>, <a href="/format/2402.18189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VulMCI : Code Splicing-based Pixel-row Oversampling for More Continuous  Vulnerability Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+T">Tao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+L">Ling Gui</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yi Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In recent years, the rapid development of deep learning technology has
brought new prospects to the field of vulnerability detection. Many
vulnerability detection methods involve converting source code into images for
detection, yet they often overlook the quality of the generated images. Due to
the fact that vulnerability images lack clear and continuous contours, unlike
images used in object detection, Convolutional Neural Networks (CNNs) tend to
lose semantic information during the convolution and pooling processes.
Therefore, this paper proposes a pixel row oversampling method based on code
line concatenation to generate more continuous code features, addressing the
issue of discontinuity in code image coloration.Building upon these
contributions, we propose the vulnerability detection system VulMCI and conduct
tests on the SARD and NVD datasets. Experimental results demonstrate that
VulMCI outperforms seven state-of-the-art vulnerability detectors (namely
Checkmarx, FlawFinder, RATS, VulDeePecker, SySeVR, VulCNN, and Devign).
Compared to other image-based methods, VulMCI shows improvements in various
metrics, including a 2.877\% increase in True Positive Rate (TPR), a 5.446\%
increase in True Negative Rate (TNR), and a 5.91\% increase in Accuracy (ACC).
On the NVD real-world dataset, VulMCI achieves an average accuracy of 5.162\%,
confirming its value in practical vulnerability detection applications.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18191" title="Abstract">arXiv:2402.18191</a> [<a href="/pdf/2402.18191" title="Download PDF">pdf</a>, <a href="/format/2402.18191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clustering and Ranking: Diversity-preserved Instruction Selection  through Expert-aligned Quality Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yuan Ge</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yilun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+W">Weibin Meng</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+S">Shimin Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiaofeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Hongxia Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Tong Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With contributions from the open-source community, a vast amount of
instruction tuning (IT) data has emerged. Given the significant resource
allocation required by training and evaluating models, it is advantageous to
have an efficient method for selecting high-quality IT data. However, existing
methods for instruction data selection have limitations such as relying on
fragile external APIs, being affected by biases in GPT models, or reducing the
diversity of the selected instruction dataset. In this paper, we propose an
industrial-friendly, expert-aligned and diversity-preserved instruction data
selection method: Clustering and Ranking (CaR). CaR consists of two steps. The
first step involves ranking instruction pairs using a scoring model that is
well aligned with expert preferences (achieving an accuracy of 84.25%). The
second step involves preserving dataset diversity through a clustering
process.In our experiment, CaR selected a subset containing only 1.96% of
Alpaca's IT data, yet the underlying AlpaCaR model trained on this subset
outperforms Alpaca by an average of 32.1% in GPT-4 evaluations. Furthermore,
our method utilizes small models (355M parameters) and requires only 11.2% of
the monetary cost compared to existing methods, making it easily deployable in
industrial scenarios.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18192" title="Abstract">arXiv:2402.18192</a> [<a href="/pdf/2402.18192" title="Download PDF">pdf</a>, <a href="/format/2402.18192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Misalignment-Robust Frequency Distribution Loss for Image Transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+Z">Zhangkai Ni</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Juncheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenhan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanli Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lin Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Computer Vision and Pattern Recognition Conference (CVPR) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">This paper aims to address a common challenge in deep learning-based image
transformation methods, such as image enhancement and super-resolution, which
heavily rely on precisely aligned paired datasets with pixel-level alignments.
However, creating precisely aligned paired images presents significant
challenges and hinders the advancement of methods trained on such data. To
overcome this challenge, this paper introduces a novel and simple Frequency
Distribution Loss (FDL) for computing distribution distance within the
frequency domain. Specifically, we transform image features into the frequency
domain using Discrete Fourier Transformation (DFT). Subsequently, frequency
components (amplitude and phase) are processed separately to form the FDL loss
function. Our method is empirically proven effective as a training constraint
due to the thoughtful utilization of global information in the frequency
domain. Extensive experimental evaluations, focusing on image enhancement and
super-resolution tasks, demonstrate that FDL outperforms existing
misalignment-robust loss functions. Furthermore, we explore the potential of
our FDL for image style transfer that relies solely on completely misaligned
data. Our code is available at: https://github.com/eezkni/FDL
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18194" title="Abstract">arXiv:2402.18194</a> [<a href="/pdf/2402.18194" title="Download PDF">pdf</a>, <a href="/ps/2402.18194" title="Download PostScript">ps</a>, <a href="/format/2402.18194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formalized Identification Of Key Factors In Safety-Relevant Failure  Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Julitz%2C+T+M">Tim Maurice Julitz</a>, 
<a href="/search/cs?searchtype=author&query=Schl%C3%BCter%2C+N">Nadine Schl&#xfc;ter</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B6wer%2C+M">Manuel L&#xf6;wer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This research article presents a methodical data-based approach to
systematically identify key factors in safety-related failure scenarios, with a
focus on complex product-environmental systems in the era of Industry 4.0. The
study addresses the uncertainty arising from the growing complexity of modern
products. The method uses scenario analysis and focuses on failure analysis
within technical product development. The approach involves a derivation of
influencing factors based on information from failure databases. The failures
described here are documented individually in failure sequence diagrams and
then related to each other in a relationship matrix. This creates a network of
possible failure scenarios from individual failure cases that can be used in
product development. To illustrate the application of the methodology, a case
study of 41 Rapex safety alerts for a hair dryer is presented. The failure
sequence diagrams and influencing factor relationship matrices show 46
influencing factors that lead to safety-related failures. The predominant harm
is burns and electric shocks, which are highlighted by the active and passive
sum diagrams. The research demonstrates a robust method for identifying key
factors in safety-related failure scenarios using information from failure
databases. The methodology provides valuable insights into product development
and emphasizes the frequency of influencing factors and their
interconnectedness.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18196" title="Abstract">arXiv:2402.18196</a> [<a href="/pdf/2402.18196" title="Download PDF">pdf</a>, <a href="/format/2402.18196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NToP: NeRF-Powered Large-scale Dataset Generation for 2D and 3D Human  Pose Estimation in Top-View Fisheye Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingrui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Nandi%2C+D">Dipankar Nandi</a>, 
<a href="/search/cs?searchtype=author&query=Seidel%2C+R">Roman Seidel</a>, 
<a href="/search/cs?searchtype=author&query=Hirtz%2C+G">Gangolf Hirtz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Human pose estimation (HPE) in the top-view using fisheye cameras presents a
promising and innovative application domain. However, the availability of
datasets capturing this viewpoint is extremely limited, especially those with
high-quality 2D and 3D keypoint annotations. Addressing this gap, we leverage
the capabilities of Neural Radiance Fields (NeRF) technique to establish a
comprehensive pipeline for generating human pose datasets from existing 2D and
3D datasets, specifically tailored for the top-view fisheye perspective.
Through this pipeline, we create a novel dataset NToP570K (NeRF-powered
Top-view human Pose dataset for fisheye cameras with over 570 thousand images),
and conduct an extensive evaluation of its efficacy in enhancing neural
networks for 2D and 3D top-view human pose estimation. A pretrained ViTPose-B
model achieves an improvement in AP of 33.3 % on our validation set for 2D HPE
after finetuning on our training set. A similarly finetuned HybrIK-Transformer
model gains 53.7 mm reduction in PA-MPJPE for 3D HPE on the validation set.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18198" title="Abstract">arXiv:2402.18198</a> [<a href="/pdf/2402.18198" title="Download PDF">pdf</a>, <a href="/format/2402.18198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Machine Learning for Multi-Label Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wever%2C+M">Marcel Wever</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Automated machine learning (AutoML) aims to select and configure machine
learning algorithms and combine them into machine learning pipelines tailored
to a dataset at hand. For supervised learning tasks, most notably binary and
multinomial classification, aka single-label classification (SLC), such AutoML
approaches have shown promising results. However, the task of multi-label
classification (MLC), where data points are associated with a set of class
labels instead of a single class label, has received much less attention so
far. In the context of multi-label classification, the data-specific selection
and configuration of multi-label classifiers are challenging even for experts
in the field, as it is a high-dimensional optimization problem with multi-level
hierarchical dependencies. While for SLC, the space of machine learning
pipelines is already huge, the size of the MLC search space outnumbers the one
of SLC by several orders.
<br />In the first part of this thesis, we devise a novel AutoML approach for
single-label classification tasks optimizing pipelines of machine learning
algorithms, consisting of two algorithms at most. This approach is then
extended first to optimize pipelines of unlimited length and eventually
configure the complex hierarchical structures of multi-label classification
methods. Furthermore, we investigate how well AutoML approaches that form the
state of the art for single-label classification tasks scale with the increased
problem complexity of AutoML for multi-label classification.
<br />In the second part, we explore how methods for SLC and MLC could be
configured more flexibly to achieve better generalization performance and how
to increase the efficiency of execution-based AutoML systems.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18201" title="Abstract">arXiv:2402.18201</a> [<a href="/pdf/2402.18201" title="Download PDF">pdf</a>, <a href="/format/2402.18201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Invariant Inter-pixel Correlations for Superpixel Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Sen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Shikui Wei</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+T">Tao Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+L">Lixin Liao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep superpixel algorithms have made remarkable strides by substituting
hand-crafted features with learnable ones. Nevertheless, we observe that
existing deep superpixel methods, serving as mid-level representation
operations, remain sensitive to the statistical properties (e.g., color
distribution, high-level semantics) embedded within the training dataset.
Consequently, learnable features exhibit constrained discriminative capability,
resulting in unsatisfactory pixel grouping performance, particularly in
untrainable application scenarios. To address this issue, we propose the
Content Disentangle Superpixel (CDS) algorithm to selectively separate the
invariant inter-pixel correlations and statistical properties, i.e., style
noise. Specifically, We first construct auxiliary modalities that are
homologous to the original RGB image but have substantial stylistic variations.
Then, driven by mutual information, we propose the local-grid correlation
alignment across modalities to reduce the distribution discrepancy of
adaptively selected features and learn invariant inter-pixel correlations.
Afterwards, we perform global-style mutual information minimization to enforce
the separation of invariant content and train data styles. The experimental
results on four benchmark datasets demonstrate the superiority of our approach
to existing state-of-the-art methods, regarding boundary adherence,
generalization, and efficiency. Code and pre-trained model are available at
https://github.com/rookiie/CDSpixel.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18202" title="Abstract">arXiv:2402.18202</a> [<a href="/pdf/2402.18202" title="Download PDF">pdf</a>, <a href="/format/2402.18202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Oil Spill Drone: A Dataset of Drone-Captured, Segmented RGB Images for  Oil Spill Detection in Port Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Kerf%2C+T">T. De Kerf</a>, 
<a href="/search/cs?searchtype=author&query=Sels%2C+S">S. Sels</a>, 
<a href="/search/cs?searchtype=author&query=Samsonova%2C+S">S. Samsonova</a>, 
<a href="/search/cs?searchtype=author&query=Vanlanduit%2C+S">S. Vanlanduit</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The high incidence of oil spills in port areas poses a serious threat to the
environment, prompting the need for efficient detection mechanisms. Utilizing
automated drones for this purpose can significantly improve the speed and
accuracy of oil spill detection. Such advancements not only expedite cleanup
operations, reducing environmental harm but also enhance polluter
accountability, potentially deterring future incidents. Currently, there's a
scarcity of datasets employing RGB images for oil spill detection in maritime
settings. This paper presents a unique, annotated dataset aimed at addressing
this gap, leveraging a neural network for analysis on both desktop and edge
computing platforms. The dataset, captured via drone, comprises 1268 images
categorized into oil, water, and other, with a convolutional neural network
trained using an Unet model architecture achieving an F1 score of 0.71 for oil
detection. This underscores the dataset's practicality for real-world
applications, offering crucial resources for environmental conservation in port
environments.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18204" title="Abstract">arXiv:2402.18204</a> [<a href="/pdf/2402.18204" title="Download PDF">pdf</a>, <a href="/format/2402.18204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConvDTW-ACS: Audio Segmentation for Track Type Detection During Car  Manufacturing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez-Chilet%2C+%C3%81">&#xc1;lvaro L&#xf3;pez-Chilet</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhaoyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez%2C+J+A">Jon Ander G&#xf3;mez</a>, 
<a href="/search/cs?searchtype=author&query=Alvarez%2C+C">Carlos Alvarez</a>, 
<a href="/search/cs?searchtype=author&query=Ortiz%2C+M+A">Marivi Alonso Ortiz</a>, 
<a href="/search/cs?searchtype=author&query=Mesa%2C+A+O">Andres Orejuela Mesa</a>, 
<a href="/search/cs?searchtype=author&query=Newton%2C+D">David Newton</a>, 
<a href="/search/cs?searchtype=author&query=Wolf-Monheim%2C+F">Friedrich Wolf-Monheim</a>, 
<a href="/search/cs?searchtype=author&query=Michiels%2C+S">Sam Michiels</a>, 
<a href="/search/cs?searchtype=author&query=Hughes%2C+D">Danny Hughes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This paper proposes a method for Acoustic Constrained Segmentation (ACS) in
audio recordings of vehicles driven through a production test track, delimiting
the boundaries of surface types in the track. ACS is a variant of classical
acoustic segmentation where the sequence of labels is known, contiguous and
invariable, which is especially useful in this work as the test track has a
standard configuration of surface types. The proposed ConvDTW-ACS method
utilizes a Convolutional Neural Network for classifying overlapping image
chunks extracted from the full audio spectrogram. Then, our custom Dynamic Time
Warping algorithm aligns the sequence of predicted probabilities to the
sequence of surface types in the track, from which timestamps of the surface
type boundaries can be extracted. The method was evaluated on a real-world
dataset collected from the Ford Manufacturing Plant in Valencia (Spain),
achieving a mean error of 166 milliseconds when delimiting, within the audio,
the boundaries of the surfaces in the track. The results demonstrate the
effectiveness of the proposed method in accurately segmenting different surface
types, which could enable the development of more specialized AI systems to
improve the quality inspection process.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18205" title="Abstract">arXiv:2402.18205</a> [<a href="/pdf/2402.18205" title="Download PDF">pdf</a>, <a href="/format/2402.18205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lemur: Log Parsing with Entropy Sampling and Chain-of-Thought Merging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hongcheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+A">Anjie Le</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhoujun Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tieqiao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zang%2C+R">Runqiang Zang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Liangfan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Logs produced by extensive software systems are integral to monitoring system
behaviors. Advanced log analysis facilitates the detection, alerting, and
diagnosis of system faults. Log parsing, which entails transforming raw log
messages into structured templates, constitutes a critical phase in the
automation of log analytics. Existing log parsers fail to identify the correct
templates due to reliance on human-made rules. Besides, These methods focus on
statistical features while ignoring semantic information in log messages. To
address these challenges, we introduce a cutting-edge \textbf{L}og parsing
framework with \textbf{E}ntropy sampling and Chain-of-Thought \textbf{M}erging
(Lemur). Specifically, to discard the tedious manual rules. We propose a novel
sampling method inspired by information entropy, which efficiently clusters
typical logs. Furthermore, to enhance the merging of log templates, we design a
chain-of-thought method for large language models (LLMs). LLMs exhibit
exceptional semantic comprehension, deftly distinguishing between parameters
and invariant tokens. We have conducted experiments on large-scale public
datasets. Extensive evaluation demonstrates that Lemur achieves the
state-of-the-art performance and impressive efficiency.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18206" title="Abstract">arXiv:2402.18206</a> [<a href="/pdf/2402.18206" title="Download PDF">pdf</a>, <a href="/format/2402.18206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balancing Act: Distribution-Guided Debiasing in Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parihar%2C+R">Rishubh Parihar</a>, 
<a href="/search/cs?searchtype=author&query=Bhat%2C+A">Abhijnya Bhat</a>, 
<a href="/search/cs?searchtype=author&query=Mallick%2C+S">Saswat Mallick</a>, 
<a href="/search/cs?searchtype=author&query=Basu%2C+A">Abhipsa Basu</a>, 
<a href="/search/cs?searchtype=author&query=Kundu%2C+J+N">Jogendra Nath Kundu</a>, 
<a href="/search/cs?searchtype=author&query=Babu%2C+R+V">R. Venkatesh Babu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024. Project Page : <a href="https://ab-34.github.io/balancing_act/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion Models (DMs) have emerged as powerful generative models with
unprecedented image generation capability. These models are widely used for
data augmentation and creative applications. However, DMs reflect the biases
present in the training datasets. This is especially concerning in the context
of faces, where the DM prefers one demographic subgroup vs others (eg. female
vs male). In this work, we present a method for debiasing DMs without relying
on additional data or model retraining. Specifically, we propose Distribution
Guidance, which enforces the generated images to follow the prescribed
attribute distribution. To realize this, we build on the key insight that the
latent features of denoising UNet hold rich demographic semantics, and the same
can be leveraged to guide debiased generation. We train Attribute Distribution
Predictor (ADP) - a small mlp that maps the latent features to the distribution
of attributes. ADP is trained with pseudo labels generated from existing
attribute classifiers. The proposed Distribution Guidance with ADP enables us
to do fair generation. Our method reduces bias across single/multiple
attributes and outperforms the baseline by a significant margin for
unconditional and text-conditional diffusion models. Further, we present a
downstream task of training a fair attribute classifier by rebalancing the
training set with our generated data.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18208" title="Abstract">arXiv:2402.18208</a> [<a href="/pdf/2402.18208" title="Download PDF">pdf</a>, <a href="/format/2402.18208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shorts on the Rise: Assessing the Effects of YouTube Shorts on Long-Form  Video Content
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajendran%2C+P+T">Prajit T. Rajendran</a>, 
<a href="/search/cs?searchtype=author&query=Creusy%2C+K">Kevin Creusy</a>, 
<a href="/search/cs?searchtype=author&query=Garnes%2C+V">Vivien Garnes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Short form content has permeated into the video creator space over the past
few years, led by industry leading products such as TikTok, YouTube Shorts and
Instagram Reels. YouTube in particular was previously synonymous with being the
main hub for long form video content consumption. The monetization of long form
videos was easier as it allowed multiple advertisement placements during the
course of the video. This model also facilitated thematic brand partnerships.
However, since the introduction of short form content, creators have found it
more difficult to generate revenue as advertisement placements have decreased.
This leads to a unique situation where people are spending more time watching
shorter videos, and yet they generate less revenue for the creators. In this
paper, we perform a study of 250 creators with significant audiences to see if
the introduction of short form content has affected the view counts and
engagement of long form content. Our findings reveal a noteworthy trend: since
the advent of short-form content, there has been a significant decrease in both
view counts and engagement in long-form videos on these channels.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18209" title="Abstract">arXiv:2402.18209</a> [<a href="/pdf/2402.18209" title="Download PDF">pdf</a>, <a href="/format/2402.18209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DANSK and DaCy 2.6.0: Domain Generalization of Danish Named Entity  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Enevoldsen%2C+K">Kenneth Enevoldsen</a>, 
<a href="/search/cs?searchtype=author&query=Jessen%2C+E+T">Emil Trenckner Jessen</a>, 
<a href="/search/cs?searchtype=author&query=Baglini%2C+R">Rebekah Baglini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Named entity recognition is one of the cornerstones of Danish NLP, essential
for language technology applications within both industry and research.
However, Danish NER is inhibited by a lack of available datasets. As a
consequence, no current models are capable of fine-grained named entity
recognition, nor have they been evaluated for potential generalizability issues
across datasets and domains. To alleviate these limitations, this paper
introduces: 1) DANSK: a named entity dataset providing for high-granularity
tagging as well as within-domain evaluation of models across a diverse set of
domains; 2) DaCy 2.6.0 that includes three generalizable models with
fine-grained annotation; and 3) an evaluation of current state-of-the-art
models' ability to generalize across domains. The evaluation of existing and
new models revealed notable performance discrepancies across domains, which
should be addressed within the field. Shortcomings of the annotation quality of
the dataset and its impact on model training and evaluation are also discussed.
Despite these limitations, we advocate for the use of the new dataset DANSK
alongside further work on the generalizability within Danish NER.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18211" title="Abstract">arXiv:2402.18211</a> [<a href="/pdf/2402.18211" title="Download PDF">pdf</a>, <a href="/format/2402.18211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Catastrophic Overfitting: A Potential Blessing in Disguise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Mengnan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lihe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Y">Yuqiu Kong</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+B">Baocai Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Fast Adversarial Training (FAT) has gained increasing attention within the
research community owing to its efficacy in improving adversarial robustness.
Particularly noteworthy is the challenge posed by catastrophic overfitting (CO)
in this field. Although existing FAT approaches have made strides in mitigating
CO, the ascent of adversarial robustness occurs with a non-negligible decline
in classification accuracy on clean samples. To tackle this issue, we initially
employ the feature activation differences between clean and adversarial
examples to analyze the underlying causes of CO. Intriguingly, our findings
reveal that CO can be attributed to the feature coverage induced by a few
specific pathways. By intentionally manipulating feature activation differences
in these pathways with well-designed regularization terms, we can effectively
mitigate and induce CO, providing further evidence for this observation.
Notably, models trained stably with these terms exhibit superior performance
compared to prior FAT work. On this basis, we harness CO to achieve `attack
obfuscation', aiming to bolster model performance. Consequently, the models
suffering from CO can attain optimal classification accuracy on both clean and
adversarial data when adding random noise to inputs during evaluation. We also
validate their robustness against transferred adversarial examples and the
necessity of inducing CO to improve robustness. Hence, CO may not be a problem
that has to be solved.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18213" title="Abstract">arXiv:2402.18213</a> [<a href="/pdf/2402.18213" title="Download PDF">pdf</a>, <a href="/format/2402.18213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-objective Differentiable Neural Architecture Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sukthanker%2C+R+S">Rhea Sanjay Sukthanker</a>, 
<a href="/search/cs?searchtype=author&query=Zela%2C+A">Arber Zela</a>, 
<a href="/search/cs?searchtype=author&query=Staffler%2C+B">Benedikt Staffler</a>, 
<a href="/search/cs?searchtype=author&query=Dooley%2C+S">Samuel Dooley</a>, 
<a href="/search/cs?searchtype=author&query=Grabocka%2C+J">Josif Grabocka</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+F">Frank Hutter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 22 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
<p class="mathjax">Pareto front profiling in multi-objective optimization (MOO), i.e. finding a
diverse set of Pareto optimal solutions, is challenging, especially with
expensive objectives like neural network training. Typically, in MOO neural
architecture search (NAS), we aim to balance performance and hardware metrics
across devices. Prior NAS approaches simplify this task by incorporating
hardware constraints into the objective function, but profiling the Pareto
front necessitates a search for each constraint. In this work, we propose a
novel NAS algorithm that encodes user preferences for the trade-off between
performance and hardware metrics, and yields representative and diverse
architectures across multiple devices in just one search run. To this end, we
parameterize the joint architectural distribution across devices and multiple
objectives via a hypernetwork that can be conditioned on hardware features and
preference vectors, enabling zero-shot transferability to new devices.
Extensive experiments with up to 19 hardware devices and 3 objectives showcase
the effectiveness and scalability of our method. Finally, we show that, without
additional costs, our method outperforms existing MOO NAS methods across
qualitatively different search spaces and datasets, including MobileNetV3 on
ImageNet-1k and a Transformer space on machine translation.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18216" title="Abstract">arXiv:2402.18216</a> [<a href="/pdf/2402.18216" title="Download PDF">pdf</a>, <a href="/format/2402.18216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM Task Interference: An Initial Study on the Impact of Task-Switch in  Conversational History
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Akash Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Sheth%2C+I">Ivaxi Sheth</a>, 
<a href="/search/cs?searchtype=author&query=Raina%2C+V">Vyas Raina</a>, 
<a href="/search/cs?searchtype=author&query=Gales%2C+M">Mark Gales</a>, 
<a href="/search/cs?searchtype=author&query=Fritz%2C+M">Mario Fritz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 11 figures, 10 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the recent emergence of powerful instruction-tuned large language models
(LLMs), various helpful conversational Artificial Intelligence (AI) systems
have been deployed across many applications. When prompted by users, these AI
systems successfully perform a wide range of tasks as part of a conversation.
To provide some sort of memory and context, such approaches typically condition
their output on the entire conversational history. Although this sensitivity to
the conversational history can often lead to improved performance on subsequent
tasks, we find that performance can in fact also be negatively impacted, if
there is a task-switch. To the best of our knowledge, our work makes the first
attempt to formalize the study of such vulnerabilities and interference of
tasks in conversational LLMs caused by task-switches in the conversational
history. Our experiments across 5 datasets with 15 task switches using popular
LLMs reveal that many of the task-switches can lead to significant performance
degradation.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18217" title="Abstract">arXiv:2402.18217</a> [<a href="/pdf/2402.18217" title="Download PDF">pdf</a>, <a href="/format/2402.18217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Region-Aware Exposure Consistency Network for Mixed Exposure Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Huiyuan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chuanming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Huadong Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Exposure correction aims to enhance images suffering from improper exposure
to achieve satisfactory visual effects. Despite recent progress, existing
methods generally mitigate either overexposure or underexposure in input
images, and they still struggle to handle images with mixed exposure, i.e., one
image incorporates both overexposed and underexposed regions. The mixed
exposure distribution is non-uniform and leads to varying representation, which
makes it challenging to address in a unified process. In this paper, we
introduce an effective Region-aware Exposure Correction Network (RECNet) that
can handle mixed exposure by adaptively learning and bridging different
regional exposure representations. Specifically, to address the challenge posed
by mixed exposure disparities, we develop a region-aware de-exposure module
that effectively translates regional features of mixed exposure scenarios into
an exposure-invariant feature space. Simultaneously, as de-exposure operation
inevitably reduces discriminative information, we introduce a mixed-scale
restoration unit that integrates exposure-invariant features and unprocessed
features to recover local information. To further achieve a uniform exposure
distribution in the global image, we propose an exposure contrastive
regularization strategy under the constraints of intra-regional exposure
consistency and inter-regional exposure continuity. Extensive experiments are
conducted on various datasets, and the experimental results demonstrate the
superiority and generalization of our proposed method. The code is released at:
https://github.com/kravrolens/RECNet.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18222" title="Abstract">arXiv:2402.18222</a> [<a href="/pdf/2402.18222" title="Download PDF">pdf</a>, <a href="/format/2402.18222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HearHere: Mitigating Echo Chambers in News Consumption through an  AI-based Web System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeon%2C+Y">Youngseung Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jaehoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sohyun Park</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+Y">Yunyong Ko</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+S">Seongeun Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sang-Wook Kim</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kyungsik Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 6 figures, 6 tables, CSCW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Considerable efforts are currently underway to mitigate the negative impacts
of echo chambers, such as increased susceptibility to fake news and resistance
towards accepting scientific evidence. Prior research has presented the
development of computer systems that support the consumption of news
information from diverse political perspectives to mitigate the echo chamber
effect. However, existing studies still lack the ability to effectively support
the key processes of news information consumption and quantitatively identify a
political stance towards the information. In this paper, we present HearHere,
an AI-based web system designed to help users accommodate information and
opinions from diverse perspectives. HearHere facilitates the key processes of
news information consumption through two visualizations. Visualization 1
provides political news with quantitative political stance information, derived
from our graph-based political classification model, and users can experience
diverse perspectives (Hear). Visualization 2 allows users to express their
opinions on specific political issues in a comment form and observe the
position of their own opinions relative to pro-liberal and pro-conservative
comments presented on a map interface (Here). Through a user study with 94
participants, we demonstrate the feasibility of HearHere in supporting the
consumption of information from various perspectives. Our findings highlight
the importance of providing political stance information and quantifying users'
political status as a means to mitigate political polarization. In addition, we
propose design implications for system development, including the consideration
of demographics such as political interest and providing users with
initiatives.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18223" title="Abstract">arXiv:2402.18223</a> [<a href="/pdf/2402.18223" title="Download PDF">pdf</a>, <a href="/format/2402.18223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Open-Ended Text Generation via Adaptive Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenhong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+H">Hongkun Hao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhiwei He</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+Y">Yiming Ai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Current language models decode text token by token according to probabilistic
distribution, and determining the appropriate candidates for the next token is
crucial to ensure generation quality. This study introduces adaptive decoding,
a mechanism that empowers the language models to ascertain a sensible candidate
set during the generation process dynamically. Specifically, we introduce an
entropy-based metric called confidence and conceptualize determining the
optimal candidate set as a confidence-increasing process. The rationality of
including a token in the candidate set is assessed by leveraging the increment
of confidence, enabling the model to determine the most suitable candidate set
adaptively. The experimental results reveal that our method achieves higher
MAUVE and diversity in story generation tasks and maintains certain coherence,
underscoring its superiority over existing algorithms. The code is available at
https://github.com/zwhong714/adaptive_decoding.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18224" title="Abstract">arXiv:2402.18224</a> [<a href="/pdf/2402.18224" title="Download PDF">pdf</a>, <a href="/format/2402.18224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utilization of Reconfigurable Intelligent Surfaces with Context  Information: Use Cases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ku%C5%82acz%2C+%C5%81">&#x141;ukasz Ku&#x142;acz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 7 figures, English language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In terms of complex radio environments especially in dense urban areas, a
very interesting topic is considered - the utilization of reconfigurable
intelligent surfaces. Basically, based on simple controls of the angle of
reflection of the signal from the surface, it is possible to achieve different
effects in a radio communication system. Maximizing or minimizing the received
power at specific locations near the reflecting surface is the most important
effect. Thanks to this, it is possible to: receive a signal in a place where it
was not possible, detect spectrum occupancy in a place where the sensor could
not make a correct detection, or minimize interference in a specific receiver.
In this paper, all three concepts are presented, and, using a simple ray
tracing simulation, the potential profit in each scenario is shown. In
addition, a scenario was analyzed in which several of the aforementioned
situations are combined.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18225" title="Abstract">arXiv:2402.18225</a> [<a href="/pdf/2402.18225" title="Download PDF">pdf</a>, <a href="/format/2402.18225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CogBench: a large language model walks into a psychology lab
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coda-Forno%2C+J">Julian Coda-Forno</a>, 
<a href="/search/cs?searchtype=author&query=Binz%2C+M">Marcel Binz</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J+X">Jane X. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+E">Eric Schulz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) have significantly advanced the field of
artificial intelligence. Yet, evaluating them comprehensively remains
challenging. We argue that this is partly due to the predominant focus on
performance metrics in most benchmarks. This paper introduces CogBench, a
benchmark that includes ten behavioral metrics derived from seven cognitive
psychology experiments. This novel approach offers a toolkit for phenotyping
LLMs' behavior. We apply CogBench to 35 LLMs, yielding a rich and diverse
dataset. We analyze this data using statistical multilevel modeling techniques,
accounting for the nested dependencies among fine-tuned versions of specific
LLMs. Our study highlights the crucial role of model size and reinforcement
learning from human feedback (RLHF) in improving performance and aligning with
human behavior. Interestingly, we find that open-source models are less
risk-prone than proprietary models and that fine-tuning on code does not
necessarily enhance LLMs' behavior. Finally, we explore the effects of
prompt-engineering techniques. We discover that chain-of-thought prompting
improves probabilistic reasoning, while take-a-step-back prompting fosters
model-based behaviors.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18227" title="Abstract">arXiv:2402.18227</a> [<a href="/pdf/2402.18227" title="Download PDF">pdf</a>, <a href="/format/2402.18227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Potentials of Green Coding -- Findings and Recommendations for Industry,  Education and Science -- Extended Paper
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Junger%2C+D">Dennis Junger</a> (HTW Berlin), 
<a href="/search/cs?searchtype=author&query=Westing%2C+M">Max Westing</a> (Umwelt-Campus Birkenfeld), 
<a href="/search/cs?searchtype=author&query=Freitag%2C+C+P">Christopher P. Freitag</a> (HTW Berlin), 
<a href="/search/cs?searchtype=author&query=Guldner%2C+A">Achim Guldner</a> (Umwelt-Campus Birkenfeld), 
<a href="/search/cs?searchtype=author&query=Mittelbach%2C+K">Konstantin Mittelbach</a> (HTW Berlin), 
<a href="/search/cs?searchtype=author&query=Oberg%C3%B6ker%2C+K">Kira Oberg&#xf6;ker</a> (Umwelt-Campus Birkenfeld), 
<a href="/search/cs?searchtype=author&query=Weber%2C+S">Sebastian Weber</a> (Umwelt-Campus Birkenfeld), 
<a href="/search/cs?searchtype=author&query=Naumann%2C+S">Stefan Naumann</a> (Umwelt-Campus Birkenfeld), 
<a href="/search/cs?searchtype=author&query=Wohlgemuth%2C+V">Volker Wohlgemuth</a> (HTW Berlin)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This document is the extended version of the literature report published at the German Informatik Conference titled "Potentials of Green Coding - Findings and Recommendations for Industry, Education and Science". This document has since been updated and expanded to include relevant sources
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> INFORMATIK 2023 - Designing Futures: Zuk\"unfte gestalten pp.
  1289-1299
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Progressing digitalization and increasing demand and use of software cause
rises in energy- and resource consumption from information and communication
technologies (ICT). This raises the issue of sustainability in ICT, which
increasingly includes the sustainability of the software products themselves
and the art of creating sustainable software. To this end, we conducted an
analysis to gather and present existing literature on three research questions
relating to the production of ecologically sustainable software ("Green
Coding") and to provide orientation for stakeholders approaching the subject.
We compile the approaches to Green Coding and Green Software Engineering (GSE)
that have been published since 2010. Furthermore, we considered ways to
integrate the findings into existing industrial processes and higher education
curricula to influence future development in an environmentally friendly way.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18233" title="Abstract">arXiv:2402.18233</a> [<a href="/pdf/2402.18233" title="Download PDF">pdf</a>, <a href="/format/2402.18233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Aerial Object Detection with Visual Description Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zang%2C+Z">Zhengqing Zang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chenwei Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+J">Jiancheng Lv</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing object detection models are mainly trained on large-scale labeled
datasets. However, annotating data for novel aerial object classes is expensive
since it is time-consuming and may require expert knowledge. Thus, it is
desirable to study label-efficient object detection methods on aerial images.
In this work, we propose a zero-shot method for aerial object detection named
visual Description Regularization, or DescReg. Concretely, we identify the weak
semantic-visual correlation of the aerial objects and aim to address the
challenge with prior descriptions of their visual appearance. Instead of
directly encoding the descriptions into class embedding space which suffers
from the representation gap problem, we propose to infuse the prior inter-class
visual similarity conveyed in the descriptions into the embedding learning. The
infusion process is accomplished with a newly designed similarity-aware triplet
loss which incorporates structured regularization on the representation space.
We conduct extensive experiments with three challenging aerial object detection
datasets, including DIOR, xView, and DOTA. The results demonstrate that DescReg
significantly outperforms the state-of-the-art ZSD methods with complex
projection designs and generative frameworks, e.g., DescReg outperforms best
reported ZSD method on DIOR by 4.5 mAP on unseen classes and 8.1 in HM. We
further show the generalizability of DescReg by integrating it into generative
ZSD methods as well as varying the detection architecture.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18235" title="Abstract">arXiv:2402.18235</a> [<a href="/pdf/2402.18235" title="Download PDF">pdf</a>, <a href="/format/2402.18235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Joint Effect of Culture and Discussion Topics on X (Twitter)  Signed Ego Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tacchi%2C+J">Jack Tacchi</a>, 
<a href="/search/cs?searchtype=author&query=Boldrini%2C+C">Chiara Boldrini</a>, 
<a href="/search/cs?searchtype=author&query=Passarella%2C+A">Andrea Passarella</a>, 
<a href="/search/cs?searchtype=author&query=Conti%2C+M">Marco Conti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Funding: H2020 SoBigData++ (Grant Agreement n.871042), PNRR SoBigData.it (Prot. IR0000013), PNRR ICSC (CN00000013), PNRR FAIR (PE00000013)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Humans are known to structure social relationships according to certain
patterns, such as the Ego Network Model (ENM). These patterns result from our
innate cognitive limits and can therefore be observed in the vast majority of
large human social groups. Until recently, the main focus of research was the
structural characteristics of this model. The main aim of this paper is to
complement previous findings with systematic and data-driven analyses on the
positive and negative sentiments of social relationships, across different
cultures, communities and topics of discussion. A total of 26 datasets were
collected for this work. It was found that contrary to previous findings, the
influence of culture is not easily ``overwhelmed'' by that of the topic of
discussion. However, more specific and polarising topics do lead to noticeable
increases in negativity across all cultures. These negativities also appear to
be stable across the different levels of the ENM, which contradicts previous
hypotheses. Finally, the number of generic topics being discussed between users
seems to be a good predictor of the overall positivity of their relationships.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18236" title="Abstract">arXiv:2402.18236</a> [<a href="/pdf/2402.18236" title="Download PDF">pdf</a>, <a href="/ps/2402.18236" title="Download PostScript">ps</a>, <a href="/format/2402.18236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image2Flow: A hybrid image and graph convolutional neural network for  rapid patient-specific pulmonary artery segmentation and CFD flow field  calculation from 3D cardiac MRI data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+T">Tina Yao</a>, 
<a href="/search/cs?searchtype=author&query=Pajaziti%2C+E">Endrit Pajaziti</a>, 
<a href="/search/cs?searchtype=author&query=Quail%2C+M">Michael Quail</a>, 
<a href="/search/cs?searchtype=author&query=Schievano%2C+S">Silvia Schievano</a>, 
<a href="/search/cs?searchtype=author&query=Steeden%2C+J+A">Jennifer A Steeden</a>, 
<a href="/search/cs?searchtype=author&query=Muthurangu%2C+V">Vivek Muthurangu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 7 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Computational fluid dynamics (CFD) can be used for evaluation of
hemodynamics. However, its routine use is limited by labor-intensive manual
segmentation, CFD mesh creation, and time-consuming simulation. This study aims
to train a deep learning model to both generate patient-specific volume-meshes
of the pulmonary artery from 3D cardiac MRI data and directly estimate CFD flow
fields.
<br />This study used 135 3D cardiac MRIs from both a public and private dataset.
The pulmonary arteries in the MRIs were manually segmented and converted into
volume-meshes. CFD simulations were performed on ground truth meshes and
interpolated onto point-point correspondent meshes to create the ground truth
dataset. The dataset was split 85/10/15 for training, validation and testing.
Image2Flow, a hybrid image and graph convolutional neural network, was trained
to transform a pulmonary artery template to patient-specific anatomy and CFD
values. Image2Flow was evaluated in terms of segmentation and accuracy of CFD
predicted was assessed using node-wise comparisons. Centerline comparisons of
Image2Flow and CFD simulations performed using machine learning segmentation
were also performed.
<br />Image2Flow achieved excellent segmentation accuracy with a median Dice score
of 0.9 (IQR: 0.86-0.92). The median node-wise normalized absolute error for
pressure and velocity magnitude was 11.98% (IQR: 9.44-17.90%) and 8.06% (IQR:
7.54-10.41), respectively. Centerline analysis showed no significant difference
between the Image2Flow and conventional CFD simulated on machine
learning-generated volume-meshes.
<br />This proof-of-concept study has shown it is possible to simultaneously
perform patient specific volume-mesh based segmentation and pressure and flow
field estimation. Image2Flow completes segmentation and CFD in ~205ms, which
~7000 times faster than manual methods, making it more feasible in a clinical
environment.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18240" title="Abstract">arXiv:2402.18240</a> [<a href="/pdf/2402.18240" title="Download PDF">pdf</a>, <a href="/format/2402.18240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prospect Personalized Recommendation on Large Language Model-based Agent  Platform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jizhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+K">Keqin Bao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wentao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wanhong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fuli Feng</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The new kind of Agent-oriented information system, exemplified by GPTs, urges
us to inspect the information system infrastructure to support Agent-level
information processing and to adapt to the characteristics of Large Language
Model (LLM)-based Agents, such as interactivity. In this work, we envisage the
prospect of the recommender system on LLM-based Agent platforms and introduce a
novel recommendation paradigm called Rec4Agentverse, comprised of Agent Items
and Agent Recommender. Rec4Agentverse emphasizes the collaboration between
Agent Items and Agent Recommender, thereby promoting personalized information
services and enhancing the exchange of information beyond the traditional
user-recommender feedback loop. Additionally, we prospect the evolution of
Rec4Agentverse and conceptualize it into three stages based on the enhancement
of the interaction and information exchange among Agent Items, Agent
Recommender, and the user. A preliminary study involving several cases of
Rec4Agentverse validates its significant potential for application. Lastly, we
discuss potential issues and promising directions for future research.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18241" title="Abstract">arXiv:2402.18241</a> [<a href="/pdf/2402.18241" title="Download PDF">pdf</a>, <a href="/ps/2402.18241" title="Download PostScript">ps</a>, <a href="/format/2402.18241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Affective State Detection using fNIRs and Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+R">Ritam Ghosh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Affective states regulate our day to day to function and has a tremendous
effect on mental and physical health. Detection of affective states is of
utmost importance for mental health monitoring, smart entertainment selection
and dynamic workload management. In this paper, we discussed relevant
literature on affective state detection using physiology data, the benefits and
limitations of different sensors and methods used for collecting physiology
data, and our rationale for selecting functional near-infrared spectroscopy. We
present the design of an experiment involving nine subjects to evoke the
affective states of meditation, amusement and cognitive load and the results of
the attempt to classify using machine learning. A mean accuracy of 83.04% was
achieved in three class classification with an individual model; 84.39%
accuracy was achieved for a group model and 60.57% accuracy was achieved for
subject independent model using leave one out cross validation. It was found
that prediction accuracy for cognitive load was higher (evoked using a pen and
paper task) than the other two classes (evoked using computer bases tasks). To
verify that this discrepancy was not due to motor skills involved in the pen
and paper task, a second experiment was conducted using four participants and
the results of that experiment has also been presented in the paper.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18243" title="Abstract">arXiv:2402.18243</a> [<a href="/pdf/2402.18243" title="Download PDF">pdf</a>, <a href="/format/2402.18243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning or Self-aligning? Rethinking Instruction Fine-tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+M">Mengjie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+B">Boxi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hongyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Liu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xianpei Han</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+K">Ke Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+G">Guanglu Wan</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xunliang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Le Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Instruction Fine-tuning~(IFT) is a critical phase in building large language
models~(LLMs). Previous works mainly focus on the IFT's role in the transfer of
behavioral norms and the learning of additional world knowledge. However, the
understanding of the underlying mechanisms of IFT remains significantly
limited. In this paper, we design a knowledge intervention framework to
decouple the potential underlying factors of IFT, thereby enabling individual
analysis of different factors. Surprisingly, our experiments reveal that
attempting to learn additional world knowledge through IFT often struggles to
yield positive impacts and can even lead to markedly negative effects. Further,
we discover that maintaining internal knowledge consistency before and after
IFT is a critical factor for achieving successful IFT. Our findings reveal the
underlying mechanisms of IFT and provide robust support for some very recent
and potential future works.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18245" title="Abstract">arXiv:2402.18245</a> [<a href="/pdf/2402.18245" title="Download PDF">pdf</a>, <a href="/format/2402.18245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lower Bounds for Leaf Rank of Leaf Powers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=H%C3%B8gemo%2C+S">Svein H&#xf8;gemo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IWOCA 2024. 14 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)

</div>
<p class="mathjax">Leaf powers and $k$-leaf powers have been studied for over 20 years, but
there are still several aspects of this graph class that are poorly understood.
One such aspect is the leaf rank of leaf powers, i.e. the smallest number $k$
such that a graph $G$ is a $k$-leaf power. Computing the leaf rank of leaf
powers has proved a hard task, and furthermore, results about the asymptotic
growth of the leaf rank as a function of the number of vertices in the graph
have been few and far between. We present an infinite family of rooted directed
path graphs that are leaf powers, and prove that they have leaf rank
exponential in the number of vertices (utilizing a type of subtree model first
presented by Rautenbach [Some remarks about leaf roots. Discrete mathematics,
2006]). This answers an open question by Brandst\"adt et al. [Rooted directed
path graphs are leaf powers. Discrete mathematics, 2010].
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18246" title="Abstract">arXiv:2402.18246</a> [<a href="/pdf/2402.18246" title="Download PDF">pdf</a>, <a href="/format/2402.18246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning and Graph Neural Networks for Probabilistic Risk  Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Grimstad%2C+J">Joachim Grimstad</a>, 
<a href="/search/eess?searchtype=author&query=Morozov%2C+A">Andrey Morozov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents a new approach to the solution of Probabilistic Risk
Assessment (PRA) models using the combination of Reinforcement Learning (RL)
and Graph Neural Networks (GNNs). The paper introduces and demonstrates the
concept using one of the most popular PRA models - Fault Trees. This paper's
original idea is to apply RL algorithms to solve a PRA model represented with a
graph model. Given enough training data, or through RL, such an approach helps
train generic PRA solvers that can optimize and partially substitute classical
PRA solvers that are based on existing formal methods. Such an approach helps
to solve the problem of the fast-growing complexity of PRA models of modern
technical systems.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18251" title="Abstract">arXiv:2402.18251</a> [<a href="/pdf/2402.18251" title="Download PDF">pdf</a>, <a href="/ps/2402.18251" title="Download PostScript">ps</a>, <a href="/format/2402.18251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Accuracy of Edge Detectors in Number Plate Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sadiq%2C+B+O">Bashir Olaniyi Sadiq</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Edge detection as a pre-processing stage is a fundamental and important
aspect of the number plate extraction system. This is due to the fact that the
identification of a particular vehicle is achievable using the number plate
because each number plate is unique to a vehicle. As such, the characters of a
number plate system that differ in lines and shapes can be extracted using the
principle of edge detection. This paper presents a method of number plate
extraction using edge detection technique. Edges in number plates are
identified with changes in the intensity of pixel values. Therefore, these
edges are identified using a single based pixel or collection of pixel-based
approach. The efficiency of these approaches of edge detection algorithms in
number plate extraction in both noisy and clean environment are experimented.
Experimental results are achieved in MATLAB 2017b using the Pratt Figure of
Merit (PFOM) as a performance metric
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18252" title="Abstract">arXiv:2402.18252</a> [<a href="/pdf/2402.18252" title="Download PDF">pdf</a>, <a href="/format/2402.18252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Generalist Prompting for Large Language Models by Mental Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+H">Haoxiang Guan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiyan He</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shuxin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">En-Hong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Nenghai Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated impressive performance on many
tasks. However, to achieve optimal performance, specially designed prompting
methods are still needed. These methods either rely on task-specific few-shot
examples that require a certain level of domain knowledge, or are designed to
be simple but only perform well on a few types of tasks. In this work, we
attempt to introduce the concept of generalist prompting, which operates on the
design principle of achieving optimal or near-optimal performance on a wide
range of tasks while eliminating the need for manual selection and
customization of prompts tailored to specific problems. Furthermore, we propose
MeMo (Mental Models), an innovative prompting method that is simple-designed
yet effectively fulfills the criteria of generalist prompting. MeMo distills
the cores of various prompting methods into individual mental models and allows
LLMs to autonomously select the most suitable mental models for the problem,
achieving or being near to the state-of-the-art results on diverse tasks such
as STEM, logical reasoning, and commonsense reasoning in zero-shot settings. We
hope that the insights presented herein will stimulate further exploration of
generalist prompting methods for LLMs.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18255" title="Abstract">arXiv:2402.18255</a> [<a href="/pdf/2402.18255" title="Download PDF">pdf</a>, <a href="/format/2402.18255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How open are hybrid journals included in transformative agreements?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jahn%2C+N">Najko Jahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">The ongoing controversy surrounding transformative agreements, which aim to
transition journal publishing to full open access, highlight the need for
large-scale studies assessing the uptake of open access in hybrid journals.
This includes evaluating the extent to which transformative agreements enabled
open access. By combining publicly available data from various sources,
including cOAlition S Journal Checker, Crossref, and OpenAlex, this study
presents a novel approach that analyses over 700 agreements and nine million
journal articles published in more than 11.000 hybrid journals. Estimates
suggest a strong growth in open access between 2018 and 2022 from 4.3% to 15%.
In 2022, 58% of hybrid open access was enabled by transformative agreements.
This trend was largely driven by the three commercial publishers Elsevier,
Springer Nature, and Wiley, but the open access uptake varied substantially
across journals, publishers, disciplines, and country affiliations. In
particular, comparing the developments in the OECD and BRICS areas revealed
different publication trends relative to hybrid open access. In conclusion,
estimates suggest that current levels of implementation of transformative
agreements is insufficient to bring about a large-scale transition to full open
access.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18256" title="Abstract">arXiv:2402.18256</a> [<a href="/pdf/2402.18256" title="Download PDF">pdf</a>, <a href="/format/2402.18256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Cost of Permissionless Liquidity Provision in Automated Market  Makers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Julian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Crapis%2C+D">Davide Crapis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Automated market makers (AMMs) allocate fee revenue proportional to the
amount of liquidity investors deposit. In this paper, we study the economic
consequences of the competition between passive liquidity providers (LPs)
caused by this allocation rule. We employ a game-theoretic model in which $N$
strategic agents optimally provide liquidity. In this setting, we find that
competition drives LPs to provide excess liquidity. In the limit, the excess
liquidity converges to a constant that linearly increases with the amount of
base demand, demand that is insensitive to trading costs. Providing excess
liquidity is costly as more capital is exposed to adverse selection costs,
leading to a loss in welfare. Our main result is that the price of anarchy,
defined over the liquidity provider performance, is $O(N)$, implying that the
welfare loss scales linearly with the number of liquidity providers. We show
that this result is still observable when using richer aggregate demand models.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18258" title="Abstract">arXiv:2402.18258</a> [<a href="/pdf/2402.18258" title="Download PDF">pdf</a>, <a href="/format/2402.18258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A BiRGAT Model for Multi-intent Spoken Language Understanding with  Hierarchical Semantic Frames
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongshen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+R">Ruisheng Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Su Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Sheng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanchong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kai Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Previous work on spoken language understanding (SLU) mainly focuses on
single-intent settings, where each input utterance merely contains one user
intent. This configuration significantly limits the surface form of user
utterances and the capacity of output semantics. In this work, we first propose
a Multi-Intent dataset which is collected from a realistic in-Vehicle dialogue
System, called MIVS. The target semantic frame is organized in a 3-layer
hierarchical structure to tackle the alignment and assignment problems in
multi-intent cases. Accordingly, we devise a BiRGAT model to encode the
hierarchy of ontology items, the backbone of which is a dual relational graph
attention network. Coupled with the 3-way pointer-generator decoder, our method
outperforms traditional sequence labeling and classification-based schemes by a
large margin.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18260" title="Abstract">arXiv:2402.18260</a> [<a href="/pdf/2402.18260" title="Download PDF">pdf</a>, <a href="/format/2402.18260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficiently Computable Safety Bounds for Gaussian Processes in Active  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tebbe%2C+J">J&#xf6;rn Tebbe</a>, 
<a href="/search/cs?searchtype=author&query=Zimmer%2C+C">Christoph Zimmer</a>, 
<a href="/search/cs?searchtype=author&query=Steland%2C+A">Ansgar Steland</a>, 
<a href="/search/cs?searchtype=author&query=Lange-Hegermann%2C+M">Markus Lange-Hegermann</a>, 
<a href="/search/cs?searchtype=author&query=Mies%2C+F">Fabian Mies</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Active learning of physical systems must commonly respect practical safety
constraints, which restricts the exploration of the design space. Gaussian
Processes (GPs) and their calibrated uncertainty estimations are widely used
for this purpose. In many technical applications the design space is explored
via continuous trajectories, along which the safety needs to be assessed. This
is particularly challenging for strict safety requirements in GP methods, as it
employs computationally expensive Monte-Carlo sampling of high quantiles. We
address these challenges by providing provable safety bounds based on the
adaptively sampled median of the supremum of the posterior GP. Our method
significantly reduces the number of samples required for estimating high safety
probabilities, resulting in faster evaluation without sacrificing accuracy and
exploration speed. The effectiveness of our safe active learning approach is
demonstrated through extensive simulations and validated using a real-world
engine example.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18262" title="Abstract">arXiv:2402.18262</a> [<a href="/pdf/2402.18262" title="Download PDF">pdf</a>, <a href="/format/2402.18262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Multimodal Pre-training for Visually Rich Webpage  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongshen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zihan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+D">Da Ma</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+R">Ruisheng Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zichen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kai Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The growing prevalence of visually rich documents, such as webpages and
scanned/digital-born documents (images, PDFs, etc.), has led to increased
interest in automatic document understanding and information extraction across
academia and industry. Although various document modalities, including image,
text, layout, and structure, facilitate human information retrieval, the
interconnected nature of these modalities presents challenges for neural
networks. In this paper, we introduce WebLM, a multimodal pre-training network
designed to address the limitations of solely modeling text and structure
modalities of HTML in webpages. Instead of processing document images as
unified natural images, WebLM integrates the hierarchical structure of document
images to enhance the understanding of markup-language-based documents.
Additionally, we propose several pre-training tasks to model the interaction
among text, structure, and image modalities effectively. Empirical results
demonstrate that the pre-trained WebLM significantly surpasses previous
state-of-the-art pre-trained models across several webpage understanding tasks.
The pre-trained models and code are available at
https://github.com/X-LANCE/weblm.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18263" title="Abstract">arXiv:2402.18263</a> [<a href="/pdf/2402.18263" title="Download PDF">pdf</a>, <a href="/ps/2402.18263" title="Download PostScript">ps</a>, <a href="/format/2402.18263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Max-Cut with $&#x3b5;$-Accurate Predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cohen-Addad%2C+V">Vincent Cohen-Addad</a>, 
<a href="/search/cs?searchtype=author&query=d%27Orsi%2C+T">Tommaso d&#x27;Orsi</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Anupam Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+E">Euiwoong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Panigrahi%2C+D">Debmalya Panigrahi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">We study the approximability of the MaxCut problem in the presence of
predictions. Specifically, we consider two models: in the noisy predictions
model, for each vertex we are given its correct label in $\{-1,+1\}$ with some
unknown probability $1/2 + \epsilon$, and the other (incorrect) label
otherwise. In the more-informative partial predictions model, for each vertex
we are given its correct label with probability $\epsilon$ and no label
otherwise. We assume only pairwise independence between vertices in both
models.
<br />We show how these predictions can be used to improve on the worst-case
approximation ratios for this problem. Specifically, we give an algorithm that
achieves an $\alpha + \widetilde{\Omega}(\epsilon^4)$-approximation for the
noisy predictions model, where $\alpha \approx 0.878$ is the MaxCut threshold.
While this result also holds for the partial predictions model, we can also
give a $\beta + \Omega(\epsilon)$-approximation, where $\beta \approx 0.858$ is
the approximation ratio for MaxBisection given by Raghavendra and Tan. This
answers a question posed by Ola Svensson in his plenary session talk at
SODA'23.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18264" title="Abstract">arXiv:2402.18264</a> [<a href="/pdf/2402.18264" title="Download PDF">pdf</a>, <a href="/format/2402.18264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval-based Full-length Wikipedia Generation for Emergent Events
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiebin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+E+J">Eugene J. Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qinyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Chenhao Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Dawei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+H">Han Qian</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Mingbo Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoguang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sujian Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In today's fast-paced world, the growing demand to quickly generate
comprehensive and accurate Wikipedia documents for emerging events is both
crucial and challenging. However, previous efforts in Wikipedia generation have
often fallen short of meeting real-world requirements. Some approaches focus
solely on generating segments of a complete Wikipedia document, while others
overlook the importance of faithfulness in generation or fail to consider the
influence of the pre-training corpus. In this paper, we simulate a real-world
scenario where structured full-length Wikipedia documents are generated for
emergent events using input retrieved from web sources. To ensure that Large
Language Models (LLMs) are not trained on corpora related to recently occurred
events, we select events that have taken place recently and introduce a new
benchmark Wiki-GenBen, which consists of 309 events paired with their
corresponding retrieved web pages for generating evidence. Additionally, we
design a comprehensive set of systematic evaluation metrics and baseline
methods, to evaluate the capability of LLMs in generating factual full-length
Wikipedia documents. The data and code are open-sourced at WikiGenBench.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18265" title="Abstract">arXiv:2402.18265</a> [<a href="/pdf/2402.18265" title="Download PDF">pdf</a>, <a href="/format/2402.18265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Output-Sensitive Enumeration of Potential Maximal Cliques in Polynomial  Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brosse%2C+C">Caroline Brosse</a>, 
<a href="/search/cs?searchtype=author&query=Conte%2C+A">Alessio Conte</a>, 
<a href="/search/cs?searchtype=author&query=Limouzy%2C+V">Vincent Limouzy</a>, 
<a href="/search/cs?searchtype=author&query=Punzi%2C+G">Giulia Punzi</a>, 
<a href="/search/cs?searchtype=author&query=Rucci%2C+D">Davide Rucci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">A set of vertices in a graph forms a potential maximal clique if there exists
a minimal chordal completion in which it is a maximal clique. Potential maximal
cliques were first introduced as a key tool to obtain an efficient, though
exponential-time algorithm to compute the treewidth of a graph. As a byproduct,
this allowed to compute the treewidth of various graph classes in polynomial
time.
<br />In recent years, the concept of potential maximal cliques regained interest
as it proved to be useful for a handful of graph algorithmic problems. In
particular, it turned out to be a key tool to obtain a polynomial time
algorithm for computing maximum weight independent sets in $P_5$-free and
$P_6$-free graphs (Lokshtanov et al., SODA `14 and Grzeskik et al., SODA `19.
In most of their applications, obtaining all the potential maximal cliques
constitutes an algorithmic bottleneck, thus motivating the question of how to
efficiently enumerate all the potential maximal cliques in a graph $G$.
<br />The state-of-the-art algorithm by Bouchitt\'e \&amp; Todinca can enumerate
potential maximal cliques in output-polynomial time by using exponential space,
a significant limitation for the size of feasible instances. In this paper, we
revisit this algorithm and design an enumeration algorithm that preserves an
output-polynomial time complexity while only requiring polynomial space.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18267" title="Abstract">arXiv:2402.18267</a> [<a href="/pdf/2402.18267" title="Download PDF">pdf</a>, <a href="/ps/2402.18267" title="Download PostScript">ps</a>, <a href="/format/2402.18267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Neural Question Generation: Methods, Applications, and  Prospects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Shasha Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+L">Lizi Liao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Cuiping Li</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this survey, we present a detailed examination of the advancements in
Neural Question Generation (NQG), a field leveraging neural network techniques
to generate relevant questions from diverse inputs like knowledge bases, texts,
and images. The survey begins with an overview of NQG's background,
encompassing the task's problem formulation, prevalent benchmark datasets,
established evaluation metrics, and notable applications. It then methodically
classifies NQG approaches into three predominant categories: structured NQG,
which utilizes organized data sources, unstructured NQG, focusing on more
loosely structured inputs like texts or visual content, and hybrid NQG, drawing
on diverse input modalities. This classification is followed by an in-depth
analysis of the distinct neural network models tailored for each category,
discussing their inherent strengths and potential limitations. The survey
culminates with a forward-looking perspective on the trajectory of NQG,
identifying emergent research trends and prospective developmental paths.
Accompanying this survey is a curated collection of related research papers,
datasets and codes, systematically organized on Github, providing an extensive
reference for those delving into NQG.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18272" title="Abstract">arXiv:2402.18272</a> [<a href="/pdf/2402.18272" title="Download PDF">pdf</a>, <a href="/format/2402.18272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the  Key?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qineng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Ying Su</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+H">Hanghang Tong</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yangqiu Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 5 figures, 10 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent progress in LLMs discussion suggests that multi-agent discussion
improves the reasoning abilities of LLMs. In this work, we reevaluate this
claim through systematic experiments, where we propose a novel group discussion
framework to enrich the set of discussion mechanisms. Interestingly, our
results show that a single-agent LLM with strong prompts can achieve almost the
same performance as the best existing discussion approach on a wide range of
reasoning tasks and backbone LLMs. We observe that the multi-agent discussion
performs better than a single agent only when there is no demonstration in the
prompt. Further study reveals the common interaction mechanisms of LLMs during
the discussion.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18275" title="Abstract">arXiv:2402.18275</a> [<a href="/pdf/2402.18275" title="Download PDF">pdf</a>, <a href="/format/2402.18275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploration of Adapter for Noise Robust Automatic Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Hao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Kawahara%2C+T">Tatsuya Kawahara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Adapting a robust automatic speech recognition (ASR) system to tackle unseen
noise scenarios is crucial. Integrating adapters into neural networks has
emerged as a potent technique for transfer learning. This paper thoroughly
investigates adapter-based noise-robust ASR adaptation. We conducted the
experiments using the CHiME--4 dataset. The results show that inserting the
adapter in the shallow layer yields superior effectiveness, and there is no
significant difference between adapting solely within the shallow layer and
adapting across all layers. Besides, the simulated data helps the system to
improve its performance under real noise conditions. Nonetheless, when the
amount of data is the same, the real data is more effective than the simulated
data. Multi-condition training remains valid for adapter training. Furthermore,
integrating adapters into speech enhancement-based ASR systems yields
substantial improvements.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18276" title="Abstract">arXiv:2402.18276</a> [<a href="/pdf/2402.18276" title="Download PDF">pdf</a>, <a href="/ps/2402.18276" title="Download PostScript">ps</a>, <a href="/format/2402.18276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fractional Linear Matroid Matching is in quasi-NC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gurjar%2C+R">Rohit Gurjar</a>, 
<a href="/search/cs?searchtype=author&query=Oki%2C+T">Taihei Oki</a>, 
<a href="/search/cs?searchtype=author&query=Raj%2C+R">Roshan Raj</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">The matching and linear matroid intersection problems are solvable in
quasi-NC, meaning that there exist deterministic algorithms that run in
polylogarithmic time and use quasi-polynomially many parallel processors.
However, such a parallel algorithm is unknown for linear matroid matching,
which generalizes both of these problems. In this work, we propose a quasi-NC
algorithm for fractional linear matroid matching, which is a relaxation of
linear matroid matching and commonly generalizes fractional matching and linear
matroid intersection. Our algorithm builds upon the connection of fractional
matroid matching to non-commutative Edmonds' problem recently revealed by Oki
and Soma~(2023). As a corollary, we also solve black-box non-commutative
Edmonds' problem with rank-two skew-symmetric coefficients.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18277" title="Abstract">arXiv:2402.18277</a> [<a href="/pdf/2402.18277" title="Download PDF">pdf</a>, <a href="/format/2402.18277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attentive Illumination Decomposition Model for Multi-Illuminant White  Balancing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dongyoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jinwoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Junsang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+J">Seon Joo Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">White balance (WB) algorithms in many commercial cameras assume single and
uniform illumination, leading to undesirable results when multiple lighting
sources with different chromaticities exist in the scene. Prior research on
multi-illuminant WB typically predicts illumination at the pixel level without
fully grasping the scene's actual lighting conditions, including the number and
color of light sources. This often results in unnatural outcomes lacking in
overall consistency. To handle this problem, we present a deep white balancing
model that leverages the slot attention, where each slot is in charge of
representing individual illuminants. This design enables the model to generate
chromaticities and weight maps for individual illuminants, which are then fused
to compose the final illumination map. Furthermore, we propose the
centroid-matching loss, which regulates the activation of each slot based on
the color range, thereby enhancing the model to separate illumination more
effectively. Our method achieves the state-of-the-art performance on both
single- and multi-illuminant WB benchmarks, and also offers additional
information such as the number of illuminants in the scene and their
chromaticity. This capability allows for illumination editing, an application
not feasible with prior methods.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18278" title="Abstract">arXiv:2402.18278</a> [<a href="/pdf/2402.18278" title="Download PDF">pdf</a>, <a href="/format/2402.18278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EAN-MapNet: Efficient Vectorized HD Map Construction with Anchor  Neighborhoods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Huiyuan Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Taohong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yuelong Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">High-definition (HD) map is crucial for autonomous driving systems. Most
existing works design map elements detection heads based on the DETR decoder.
However, the initial queries lack integration with the physical location
feature of map elements, and vanilla self-attention entails high computational
complexity. Therefore, we propose EAN-MapNet for Efficiently constructing HD
map using Anchor Neighborhoods. Firstly, we design query units based on the
physical location feature of anchor neighborhoods. Non-neighborhood central
anchors effectively assist the neighborhood central anchors in fitting to the
target points, significantly improving the prediction accuracy. Then, we
introduce grouped local self-attention (GL-SA), which innovatively utilizes
local queries as the medium for feature interaction, thereby substantially
reducing the computational complexity of self-attention while facilitating
ample feature interaction among queries. On nuScenes dataset, EAN-MapNet
achieves a state-of-the-art performance with 63.0 mAP after training for 24
epochs. Furthermore, it considerably reduces memory consumption by 8198M
compared to the baseline.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18281" title="Abstract">arXiv:2402.18281</a> [<a href="/pdf/2402.18281" title="Download PDF">pdf</a>, <a href="/format/2402.18281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Better Understanding of Contrastive Sentence Representation  Learning: A Unified Paradigm for Gradient
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Richong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Z">Zhijie Nie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Sentence Representation Learning (SRL) is a crucial task in Natural Language
Processing (NLP), where contrastive Self-Supervised Learning (SSL) is currently
a mainstream approach. However, the reasons behind its remarkable effectiveness
remain unclear. Specifically, in other research fields, contrastive SSL shares
similarities in both theory and practical performance with non-contrastive SSL
(e.g., alignment &amp; uniformity, Barlow Twins, and VICReg). However, in SRL,
contrastive SSL outperforms non-contrastive SSL significantly. Therefore, two
questions arise: First, what commonalities enable various contrastive losses to
achieve superior performance in SRL? Second, how can we make non-contrastive
SSL, which is similar to contrastive SSL but ineffective in SRL, effective? To
address these questions, we start from the perspective of gradients and
discover that four effective contrastive losses can be integrated into a
unified paradigm, which depends on three components: the Gradient Dissipation,
the Weight, and the Ratio. Then, we conduct an in-depth analysis of the roles
these components play in optimization and experimentally demonstrate their
significance for model performance. Finally, by adjusting these components, we
enable non-contrastive SSL to achieve outstanding performance in SRL.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18284" title="Abstract">arXiv:2402.18284</a> [<a href="/pdf/2402.18284" title="Download PDF">pdf</a>, <a href="/format/2402.18284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is Crowdsourcing Breaking Your Bank? Cost-Effective Fine-Tuning of  Pre-trained Language Models with Proximal Policy Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kasneci%2C+G">Gjergji Kasneci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Wide usage of ChatGPT has highlighted the potential of reinforcement learning
from human feedback. However, its training pipeline relies on manual ranking, a
resource-intensive process. To reduce labor costs, we propose a self-supervised
text ranking approach for applying Proximal-Policy-Optimization to fine-tune
language models while eliminating the need for human annotators. Our method
begins with probabilistic sampling to encourage a language model to generate
diverse responses for each input. We then employ TextRank and ISODATA
algorithms to rank and cluster these responses based on their semantics.
Subsequently, we construct a reward model to learn the rank and optimize our
generative policy. Our experimental results, conducted using two language
models on three tasks, demonstrate that the models trained by our method
considerably outperform baselines regarding BLEU, GLEU, and METEOR scores.
Furthermore, our manual evaluation shows that our ranking results exhibit a
remarkably high consistency with that of humans. This research significantly
reduces training costs of proximal policy-guided models and demonstrates the
potential for self-correction of language models.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18285" title="Abstract">arXiv:2402.18285</a> [<a href="/pdf/2402.18285" title="Download PDF">pdf</a>, <a href="/format/2402.18285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PiShield: A NeSy Framework for Learning with Requirements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stoian%2C+M+C">Mihaela C&#x103;t&#x103;lina Stoian</a>, 
<a href="/search/cs?searchtype=author&query=Tatomir%2C+A">Alex Tatomir</a>, 
<a href="/search/cs?searchtype=author&query=Lukasiewicz%2C+T">Thomas Lukasiewicz</a>, 
<a href="/search/cs?searchtype=author&query=Giunchiglia%2C+E">Eleonora Giunchiglia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Demo paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Deep learning models have shown their strengths in various application
domains, however, they often struggle to meet safety requirements for their
outputs. In this paper, we introduce PiShield, the first framework ever
allowing for the integration of the requirements into the neural networks'
topology. PiShield guarantees compliance with these requirements, regardless of
input. Additionally, it allows for integrating requirements both at inference
and/or training time, depending on the practitioners' needs. Given the
widespread application of deep learning, there is a growing need for frameworks
allowing for the integration of the requirements across various domains. Here,
we explore three application scenarios: functional genomics, autonomous
driving, and tabular data generation.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18286" title="Abstract">arXiv:2402.18286</a> [<a href="/pdf/2402.18286" title="Download PDF">pdf</a>, <a href="/format/2402.18286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Learning in Electron Microscopy: Towards a Foundation  Model for Advanced Image Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kazimi%2C+B">Bashir Kazimi</a>, 
<a href="/search/cs?searchtype=author&query=Ruzaeva%2C+K">Karina Ruzaeva</a>, 
<a href="/search/cs?searchtype=author&query=Sandfeld%2C+S">Stefan Sandfeld</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Materials Science (cond-mat.mtrl-sci); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work, we explore the potential of self-supervised learning from
unlabeled electron microscopy datasets, taking a step toward building a
foundation model in this field. We show how self-supervised pretraining
facilitates efficient fine-tuning for a spectrum of downstream tasks, including
semantic segmentation, denoising, noise &amp; background removal, and
super-resolution. Experimentation with varying model complexities and receptive
field sizes reveals the remarkable phenomenon that fine-tuned models of lower
complexity consistently outperform more complex models with random weight
initialization. We demonstrate the versatility of self-supervised pretraining
across various downstream tasks in the context of electron microscopy, allowing
faster convergence and better performance. We conclude that self-supervised
pretraining serves as a powerful catalyst, being especially advantageous when
limited annotated data are available and efficient scaling of computational
cost are important.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18287" title="Abstract">arXiv:2402.18287</a> [<a href="/pdf/2402.18287" title="Download PDF">pdf</a>, <a href="/format/2402.18287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Windowed-FourierMixer: Enhancing Clutter-Free Room Modeling with Fourier  Transform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Henriques%2C+B">Bruno Henriques</a>, 
<a href="/search/cs?searchtype=author&query=Allaert%2C+B">Benjamin Allaert</a>, 
<a href="/search/cs?searchtype=author&query=Vandeborre%2C+J">Jean-Philippe Vandeborre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the growing demand for immersive digital applications, the need to
understand and reconstruct 3D scenes has significantly increased. In this
context, inpainting indoor environments from a single image plays a crucial
role in modeling the internal structure of interior spaces as it enables the
creation of textured and clutter-free reconstructions. While recent methods
have shown significant progress in room modeling, they rely on constraining
layout estimators to guide the reconstruction process. These methods are highly
dependent on the performance of the structure estimator and its generative
ability in heavily occluded environments. In response to these issues, we
propose an innovative approach based on a U-Former architecture and a new
Windowed-FourierMixer block, resulting in a unified, single-phase network
capable of effectively handle human-made periodic structures such as indoor
spaces. This new architecture proves advantageous for tasks involving indoor
scenes where symmetry is prevalent, allowing the model to effectively capture
features such as horizon/ceiling height lines and cuboid-shaped rooms.
Experiments show the proposed approach outperforms current state-of-the-art
methods on the Structured3D dataset demonstrating superior performance in both
quantitative metrics and qualitative results. Code and models will be made
publicly available.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18288" title="Abstract">arXiv:2402.18288</a> [<a href="/pdf/2402.18288" title="Download PDF">pdf</a>, <a href="/format/2402.18288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Development of Context-Sensitive Formulas to Obtain Constant Luminance  Perception for a Foreground Object in Front of Backgrounds of Varying  Luminance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akleman%2C+E">Ergun Akleman</a>, 
<a href="/search/cs?searchtype=author&query=Akgun%2C+B+T">Bekir Tevfik Akgun</a>, 
<a href="/search/cs?searchtype=author&query=Alpkocak%2C+A">Adil Alpkocak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this article, we present a framework for developing context-sensitive
luminance correction formulas that can produce constant luminance perception
for foreground objects. Our formulas make the foreground object slightly
translucent to mix with the blurred version of the background. This mix can
quickly produce any desired illusion of luminance in foreground objects based
on the luminance of the background. The translucency formula has only one
parameter; the relative size of the foreground object, which is a number
between zero and one. We have identified the general structure of the
translucency formulas as a power function of the relative size of the
foreground object. We have implemented a web-based interactive program in
Shadertoy. Using this program, we determined the coefficients of the polynomial
exponents of the power function. To intuitively control the coefficients of the
polynomial functions, we have used a B\'{e}zier form. Our final translucency
formula uses a quadratic polynomial and requires only three coefficients. We
also identified a simpler affine formula, which requires only two coefficients.
We made our program publicly available in Shadertoy so that anyone can access
and improve it. In this article, we also explain how to intuitively change the
polynomial part of the formula. Using our explanation, users change the
polynomial part of the formula to obtain their own perceptively constant
luminance. This can be used as a crowd-sourcing experiment for further
improvement of the formula.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18292" title="Abstract">arXiv:2402.18292</a> [<a href="/pdf/2402.18292" title="Download PDF">pdf</a>, <a href="/format/2402.18292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FSL Model can Score Higher as It Is
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yunwei Bai</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y+K">Ying Kiat Tan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tsuhan Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In daily life, we tend to present the front of our faces by staring squarely
at a facial recognition machine, instead of facing it sideways, in order to
increase the chance of being correctly recognised. Few-shot-learning (FSL)
classification is challenging in itself because a model has to identify images
that belong to classes previously unseen during training. Therefore, a warped
and non-typical query or support image during testing can make it even more
challenging for a model to predict correctly. In our work, to increase the
chance of correct prediction during testing, we aim to rectify the test input
of a trained FSL model by generating new samples of the tested classes through
image-to-image translation. An FSL model is usually trained on classes with
sufficient samples, and then tested on classes with few-shot samples. Our
proposed method first captures the style or shape of the test image, and then
identifies a suitable trained class sample. It then transfers the style or
shape of the test image to the train-class images for generation of more
test-class samples, before performing classification based on a set of
generated samples instead of just one sample. Our method has potential in
empowering a trained FSL model to score higher during the testing phase without
any extra training nor dataset. According to our experiments, by augmenting the
support set with just 1 additional generated sample, we can achieve around 2%
improvement for trained FSL models on datasets consisting of either animal
faces or traffic signs. By augmenting both the support set and the queries, we
can achieve even more performance improvement. Our Github Repository is
publicly available.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18293" title="Abstract">arXiv:2402.18293</a> [<a href="/pdf/2402.18293" title="Download PDF">pdf</a>, <a href="/format/2402.18293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grid-Based Continuous Normal Representation for Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+C">Joo Chan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taejune Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+E">Eunbyung Park</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+S+S">Simon S. Woo</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+J+H">Jong Hwan Ko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://tae-mo.github.io/grad/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">There have been significant advancements in anomaly detection in an
unsupervised manner, where only normal images are available for training.
Several recent methods aim to detect anomalies based on a memory, comparing the
input and the directly stored normal features (or trained features with normal
images). However, such memory-based approaches operate on a discrete feature
space implemented by the nearest neighbor or attention mechanism, suffering
from poor generalization or an identity shortcut issue outputting the same as
input, respectively. Furthermore, the majority of existing methods are designed
to detect single-class anomalies, resulting in unsatisfactory performance when
presented with multiple classes of objects. To tackle all of the above
challenges, we propose GRAD, a novel anomaly detection method for representing
normal features within a "continuous" feature space, enabled by transforming
spatial features into coordinates and mapping them to continuous grids.
Furthermore, we carefully design the grids tailored for anomaly detection,
representing both local and global normal features and fusing them effectively.
Our extensive experiments demonstrate that GRAD successfully generalizes the
normal features and mitigates the identity shortcut, furthermore, GRAD
effectively handles diverse classes in a single model thanks to the
high-granularity global representation. In an evaluation using the MVTec AD
dataset, GRAD significantly outperforms the previous state-of-the-art method by
reducing 65.0\% of the error for multi-class unified anomaly detection. The
project page is available at https://tae-mo.github.io/grad/.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18294" title="Abstract">arXiv:2402.18294</a> [<a href="/pdf/2402.18294" title="Download PDF">pdf</a>, <a href="/format/2402.18294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Whole-body Humanoid Robot Locomotion with Human Reference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+P">Peter Cui</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+D">David Yan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jingkai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yiqun Duan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Arthur Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Renjing Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Recently, humanoid robots have made significant advances in their ability to
perform complex tasks due to the deployment of Reinforcement Learning (RL),
however, the inherent complexity of humanoid robots, including the difficulty
of planning complex reward functions and training entire complex systems, still
poses a notable challenge. To conquer these challenges, after many iterations
and in-depth investigations, we have meticulously developed a full-size
humanoid robot, ''Adam'', whose innovative structural design greatly improves
the efficiency and effectiveness of the imitation learning process. In
addition, we have developed a novel imitation learning framework based on an
adversarial motion prior, which applies not only to Adam but also to humanoid
robots in general. Using the framework, Adam can exhibit unprecedented
human-like characteristics in locomotion tasks. Our experimental results
demonstrate that the proposed framework enables Adam to achieve
human-comparable performance in complex locomotion tasks, marking the first
time that human locomotion data has been used for imitation learning in a
full-size humanoid robot.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18296" title="Abstract">arXiv:2402.18296</a> [<a href="/pdf/2402.18296" title="Download PDF">pdf</a>, <a href="/ps/2402.18296" title="Download PostScript">ps</a>, <a href="/format/2402.18296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Analysis of XGBoost and Minirocket Algortihms for Human  Activity Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alagoz%2C+C">Celal Alagoz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 1 figure, 1st Bilsel International Sur Scientific Researches Congress, 10-11 February, 2024, Diyarbakir, T\"urk\.Iye
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Human Activity Recognition (HAR) has been extensively studied, with recent
emphasis on the implementation of advanced Machine Learning (ML) and Deep
Learning (DL) algorithms for accurate classification. This study investigates
the efficacy of two ML algorithms, eXtreme Gradient Boosting (XGBoost) and
MiniRocket, in the realm of HAR using data collected from smartphone sensors.
The experiments are conducted on a dataset obtained from the UCI repository,
comprising accelerometer and gyroscope signals captured from 30 volunteers
performing various activities while wearing a smartphone. The dataset undergoes
preprocessing, including noise filtering and feature extraction, before being
utilized for training and testing the classifiers. Monte Carlo cross-validation
is employed to evaluate the models' robustness. The findings reveal that both
XGBoost and MiniRocket attain accuracy, F1 score, and AUC values as high as
0.99 in activity classification. XGBoost exhibits a slightly superior
performance compared to MiniRocket. Notably, both algorithms surpass the
performance of other ML and DL algorithms reported in the literature for HAR
tasks. Additionally, the study compares the computational efficiency of the two
algorithms, revealing XGBoost's advantage in terms of training time.
Furthermore, the performance of MiniRocket, which achieves accuracy and F1
values of 0.94, and an AUC value of 0.96 using raw data and utilizing only one
channel from the sensors, highlights the potential of directly leveraging
unprocessed signals. It also suggests potential advantages that could be gained
by utilizing sensor fusion or channel fusion techniques. Overall, this research
sheds light on the effectiveness and computational characteristics of XGBoost
and MiniRocket in HAR tasks, providing insights for future studies in activity
recognition using smartphone sensor data.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18301" title="Abstract">arXiv:2402.18301</a> [<a href="/pdf/2402.18301" title="Download PDF">pdf</a>, <a href="/ps/2402.18301" title="Download PostScript">ps</a>, <a href="/format/2402.18301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantification and Modeling of Broken Links Prevalence in Hyper Traffic  Websites Homepages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mouchoux%2C+R">Ronan Mouchoux</a>, 
<a href="/search/cs?searchtype=author&query=Moulin%2C+L">Laurent Moulin</a>, 
<a href="/search/cs?searchtype=author&query=Striebig%2C+N">Nicolas Striebig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 tables, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Broken links in websites external resources pose a serious threat to
cybersecurity and the credibility of websites. They can be hijacked to
eavesdrop user traffic or to inject malicious software. In this paper, we
present the first result of an ongoing research. We focus on the prevalence of
broken links in external resources on home pages of the most visited websites
in the world. The analysis was conducted on the top 88 000 homepages extracted
from the Majestic Million rankings. 35,2% of them have at least one broken
link. We also identify the common causes of these broken links and highlight
improper implementation of testing phases to prevent such errors. We provide a
formal model for the distribution of external links. At the next research step,
we are exploring the potential impact on privacy of broken links by analyzing
inherited traffic of purchasable expired domains.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18302" title="Abstract">arXiv:2402.18302</a> [<a href="/pdf/2402.18302" title="Download PDF">pdf</a>, <a href="/format/2402.18302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EchoTrack: Auditory Referring Multi-Object Tracking for Autonomous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiacheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiajun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+K">Kunyu Peng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xuan He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiyong Li</a>, 
<a href="/search/cs?searchtype=author&query=Stiefelhagen%2C+R">Rainer Stiefelhagen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kailun Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The source code and datasets will be made publicly available at <a href="https://github.com/lab206/EchoTrack">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO); Audio and Speech Processing (eess.AS); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">This paper introduces the task of Auditory Referring Multi-Object Tracking
(AR-MOT), which dynamically tracks specific objects in a video sequence based
on audio expressions and appears as a challenging problem in autonomous
driving. Due to the lack of semantic modeling capacity in audio and video,
existing works have mainly focused on text-based multi-object tracking, which
often comes at the cost of tracking quality, interaction efficiency, and even
the safety of assistance systems, limiting the application of such methods in
autonomous driving. In this paper, we delve into the problem of AR-MOT from the
perspective of audio-video fusion and audio-video tracking. We put forward
EchoTrack, an end-to-end AR-MOT framework with dual-stream vision transformers.
The dual streams are intertwined with our Bidirectional Frequency-domain
Cross-attention Fusion Module (Bi-FCFM), which bidirectionally fuses audio and
video features from both frequency- and spatiotemporal domains. Moreover, we
propose the Audio-visual Contrastive Tracking Learning (ACTL) regime to extract
homogeneous semantic features between expressions and visual objects by
learning homogeneous features between different audio and video objects
effectively. Aside from the architectural design, we establish the first set of
large-scale AR-MOT benchmarks, including Echo-KITTI, Echo-KITTI+, and Echo-BDD.
Extensive experiments on the established benchmarks demonstrate the
effectiveness of the proposed EchoTrack model and its components. The source
code and datasets will be made publicly available at
https://github.com/lab206/EchoTrack.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18304" title="Abstract">arXiv:2402.18304</a> [<a href="/pdf/2402.18304" title="Download PDF">pdf</a>, <a href="/format/2402.18304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Play like a Vertex: A Stackelberg Game Approach for Streaming Graph  Partitioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zezhong Ding</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Y">Yongan Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shangyou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xike Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S+K">S. Kevin Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by SIGMOD 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Databases (cs.DB); Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">In the realm of distributed systems tasked with managing and processing
large-scale graph-structured data, optimizing graph partitioning stands as a
pivotal challenge. The primary goal is to minimize communication overhead and
runtime cost. However, alongside the computational complexity associated with
optimal graph partitioning, a critical factor to consider is memory overhead.
Real-world graphs often reach colossal sizes, making it impractical and
economically unviable to load the entire graph into memory for partitioning.
This is also a fundamental premise in distributed graph processing, where
accommodating a graph with non-distributed systems is unattainable. Currently,
existing streaming partitioning algorithms exhibit a skew-oblivious nature,
yielding satisfactory partitioning results exclusively for specific graph
types. In this paper, we propose a novel streaming partitioning algorithm, the
Skewness-aware Vertex-cut Partitioner S5P, designed to leverage the skewness
characteristics of real graphs for achieving high-quality partitioning. S5P
offers high partitioning quality by segregating the graph's edge set into two
subsets, head and tail sets. Following processing by a skewness-aware
clustering algorithm, these two subsets subsequently undergo a Stackelberg
graph game. Our extensive evaluations conducted on substantial real-world and
synthetic graphs demonstrate that, in all instances, the partitioning quality
of S5P surpasses that of existing streaming partitioning algorithms, operating
within the same load balance constraints. For example, S5P can bring up to a
51% improvement in partitioning quality compared to the top partitioner among
the baselines. Lastly, we showcase that the implementation of S5P results in up
to an 81% reduction in communication cost and a 130% increase in runtime
efficiency for distributed graph processing tasks on PowerGraph.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18307" title="Abstract">arXiv:2402.18307</a> [<a href="/pdf/2402.18307" title="Download PDF">pdf</a>, <a href="/format/2402.18307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Denoising For Low-Light Instance Segmentation Using Weighted  Non-Local Blocks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Joanne Lin</a>, 
<a href="/search/cs?searchtype=author&query=Anantrasirichai%2C+N">Nantheera Anantrasirichai</a>, 
<a href="/search/cs?searchtype=author&query=Bull%2C+D">David Bull</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Instance segmentation for low-light imagery remains largely unexplored due to
the challenges imposed by such conditions, for example shot noise due to low
photon count, color distortions and reduced contrast. In this paper, we propose
an end-to-end solution to address this challenging task. Based on Mask R-CNN,
our proposed method implements weighted non-local (NL) blocks in the feature
extractor. This integration enables an inherent denoising process at the
feature level. As a result, our method eliminates the need for aligned ground
truth images during training, thus supporting training on real-world low-light
datasets. We introduce additional learnable weights at each layer in order to
enhance the network's adaptability to real-world noise characteristics, which
affect different feature scales in different ways.
<br />Experimental results show that the proposed method outperforms the pretrained
Mask R-CNN with an Average Precision (AP) improvement of +10.0, with the
introduction of weighted NL Blocks further enhancing AP by +1.0.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18309" title="Abstract">arXiv:2402.18309</a> [<a href="/pdf/2402.18309" title="Download PDF">pdf</a>, <a href="/format/2402.18309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Roadway Safety: LiDAR-based Tree Clearance Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carnot%2C+M+L">Miriam Louise Carnot</a>, 
<a href="/search/cs?searchtype=author&query=Peukert%2C+E">Eric Peukert</a>, 
<a href="/search/cs?searchtype=author&query=Franczyk%2C+B">Bogdan Franczyk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computational Geometry (cs.CG)

</div>
<p class="mathjax">In the efforts for safer roads, ensuring adequate vertical clearance above
roadways is of great importance. Frequently, trees or other vegetation is
growing above the roads, blocking the sight of traffic signs and lights and
posing danger to traffic participants. Accurately estimating this space from
simple images proves challenging due to a lack of depth information. This is
where LiDAR technology comes into play, a laser scanning sensor that reveals a
three-dimensional perspective. Thus far, LiDAR point clouds at the street level
have mainly been used for applications in the field of autonomous driving.
These scans, however, also open up possibilities in urban management. In this
paper, we present a new point cloud algorithm that can automatically detect
those parts of the trees that grow over the street and need to be trimmed. Our
system uses semantic segmentation to filter relevant points and downstream
processing steps to create the required volume to be kept clear above the road.
Challenges include obscured stretches of road, the noisy unstructured nature of
LiDAR point clouds, and the assessment of the road shape. The identified points
of non-compliant trees can be projected from the point cloud onto images,
providing municipalities with a visual aid for dealing with such occurrences.
By automating this process, municipalities can address potential road space
constraints, enhancing safety for all. They may also save valuable time by
carrying out the inspections more systematically. Our open-source code gives
communities inspiration on how to automate the process themselves.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18311" title="Abstract">arXiv:2402.18311</a> [<a href="/pdf/2402.18311" title="Download PDF">pdf</a>, <a href="/format/2402.18311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Escaping Local Optima in Global Placement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+K">Ke Xue</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yunqi Shi</a>, 
<a href="/search/cs?searchtype=author&query=Kai%2C+S">Shixiong Kai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Siyuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chao Qian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work-in-Progress (WIP) poster of DAC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Placement is crucial in the physical design, as it greatly affects power,
performance, and area metrics. Recent advancements in analytical methods, such
as DREAMPlace, have demonstrated impressive performance in global placement.
However, DREAMPlace has some limitations, e.g., may not guarantee legalizable
placements under the same settings, leading to fragile and unpredictable
results. This paper highlights the main issue as being stuck in local optima,
and proposes a hybrid optimization framework to efficiently escape the local
optima, by perturbing the placement result iteratively. The proposed framework
achieves significant improvements compared to state-of-the-art methods on two
popular benchmarks.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18312" title="Abstract">arXiv:2402.18312</a> [<a href="/pdf/2402.18312" title="Download PDF">pdf</a>, <a href="/format/2402.18312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to think step-by-step: A mechanistic understanding of  chain-of-thought reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dutta%2C+S">Subhabrata Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+J">Joykirat Singh</a>, 
<a href="/search/cs?searchtype=author&query=Chakrabarti%2C+S">Soumen Chakrabarti</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+T">Tanmoy Chakraborty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite superior reasoning prowess demonstrated by Large Language Models
(LLMs) with Chain-of-Thought (CoT) prompting, a lack of understanding prevails
around the internal mechanisms of the models that facilitate CoT generation.
This work investigates the neural sub-structures within LLMs that manifest CoT
reasoning from a mechanistic point of view. From an analysis of LLaMA-2 7B
applied to multistep reasoning over fictional ontologies, we demonstrate that
LLMs deploy multiple parallel pathways of answer generation for step-by-step
reasoning. These parallel pathways provide sequential answers from the input
question context as well as the generated CoT. We observe a striking functional
rift in the middle layers of the LLM. Token representations in the initial half
remain strongly biased towards the pretraining prior, with the in-context
taking over abruptly in the later half. This internal phase shift manifests in
different functional components: attention heads that write the answer token
predominantly appear in the later half, attention heads that move information
along ontological relationships appear exclusively in the initial half, and so
on. To the best of our knowledge, this is the first attempt towards mechanistic
investigation of CoT reasoning in LLMs.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18318" title="Abstract">arXiv:2402.18318</a> [<a href="/pdf/2402.18318" title="Download PDF">pdf</a>, <a href="/ps/2402.18318" title="Download PostScript">ps</a>, <a href="/format/2402.18318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SD-SLAM: A Semantic SLAM Approach for Dynamic Scenes Based on LiDAR  Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Feiya Li</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Chunyun Fu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Dongye Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jian Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianwen Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Point cloud maps generated via LiDAR sensors using extensive remotely sensed
data are commonly used by autonomous vehicles and robots for localization and
navigation. However, dynamic objects contained in point cloud maps not only
downgrade localization accuracy and navigation performance but also jeopardize
the map quality. In response to this challenge, we propose in this paper a
novel semantic SLAM approach for dynamic scenes based on LiDAR point clouds,
referred to as SD-SLAM hereafter. The main contributions of this work are in
three aspects: 1) introducing a semantic SLAM framework dedicatedly for dynamic
scenes based on LiDAR point clouds, 2) Employing semantics and Kalman filtering
to effectively differentiate between dynamic and semi-static landmarks, and 3)
Making full use of semi-static and pure static landmarks with semantic
information in the SD-SLAM process to improve localization and mapping
performance. To evaluate the proposed SD-SLAM, tests were conducted using the
widely adopted KITTI odometry dataset. Results demonstrate that the proposed
SD-SLAM effectively mitigates the adverse effects of dynamic objects on SLAM,
improving vehicle localization and mapping performance in dynamic scenes, and
simultaneously constructing a static semantic map with multiple semantic
classes for enhanced environment understanding.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18319" title="Abstract">arXiv:2402.18319</a> [<a href="/pdf/2402.18319" title="Download PDF">pdf</a>, <a href="/format/2402.18319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multimodal Handover Failure Detection Dataset and Baselines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thoduka%2C+S">Santosh Thoduka</a>, 
<a href="/search/cs?searchtype=author&query=Hochgeschwender%2C+N">Nico Hochgeschwender</a>, 
<a href="/search/cs?searchtype=author&query=Gall%2C+J">Juergen Gall</a>, 
<a href="/search/cs?searchtype=author&query=Pl%C3%B6ger%2C+P+G">Paul G. Pl&#xf6;ger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">An object handover between a robot and a human is a coordinated action which
is prone to failure for reasons such as miscommunication, incorrect actions and
unexpected object properties. Existing works on handover failure detection and
prevention focus on preventing failures due to object slip or external
disturbances. However, there is a lack of datasets and evaluation methods that
consider unpreventable failures caused by the human participant. To address
this deficit, we present the multimodal Handover Failure Detection dataset,
which consists of failures induced by the human participant, such as ignoring
the robot or not releasing the object. We also present two baseline methods for
handover failure detection: (i) a video classification method using 3D CNNs and
(ii) a temporal action segmentation approach which jointly classifies the human
action, robot action and overall outcome of the action. The results show that
video is an important modality, but using force-torque data and gripper
position help improve failure detection and action segmentation accuracy.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18320" title="Abstract">arXiv:2402.18320</a> [<a href="/pdf/2402.18320" title="Download PDF">pdf</a>, <a href="/format/2402.18320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Location-guided Head Pose Estimation for Fisheye Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Cheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+Y">Yun Xian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dah-Jye Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Camera with a fisheye or ultra-wide lens covers a wide field of view that
cannot be modeled by the perspective projection. Serious fisheye
\textcolor{blue}{lens} distortion in the peripheral region of the image leads
to degraded performance of the \textcolor{blue}{existing} head pose estimation
models trained on undistorted images. This paper presents a new approach for
head pose estimation that uses the knowledge of head location in the image to
reduce the negative effect of fisheye distortion. We develop an end-to-end
convolutional neural network to estimate the head pose with the multi-task
learning of head pose and head location. Our proposed network estimates the
head pose directly from the fisheye image without the operation of
rectification or calibration. We also created \textcolor{blue}{a}
fisheye-\textcolor{blue}{distorted} version of the three popular head pose
estimation datasets, BIWI, 300W-LP, and AFLW2000 for our experiments.
Experiments results show that our network remarkably improves the accuracy of
head pose estimation compared with other state-of-the-art one-stage and
two-stage methods.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18321" title="Abstract">arXiv:2402.18321</a> [<a href="/pdf/2402.18321" title="Download PDF">pdf</a>, <a href="/format/2402.18321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy Policies and Consent Management Platforms: Growth and Users&#x27;  Interactions over Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jha%2C+N">Nikhil Jha</a>, 
<a href="/search/cs?searchtype=author&query=Trevisan%2C+M">Martino Trevisan</a>, 
<a href="/search/cs?searchtype=author&query=Mellia%2C+M">Marco Mellia</a>, 
<a href="/search/cs?searchtype=author&query=Fernandez%2C+D">Daniel Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=Irarrazaval%2C+R">Rodrigo Irarrazaval</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">In response to growing concerns about user privacy, legislators have
introduced new regulations and laws such as the General Data Protection
Regulation (GDPR) and the California Consumer Privacy Act (CCPA) that force
websites to obtain user consent before activating personal data collection,
fundamental to providing targeted advertising. The cornerstone of this
consent-seeking process involves the use of Privacy Banners, the technical
mechanism to collect users' approval for data collection practices. Consent
management platforms (CMPs) have emerged as practical solutions to make it
easier for website administrators to properly manage consent, allowing them to
outsource the complexities of managing user consent and activating advertising
features.
<br />This paper presents a detailed and longitudinal analysis of the evolution of
CMPs spanning nine years. We take a twofold perspective: Firstly, thanks to the
HTTP Archive dataset, we provide insights into the growth, market share, and
geographical spread of CMPs. Noteworthy observations include the substantial
impact of GDPR on the proliferation of CMPs in Europe. Secondly, we analyse
millions of user interactions with a medium-sized CMP present in thousands of
websites worldwide. We observe how even small changes in the design of Privacy
Banners have a critical impact on the user's giving or denying their consent to
data collection. For instance, over 60% of users do not consent when offered a
simple "one-click reject-all" option. Conversely, when opting out requires more
than one click, about 90% of users prefer to simply give their consent. The
main objective is in fact to eliminate the annoying privacy banner rather the
make an informed decision. Curiously, we observe iOS users exhibit a higher
tendency to accept cookies compared to Android users, possibly indicating
greater confidence in the privacy offered by Apple devices.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18322" title="Abstract">arXiv:2402.18322</a> [<a href="/pdf/2402.18322" title="Download PDF">pdf</a>, <a href="/ps/2402.18322" title="Download PostScript">ps</a>, <a href="/format/2402.18322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling novel insights into Kirchhoff migration for effective object  detection using experimental Fresnel dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Park%2C+W">Won-Kwang Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This study investigates the applicability of Kirchhoff migration (KM) for a
fast identification of unknown objects in a real-world limited-aperture inverse
scattering problem. To demonstrate the theoretical basis for the applicability
including unique determination of objects, the imaging function of the KM was
formulated using a uniformly convergent infinite series of Bessel functions of
integer order of the first kind based on the integral equation formula for the
scattered field. Numerical simulations performed using the experimental Fresnel
dataset are exhibited to achieve the theoretical results.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18323" title="Abstract">arXiv:2402.18323</a> [<a href="/pdf/2402.18323" title="Download PDF">pdf</a>, <a href="/format/2402.18323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equivalent Environments and Covering Spaces for Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weinstein%2C+V+K">Vadim K. Weinstein</a>, 
<a href="/search/cs?searchtype=author&query=LaValle%2C+S+M">Steven M. LaValle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Dynamical Systems (math.DS); General Topology (math.GN); Geometric Topology (math.GT)

</div>
<p class="mathjax">This paper formally defines a robot system, including its sensing and
actuation components, as a general, topological dynamical system. The focus is
on determining general conditions under which various environments in which the
robot can be placed are indistinguishable. A key result is that, under very
general conditions, covering maps witness such indistinguishability. This
formalizes the intuition behind the well studied loop closure problem in
robotics. An important special case is where the sensor mapping reports an
invariant of the local topological (metric) structure of an environment because
such structure is preserved by (metric) covering maps. Whereas coverings
provide a sufficient condition for the equivalence of environments, we also
give a necessary condition using bisimulation. The overall framework is applied
to unify previously identified phenomena in robotics and related fields, in
which moving agents with sensors must make inferences about their environments
based on limited data. Many open problems are identified.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18325" title="Abstract">arXiv:2402.18325</a> [<a href="/pdf/2402.18325" title="Download PDF">pdf</a>, <a href="/ps/2402.18325" title="Download PostScript">ps</a>, <a href="/format/2402.18325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robotising Psychometrics: Validating Wellbeing Assessment Tools in  Child-Robot Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abbasi%2C+N+I">Nida Itrat Abbasi</a>, 
<a href="/search/cs?searchtype=author&query=Laban%2C+G">Guy Laban</a>, 
<a href="/search/cs?searchtype=author&query=Ford%2C+T">Tamsin Ford</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+P+B">Peter B Jones</a>, 
<a href="/search/cs?searchtype=author&query=Gunes%2C+H">Hatice Gunes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">The interdisciplinary nature of Child-Robot Interaction (CRI) fosters
incorporating measures and methodologies from many established domains.
However, when employing CRI approaches to sensitive avenues of health and
wellbeing, caution is critical in adapting metrics to retain their safety
standards and ensure accurate utilisation. In this work, we conducted a
secondary analysis to previous empirical work, investigating the reliability
and construct validity of established psychological questionnaires such as the
Short Moods and Feelings Questionnaire (SMFQ) and three subscales (generalised
anxiety, panic and low mood) of the Revised Child Anxiety and Depression Scale
(RCADS) within a CRI setting for the assessment of mental wellbeing. Through
confirmatory principal component analysis, we have observed that these measures
are reliable and valid in the context of CRI. Furthermore, our analysis
revealed that scales communicated by a robot demonstrated a better fit than
when self-reported, underscoring the efficiency and effectiveness of
robot-mediated psychological assessments in these settings. Nevertheless, we
have also observed variations in item contributions to the main factor,
suggesting potential areas of examination and revision (e.g., relating to
physiological changes, inactivity and cognitive demands) when used in CRI.
Findings from this work highlight the importance of verifying the reliability
and validity of standardised metrics and assessment tools when employed in CRI
settings, thus, aiming to avoid any misinterpretations and misrepresentations.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18326" title="Abstract">arXiv:2402.18326</a> [<a href="/pdf/2402.18326" title="Download PDF">pdf</a>, <a href="/format/2402.18326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Should Algorithms Resign?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhatt%2C+U">Umang Bhatt</a>, 
<a href="/search/cs?searchtype=author&query=Sargeant%2C+H">Holli Sargeant</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper discusses algorithmic resignation, a strategic approach for
managing the use of AI systems within organizations. Algorithmic resignation
involves the deliberate and informed disengagement from AI assistance in
certain scenarios, by embedding governance mechanisms directly into AI systems.
Our proposal is not merely about disuse of AI but includes guiding when and how
these systems should be used or avoided. We discuss the multifaceted benefits
of algorithmic resignation, spanning economic efficiency, reputational gains,
and legal compliance. Further, we outline the operationalization of resignation
through various methods such as positive and negative nudges, stakeholder
incentive alignment, and careful consideration of the level of AI engagement.
Using techniques like barring access to AI outputs selectively or providing
explicit disclaimers on system performance, algorithmic resignation not only
mitigates risks associated with AI but also leverages its benefits, ensuring
the responsible and effective use of AI systems.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18329" title="Abstract">arXiv:2402.18329</a> [<a href="/pdf/2402.18329" title="Download PDF">pdf</a>, <a href="/format/2402.18329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Living-off-The-Land Reverse-Shell Detection by Informed Data  Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trizna%2C+D">Dmitrijs Trizna</a>, 
<a href="/search/cs?searchtype=author&query=Demetrio%2C+L">Luca Demetrio</a>, 
<a href="/search/cs?searchtype=author&query=Biggio%2C+B">Battista Biggio</a>, 
<a href="/search/cs?searchtype=author&query=Roli%2C+F">Fabio Roli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The living-off-the-land (LOTL) offensive methodologies rely on the
perpetration of malicious actions through chains of commands executed by
legitimate applications, identifiable exclusively by analysis of system logs.
LOTL techniques are well hidden inside the stream of events generated by common
legitimate activities, moreover threat actors often camouflage activity through
obfuscation, making them particularly difficult to detect without incurring in
plenty of false alarms, even using machine learning. To improve the performance
of models in such an harsh environment, we propose an augmentation framework to
enhance and diversify the presence of LOTL malicious activity inside legitimate
logs. Guided by threat intelligence, we generate a dataset by injecting attack
templates known to be employed in the wild, further enriched by malleable
patterns of legitimate activities to replicate the behavior of evasive threat
actors. We conduct an extensive ablation study to understand which models
better handle our augmented dataset, also manipulated to mimic the presence of
model-agnostic evasion and poisoning attacks. Our results suggest that
augmentation is needed to maintain high-predictive capabilities, robustness to
attack is achieved through specific hardening techniques like adversarial
training, and it is possible to deploy near-real-time models with almost-zero
false alarms.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18330" title="Abstract">arXiv:2402.18330</a> [<a href="/pdf/2402.18330" title="Download PDF">pdf</a>, <a href="/format/2402.18330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-Propagation Network for Egocentric Heatmap to 3D Pose Lifting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+T">Taeho Kang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Youngki Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures, to be published as CVPR 2024 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present EgoTAP, a heatmap-to-3D pose lifting method for highly accurate
stereo egocentric 3D pose estimation. Severe self-occlusion and out-of-view
limbs in egocentric camera views make accurate pose estimation a challenging
problem. To address the challenge, prior methods employ joint
heatmaps-probabilistic 2D representations of the body pose, but heatmap-to-3D
pose conversion still remains an inaccurate process. We propose a novel
heatmap-to-3D lifting method composed of the Grid ViT Encoder and the
Propagation Network. The Grid ViT Encoder summarizes joint heatmaps into
effective feature embedding using self-attention. Then, the Propagation Network
estimates the 3D pose by utilizing skeletal information to better estimate the
position of obscure joints. Our method significantly outperforms the previous
state-of-the-art qualitatively and quantitatively demonstrated by a 23.9\%
reduction of error in an MPJPE metric. Our source code is available in GitHub.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18331" title="Abstract">arXiv:2402.18331</a> [<a href="/pdf/2402.18331" title="Download PDF">pdf</a>, <a href="/format/2402.18331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FineDiffusion: Scaling up Diffusion Models for Fine-grained Image  Generation with 10,000 Classes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Ziying Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gang Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+F">Feihong He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiwang Li</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yongxuan Lai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The class-conditional image generation based on diffusion models is renowned
for generating high-quality and diverse images. However, most prior efforts
focus on generating images for general categories, e.g., 1000 classes in
ImageNet-1k. A more challenging task, large-scale fine-grained image
generation, remains the boundary to explore. In this work, we present a
parameter-efficient strategy, called FineDiffusion, to fine-tune large
pre-trained diffusion models scaling to large-scale fine-grained image
generation with 10,000 categories. FineDiffusion significantly accelerates
training and reduces storage overhead by only fine-tuning tiered class
embedder, bias terms, and normalization layers' parameters. To further improve
the image generation quality of fine-grained categories, we propose a novel
sampling method for fine-grained image generation, which utilizes
superclass-conditioned guidance, specifically tailored for fine-grained
categories, to replace the conventional classifier-free guidance sampling.
Compared to full fine-tuning, FineDiffusion achieves a remarkable 1.56x
training speed-up and requires storing merely 1.77% of the total model
parameters, while achieving state-of-the-art FID of 9.776 on image generation
of 10,000 classes. Extensive qualitative and quantitative experiments
demonstrate the superiority of our method compared to other parameter-efficient
fine-tuning methods. The code and more generated results are available at our
project website: https://finediffusion.github.io/.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18334" title="Abstract">arXiv:2402.18334</a> [<a href="/pdf/2402.18334" title="Download PDF">pdf</a>, <a href="/format/2402.18334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Generate Instruction Tuning Datasets for Zero-Shot Task  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nayak%2C+N+V">Nihal V. Nayak</a>, 
<a href="/search/cs?searchtype=author&query=Nan%2C+Y">Yiyang Nan</a>, 
<a href="/search/cs?searchtype=author&query=Trost%2C+A">Avi Trost</a>, 
<a href="/search/cs?searchtype=author&query=Bach%2C+S+H">Stephen H. Bach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce Bonito, an open-source model for conditional task generation:
the task of converting unannotated text into task-specific training datasets
for instruction tuning. Our goal is to enable zero-shot task adaptation of
large language models on users' specialized, private data. We train Bonito on a
new large-scale dataset with 1.65M examples created by remixing existing
instruction tuning datasets into meta-templates. The meta-templates for a
dataset produce training examples where the input is the unannotated text and
the task attribute and the output consists of the instruction and the response.
We use Bonito to generate synthetic tasks for seven datasets from specialized
domains across three task types -- yes-no question answering, extractive
question answering, and natural language inference -- and adapt language
models. We show that Bonito significantly improves the average performance of
pretrained and instruction tuned models over the de facto self supervised
baseline. For example, adapting Mistral-Instruct-v2 and instruction tuned
variants of Mistral and Llama2 with Bonito improves the strong zero-shot
performance by 22.1 F1 points whereas the next word prediction objective undoes
some of the benefits of instruction tuning and reduces the average performance
by 0.8 F1 points. We conduct additional experiments with Bonito to understand
the effects of the domain, the size of the training set, and the choice of
alternative synthetic task generators. Overall, we show that learning with
synthetic instruction tuning datasets is an effective way to adapt language
models to new domains. The model, dataset, and code are available at
https://github.com/BatsResearch/bonito.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18335" title="Abstract">arXiv:2402.18335</a> [<a href="/pdf/2402.18335" title="Download PDF">pdf</a>, <a href="/format/2402.18335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Anti-vaccine Content on Twitter using Multiple Message-Based  Network Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ashford%2C+J+R">James R. Ashford</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Social media platforms such as Twitter have a fundamental role in
facilitating the spread and discussion of ideas online through the concept of
retweeting and replying. However, these features also contribute to the spread
of mis/disinformation during the vaccine rollout of the COVID-19 pandemic.
Using COVID-19 vaccines as a case study, we analyse multiple social network
representation derived from three message-based interactions on Twitter (quote
retweets, mentions and replies) based upon a set of known anti-vax hashtags and
keywords. Each network represents a certain hashtag or keyword which were
labelled as "controversial" and "non-controversial" according to a small group
of participants. For each network, we extract a combination of global and local
network-based metrics which are used as feature vectors for binary
classification. Our results suggest that it is possible to detect controversial
from non-controversial terms with high accuracy using simple network-based
metrics. Furthermore, these results demonstrate the potential of network
representations as language-agnostic models for detecting mis/disinformation at
scale, irrespective of content and across multiple social media platforms.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18337" title="Abstract">arXiv:2402.18337</a> [<a href="/pdf/2402.18337" title="Download PDF">pdf</a>, <a href="/format/2402.18337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Bayesian optimal experimental design using conditional  normalizing flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Orozco%2C+R">Rafael Orozco</a>, 
<a href="/search/cs?searchtype=author&query=Herrmann%2C+F+J">Felix J. Herrmann</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Bayesian optimal experimental design (OED) seeks to conduct the most
informative experiment under budget constraints to update the prior knowledge
of a system to its posterior from the experimental data in a Bayesian
framework. Such problems are computationally challenging because of (1)
expensive and repeated evaluation of some optimality criterion that typically
involves a double integration with respect to both the system parameters and
the experimental data, (2) suffering from the curse-of-dimensionality when the
system parameters and design variables are high-dimensional, (3) the
optimization is combinatorial and highly non-convex if the design variables are
binary, often leading to non-robust designs. To make the solution of the
Bayesian OED problem efficient, scalable, and robust for practical
applications, we propose a novel joint optimization approach. This approach
performs simultaneous (1) training of a scalable conditional normalizing flow
(CNF) to efficiently maximize the expected information gain (EIG) of a jointly
learned experimental design (2) optimization of a probabilistic formulation of
the binary experimental design with a Bernoulli distribution. We demonstrate
the performance of our proposed method for a practical MRI data acquisition
problem, one of the most challenging Bayesian OED problems that has
high-dimensional (320 $\times$ 320) parameters at high image resolution,
high-dimensional (640 $\times$ 386) observations, and binary mask designs to
select the most informative observations.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18339" title="Abstract">arXiv:2402.18339</a> [<a href="/pdf/2402.18339" title="Download PDF">pdf</a>, <a href="/format/2402.18339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Edge Coloring is (Nearly) as Easy as Offline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blikstad%2C+J">Joakim Blikstad</a>, 
<a href="/search/cs?searchtype=author&query=Svensson%2C+O">Ola Svensson</a>, 
<a href="/search/cs?searchtype=author&query=Vintan%2C+R">Radu Vintan</a>, 
<a href="/search/cs?searchtype=author&query=Wajc%2C+D">David Wajc</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, to appear in STOC'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">The classic theorem of Vizing (Diskret. Analiz.'64) asserts that any graph of
maximum degree $\Delta$ can be edge colored (offline) using no more than
$\Delta+1$ colors (with $\Delta$ being a trivial lower bound). In the online
setting, Bar-Noy, Motwani and Naor (IPL'92) conjectured that a
$(1+o(1))\Delta$-edge-coloring can be computed online in $n$-vertex graphs of
maximum degree $\Delta=\omega(\log n)$. Numerous algorithms made progress on
this question, using a higher number of colors or assuming restricted arrival
models, such as random-order edge arrivals or vertex arrivals (e.g., AGKM
FOCS'03, BMM SODA'10, CPW FOCS'19, BGW SODA'21, KLSST STOC'22). In this work,
we resolve this longstanding conjecture in the affirmative in the most general
setting of adversarial edge arrivals. We further generalize this result to
obtain online counterparts of the list edge coloring result of Kahn (J. Comb.
Theory. A'96) and of the recent "local" edge coloring result of Christiansen
(STOC'23).
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18344" title="Abstract">arXiv:2402.18344</a> [<a href="/pdf/2402.18344" title="Download PDF">pdf</a>, <a href="/format/2402.18344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Focus on Your Question! Interpreting and Mitigating Toxic CoT Problems  in Commonsense Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiachun Li</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+P">Pengfei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhuoran Jin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yubo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+D">Daojian Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models exhibit high-level commonsense reasoning abilities,
especially with enhancement methods like Chain-of-Thought (CoT). However, we
find these CoT-like methods lead to a considerable number of originally correct
answers turning wrong, which we define as the Toxic CoT problem. To interpret
and mitigate this problem, we first utilize attribution tracing and causal
tracing methods to probe the internal working mechanism of the LLM during CoT
reasoning. Through comparisons, we prove that the model exhibits information
loss from the question over the shallow attention layers when generating
rationales or answers. Based on the probing findings, we design a novel method
called RIDERS (Residual decodIng and sERial-position Swap), which compensates
for the information deficit in the model from both decoding and serial-position
perspectives. Through extensive experiments on multiple commonsense reasoning
benchmarks, we validate that this method not only significantly eliminates
Toxic CoT problems (decreased by 23.6%), but also effectively improves the
model's overall commonsense reasoning performance (increased by 5.5%).
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18345" title="Abstract">arXiv:2402.18345</a> [<a href="/pdf/2402.18345" title="Download PDF">pdf</a>, <a href="/format/2402.18345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Multi-Entity Robotic Problems Using Permutation Invariant Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+T">Tianxu An</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Joonho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Bjelonic%2C+M">Marko Bjelonic</a>, 
<a href="/search/cs?searchtype=author&query=De+Vincenti%2C+F">Flavio De Vincenti</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+M">Marco Hutter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Challenges in real-world robotic applications often stem from managing
multiple, dynamically varying entities such as neighboring robots, manipulable
objects, and navigation goals. Existing multi-agent control strategies face
scalability limitations, struggling to handle arbitrary numbers of entities.
Additionally, they often rely on engineered heuristics for assigning entities
among agents. We propose a data driven approach to address these limitations by
introducing a decentralized control system using neural network policies
trained in simulation. Leveraging permutation invariant neural network
architectures and model-free reinforcement learning, our approach allows
control agents to autonomously determine the relative importance of different
entities without being biased by ordering or limited by a fixed capacity. We
validate our approach through both simulations and real-world experiments
involving multiple wheeled-legged quadrupedal robots, demonstrating their
collaborative control capabilities. We prove the effectiveness of our
architectural choice through experiments with three exemplary multi-entity
problems. Our analysis underscores the pivotal role of the end-to-end trained
permutation invariant encoders in achieving scalability and improving the task
performance in multi-object manipulation or multi-goal navigation problems. The
adaptability of our policy is further evidenced by its ability to manage
varying numbers of entities in a zero-shot manner, showcasing near-optimal
autonomous task distribution and collision avoidance behaviors.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18351" title="Abstract">arXiv:2402.18351</a> [<a href="/pdf/2402.18351" title="Download PDF">pdf</a>, <a href="/format/2402.18351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LatentSwap: An Efficient Latent Code Mapping Framework for Face Swapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+C">Changho Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minho Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Junhyeok Lee</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hyoung-Kyu Song</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Younggeun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungryong Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose LatentSwap, a simple face swapping framework generating a face
swap latent code of a given generator. Utilizing randomly sampled latent codes,
our framework is light and does not require datasets besides employing the
pre-trained models, with the training procedure also being fast and
straightforward. The loss objective consists of only three terms, and can
effectively control the face swap results between source and target images. By
attaching a pre-trained GAN inversion model independent to the model and using
the StyleGAN2 generator, our model produces photorealistic and high-resolution
images comparable to other competitive face swap models. We show that our
framework is applicable to other generators such as StyleNeRF, paving a way to
3D-aware face swapping and is also compatible with other downstream StyleGAN2
generator tasks. The source code and models can be found at
\url{https://github.com/usingcolor/LatentSwap}.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18352" title="Abstract">arXiv:2402.18352</a> [<a href="/pdf/2402.18352" title="Download PDF">pdf</a>, <a href="/format/2402.18352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial-time approximation schemes for induced subgraph problems on  fractionally tree-independence-number-fragile graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Galby%2C+E">Esther Galby</a>, 
<a href="/search/cs?searchtype=author&query=Munaro%2C+A">Andrea Munaro</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shizhou Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, 8 figures. arXiv admin note: substantial text overlap with <a href="/abs/2303.07444">arXiv:2303.07444</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Geometry (cs.CG); Combinatorics (math.CO)

</div>
<p class="mathjax">We investigate a relaxation of the notion of fractional treewidth-fragility,
namely fractional tree-independence-number-fragility. In particular, we obtain
polynomial-time approximation schemes for meta-problems such as finding a
maximum-weight sparse induced subgraph satisfying a given $\mathsf{CMSO}_2$
formula on fractionally tree-independence-number-fragile graph classes. Our
approach unifies and extends several known polynomial-time approximation
schemes on seemingly unrelated graph classes, such as classes of intersection
graphs of fat objects in a fixed dimension or proper minor-closed classes. We
also study the related notion of layered tree-independence number, a relaxation
of layered treewidth, and its applications to exact subexponential-time
algorithms.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18355" title="Abstract">arXiv:2402.18355</a> [<a href="/pdf/2402.18355" title="Download PDF">pdf</a>, <a href="/ps/2402.18355" title="Download PostScript">ps</a>, <a href="/format/2402.18355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DynaWarp -- Efficient, large-scale log storage and retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reichinger%2C+J">Julian Reichinger</a>, 
<a href="/search/cs?searchtype=author&query=Krismayer%2C+T">Thomas Krismayer</a>, 
<a href="/search/cs?searchtype=author&query=Rellermeyer%2C+J">Jan Rellermeyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Databases (cs.DB); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Modern, large scale monitoring systems have to process and store vast amounts
of log data in near real-time. At query time the systems have to find relevant
logs based on the content of the log message using support structures that can
scale to these amounts of data while still being efficient to use. We present
our novel DynaWarp membership sketch, capable of answering Multi-Set
Multi-Membership-Queries, that can be used as an alternative to existing
indexing structures for streamed log data. In our experiments, DynaWarp
required up to 93% less storage space than the tested state-of-the-art inverted
index and had up to four orders of magnitude less false-positives than the
tested state-of-the-art membership sketch. Additionally, DynaWarp achieved up
to 250 times higher query throughput than the tested inverted index and up to
240 times higher query throughput than the tested membership sketch.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18360" title="Abstract">arXiv:2402.18360</a> [<a href="/pdf/2402.18360" title="Download PDF">pdf</a>, <a href="/ps/2402.18360" title="Download PostScript">ps</a>, <a href="/format/2402.18360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Similarity-based analogical proportions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anti%C4%87%2C+C">Christian Anti&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI); Logic (math.LO)

</div>
<p class="mathjax">The author has recently introduced abstract algebraic frameworks of
analogical proportions and similarity within the general setting of universal
algebra. The purpose of this paper is to build a bridge from similarity to
analogical proportions by formulating the latter in terms of the former. The
benefit of this similarity-based approach is that the connection between
proportions and similarity is built into the framework and therefore evident
which is appealing since proportions and similarity are both at the center of
analogy; moreover, future results on similarity can directly be applied to
analogical proportions.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18362" title="Abstract">arXiv:2402.18362</a> [<a href="/pdf/2402.18362" title="Download PDF">pdf</a>, <a href="/format/2402.18362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Objective and Interpretable Breast Cosmesis Evaluation with Attention  Guided Denoising Diffusion Anomaly Detection Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sangjoon Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y+B">Yong Bae Kim</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+J+S">Jee Suk Chang</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S+H">Seo Hee Choi</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+H">Hyungjin Chung</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+I+J">Ik Jae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Byun%2C+H+K">Hwa Kyung Byun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As advancements in the field of breast cancer treatment continue to progress,
the assessment of post-surgical cosmetic outcomes has gained increasing
significance due to its substantial impact on patients' quality of life.
However, evaluating breast cosmesis presents challenges due to the inherently
subjective nature of expert labeling. In this study, we present a novel
automated approach, Attention-Guided Denoising Diffusion Anomaly Detection
(AG-DDAD), designed to assess breast cosmesis following surgery, addressing the
limitations of conventional supervised learning and existing anomaly detection
models. Our approach leverages the attention mechanism of the distillation with
no label (DINO) self-supervised Vision Transformer (ViT) in combination with a
diffusion model to achieve high-quality image reconstruction and precise
transformation of discriminative regions. By training the diffusion model on
unlabeled data predominantly with normal cosmesis, we adopt an unsupervised
anomaly detection perspective to automatically score the cosmesis. Real-world
data experiments demonstrate the effectiveness of our method, providing
visually appealing representations and quantifiable scores for cosmesis
evaluation. Compared to commonly used rule-based programs, our fully automated
approach eliminates the need for manual annotations and offers objective
evaluation. Moreover, our anomaly detection model exhibits state-of-the-art
performance, surpassing existing models in accuracy. Going beyond the scope of
breast cosmesis, our research represents a significant advancement in
unsupervised anomaly detection within the medical domain, thereby paving the
way for future investigations.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18365" title="Abstract">arXiv:2402.18365</a> [<a href="/pdf/2402.18365" title="Download PDF">pdf</a>, <a href="/format/2402.18365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Token-based Vehicular Security System (TVSS): Scalable, Secure,  Low-latency Public Key Infrastructure for Connected Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rabiah%2C+A+B">Abdulrahman Bin Rabiah</a>, 
<a href="/search/cs?searchtype=author&query=Alsoliman%2C+A">Anas Alsoliman</a>, 
<a href="/search/cs?searchtype=author&query=Shashwat%2C+Y">Yugarshi Shashwat</a>, 
<a href="/search/cs?searchtype=author&query=Richelson%2C+S">Silas Richelson</a>, 
<a href="/search/cs?searchtype=author&query=Abu-Ghazaleh%2C+N">Nael Abu-Ghazaleh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Connected and Autonomous vehicles stand to drastically improve the safety and
efficiency of the transportation system in the near future while also reducing
pollution. These systems leverage communication to coordinate among vehicles
and infrastructure in service of a number of safety and efficiency driver
assist and even fully autonomous applications. Attackers can compromise these
systems in a number of ways including by falsifying communication messages,
making it critical to support security mechanisms that can operate and scale in
dynamic scenarios. Towards this end, we present TVSS, a new VPKI system which
improves drastically over prior work in the area (including over SCMS; the US
department of transportation standard for VPKI). TVSS leverages the idea of
unforgeable tokens to enable rapid verification at the road side units (RSUs),
which are part of the road infrastructure at the edge of the network. This edge
based solution enables agile authentication by avoiding the need for back-end
servers during the potentially short contact time between a moving vehicle and
the infrastructure. It also results in several security advantages: (1)
Scalable Revocation: it greatly simplifies the revocation problem, a difficult
problem in large scale certificate systems; and (2) Faster Refresh: Vehicles
interact more frequently with the system to refresh their credentials,
improving the privacy of the system. We provide a construction of the system
and formally prove its security. Field experiments on a test-bed we develop
consisting of on-board units (OBUs) and RSUs shows substantial reduction in the
latency of refreshing credentials compared to SCMS, allowing the system to work
even with smaller window of connectivity when vehicles are moving at higher
speeds. Notably, we are able to execute the bottleneck operation of our scheme
with a stationary RSU while traveling at highway speeds .
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18370" title="Abstract">arXiv:2402.18370</a> [<a href="/pdf/2402.18370" title="Download PDF">pdf</a>, <a href="/format/2402.18370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial example soups: averaging multiple adversarial examples  improves transferability without increasing additional generation time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hengwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jindong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 8 figures, 12 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">For transfer-based attacks, the adversarial examples are crafted on the
surrogate model, which can be implemented to mislead the target model
effectively. The conventional method for maximizing adversarial transferability
involves: (1) fine-tuning hyperparameters to generate multiple batches of
adversarial examples on the substitute model; (2) conserving the batch of
adversarial examples that have the best comprehensive performance on substitute
model and target model, and discarding the others. In this work, we revisit the
second step of this process in the context of fine-tuning hyperparameters to
craft adversarial examples, where multiple batches of fine-tuned adversarial
examples often appear in a single high error hilltop. We demonstrate that
averaging multiple batches of adversarial examples under different
hyperparameter configurations, which refers to as "adversarial example soups",
can often enhance adversarial transferability. Compared with traditional
methods, the proposed method incurs no additional generation time and
computational cost. Besides, our method is orthogonal to existing
transfer-based methods and can be combined with them seamlessly to generate
more transferable adversarial examples. Extensive experiments on the ImageNet
dataset show that our methods achieve a higher attack success rate than the
state-of-the-art attacks.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18372" title="Abstract">arXiv:2402.18372</a> [<a href="/pdf/2402.18372" title="Download PDF">pdf</a>, <a href="/format/2402.18372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedUV: Uniformity and Variance for Heterogeneous Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Son%2C+H+M">Ha Min Son</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M+H">Moon Hyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+T">Tai-Myoung Chung</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures, 5 tables, to appear at CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated learning is a promising framework to train neural networks with
widely distributed data. However, performance degrades heavily with
heterogeneously distributed data. Recent work has shown this is due to the
final layer of the network being most prone to local bias, some finding success
freezing the final layer as an orthogonal classifier. We investigate the
training dynamics of the classifier by applying SVD to the weights motivated by
the observation that freezing weights results in constant singular values. We
find that there are differences when training in IID and non-IID settings.
Based on this finding, we introduce two regularization terms for local training
to continuously emulate IID settings: (1) variance in the dimension-wise
probability distribution of the classifier and (2) hyperspherical uniformity of
representations of the encoder. These regularizations promote local models to
act as if it were in an IID setting regardless of the local data distribution,
thus offsetting proneness to bias while being flexible to the data. On
extensive experiments in both label-shift and feature-shift settings, we verify
that our method achieves highest performance by a large margin especially in
highly non-IID cases in addition to being scalable to larger models and
datasets.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18374" title="Abstract">arXiv:2402.18374</a> [<a href="/pdf/2402.18374" title="Download PDF">pdf</a>, <a href="/format/2402.18374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VerifiNER: Verification-augmented NER via Knowledge-grounded Reasoning  with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seoyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+K">Kwangwook Seo</a>, 
<a href="/search/cs?searchtype=author&query=Chae%2C+H">Hyungjoo Chae</a>, 
<a href="/search/cs?searchtype=author&query=Yeo%2C+J">Jinyoung Yeo</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongha Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent approaches in domain-specific named entity recognition (NER), such as
biomedical NER, have shown remarkable advances. However, they still lack of
faithfulness, producing erroneous predictions. We assume that knowledge of
entities can be useful in verifying the correctness of the predictions. Despite
the usefulness of knowledge, resolving such errors with knowledge is
nontrivial, since the knowledge itself does not directly indicate the
ground-truth label. To this end, we propose VerifiNER, a post-hoc verification
framework that identifies errors from existing NER methods using knowledge and
revises them into more faithful predictions. Our framework leverages the
reasoning abilities of large language models to adequately ground on knowledge
and the contextual information in the verification process. We validate
effectiveness of VerifiNER through extensive experiments on biomedical
datasets. The results suggest that VerifiNER can successfully verify errors
from existing models as a model-agnostic approach. Further analyses on
out-of-domain and low-resource settings show the usefulness of VerifiNER on
real-world applications.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18375" title="Abstract">arXiv:2402.18375</a> [<a href="/pdf/2402.18375" title="Download PDF">pdf</a>, <a href="/format/2402.18375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Modeling of Software Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cabot%2C+J">Jordi Cabot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">There is a growing need for better development methods and tools to keep up
with the increasing complexity of new software systems. New types of user
interfaces, the need for intelligent components, sustainability concerns, ...
bring new challenges that we need to handle. In the last years, model-driven
engineering has been key to improving the quality and productivity of software
development, but models themselves are becoming increasingly complex to specify
and manage. In this paper, we present the concept of low-modeling as a solution
to enhance current model-driven engineering techniques and get them ready for
this new generation of software systems.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18376" title="Abstract">arXiv:2402.18376</a> [<a href="/pdf/2402.18376" title="Download PDF">pdf</a>, <a href="/format/2402.18376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tokenization Is More Than Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+C+W">Craig W. Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+V">Varshini Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoran Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Alameddine%2C+A">Alec Alameddine</a>, 
<a href="/search/cs?searchtype=author&query=Uzan%2C+O">Omri Uzan</a>, 
<a href="/search/cs?searchtype=author&query=Pinter%2C+Y">Yuval Pinter</a>, 
<a href="/search/cs?searchtype=author&query=Tanner%2C+C">Chris Tanner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Tokenization is a foundational step in Natural Language Processing (NLP)
tasks, bridging raw text and language models. Existing tokenization approaches
like Byte-Pair Encoding (BPE) originate from the field of data compression, and
it has been suggested that the effectiveness of BPE stems from its ability to
condense text into a relatively small number of tokens. We test the hypothesis
that fewer tokens lead to better downstream performance by introducing
PathPiece, a new tokenizer that segments a document's text into the minimum
number of tokens for a given vocabulary. Through extensive experimentation we
find this hypothesis not to be the case, casting doubt on the understanding of
the reasons for effective tokenization. To examine which other factors play a
role, we evaluate design decisions across all three phases of tokenization:
pre-tokenization, vocabulary construction, and segmentation, offering new
insights into the design of effective tokenizers. Specifically, we illustrate
the importance of pre-tokenization and the benefits of using BPE to initialize
vocabulary construction. We train 64 language models with varying tokenization,
ranging in size from 350M to 2.4B parameters, all of which are made publicly
available.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18377" title="Abstract">arXiv:2402.18377</a> [<a href="/pdf/2402.18377" title="Download PDF">pdf</a>, <a href="/format/2402.18377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Out-of-Domain Generalization in Dynamical Systems Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C3%B6ring%2C+N">Niclas G&#xf6;ring</a>, 
<a href="/search/cs?searchtype=author&query=Hess%2C+F">Florian Hess</a>, 
<a href="/search/cs?searchtype=author&query=Brenner%2C+M">Manuel Brenner</a>, 
<a href="/search/cs?searchtype=author&query=Monfared%2C+Z">Zahra Monfared</a>, 
<a href="/search/cs?searchtype=author&query=Durstewitz%2C+D">Daniel Durstewitz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In science we are interested in finding the governing equations, the
dynamical rules, underlying empirical phenomena. While traditionally scientific
models are derived through cycles of human insight and experimentation,
recently deep learning (DL) techniques have been advanced to reconstruct
dynamical systems (DS) directly from time series data. State-of-the-art
dynamical systems reconstruction (DSR) methods show promise in capturing
invariant and long-term properties of observed DS, but their ability to
generalize to unobserved domains remains an open challenge. Yet, this is a
crucial property we would expect from any viable scientific theory. In this
work, we provide a formal framework that addresses generalization in DSR. We
explain why and how out-of-domain (OOD) generalization (OODG) in DSR profoundly
differs from OODG considered elsewhere in machine learning. We introduce
mathematical notions based on topological concepts and ergodic theory to
formalize the idea of learnability of a DSR model. We formally prove that
black-box DL techniques, without adequate structural priors, generally will not
be able to learn a generalizing DSR model. We also show this empirically,
considering major classes of DSR algorithms proposed so far, and illustrate
where and why they fail to generalize across the whole phase space. Our study
provides the first comprehensive mathematical treatment of OODG in DSR, and
gives a deeper conceptual understanding of where the fundamental problems in
OODG lie and how they could possibly be addressed in practice.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18380" title="Abstract">arXiv:2402.18380</a> [<a href="/pdf/2402.18380" title="Download PDF">pdf</a>, <a href="/ps/2402.18380" title="Download PostScript">ps</a>, <a href="/format/2402.18380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UKF-Based Sensor Fusion for Joint-Torque Sensorless Humanoid Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sorrentino%2C+I">Ines Sorrentino</a>, 
<a href="/search/cs?searchtype=author&query=Romualdi%2C+G">Giulio Romualdi</a>, 
<a href="/search/cs?searchtype=author&query=Pucci%2C+D">Daniele Pucci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper proposes a novel sensor fusion based on Unscented Kalman Filtering
for the online estimation of joint-torques of humanoid robots without
joint-torque sensors. At the feature level, the proposed approach considers
multimodal measurements (e.g. currents, accelerations, etc.) and non-directly
measurable effects, such as external contacts, thus leading to joint torques
readily usable in control architectures for human-robot interaction. The
proposed sensor fusion can also integrate distributed, non-collocated
force/torque sensors, thus being a flexible framework with respect to the
underlying robot sensor suit. To validate the approach, we show how the
proposed sensor fusion can be integrated into a twolevel torque control
architecture aiming at task-space torquecontrol. The performances of the
proposed approach are shown through extensive tests on the new humanoid robot
ergoCub, currently being developed at Istituto Italiano di Tecnologia. We also
compare our strategy with the existing state-of-theart approach based on the
recursive Newton-Euler algorithm. Results demonstrate that our method achieves
low root mean square errors in torque tracking, ranging from 0.05 Nm to 2.5 Nm,
even in the presence of external contacts.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18381" title="Abstract">arXiv:2402.18381</a> [<a href="/pdf/2402.18381" title="Download PDF">pdf</a>, <a href="/format/2402.18381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models As Evolution Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lange%2C+R+T">Robert Tjarko Lange</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yingtao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yujin Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Large Transformer models are capable of implementing a plethora of so-called
in-context learning algorithms. These include gradient descent, classification,
sequence completion, transformation, and improvement. In this work, we
investigate whether large language models (LLMs), which never explicitly
encountered the task of black-box optimization, are in principle capable of
implementing evolutionary optimization algorithms. While previous works have
solely focused on language-based task specification, we move forward and focus
on the zero-shot application of LLMs to black-box optimization. We introduce a
novel prompting strategy, consisting of least-to-most sorting of discretized
population members and querying the LLM to propose an improvement to the mean
statistic, i.e. perform a type of black-box recombination operation.
Empirically, we find that our setup allows the user to obtain an LLM-based
evolution strategy, which we call `EvoLLM', that robustly outperforms baseline
algorithms such as random search and Gaussian Hill Climbing on synthetic BBOB
functions as well as small neuroevolution tasks. Hence, LLMs can act as
`plug-in' in-context recombination operators. We provide several comparative
studies of the LLM's model size, prompt strategy, and context construction.
Finally, we show that one can flexibly improve EvoLLM's performance by
providing teacher algorithm information via instruction fine-tuning on
previously collected teacher optimization trajectories.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18383" title="Abstract">arXiv:2402.18383</a> [<a href="/pdf/2402.18383" title="Download PDF">pdf</a>, <a href="/ps/2402.18383" title="Download PostScript">ps</a>, <a href="/format/2402.18383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Quantification of Percent Emphysema on CT via Domain Attention:  the Multi-Ethnic Study of Atherosclerosis (MESA) Lung Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuzhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Angelini%2C+E+D">Elsa D. Angelini</a>, 
<a href="/search/cs?searchtype=author&query=Hoffman%2C+E+A">Eric A. Hoffman</a>, 
<a href="/search/cs?searchtype=author&query=Watson%2C+K+E">Karol E. Watson</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+B+M">Benjamin M. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Barr%2C+R+G">R. Graham Barr</a>, 
<a href="/search/cs?searchtype=author&query=Laine%2C+A+F">Andrew F. Laine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures. Accepted to IEEE International Symposium on Biomedical Imaging 2024 (ISBI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Robust quantification of pulmonary emphysema on computed tomography (CT)
remains challenging for large-scale research studies that involve scans from
different scanner types and for translation to clinical scans. Existing studies
have explored several directions to tackle this challenge, including density
correction, noise filtering, regression, hidden Markov measure field (HMMF)
model-based segmentation, and volume-adjusted lung density. Despite some
promising results, previous studies either required a tedious workflow or
limited opportunities for downstream emphysema subtyping, limiting efficient
adaptation on a large-scale study. To alleviate this dilemma, we developed an
end-to-end deep learning framework based on an existing HMMF segmentation
framework. We first demonstrate that a regular UNet cannot replicate the
existing HMMF results because of the lack of scanner priors. We then design a
novel domain attention block to fuse image feature with quantitative scanner
priors which significantly improves the results.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18385" title="Abstract">arXiv:2402.18385</a> [<a href="/pdf/2402.18385" title="Download PDF">pdf</a>, <a href="/format/2402.18385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The First Place Solution of WSDM Cup 2024: Leveraging Large Language  Models for Conversational Multi-Doc QA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiming Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 1st solution for WSDM Cup 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Conversational multi-doc question answering aims to answer specific questions
based on the retrieved documents as well as the contextual conversations. In
this paper, we introduce our winning approach for the "Conversational Multi-Doc
QA" challenge in WSDM Cup 2024, which exploits the superior natural language
understanding and generation capability of Large Language Models (LLMs). We
first adapt LLMs to the task, then devise a hybrid training strategy to make
the most of in-domain unlabeled data. Moreover, an advanced text embedding
model is adopted to filter out potentially irrelevant documents and several
approaches are designed and compared for the model ensemble. Equipped with all
these techniques, our solution finally ranked 1st place in WSDM Cup 2024,
surpassing its rivals to a large extent. The source codes have been released at
https://github.com/zhangzhao219/WSDM-Cup-2024.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18386" title="Abstract">arXiv:2402.18386</a> [<a href="/pdf/2402.18386" title="Download PDF">pdf</a>, <a href="/format/2402.18386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TrustRate: A Decentralized Platform for Hijack-Resistant Anonymous  Reviews
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dwivedula%2C+R">Rohit Dwivedula</a>, 
<a href="/search/cs?searchtype=author&query=Sridhar%2C+S">Sriram Sridhar</a>, 
<a href="/search/cs?searchtype=author&query=Satija%2C+S">Sambhav Satija</a>, 
<a href="/search/cs?searchtype=author&query=Sivathanu%2C+M">Muthian Sivathanu</a>, 
<a href="/search/cs?searchtype=author&query=Chandran%2C+N">Nishanth Chandran</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+D">Divya Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Lokam%2C+S">Satya Lokam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Reviews and ratings by users form a central component in several widely used
products today (e.g., product reviews, ratings of online content, etc.), but
today's platforms for managing such reviews are ad-hoc and vulnerable to
various forms of tampering and hijack by fake reviews either by bots or
motivated paid workers. We define a new metric called 'hijack-resistance' for
such review platforms, and then present TrustRate, an end-to-end decentralized,
hijack-resistant platform for authentic, anonymous, tamper-proof reviews. With
a prototype implementation and evaluation at the scale of thousands of nodes,
we demonstrate the efficacy and performance of our platform, towards a new
paradigm for building products based on trusted reviews by end users without
having to trust a single organization that manages the reviews.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18387" title="Abstract">arXiv:2402.18387</a> [<a href="/pdf/2402.18387" title="Download PDF">pdf</a>, <a href="/format/2402.18387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Precoding for Multi-Cell ISAC: from Coordinated Beamforming to  Coordinated Multipoint and Bi-Static Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Babu%2C+N">Nithin Babu</a>, 
<a href="/search/cs?searchtype=author&query=Masouros%2C+C">Christos Masouros</a>, 
<a href="/search/cs?searchtype=author&query=Papadias%2C+C+B">Constantinos B. Papadias</a>, 
<a href="/search/cs?searchtype=author&query=Eldar%2C+Y+C">Yonina C. Eldar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9 figures, subnitted to IEEE Trans. on Wireless Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper proposes a framework for designing robust precoders for a
multi-input single-output (MISO) system that performs integrated sensing and
communication (ISAC) across multiple cells and users. We use Cramer-Rao-Bound
(CRB) to measure the sensing performance and derive its expressions for two
multi-cell scenarios, namely coordinated beamforming (CBF) and coordinated
multi-point (CoMP). In the CBF scheme, a BS shares channel state information
(CSI) and estimates target parameters using monostatic sensing. In contrast, a
BS in the CoMP scheme shares the CSI and data, allowing bistatic sensing
through inter-cell reflection. We consider both block-level (BL) and
symbol-level (SL) precoding schemes for both the multi-cell scenarios that are
robust to channel state estimation errors. The formulated optimization problems
to minimize the CRB in estimating the parameters of a target and maximize the
minimum communication signal-to-interference-plus-noise-ratio (SINR) while
satisfying a given total transmit power budget are non-convex. We tackle the
non-convexity using a combination of semidefinite relaxation (SDR) and
alternating optimization (AO) techniques. Simulations suggest that neglecting
the inter-cell reflection and communication links degrades the performance of
an ISAC system. The CoMP scenario employing SL precoding performs the best,
whereas the BL precoding applied in the CBF scenario produces relatively high
estimation error for a given minimum SINR value.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18390" title="Abstract">arXiv:2402.18390</a> [<a href="/pdf/2402.18390" title="Download PDF">pdf</a>, <a href="/format/2402.18390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuromorphic Event-Driven Semantic Communication in Microgrids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diao%2C+X">Xiaoguang Diao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yubo Song</a>, 
<a href="/search/cs?searchtype=author&query=Sahoo%2C+S">Subham Sahoo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The manuscript has been accepted for publication in IEEE Transactions on Smart Grid
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Systems and Control (eess.SY)

</div>
<p class="mathjax">Synergies between advanced communications, computing and artificial
intelligence are unraveling new directions of coordinated operation and
resiliency in microgrids. On one hand, coordination among sources is
facilitated by distributed, privacy-minded processing at multiple locations,
whereas on the other hand, it also creates exogenous data arrival paths for
adversaries that can lead to cyber-physical attacks amongst other reliability
issues in the communication layer. This long-standing problem necessitates new
intrinsic ways of exchanging information between converters through power lines
to optimize the system's control performance. Going beyond the existing power
and data co-transfer technologies that are limited by efficiency and
scalability concerns, this paper proposes neuromorphic learning to implant
communicative features using spiking neural networks (SNNs) at each node, which
is trained collaboratively in an online manner simply using the power exchanges
between the nodes. As opposed to the conventional neuromorphic sensors that
operate with spiking signals, we employ an event-driven selective process to
collect sparse data for training of SNNs. Finally, its multi-fold effectiveness
and reliable performance is validated under simulation conditions with
different microgrid topologies and components to establish a new direction in
the sense-actuate-compute cycle for power electronic dominated grids and
microgrids.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18391" title="Abstract">arXiv:2402.18391</a> [<a href="/pdf/2402.18391" title="Download PDF">pdf</a>, <a href="/format/2402.18391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sound Concurrent Traces for Online Monitoring Technical Report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soueidi%2C+C">Chukri Soueidi</a>, 
<a href="/search/cs?searchtype=author&query=Falcone%2C+Y">Ylies Falcone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Monitoring concurrent programs typically rely on collecting traces to
abstract program executions. However, existing approaches targeting general
behavioral properties are either not tailored for online monitoring, are no
longer maintained, or implement naive instrumentation that often leads to
unsound verdicts. We first define the notion of when a trace is representative
of a concurrent execution. We then present a non-blocking vector clock
algorithm to collect sound concurrent traces on the fly reflecting the partial
order between events. Moreover, concurrent events in the representative trace
pose a soundness problem for monitors synthesized from total order formalisms.
For this, we extract a causal dependence relation from the monitor to check if
the trace has the needed orderings and define the conditions to decide at
runtime when a collected trace is monitorable. We implement our contributions
in a tool, FACTS, which instruments programs compiling to Java bytecode,
constructs sound representative traces, and warns the monitor about
non-monitorable traces. We evaluate our work and compare it with existing
approaches.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18392" title="Abstract">arXiv:2402.18392</a> [<a href="/pdf/2402.18392" title="Download PDF">pdf</a>, <a href="/format/2402.18392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling the Potential of Robustness in Evaluating Causal Inference  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiyan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Leung%2C+C+H">Cheuk Hang Leung</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yijun Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Econometrics (econ.EM); Machine Learning (stat.ML)

</div>
<p class="mathjax">The growing demand for personalized decision-making has led to a surge of
interest in estimating the Conditional Average Treatment Effect (CATE). The
intersection of machine learning and causal inference has yielded various
effective CATE estimators. However, deploying these estimators in practice is
often hindered by the absence of counterfactual labels, making it challenging
to select the desirable CATE estimator using conventional model selection
procedures like cross-validation. Existing approaches for CATE estimator
selection, such as plug-in and pseudo-outcome metrics, face two inherent
challenges. Firstly, they are required to determine the metric form and the
underlying machine learning models for fitting nuisance parameters or plug-in
learners. Secondly, they lack a specific focus on selecting a robust estimator.
To address these challenges, this paper introduces a novel approach, the
Distributionally Robust Metric (DRM), for CATE estimator selection. The
proposed DRM not only eliminates the need to fit additional models but also
excels at selecting a robust CATE estimator. Experimental studies demonstrate
the efficacy of the DRM method, showcasing its consistent effectiveness in
identifying superior estimators while mitigating the risk of selecting inferior
ones.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18393" title="Abstract">arXiv:2402.18393</a> [<a href="/pdf/2402.18393" title="Download PDF">pdf</a>, <a href="/format/2402.18393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Decision Optimality of Autonomous Driving via Metamorphic  Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Mingfei Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaofei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+G">Guozhu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kairui Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Neural and Evolutionary Computing (cs.NE); Robotics (cs.RO); Software Engineering (cs.SE)

</div>
<p class="mathjax">Autonomous Driving System (ADS) testing is crucial in ADS development, with
the current primary focus being on safety. However, the evaluation of
non-safety-critical performance, particularly the ADS's ability to make optimal
decisions and produce optimal paths for autonomous vehicles (AVs), is equally
vital to ensure the intelligence and reduce risks of AVs. Currently, there is
little work dedicated to assessing ADSs' optimal decision-making performance
due to the lack of corresponding oracles and the difficulty in generating
scenarios with non-optimal decisions. In this paper, we focus on evaluating the
decision-making quality of an ADS and propose the first method for detecting
non-optimal decision scenarios (NoDSs), where the ADS does not compute optimal
paths for AVs. Firstly, to deal with the oracle problem, we propose a novel
metamorphic relation (MR) aimed at exposing violations of optimal decisions.
The MR identifies the property that the ADS should retain optimal decisions
when the optimal path remains unaffected by non-invasive changes. Subsequently,
we develop a new framework, Decictor, designed to generate NoDSs efficiently.
Decictor comprises three main components: Non-invasive Mutation, MR Check, and
Feedback. The Non-invasive Mutation ensures that the original optimal path in
the mutated scenarios is not affected, while the MR Check is responsible for
determining whether non-optimal decisions are made. To enhance the
effectiveness of identifying NoDSs, we design a feedback metric that combines
both spatial and temporal aspects of the AV's movement. We evaluate Decictor on
Baidu Apollo, an open-source and production-grade ADS. The experimental results
validate the effectiveness of Decictor in detecting non-optimal decisions of
ADSs. Our work provides valuable and original insights into evaluating the
non-safety-critical performance of ADSs.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18394" title="Abstract">arXiv:2402.18394</a> [<a href="/pdf/2402.18394" title="Download PDF">pdf</a>, <a href="/format/2402.18394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-IMU State Estimation for Relative Localization of Two Mobile Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+W">Wenqian Lai</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Ruonan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K+J">Kejian J. Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this paper, we address the problem of relative localization of two mobile
agents. Specifically, we consider the Dual-IMU system, where each agent is
equipped with one IMU, and employs relative pose observations between them.
Previous works, however, typically assumed known ego motion and ignored biases
of the IMUs. Instead, we study the most general case of unknown biases for both
IMUs. Besides the derivation of dynamic model equations of the proposed system,
we focus on the observability analysis, for the observability under general
motion and the unobservable directions arising from various special motions.
Through numerical simulations, we validate our key observability findings and
examine their impact on the estimation accuracy and consistency. Finally, the
system is implemented to achieve effective relative localization of an HMD with
respect to a vehicle moving in the real world.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18397" title="Abstract">arXiv:2402.18397</a> [<a href="/pdf/2402.18397" title="Download PDF">pdf</a>, <a href="/format/2402.18397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decomposed Prompting: Unveiling Multilingual Linguistic Structure  Knowledge in English-Centric Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nie%2C+E">Ercong Nie</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+S">Shuzhou Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+B">Bolei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+H">Helmut Schmid</a>, 
<a href="/search/cs?searchtype=author&query=F%C3%A4rber%2C+M">Michael F&#xe4;rber</a>, 
<a href="/search/cs?searchtype=author&query=Kreuter%2C+F">Frauke Kreuter</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%BCtze%2C+H">Hinrich Sch&#xfc;tze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Despite the predominance of English in their training data, English-centric
Large Language Models (LLMs) like GPT-3 and LLaMA display a remarkable ability
to perform multilingual tasks, raising questions about the depth and nature of
their cross-lingual capabilities. This paper introduces the decomposed
prompting approach to probe the linguistic structure understanding of these
LLMs in sequence labeling tasks. Diverging from the single text-to-text prompt,
our method generates for each token of the input sentence an individual prompt
which asks for its linguistic label. We assess our method on the Universal
Dependencies part-of-speech tagging dataset for 38 languages, utilizing both
English-centric and multilingual LLMs. Our findings show that decomposed
prompting surpasses the iterative prompting baseline in efficacy and efficiency
under zero- and few-shot settings. Further analysis reveals the influence of
evaluation methods and the use of instructions in prompts. Our multilingual
investigation shows that English-centric language models perform better on
average than multilingual models. Our study offers insights into the
multilingual transferability of English-centric LLMs, contributing to the
understanding of their multilingual linguistic knowledge.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18400" title="Abstract">arXiv:2402.18400</a> [<a href="/pdf/2402.18400" title="Download PDF">pdf</a>, <a href="/format/2402.18400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balanced Similarity with Auxiliary Prompts: Towards Alleviating  Text-to-Image Retrieval Bias for CLIP in Zero-shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanyao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Y">Yibing Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Liu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Liang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jun Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">CLIP has the ability to align texts and images and is nearly the most
frequently used foundation model in cross-modal zero-shot learning. However,
our experimental findings reveal that CLIP suffers from a bias in text-to-image
retrieval, resulting in a decrease in CLIP's zero-shot learning performance. We
analytically discover that the bias partly arises from the imbalanced range of
similarity scores obtained by CLIP. Accordingly, we propose a Balanced
Similarity with Auxiliary Prompts (BSAP) to mitigate the text-to-image
retrieval bias of CLIP. Specifically, our BSAP designs auxiliary prompts for
CLIP to calculate multiple similarity scores for the retrieval images and then
normalizes the scores between each image and the given query text as well as
our auxiliary prompts to obtain balanced similarity scores. The balanced
similarity score of the given query text is used for the final retrieval. In
addition, we attempt to adopt a hybrid similarity that combines our BSAP with
the original similarity of CLIP to obtain a more robust outcome. Extensive
experiments on two typical zero-shot learning tasks,i.e., Referring Expression
Comprehension (REC) and Referring Image Segmentation (RIS), are conducted to
demonstrate the effectiveness of our BSAP. Specifically, when using the val
dataset of RefCOCO in REC, BSAP increases CLIP's performance by 20.6%.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18401" title="Abstract">arXiv:2402.18401</a> [<a href="/pdf/2402.18401" title="Download PDF">pdf</a>, <a href="/format/2402.18401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DevPhish: Exploring Social Engineering in Software Supply Chain Attacks  on Developers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Siadati%2C+H">Hossein Siadati</a>, 
<a href="/search/cs?searchtype=author&query=Jafarikhah%2C+S">Sima Jafarikhah</a>, 
<a href="/search/cs?searchtype=author&query=Sahin%2C+E">Elif Sahin</a>, 
<a href="/search/cs?searchtype=author&query=Hernandez%2C+T+B">Terrence Brent Hernandez</a>, 
<a href="/search/cs?searchtype=author&query=Tripp%2C+E+L">Elijah Lorenzo Tripp</a>, 
<a href="/search/cs?searchtype=author&query=Khryashchev%2C+D">Denis Khryashchev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The Software Supply Chain (SSC) has captured considerable attention from
attackers seeking to infiltrate systems and undermine organizations. There is
evidence indicating that adversaries utilize Social Engineering (SocE)
techniques specifically aimed at software developers. That is, they interact
with developers at critical steps in the Software Development Life Cycle
(SDLC), such as accessing Github repositories, incorporating code dependencies,
and obtaining approval for Pull Requests (PR) to introduce malicious code. This
paper aims to comprehensively explore the existing and emerging SocE tactics
employed by adversaries to trick Software Engineers (SWEs) into delivering
malicious software. By analyzing a diverse range of resources, which encompass
established academic literature and real-world incidents, the paper
systematically presents an overview of these manipulative strategies within the
realm of the SSC. Such insights prove highly beneficial for threat modeling and
security gap analysis.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18402" title="Abstract">arXiv:2402.18402</a> [<a href="/pdf/2402.18402" title="Download PDF">pdf</a>, <a href="/format/2402.18402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Modular System for Enhanced Robustness of Multimedia Understanding  Networks via Deep Parametric Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barbato%2C+F">Francesco Barbato</a>, 
<a href="/search/cs?searchtype=author&query=Michieli%2C+U">Umberto Michieli</a>, 
<a href="/search/cs?searchtype=author&query=Yucel%2C+M+K">Mehmet Karim Yucel</a>, 
<a href="/search/cs?searchtype=author&query=Zanuttigh%2C+P">Pietro Zanuttigh</a>, 
<a href="/search/cs?searchtype=author&query=Ozay%2C+M">Mete Ozay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ACM MMSys'24. 10 pages, 7 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In multimedia understanding tasks, corrupted samples pose a critical
challenge, because when fed to machine learning models they lead to performance
degradation. In the past, three groups of approaches have been proposed to
handle noisy data: i) enhancer and denoiser modules to improve the quality of
the noisy data, ii) data augmentation approaches, and iii) domain adaptation
strategies. All the aforementioned approaches come with drawbacks that limit
their applicability; the first has high computational costs and requires pairs
of clean-corrupted data for training, while the others only allow deployment of
the same task/network they were trained on (\ie, when upstream and downstream
task/network are the same). In this paper, we propose SyMPIE to solve these
shortcomings. To this end, we design a small, modular, and efficient (just
2GFLOPs to process a Full HD image) system to enhance input data for robust
downstream multimedia understanding with minimal computational cost. Our SyMPIE
is pre-trained on an upstream task/network that should not match the downstream
ones and does not need paired clean-corrupted samples. Our key insight is that
most input corruptions found in real-world tasks can be modeled through global
operations on color channels of images or spatial filters with small kernels.
We validate our approach on multiple datasets and tasks, such as image
classification (on ImageNetC, ImageNetC-Bar, VizWiz, and a newly proposed mixed
corruption benchmark named ImageNetC-mixed) and semantic segmentation (on
Cityscapes, ACDC, and DarkZurich) with consistent improvements of about 5\%
relative accuracy gain across the board. The code of our approach and the new
ImageNetC-mixed benchmark will be made available upon publication.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18403" title="Abstract">arXiv:2402.18403</a> [<a href="/pdf/2402.18403" title="Download PDF">pdf</a>, <a href="/format/2402.18403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preconditioned iterative solvers for constrained high-order implicit  shock tracking methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Vandergrift%2C+J">Jakob Vandergrift</a>, 
<a href="/search/math?searchtype=author&query=Zahr%2C+M+J">Matthew J. Zahr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 16 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">High-order implicit shock tracking (fitting) is a class of high-order
numerical methods that use numerical optimization to simultaneously compute a
high-order approximation to a conservation law solution and align elements of
the computational mesh with non-smooth features. This alignment ensures that
non-smooth features are perfectly represented by inter-element jumps and
high-order basis functions approximate smooth regions of the solution without
nonlinear stabilization, which leads to accurate approximations on
traditionally coarse meshes. In this work, we devise a family of
preconditioners for the saddle point linear system that defines the step toward
optimality at each iteration of the optimization solver so Krylov solvers can
be effectively used. Our preconditioners integrate standard preconditioners
from constrained optimization with popular preconditioners for discontinuous
Galerkin discretizations such as block Jacobi, block incomplete LU
factorizations with minimum discarded fill reordering, and p-multigrid.
Thorough studies are performed using two inviscid compressible flow problems to
evaluate the effectivity of each preconditioner in this family and their
sensitivity to critical shock tracking parameters such as the mesh and Hessian
regularization, linearization state, and resolution of the solution space.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18405" title="Abstract">arXiv:2402.18405</a> [<a href="/pdf/2402.18405" title="Download PDF">pdf</a>, <a href="/format/2402.18405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-cell Coordinated Joint Sensing and Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Babu%2C+N">Nithin Babu</a>, 
<a href="/search/cs?searchtype=author&query=Masouros%2C+C">Christos Masouros</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper proposes block-level precoder (BLP) designs for a multi-input
single-output (MISO) system that performs joint sensing and communication
across multiple cells and users. The Cramer-Rao-Bound for estimating a target's
azimuth angle is determined for coordinated beamforming (CBF) and coordinated
multi-point (CoMP) scenarios while considering inter-cell communication and
sensing links. The formulated optimization problems to minimize the CRB and
maximize the minimum-signal-to-interference-plus-noise-ratio (SINR) are
non-convex and are represented in the semidefinite relaxed (SDR) form to solve
using an alternate optimization algorithm. The proposed solutions show improved
performance compared to the baseline scenario that neglects the signal
component from neighboring cells.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18406" title="Abstract">arXiv:2402.18406</a> [<a href="/pdf/2402.18406" title="Download PDF">pdf</a>, <a href="/ps/2402.18406" title="Download PostScript">ps</a>, <a href="/format/2402.18406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WKB-based third order method for the highly oscillatory 1D stationary  Schr&#xf6;dinger equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Arnold%2C+A">Anton Arnold</a>, 
<a href="/search/math?searchtype=author&query=K%C3%B6rner%2C+J">Jannis K&#xf6;rner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper introduces an efficient high-order numerical method for solving
the 1D stationary Schr\"odinger equation in the highly oscillatory regime.
Building upon the ideas from [2], we first analytically transform the given
equation into a smoother (i.e. less oscillatory) equation. By developing
sufficiently accurate quadratures for several (iterated) oscillatory integrals
occurring in the Picard approximation of the solution, we obtain a one-step
method that is third order w.r.t. the step size. The accuracy and efficiency of
the method are illustrated through several numerical examples.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18409" title="Abstract">arXiv:2402.18409</a> [<a href="/pdf/2402.18409" title="Download PDF">pdf</a>, <a href="/format/2402.18409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Cognitive Evaluation Benchmark of Image Reasoning and Description for  Large Vision Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiujie Song</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Mengyue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K+Q">Kenny Q. Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chunhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yanyi Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Large Vision Language Models (LVLMs), despite their recent success, are
hardly comprehensively tested for their cognitive abilities. Inspired by the
prevalent use of the "Cookie Theft" task in human cognition test, we propose a
novel evaluation benchmark to evaluate high-level cognitive ability of LVLMs
using images with rich semantics. It defines eight reasoning capabilities and
consists of an image description task and a visual question answering task. Our
evaluation on well-known LVLMs shows that there is still a large gap in
cognitive ability between LVLMs and humans.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18411" title="Abstract">arXiv:2402.18411</a> [<a href="/pdf/2402.18411" title="Download PDF">pdf</a>, <a href="/format/2402.18411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Cross-Domain Image Retrieval via Prototypical Optimal  Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bin Li</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Ye Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingya Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised cross-domain image retrieval (UCIR) aims to retrieve images
sharing the same category across diverse domains without relying on labeled
data. Prior approaches have typically decomposed the UCIR problem into two
distinct tasks: intra-domain representation learning and cross-domain feature
alignment. However, these segregated strategies overlook the potential
synergies between these tasks. This paper introduces ProtoOT, a novel Optimal
Transport formulation explicitly tailored for UCIR, which integrates
intra-domain feature representation learning and cross-domain alignment into a
unified framework. ProtoOT leverages the strengths of the K-means clustering
method to effectively manage distribution imbalances inherent in UCIR. By
utilizing K-means for generating initial prototypes and approximating class
marginal distributions, we modify the constraints in Optimal Transport
accordingly, significantly enhancing its performance in UCIR scenarios.
Furthermore, we incorporate contrastive learning into the ProtoOT framework to
further improve representation learning. This encourages local semantic
consistency among features with similar semantics, while also explicitly
enforcing separation between features and unmatched prototypes, thereby
enhancing global discriminativeness. ProtoOT surpasses existing
state-of-the-art methods by a notable margin across benchmark datasets.
Notably, on DomainNet, ProtoOT achieves an average P@200 enhancement of 24.44%,
and on Office-Home, it demonstrates a P@15 improvement of 12.12%. Code is
available at https://github.com/HCVLAB/ProtoOT.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18414" title="Abstract">arXiv:2402.18414</a> [<a href="/pdf/2402.18414" title="Download PDF">pdf</a>, <a href="/format/2402.18414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-based block preconditioning for mixed-dimensional beam-solid  interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Firmbach%2C+M">Max Firmbach</a>, 
<a href="/search/cs?searchtype=author&query=Steinbrecher%2C+I">Ivo Steinbrecher</a>, 
<a href="/search/cs?searchtype=author&query=Popp%2C+A">Alexander Popp</a>, 
<a href="/search/cs?searchtype=author&query=Mayr%2C+M">Matthias Mayr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">This paper presents a scalable physics-based block preconditioner for
mixed-dimensional models in beam-solid interaction and their application in
engineering. In particular, it studies the linear systems arising from a
regularized mortar-type approach for embedding geometrically exact beams into
solid continua. Due to the lack of block diagonal dominance of the arising 2 x
2 block system, an approximate block factorization preconditioner is used. It
exploits the sparsity structure of the beam sub-block to construct a sparse
approximate inverse, which is then not only used to explicitly form an
approximation of the Schur complement, but also acts as a smoother within the
prediction step of the arising SIMPLE-type preconditioner. The correction step
utilizes an algebraic multigrid method. Although, for now, the beam sub-block
is tackled by a one-level method only, the multi-level nature of the
computationally demanding correction step delivers a scalable preconditioner in
practice. In numerical test cases, the influence of different algorithmic
parameters on the quality of the sparse approximate inverse is studied and the
weak scaling behavior of the proposed preconditioner on up to 1000 MPI ranks is
demonstrated, before the proposed preconditioner is finally applied for the
analysis of steel-reinforced concrete structures in civil engineering.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18419" title="Abstract">arXiv:2402.18419</a> [<a href="/pdf/2402.18419" title="Download PDF">pdf</a>, <a href="/ps/2402.18419" title="Download PostScript">ps</a>, <a href="/format/2402.18419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can GPT Improve the State of Prior Authorization via Guideline Based  Automated Question Answering?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vatsal%2C+S">Shubham Vatsal</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Ayush Singh</a>, 
<a href="/search/cs?searchtype=author&query=Tafreshi%2C+S">Shabnam Tafreshi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Health insurance companies have a defined process called prior authorization
(PA) which is a health plan cost-control process that requires doctors and
other healthcare professionals to get clearance in advance from a health plan
before performing a particular procedure on a patient in order to be eligible
for payment coverage. For health insurance companies, approving PA requests for
patients in the medical domain is a time-consuming and challenging task. One of
those key challenges is validating if a request matches up to certain criteria
such as age, gender, etc. In this work, we evaluate whether GPT can validate
numerous key factors, in turn helping health plans reach a decision drastically
faster. We frame it as a question answering task, prompting GPT to answer a
question from patient electronic health record. We experiment with different
conventional prompting techniques as well as introduce our own novel prompting
technique. Moreover, we report qualitative assessment by humans on the natural
language generation outputs from our approach. Results show that our method
achieves superior performance with the mean weighted F1 score of 0.61 as
compared to its standard counterparts.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18420" title="Abstract">arXiv:2402.18420</a> [<a href="/pdf/2402.18420" title="Download PDF">pdf</a>, <a href="/format/2402.18420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CafkNet: GNN-Empowered Forward Kinematic Modeling for Cable-Driven  Parallel Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Linhan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Cong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+W">Weiwei Shang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jia Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To the best of our knowledge, it is the first study to employ the GNN for FK problem of CDPRs. 9 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">When deploying Cable-Driven Parallel Robots (CDPRs) in practice, one of the
challenges is kinematic modeling. Unlike serial mechanisms, CDPRs have a simple
inverse kinematics problem but a complex forward kinematics (FK) issue.
Therefore, the development of accurate and efficient FK solvers has been a
prominent research focus in CDPR applications. By observing the topology within
CDPRs, in this letter, we propose a graph-based representation to model CDPRs
and introduce CafkNet, a fast and general FK solver, leveraging Graph Neural
Network (GNN). Extensive experiments are conducted on 3D and 2D CDPRs across
various configurations, including under-constrained, fully-constrained, and
over-constrained cases, in both simulation environments and real-world
scenarios. The experimental results showcase that CafkNet can learn the
internal topological information of CDPRs and accurately solve the FK problem
as an FK solver. Furthermore, training the CafkNet model on partial
configurations enables zero-shot generalization to other configurations.
Lastly, CafkNet effectively bridges the sim2real gap by using both simulation
data and part of real-world data. To the best of our knowledge, it is the first
study that employs the GNN to solve the FK problem for CDPRs.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18424" title="Abstract">arXiv:2402.18424</a> [<a href="/pdf/2402.18424" title="Download PDF">pdf</a>, <a href="/format/2402.18424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emotion Classification in Low and Moderate Resource Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tafreshi%2C+S">Shabnam Tafreshi</a>, 
<a href="/search/cs?searchtype=author&query=Vatsal%2C+S">Shubham Vatsal</a>, 
<a href="/search/cs?searchtype=author&query=Diab%2C+M">Mona Diab</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">It is important to be able to analyze the emotional state of people around
the globe. There are 7100+ active languages spoken around the world and
building emotion classification for each language is labor intensive.
Particularly for low-resource and endangered languages, building emotion
classification can be quite challenging. We present a cross-lingual emotion
classifier, where we train an emotion classifier with resource-rich languages
(i.e. \textit{English} in our work) and transfer the learning to low and
moderate resource languages. We compare and contrast two approaches of transfer
learning from a high-resource language to a low or moderate-resource language.
One approach projects the annotation from a high-resource language to low and
moderate-resource language in parallel corpora and the other one uses direct
transfer from high-resource language to the other languages. We show the
efficacy of our approaches on 6 languages: Farsi, Arabic, Spanish, Ilocano,
Odia, and Azerbaijani. Our results indicate that our approaches outperform
random baselines and transfer emotions across languages successfully. For all
languages, the direct cross-lingual transfer of emotion yields better results.
We also create annotated emotion-labeled resources for four languages: Farsi,
Azerbaijani, Ilocano and Odia.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18426" title="Abstract">arXiv:2402.18426</a> [<a href="/pdf/2402.18426" title="Download PDF">pdf</a>, <a href="/format/2402.18426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Relational Inductive Bias for Dimensional Abstraction in Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Campbell%2C+D">Declan Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+J+D">Jonathan D. Cohen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The human cognitive system exhibits remarkable flexibility and generalization
capabilities, partly due to its ability to form low-dimensional, compositional
representations of the environment. In contrast, standard neural network
architectures often struggle with abstract reasoning tasks, overfitting, and
requiring extensive data for training. This paper investigates the impact of
the relational bottleneck -- a mechanism that focuses processing on relations
among inputs -- on the learning of factorized representations conducive to
compositional coding and the attendant flexibility of processing. We
demonstrate that such a bottleneck not only improves generalization and
learning efficiency, but also aligns network performance with human-like
behavioral biases. Networks trained with the relational bottleneck developed
orthogonal representations of feature dimensions latent in the dataset,
reflecting the factorized structure thought to underlie human cognitive
flexibility. Moreover, the relational network mimics human biases towards
regularity without pre-specified symbolic primitives, suggesting that the
bottleneck fosters the emergence of abstract representations that confer
flexibility akin to symbols.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18427" title="Abstract">arXiv:2402.18427</a> [<a href="/pdf/2402.18427" title="Download PDF">pdf</a>, <a href="/format/2402.18427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Better than best low-rank approximation with the singular value  decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gleich%2C+D+F">David F. Gleich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The Eckhart-Young theorem states that the best low-rank approximation of a
matrix can be constructed from the leading singular values and vectors of the
matrix. Here, we illustrate that the practical implications of this result
crucially depend on the organization of the matrix data. In particular, we will
show examples where a rank 2 approximation of the matrix data in a different
representation more accurately represents the entire matrix than a rank 5
approximation of the original matrix data -- even though both approximations
have the same number of underlying parameters. Beyond images, we show examples
of how flexible orientation enables better approximation of time series data,
which suggests additional applicability of the findings. Finally, we conclude
with a theoretical result that the effect of data organization can result in an
unbounded improvement to the matrix approximation factor as the matrix
dimension grows.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18428" title="Abstract">arXiv:2402.18428</a> [<a href="/pdf/2402.18428" title="Download PDF">pdf</a>, <a href="/format/2402.18428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Diverse Modeling Contexts with Collaborating Learning for  Neural Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yusheng Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Autoregressive (AR) and Non-autoregressive (NAR) models are two types of
generative models for Neural Machine Translation (NMT). AR models predict
tokens in a word-by-word manner and can effectively capture the distribution of
real translations. NAR models predict tokens by extracting bidirectional
contextual information which can improve the inference speed but they suffer
from performance degradation. Previous works utilized AR models to enhance NAR
models by reducing the training data's complexity or incorporating the global
information into AR models by virtue of NAR models. However, those investigated
methods only take advantage of the contextual information of a single type of
model while neglecting the diversity in the contextual information that can be
provided by different types of models. In this paper, we propose a novel
generic collaborative learning method, DCMCL, where AR and NAR models are
treated as collaborators instead of teachers and students. To hierarchically
leverage the bilateral contextual information, token-level mutual learning and
sequence-level contrastive learning are adopted between AR and NAR models.
Extensive experiments on four widely used benchmarks show that the proposed
DCMCL method can simultaneously improve both AR and NAR models with up to 1.38
and 2.98 BLEU scores respectively, and can also outperform the current
best-unified model with up to 0.97 BLEU scores for both AR and NAR decoding.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18430" title="Abstract">arXiv:2402.18430</a> [<a href="/pdf/2402.18430" title="Download PDF">pdf</a>, <a href="/ps/2402.18430" title="Download PostScript">ps</a>, <a href="/format/2402.18430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smishing Dataset I: Phishing SMS Dataset from Smishtank.com
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Timko%2C+D">Daniel Timko</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+L">Muhammad Lutfor Rahman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">While smishing (SMS Phishing) attacks have risen to become one of the most
common types of social engineering attacks, there is a lack of relevant
smishing datasets. One of the biggest challenges in the domain of smishing
prevention is the availability of fresh smishing datasets. Additionally, as
time persists, smishing campaigns are shut down and the crucial information
related to the attack are lost. With the changing nature of smishing attacks, a
consistent flow of new smishing examples is needed by both researchers and
engineers to create effective defenses. In this paper, we present the
community-sourced smishing datasets from the smishtank.com. It provides a
wealth of information relevant to combating smishing attacks through the
breakdown and analysis of smishing samples at the point of submission. In the
contribution of our work, we provide a corpus of 1090 smishing samples that
have been publicly submitted through the site. Each message includes
information relating to the sender, message body, and any brands referenced in
the message. Additionally, when a URL is found, we provide additional
information on the domain, VirusTotal results, and a characterization of the
URL. Through the open access of fresh smishing data, we empower academia and
industries to create robust defenses against this evolving threat.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18434" title="Abstract">arXiv:2402.18434</a> [<a href="/pdf/2402.18434" title="Download PDF">pdf</a>, <a href="/format/2402.18434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Regularized Encoder Training for Extreme Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mittal%2C+A">Anshul Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Mohan%2C+S">Shikhar Mohan</a>, 
<a href="/search/cs?searchtype=author&query=Saini%2C+D">Deepak Saini</a>, 
<a href="/search/cs?searchtype=author&query=Prabhu%2C+S+C">Suchith C. Prabhu</a>, 
<a href="/search/cs?searchtype=author&query=jiao%2C+J">Jain jiao</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+S">Sumeet Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Chakrabarti%2C+S">Soumen Chakrabarti</a>, 
<a href="/search/cs?searchtype=author&query=Kar%2C+P">Purushottam Kar</a>, 
<a href="/search/cs?searchtype=author&query=Varma%2C+M">Manik Varma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Deep extreme classification (XC) aims to train an encoder architecture and an
accompanying classifier architecture to tag a data point with the most relevant
subset of labels from a very large universe of labels. XC applications in
ranking, recommendation and tagging routinely encounter tail labels for which
the amount of training data is exceedingly small. Graph convolutional networks
(GCN) present a convenient but computationally expensive way to leverage task
metadata and enhance model accuracies in these settings. This paper formally
establishes that in several use cases, the steep computational cost of GCNs is
entirely avoidable by replacing GCNs with non-GCN architectures. The paper
notices that in these settings, it is much more effective to use graph data to
regularize encoder training than to implement a GCN. Based on these insights,
an alternative paradigm RAMEN is presented to utilize graph metadata in XC
settings that offers significant performance boosts with zero increase in
inference computational costs. RAMEN scales to datasets with up to 1M labels
and offers prediction accuracy up to 15% higher on benchmark datasets than
state of the art methods, including those that use graph metadata to train
GCNs. RAMEN also offers 10% higher accuracy over the best baseline on a
proprietary recommendation dataset sourced from click logs of a popular search
engine. Code for RAMEN will be released publicly.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18439" title="Abstract">arXiv:2402.18439</a> [<a href="/pdf/2402.18439" title="Download PDF">pdf</a>, <a href="/format/2402.18439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Natural Language: LLMs Leveraging Alternative Formats for  Enhanced Reasoning and Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weize Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chenfei Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jiarui Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yusheng Su</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+R">Ruobing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Maosong Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Natural language (NL) has long been the predominant format for human
cognition and communication, and by extension, has been similarly pivotal in
the development and application of Large Language Models (LLMs). Yet, besides
NL, LLMs have seen various non-NL formats during pre-training, such as code and
logical expression. NL's status as the optimal format for LLMs, particularly in
single-LLM reasoning and multi-agent communication, has not been thoroughly
examined. In this work, we challenge the default use of NL by exploring the
utility of non-NL formats in these contexts. We show that allowing LLMs to
autonomously select the most suitable format before reasoning or communicating
leads to a 3.3 to 5.7\% improvement in reasoning efficiency for different LLMs,
and up to a 72.7\% reduction in token usage in multi-agent communication, all
while maintaining communicative effectiveness. Our comprehensive analysis
further reveals that LLMs can devise a format from limited task instructions
and that the devised format is effectively transferable across different LLMs.
Intriguingly, the structured communication format decided by LLMs exhibits
notable parallels with established agent communication languages, suggesting a
natural evolution towards efficient, structured communication in agent
communication. Our code is released at
\url{https://github.com/thunlp/AutoForm}.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18443" title="Abstract">arXiv:2402.18443</a> [<a href="/pdf/2402.18443" title="Download PDF">pdf</a>, <a href="/format/2402.18443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LeMo-NADe: Multi-Parameter Neural Architecture Discovery with LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+H">Md Hafizur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+P">Prabuddha Chakraborty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 5 figures, 10 tables and 3 algorithms
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Building efficient neural network architectures can be a time-consuming task
requiring extensive expert knowledge. This task becomes particularly
challenging for edge devices because one has to consider parameters such as
power consumption during inferencing, model size, inferencing speed, and CO2
emissions. In this article, we introduce a novel framework designed to
automatically discover new neural network architectures based on user-defined
parameters, an expert system, and an LLM trained on a large amount of
open-domain knowledge. The introduced framework (LeMo-NADe) is tailored to be
used by non-AI experts, does not require a predetermined neural architecture
search space, and considers a large set of edge device-specific parameters. We
implement and validate this proposed neural architecture discovery framework
using CIFAR-10, CIFAR-100, and ImageNet16-120 datasets while using GPT-4 Turbo
and Gemini as the LLM component. We observe that the proposed framework can
rapidly (within hours) discover intricate neural network models that perform
extremely well across a diverse set of application settings defined by the
user.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18445" title="Abstract">arXiv:2402.18445</a> [<a href="/pdf/2402.18445" title="Download PDF">pdf</a>, <a href="/format/2402.18445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperFedNet: Communication-Efficient Personalized Federated Learning Via  Hypernetwork
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xingyun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhenzhen Xie</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+J">Junjie Pang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">There are still many challenges in Federated Learning (FL). First, during the
model update process, the model parameters on the local user need to be sent to
the server for aggregation. This involves the consumption of network bandwidth,
especially when the number of users participating in FL is large. High
communication costs may limit the application of FL in certain scenarios.
Secondly, since users participating in FL usually have different data
distributions, this heterogeneity of data may lead to poor model performance or
even failure to converge. Third, privacy and security issues are also
challenges that need to be addressed in FL. There is still a risk of
information leakage during model aggregation. Malicious users may obtain
sensitive information by analyzing communications during model updates or
aggregation processes. To address these challenges, we propose HyperFedNet
(HFN), an innovative approach that leverages hypernetwork. HFN introduces a
paradigm shift in transmission aggregation within FL. Unlike traditional FL
methods that transmit a large number of parameters from the main network, HFN
reduces the communication burden and improves security by transmitting a
compact set of hypernetwork parameters. After the parameters of the
hypernetwork are deployed locally to the user, the local database features
quantified by the embedding vector can be used as input, and parameters can be
dynamically generated for the FL main network through user forward propagation.
HFN efficiently reduces communication costs while improving accuracy. Extensive
experimentation demonstrates that HFN outperforms traditional FL methods
significantly. By seamlessly integrating this concept into the conventional FL
algorithm, we achieve even more impressive results compared to the original
approach.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18447" title="Abstract">arXiv:2402.18447</a> [<a href="/pdf/2402.18447" title="Download PDF">pdf</a>, <a href="/format/2402.18447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt-Driven Dynamic Object-Centric Learning for Single Domain  Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Deng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+A">Aming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yahong Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Single-domain generalization aims to learn a model from single source domain
data to achieve generalized performance on other unseen target domains.
Existing works primarily focus on improving the generalization ability of
static networks. However, static networks are unable to dynamically adapt to
the diverse variations in different image scenes, leading to limited
generalization capability. Different scenes exhibit varying levels of
complexity, and the complexity of images further varies significantly in
cross-domain scenarios. In this paper, we propose a dynamic object-centric
perception network based on prompt learning, aiming to adapt to the variations
in image complexity. Specifically, we propose an object-centric gating module
based on prompt learning to focus attention on the object-centric features
guided by the various scene prompts. Then, with the object-centric gating
masks, the dynamic selective module dynamically selects highly correlated
feature regions in both spatial and channel dimensions enabling the model to
adaptively perceive object-centric relevant features, thereby enhancing the
generalization capability. Extensive experiments were conducted on
single-domain generalization tasks in image classification and object
detection. The experimental results demonstrate that our approach outperforms
state-of-the-art methods, which validates the effectiveness and generally of
our proposed method.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18449" title="Abstract">arXiv:2402.18449</a> [<a href="/pdf/2402.18449" title="Download PDF">pdf</a>, <a href="/format/2402.18449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HOP to the Next Tasks and Domains for Continual Learning in NLP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Michieli%2C+U">Umberto Michieli</a>, 
<a href="/search/cs?searchtype=author&query=Ozay%2C+M">Mete Ozay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024. Main + supplmentary
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Continual Learning (CL) aims to learn a sequence of problems (i.e., tasks and
domains) by transferring knowledge acquired on previous problems, whilst
avoiding forgetting of past ones. Different from previous approaches which
focused on CL for one NLP task or domain in a specific use-case, in this paper,
we address a more general CL setting to learn from a sequence of problems in a
unique framework. Our method, HOP, permits to hop across tasks and domains by
addressing the CL problem along three directions: (i) we employ a set of
adapters to generalize a large pre-trained model to unseen problems, (ii) we
compute high-order moments over the distribution of embedded representations to
distinguish independent and correlated statistics across different tasks and
domains, (iii) we process this enriched information with auxiliary heads
specialized for each end problem. Extensive experimental campaign on 4 NLP
applications, 5 benchmarks and 2 CL setups demonstrates the effectiveness of
our HOP.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18458" title="Abstract">arXiv:2402.18458</a> [<a href="/pdf/2402.18458" title="Download PDF">pdf</a>, <a href="/format/2402.18458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-Task Prompting Elicits Embedding from Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+Y">Yibin Lei</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Di Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+T">Tao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+C">Chongyang Tao</a>, 
<a href="/search/cs?searchtype=author&query=Yates%2C+A">Andrew Yates</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this work, we introduce a new unsupervised embedding method, Meta-Task
Prompting with Explicit One-Word Limitation (MetaEOL), for generating
high-quality sentence embeddings from Large Language Models (LLMs) without the
need for model fine-tuning or task-specific engineering. Leveraging meta-task
prompting, MetaEOL guides LLMs to produce embeddings through a series of
carefully designed prompts that address multiple representational aspects. Our
comprehensive experiments demonstrate that embeddings averaged from various
meta-tasks yield competitive performance on Semantic Textual Similarity (STS)
benchmarks and excel in downstream tasks, surpassing contrastive-trained
models. Our findings suggest a new scaling law for embedding generation,
offering a versatile, resource-efficient approach for embedding extraction
across diverse sentence-centric scenarios.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18463" title="Abstract">arXiv:2402.18463</a> [<a href="/pdf/2402.18463" title="Download PDF">pdf</a>, <a href="/format/2402.18463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Impact of AI Generated Content on Social Media: The  Pixiv Case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yiluo Wei</a>, 
<a href="/search/cs?searchtype=author&query=Tyson%2C+G">Gareth Tyson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">In the last two years, Artificial Intelligence Generated Content (AIGC) has
received significant attention, leading to an anecdotal rise in the amount of
AIGC being shared via social media platforms. The impact of AIGC and its
implications are of key importance to social platforms, e.g., regarding the
implementation of policies, community formation, and algorithmic design. Yet,
to date, we know little about how the arrival of AIGC has impacted the social
media ecosystem. To fill this gap, we present a comprehensive study of Pixiv,
an online community for artists who wish to share and receive feedback on their
illustrations. Pixiv hosts over 100 million artistic submissions and receives
more than 1 billion page views per month (as of 2023). Importantly, it allows
both human and AI generated content to be uploaded. Exploiting this, we perform
the first analysis of the impact that AIGC has had on the social media
ecosystem, through the lens of Pixiv. Based on a dataset of 15.2 million posts
(including 2.4 million AI-generated images), we measure the impact of AIGC on
the Pixiv community, as well as the differences between AIGC and
human-generated content in terms of content creation and consumption patterns.
Our results offer key insight to how AIGC is changing the dynamics of social
media platforms like Pixiv.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18465" title="Abstract">arXiv:2402.18465</a> [<a href="/pdf/2402.18465" title="Download PDF">pdf</a>, <a href="/format/2402.18465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Information in MC: Chemotaxis Beyond Shannon
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brand%2C+L">Lukas Brand</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Magarini%2C+M">Maurizio Magarini</a>, 
<a href="/search/cs?searchtype=author&query=Schober%2C+R">Robert Schober</a>, 
<a href="/search/cs?searchtype=author&query=Lotter%2C+S">Sebastian Lotter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The recently emerging molecular communication (MC) paradigm intents to
leverage communication engineering tools for the design of synthetic chemical
communication systems. These systems are envisioned to operate on nanoscale and
in biological environments, such as the human body, and catalyze the emergence
of revolutionary applications in the context of early disease monitoring and
drug targeting. However, while a plethora of theoretical (and more recently
also more and more practical) MC system designs have been proposed over the
past years, some fundamental questions remain open, hindering the breakthrough
of MC in real-world applications. One of these questions is: What is a useful
measure of information in the context of MC-based applications? While most
existing works in MC build upon the concept of syntactic information as
introduced by Shannon, in this paper, we explore the framework of semantic
information as introduced by Kolchinsky and Wolpert for the information
theoretical analysis of a natural MC system, namely bacterial chemotaxis.
Exploiting the computational modeling tool of agent-based modeling (ABM), we
are able to demonstrate that the semantic information framework can provide a
useful information theoretical framework for quantifying the information
exchange of chemotactic bacteria with their environment. In particular, we show
that the measured semantic information provides a useful measure of the ability
of the bacteria to adapt to and survive in a changing environment. Encouraged
by our results, we envision that the semantic information framework can open
new avenues for developing theoretical and practical MC system designs and in
this way help to unleash the full potential of MC for complex adaptive
systems-based nanoscale applications.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18467" title="Abstract">arXiv:2402.18467</a> [<a href="/pdf/2402.18467" title="Download PDF">pdf</a>, <a href="/format/2402.18467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Separate and Conquer: Decoupling Co-occurrence via Decomposition and  Representation for Weakly Supervised Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhiwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+K">Kexue Fu</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+M">Minghong Duan</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+L">Linhao Qu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhijian Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Attributed to the frequent coupling of co-occurring objects and the limited
supervision from image-level labels, the challenging co-occurrence problem is
widely present and leads to false activation of objects in weakly supervised
semantic segmentation (WSSS). In this work, we devise a 'Separate and Conquer'
scheme SeCo to tackle this issue from dimensions of image space and feature
space. In the image space, we propose to 'separate' the co-occurring objects
with image decomposition by subdividing images into patches. Importantly, we
assign each patch a category tag from Class Activation Maps (CAMs), which
spatially helps remove the co-context bias and guide the subsequent
representation. In the feature space, we propose to 'conquer' the false
activation by enhancing semantic representation with multi-granularity
knowledge contrast. To this end, a dual-teacher-single-student architecture is
designed and tag-guided contrast is conducted to guarantee the correctness of
knowledge and further facilitate the discrepancy among co-occurring objects. We
streamline the multi-staged WSSS pipeline end-to-end and tackle co-occurrence
without external supervision. Extensive experiments are conducted, validating
the efficiency of our method tackling co-occurrence and the superiority over
previous single-staged and even multi-staged competitors on PASCAL VOC and MS
COCO. Code will be available.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18469" title="Abstract">arXiv:2402.18469</a> [<a href="/pdf/2402.18469" title="Download PDF">pdf</a>, <a href="/ps/2402.18469" title="Download PostScript">ps</a>, <a href="/format/2402.18469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interval-Constrained Bipartite Matching over Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abels%2C+A">Andreas Abels</a>, 
<a href="/search/cs?searchtype=author&query=Anapolska%2C+M">Mariia Anapolska</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Interval-constrained online bipartite matching problem frequently occurs in
medical appointment scheduling: unit-time jobs representing patients arrive
online and are assigned to a time slot within their given time interval. We
consider a variant of this problem where reassignments are allowed and extend
it by a notion of current time, which is decoupled from the job arrival events.
As jobs appear, the current point in time gradually advances. Jobs that are
assigned to the current time unit become processed, which fixes part of the
matching and disables these jobs or slots for reassignments in future steps. We
refer to these time-dependent restrictions on reassignments as the over-time
property.
<br />We show that FirstFit with reassignments according to the shortest augmenting
path rule is $\frac{2}{3}$-competitive with respect to the matching
cardinality, and that the bound is tight. Interestingly, this bound holds even
if the number of reassignments per job is bound by a constant. For the number
of reassignments performed by the algorithm, we show that it is in $\Omega(n
\log n)$ in the worst case, where $n$ is the number of patients or jobs on the
online side. This result is in line with lower bounds for the number of
reassignments in online bipartite matching with reassignments, and, similarly
to this previous work, we also conjecture that this bound should be tight.
Known upper bounds like the $O(n \log^2 n)$ for online bipartite matching with
reassignments by Bernstein, Holm, and Rotenberg do not transfer directly: while
our interval constraints simplify the problem, the over-time property restricts
the set of possible reassignments.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18470" title="Abstract">arXiv:2402.18470</a> [<a href="/pdf/2402.18470" title="Download PDF">pdf</a>, <a href="/format/2402.18470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Higher-Order Lens for Social Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Preti%2C+G">Giulia Preti</a>, 
<a href="/search/cs?searchtype=author&query=Fazzone%2C+A">Adriano Fazzone</a>, 
<a href="/search/cs?searchtype=author&query=Petri%2C+G">Giovanni Petri</a>, 
<a href="/search/cs?searchtype=author&query=De+Francisci+Morales%2C+G">Gianmarco De Francisci Morales</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">Despite the widespread adoption of higher-order mathematical structures such
as hypergraphs, methodological tools for their analysis lag behind those for
traditional graphs. This work addresses a critical gap in this context by
proposing two micro-canonical random null models for directed hypergraphs: the
Directed Hypergraph Configuration Model (DHCM) and the Directed Hypergraph
JOINT Model (DHJM). These models preserve essential structural properties of
directed hypergraphs such as node in- and out-degree sequences and hyperedge
head and tail size sequences, or their joint tensor. We also describe two
efficient MCMC algorithms, NuDHy-Degs and NuDHy-JOINT, to sample random
hypergraphs from these ensembles.
<br />To showcase the interdisciplinary applicability of the proposed null models,
we present three distinct use cases in sociology, epidemiology, and economics.
First, we reveal the oscillatory behavior of increased homophily in opposition
parties in the US Congress over a 40-year span, emphasizing the role of
higher-order structures in quantifying political group homophily. Second, we
investigate non-linear contagion in contact hyper-networks, demonstrating that
disparities between simulations and theoretical predictions can be explained by
considering higher-order joint degree distributions. Last, we examine the
economic complexity of countries in the global trade network, showing that
local network properties preserved by NuDHy explain the main structural
economic complexity indexes.
<br />This work pioneers the development of null models for directed hypergraphs,
addressing the intricate challenges posed by their complex entity relations,
and providing a versatile suite of tools for researchers across various
domains.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18472" title="Abstract">arXiv:2402.18472</a> [<a href="/pdf/2402.18472" title="Download PDF">pdf</a>, <a href="/ps/2402.18472" title="Download PostScript">ps</a>, <a href="/format/2402.18472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implementing Online Reinforcement Learning with Clustering Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Smith%2C+J+E">James E. Smith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">An agent employing reinforcement learning takes inputs (state variables) from
an environment and performs actions that affect the environment in order to
achieve some objective. Rewards (positive or negative) guide the agent toward
improved future actions. This paper builds on prior clustering neural network
research by constructing an agent with biologically plausible neo-Hebbian
three-factor synaptic learning rules, with a reward signal as the third factor
(in addition to pre- and post-synaptic spikes). The classic cart-pole problem
(balancing an inverted pendulum) is used as a running example throughout the
exposition. Simulation results demonstrate the efficacy of the approach, and
the proposed method may eventually serve as a low-level component of a more
general method.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18476" title="Abstract">arXiv:2402.18476</a> [<a href="/pdf/2402.18476" title="Download PDF">pdf</a>, <a href="/format/2402.18476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IBD: Alleviating Hallucinations in Large Vision-Language Models via  Image-Biased Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lanyun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+D">Deyi Ji</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianrun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Peng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jieping Ye</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite achieving rapid developments and with widespread applications, Large
Vision-Language Models (LVLMs) confront a serious challenge of being prone to
generating hallucinations. An over-reliance on linguistic priors has been
identified as a key factor leading to these hallucinations. In this paper, we
propose to alleviate this problem by introducing a novel image-biased decoding
(IBD) technique. Our method derives the next-token probability distribution by
contrasting predictions from a conventional LVLM with those of an image-biased
LVLM, thereby amplifying the correct information highly correlated with image
content while mitigating the hallucinatory errors caused by excessive
dependence on text. We further conduct a comprehensive statistical analysis to
validate the reliability of our method, and design an adaptive adjustment
strategy to achieve robust and flexible handling under varying conditions.
Experimental results across multiple evaluation metrics verify that our method,
despite not requiring additional training data and only with a minimal increase
in model parameters, can significantly reduce hallucinations in LVLMs and
enhance the truthfulness of the generated response.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18477" title="Abstract">arXiv:2402.18477</a> [<a href="/pdf/2402.18477" title="Download PDF">pdf</a>, <a href="/format/2402.18477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Signature Kernel Conditional Independence Tests in Causal Discovery for  Stochastic Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manten%2C+G">Georg Manten</a>, 
<a href="/search/cs?searchtype=author&query=Casolo%2C+C">Cecilia Casolo</a>, 
<a href="/search/cs?searchtype=author&query=Ferrucci%2C+E">Emilio Ferrucci</a>, 
<a href="/search/cs?searchtype=author&query=Mogensen%2C+S+W">S&#xf8;ren Wengel Mogensen</a>, 
<a href="/search/cs?searchtype=author&query=Salvi%2C+C">Cristopher Salvi</a>, 
<a href="/search/cs?searchtype=author&query=Kilbertus%2C+N">Niki Kilbertus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Inferring the causal structure underlying stochastic dynamical systems from
observational data holds great promise in domains ranging from science and
health to finance. Such processes can often be accurately modeled via
stochastic differential equations (SDEs), which naturally imply causal
relationships via "which variables enter the differential of which other
variables". In this paper, we develop a kernel-based test of conditional
independence (CI) on "path-space" -- solutions to SDEs -- by leveraging recent
advances in signature kernels. We demonstrate strictly superior performance of
our proposed CI test compared to existing approaches on path-space. Then, we
develop constraint-based causal discovery algorithms for acyclic stochastic
dynamical systems (allowing for loops) that leverage temporal information to
recover the entire directed graph. Assuming faithfulness and a CI oracle, our
algorithm is sound and complete. We empirically verify that our developed CI
test in conjunction with the causal discovery algorithm reliably outperforms
baselines across a range of settings.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18479" title="Abstract">arXiv:2402.18479</a> [<a href="/pdf/2402.18479" title="Download PDF">pdf</a>, <a href="/format/2402.18479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NewsQs: Multi-Source Question Generation for the Inquiring Mind
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hwang%2C+A">Alyssa Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Dixit%2C+K">Kalpit Dixit</a>, 
<a href="/search/cs?searchtype=author&query=Ballesteros%2C+M">Miguel Ballesteros</a>, 
<a href="/search/cs?searchtype=author&query=Benajiba%2C+Y">Yassine Benajiba</a>, 
<a href="/search/cs?searchtype=author&query=Castelli%2C+V">Vittorio Castelli</a>, 
<a href="/search/cs?searchtype=author&query=Dreyer%2C+M">Markus Dreyer</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+M">Mohit Bansal</a>, 
<a href="/search/cs?searchtype=author&query=McKeown%2C+K">Kathleen McKeown</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present NewsQs (news-cues), a dataset that provides question-answer pairs
for multiple news documents. To create NewsQs, we augment a traditional
multi-document summarization dataset with questions automatically generated by
a T5-Large model fine-tuned on FAQ-style news articles from the News On the Web
corpus. We show that fine-tuning a model with control codes produces questions
that are judged acceptable more often than the same model without them as
measured through human evaluation. We use a QNLI model with high correlation
with human annotations to filter our data. We release our final dataset of
high-quality questions, answers, and document clusters as a resource for future
work in query-based multi-document summarization.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18480" title="Abstract">arXiv:2402.18480</a> [<a href="/pdf/2402.18480" title="Download PDF">pdf</a>, <a href="/format/2402.18480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Libfork: portable continuation-stealing with stackless coroutines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Williams%2C+C+J">Conor John Williams</a>, 
<a href="/search/cs?searchtype=author&query=Elliott%2C+J">James Elliott</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Fully-strict fork-join parallelism is a powerful model for shared-memory
programming due to its optimal time scaling and strong bounds on memory
scaling. The latter is rarely achieved due to the difficulty of implementing
continuation stealing in traditional High Performance Computing (HPC) languages
-- where it is often impossible without modifying the compiler or resorting to
non-portable techniques. We demonstrate how stackless coroutines (a new feature
in C++20) can enable fully-portable continuation stealing and present libfork a
lock-free fine-grained parallelism library, combining coroutines with
user-space, geometric segmented-stacks. We show our approach is able to achieve
optimal time/memory scaling, both theoretically and empirically, across a
variety of benchmarks. Compared to openMP (libomp), libfork is on average 7.2x
faster and consumes 10x less memory. Similarly, compared to Intel's TBB,
libfork is on average 2.7x faster and consumes 6.2x less memory. Additionally,
we introduce non-uniform memory access (NUMA) optimizations for schedulers that
demonstrate performance matching busy-waiting schedulers.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18487" title="Abstract">arXiv:2402.18487</a> [<a href="/pdf/2402.18487" title="Download PDF">pdf</a>, <a href="/ps/2402.18487" title="Download PostScript">ps</a>, <a href="/format/2402.18487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-Centric Aware UAV Trajectory Planning in Search and Rescue  Missions Employing Multi-Objective Reinforcement Learning with AHP and  Similarity-Based Experience Replay
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramezani%2C+M">Mahya Ramezani</a>, 
<a href="/search/cs?searchtype=author&query=Sanchez-Lopez%2C+J+L">Jose Luis Sanchez-Lopez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">The integration of Unmanned Aerial Vehicles (UAVs) into Search and Rescue
(SAR) missions presents a promising avenue for enhancing operational efficiency
and effectiveness. However, the success of these missions is not solely
dependent on the technical capabilities of the drones but also on their
acceptance and interaction with humans on the ground. This paper explores the
effect of human-centric factor in UAV trajectory planning for SAR missions. We
introduce a novel approach based on the reinforcement learning augmented with
Analytic Hierarchy Process and novel similarity-based experience replay to
optimize UAV trajectories, balancing operational objectives with human comfort
and safety considerations. Additionally, through a comprehensive survey, we
investigate the impact of gender cues and anthropomorphism in UAV design on
public acceptance and trust, revealing significant implications for drone
interaction strategies in SAR. Our contributions include (1) a reinforcement
learning framework for UAV trajectory planning that dynamically integrates
multi-objective considerations, (2) an analysis of human perceptions towards
gendered and anthropomorphized drones in SAR contexts, and (3) the application
of similarity-based experience replay for enhanced learning efficiency in
complex SAR scenarios. The findings offer valuable insights into designing UAV
systems that are not only technically proficient but also aligned with
human-centric values.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18490" title="Abstract">arXiv:2402.18490</a> [<a href="/pdf/2402.18490" title="Download PDF">pdf</a>, <a href="/format/2402.18490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TAMM: TriAdapter Multi-Modal Learning for 3D Shape Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Shengcao Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Xiong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The limited scale of current 3D shape datasets hinders the advancements in 3D
shape understanding, and motivates multi-modal learning approaches which
transfer learned knowledge from data-abundant 2D image and language modalities
to 3D shapes. However, even though the image and language representations have
been aligned by cross-modal models like CLIP, we find that the image modality
fails to contribute as much as the language in existing multi-modal 3D
representation learning methods. This is attributed to the domain shift in the
2D images and the distinct focus of each modality. To more effectively leverage
both modalities in the pre-training, we introduce TriAdapter Multi-Modal
Learning (TAMM) -- a novel two-stage learning approach based on three
synergetic adapters. First, our CLIP Image Adapter mitigates the domain gap
between 3D-rendered images and natural images, by adapting the visual
representations of CLIP for synthetic image-text pairs. Subsequently, our Dual
Adapters decouple the 3D shape representation space into two complementary
sub-spaces: one focusing on visual attributes and the other for semantic
understanding, which ensure a more comprehensive and effective multi-modal
pre-training. Extensive experiments demonstrate that TAMM consistently enhances
3D representations for a wide range of 3D encoder architectures, pre-training
datasets, and downstream tasks. Notably, we boost the zero-shot classification
accuracy on Objaverse-LVIS from 46.8 to 50.7, and improve the 5-way 10-shot
linear probing classification accuracy on ModelNet40 from 96.1 to 99.0. Project
page: \url{https://alanzhangcs.github.io/tamm-page}.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18491" title="Abstract">arXiv:2402.18491</a> [<a href="/pdf/2402.18491" title="Download PDF">pdf</a>, <a href="/format/2402.18491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamical Regimes of Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biroli%2C+G">Giulio Biroli</a>, 
<a href="/search/cs?searchtype=author&query=Bonnaire%2C+T">Tony Bonnaire</a>, 
<a href="/search/cs?searchtype=author&query=de+Bortoli%2C+V">Valentin de Bortoli</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%A9zard%2C+M">Marc M&#xe9;zard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistical Mechanics (cond-mat.stat-mech)

</div>
<p class="mathjax">Using statistical physics methods, we study generative diffusion models in
the regime where the dimension of space and the number of data are large, and
the score function has been trained optimally. Our analysis reveals three
distinct dynamical regimes during the backward generative diffusion process.
The generative dynamics, starting from pure noise, encounters first a
'speciation' transition where the gross structure of data is unraveled, through
a mechanism similar to symmetry breaking in phase transitions. It is followed
at later time by a 'collapse' transition where the trajectories of the dynamics
become attracted to one of the memorized data points, through a mechanism which
is similar to the condensation in a glass phase. For any dataset, the
speciation time can be found from a spectral analysis of the correlation
matrix, and the collapse time can be found from the estimation of an 'excess
entropy' in the data. The dependence of the collapse time on the dimension and
number of data provides a thorough characterization of the curse of
dimensionality for diffusion models. Analytical solutions for simple models
like high-dimensional Gaussian mixtures substantiate these findings and provide
a theoretical framework, while extensions to more complex scenarios and
numerical validations with real datasets confirm the theoretical predictions.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18493" title="Abstract">arXiv:2402.18493</a> [<a href="/pdf/2402.18493" title="Download PDF">pdf</a>, <a href="/format/2402.18493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sunshine to Rainstorm: Cross-Weather Knowledge Distillation for Robust  3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiaoliang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+C">Chenglu Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cheng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">LiDAR-based 3D object detection models have traditionally struggled under
rainy conditions due to the degraded and noisy scanning signals. Previous
research has attempted to address this by simulating the noise from rain to
improve the robustness of detection models. However, significant disparities
exist between simulated and actual rain-impacted data points. In this work, we
propose a novel rain simulation method, termed DRET, that unifies Dynamics and
Rainy Environment Theory to provide a cost-effective means of expanding the
available realistic rain data for 3D detection training. Furthermore, we
present a Sunny-to-Rainy Knowledge Distillation (SRKD) approach to enhance 3D
detection under rainy conditions. Extensive experiments on the WaymoOpenDataset
large-scale dataset show that, when combined with the state-of-the-art DSVT
model and other classical 3D detectors, our proposed framework demonstrates
significant detection accuracy improvements, without losing efficiency.
Remarkably, our framework also improves detection capabilities under sunny
conditions, therefore offering a robust solution for 3D detection regardless of
whether the weather is rainy or sunny
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18495" title="Abstract">arXiv:2402.18495</a> [<a href="/pdf/2402.18495" title="Download PDF">pdf</a>, <a href="/format/2402.18495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ROG$_{PL}$: Robust Open-Set Graph Learning via Region-Based Prototype  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaowei Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiexin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Liping Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaojun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junyang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Open-set graph learning is a practical task that aims to classify the known
class nodes and to identify unknown class samples as unknowns. Conventional
node classification methods usually perform unsatisfactorily in open-set
scenarios due to the complex data they encounter, such as out-of-distribution
(OOD) data and in-distribution (IND) noise. OOD data are samples that do not
belong to any known classes. They are outliers if they occur in training (OOD
noise), and open-set samples if they occur in testing. IND noise are training
samples which are assigned incorrect labels. The existence of IND noise and OOD
noise is prevalent, which usually cause the ambiguity problem, including the
intra-class variety problem and the inter-class confusion problem. Thus, to
explore robust open-set learning methods is necessary and difficult, and it
becomes even more difficult for non-IID graph data.To this end, we propose a
unified framework named ROG$_{PL}$ to achieve robust open-set learning on
complex noisy graph data, by introducing prototype learning. In specific,
ROG$_{PL}$ consists of two modules, i.e., denoising via label propagation and
open-set prototype learning via regions. The first module corrects noisy labels
through similarity-based label propagation and removes low-confidence samples,
to solve the intra-class variety problem caused by noise. The second module
learns open-set prototypes for each known class via non-overlapped regions and
remains both interior and border prototypes to remedy the inter-class confusion
problem.The two modules are iteratively updated under the constraints of
classification loss and prototype diversity loss. To the best of our knowledge,
the proposed ROG$_{PL}$ is the first robust open-set node classification method
for graph data with complex noise.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18496" title="Abstract">arXiv:2402.18496</a> [<a href="/pdf/2402.18496" title="Download PDF">pdf</a>, <a href="/format/2402.18496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Models Represent Beliefs of Self and Others
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wentao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhining Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yizhou Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page: <a href="https://walter0807.github.io/RepBelief/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Understanding and attributing mental states, known as Theory of Mind (ToM),
emerges as a fundamental capability for human social reasoning. While Large
Language Models (LLMs) appear to possess certain ToM abilities, the mechanisms
underlying these capabilities remain elusive. In this study, we discover that
it is possible to linearly decode the belief status from the perspectives of
various agents through neural activations of language models, indicating the
existence of internal representations of self and others' beliefs. By
manipulating these representations, we observe dramatic changes in the models'
ToM performance, underscoring their pivotal role in the social reasoning
process. Additionally, our findings extend to diverse social reasoning tasks
that involve different causal inference patterns, suggesting the potential
generalizability of these representations.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18498" title="Abstract">arXiv:2402.18498</a> [<a href="/pdf/2402.18498" title="Download PDF">pdf</a>, <a href="/format/2402.18498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Take It, Leave It, or Fix It: Measuring Productivity and Trust in  Human-AI Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Crystal Qian</a>, 
<a href="/search/cs?searchtype=author&query=Wexler%2C+J">James Wexler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Although recent developments in generative AI have greatly enhanced the
capabilities of conversational agents such as Google's Bard or OpenAI's
ChatGPT, it's unclear whether the usage of these agents aids users across
various contexts. To better understand how access to conversational AI affects
productivity and trust, we conducted a mixed-methods, task-based user study,
observing 76 software engineers (N=76) as they completed a programming exam
with and without access to Bard. Effects on performance, efficiency,
satisfaction, and trust vary depending on user expertise, question type
(open-ended "solve" questions vs. definitive "search" questions), and
measurement type (demonstrated vs. self-reported). Our findings include
evidence of automation complacency, increased reliance on the AI over the
course of the task, and increased performance for novices on "solve"-type
questions when using the AI. We discuss common behaviors, design
recommendations, and impact considerations to improve collaborations with
conversational AI.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18502" title="Abstract">arXiv:2402.18502</a> [<a href="/pdf/2402.18502" title="Download PDF">pdf</a>, <a href="/format/2402.18502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-Shot Fairness: Unveiling LLM&#x27;s Potential for Fairness-Aware  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chhikara%2C+G">Garima Chhikara</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Anurag Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+K">Kripabandhu Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+A">Abhijnan Chakraborty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Employing Large Language Models (LLM) in various downstream applications such
as classification is crucial, especially for smaller companies lacking the
expertise and resources required for fine-tuning a model. Fairness in LLMs
helps ensure inclusivity, equal representation based on factors such as race,
gender and promotes responsible AI deployment. As the use of LLMs has become
increasingly prevalent, it is essential to assess whether LLMs can generate
fair outcomes when subjected to considerations of fairness. In this study, we
introduce a framework outlining fairness regulations aligned with various
fairness definitions, with each definition being modulated by varying degrees
of abstraction. We explore the configuration for in-context learning and the
procedure for selecting in-context demonstrations using RAG, while
incorporating fairness rules into the process. Experiments conducted with
different LLMs indicate that GPT-4 delivers superior results in terms of both
accuracy and fairness compared to other models. This work is one of the early
attempts to achieve fairness in prediction tasks by utilizing LLMs through
in-context learning.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18503" title="Abstract">arXiv:2402.18503</a> [<a href="/pdf/2402.18503" title="Download PDF">pdf</a>, <a href="/format/2402.18503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detection of Micromobility Vehicles in Urban Traffic Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sabri%2C+K">Khalil Sabri</a>, 
<a href="/search/cs?searchtype=author&query=Djilali%2C+C">C&#xe9;lia Djilali</a>, 
<a href="/search/cs?searchtype=author&query=Bilodeau%2C+G">Guillaume-Alexandre Bilodeau</a>, 
<a href="/search/cs?searchtype=author&query=Saunier%2C+N">Nicolas Saunier</a>, 
<a href="/search/cs?searchtype=author&query=Bouachir%2C+W">Wassim Bouachir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Urban traffic environments present unique challenges for object detection,
particularly with the increasing presence of micromobility vehicles like
e-scooters and bikes. To address this object detection problem, this work
introduces an adapted detection model that combines the accuracy and speed of
single-frame object detection with the richer features offered by video object
detection frameworks. This is done by applying aggregated feature maps from
consecutive frames processed through motion flow to the YOLOX architecture.
This fusion brings a temporal perspective to YOLOX detection abilities,
allowing for a better understanding of urban mobility patterns and
substantially improving detection reliability. Tested on a custom dataset
curated for urban micromobility scenarios, our model showcases substantial
improvement over existing state-of-the-art methods, demonstrating the need to
consider spatio-temporal information for detecting such small and thin objects.
Our approach enhances detection in challenging conditions, including
occlusions, ensuring temporal consistency, and effectively mitigating motion
blur.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18505" title="Abstract">arXiv:2402.18505</a> [<a href="/pdf/2402.18505" title="Download PDF">pdf</a>, <a href="/ps/2402.18505" title="Download PostScript">ps</a>, <a href="/format/2402.18505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolving machine learning workflows through interactive AutoML
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barbudo%2C+R">Rafael Barbudo</a>, 
<a href="/search/cs?searchtype=author&query=Ram%C3%ADrez%2C+A">Aurora Ram&#xed;rez</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+J+R">Jos&#xe9; Ra&#xfa;l Romero</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 5 figures, 3 tables. Paper submitted to journal. Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Automatic workflow composition (AWC) is a relevant problem in automated
machine learning (AutoML) that allows finding suitable sequences of
preprocessing and prediction models together with their optimal
hyperparameters. This problem can be solved using evolutionary algorithms and,
in particular, grammar-guided genetic programming (G3P). Current G3P approaches
to AWC define a fixed grammar that formally specifies how workflow elements can
be combined and which algorithms can be included. In this paper we present
\ourmethod, an interactive G3P algorithm that allows users to dynamically
modify the grammar to prune the search space and focus on their regions of
interest. Our proposal is the first to combine the advantages of a G3P method
with ideas from interactive optimisation and human-guided machine learning, an
area little explored in the context of AutoML. To evaluate our approach, we
present an experimental study in which 20 participants interact with \ourmethod
to evolve workflows according to their preferences. Our results confirm that
the collaboration between \ourmethod and humans allows us to find
high-performance workflows in terms of accuracy that require less tuning time
than those found without human intervention.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18507" title="Abstract">arXiv:2402.18507</a> [<a href="/pdf/2402.18507" title="Download PDF">pdf</a>, <a href="/format/2402.18507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Learning To Improve Cardiac Late Mechanical Activation  Detection From Cine MR Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+J">Jiarui Xing</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+N">Nian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Bilchick%2C+K">Kenneth Bilchick</a>, 
<a href="/search/cs?searchtype=author&query=Epstein%2C+F">Frederick Epstein</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Miaomiao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents a multimodal deep learning framework that utilizes
advanced image techniques to improve the performance of clinical analysis
heavily dependent on routinely acquired standard images. More specifically, we
develop a joint learning network that for the first time leverages the accuracy
and reproducibility of myocardial strains obtained from Displacement Encoding
with Stimulated Echo (DENSE) to guide the analysis of cine cardiac magnetic
resonance (CMR) imaging in late mechanical activation (LMA) detection. An image
registration network is utilized to acquire the knowledge of cardiac motions,
an important feature estimator of strain values, from standard cine CMRs. Our
framework consists of two major components: (i) a DENSE-supervised strain
network leveraging latent motion features learned from a registration network
to predict myocardial strains; and (ii) a LMA network taking advantage of the
predicted strain for effective LMA detection. Experimental results show that
our proposed work substantially improves the performance of strain analysis and
LMA detection from cine CMR images, aligning more closely with the achievements
of DENSE.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18508" title="Abstract">arXiv:2402.18508</a> [<a href="/pdf/2402.18508" title="Download PDF">pdf</a>, <a href="/format/2402.18508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orchid: Flexible and Data-Dependent Convolution for Sequence Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karami%2C+M">Mahdi Karami</a>, 
<a href="/search/cs?searchtype=author&query=Ghodsi%2C+A">Ali Ghodsi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In the rapidly evolving landscape of deep learning, the quest for models that
balance expressivity with computational efficiency has never been more
critical. This paper introduces Orchid, a novel architecture that reimagines
sequence modeling by incorporating a new data-dependent convolution mechanism.
Orchid is designed to address the inherent limitations of traditional attention
mechanisms, particularly their quadratic complexity, without compromising the
ability to capture long-range dependencies and in-context learning. At the core
of Orchid lies the data-dependent convolution layer, which dynamically adjusts
its kernel conditioned on input data using a dedicated conditioning neural
network. We design two simple conditioning networks that maintain shift
equivariance in the adaptive convolution operation. The dynamic nature of
data-dependent convolution kernel, coupled with gating operations, grants
Orchid high expressivity while maintaining efficiency and quasilinear
scalability for long sequences. We rigorously evaluate Orchid across multiple
domains, including language modeling and image classification, to showcase its
performance and generality. Our experiments demonstrate that Orchid
architecture not only outperforms traditional attention-based architectures
such as BERT and Vision Transformers with smaller model sizes, but also extends
the feasible sequence length beyond the limitations of the dense attention
layers. This achievement represents a significant step towards more efficient
and scalable deep learning models for sequence modeling.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18510" title="Abstract">arXiv:2402.18510</a> [<a href="/pdf/2402.18510" title="Download PDF">pdf</a>, <a href="/format/2402.18510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RNNs are not Transformers (Yet): The Key Bottleneck on In-context  Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+K">Kaiyue Wen</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+X">Xingyu Dang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+K">Kaifeng Lyu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper investigates the gap in representation powers of Recurrent Neural
Networks (RNNs) and Transformers in the context of solving algorithmic
problems. We focus on understanding whether RNNs, known for their memory
efficiency in handling long sequences, can match the performance of
Transformers, particularly when enhanced with Chain-of-Thought (CoT) prompting.
Our theoretical analysis reveals that CoT improves RNNs but is insufficient to
close the gap with Transformers. A key bottleneck lies in the inability of RNNs
to perfectly retrieve information from the context, even with CoT: for several
tasks that explicitly or implicitly require this capability, such as
associative recall and determining if a graph is a tree, we prove that RNNs are
not expressive enough to solve the tasks while Transformers can solve them with
ease. Conversely, we prove that adopting techniques to enhance the in-context
retrieval capability of RNNs, including Retrieval-Augmented Generation (RAG)
and adding a single Transformer layer, can elevate RNNs to be capable of
solving all polynomial-time solvable problems with CoT, hence closing the
representation gap with Transformers.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18511" title="Abstract">arXiv:2402.18511</a> [<a href="/pdf/2402.18511" title="Download PDF">pdf</a>, <a href="/ps/2402.18511" title="Download PostScript">ps</a>, <a href="/format/2402.18511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Compliant Tactile Perception for Haptic Blind Surface  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheret%2C+L+Y+E+R">Laurent Yves Emile Ramos Cheret</a>, 
<a href="/search/cs?searchtype=author&query=da+Fonseca%2C+V+P">Vinicius Prado da Fonseca</a>, 
<a href="/search/cs?searchtype=author&query=de+Oliveira%2C+T+E+A">Thiago Eustaquio Alves de Oliveira</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 9 figures, 2024 IEEE International Conference on Robotics and Automation (ICRA 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Non-flat surfaces pose difficulties for robots operating in unstructured
environments. Reconstructions of uneven surfaces may only be partially possible
due to non-compliant end-effectors and limitations on vision systems such as
transparency, reflections, and occlusions. This study achieves blind surface
reconstruction by harnessing the robotic manipulator's kinematic data and a
compliant tactile sensing module, which incorporates inertial, magnetic, and
pressure sensors. The module's flexibility enables us to estimate contact
positions and surface normals by analyzing its deformation during interactions
with unknown objects. While previous works collect only positional information,
we include the local normals in a geometrical approach to estimate curvatures
between adjacent contact points. These parameters then guide a spline-based
patch generation, which allows us to recreate larger surfaces without an
increase in complexity while reducing the time-consuming step of probing the
surface. Experimental validation demonstrates that this approach outperforms an
off-the-shelf vision system in estimation accuracy. Moreover, this compliant
haptic method works effectively even when the manipulator's approach angle is
not aligned with the surface normals, which is ideal for unknown non-flat
surfaces.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18512" title="Abstract">arXiv:2402.18512</a> [<a href="/pdf/2402.18512" title="Download PDF">pdf</a>, <a href="/format/2402.18512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Log Neural Controlled Differential Equations: The Lie Brackets Make a  Difference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Walker%2C+B">Benjamin Walker</a>, 
<a href="/search/cs?searchtype=author&query=McLeod%2C+A+D">Andrew D. McLeod</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+T">Tiexin Qin</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yichuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Lyons%2C+T">Terry Lyons</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The vector field of a controlled differential equation (CDE) describes the
relationship between a control path and the evolution of a solution path.
Neural CDEs (NCDEs) treat time series data as observations from a control path,
parameterise a CDE's vector field using a neural network, and use the solution
path as a continuously evolving hidden state. As their formulation makes them
robust to irregular sampling rates, NCDEs are a powerful approach for modelling
real-world data. Building on neural rough differential equations (NRDEs), we
introduce Log-NCDEs, a novel and effective method for training NCDEs. The core
component of Log-NCDEs is the Log-ODE method, a tool from the study of rough
paths for approximating a CDE's solution. On a range of multivariate time
series classification benchmarks, Log-NCDEs are shown to achieve a higher
average test set accuracy than NCDEs, NRDEs, and two state-of-the-art models,
S5 and the linear recurrent unit.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18516" title="Abstract">arXiv:2402.18516</a> [<a href="/pdf/2402.18516" title="Download PDF">pdf</a>, <a href="/ps/2402.18516" title="Download PostScript">ps</a>, <a href="/format/2402.18516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Predictive Control with adaptive resilience for Denial-of-Service  Attacks mitigation on a Regulated Dam
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cestari%2C+R+G">Raffaele Giuseppe Cestari</a>, 
<a href="/search/eess?searchtype=author&query=Longari%2C+S">Stefano Longari</a>, 
<a href="/search/eess?searchtype=author&query=Zanero%2C+S">Stefano Zanero</a>, 
<a href="/search/eess?searchtype=author&query=Formentin%2C+S">Simone Formentin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">In recent years, SCADA (Supervisory Control and Data Acquisition) systems
have increasingly become the target of cyber attacks. SCADAs are no longer
isolated, as web-based applications expose strategic infrastructures to the
outside world connection. In a cyber-warfare context, we propose a Model
Predictive Control (MPC) architecture with adaptive resilience, capable of
guaranteeing control performance in normal operating conditions and driving
towards resilience against DoS (controller-actuator) attacks when needed. Since
the attackers' goal is typically to maximize the system damage, we assume they
solve an adversarial optimal control problem. An adaptive resilience factor is
then designed as a function of the intensity function of a Hawkes process, a
point process model estimating the occurrence of random events in time, trained
on a moving window to estimate the return time of the next attack. We
demonstrate the resulting MPC strategy's effectiveness in 2 attack scenarios on
a real system with actual data, the regulated Olginate dam of Lake Como.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18526" title="Abstract">arXiv:2402.18526</a> [<a href="/pdf/2402.18526" title="Download PDF">pdf</a>, <a href="/format/2402.18526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mental Models of Meeting Goals: Supporting Intentionality in Meeting  Technologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scott%2C+A+E">Ava Elizabeth Scott</a>, 
<a href="/search/cs?searchtype=author&query=Tankelevitch%2C+L">Lev Tankelevitch</a>, 
<a href="/search/cs?searchtype=author&query=Rintel%2C+S">Sean Rintel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Ineffective meetings due to unclear goals are major obstacles to
productivity, yet support for intentionality is surprisingly scant in our
meeting and allied workflow technologies. To design for intentionality, we need
to understand workers' attitudes and practices around goals. We interviewed 21
employees of a global technology company and identified contrasting mental
models of meeting goals: meetings as a means to an end, and meetings as an end
in themselves. We explore how these mental models impact how meeting goals
arise, goal prioritization, obstacles to considering goals, and how lack of
alignment around goals may create tension between organizers and attendees. We
highlight the challenges in balancing preparation, constraining scope, and
clear outcomes, with the need for intentional adaptability and discovery in
meetings. Our findings have implications for designing systems which increase
effectiveness in meetings by catalyzing intentionality and reducing tension in
the organisation of meetings.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18527" title="Abstract">arXiv:2402.18527</a> [<a href="/pdf/2402.18527" title="Download PDF">pdf</a>, <a href="/format/2402.18527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defect Detection in Tire X-Ray Images: Conventional Methods Meet Deep  Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cozma%2C+A">Andrei Cozma</a>, 
<a href="/search/cs?searchtype=author&query=Harris%2C+L">Landon Harris</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+H">Hairong Qi</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+P">Ping Ji</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wenpeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+S">Song Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures, 3 tables, submitted to ICIP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">This paper introduces a robust approach for automated defect detection in
tire X-ray images by harnessing traditional feature extraction methods such as
Local Binary Pattern (LBP) and Gray Level Co-Occurrence Matrix (GLCM) features,
as well as Fourier and Wavelet-based features, complemented by advanced machine
learning techniques. Recognizing the challenges inherent in the complex
patterns and textures of tire X-ray images, the study emphasizes the
significance of feature engineering to enhance the performance of defect
detection systems. By meticulously integrating combinations of these features
with a Random Forest (RF) classifier and comparing them against advanced models
like YOLOv8, the research not only benchmarks the performance of traditional
features in defect detection but also explores the synergy between classical
and modern approaches. The experimental results demonstrate that these
traditional features, when fine-tuned and combined with machine learning
models, can significantly improve the accuracy and reliability of tire defect
detection, aiming to set a new standard in automated quality assurance in tire
manufacturing.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18528" title="Abstract">arXiv:2402.18528</a> [<a href="/pdf/2402.18528" title="Download PDF">pdf</a>, <a href="/format/2402.18528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient Reweighting: Towards Imbalanced Class-Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiangpeng He</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Fengqing Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Class-Incremental Learning (CIL) trains a model to continually recognize new
classes from non-stationary data while retaining learned knowledge. A major
challenge of CIL arises when applying to real-world data characterized by
non-uniform distribution, which introduces a dual imbalance problem involving
(i) disparities between stored exemplars of old tasks and new class data
(inter-phase imbalance), and (ii) severe class imbalances within each
individual task (intra-phase imbalance). We show that this dual imbalance issue
causes skewed gradient updates with biased weights in FC layers, thus inducing
over/under-fitting and catastrophic forgetting in CIL. Our method addresses it
by reweighting the gradients towards balanced optimization and unbiased
classifier learning. Additionally, we observe imbalanced forgetting where
paradoxically the instance-rich classes suffer higher performance degradation
during CIL due to a larger amount of training data becoming unavailable in
subsequent learning phases. To tackle this, we further introduce a
distribution-aware knowledge distillation loss to mitigate forgetting by
aligning output logits proportionally with the distribution of lost training
data. We validate our method on CIFAR-100, ImageNetSubset, and Food101 across
various evaluation protocols and demonstrate consistent improvements compared
to existing works, showing great potential to apply CIL in real-world scenarios
with enhanced robustness and effectiveness.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18537" title="Abstract">arXiv:2402.18537</a> [<a href="/pdf/2402.18537" title="Download PDF">pdf</a>, <a href="/format/2402.18537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the enumeration of signatures of XOR-CNF&#x27;s
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Creignou%2C+N">Nadia Creignou</a>, 
<a href="/search/cs?searchtype=author&query=Defrain%2C+O">Oscar Defrain</a>, 
<a href="/search/cs?searchtype=author&query=Olive%2C+F">Fr&#xe9;d&#xe9;ric Olive</a>, 
<a href="/search/cs?searchtype=author&query=Vilmin%2C+S">Simon Vilmin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">Given a CNF formula $\varphi$ with clauses $C_1, \dots, C_m$ over a set of
variables $V$, a truth assignment $\mathbf{a} : V \to \{0, 1\}$ generates a
binary sequence $\sigma_\varphi(\mathbf{a})=(C_1(\mathbf{a}), \ldots,
C_m(\mathbf{a}))$, called a signature of $\varphi$, where $C_i(\mathbf{a})=1$
if clause $C_i$ evaluates to 1 under assignment $\mathbf{a}$, and
$C_i(\mathbf{a})=0$ otherwise. Signatures and their associated generation
problems have given rise to new yet promising research questions in algorithmic
enumeration. In a recent paper, B\'erczi et al. interestingly proved that
generating signatures of a CNF is tractable despite the fact that verifying a
solution is hard. They also showed the hardness of finding maximal signatures
of an arbitrary CNF due to the intractability of satisfiability in general.
Their contribution leaves open the problem of efficiently generating maximal
signatures for tractable classes of CNFs, i.e., those for which satisfiability
can be solved in polynomial time. Stepping into that direction, we completely
characterize the complexity of generating all, minimal, and maximal signatures
for XOR-CNFs.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18540" title="Abstract">arXiv:2402.18540</a> [<a href="/pdf/2402.18540" title="Download PDF">pdf</a>, <a href="/format/2402.18540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Keeping LLMs Aligned After Fine-tuning: The Crucial Role of Prompt  Templates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+K">Kaifeng Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haoyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xinran Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dingli Yu</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+A">Anirudh Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+S">Sanjeev Arora</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Public LLMs such as the Llama 2-Chat have driven huge activity in LLM
research. These models underwent alignment training and were considered safe.
Recently Qi et al. (2023) reported that even benign fine-tuning (e.g., on
seemingly safe datasets) can give rise to unsafe behaviors in the models. The
current paper is about methods and best practices to mitigate such loss of
alignment. Through extensive experiments on several chat models (Meta's Llama
2-Chat, Mistral AI's Mistral 7B Instruct v0.2, and OpenAI's GPT-3.5 Turbo),
this paper uncovers that the prompt templates used during fine-tuning and
inference play a crucial role in preserving safety alignment, and proposes the
"Pure Tuning, Safe Testing" (PTST) principle -- fine-tune models without a
safety prompt, but include it at test time. Fine-tuning experiments on GSM8K,
ChatDoctor, and OpenOrca show that PTST significantly reduces the rise of
unsafe behaviors, and even almost eliminates them in some cases.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18541" title="Abstract">arXiv:2402.18541</a> [<a href="/pdf/2402.18541" title="Download PDF">pdf</a>, <a href="/ps/2402.18541" title="Download PostScript">ps</a>, <a href="/format/2402.18541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Deterministic Constant-Approximate Distance Oracles with  $n^&#x3b5;$ Worst-Case Update Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haeupler%2C+B">Bernhard Haeupler</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+Y">Yaowei Long</a>, 
<a href="/search/cs?searchtype=author&query=Saranurak%2C+T">Thatchaphol Saranurak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 120 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We present a new distance oracle in the fully dynamic setting: given a
weighted undirected graph $G=(V,E)$ with $n$ vertices undergoing both edge
insertions and deletions, and an arbitrary parameter $\epsilon$ where
$1/\log^{c} n&lt;\epsilon&lt;1$ and $c&gt;0$ is a small constant, we can
deterministically maintain a data structure with $n^{\epsilon}$ worst-case
update time that, given any pair of vertices $(u,v)$, returns a $2^{{\rm
poly}(1/\epsilon)}$-approximate distance between $u$ and $v$ in ${\rm
poly}(1/\epsilon)\log\log n$ query time.
<br />Our algorithm significantly advances the state-of-the-art in two aspects,
both for fully dynamic algorithms and even decremental algorithms. First, no
existing algorithm with worst-case update time guarantees a
$o(n)$-approximation while also achieving an $n^{2-\Omega(1)}$ update and
$n^{o(1)}$ query time, while our algorithm offers a constant
$O_{\epsilon}(1)$-approximation with $n^{\epsilon}$ update time and
$O_{\epsilon}(\log \log n)$ query time. Second, even if amortized update time
is allowed, it is the first deterministic constant-approximation algorithm with
$n^{1-\Omega(1)}$ update and query time. The best result in this direction is
the recent deterministic distance oracle by Chuzhoy and Zhang [STOC 2023] which
achieves an approximation of $(\log\log n)^{2^{O(1/\epsilon^{3})}}$ with
amortized update time of $n^{\epsilon}$ and query time of $2^{{\rm
poly}(1/\epsilon)}\log n\log\log n$.
<br />We obtain the result by dynamizing tools related to length-constrained
expanders [Haeupler-R\"acke-Ghaffari, STOC 2022; Haeupler-Hershkowitz-Tan,
2023; Haeupler-Huebotter-Ghaffari, 2022]. Our technique completely bypasses the
40-year-old Even-Shiloach tree, which has remained the most pervasive tool in
the area but is inherently amortized.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18545" title="Abstract">arXiv:2402.18545</a> [<a href="/pdf/2402.18545" title="Download PDF">pdf</a>, <a href="/format/2402.18545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crowdsourcing Dermatology Images with Google Search Ads: Creating a  Real-World Skin Condition Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ward%2C+A">Abbi Ward</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jimmy Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Julie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lakshminarasimhan%2C+S">Sriram Lakshminarasimhan</a>, 
<a href="/search/cs?searchtype=author&query=Carrick%2C+A">Ashley Carrick</a>, 
<a href="/search/cs?searchtype=author&query=Campana%2C+B">Bilson Campana</a>, 
<a href="/search/cs?searchtype=author&query=Hartford%2C+J">Jay Hartford</a>, 
<a href="/search/cs?searchtype=author&query=S%2C+P+K">Pradeep Kumar S</a>, 
<a href="/search/cs?searchtype=author&query=Tiyasirichokchai%2C+T">Tiya Tiyasirichokchai</a>, 
<a href="/search/cs?searchtype=author&query=Virmani%2C+S">Sunny Virmani</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+R">Renee Wong</a>, 
<a href="/search/cs?searchtype=author&query=Matias%2C+Y">Yossi Matias</a>, 
<a href="/search/cs?searchtype=author&query=Corrado%2C+G+S">Greg S. Corrado</a>, 
<a href="/search/cs?searchtype=author&query=Webster%2C+D+R">Dale R. Webster</a>, 
<a href="/search/cs?searchtype=author&query=Siegel%2C+D">Dawn Siegel</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Steven Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+J">Justin Ko</a>, 
<a href="/search/cs?searchtype=author&query=Karthikesalingam%2C+A">Alan Karthikesalingam</a>, 
<a href="/search/cs?searchtype=author&query=Semturs%2C+C">Christopher Semturs</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+P">Pooja Rao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Background: Health datasets from clinical sources do not reflect the breadth
and diversity of disease in the real world, impacting research, medical
education, and artificial intelligence (AI) tool development. Dermatology is a
suitable area to develop and test a new and scalable method to create
representative health datasets.
<br />Methods: We used Google Search advertisements to invite contributions to an
open access dataset of images of dermatology conditions, demographic and
symptom information. With informed contributor consent, we describe and release
this dataset containing 10,408 images from 5,033 contributions from internet
users in the United States over 8 months starting March 2023. The dataset
includes dermatologist condition labels as well as estimated Fitzpatrick Skin
Type (eFST) and Monk Skin Tone (eMST) labels for the images.
<br />Results: We received a median of 22 submissions/day (IQR 14-30). Female
(66.72%) and younger (52% &lt; age 40) contributors had a higher representation in
the dataset compared to the US population, and 32.6% of contributors reported a
non-White racial or ethnic identity. Over 97.5% of contributions were genuine
images of skin conditions. Dermatologist confidence in assigning a differential
diagnosis increased with the number of available variables, and showed a weaker
correlation with image sharpness (Spearman's P values &lt;0.001 and 0.01
respectively). Most contributions were short-duration (54% with onset &lt; 7 days
ago ) and 89% were allergic, infectious, or inflammatory conditions. eFST and
eMST distributions reflected the geographical origin of the dataset. The
dataset is available at github.com/google-research-datasets/scin .
<br />Conclusion: Search ads are effective at crowdsourcing images of health
conditions. The SCIN dataset bridges important gaps in the availability of
representative images of common skin conditions.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18546" title="Abstract">arXiv:2402.18546</a> [<a href="/pdf/2402.18546" title="Download PDF">pdf</a>, <a href="/format/2402.18546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizability Under Sensor Failure: Tokenization + Transformers  Enable More Robust Latent Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chau%2C+G">Geeling Chau</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+Y">Yujin An</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+A+R">Ahamed Raffey Iqbal</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+S">Soon-Jo Chung</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yisong Yue</a>, 
<a href="/search/cs?searchtype=author&query=Talukder%2C+S">Sabera Talukder</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">A major goal in neuroscience is to discover neural data representations that
generalize. This goal is challenged by variability along recording sessions
(e.g. environment), subjects (e.g. varying neural structures), and sensors
(e.g. sensor noise), among others. Recent work has begun to address
generalization across sessions and subjects, but few study robustness to sensor
failure which is highly prevalent in neuroscience experiments. In order to
address these generalizability dimensions we first collect our own
electroencephalography dataset with numerous sessions, subjects, and sensors,
then study two time series models: EEGNet (Lawhern et al., 2018) and TOTEM
(Talukder et al., 2024). EEGNet is a widely used convolutional neural network,
while TOTEM is a discrete time series tokenizer and transformer model. We find
that TOTEM outperforms or matches EEGNet across all generalizability cases.
Finally through analysis of TOTEM's latent codebook we observe that
tokenization enables generalization.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18551" title="Abstract">arXiv:2402.18551</a> [<a href="/pdf/2402.18551" title="Download PDF">pdf</a>, <a href="/format/2402.18551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Bias of Next-Token Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thrampoulidis%2C+C">Christos Thrampoulidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
<p class="mathjax">Next-token prediction (NTP), the go-to training paradigm in training large
language models, involves predicting the next token in a sequence. Departing
from traditional one-hot classification, in NTP, multiple tokens with varying
frequencies follow each given context. This work frames NTP training as
cross-entropy minimization over distinct contexts, each associated with a
sparse empirical probability vector across a finite vocabulary. It then
addresses the following question: do gradient-based optimizers exhibit a bias
towards solutions with specific structure as the NTP training loss reaches its
lower bound (entropy)? Specifically, for linear NTP models trained using
gradient descent (GD), we make the following contributions: Firstly, we
determine NTP-separability conditions on the data, under which GD can attain
its lower bound. We also demonstrate that these conditions hold under
overparameterization. Secondly, we establish that the parameters of GD
projected onto an appropriate data subspace converge to the unique solution of
a system of linear equations, which requires the logits' difference of
in-support tokens to be equal to the log-ratio of their respective
probabilities. Meanwhile, on the orthogonal subspace, the parameters diverge
and converge in the direction of the solution of a max-margin quadratic
program, minimizing the Euclidean norm of parameters satisfying the
\NTP-separability conditions. Akin to prior research on implicit bias of
one-hot classification, our work opens exciting avenues for future research
that can lead to better understanding optimization, generalization and
robustness principles of models trained with NTP.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18553" title="Abstract">arXiv:2402.18553</a> [<a href="/pdf/2402.18553" title="Download PDF">pdf</a>, <a href="/ps/2402.18553" title="Download PostScript">ps</a>, <a href="/format/2402.18553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Selection of appropriate multispectral camera exposure settings and  radiometric calibration methods for applications in phenotyping and precision  agriculture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Swaminathan%2C+V">Vaishali Swaminathan</a>, 
<a href="/search/cs?searchtype=author&query=Thomasson%2C+J+A">J. Alex Thomasson</a>, 
<a href="/search/cs?searchtype=author&query=Hardin%2C+R+G">Robert G. Hardin</a>, 
<a href="/search/cs?searchtype=author&query=Rajan%2C+N">Nithya Rajan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Radiometric accuracy of data is crucial in quantitative precision
agriculture, to produce reliable and repeatable data for modeling and decision
making. The effect of exposure time and gain settings on the radiometric
accuracy of multispectral images was not explored enough. The goal of this
study was to determine if having a fixed exposure (FE) time during image
acquisition improved radiometric accuracy of images, compared to the default
auto-exposure (AE) settings. This involved quantifying the errors from
auto-exposure and determining ideal exposure values within which radiometric
mean absolute percentage error (MAPE) were minimal (&lt; 5%). The results showed
that FE orthomosaic was closer to ground-truth (higher R2 and lower MAPE) than
AE orthomosaic. An ideal exposure range was determined for capturing canopy and
soil objects, without loss of information from under-exposure or saturation
from over-exposure. A simulation of errors from AE showed that MAPE &lt; 5% for
the blue, green, red, and NIR bands and &lt; 7% for the red edge band for exposure
settings within the determined ideal ranges and increased exponentially beyond
the ideal exposure upper limit. Further, prediction of total plant nitrogen
uptake (g/plant) using vegetation indices (VIs) from two different growing
seasons were closer to the ground truth (mostly, R2 &gt; 0.40, and MAPE = 12 to
14%, p &lt; 0.05) when FE was used, compared to the prediction from AE images
(mostly, R2 &lt; 0.13, MAPE = 15 to 18%, p &gt;= 0.05).
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18554" title="Abstract">arXiv:2402.18554</a> [<a href="/pdf/2402.18554" title="Download PDF">pdf</a>, <a href="/format/2402.18554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extended Kalman filter -- Koopman operator for tractable stochastic  optimal control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ramadan%2C+M+S">Mohammad S. Ramadan</a>, 
<a href="/search/eess?searchtype=author&query=Anitescu%2C+M">Mihai Anitescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">It has been more than seven decades since the introduction of the theory of
dual control \cite{feldbaum1960dual}. Although it has provided rich insights to
the fields of control, estimation, and system identification, dual control is
generally computationally prohibitive. In recent years, however, the use of
Koopman operator theory for control applications has been emerging. The paper
presents a new reformulation of the stochastic optimal control problem that,
employing the Koopman operator, yields a standard LQR problem with the dual
control as its solution. We conclude the paper with a numerical example that
demonstrates the effectiveness of the proposed approach, compared to certainty
equivalence control, when applied to systems with varying observability.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18558" title="Abstract">arXiv:2402.18558</a> [<a href="/pdf/2402.18558" title="Download PDF">pdf</a>, <a href="/format/2402.18558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unifying F1TENTH Autonomous Racing: Survey, Methods and Benchmarks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Evans%2C+B+D">Benjamin David Evans</a>, 
<a href="/search/cs?searchtype=author&query=Trumpp%2C+R">Raphael Trumpp</a>, 
<a href="/search/cs?searchtype=author&query=Caccamo%2C+M">Marco Caccamo</a>, 
<a href="/search/cs?searchtype=author&query=Jordaan%2C+H+W">Hendrik Willem Jordaan</a>, 
<a href="/search/cs?searchtype=author&query=Engelbrecht%2C+H+A">Herman Arnold Engelbrecht</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 18 figures. Sumbitted for publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The F1TENTH autonomous racing platform, consisting of 1:10 scale RC cars, has
evolved into a leading research platform. The many publications and real-world
competitions span many domains, from classical path planning to novel
learning-based algorithms. Consequently, the field is wide and disjointed,
hindering direct comparison of methods and making it difficult to assess the
state-of-the-art. Therefore, we aim to unify the field by surveying current
approaches, describing common methods and providing benchmark results to
facilitate clear comparison and establish a baseline for future work. We survey
current work in F1TENTH racing in the classical and learning categories,
explaining the different solution approaches. We describe particle filter
localisation, trajectory optimisation and tracking, model predictive contouring
control (MPCC), follow-the-gap and end-to-end reinforcement learning. We
provide an open-source evaluation of benchmark methods and investigate
overlooked factors of control frequency and localisation accuracy for classical
methods and reward signal and training map for learning methods. The evaluation
shows that the optimisation and tracking method achieves the fastest lap times,
followed by the MPCC planner. Finally, our work identifies and outlines the
relevant research aspects to help motivate future work in the F1TENTH domain.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18563" title="Abstract">arXiv:2402.18563</a> [<a href="/pdf/2402.18563" title="Download PDF">pdf</a>, <a href="/format/2402.18563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approaching Human-Level Forecasting with Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Halawi%2C+D">Danny Halawi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fred Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yueh-Han%2C+C">Chen Yueh-Han</a>, 
<a href="/search/cs?searchtype=author&query=Steinhardt%2C+J">Jacob Steinhardt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Forecasting future events is important for policy and decision making. In
this work, we study whether language models (LMs) can forecast at the level of
competitive human forecasters. Towards this goal, we develop a
retrieval-augmented LM system designed to automatically search for relevant
information, generate forecasts, and aggregate predictions. To facilitate our
study, we collect a large dataset of questions from competitive forecasting
platforms. Under a test set published after the knowledge cut-offs of our LMs,
we evaluate the end-to-end performance of our system against the aggregates of
human forecasts. On average, the system nears the crowd aggregate of
competitive forecasters, and in some settings surpasses it. Our work suggests
that using LMs to forecast the future could provide accurate predictions at
scale and help to inform institutional decision making.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18566" title="Abstract">arXiv:2402.18566</a> [<a href="/pdf/2402.18566" title="Download PDF">pdf</a>, <a href="/format/2402.18566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Categorization of Complexity Classes for Information Retrieval and  Synthesis Using Natural Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coppola%2C+G">Gregory Coppola</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Given the emergent reasoning abilities of large language models, information
retrieval is becoming more complex. Rather than just retrieve a document,
modern information retrieval systems advertise that they can synthesize an
answer based on potentially many different documents, conflicting data sources,
and using reasoning. But, different kinds of questions have different answers,
and different answers have different complexities. In this paper, we introduce
a novel framework for analyzing the complexity of a question answer based on
the natural deduction calculus as presented in Prawitz (1965). Our framework is
novel both in that no one to our knowledge has used this logic as a basis for
complexity classes, and also in that no other existing complexity classes to
these have been delineated using any analogous methods either. We identify
three decidable fragments in particular called the forward, query and planning
fragments, and we compare this to what would be needed to do proofs for the
complete first-order calculus, for which theorem-proving is long known to be
undecidable.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18567" title="Abstract">arXiv:2402.18567</a> [<a href="/pdf/2402.18567" title="Download PDF">pdf</a>, <a href="/format/2402.18567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Language Models Are Versatile Protein Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zaixiang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+F">Fei Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+D">Dongyu Xue</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shujian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Quanquan Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
<p class="mathjax">This paper introduces diffusion protein language model (DPLM), a versatile
protein language model that demonstrates strong generative and predictive
capabilities for protein sequences. We first pre-train scalable DPLMs from
evolutionary-scale protein sequences within a generative self-supervised
discrete diffusion probabilistic framework, which generalizes language modeling
for proteins in a principled way. After pre-training, DPLM exhibits the ability
to generate structurally plausible, novel, and diverse protein sequences for
unconditional generation. We further demonstrate the proposed diffusion
generative pre-training makes DPLM possess a better understanding of proteins,
making it a superior representation learner, which can be fine-tuned for
various predictive tasks, comparing favorably to ESM2 (Lin et al., 2022).
Moreover, DPLM can be tailored for various needs, which showcases its prowess
of conditional generation in several ways: (1) conditioning on partial peptide
sequences, e.g., generating scaffolds for functional motifs with high success
rate; (2) incorporating other modalities as conditioner, e.g.,
structure-conditioned generation for inverse folding; and (3) steering sequence
generation towards desired properties, e.g., satisfying specified secondary
structures, through a plug-and-play classifier guidance.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18569" title="Abstract">arXiv:2402.18569</a> [<a href="/pdf/2402.18569" title="Download PDF">pdf</a>, <a href="/format/2402.18569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-Aware Heterogeneous Federated Learning via Approximate Systolic  DNN Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pfeiffer%2C+K">Kilian Pfeiffer</a>, 
<a href="/search/cs?searchtype=author&query=Balaskas%2C+K">Konstantinos Balaskas</a>, 
<a href="/search/cs?searchtype=author&query=Siozios%2C+K">Kostas Siozios</a>, 
<a href="/search/cs?searchtype=author&query=Henkel%2C+J">J&#xf6;rg Henkel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">In Federated Learning (FL), devices that participate in the training usually
have heterogeneous resources, i.e., energy availability. In current deployments
of FL, devices that do not fulfill certain hardware requirements are often
dropped from the collaborative training. However, dropping devices in FL can
degrade training accuracy and introduce bias or unfairness. Several works have
tacked this problem on an algorithmic level, e.g., by letting constrained
devices train a subset of the server neural network (NN) model. However, it has
been observed that these techniques are not effective w.r.t. accuracy.
Importantly, they make simplistic assumptions about devices' resources via
indirect metrics such as multiply accumulate (MAC) operations or peak memory
requirements. In this work, for the first time, we consider on-device
accelerator design for FL with heterogeneous devices. We utilize compressed
arithmetic formats and approximate computing, targeting to satisfy limited
energy budgets. Using a hardware-aware energy model, we observe that, contrary
to the state of the art's moderate energy reduction, our technique allows for
lowering the energy requirements (by 4x) while maintaining higher accuracy.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18571" title="Abstract">arXiv:2402.18571</a> [<a href="/pdf/2402.18571" title="Download PDF">pdf</a>, <a href="/format/2402.18571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arithmetic Control of LLMs for Diverse User Preferences: Directional  Preference Alignment with Multi-Objective Rewards
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+W">Wei Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Rui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Diao%2C+S">Shizhe Diao</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+S">Shuang Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Han Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code and model are released at <a href="https://github.com/Haoxiang-Wang/directional-preference-alignment">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
<p class="mathjax">Fine-grained control over large language models (LLMs) remains a significant
challenge, hindering their adaptability to diverse user needs. While
Reinforcement Learning from Human Feedback (RLHF) shows promise in aligning
LLMs, its reliance on scalar rewards often limits its ability to capture
diverse user preferences in real-world applications. To address this
limitation, we introduce the Directional Preference Alignment (DPA) framework.
Unlike the scalar-reward RLHF, DPA incorporates multi-objective reward modeling
to represent diverse preference profiles. Additionally, DPA models user
preferences as directions (i.e., unit vectors) in the reward space to achieve
user-dependent preference control. Our method involves training a
multi-objective reward model and then fine-tuning the LLM with a
preference-conditioned variant of Rejection Sampling Finetuning (RSF), an RLHF
method adopted by Llama 2. This method enjoys a better performance trade-off
across various reward objectives. In comparison with the scalar-reward RLHF,
DPA offers users intuitive control over LLM generation: they can arithmetically
specify their desired trade-offs (e.g., more helpfulness with less verbosity).
We also validate the effectiveness of DPA with real-world alignment experiments
on Mistral-7B. Our method provides straightforward arithmetic control over the
trade-off between helpfulness and verbosity while maintaining competitive
performance with strong baselines such as Direct Preference Optimization (DPO).
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18573" title="Abstract">arXiv:2402.18573</a> [<a href="/pdf/2402.18573" title="Download PDF">pdf</a>, <a href="/format/2402.18573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniMODE: Unified Monocular 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuoling Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaogang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">SerNam Lim</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hengshuang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication in CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Realizing unified monocular 3D object detection, including both indoor and
outdoor scenes, holds great importance in applications like robot navigation.
However, involving various scenarios of data to train models poses challenges
due to their significantly different characteristics, e.g., diverse geometry
properties and heterogeneous domain distributions. To address these challenges,
we build a detector based on the bird's-eye-view (BEV) detection paradigm,
where the explicit feature projection is beneficial to addressing the geometry
learning ambiguity when employing multiple scenarios of data to train
detectors. Then, we split the classical BEV detection architecture into two
stages and propose an uneven BEV grid design to handle the convergence
instability caused by the aforementioned challenges. Moreover, we develop a
sparse BEV feature projection strategy to reduce computational cost and a
unified domain alignment method to handle heterogeneous domains. Combining
these techniques, a unified detector UniMODE is derived, which surpasses the
previous state-of-the-art on the challenging Omni3D dataset (a large-scale
dataset including both indoor and outdoor scenes) by 4.9% AP_3D, revealing the
first successful generalization of a BEV detector to unified 3D object
detection.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Thu, 29 Feb 24</h3>
<dl>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17771" title="Abstract">arXiv:2402.17771</a> (cross-list from eess.SP) [<a href="/pdf/2402.17771" title="Download PDF">pdf</a>, <a href="/ps/2402.17771" title="Download PostScript">ps</a>, <a href="/format/2402.17771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utilizing Machine Learning for Signal Classification and Noise Reduction  in Amateur Radio
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sanchez%2C+J">Jimi Sanchez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the realm of amateur radio, the effective classification of signals and
the mitigation of noise play crucial roles in ensuring reliable communication.
Traditional methods for signal classification and noise reduction often rely on
manual intervention and predefined thresholds, which can be labor-intensive and
less adaptable to dynamic radio environments. In this paper, we explore the
application of machine learning techniques for signal classification and noise
reduction in amateur radio operations. We investigate the feasibility and
effectiveness of employing supervised and unsupervised learning algorithms to
automatically differentiate between desired signals and unwanted interference,
as well as to reduce the impact of noise on received transmissions.
Experimental results demonstrate the potential of machine learning approaches
to enhance the efficiency and robustness of amateur radio communication
systems, paving the way for more intelligent and adaptive radio solutions in
the amateur radio community.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17772" title="Abstract">arXiv:2402.17772</a> (cross-list from eess.SP) [<a href="/pdf/2402.17772" title="Download PDF">pdf</a>, <a href="/format/2402.17772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EEG2Rep: Enhancing Self-supervised EEG Representation Through  Informative Masked Inputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Foumani%2C+N+M">Navid Mohammadi Foumani</a>, 
<a href="/search/eess?searchtype=author&query=Mackellar%2C+G">Geoffrey Mackellar</a>, 
<a href="/search/eess?searchtype=author&query=Ghane%2C+S">Soheila Ghane</a>, 
<a href="/search/eess?searchtype=author&query=Irtza%2C+S">Saad Irtza</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+N">Nam Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Salehi%2C+M">Mahsa Salehi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Self-supervised approaches for electroencephalography (EEG) representation
learning face three specific challenges inherent to EEG data: (1) The low
signal-to-noise ratio which challenges the quality of the representation
learned, (2) The wide range of amplitudes from very small to relatively large
due to factors such as the inter-subject variability, risks the models to be
dominated by higher amplitude ranges, and (3) The absence of explicit
segmentation in the continuous-valued sequences which can result in less
informative representations. To address these challenges, we introduce EEG2Rep,
a self-prediction approach for self-supervised representation learning from
EEG. Two core novel components of EEG2Rep are as follows: 1) Instead of
learning to predict the masked input from raw EEG, EEG2Rep learns to predict
masked input in latent representation space, and 2) Instead of conventional
masking methods, EEG2Rep uses a new semantic subsequence preserving (SSP)
method which provides informative masked inputs to guide EEG2Rep to generate
rich semantic representations. In experiments on 6 diverse EEG tasks with
subject variability, EEG2Rep significantly outperforms state-of-the-art
methods. We show that our semantic subsequence preserving improves the existing
masking methods in self-prediction literature and find that preserving 50\% of
EEG recordings will result in the most accurate results on all 6 tasks on
average. Finally, we show that EEG2Rep is robust to noise addressing a
significant challenge that exists in EEG data. Models and code are available
at: https://github.com/Navidfoumani/EEG2Rep
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17773" title="Abstract">arXiv:2402.17773</a> (cross-list from eess.SP) [<a href="/pdf/2402.17773" title="Download PDF">pdf</a>, <a href="/format/2402.17773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SINR-Aware Deep Reinforcement Learning for Distributed Dynamic Channel  Allocation in Cognitive Interference Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cohen%2C+Y">Yaniv Cohen</a>, 
<a href="/search/eess?searchtype=author&query=Gafni%2C+T">Tomer Gafni</a>, 
<a href="/search/eess?searchtype=author&query=Greenberg%2C+R">Ronen Greenberg</a>, 
<a href="/search/eess?searchtype=author&query=Cohen%2C+K">Kobi Cohen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We consider the problem of dynamic channel allocation (DCA) in cognitive
communication networks with the goal of maximizing a global
signal-to-interference-plus-noise ratio (SINR) measure under a specified target
quality of service (QoS)-SINR for each network. The shared bandwidth is
partitioned into K channels with frequency separation. In contrast to the
majority of existing studies that assume perfect orthogonality or a one- to-one
user-channel allocation mapping, this paper focuses on real-world systems
experiencing inter-carrier interference (ICI) and channel reuse by multiple
large-scale networks. This realistic scenario significantly increases the
problem dimension, rendering existing algorithms inefficient. We propose a
novel multi-agent reinforcement learning (RL) framework for distributed DCA,
named Channel Allocation RL To Overlapped Networks (CARLTON). The CARLTON
framework is based on the Centralized Training with Decentralized Execution
(CTDE) paradigm, utilizing the DeepMellow value-based RL algorithm. To ensure
robust performance in the interference-laden environment we address, CARLTON
employs a low-dimensional representation of observations, generating a QoS-type
measure while maximizing a global SINR measure and ensuring the target QoS-SINR
for each network. Our results demonstrate exceptional performance and robust
generalization, showcasing superior efficiency compared to alternative
state-of-the-art methods, while achieving a marginally diminished performance
relative to a fully centralized approach.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17775" title="Abstract">arXiv:2402.17775</a> (cross-list from eess.SP) [<a href="/pdf/2402.17775" title="Download PDF">pdf</a>, <a href="/format/2402.17775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wavelet Scattering Transform for Bioacustics: Application to Watkins  Marine Mammal Sound Database
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Carbone%2C+D">Davide Carbone</a> (1 and 2), 
<a href="/search/eess?searchtype=author&query=Licciardi%2C+A">Alessandro Licciardi</a> (1 and 2) ((1) Politecnico di Torino, (2) Istituto Nazionale di Fisica Nucleare Sezione di Torino)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Marine mammal communication is a complex field, hindered by the diversity of
vocalizations and environmental factors. The Watkins Marine Mammal Sound
Database (WMMD) is an extensive labeled dataset used in machine learning
applications. However, the methods for data preparation, preprocessing, and
classification found in the literature are quite disparate. This study first
focuses on a brief review of the state-of-the-art benchmarks on the dataset,
with an emphasis on clarifying data preparation and preprocessing methods.
Subsequently, we propose the application of the Wavelet Scattering Transform
(WST) in place of standard methods based on the Short-Time Fourier Transform
(STFT). The study also tackles a classification task using an ad-hoc deep
architecture with residual layers. We outperform the existing classification
architecture by $6\%$ in accuracy using WST and $8\%$ using Mel spectrogram
preprocessing, effectively reducing by half the number of misclassified
samples, and reaching a top accuracy of $96\%$.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17778" title="Abstract">arXiv:2402.17778</a> (cross-list from eess.SP) [<a href="/pdf/2402.17778" title="Download PDF">pdf</a>, <a href="/format/2402.17778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Anchor Selection and Real-Time Pose Prediction for  Ultra-wideband Tagless Gate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Choi%2C+J">Junyoung Choi</a>, 
<a href="/search/eess?searchtype=author&query=Bhattacharya%2C+S">Sagnik Bhattacharya</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+J">Joohyun Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2402.08399">arXiv:2402.08399</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Ultra-wideband (UWB) is emerging as a promising solution that can realize
proximity services, such as UWB tagless gate (UTG), thanks to centimeter-level
localization accuracy based on two different ranging methods such as downlink
time-difference of arrival (DL-TDoA) and double-sided two-way ranging (DS-TWR).
The UTG is a UWB-based proximity service that provides a seamless gate pass
system without requiring real-time mobile device (MD) tapping. The location of
MD is calculated using DL-TDoA, and the MD communicates with the nearest UTG
using DS-TWR to open the gate. Therefore, the knowledge about the exact
location of MD is the main challenge of UTG, and hence we provide the solutions
for both DL-TDoA and DS-TWR. In this paper, we propose dynamic anchor selection
for extremely accurate DL-TDoA localization and pose prediction for DS-TWR,
called DynaPose. The pose is defined as the actual location of MD on the human
body, which affects the localization accuracy. DynaPose is based on
line-of-sight (LOS) and non-LOS (NLOS) classification using deep learning for
anchor selection and pose prediction. Deep learning models use the UWB channel
impulse response and the inertial measurement unit embedded in the smartphone.
DynaPose is implemented on Samsung Galaxy Note20 Ultra and Qorvo UWB board to
show the feasibility and applicability. DynaPose achieves a LOS/NLOS
classification accuracy of 0.984, 62% higher DL-TDoA localization accuracy, and
ultimately detects four different poses with an accuracy of 0.961 in real-time.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17779" title="Abstract">arXiv:2402.17779</a> (cross-list from eess.SP) [<a href="/pdf/2402.17779" title="Download PDF">pdf</a>, <a href="/format/2402.17779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the importance of long-range correlations for  deep-learning-based sleep staging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+T">Tiezhi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Strodthoff%2C+N">Nils Strodthoff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages, 1 figure, Accepted at Workshop Biosignals, 28.2.-1.3.2024, G\"ottingen, Germany
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This study aims to elucidate the significance of long-range correlations for
deep-learning-based sleep staging. It is centered around S4Sleep(TS), a
recently proposed model for automated sleep staging. This model utilizes
electroencephalography (EEG) as raw time series input and relies on structured
state space sequence (S4) models as essential model component. Although the
model already surpasses state-of-the-art methods for a moderate number of 15
input epochs, recent literature results suggest potential benefits from
incorporating very long correlations spanning hundreds of input epochs. In this
submission, we explore the possibility of achieving further enhancements by
systematically scaling up the model's input size, anticipating potential
improvements in prediction accuracy. In contrast to findings in literature, our
results demonstrate that augmenting the input size does not yield a significant
enhancement in the performance of S4Sleep(TS). These findings, coupled with the
distinctive ability of S4 models to capture long-range dependencies in time
series data, cast doubt on the diagnostic relevance of very long-range
interactions for sleep staging.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17780" title="Abstract">arXiv:2402.17780</a> (cross-list from eess.SP) [<a href="/pdf/2402.17780" title="Download PDF">pdf</a>, <a href="/format/2402.17780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constraint Latent Space Matters: An Anti-anomalous Waveform  Transformation Solution from Photoplethysmography to Arterial Blood Pressure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bian%2C+C">Cheng Bian</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiaoyu Li</a>, 
<a href="/search/eess?searchtype=author&query=Bi%2C+Q">Qi Bi</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+G">Guangpu Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Lyu%2C+J">Jiegeng Lyu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+W">Weile Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yelei Li</a>, 
<a href="/search/eess?searchtype=author&query=Zeng%2C+Z">Zijing Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-2024, main track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Arterial blood pressure (ABP) holds substantial promise for proactive
cardiovascular health management. Notwithstanding its potential, the invasive
nature of ABP measurements confines their utility primarily to clinical
environments, limiting their applicability for continuous monitoring beyond
medical facilities. The conversion of photoplethysmography (PPG) signals into
ABP equivalents has garnered significant attention due to its potential in
revolutionizing cardiovascular disease management. Recent strides in PPG-to-ABP
prediction encompass the integration of generative and discriminative models.
Despite these advances, the efficacy of these models is curtailed by the latent
space shift predicament, stemming from alterations in PPG data distribution
across disparate hardware and individuals, potentially leading to distorted ABP
waveforms. To tackle this problem, we present an innovative solution named the
Latent Space Constraint Transformer (LSCT), leveraging a quantized codebook to
yield robust latent spaces by employing multiple discretizing bases. To
facilitate improved reconstruction, the Correlation-boosted Attention Module
(CAM) is introduced to systematically query pertinent bases on a global scale.
Furthermore, to enhance expressive capacity, we propose the Multi-Spectrum
Enhancement Knowledge (MSEK), which fosters local information flow within the
channels of latent code and provides additional embedding for reconstruction.
Through comprehensive experimentation on both publicly available datasets and a
private downstream task dataset, the proposed approach demonstrates noteworthy
performance enhancements compared to existing methods. Extensive ablation
studies further substantiate the effectiveness of each introduced module.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17783" title="Abstract">arXiv:2402.17783</a> (cross-list from eess.SP) [<a href="/pdf/2402.17783" title="Download PDF">pdf</a>, <a href="/format/2402.17783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BagStacking: An Integrated Ensemble Learning Approach for Freezing of  Gait Detection in Parkinson&#x27;s Disease
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cohen%2C+S">Seffi Cohen</a>, 
<a href="/search/eess?searchtype=author&query=Rokach%2C+L">Lior Rokach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper introduces BagStacking, a novel ensemble learning method designed
to enhance the detection of Freezing of Gait (FOG) in Parkinson's Disease (PD)
by using a lower-back sensor to track acceleration. Building on the principles
of bagging and stacking, BagStacking aims to achieve the variance reduction
benefit of bagging's bootstrap sampling while also learning sophisticated
blending through stacking. The method involves training a set of base models on
bootstrap samples from the training data, followed by a meta-learner trained on
the base model outputs and true labels to find an optimal aggregation scheme.
The experimental evaluation demonstrates significant improvements over other
state-of-the-art machine learning methods on the validation set. Specifically,
BagStacking achieved a MAP score of 0.306, outperforming LightGBM (0.234) and
classic Stacking (0.286). Additionally, the run-time of BagStacking was
measured at 3828 seconds, illustrating an efficient approach compared to
Regular Stacking's 8350 seconds. BagStacking presents a promising direction for
handling the inherent variability in FOG detection data, offering a robust and
scalable solution to improve patient care in PD.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17788" title="Abstract">arXiv:2402.17788</a> (cross-list from eess.SP) [<a href="/pdf/2402.17788" title="Download PDF">pdf</a>, <a href="/format/2402.17788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Sleep Apnea Detection with Missing or Noisy Modalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fayyaz%2C+H">Hamed Fayyaz</a>, 
<a href="/search/eess?searchtype=author&query=Strang%2C+A">Abigail Strang</a>, 
<a href="/search/eess?searchtype=author&query=D%27Souza%2C+N+S">Niharika S. D&#x27;Souza</a>, 
<a href="/search/eess?searchtype=author&query=Beheshti%2C+R">Rahmatollah Beheshti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Polysomnography (PSG) is a type of sleep study that records multimodal
physiological signals and is widely used for purposes such as sleep staging and
respiratory event detection. Conventional machine learning methods assume that
each sleep study is associated with a fixed set of observed modalities and that
all modalities are available for each sample. However, noisy and missing
modalities are a common issue in real-world clinical settings. In this study,
we propose a comprehensive pipeline aiming to compensate for the missing or
noisy modalities when performing sleep apnea detection. Unlike other existing
studies, our proposed model works with any combination of available modalities.
Our experiments show that the proposed model outperforms other state-of-the-art
approaches in sleep apnea detection using various subsets of available data and
different levels of noise, and maintains its high performance (AUROC&gt;0.9) even
in the presence of high levels of noise or missingness. This is especially
relevant in settings where the level of noise and missingness is high (such as
pediatric or outside-of-clinic scenarios).
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17790" title="Abstract">arXiv:2402.17790</a> (cross-list from eess.SP) [<a href="/pdf/2402.17790" title="Download PDF">pdf</a>, <a href="/format/2402.17790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EEG classifier cross-task transfer to avoid training sessions in  robot-assisted rehabilitation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kueper%2C+N">Niklas Kueper</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+S+K">Su Kyoung Kim</a>, 
<a href="/search/eess?searchtype=author&query=Kirchner%2C+E+A">Elsa Andrea Kirchner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Background: For an individualized support of patients during rehabilitation,
learning of individual machine learning models from the human
electroencephalogram (EEG) is required. Our approach allows labeled training
data to be recorded without the need for a specific training session. For this,
the planned exoskeleton-assisted rehabilitation enables bilateral mirror
therapy, in which movement intentions can be inferred from the activity of the
unaffected arm. During this therapy, labeled EEG data can be collected to
enable movement predictions of only the affected arm of a patient. Methods: A
study was conducted with 8 healthy subjects and the performance of the
classifier transfer approach was evaluated. Each subject performed 3 runs of 40
self-intended unilateral and bilateral reaching movements toward a target while
EEG data was recorded from 64 channels. A support vector machine (SVM)
classifier was trained under both movement conditions to make predictions for
the same type of movement. Furthermore, the classifier was evaluated to predict
unilateral movements by only beeing trained on the data of the bilateral
movement condition. Results: The results show that the performance of the
classifier trained on selected EEG channels evoked by bilateral movement
intentions is not significantly reduced compared to a classifier trained
directly on EEG data including unilateral movement intentions. Moreover, the
results show that our approach also works with only 8 or even 4 channels.
Conclusion: It was shown that the proposed classifier transfer approach enables
motion prediction without explicit collection of training data. Since the
approach can be applied even with a small number of EEG channels, this speaks
for the feasibility of the approach in real therapy sessions with patients and
motivates further investigations with stroke patients.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17792" title="Abstract">arXiv:2402.17792</a> (cross-list from eess.SP) [<a href="/pdf/2402.17792" title="Download PDF">pdf</a>, <a href="/format/2402.17792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EGNN-C+: Interpretable Evolving Granular Neural Network and Application  in Classification of Weakly-Supervised EEG Data Streams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Leite%2C+D">Daniel Leite</a>, 
<a href="/search/eess?searchtype=author&query=Silva%2C+A">Alisson Silva</a>, 
<a href="/search/eess?searchtype=author&query=Casalino%2C+G">Gabriella Casalino</a>, 
<a href="/search/eess?searchtype=author&query=Sharma%2C+A">Arnab Sharma</a>, 
<a href="/search/eess?searchtype=author&query=Fortunato%2C+D">Danielle Fortunato</a>, 
<a href="/search/eess?searchtype=author&query=Ngomo%2C+A">Axel-Cyrille Ngomo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, IEEE International Conference on Evolving and Adaptive Intelligent Systems 2024 (IEEE EAIS 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">We introduce a modified incremental learning algorithm for evolving Granular
Neural Network Classifiers (eGNN-C+). We use double-boundary hyper-boxes to
represent granules, and customize the adaptation procedures to enhance the
robustness of outer boxes for data coverage and noise suppression, while
ensuring that inner boxes remain flexible to capture drifts. The classifier
evolves from scratch, incorporates new classes on the fly, and performs local
incremental feature weighting. As an application, we focus on the
classification of emotion-related patterns within electroencephalogram (EEG)
signals. Emotion recognition is crucial for enhancing the realism and
interactivity of computer systems. We extract features from the Fourier
spectrum of EEG signals obtained from 28 individuals engaged in playing
computer games -- a public dataset. Each game elicits a different predominant
emotion: boredom, calmness, horror, or joy. We analyze individual electrodes,
time window lengths, and frequency bands to assess the accuracy and
interpretability of resulting user-independent neural models. The findings
indicate that both brain hemispheres assist classification, especially
electrodes on the temporal (T8) and parietal (P7) areas, alongside
contributions from frontal and occipital electrodes. While patterns may
manifest in any band, the Alpha (8-13Hz), Delta (1-4Hz), and Theta (4-8Hz)
bands, in this order, exhibited higher correspondence with the emotion classes.
The eGNN-C+ demonstrates effectiveness in learning EEG data. It achieves an
accuracy of 81.7% and a 0.0029 II interpretability using 10-second time
windows, even in face of a highly-stochastic time-varying 4-class
classification problem.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17797" title="Abstract">arXiv:2402.17797</a> (cross-list from eess.IV) [<a href="/pdf/2402.17797" title="Download PDF">pdf</a>, <a href="/format/2402.17797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Radiance Fields in Medical Imaging: Challenges and Next Steps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+S">Shu Hu</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+H">Heng Fan</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+H">Hongtu Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Neural Radiance Fields (NeRF), as a pioneering technique in computer vision,
offer great potential to revolutionize medical imaging by synthesizing
three-dimensional representations from the projected two-dimensional image
data. However, they face unique challenges when applied to medical
applications. This paper presents a comprehensive examination of applications
of NeRFs in medical imaging, highlighting four imminent challenges, including
fundamental imaging principles, inner structure requirement, object boundary
definition, and color density significance. We discuss current methods on
different organs and discuss related limitations. We also review several
datasets and evaluation metrics and propose several promising directions for
future research.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17801" title="Abstract">arXiv:2402.17801</a> (cross-list from econ.TH) [<a href="/pdf/2402.17801" title="Download PDF">pdf</a>, <a href="/format/2402.17801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative AI and Copyright: A Dynamic Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Yang%2C+S+A">S. Alex Yang</a>, 
<a href="/search/econ?searchtype=author&query=Zhang%2C+A+H">Angela Huyue Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The rapid advancement of generative AI is poised to disrupt the creative
industry. Amidst the immense excitement for this new technology, its future
development and applications in the creative industry hinge crucially upon two
copyright issues: 1) the compensation to creators whose content has been used
to train generative AI models (the fair use standard); and 2) the eligibility
of AI-generated content for copyright protection (AI-copyrightability). While
both issues have ignited heated debates among academics and practitioners, most
analysis has focused on their challenges posed to existing copyright doctrines.
In this paper, we aim to better understand the economic implications of these
two regulatory issues and their interactions. By constructing a dynamic model
with endogenous content creation and AI model development, we unravel the
impacts of the fair use standard and AI-copyrightability on AI development, AI
company profit, creators income, and consumer welfare, and how these impacts
are influenced by various economic and operational factors. For example, while
generous fair use (use data for AI training without compensating the creator)
benefits all parties when abundant training data exists, it can hurt creators
and consumers when such data is scarce. Similarly, stronger AI-copyrightability
(AI content enjoys more copyright protection) could hinder AI development and
reduce social welfare. Our analysis also highlights the complex interplay
between these two copyright issues. For instance, when existing training data
is scarce, generous fair use may be preferred only when AI-copyrightability is
weak. Our findings underscore the need for policymakers to embrace a dynamic,
context-specific approach in making regulatory decisions and provide insights
for business leaders navigating the complexities of the global regulatory
environment.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17807" title="Abstract">arXiv:2402.17807</a> (cross-list from q-bio.GN) [<a href="/pdf/2402.17807" title="Download PDF">pdf</a>, <a href="/format/2402.17807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Gene Regulatory Interaction Networks and predicting  therapeutic molecules for Hypopharyngeal Cancer and EGFR-mutated lung  adenocarcinoma
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Bhattacharjya%2C+A">Abanti Bhattacharjya</a>, 
<a href="/search/q-bio?searchtype=author&query=Islam%2C+M+M">Md Manowarul Islam</a>, 
<a href="/search/q-bio?searchtype=author&query=Uddin%2C+M+A">Md Ashraf Uddin</a>, 
<a href="/search/q-bio?searchtype=author&query=Talukder%2C+M+A">Md. Alamin Talukder</a>, 
<a href="/search/q-bio?searchtype=author&query=Azad%2C+A">AKM Azad</a>, 
<a href="/search/q-bio?searchtype=author&query=Aryal%2C+S">Sunil Aryal</a>, 
<a href="/search/q-bio?searchtype=author&query=Paul%2C+B+K">Bikash Kumar Paul</a>, 
<a href="/search/q-bio?searchtype=author&query=Tasnim%2C+W">Wahia Tasnim</a>, 
<a href="/search/q-bio?searchtype=author&query=Almoyad%2C+M+A+A">Muhammad Ali Abdulllah Almoyad</a>, 
<a href="/search/q-bio?searchtype=author&query=Moni%2C+M+A">Mohammad Ali Moni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted In The FEBS OPEN BIO (Q2, SCOPUS, SCIE, IF: 2.6, CS: 4.7), Wiley Journal, On FEB 25, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">With the advent of Information technology, the Bioinformatics research field
is becoming increasingly attractive to researchers and academicians. The recent
development of various Bioinformatics toolkits has facilitated the rapid
processing and analysis of vast quantities of biological data for human
perception. Most studies focus on locating two connected diseases and making
some observations to construct diverse gene regulatory interaction networks, a
forerunner to general drug design for curing illness. For instance,
Hypopharyngeal cancer is a disease that is associated with EGFR-mutated lung
adenocarcinoma. In this study, we select EGFR-mutated lung adenocarcinoma and
Hypopharyngeal cancer by finding the Lung metastases in hypopharyngeal cancer.
To conduct this study, we collect Mircorarray datasets from GEO (Gene
Expression Omnibus), an online database controlled by NCBI. Differentially
expressed genes, common genes, and hub genes between the selected two diseases
are detected for the succeeding move. Our research findings have suggested
common therapeutic molecules for the selected diseases based on 10 hub genes
with the highest interactions according to the degree topology method and the
maximum clique centrality (MCC). Our suggested therapeutic molecules will be
fruitful for patients with those two diseases simultaneously.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17808" title="Abstract">arXiv:2402.17808</a> (cross-list from eess.SP) [<a href="/pdf/2402.17808" title="Download PDF">pdf</a>, <a href="/ps/2402.17808" title="Download PostScript">ps</a>, <a href="/format/2402.17808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AN An ica-ensemble learning approach for prediction of uwb nlos signals  data classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Enoch%2C+J+A">Jiya A. Enoch</a>, 
<a href="/search/eess?searchtype=author&query=Oluwafemi%2C+I+B">Ilesanmi B. Oluwafemi</a>, 
<a href="/search/eess?searchtype=author&query=Ibikunle%2C+F+A">Francis A. Ibikunle</a>, 
<a href="/search/eess?searchtype=author&query=Paul%2C+O+K">Olulope K. Paul</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages,4 figures, 1 algorithm and 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">Trapped human detection in search and rescue (SAR) scenarios poses a
significant challenge in pervasive computing. This study addresses this issue
by leveraging machine learning techniques, given their high accuracy. However,
accurate identification of trapped individuals is hindered by the curse of
dimensionality and noisy data. Particularly in non-line-of-sight (NLOS)
situations during catastrophic events, the curse of dimensionality may lead to
blind spots due to noise and uncorrelated values in detections. This research
focuses on harmonizing information through wireless communication and
identifying individuals in NLOS scenarios using ultra-wideband (UWB) radar
signals. Employing independent component analysis (ICA) for feature extraction,
the study evaluates classification performance using ensemble algorithms on
both static and dynamic datasets. The experimental results demonstrate
categorization accuracies of 88.37% for static data and 87.20% for dynamic
data, highlighting the effectiveness of the proposed approach. Finally, this
work can help scientists and engineers make instant decisions during SAR
operations.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17810" title="Abstract">arXiv:2402.17810</a> (cross-list from q-bio.QM) [<a href="/pdf/2402.17810" title="Download PDF">pdf</a>, <a href="/format/2402.17810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BioT5+: Towards Generalized Biological Understanding with IUPAC  Integration and Multi-task Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Pei%2C+Q">Qizhi Pei</a>, 
<a href="/search/q-bio?searchtype=author&query=Wu%2C+L">Lijun Wu</a>, 
<a href="/search/q-bio?searchtype=author&query=Gao%2C+K">Kaiyuan Gao</a>, 
<a href="/search/q-bio?searchtype=author&query=Liang%2C+X">Xiaozhuan Liang</a>, 
<a href="/search/q-bio?searchtype=author&query=Fang%2C+Y">Yin Fang</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhu%2C+J">Jinhua Zhu</a>, 
<a href="/search/q-bio?searchtype=author&query=Xie%2C+S">Shufang Xie</a>, 
<a href="/search/q-bio?searchtype=author&query=Qin%2C+T">Tao Qin</a>, 
<a href="/search/q-bio?searchtype=author&query=Yan%2C+R">Rui Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent research trends in computational biology have increasingly focused on
integrating text and bio-entity modeling, especially in the context of
molecules and proteins. However, previous efforts like BioT5 faced challenges
in generalizing across diverse tasks and lacked a nuanced understanding of
molecular structures, particularly in their textual representations (e.g.,
IUPAC). This paper introduces BioT5+, an extension of the BioT5 framework,
tailored to enhance biological research and drug discovery. BioT5+ incorporates
several novel features: integration of IUPAC names for molecular understanding,
inclusion of extensive bio-text and molecule data from sources like bioRxiv and
PubChem, the multi-task instruction tuning for generality across tasks, and a
novel numerical tokenization technique for improved processing of numerical
data. These enhancements allow BioT5+ to bridge the gap between molecular
representations and their textual descriptions, providing a more holistic
understanding of biological entities, and largely improving the grounded
reasoning of bio-text and bio-sequences. The model is pre-trained and
fine-tuned with a large number of experiments, including \emph{3 types of
problems (classification, regression, generation), 15 kinds of tasks, and 21
total benchmark datasets}, demonstrating the remarkable performance and
state-of-the-art results in most cases. BioT5+ stands out for its ability to
capture intricate relationships in biological data, thereby contributing
significantly to bioinformatics and computational biology. Our code is
available at \url{https://github.com/QizhiPei/BioT5}.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17848" title="Abstract">arXiv:2402.17848</a> (cross-list from nlin.AO) [<a href="/pdf/2402.17848" title="Download PDF">pdf</a>, <a href="/format/2402.17848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Looking for Complexity at Phase Boundaries in Continuous Cellular  Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/nlin?searchtype=author&query=Papadopoulos%2C+V">Vassilis Papadopoulos</a>, 
<a href="/search/nlin?searchtype=author&query=Doat%2C+G">Guilhem Doat</a>, 
<a href="/search/nlin?searchtype=author&query=Renard%2C+A">Arthur Renard</a>, 
<a href="/search/nlin?searchtype=author&query=Hongler%2C+C">Cl&#xe9;ment Hongler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Adaptation and Self-Organizing Systems (nlin.AO)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">One key challenge in Artificial Life is designing systems that display an
emergence of complex behaviors. Many such systems depend on a high-dimensional
parameter space, only a small subset of which displays interesting dynamics.
Focusing on the case of continuous systems, we introduce the 'Phase Transition
Finder'(PTF) algorithm, which can be used to efficiently generate parameters
lying at the border between two phases. We argue that such points are more
likely to display complex behaviors, and confirm this by applying PTF to Lenia
showing it can increase the frequency of interesting behaviors more than
two-fold, while remaining efficient enough for large-scale searches.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17870" title="Abstract">arXiv:2402.17870</a> (cross-list from stat.CO) [<a href="/pdf/2402.17870" title="Download PDF">pdf</a>, <a href="/format/2402.17870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Approximation with Biased MCMC for Expectation Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Gruffaz%2C+S">Samuel Gruffaz</a>, 
<a href="/search/stat?searchtype=author&query=Kim%2C+K">Kyurae Kim</a>, 
<a href="/search/stat?searchtype=author&query=Durmus%2C+A+O">Alain Oliviero Durmus</a>, 
<a href="/search/stat?searchtype=author&query=Gardner%2C+J+R">Jacob R. Gardner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AISTATS'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation (stat.CO)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">The expectation maximization (EM) algorithm is a widespread method for
empirical Bayesian inference, but its expectation step (E-step) is often
intractable. Employing a stochastic approximation scheme with Markov chain
Monte Carlo (MCMC) can circumvent this issue, resulting in an algorithm known
as MCMC-SAEM. While theoretical guarantees for MCMC-SAEM have previously been
established, these results are restricted to the case where asymptotically
unbiased MCMC algorithms are used. In practice, MCMC-SAEM is often run with
asymptotically biased MCMC, for which the consequences are theoretically less
understood. In this work, we fill this gap by analyzing the asymptotics and
non-asymptotics of SAEM with biased MCMC steps, particularly the effect of
bias. We also provide numerical experiments comparing the Metropolis-adjusted
Langevin algorithm (MALA), which is asymptotically unbiased, and the unadjusted
Langevin algorithm (ULA), which is asymptotically biased, on synthetic and real
datasets. Experimental results show that ULA is more stable with respect to the
choice of Langevin stepsize and can sometimes result in faster convergence.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17886" title="Abstract">arXiv:2402.17886</a> (cross-list from stat.ML) [<a href="/pdf/2402.17886" title="Download PDF">pdf</a>, <a href="/format/2402.17886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zeroth-Order Sampling Methods for Non-Log-Concave Distributions:  Alleviating Metastability by Denoising Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=He%2C+Y">Ye He</a>, 
<a href="/search/stat?searchtype=author&query=Rojas%2C+K">Kevin Rojas</a>, 
<a href="/search/stat?searchtype=author&query=Tao%2C+M">Molei Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Probability (math.PR); Statistics Theory (math.ST); Methodology (stat.ME)

</div>
<p class="mathjax">This paper considers the problem of sampling from non-logconcave
distribution, based on queries of its unnormalized density. It first describes
a framework, Diffusion Monte Carlo (DMC), based on the simulation of a
denoising diffusion process with its score function approximated by a generic
Monte Carlo estimator. DMC is an oracle-based meta-algorithm, where its oracle
is the assumed access to samples that generate a Monte Carlo score estimator.
Then we provide an implementation of this oracle, based on rejection sampling,
and this turns DMC into a true algorithm, termed Zeroth-Order Diffusion Monte
Carlo (ZOD-MC). We provide convergence analyses by first constructing a general
framework, i.e. a performance guarantee for DMC, without assuming the target
distribution to be log-concave or satisfying any isoperimetric inequality. Then
we prove that ZOD-MC admits an inverse polynomial dependence on the desired
sampling accuracy, albeit still suffering from the curse of dimensionality.
Consequently, for low dimensional distributions, ZOD-MC is a very efficient
sampler, with performance exceeding latest samplers, including
also-denoising-diffusion-based RDMC and RS-DMC. Last, we experimentally
demonstrate the insensitivity of ZOD-MC to increasingly higher barriers between
modes or discontinuity in non-convex potential.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17898" title="Abstract">arXiv:2402.17898</a> (cross-list from astro-ph.EP) [<a href="/pdf/2402.17898" title="Download PDF">pdf</a>, <a href="/format/2402.17898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exoplanets Prediction in Multi-Planetary Systems and Determining the  Correlation Between the Parameters of Planets and Host Stars Using Artificial  Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Mousavi-Sadr%2C+M">Mahdiyar Mousavi-Sadr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A Ph.D. dissertation. 154 pages, 52 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The number of extrasolar planets discovered is increasing, so that more than
five thousand exoplanets have been confirmed to date. Now we have an
opportunity to test the validity of the laws governing planetary systems and
take steps to discover the relationships between the physical parameters of
planets and stars. Firstly, we present the results of a search for additional
exoplanets in 229 multi-planetary systems that house at least three or more
confirmed planets, employing a logarithmic spacing between planets in our Solar
System known as the Titius-Bode (TB) relation. We find that the planets in
$\sim53\%$ of these systems adhere to a logarithmic spacing relation remarkably
better than the Solar System planets. We predict the presence of 426 additional
exoplanets, 47 of which are located within the habitable zone (HZ), and five of
the 47 planets have a maximum mass limit of 0.1-2$M_{\oplus}$ and a maximum
radius lower than 1.25$R_{\oplus}$. Secondly, we employ efficient machine
learning approaches to analyze a dataset comprising 762 confirmed exoplanets
and eight Solar System planets, aiming to characterize their fundamental
quantities. We classify the data into two main classes: 'small' and 'giant'
planets, with cut-off values at $R_{p}=8.13R_{\oplus}$ and
$M_{p}=52.48M_{\oplus}$. Giant planets have lower densities, suggesting higher
H-He mass fractions, while small planets are denser, composed mainly of heavier
elements. We highlight that planetary mass, orbital period, and stellar mass
play crucial roles in predicting exoplanet radius. Notably, our study reveals a
noteworthy result: for giant planets, we observe a strong correlation between
planetary radius and the mass of their host stars, which might provide
intriguing insights into the relationship between giant planet formation and
stellar characteristics.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17900" title="Abstract">arXiv:2402.17900</a> (cross-list from math.OC) [<a href="/pdf/2402.17900" title="Download PDF">pdf</a>, <a href="/ps/2402.17900" title="Download PostScript">ps</a>, <a href="/format/2402.17900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pathwise Relaxed Optimal Control of Rough Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chakraborty%2C+P">Prakash Chakraborty</a>, 
<a href="/search/math?searchtype=author&query=Honnappa%2C+H">Harsha Honnappa</a>, 
<a href="/search/math?searchtype=author&query=Tindel%2C+S">Samy Tindel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY); Probability (math.PR)

</div>
<p class="mathjax">This note lays part of the theoretical ground for a definition of
differential systems modeling reinforcement learning in continuous time
non-Markovian rough environments. Specifically we focus on optimal relaxed
control of rough equations (the term relaxed referring to the fact that
controls have to be considered as measure valued objects). With reinforcement
learning in view, our reward functions encompass forms that involve an
entropy-type term favoring exploration. In this context, our contribution
focuses on a careful definition of the corresponding relaxed
Hamilton-Jacobi-Bellman (HJB)-type equation. A substantial part of our endeavor
consists in a precise definition of the notion of test function and viscosity
solution for the rough relaxed PDE obtained in this framework. Note that this
task is often merely sketched in the rough viscosity literature, in spite of
the fact that it gives a proper meaning to the differential system at stake. In
the last part of the paper we prove that the natural value function in our
context solves a relaxed rough HJB equation in the viscosity sense.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17907" title="Abstract">arXiv:2402.17907</a> (cross-list from eess.AS) [<a href="/pdf/2402.17907" title="Download PDF">pdf</a>, <a href="/format/2402.17907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NIIRF: Neural IIR Filter Field for HRTF Upsampling and Personalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Masuyama%2C+Y">Yoshiki Masuyama</a>, 
<a href="/search/eess?searchtype=author&query=Wichern%2C+G">Gordon Wichern</a>, 
<a href="/search/eess?searchtype=author&query=Germain%2C+F+G">Fran&#xe7;ois G. Germain</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+Z">Zexu Pan</a>, 
<a href="/search/eess?searchtype=author&query=Khurana%2C+S">Sameer Khurana</a>, 
<a href="/search/eess?searchtype=author&query=Hori%2C+C">Chiori Hori</a>, 
<a href="/search/eess?searchtype=author&query=Roux%2C+J+L">Jonathan Le Roux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Head-related transfer functions (HRTFs) are important for immersive audio,
and their spatial interpolation has been studied to upsample finite
measurements. Recently, neural fields (NFs) which map from sound source
direction to HRTF have gained attention. Existing NF-based methods focused on
estimating the magnitude of the HRTF from a given sound source direction, and
the magnitude is converted to a finite impulse response (FIR) filter. We
propose the neural infinite impulse response filter field (NIIRF) method that
instead estimates the coefficients of cascaded IIR filters. IIR filters mimic
the modal nature of HRTFs, thus needing fewer coefficients to approximate them
well compared to FIR filters. We find that our method can match the performance
of existing NF-based methods on multiple datasets, even outperforming them when
measurements are sparse. We also explore approaches to personalize the NF to a
subject and experimentally find low-rank adaptation to be effective.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17911" title="Abstract">arXiv:2402.17911</a> (cross-list from quant-ph) [<a href="/pdf/2402.17911" title="Download PDF">pdf</a>, <a href="/format/2402.17911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demonstration of Robust and Efficient Quantum Property Learning with  Shallow Shadows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Hu%2C+H">Hong-Ye Hu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gu%2C+A">Andi Gu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Majumder%2C+S">Swarnadeep Majumder</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ren%2C+H">Hang Ren</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+Y">Yipei Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+D+S">Derek S. Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=You%2C+Y">Yi-Zhuang You</a>, 
<a href="/search/quant-ph?searchtype=author&query=Minev%2C+Z">Zlatko Minev</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yelin%2C+S+F">Susanne F. Yelin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Seif%2C+A">Alireza Seif</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Statistical Mechanics (cond-mat.stat-mech); Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">Extracting information efficiently from quantum systems is a major component
of quantum information processing tasks. Randomized measurements, or classical
shadows, enable predicting many properties of arbitrary quantum states using
few measurements. While random single qubit measurements are experimentally
friendly and suitable for learning low-weight Pauli observables, they perform
poorly for nonlocal observables. Prepending a shallow random quantum circuit
before measurements maintains this experimental friendliness, but also has
favorable sample complexities for observables beyond low-weight Paulis,
including high-weight Paulis and global low-rank properties such as fidelity.
However, in realistic scenarios, quantum noise accumulated with each additional
layer of the shallow circuit biases the results. To address these challenges,
we propose the robust shallow shadows protocol. Our protocol uses Bayesian
inference to learn the experimentally relevant noise model and mitigate it in
postprocessing. This mitigation introduces a bias-variance trade-off:
correcting for noise-induced bias comes at the cost of a larger estimator
variance. Despite this increased variance, as we demonstrate on a
superconducting quantum processor, our protocol correctly recovers state
properties such as expectation values, fidelity, and entanglement entropy,
while maintaining a lower sample complexity compared to the random single qubit
measurement scheme. We also theoretically analyze the effects of noise on
sample complexity and show how the optimal choice of the shallow shadow depth
varies with noise strength. This combined theoretical and experimental analysis
positions the robust shallow shadow protocol as a scalable, robust, and
sample-efficient protocol for characterizing quantum states on current quantum
computing platforms.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17913" title="Abstract">arXiv:2402.17913</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2402.17913" title="Download PDF">pdf</a>, <a href="/format/2402.17913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using AI libraries for Incompressible Computational Fluid Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Chen%2C+B">Boyang Chen</a>, 
<a href="/search/physics?searchtype=author&query=Heaney%2C+C+E">Claire E. Heaney</a>, 
<a href="/search/physics?searchtype=author&query=Pain%2C+C+C">Christopher C. Pain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, there has been a huge effort focused on developing highly efficient
open source libraries to perform Artificial Intelligence (AI) related
computations on different computer architectures (for example, CPUs, GPUs and
new AI processors). This has not only made the algorithms based on these
libraries highly efficient and portable between different architectures, but
also has substantially simplified the entry barrier to develop methods using
AI. Here, we present a novel methodology to bring the power of both AI software
and hardware into the field of numerical modelling by repurposing AI methods,
such as Convolutional Neural Networks (CNNs), for the standard operations
required in the field of the numerical solution of Partial Differential
Equations (PDEs). The aim of this work is to bring the high performance,
architecture agnosticism and ease of use into the field of the numerical
solution of PDEs. We use the proposed methodology to solve the
advection-diffusion equation, the non-linear Burgers equation and
incompressible flow past a bluff body. For the latter, a convolutional neural
network is used as a multigrid solver in order to enforce the incompressibility
constraint. We show that the presented methodology can solve all these problems
using repurposed AI libraries in an efficient way, and presents a new avenue to
explore in the development of methods to solve PDEs and Computational Fluid
Dynamics problems with implicit methods.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17922" title="Abstract">arXiv:2402.17922</a> (cross-list from quant-ph) [<a href="/pdf/2402.17922" title="Download PDF">pdf</a>, <a href="/format/2402.17922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-stage Quantum Estimation and the Asymptotics of Quantum-enhanced  Transmittance Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Gong%2C+Z">Zihao Gong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bash%2C+B+A">Boulat A. Bash</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); Statistics Theory (math.ST)

</div>
<p class="mathjax">Quantum Cram\'er-Rao bound is the ultimate limit of the mean squared error
for unbiased estimation of an unknown parameter embedded in a quantum state.
While it can be achieved asymptotically for large number of quantum state
copies, the measurement required often depends on the true value of the
parameter of interest. This paradox was addressed by Hayashi and Matsumoto
using a two-stage approach in 2005. Unfortunately, their analysis imposes
conditions that severely restrict the class of classical estimators applied to
the quantum measurement outcomes, hindering applications of this method. We
relax these conditions to substantially broaden the class of usable estimators
at the cost of slightly weakening the asymptotic properties of the two-stage
method. We apply our results to obtain the asymptotics of quantum-enhanced
transmittance sensing.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17926" title="Abstract">arXiv:2402.17926</a> (cross-list from stat.ML) [<a href="/pdf/2402.17926" title="Download PDF">pdf</a>, <a href="/format/2402.17926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Certain and Approximately Certain Models for Statistical Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhen%2C+C">Cheng Zhen</a>, 
<a href="/search/stat?searchtype=author&query=Aryal%2C+N">Nischal Aryal</a>, 
<a href="/search/stat?searchtype=author&query=Termehchy%2C+A">Arash Termehchy</a>, 
<a href="/search/stat?searchtype=author&query=Chabada%2C+A+S">Amandeep Singh Chabada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A technical report for a paper to appear at SIGMOD 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Databases (cs.DB); Machine Learning (cs.LG)

</div>
<p class="mathjax">Real-world data is often incomplete and contains missing values. To train
accurate models over real-world datasets, users need to spend a substantial
amount of time and resources imputing and finding proper values for missing
data items. In this paper, we demonstrate that it is possible to learn accurate
models directly from data with missing values for certain training data and
target models. We propose a unified approach for checking the necessity of data
imputation to learn accurate models across various widely-used machine learning
paradigms. We build efficient algorithms with theoretical guarantees to check
this necessity and return accurate models in cases where imputation is
unnecessary. Our extensive experiments indicate that our proposed algorithms
significantly reduce the amount of time and effort needed for data imputation
without imposing considerable computational overhead.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17943" title="Abstract">arXiv:2402.17943</a> (cross-list from stat.ML) [<a href="/pdf/2402.17943" title="Download PDF">pdf</a>, <a href="/format/2402.17943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sequential transport maps using SoS density estimation and  $&#x3b1;$-divergences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zanger%2C+B">Benjamin Zanger</a>, 
<a href="/search/stat?searchtype=author&query=Cui%2C+T">Tiangang Cui</a>, 
<a href="/search/stat?searchtype=author&query=Schreiber%2C+M">Martin Schreiber</a>, 
<a href="/search/stat?searchtype=author&query=Zahm%2C+O">Olivier Zahm</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Transport-based density estimation methods are receiving growing interest
because of their ability to efficiently generate samples from the approximated
density. We further invertigate the sequential transport maps framework
proposed from <a href="/abs/2106.04170">arXiv:2106.04170</a> <a href="/abs/2303.02554">arXiv:2303.02554</a>, which builds on a sequence of
composed Knothe-Rosenblatt (KR) maps. Each of those maps are built by first
estimating an intermediate density of moderate complexity, and then by
computing the exact KR map from a reference density to the precomputed
approximate density. In our work, we explore the use of Sum-of-Squares (SoS)
densities and $\alpha$-divergences for approximating the intermediate
densities. Combining SoS densities with $\alpha$-divergence interestingly
yields convex optimization problems which can be efficiently solved using
semidefinite programming. The main advantage of $\alpha$-divergences is to
enable working with unnormalized densities, which provides benefits both
numerically and theoretically. In particular, we provide two new convergence
analyses of the sequential transport maps: one based on a triangle-like
inequality and the second on information geometric properties of
$\alpha$-divergences for unnormalizied densities. The choice of intermediate
densities is also crucial for the efficiency of the method. While tempered (or
annealed) densities are the state-of-the-art, we introduce diffusion-based
intermediate densities which permits to approximate densities known from
samples only. Such intermediate densities are well-established in machine
learning for generative modeling. Finally we propose and try different
low-dimensional maps (or lazy maps) for dealing with high-dimensional problems
and numerically demonstrate our methods on several benchmarks, including
Bayesian inference problems and unsupervised learning task.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17951" title="Abstract">arXiv:2402.17951</a> (cross-list from eess.IV) [<a href="/pdf/2402.17951" title="Download PDF">pdf</a>, <a href="/format/2402.17951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QN-Mixer: A Quasi-Newton MLP-Mixer Model for Sparse-View CT  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ayad%2C+I">Ishak Ayad</a>, 
<a href="/search/eess?searchtype=author&query=Larue%2C+N">Nicolas Larue</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+M+K">Ma&#xef; K. Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CVPR 2024. Project page: <a href="https://towzeur.github.io/QN-Mixer/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Inverse problems span across diverse fields. In medical contexts, computed
tomography (CT) plays a crucial role in reconstructing a patient's internal
structure, presenting challenges due to artifacts caused by inherently
ill-posed inverse problems. Previous research advanced image quality via
post-processing and deep unrolling algorithms but faces challenges, such as
extended convergence times with ultra-sparse data. Despite enhancements,
resulting images often show significant artifacts, limiting their effectiveness
for real-world diagnostic applications. We aim to explore deep second-order
unrolling algorithms for solving imaging inverse problems, emphasizing their
faster convergence and lower time complexity compared to common first-order
methods like gradient descent. In this paper, we introduce QN-Mixer, an
algorithm based on the quasi-Newton approach. We use learned parameters through
the BFGS algorithm and introduce Incept-Mixer, an efficient neural architecture
that serves as a non-local regularization term, capturing long-range
dependencies within images. To address the computational demands typically
associated with quasi-Newton algorithms that require full Hessian matrix
computations, we present a memory-efficient alternative. Our approach
intelligently downsamples gradient information, significantly reducing
computational requirements while maintaining performance. The approach is
validated through experiments on the sparse-view CT problem, involving various
datasets and scanning protocols, and is compared with post-processing and deep
unrolling state-of-the-art approaches. Our method outperforms existing
approaches and achieves state-of-the-art performance in terms of SSIM and PSNR,
all while reducing the number of unrolling iterations required.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17987" title="Abstract">arXiv:2402.17987</a> (cross-list from eess.SP) [<a href="/pdf/2402.17987" title="Download PDF">pdf</a>, <a href="/format/2402.17987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multistatic-Radar RCS-Signature Recognition of Aerial Vehicles: A  Bayesian Fusion Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Potter%2C+M">Michael Potter</a>, 
<a href="/search/eess?searchtype=author&query=Akcakaya%2C+M">Murat Akcakaya</a>, 
<a href="/search/eess?searchtype=author&query=Necsoiu%2C+M">Marius Necsoiu</a>, 
<a href="/search/eess?searchtype=author&query=Schirner%2C+G">Gunar Schirner</a>, 
<a href="/search/eess?searchtype=author&query=Erdogmus%2C+D">Deniz Erdogmus</a>, 
<a href="/search/eess?searchtype=author&query=Imbiriba%2C+T">Tales Imbiriba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be submitted to IEEE Transactions on Aerospace and Electronic Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Probability (math.PR); Machine Learning (stat.ML)

</div>
<p class="mathjax">Radar Automated Target Recognition (RATR) for Unmanned Aerial Vehicles (UAVs)
involves transmitting Electromagnetic Waves (EMWs) and performing target type
recognition on the received radar echo, crucial for defense and aerospace
applications. Previous studies highlighted the advantages of multistatic radar
configurations over monostatic ones in RATR. However, fusion methods in
multistatic radar configurations often suboptimally combine classification
vectors from individual radars probabilistically. To address this, we propose a
fully Bayesian RATR framework employing Optimal Bayesian Fusion (OBF) to
aggregate classification probability vectors from multiple radars. OBF, based
on expected 0-1 loss, updates a Recursive Bayesian Classification (RBC)
posterior distribution for target UAV type, conditioned on historical
observations across multiple time steps. We evaluate the approach using
simulated random walk trajectories for seven drones, correlating target aspect
angles to Radar Cross Section (RCS) measurements in an anechoic chamber.
Comparing against single radar Automated Target Recognition (ATR) systems and
suboptimal fusion methods, our empirical results demonstrate that the OBF
method integrated with RBC significantly enhances classification accuracy
compared to other fusion methods and single radar configurations.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17992" title="Abstract">arXiv:2402.17992</a> (cross-list from physics.app-ph) [<a href="/pdf/2402.17992" title="Download PDF">pdf</a>, <a href="/ps/2402.17992" title="Download PostScript">ps</a>, <a href="/format/2402.17992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Informed Machine Learning for Seismic Response Prediction OF  Nonlinear Steel Moment Resisting Frame Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Bond%2C+R+B">R. Bailey Bond</a>, 
<a href="/search/physics?searchtype=author&query=Ren%2C+P">Pu Ren</a>, 
<a href="/search/physics?searchtype=author&query=Hajjar%2C+J+F">Jerome F. Hajjar</a>, 
<a href="/search/physics?searchtype=author&query=Sun%2C+H">Hao Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applied Physics (physics.app-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">There is a growing interest in utilizing machine learning (ML) methods for
structural metamodeling due to the substantial computational cost of
traditional numerical simulations. The existing data-driven strategies show
potential limitations to the model robustness and interpretability as well as
the dependency of rich data. To address these challenges, this paper presents a
novel physics-informed machine learning (PiML) method, which incorporates
scientific principles and physical laws into deep neural networks for modeling
seismic responses of nonlinear structures. The basic concept is to constrain
the solution space of the ML model within known physical bounds. This is made
possible with three main features, namely, model order reduction, a long
short-term memory (LSTM) networks, and Newton's second law (e.g., the equation
of motion). Model order reduction is essential for handling structural systems
with inherent redundancy and enhancing model efficiency. The LSTM network
captures temporal dependencies, enabling accurate prediction of time series
responses. The equation of motion is manipulated to learn system nonlinearities
and confines the solution space within physically interpretable results. These
features enable model training with relatively sparse data and offer benefits
in terms of accuracy, interpretability, and robustness. Furthermore, a dataset
of seismically designed archetype ductile planar steel moment resistant frames
under horizontal seismic loading, available in the DesignSafe-CI Database, is
considered for evaluation of the proposed method. The resulting metamodel is
capable of handling more complex data compared to existing physics-guided LSTM
models and outperforms other non-physics data-driven neural networks.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17996" title="Abstract">arXiv:2402.17996</a> (cross-list from eess.SP) [<a href="/pdf/2402.17996" title="Download PDF">pdf</a>, <a href="/ps/2402.17996" title="Download PostScript">ps</a>, <a href="/format/2402.17996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Activity-Delay Detection and Channel Estimation for Asynchronous  Massive Random Access: A Free Probability Theory Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bian%2C+X">Xinyu Bian</a>, 
<a href="/search/eess?searchtype=author&query=Mao%2C+Y">Yuyi Mao</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2305.12372">arXiv:2305.12372</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Grant-free random access (RA) has been recognized as a promising solution to
support massive connectivity due to the removal of the uplink grant request
procedures. While most endeavours assume perfect synchronization among users
and the base station, this paper investigates asynchronous grant-free massive
RA, and develop efficient algorithms for joint user activity detection,
synchronization delay detection, and channel estimation. Considering the
sparsity on user activity, we formulate a sparse signal recovery problem and
propose to utilize the framework of orthogonal approximate message passing
(OAMP) to deal with the non-independent and identically distributed (i.i.d.)
Gaussian pilot matrices caused by the synchronization delays. In particular, an
OAMP-based algorithm is developed to fully harness the common sparsity among
received pilot signals from multiple base station antennas. To reduce the
computational complexity, we further propose a free probability AMP
(FPAMP)-based algorithm, which exploits the rectangular free cumulants to make
the cost-effective AMP framework compatible to general pilot matrices.
Simulation results demonstrate that the two proposed algorithms outperform
various baselines, and the FPAMP-based algorithm reduces 40% of the
computations while maintaining comparable detection/estimation accuracy with
the OAMP-based algorithm.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18056" title="Abstract">arXiv:2402.18056</a> (cross-list from eess.IV) [<a href="/pdf/2402.18056" title="Download PDF">pdf</a>, <a href="/format/2402.18056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improvement Of Audiovisual Quality Estimation Using A Nonlinear  Autoregressive Exogenous Neural Network And Bitstream Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kossi%2C+K">Koffi Kossi</a>, 
<a href="/search/eess?searchtype=author&query=Coulombe%2C+S">Stephane Coulombe</a>, 
<a href="/search/eess?searchtype=author&query=Desrosiers%2C+C">Christian Desrosiers</a>, 
<a href="/search/eess?searchtype=author&query=Gagnon%2C+G">Ghyslain Gagnon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">With the increasing demand for audiovisual services, telecom service
providers and application developers are compelled to ensure that their
services provide the best possible user experience. Particularly, services such
as videoconferencing are very sensitive to network conditions. Therefore, their
performance should be monitored in real time in order to adjust parameters to
any network perturbation. In this paper, we developed a parametric model for
estimating the perceived audiovisual quality in videoconference services. Our
model is developed with the nonlinear autoregressive exogenous (NARX) recurrent
neural network and estimates the perceived quality in terms of mean opinion
score (MOS). We validate our model using the publicly available INRS bitstream
audiovisual quality dataset. This dataset contains bitstream parameters such as
loss per frame, bit rate and video duration. We compare the proposed model
against state-of-the-art methods based on machine learning and show our model
to outperform these methods in terms of mean square error (MSE=0.150) and
Pearson correlation coefficient (R=0.931)
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18102" title="Abstract">arXiv:2402.18102</a> (cross-list from eess.IV) [<a href="/pdf/2402.18102" title="Download PDF">pdf</a>, <a href="/format/2402.18102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Passive Snapshot Coded Aperture Dual-Pixel RGB-D Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ghanekar%2C+B">Bhargav Ghanekar</a>, 
<a href="/search/eess?searchtype=author&query=Khan%2C+S+S">Salman Siddique Khan</a>, 
<a href="/search/eess?searchtype=author&query=Boominathan%2C+V">Vivek Boominathan</a>, 
<a href="/search/eess?searchtype=author&query=Sharma%2C+P">Pranav Sharma</a>, 
<a href="/search/eess?searchtype=author&query=Singh%2C+S">Shreyas Singh</a>, 
<a href="/search/eess?searchtype=author&query=Mitra%2C+K">Kaushik Mitra</a>, 
<a href="/search/eess?searchtype=author&query=Veeraraghavan%2C+A">Ashok Veeraraghavan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Passive, compact, single-shot 3D sensing is useful in many application areas
such as microscopy, medical imaging, surgical navigation, and autonomous
driving where form factor, time, and power constraints can exist. Obtaining
RGB-D scene information over a short imaging distance, in an ultra-compact form
factor, and in a passive, snapshot manner is challenging. Dual-pixel (DP)
sensors are a potential solution to achieve the same. DP sensors collect light
rays from two different halves of the lens in two interleaved pixel arrays,
thus capturing two slightly different views of the scene, like a stereo camera
system. However, imaging with a DP sensor implies that the defocus blur size is
directly proportional to the disparity seen between the views. This creates a
trade-off between disparity estimation vs. deblurring accuracy. To improve this
trade-off effect, we propose CADS (Coded Aperture Dual-Pixel Sensing), in which
we use a coded aperture in the imaging lens along with a DP sensor. In our
approach, we jointly learn an optimal coded pattern and the reconstruction
algorithm in an end-to-end optimization setting. Our resulting CADS imaging
system demonstrates improvement of $&gt;$1.5dB PSNR in all-in-focus (AIF)
estimates and 5-6% in depth estimation quality over naive DP sensing for a wide
range of aperture settings. Furthermore, we build the proposed CADS prototypes
for DSLR photography settings and in an endoscope and a dermoscope form factor.
Our novel coded dual-pixel sensing approach demonstrates accurate RGB-D
reconstruction results in simulations and real-world experiments in a passive,
snapshot, and compact manner.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18112" title="Abstract">arXiv:2402.18112</a> (cross-list from eess.SP) [<a href="/pdf/2402.18112" title="Download PDF">pdf</a>, <a href="/format/2402.18112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple But Effective: Rethinking the Ability of Deep Learning in fNIRS  to Exclude Abnormal Input
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cao%2C+Z">Zhihao Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Functional near-infrared spectroscopy (fNIRS) is a non-invasive technique for
monitoring brain activity. To better understand the brain, researchers often
use deep learning to address the classification challenges of fNIRS data. Our
study shows that while current networks in fNIRS are highly accurate for
predictions within their training distribution, they falter at identifying and
excluding abnormal data which is out-of-distribution, affecting their
reliability. We propose integrating metric learning and supervised methods into
fNIRS research to improve networks capability in identifying and excluding
out-of-distribution outliers. This method is simple yet effective. In our
experiments, it significantly enhances the performance of various networks in
fNIRS, particularly transformer-based one, which shows the great improvement in
reliability. We will make our experiment data available on GitHub.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18119" title="Abstract">arXiv:2402.18119</a> (cross-list from q-fin.RM) [<a href="/pdf/2402.18119" title="Download PDF">pdf</a>, <a href="/format/2402.18119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling and Analysis of Crypto-Backed Over-Collateralized Stable  Derivatives in DeFi
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Feng%2C+Z">Zhenbang Feng</a>, 
<a href="/search/q-fin?searchtype=author&query=Mohanty%2C+H">Hardhik Mohanty</a>, 
<a href="/search/q-fin?searchtype=author&query=Krishnamachari%2C+B">Bhaskar Krishnamachari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Risk Management (q-fin.RM)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">In decentralized finance (DeFi), stablecoins like DAI are designed to offer a
stable value amidst the fluctuating nature of cryptocurrencies. We examine the
class of crypto-backed stable derivatives, with a focus on mechanisms for price
stabilization, which is exemplified by the well-known stablecoin DAI from
MakerDAO. For simplicity, we focus on a single-collateral setting. We introduce
a belief parameter to the simulation model of DAI in a previous work (DAISIM),
reflecting market sentiments about the value and stability of DAI, and show
that it better matches the expected behavior when this parameter is set to a
sufficiently high value. We also propose a simple mathematical model of DAI
price to explain its stability and dependency on ETH price. Finally, we analyze
possible risk factors associated with these stable derivatives to provide
valuable insights for stakeholders in the DeFi ecosystem.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18147" title="Abstract">arXiv:2402.18147</a> (cross-list from eess.IV) [<a href="/pdf/2402.18147" title="Download PDF">pdf</a>, <a href="/format/2402.18147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lightweight Low-Light Image Enhancement Network via Channel Prior and  Gamma Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Weng%2C+S">Shyang-En Weng</a>, 
<a href="/search/eess?searchtype=author&query=Miaou%2C+S">Shaou-Gang Miaou</a>, 
<a href="/search/eess?searchtype=author&query=Christanto%2C+R">Ricky Christanto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint of an article submitted for consideration in [International Journal of Pattern Recognition and Artificial Intelligence] \c{opyright} [2024] [copyright World Scientific Publishing Company] [<a href="https://www.worldscientific.com/worldscinet/ijprai">this https URL</a>]
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Human vision relies heavily on available ambient light to perceive objects.
Low-light scenes pose two distinct challenges: information loss due to
insufficient illumination and undesirable brightness shifts. Low-light image
enhancement (LLIE) refers to image enhancement technology tailored to handle
this scenario. We introduce CPGA-Net, an innovative LLIE network that combines
dark/bright channel priors and gamma correction via deep learning and
integrates features inspired by the Atmospheric Scattering Model and the
Retinex Theory. This approach combines the use of traditional and deep learning
methodologies, designed within a simple yet efficient architectural framework
that focuses on essential feature extraction. The resulting CPGA-Net is a
lightweight network with only 0.025 million parameters and 0.030 seconds for
inference time, yet it achieves superior performance over existing LLIE methods
on both objective and subjective evaluation criteria. Furthermore, we utilized
knowledge distillation with explainable factors and proposed an efficient
version that achieves 0.018 million parameters and 0.006 seconds for inference
time. The proposed approaches inject new solution ideas into LLIE, providing
practical applications in challenging low-light scenarios.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18152" title="Abstract">arXiv:2402.18152</a> (cross-list from eess.IV) [<a href="/pdf/2402.18152" title="Download PDF">pdf</a>, <a href="/format/2402.18152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Neural Representations for Videos with a Conditional Decoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xinjie Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+R">Ren Yang</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+D">Dailan He</a>, 
<a href="/search/eess?searchtype=author&query=Ge%2C+X">Xingtong Ge</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+T">Tongda Xu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Qin%2C+H">Hongwei Qin</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accept by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Implicit neural representations (INRs) have emerged as a promising approach
for video storage and processing, showing remarkable versatility across various
video tasks. However, existing methods often fail to fully leverage their
representation capabilities, primarily due to inadequate alignment of
intermediate features during target frame decoding. This paper introduces a
universal boosting framework for current implicit video representation
approaches. Specifically, we utilize a conditional decoder with a
temporal-aware affine transform module, which uses the frame index as a prior
condition to effectively align intermediate features with target frames.
Besides, we introduce a sinusoidal NeRV-like block to generate diverse
intermediate features and achieve a more balanced parameter distribution,
thereby enhancing the model's capacity. With a high-frequency
information-preserving reconstruction loss, our approach successfully boosts
multiple baseline INRs in the reconstruction quality and convergence speed for
video regression, and exhibits superior inpainting and interpolation results.
Further, we integrate a consistent entropy minimization technique and develop
video codecs based on these boosted INRs. Experiments on the UVG dataset
confirm that our enhanced codecs significantly outperform baseline INRs and
offer competitive rate-distortion performance compared to traditional and
learning-based codecs.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18193" title="Abstract">arXiv:2402.18193</a> (cross-list from math.AG) [<a href="/pdf/2402.18193" title="Download PDF">pdf</a>, <a href="/format/2402.18193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counting points with Riemann-Roch formulas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mart%C3%ADn-Morales%2C+J">Jorge Mart&#xed;n-Morales</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Revista de la Real Academia de Ciencias de Zaragoza 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Geometry (math.AG)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">We provide an algorithm for computing the number of integral points lying in
certain triangles that do not have integral vertices. We use techniques from
Algebraic Geometry such as the Riemann-Roch formula for weighted projective
planes and resolution of singularities. We analyze the complexity of the method
and show that the worst case is given by the Fibonacci sequence. At the end of
the manuscript a concrete example is developed in detail where the interplay
with other invariants of singularity theory is also treated.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18203" title="Abstract">arXiv:2402.18203</a> (cross-list from physics.soc-ph) [<a href="/pdf/2402.18203" title="Download PDF">pdf</a>, <a href="/format/2402.18203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the space of graphs with fixed discrete curvatures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Roost%2C+M">Michelle Roost</a>, 
<a href="/search/physics?searchtype=author&query=Devriendt%2C+K">Karel Devriendt</a>, 
<a href="/search/physics?searchtype=author&query=Zucal%2C+G">Giulio Zucal</a>, 
<a href="/search/physics?searchtype=author&query=Jost%2C+J">J&#xfc;rgen Jost</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">Discrete curvatures are quantities associated to the nodes and edges of a
graph that reflect the local geometry around them. These curvatures have a rich
mathematical theory and they have recently found success as a tool to analyze
networks across a wide range of domains. In this work, we consider the problem
of constructing graphs with a prescribed set of discrete edge curvatures, and
explore the space of such graphs. We address this problem in two ways: first,
we develop an evolutionary algorithm to sample graphs with discrete curvatures
close to a given set. We use this algorithm to explore how other network
statistics vary when constrained by the discrete curvatures in the network.
Second, we solve the exact reconstruction problem for the specific case of
Forman-Ricci curvature. By leveraging the theory of Markov bases, we obtain a
finite set of rewiring moves that connects the space of all graphs with a fixed
discrete curvature.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18271" title="Abstract">arXiv:2402.18271</a> (cross-list from eess.SP) [<a href="/pdf/2402.18271" title="Download PDF">pdf</a>, <a href="/format/2402.18271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Intelligent Integrated Sensing and Communications: The  6G-DISAC Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Strinati%2C+E+C">Emilio Calvanese Strinati</a>, 
<a href="/search/eess?searchtype=author&query=Alexandropoulos%2C+G+C">George C. Alexandropoulos</a>, 
<a href="/search/eess?searchtype=author&query=Giyyarpuram%2C+M">Madhusudan Giyyarpuram</a>, 
<a href="/search/eess?searchtype=author&query=Sehier%2C+P">Philippe Sehier</a>, 
<a href="/search/eess?searchtype=author&query=Mekki%2C+S">Sami Mekki</a>, 
<a href="/search/eess?searchtype=author&query=Sciancalepore%2C+V">Vincenzo Sciancalepore</a>, 
<a href="/search/eess?searchtype=author&query=Stark%2C+M">Maximilian Stark</a>, 
<a href="/search/eess?searchtype=author&query=Sana%2C+M">Mohamed Sana</a>, 
<a href="/search/eess?searchtype=author&query=Denis%2C+B">Benoit Denis</a>, 
<a href="/search/eess?searchtype=author&query=Crozzoli%2C+M">Maurizio Crozzoli</a>, 
<a href="/search/eess?searchtype=author&query=Amani%2C+N">Navid Amani</a>, 
<a href="/search/eess?searchtype=author&query=Mursia%2C+P">Placido Mursia</a>, 
<a href="/search/eess?searchtype=author&query=Errico%2C+R+D">Raffaele D Errico</a>, 
<a href="/search/eess?searchtype=author&query=Boldi%2C+M">Mauro Boldi</a>, 
<a href="/search/eess?searchtype=author&query=Costanzo%2C+F">Francesca Costanzo</a>, 
<a href="/search/eess?searchtype=author&query=Rivet%2C+F">Francois Rivet</a>, 
<a href="/search/eess?searchtype=author&query=Wymeerschx%2C+H">Henk Wymeerschx</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for conference publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">This paper introduces the concept of Distributed Intelligent integrated
Sensing and Communications (DISAC), which expands the capabilities of
Integrated Sensing and Communications (ISAC) towards distributed architectures.
Additionally, the DISAC framework integrates novel waveform design with new
semantic and goal-oriented communication paradigms, enabling ISAC technologies
to transition from traditional data fusion to the semantic composition of
diverse sensed and shared information. This progress facilitates large-scale,
energy-efficient support for high-precision spatial-temporal processing,
optimizing ISAC resource utilization, and enabling effective multi-modal
sensing performance. Addressing key challenges such as efficient data
management and connect-compute resource utilization, 6G- DISAC stands to
revolutionize applications in diverse sectors including transportation,
healthcare, and industrial automation. Our study encapsulates the project
vision, methodologies, and potential impact, marking a significant stride
towards a more connected and intelligent world.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18280" title="Abstract">arXiv:2402.18280</a> (cross-list from quant-ph) [<a href="/pdf/2402.18280" title="Download PDF">pdf</a>, <a href="/ps/2402.18280" title="Download PostScript">ps</a>, <a href="/format/2402.18280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Indirect Job-Shop coding using rank: application to QAOA (IQAOA)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Bourreau%2C+E">Eric Bourreau</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fleury%2C+G">Gerard Fleury</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lacomme%2C+P">Phlippe Lacomme</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">The Job-Shop Scheduling Problem (JSSP) stands as one of the most renowned
challenges in scheduling. It is characterized as a disjunctive problem, wherein
a solution is fully depicted through an oriented disjunctive graph, with
earliest starting times computed using a longest path algorithm. The complexity
of solving this problem arises in part from the requirement that disjunctive
graphs representing solutions must be acyclic. Consequently, enumerating these
graphs is feasible for small-scale instances only. A significant advancement in
this field, credited to (Bierwith, 1995), is the introduction of the 'vector by
repetition' (commonly known as Bierwith's vector). Notably, this vector
possesses the property that it can be mapped to an acyclic disjunctive graph,
thereby enabling the mapping of a vector to a solution. This property has
facilitated the development of highly efficient resolution schemes, as it
allows the enumeration of solutions only i.e. acyclic disjunctive graphs. Our
objective is to demonstrate how Bierwith's vector can be integrated into a
Quantum Approximate Optimization Algorithm (QAOA) to tackle the job-shop
problem using a novel quantum approach.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18305" title="Abstract">arXiv:2402.18305</a> (cross-list from eess.IV) [<a href="/pdf/2402.18305" title="Download PDF">pdf</a>, <a href="/format/2402.18305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NERV++: An Enhanced Implicit Neural Video Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ghorbel%2C+A">Ahmed Ghorbel</a>, 
<a href="/search/eess?searchtype=author&query=Hamidouche%2C+W">Wassim Hamidouche</a>, 
<a href="/search/eess?searchtype=author&query=Morin%2C+L">Luce Morin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Neural fields, also known as implicit neural representations (INRs), have
shown a remarkable capability of representing, generating, and manipulating
various data types, allowing for continuous data reconstruction at a low memory
footprint. Though promising, INRs applied to video compression still need to
improve their rate-distortion performance by a large margin, and require a huge
number of parameters and long training iterations to capture high-frequency
details, limiting their wider applicability. Resolving this problem remains a
quite challenging task, which would make INRs more accessible in compression
tasks. We take a step towards resolving these shortcomings by introducing
neural representations for videos NeRV++, an enhanced implicit neural video
representation, as more straightforward yet effective enhancement over the
original NeRV decoder architecture, featuring separable conv2d residual blocks
(SCRBs) that sandwiches the upsampling block (UB), and a bilinear interpolation
skip layer for improved feature representation. NeRV++ allows videos to be
directly represented as a function approximated by a neural network, and
significantly enhance the representation capacity beyond current INR-based
video codecs. We evaluate our method on UVG, MCL JVC, and Bunny datasets,
achieving competitive results for video compression with INRs. This achievement
narrows the gap to autoencoder-based video coding, marking a significant stride
in INR-based video compression research.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18396" title="Abstract">arXiv:2402.18396</a> (cross-list from q-bio.BM) [<a href="/pdf/2402.18396" title="Download PDF">pdf</a>, <a href="/format/2402.18396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Confident Steps to New Pockets: Strategies for Docking  Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Corso%2C+G">Gabriele Corso</a>, 
<a href="/search/q-bio?searchtype=author&query=Deng%2C+A">Arthur Deng</a>, 
<a href="/search/q-bio?searchtype=author&query=Fry%2C+B">Benjamin Fry</a>, 
<a href="/search/q-bio?searchtype=author&query=Polizzi%2C+N">Nicholas Polizzi</a>, 
<a href="/search/q-bio?searchtype=author&query=Barzilay%2C+R">Regina Barzilay</a>, 
<a href="/search/q-bio?searchtype=author&query=Jaakkola%2C+T">Tommi Jaakkola</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on Learning Representations 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Accurate blind docking has the potential to lead to new biological
breakthroughs, but for this promise to be realized, docking methods must
generalize well across the proteome. Existing benchmarks, however, fail to
rigorously assess generalizability. Therefore, we develop DockGen, a new
benchmark based on the ligand-binding domains of proteins, and we show that
existing machine learning-based docking models have very weak generalization
abilities. We carefully analyze the scaling laws of ML-based docking and show
that, by scaling data and model size, as well as integrating synthetic data
strategies, we are able to significantly increase the generalization capacity
and set new state-of-the-art performance across benchmarks. Further, we propose
Confidence Bootstrapping, a new training paradigm that solely relies on the
interaction between diffusion and confidence models and exploits the
multi-resolution generation process of diffusion models. We demonstrate that
Confidence Bootstrapping significantly improves the ability of ML-based docking
methods to dock to unseen protein classes, edging closer to accurate and
generalizable blind docking methods.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18412" title="Abstract">arXiv:2402.18412</a> (cross-list from quant-ph) [<a href="/pdf/2402.18412" title="Download PDF">pdf</a>, <a href="/ps/2402.18412" title="Download PostScript">ps</a>, <a href="/format/2402.18412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QAOA with random and subgraph driver Hamiltonians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Wilkie%2C+A">Anthony Wilkie</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gaidai%2C+I">Igor Gaidai</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ostrowski%2C+J">James Ostrowski</a>, 
<a href="/search/quant-ph?searchtype=author&query=Herrman%2C+R">Rebekah Herrman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">The quantum approximate optimization algorithm (QAOA) is a promising quantum
algorithm that can be used to approximately solve combinatorial optimization
problems. The usual QAOA ansatz consists of an alternating application of the
cost and mixer Hamiltonians. In this work, we study how using Hamiltonians
other than the usual cost Hamiltonian, dubbed custom driver Hamiltonians, can
affect the performance of QAOA. We derive an expected value formula for QAOA
with custom driver Hamiltonians at p = 1 and show numerically that some of
these custom drivers can achieve higher approximation ratio than the original
algorithm implementation. Out of all the graphs tested, 0.036% of the random
custom drivers, 75.9% of the subgraph custom drivers, 95.1% of the
triangle-removed custom drivers, and 93.9% of the maximal degree edge-removed
custom drivers have a higher approximation ratio than the original QAOA
implementation. This finding opens up the question of whether better driver
Hamiltonians can be designed to further improve the performance of QAOA.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18415" title="Abstract">arXiv:2402.18415</a> (cross-list from math.OC) [<a href="/pdf/2402.18415" title="Download PDF">pdf</a>, <a href="/ps/2402.18415" title="Download PostScript">ps</a>, <a href="/format/2402.18415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECCBO: An Inherently Safe Bayesian Optimization with Embedded Constraint  Control for Real-Time Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Krishnamoorthy%2C+D">Dinesh Krishnamoorthy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IFAC ADCHEM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper introduces a model-free real-time optimization (RTO) framework
based on unconstrained Bayesian optimization with embedded constraint control.
The main contribution lies in demonstrating how this approach simplifies the
black-box optimization problem while ensuring "always-feasible" setpoints,
addressing a critical challenge in real-time optimization with unknown cost and
constraints. Noting that controlling the constraint does not require detailed
process models, the key idea of this paper is to control the constraints to
"some" setpoint using simple feedback controllers. Bayesian optimization then
computes the optimum setpoint for the constraint controllers. By searching over
the setpoints for the constraint controllers, as opposed to searching directly
over the RTO degrees of freedom, this paper achieves an inherently safe and
practical model-free RTO scheme. In particular, this paper shows that the
proposed approach can achieve zero cumulative constraint violation without
relying on assumptions about the Gaussian process model used in Bayesian
optimization. The effectiveness of the proposed approach is demonstrated on a
benchmark Williams-Otto reactor example.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18417" title="Abstract">arXiv:2402.18417</a> (cross-list from eess.IV) [<a href="/pdf/2402.18417" title="Download PDF">pdf</a>, <a href="/format/2402.18417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prediction of recurrence free survival of head and neck cancer using  PET/CT radiomics and clinical information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Furukawa%2C+M">Mona Furukawa</a>, 
<a href="/search/eess?searchtype=author&query=McGowan%2C+D+R">Daniel R. McGowan</a>, 
<a href="/search/eess?searchtype=author&query=Papie%C5%BC%2C+B+W">Bart&#x142;omiej W. Papie&#x17c;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The 5-year survival rate of Head and Neck Cancer (HNC) has not improved over
the past decade and one common cause of treatment failure is recurrence. In
this paper, we built Cox proportional hazard (CoxPH) models that predict the
recurrence free survival (RFS) of oropharyngeal HNC patients. Our models
utilise both clinical information and multimodal radiomics features extracted
from tumour regions in Computed Tomography (CT) and Positron Emission
Tomography (PET). Furthermore, we were one of the first studies to explore the
impact of segmentation accuracy on the predictive power of the extracted
radiomics features, through under- and over-segmentation study. Our models were
trained using the HEad and neCK TumOR (HECKTOR) challenge data, and the best
performing model achieved a concordance index (C-index) of 0.74 for the model
utilising clinical information and multimodal CT and PET radiomics features,
which compares favourably with the model that only used clinical information
(C-index of 0.67). Our under- and over-segmentation study confirms that
segmentation accuracy affects radiomics extraction, however, it affects PET and
CT differently.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18451" title="Abstract">arXiv:2402.18451</a> (cross-list from eess.IV) [<a href="/pdf/2402.18451" title="Download PDF">pdf</a>, <a href="/format/2402.18451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MambaMIR: An Arbitrary-Masked Mamba for Joint Medical Image  Reconstruction and Uncertainty Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Huang%2C+J">Jiahao Huang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+L">Liutao Yang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+F">Fanwen Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Y">Yinzhe Wu</a>, 
<a href="/search/eess?searchtype=author&query=Nan%2C+Y">Yang Nan</a>, 
<a href="/search/eess?searchtype=author&query=Aviles-Rivero%2C+A+I">Angelica I. Aviles-Rivero</a>, 
<a href="/search/eess?searchtype=author&query=Sch%C3%B6nlieb%2C+C">Carola-Bibiane Sch&#xf6;nlieb</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+D">Daoqiang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+G">Guang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The recent Mamba model has shown remarkable adaptability for visual
representation learning, including in medical imaging tasks. This study
introduces MambaMIR, a Mamba-based model for medical image reconstruction, as
well as its Generative Adversarial Network-based variant, MambaMIR-GAN. Our
proposed MambaMIR inherits several advantages, such as linear complexity,
global receptive fields, and dynamic weights, from the original Mamba model.
The innovated arbitrary-mask mechanism effectively adapt Mamba to our image
reconstruction task, providing randomness for subsequent Monte Carlo-based
uncertainty estimation. Experiments conducted on various medical image
reconstruction tasks, including fast MRI and SVCT, which cover anatomical
regions such as the knee, chest, and abdomen, have demonstrated that MambaMIR
and MambaMIR-GAN achieve comparable or superior reconstruction results relative
to state-of-the-art methods. Additionally, the estimated uncertainty maps offer
further insights into the reliability of the reconstruction quality. The code
is publicly available at https://github.com/ayanglab/MambaMIR.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18484" title="Abstract">arXiv:2402.18484</a> (cross-list from physics.ao-ph) [<a href="/pdf/2402.18484" title="Download PDF">pdf</a>, <a href="/format/2402.18484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A non-intrusive machine learning framework for debiasing long-time  coarse resolution climate simulations and quantifying rare events statistics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Sorensen%2C+B+B">Benedikt Barthel Sorensen</a>, 
<a href="/search/physics?searchtype=author&query=Charalampopoulos%2C+A">Alexis Charalampopoulos</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+S">Shixuan Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Harrop%2C+B">Bryce Harrop</a>, 
<a href="/search/physics?searchtype=author&query=Leung%2C+R">Ruby Leung</a>, 
<a href="/search/physics?searchtype=author&query=Sapsis%2C+T">Themistoklis Sapsis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Due to the rapidly changing climate, the frequency and severity of extreme
weather is expected to increase over the coming decades. As fully-resolved
climate simulations remain computationally intractable, policy makers must rely
on coarse-models to quantify risk for extremes. However, coarse models suffer
from inherent bias due to the ignored "sub-grid" scales. We propose a framework
to non-intrusively debias coarse-resolution climate predictions using
neural-network (NN) correction operators. Previous efforts have attempted to
train such operators using loss functions that match statistics. However, this
approach falls short with events that have longer return period than that of
the training data, since the reference statistics have not converged. Here, the
scope is to formulate a learning method that allows for correction of dynamics
and quantification of extreme events with longer return period than the
training data. The key obstacle is the chaotic nature of the underlying
dynamics. To overcome this challenge, we introduce a dynamical systems approach
where the correction operator is trained using reference data and a coarse
model simulation nudged towards that reference. The method is demonstrated on
debiasing an under-resolved quasi-geostrophic model and the Energy Exascale
Earth System Model (E3SM). For the former, our method enables the
quantification of events that have return period two orders longer than the
training data. For the latter, when trained on 8 years of ERA5 data, our
approach is able to correct the coarse E3SM output to closely reflect the
36-year ERA5 statistics for all prognostic variables and significantly reduce
their spatial biases.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18485" title="Abstract">arXiv:2402.18485</a> (cross-list from q-fin.TR) [<a href="/pdf/2402.18485" title="Download PDF">pdf</a>, <a href="/format/2402.18485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FinAgent: A Multimodal Foundation Agent for Financial Trading:  Tool-Augmented, Diversified, and Generalist
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Zhang%2C+W">Wentao Zhang</a>, 
<a href="/search/q-fin?searchtype=author&query=Zhao%2C+L">Lingxuan Zhao</a>, 
<a href="/search/q-fin?searchtype=author&query=Xia%2C+H">Haochong Xia</a>, 
<a href="/search/q-fin?searchtype=author&query=Sun%2C+S">Shuo Sun</a>, 
<a href="/search/q-fin?searchtype=author&query=Sun%2C+J">Jiaze Sun</a>, 
<a href="/search/q-fin?searchtype=author&query=Qin%2C+M">Molei Qin</a>, 
<a href="/search/q-fin?searchtype=author&query=Li%2C+X">Xinyi Li</a>, 
<a href="/search/q-fin?searchtype=author&query=Zhao%2C+Y">Yuqing Zhao</a>, 
<a href="/search/q-fin?searchtype=author&query=Zhao%2C+Y">Yilei Zhao</a>, 
<a href="/search/q-fin?searchtype=author&query=Cai%2C+X">Xinyu Cai</a>, 
<a href="/search/q-fin?searchtype=author&query=Zheng%2C+L">Longtao Zheng</a>, 
<a href="/search/q-fin?searchtype=author&query=Wang%2C+X">Xinrun Wang</a>, 
<a href="/search/q-fin?searchtype=author&query=An%2C+B">Bo An</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Trading and Market Microstructure (q-fin.TR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Financial trading is a crucial component of the markets, informed by a
multimodal information landscape encompassing news, prices, and Kline charts,
and encompasses diverse tasks such as quantitative trading and high-frequency
trading with various assets. While advanced AI techniques like deep learning
and reinforcement learning are extensively utilized in finance, their
application in financial trading tasks often faces challenges due to inadequate
handling of multimodal data and limited generalizability across various tasks.
To address these challenges, we present FinAgent, a multimodal foundational
agent with tool augmentation for financial trading. FinAgent's market
intelligence module processes a diverse range of data-numerical, textual, and
visual-to accurately analyze the financial market. Its unique dual-level
reflection module not only enables rapid adaptation to market dynamics but also
incorporates a diversified memory retrieval system, enhancing the agent's
ability to learn from historical data and improve decision-making processes.
The agent's emphasis on reasoning for actions fosters trust in its financial
decisions. Moreover, FinAgent integrates established trading strategies and
expert insights, ensuring that its trading approaches are both data-driven and
rooted in sound financial principles. With comprehensive experiments on 6
financial datasets, including stocks and Crypto, FinAgent significantly
outperforms 9 state-of-the-art baselines in terms of 6 financial metrics with
over 36% average improvement on profit. Specifically, a 92.27% return (a 84.39%
relative improvement) is achieved on one dataset. Notably, FinAgent is the
first advanced multimodal foundation agent designed for financial trading
tasks.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Thu, 29 Feb 24</h3>
<dl>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2004.14147" title="Abstract">arXiv:2004.14147</a> (replaced) [<a href="/pdf/2004.14147" title="Download PDF">pdf</a>, <a href="/ps/2004.14147" title="Download PostScript">ps</a>, <a href="/format/2004.14147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Existence of Algebraic Natural Proofs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+P">Prerona Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+M">Mrinal Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Ramya%2C+C">C Ramya</a>, 
<a href="/search/cs?searchtype=author&query=Saptharishi%2C+R">Ramprasad Saptharishi</a>, 
<a href="/search/cs?searchtype=author&query=Tengse%2C+A">Anamay Tengse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The work <a href="/abs/2012.07056">arXiv:2012.07056</a> "If VNP is hard, then so are equations for it" has been combined with the previous version of this work (CKRST 2020). Further, this version generalizes the main results in the earlier version (CKRST 2020), and also includes more detailed definitions of algebraic natural proofs and other related concepts
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2005.01867" title="Abstract">arXiv:2005.01867</a> (replaced) [<a href="/pdf/2005.01867" title="Download PDF">pdf</a>, <a href="/format/2005.01867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Removable Online Knapsack and Advice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%B6ckenhauer%2C+H">Hans-Joachim B&#xf6;ckenhauer</a>, 
<a href="/search/cs?searchtype=author&query=Frei%2C+F">Fabian Frei</a>, 
<a href="/search/cs?searchtype=author&query=Rossmanith%2C+P">Peter Rossmanith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.08351" title="Abstract">arXiv:2103.08351</a> (replaced) [<a href="/pdf/2103.08351" title="Download PDF">pdf</a>, <a href="/format/2103.08351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Initial nonrepetitive complexity of regular episturmian words and their  Diophantine exponents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peltom%C3%A4ki%2C+J">Jarkko Peltom&#xe4;ki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Number Theory (math.NT)

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.10872" title="Abstract">arXiv:2103.10872</a> (replaced) [<a href="/pdf/2103.10872" title="Download PDF">pdf</a>, <a href="/format/2103.10872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Clearing Payments in a Financial Contagion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Calafiore%2C+G">Giuseppe Calafiore</a>, 
<a href="/search/math?searchtype=author&query=Fracastoro%2C+G">Giulia Fracastoro</a>, 
<a href="/search/math?searchtype=author&query=Proskurnikov%2C+A+V">Anton V. Proskurnikov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computational Engineering, Finance, and Science (cs.CE); Mathematical Finance (q-fin.MF); Risk Management (q-fin.RM)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.03893" title="Abstract">arXiv:2104.03893</a> (replaced) [<a href="/pdf/2104.03893" title="Download PDF">pdf</a>, <a href="/format/2104.03893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Fusion of EMG and Vision for Human Grasp Intent Inference in  Prosthetic Hand Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zandigohar%2C+M">Mehrshad Zandigohar</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+M">Mo Han</a>, 
<a href="/search/cs?searchtype=author&query=Sharif%2C+M">Mohammadreza Sharif</a>, 
<a href="/search/cs?searchtype=author&query=Gunay%2C+S+Y">Sezen Yagmur Gunay</a>, 
<a href="/search/cs?searchtype=author&query=Furmanek%2C+M+P">Mariusz P. Furmanek</a>, 
<a href="/search/cs?searchtype=author&query=Yarossi%2C+M">Mathew Yarossi</a>, 
<a href="/search/cs?searchtype=author&query=Bonato%2C+P">Paolo Bonato</a>, 
<a href="/search/cs?searchtype=author&query=Onal%2C+C">Cagdas Onal</a>, 
<a href="/search/cs?searchtype=author&query=Padir%2C+T">Taskin Padir</a>, 
<a href="/search/cs?searchtype=author&query=Erdogmus%2C+D">Deniz Erdogmus</a>, 
<a href="/search/cs?searchtype=author&query=Schirner%2C+G">Gunar Schirner</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Front. Robot. AI 11 (2024) Sec. Biomedical Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.10981" title="Abstract">arXiv:2107.10981</a> (replaced) [<a href="/pdf/2107.10981" title="Download PDF">pdf</a>, <a href="/format/2107.10981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Score-Based Point Cloud Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Shitong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wei Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.12365" title="Abstract">arXiv:2107.12365</a> (replaced) [<a href="/pdf/2107.12365" title="Download PDF">pdf</a>, <a href="/format/2107.12365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inference for Heteroskedastic PCA with Missing Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yan%2C+Y">Yuling Yan</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+Y">Yuxin Chen</a>, 
<a href="/search/math?searchtype=author&query=Fan%2C+J">Jianqing Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to Annals of Statistics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.11265" title="Abstract">arXiv:2109.11265</a> (replaced) [<a href="/pdf/2109.11265" title="Download PDF">pdf</a>, <a href="/format/2109.11265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-End Dense Video Grounding via Parallel Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+F">Fengyuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Weilin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Limin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Computer Vision and Image Understanding (CVIU) in February 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.10194" title="Abstract">arXiv:2110.10194</a> (replaced) [<a href="/e-print/2110.10194" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoFi: Coarse-to-Fine ICP for LiDAR Localization in an Efficient  Long-lasting Point Cloud Map
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Y">Yecheng Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xinming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revise to new article
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.10740" title="Abstract">arXiv:2110.10740</a> (replaced) [<a href="/pdf/2110.10740" title="Download PDF">pdf</a>, <a href="/format/2110.10740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Log-concave poset inequalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chan%2C+S+H">Swee Hong Chan</a>, 
<a href="/search/math?searchtype=author&query=Pak%2C+I">Igor Pak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 70 pages, 4 figures. In v3 additional references are added and typos found by referees are fixed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.07976" title="Abstract">arXiv:2203.07976</a> (replaced) [<a href="/pdf/2203.07976" title="Download PDF">pdf</a>, <a href="/format/2203.07976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Pitfalls of Batch Normalization for End-to-End Video Learning: A  Study on Surgical Workflow Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rivoir%2C+D">Dominik Rivoir</a>, 
<a href="/search/cs?searchtype=author&query=Funke%2C+I">Isabel Funke</a>, 
<a href="/search/cs?searchtype=author&query=Speidel%2C+S">Stefanie Speidel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at Medical Image Analysis (MedIA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.14045" title="Abstract">arXiv:2203.14045</a> (replaced) [<a href="/pdf/2203.14045" title="Download PDF">pdf</a>, <a href="/format/2203.14045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptively Enhancing Facial Expression Crucial Regions via Local  Non-Local Joint Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Guanghui Shi</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+S">Shasha Mao</a>, 
<a href="/search/cs?searchtype=author&query=Gou%2C+S">Shuiping Gou</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+D">Dandan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+L">Licheng Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+L">Lin Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.05424" title="Abstract">arXiv:2204.05424</a> (replaced) [<a href="/pdf/2204.05424" title="Download PDF">pdf</a>, <a href="/format/2204.05424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Call for Clarity in Beam Search: How It Works and When It Stops
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kasai%2C+J">Jungo Kasai</a>, 
<a href="/search/cs?searchtype=author&query=Sakaguchi%2C+K">Keisuke Sakaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Bras%2C+R+L">Ronan Le Bras</a>, 
<a href="/search/cs?searchtype=author&query=Radev%2C+D">Dragomir Radev</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+N+A">Noah A. Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.00530" title="Abstract">arXiv:2205.00530</a> (replaced) [<a href="/pdf/2205.00530" title="Download PDF">pdf</a>, <a href="/ps/2205.00530" title="Download PostScript">ps</a>, <a href="/format/2205.00530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Fisher-Darmois-Koopman-Pitman Theorem and Rao-Blackwell Type  Estimators for Power-Law Distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gayen%2C+A">Atin Gayen</a>, 
<a href="/search/math?searchtype=author&query=Kumar%2C+M+A">M. Ashok Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, Added an interpretation of resampling using generalized sufficient statistics, Minor modifications made, Published in IEEE Transactions on Information Theory, December 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Information Theory 69 (12) 7565 - 7583 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Information Theory (cs.IT); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.03981" title="Abstract">arXiv:2205.03981</a> (replaced) [<a href="/pdf/2205.03981" title="Download PDF">pdf</a>, <a href="/ps/2205.03981" title="Download PostScript">ps</a>, <a href="/format/2205.03981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A construction of a $&#x3bb;$- Poisson generic sequence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Becher%2C+V">Ver&#xf3;nica Becher</a>, 
<a href="/search/math?searchtype=author&query=Himelfarb%2C+G+S">Gabriel Sac Himelfarb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Math. Comp. 92 (2023), 1453-1466
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Number Theory (math.NT)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.11677" title="Abstract">arXiv:2205.11677</a> (replaced) [<a href="/pdf/2205.11677" title="Download PDF">pdf</a>, <a href="/format/2205.11677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Supervised Clustering of Sparse Graphs: Crossing the  Information-Theoretic Threshold
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sheng%2C+J">Junda Sheng</a>, 
<a href="/search/stat?searchtype=author&query=Strohmer%2C+T">Thomas Strohmer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.06154" title="Abstract">arXiv:2207.06154</a> (replaced) [<a href="/pdf/2207.06154" title="Download PDF">pdf</a>, <a href="/format/2207.06154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Robustness of Bayesian Neural Networks to Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bortolussi%2C+L">Luca Bortolussi</a>, 
<a href="/search/cs?searchtype=author&query=Carbone%2C+G">Ginevra Carbone</a>, 
<a href="/search/cs?searchtype=author&query=Laurenti%2C+L">Luca Laurenti</a>, 
<a href="/search/cs?searchtype=author&query=Patane%2C+A">Andrea Patane</a>, 
<a href="/search/cs?searchtype=author&query=Sanguinetti%2C+G">Guido Sanguinetti</a>, 
<a href="/search/cs?searchtype=author&query=Wicker%2C+M">Matthew Wicker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2002.04359">arXiv:2002.04359</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.13332" title="Abstract">arXiv:2207.13332</a> (replaced) [<a href="/pdf/2207.13332" title="Download PDF">pdf</a>, <a href="/format/2207.13332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RealTime QA: What&#x27;s the Answer Right Now?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kasai%2C+J">Jungo Kasai</a>, 
<a href="/search/cs?searchtype=author&query=Sakaguchi%2C+K">Keisuke Sakaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Takahashi%2C+Y">Yoichi Takahashi</a>, 
<a href="/search/cs?searchtype=author&query=Bras%2C+R+L">Ronan Le Bras</a>, 
<a href="/search/cs?searchtype=author&query=Asai%2C+A">Akari Asai</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xinyan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Radev%2C+D">Dragomir Radev</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+N+A">Noah A. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Inui%2C+K">Kentaro Inui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> RealTime QA Website: <a href="https://realtimeqa.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.01416" title="Abstract">arXiv:2208.01416</a> (replaced) [<a href="/pdf/2208.01416" title="Download PDF">pdf</a>, <a href="/format/2208.01416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Biologically Plausible Training of Deep Neural Networks Using a Top-down  Credit Assignment Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jian-Hui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cheng-Lin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zuoren Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.04525" title="Abstract">arXiv:2208.04525</a> (replaced) [<a href="/e-print/2208.04525" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Large Context for Kidney Multi-Structure Segmentation from CTA  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cao%2C+W">Weiwei Cao</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+Y">Yuzhu Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper lacks research value
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.05021" title="Abstract">arXiv:2210.05021</a> (replaced) [<a href="/pdf/2210.05021" title="Download PDF">pdf</a>, <a href="/format/2210.05021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The good, the bad and the ugly sides of data augmentation: An implicit  spectral regularization perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chi-Heng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Kaushik%2C+C">Chiraag Kaushik</a>, 
<a href="/search/cs?searchtype=author&query=Dyer%2C+E+L">Eva L. Dyer</a>, 
<a href="/search/cs?searchtype=author&query=Muthukumar%2C+V">Vidya Muthukumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 72 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.07484" title="Abstract">arXiv:2210.07484</a> (replaced) [<a href="/pdf/2210.07484" title="Download PDF">pdf</a>, <a href="/format/2210.07484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mutual Information Regularized Offline Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+B">Bingyi Kang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhongwen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Min Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shuicheng Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.16002" title="Abstract">arXiv:2210.16002</a> (replaced) [<a href="/pdf/2210.16002" title="Download PDF">pdf</a>, <a href="/format/2210.16002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Learning Models for Vehicle Usage Prediction During COVID-19
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lindroth%2C+T">Tobias Lindroth</a>, 
<a href="/search/cs?searchtype=author&query=Svensson%2C+A">Axel Svensson</a>, 
<a href="/search/cs?searchtype=author&query=%C3%85kerblom%2C+N">Niklas &#xc5;kerblom</a>, 
<a href="/search/cs?searchtype=author&query=Pourabdollah%2C+M">Mitra Pourabdollah</a>, 
<a href="/search/cs?searchtype=author&query=Chehreghani%2C+M+H">Morteza Haghir Chehreghani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article has been accepted for publication in IEEE Transactions on Intelligent Transportation Systems. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TITS.2024.3361676
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.06567" title="Abstract">arXiv:2211.06567</a> (replaced) [<a href="/pdf/2211.06567" title="Download PDF">pdf</a>, <a href="/ps/2211.06567" title="Download PostScript">ps</a>, <a href="/format/2211.06567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Search with Predictions: Pareto-optimal Algorithm and its  Applications in Energy Markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+R">Russell Lee</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Bo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hajiesmaili%2C+M">Mohammad Hajiesmaili</a>, 
<a href="/search/cs?searchtype=author&query=Lui%2C+J+C+S">John C.S. Lui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.07343" title="Abstract">arXiv:2211.07343</a> (replaced) [<a href="/pdf/2211.07343" title="Download PDF">pdf</a>, <a href="/format/2211.07343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Replacing Language Model for Style Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Pengyu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruineng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12954" title="Abstract">arXiv:2211.12954</a> (replaced) [<a href="/pdf/2211.12954" title="Download PDF">pdf</a>, <a href="/format/2211.12954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The NISQ Complexity of Collision Finding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Hamoudi%2C+Y">Yassine Hamoudi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+Q">Qipeng Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sinha%2C+M">Makrand Sinha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages; v2: title changed, major extension to other complexity models
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 43rd International Conference on the Theory and
  Applications of Cryptographic Techniques (EUROCRYPT 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Cryptography and Security (cs.CR); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.15652" title="Abstract">arXiv:2211.15652</a> (replaced) [<a href="/pdf/2211.15652" title="Download PDF">pdf</a>, <a href="/format/2211.15652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Optimal Control via Local Occupation Measures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Holtorf%2C+F">Flemming Holtorf</a>, 
<a href="/search/math?searchtype=author&query=Edelman%2C+A">Alan Edelman</a>, 
<a href="/search/math?searchtype=author&query=Rackauckas%2C+C">Christopher Rackauckas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 4 figures, associated implementation: <a href="https://github.com/FHoltorf/MarkovBounds.jl">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.16657" title="Abstract">arXiv:2211.16657</a> (replaced) [<a href="/pdf/2211.16657" title="Download PDF">pdf</a>, <a href="/format/2211.16657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task-Driven Hybrid Model Reduction for Dexterous Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+W">Wanxin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Posa%2C+M">Michael Posa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Reproducing code: <a href="https://github.com/wanxinjin/Task-Driven-Hybrid-Reduction.">this https URL</a> This is a preprint. The published version can be accessed at IEEE Transactions on Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.06361" title="Abstract">arXiv:2212.06361</a> (replaced) [<a href="/pdf/2212.06361" title="Download PDF">pdf</a>, <a href="/ps/2212.06361" title="Download PostScript">ps</a>, <a href="/format/2212.06361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical Stability of DeepGOPlus Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pepe%2C+I+G">In&#xe9;s Gonzalez Pepe</a>, 
<a href="/search/cs?searchtype=author&query=Chatelain%2C+Y">Yohan Chatelain</a>, 
<a href="/search/cs?searchtype=author&query=Kiar%2C+G">Gregory Kiar</a>, 
<a href="/search/cs?searchtype=author&query=Glatard%2C+T">Tristan Glatard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures, 4 tables with 3 figures, 2 tables in Appendix
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Vol 19, no. 1 (2024): e0296725
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.06540" title="Abstract">arXiv:2212.06540</a> (replaced) [<a href="/pdf/2212.06540" title="Download PDF">pdf</a>, <a href="/format/2212.06540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic ESG Assessment of Companies by Mining and Evaluating Media  Coverage Data: NLP Approach and Tool
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fischbach%2C+J">Jannik Fischbach</a>, 
<a href="/search/cs?searchtype=author&query=Adam%2C+M">Max Adam</a>, 
<a href="/search/cs?searchtype=author&query=Dzhagatspanyan%2C+V">Victor Dzhagatspanyan</a>, 
<a href="/search/cs?searchtype=author&query=Mendez%2C+D">Daniel Mendez</a>, 
<a href="/search/cs?searchtype=author&query=Frattini%2C+J">Julian Frattini</a>, 
<a href="/search/cs?searchtype=author&query=Kosenkov%2C+O">Oleksandr Kosenkov</a>, 
<a href="/search/cs?searchtype=author&query=Elahidoost%2C+P">Parisa Elahidoost</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.06606" title="Abstract">arXiv:2212.06606</a> (replaced) [<a href="/e-print/2212.06606" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenAPI Specification Extended Security Scheme: A method to reduce the  prevalence of Broken Object Level Authorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haddad%2C+R">Rami Haddad</a>, 
<a href="/search/cs?searchtype=author&query=Malki%2C+R+E">Rim El Malki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Withdraw for the time being due to authorship conflicts
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.14556" title="Abstract">arXiv:2212.14556</a> (replaced) [<a href="/pdf/2212.14556" title="Download PDF">pdf</a>, <a href="/ps/2212.14556" title="Download PostScript">ps</a>, <a href="/format/2212.14556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multisensor Multiobject Tracking with Improved Sampling Efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+W">Wenyu Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Meyer%2C+F">Florian Meyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Multiagent Systems (cs.MA); Robotics (cs.RO); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02227" title="Abstract">arXiv:2301.02227</a> (replaced) [<a href="/pdf/2301.02227" title="Download PDF">pdf</a>, <a href="/ps/2301.02227" title="Download PostScript">ps</a>, <a href="/format/2301.02227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal lower bounds for Quantum Learning via Information Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Hadiashar%2C+S+B">Shima Bab Hadiashar</a>, 
<a href="/search/quant-ph?searchtype=author&query=Nayak%2C+A">Ashwin Nayak</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sinha%2C+P">Pulkit Sinha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v3: 40 pages; Added references; edited extensively; simplified the proof of Theorem 3.2; results unchanged. A preliminary version of the results in Section 3 was included in the S.B.H.'s PhD thesis at University of Waterloo (Dec. 2020). An extended abstract of the results in Section 4 was included in the P.S.' bachelor's project report at Indian Institute of Science (Apr. 2022)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Information Theory, vol. 70, no. 3, pp.
  1876-1896, March 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.04205" title="Abstract">arXiv:2301.04205</a> (replaced) [<a href="/pdf/2301.04205" title="Download PDF">pdf</a>, <a href="/format/2301.04205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Performance Verification Methodology for Resource Allocation  Heuristics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goel%2C+S">Saksham Goel</a>, 
<a href="/search/cs?searchtype=author&query=Mikek%2C+B">Benjamin Mikek</a>, 
<a href="/search/cs?searchtype=author&query=Aly%2C+J">Jehad Aly</a>, 
<a href="/search/cs?searchtype=author&query=Arun%2C+V">Venkat Arun</a>, 
<a href="/search/cs?searchtype=author&query=Saeed%2C+A">Ahmed Saeed</a>, 
<a href="/search/cs?searchtype=author&query=Akella%2C+A">Aditya Akella</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01585" title="Abstract">arXiv:2302.01585</a> (replaced) [<a href="/pdf/2302.01585" title="Download PDF">pdf</a>, <a href="/format/2302.01585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SegForestNet: Spatial-Partitioning-Based Aerial Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gritzner%2C+D">Daniel Gritzner</a>, 
<a href="/search/cs?searchtype=author&query=Ostermann%2C+J">J&#xf6;rn Ostermann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the ISPRS for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03559" title="Abstract">arXiv:2302.03559</a> (replaced) [<a href="/pdf/2302.03559" title="Download PDF">pdf</a>, <a href="/format/2302.03559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Metrics for EMF Exposure and Coverage in Real-World Homogeneous  and Inhomogeneous Cellular Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gontier%2C+Q">Quentin Gontier</a>, 
<a href="/search/cs?searchtype=author&query=Wiame%2C+C">Charles Wiame</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shanshan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Di+Renzo%2C+M">Marco Di Renzo</a>, 
<a href="/search/cs?searchtype=author&query=Wiart%2C+J">Joe Wiart</a>, 
<a href="/search/cs?searchtype=author&query=Horlin%2C+F">Fran&#xe7;ois Horlin</a>, 
<a href="/search/cs?searchtype=author&query=Tsigros%2C+C">Christo Tsigros</a>, 
<a href="/search/cs?searchtype=author&query=Oestges%2C+C">Claude Oestges</a>, 
<a href="/search/cs?searchtype=author&query=De+Doncker%2C+P">Philippe De Doncker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11952" title="Abstract">arXiv:2302.11952</a> (replaced) [<a href="/pdf/2302.11952" title="Download PDF">pdf</a>, <a href="/format/2302.11952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simultaneous Drawing of Layered Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Katheder%2C+J">Julia Katheder</a>, 
<a href="/search/cs?searchtype=author&query=Kobourov%2C+S+G">Stephen G. Kobourov</a>, 
<a href="/search/cs?searchtype=author&query=Kuckuk%2C+A">Axel Kuckuk</a>, 
<a href="/search/cs?searchtype=author&query=Pfister%2C+M">Maximilian Pfister</a>, 
<a href="/search/cs?searchtype=author&query=Zink%2C+J">Johannes Zink</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in Proc. 18th International Conference and Workshops on Algorithms and Computation 2024 (WALCOM'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12148" title="Abstract">arXiv:2302.12148</a> (replaced) [<a href="/pdf/2302.12148" title="Download PDF">pdf</a>, <a href="/format/2302.12148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Streaming data recovery via Bayesian tensor train decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yunyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yani Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Q">Qifeng Liao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14119" title="Abstract">arXiv:2302.14119</a> (replaced) [<a href="/pdf/2302.14119" title="Download PDF">pdf</a>, <a href="/format/2302.14119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Double-loop quasi-Monte Carlo estimator for nested integration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bartuska%2C+A">Arved Bartuska</a>, 
<a href="/search/math?searchtype=author&query=Carlon%2C+A+G">Andr&#xe9; Gustavo Carlon</a>, 
<a href="/search/math?searchtype=author&query=Espath%2C+L">Luis Espath</a>, 
<a href="/search/math?searchtype=author&query=Krumscheid%2C+S">Sebastian Krumscheid</a>, 
<a href="/search/math?searchtype=author&query=Tempone%2C+R">Ra&#xfa;l Tempone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00449" title="Abstract">arXiv:2303.00449</a> (replaced) [<a href="/pdf/2303.00449" title="Download PDF">pdf</a>, <a href="/format/2303.00449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Epipolar Consistency Conditions for Rigid Motion Compensation  in In-vivo X-ray Microscopy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thies%2C+M">Mareike Thies</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+F">Fabian Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+M">Mingxuan Gu</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+S">Siyuan Mei</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yixing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Pechmann%2C+S">Sabrina Pechmann</a>, 
<a href="/search/cs?searchtype=author&query=Aust%2C+O">Oliver Aust</a>, 
<a href="/search/cs?searchtype=author&query=Weidner%2C+D">Daniela Weidner</a>, 
<a href="/search/cs?searchtype=author&query=Neag%2C+G">Georgiana Neag</a>, 
<a href="/search/cs?searchtype=author&query=Uderhardt%2C+S">Stefan Uderhardt</a>, 
<a href="/search/cs?searchtype=author&query=Schett%2C+G">Georg Schett</a>, 
<a href="/search/cs?searchtype=author&query=Christiansen%2C+S">Silke Christiansen</a>, 
<a href="/search/cs?searchtype=author&query=Maier%2C+A">Andreas Maier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01687" title="Abstract">arXiv:2303.01687</a> (replaced) [<a href="/pdf/2303.01687" title="Download PDF">pdf</a>, <a href="/format/2303.01687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Neural Tangent Kernels for Privacy-Preserving  Data Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yilin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Adamczewski%2C+K">Kamil Adamczewski</a>, 
<a href="/search/cs?searchtype=author&query=Sutherland%2C+D+J">Danica J. Sutherland</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoxiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+M">Mijung Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02638" title="Abstract">arXiv:2303.02638</a> (replaced) [<a href="/pdf/2303.02638" title="Download PDF">pdf</a>, <a href="/format/2303.02638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discretization of non-uniform rational B-spline (NURBS) models for  meshless isogeometric analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Duh%2C+U">Urban Duh</a>, 
<a href="/search/math?searchtype=author&query=Shankar%2C+V">Varun Shankar</a>, 
<a href="/search/math?searchtype=author&query=Kosec%2C+G">Gregor Kosec</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04795" title="Abstract">arXiv:2303.04795</a> (replaced) [<a href="/pdf/2303.04795" title="Download PDF">pdf</a>, <a href="/format/2303.04795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stabilized profunctors and stable species of structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fiore%2C+M">Marcelo Fiore</a>, 
<a href="/search/cs?searchtype=author&query=Galal%2C+Z">Zeinab Galal</a>, 
<a href="/search/cs?searchtype=author&query=Paquet%2C+H">Hugo Paquet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Category Theory (math.CT); Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09044" title="Abstract">arXiv:2303.09044</a> (replaced) [<a href="/pdf/2303.09044" title="Download PDF">pdf</a>, <a href="/format/2303.09044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoLo-CAM: Class Activation Mapping for Object Co-Localization in  Weakly-Labeled Unconstrained Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belharbi%2C+S">Soufiane Belharbi</a>, 
<a href="/search/cs?searchtype=author&query=Murtaza%2C+S">Shakeeb Murtaza</a>, 
<a href="/search/cs?searchtype=author&query=Pedersoli%2C+M">Marco Pedersoli</a>, 
<a href="/search/cs?searchtype=author&query=Ayed%2C+I+B">Ismail Ben Ayed</a>, 
<a href="/search/cs?searchtype=author&query=McCaffrey%2C+L">Luke McCaffrey</a>, 
<a href="/search/cs?searchtype=author&query=Granger%2C+E">Eric Granger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09117" title="Abstract">arXiv:2303.09117</a> (replaced) [<a href="/pdf/2303.09117" title="Download PDF">pdf</a>, <a href="/format/2303.09117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Modal Causal Intervention for Medical Report Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weixing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Ce Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiarui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cheng-Lin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10289" title="Abstract">arXiv:2303.10289</a> (replaced) [<a href="/pdf/2303.10289" title="Download PDF">pdf</a>, <a href="/format/2303.10289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Play to Earn in the Metaverse with Mobile Edge Computing over Wireless  Networks: A Deep Reinforcement Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chua%2C+T+J">Terence Jie Chua</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenhan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been submitted to IEEE Transactions on Wireless Communications (TWC), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13965" title="Abstract">arXiv:2303.13965</a> (replaced) [<a href="/pdf/2303.13965" title="Download PDF">pdf</a>, <a href="/format/2303.13965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Distance Metric for Various DHT Routing Algorithms in  Peer-to-Peer Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kushwaha%2C+R">Rashmi Kushwaha</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+S">Shreyas Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+Y+N">Yatindra Nath Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, 14 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02730" title="Abstract">arXiv:2304.02730</a> (replaced) [<a href="/pdf/2304.02730" title="Download PDF">pdf</a>, <a href="/ps/2304.02730" title="Download PostScript">ps</a>, <a href="/format/2304.02730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Ordering via Streaming Social Choice Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramseyer%2C+G">Geoffrey Ramseyer</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+A">Ashish Goel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05055" title="Abstract">arXiv:2304.05055</a> (replaced) [<a href="/pdf/2304.05055" title="Download PDF">pdf</a>, <a href="/format/2304.05055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Survey on Deep Graph Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ju%2C+W">Wei Ju</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zheng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yiyang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zequn Liu</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+Q">Qingqing Long</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Z">Ziyue Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yifang Qin</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jianhao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zhiping Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Junwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jingyang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yusheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Neural Networks 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05836" title="Abstract">arXiv:2304.05836</a> (replaced) [<a href="/pdf/2304.05836" title="Download PDF">pdf</a>, <a href="/format/2304.05836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Game-theoretic Framework for Privacy-preserving Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaojin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lixin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qiang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06607" title="Abstract">arXiv:2304.06607</a> (replaced) [<a href="/pdf/2304.06607" title="Download PDF">pdf</a>, <a href="/format/2304.06607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> False Claims against Model Ownership Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Szyller%2C+S">Sebastian Szyller</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+K">Kui Ren</a>, 
<a href="/search/cs?searchtype=author&query=Asokan%2C+N">N. Asokan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13pages,3 figures. To appear in the 33rd USENIX Security Symposium (USENIX Security '24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11821" title="Abstract">arXiv:2304.11821</a> (replaced) [<a href="/pdf/2304.11821" title="Download PDF">pdf</a>, <a href="/format/2304.11821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interruption-Aware Cooperative Perception for V2X Communication-Aided  Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Shunli Ren</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Z">Zixing Lei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dianati%2C+M">Mehrdad Dianati</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yafei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenjun Zhang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Intelligent Vehicles 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11881" title="Abstract">arXiv:2304.11881</a> (replaced) [<a href="/pdf/2304.11881" title="Download PDF">pdf</a>, <a href="/format/2304.11881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource and location sharing in wireless networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stegehuis%2C+C">Clara Stegehuis</a>, 
<a href="/search/cs?searchtype=author&query=Weedage%2C+L">Lotte Weedage</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> PLOS ONE 2024 19(2): e0299396
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12205" title="Abstract">arXiv:2304.12205</a> (replaced) [<a href="/pdf/2304.12205" title="Download PDF">pdf</a>, <a href="/format/2304.12205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthetic Datasets for Autonomous Driving: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Song%2C+Z">Zhihang Song</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+Z">Zimin He</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xingyu Li</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+Q">Qiming Ma</a>, 
<a href="/search/eess?searchtype=author&query=Ming%2C+R">Ruibo Ming</a>, 
<a href="/search/eess?searchtype=author&query=Mao%2C+Z">Zhiqi Mao</a>, 
<a href="/search/eess?searchtype=author&query=Pei%2C+H">Huaxin Pei</a>, 
<a href="/search/eess?searchtype=author&query=Peng%2C+L">Lihui Peng</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+J">Jianming Hu</a>, 
<a href="/search/eess?searchtype=author&query=Yao%2C+D">Danya Yao</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 5 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in IEEE Transactions on Intelligent Vehicles, vol. 9, no. 1, pp.
  1847-1864, Jan. 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14885" title="Abstract">arXiv:2304.14885</a> (replaced) [<a href="/pdf/2304.14885" title="Download PDF">pdf</a>, <a href="/format/2304.14885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Closed-Form Expressions for the Fisher-Rao Distance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Miyamoto%2C+H+K">Henrique K. Miyamoto</a>, 
<a href="/search/math?searchtype=author&query=Meneghetti%2C+F+C+C">F&#xe1;bio C. C. Meneghetti</a>, 
<a href="/search/math?searchtype=author&query=Pinele%2C+J">Julianna Pinele</a>, 
<a href="/search/math?searchtype=author&query=Costa%2C+S+I+R">Sueli I. R. Costa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 3 figures, revised and extended version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Information Theory (cs.IT); Differential Geometry (math.DG)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03919" title="Abstract">arXiv:2305.03919</a> (replaced) [<a href="/pdf/2305.03919" title="Download PDF">pdf</a>, <a href="/format/2305.03919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DBAT: Dynamic Backward Attention Transformer for Material Segmentation  with Cross-Resolution Patches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heng%2C+Y">Yuwen Heng</a>, 
<a href="/search/cs?searchtype=author&query=Dasmahapatra%2C+S">Srinandan Dasmahapatra</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hansung Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06070" title="Abstract">arXiv:2305.06070</a> (replaced) [<a href="/pdf/2305.06070" title="Download PDF">pdf</a>, <a href="/ps/2305.06070" title="Download PostScript">ps</a>, <a href="/format/2305.06070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical Ergodicity and Uniform Estimate of Monotone SPDEs Driven by  Multiplicative Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+Z">Zhihui Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06647" title="Abstract">arXiv:2305.06647</a> (replaced) [<a href="/pdf/2305.06647" title="Download PDF">pdf</a>, <a href="/format/2305.06647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PROM: A Phrase-level Copying Mechanism with Pre-training for Abstractive  Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xinbei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yeyun Gong</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+P">Pengcheng He</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+N">Nan Duan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by COLING2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10734" title="Abstract">arXiv:2305.10734</a> (replaced) [<a href="/pdf/2305.10734" title="Download PDF">pdf</a>, <a href="/format/2305.10734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-Based Speech Enhancement with Joint Generative and Predictive  Decoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Hao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Shimada%2C+K">Kazuki Shimada</a>, 
<a href="/search/cs?searchtype=author&query=Hirano%2C+M">Masato Hirano</a>, 
<a href="/search/cs?searchtype=author&query=Shibuya%2C+T">Takashi Shibuya</a>, 
<a href="/search/cs?searchtype=author&query=Koyama%2C+Y">Yuichiro Koyama</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zhi Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Takahashi%2C+S">Shusuke Takahashi</a>, 
<a href="/search/cs?searchtype=author&query=Kawahara%2C+T">Tatsuya Kawahara</a>, 
<a href="/search/cs?searchtype=author&query=Mitsufuji%2C+Y">Yuki Mitsufuji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11469" title="Abstract">arXiv:2305.11469</a> (replaced) [<a href="/pdf/2305.11469" title="Download PDF">pdf</a>, <a href="/format/2305.11469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> (Rectified Version) The Barzilai-Borwein Method for Distributed  Optimization over Unbalanced Directed Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hu%2C+J">Jinhui Hu</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/math?searchtype=author&query=Zheng%2C+L">Lifeng Zheng</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+L">Ling Zhang</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+H">Huaqing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 8 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Engineering Applications of Artificial Intelligence 99 (2021)
  104151
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11624" title="Abstract">arXiv:2305.11624</a> (replaced) [<a href="/pdf/2305.11624" title="Download PDF">pdf</a>, <a href="/format/2305.11624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient ConvBN Blocks for Transfer Learning and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=You%2C+K">Kaichao You</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+G">Guo Qin</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+A">Anchang Bao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+M">Meng Cao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+P">Ping Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+J">Jiulong Shan</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+M">Mingsheng Long</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024, camera ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13404" title="Abstract">arXiv:2305.13404</a> (replaced) [<a href="/pdf/2305.13404" title="Download PDF">pdf</a>, <a href="/format/2305.13404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Convergence and Generalization Using Parameter Symmetries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Gower%2C+R+M">Robert M. Gower</a>, 
<a href="/search/cs?searchtype=author&query=Walters%2C+R">Robin Walters</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+R">Rose Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 13 figures, ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17224" title="Abstract">arXiv:2305.17224</a> (replaced) [<a href="/pdf/2305.17224" title="Download PDF">pdf</a>, <a href="/format/2305.17224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and Accurate Estimation of Low-Rank Matrices from Noisy  Measurements via Preconditioned Non-Convex Gradient Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+G">Gavin Zhang</a>, 
<a href="/search/math?searchtype=author&query=Chiu%2C+H">Hong-Ming Chiu</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+R+Y">Richard Y. Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18400" title="Abstract">arXiv:2305.18400</a> (replaced) [<a href="/pdf/2305.18400" title="Download PDF">pdf</a>, <a href="/format/2305.18400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Meta-learning Framework for Tuning Parameters of Protection Mechanisms  in Trustworthy Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaojin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yan Kang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lixin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qiang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19044" title="Abstract">arXiv:2305.19044</a> (replaced) [<a href="/pdf/2305.19044" title="Download PDF">pdf</a>, <a href="/format/2305.19044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Promise and Limits of Real-Time Recurrent Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Irie%2C+K">Kazuki Irie</a>, 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+A">Anand Gopalakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Schmidhuber%2C+J">J&#xfc;rgen Schmidhuber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19523" title="Abstract">arXiv:2305.19523</a> (replaced) [<a href="/pdf/2305.19523" title="Download PDF">pdf</a>, <a href="/format/2305.19523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Explanations: LLM-to-LM Interpreter for Enhanced  Text-Attributed Graph Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaoxin He</a>, 
<a href="/search/cs?searchtype=author&query=Bresson%2C+X">Xavier Bresson</a>, 
<a href="/search/cs?searchtype=author&query=Laurent%2C+T">Thomas Laurent</a>, 
<a href="/search/cs?searchtype=author&query=Perold%2C+A">Adam Perold</a>, 
<a href="/search/cs?searchtype=author&query=LeCun%2C+Y">Yann LeCun</a>, 
<a href="/search/cs?searchtype=author&query=Hooi%2C+B">Bryan Hooi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04121" title="Abstract">arXiv:2306.04121</a> (replaced) [<a href="/pdf/2306.04121" title="Download PDF">pdf</a>, <a href="/format/2306.04121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matte Anything: Interactive Natural Image Matting with Segment Anything  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jingfeng Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinggang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+L">Lang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenyu Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, codes: <a href="https://github.com/hustvl/Matte-Anything">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04366" title="Abstract">arXiv:2306.04366</a> (replaced) [<a href="/pdf/2306.04366" title="Download PDF">pdf</a>, <a href="/format/2306.04366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eicient Recruitment Strategy for Collaborative Mobile Crowd Sensing  Based on GCN Trustworthiness Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Z">Zhongwei Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yingjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+P">Peiyong Duan</a>, 
<a href="/search/cs?searchtype=author&query=Sai%2C+A+M+V+V">Akshita Maradapu Vera Venkata Sai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhaowei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+C">Chaocan Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+X">Xiangrong Tong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhipeng Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05292" title="Abstract">arXiv:2306.05292</a> (replaced) [<a href="/pdf/2306.05292" title="Download PDF">pdf</a>, <a href="/format/2306.05292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Collaborative Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Togashi%2C+R">Riku Togashi</a>, 
<a href="/search/cs?searchtype=author&query=Oka%2C+T">Tatsushi Oka</a>, 
<a href="/search/cs?searchtype=author&query=Ohsaka%2C+N">Naoto Ohsaka</a>, 
<a href="/search/cs?searchtype=author&query=Morimura%2C+T">Tetsuro Morimura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at ICLR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05751" title="Abstract">arXiv:2306.05751</a> (replaced) [<a href="/pdf/2306.05751" title="Download PDF">pdf</a>, <a href="/format/2306.05751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Counterfactual Inference through Nonlinear Quantile Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shaoan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Biwei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+B">Bin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tongliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07331" title="Abstract">arXiv:2306.07331</a> (replaced) [<a href="/pdf/2306.07331" title="Download PDF">pdf</a>, <a href="/format/2306.07331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Splitting and Parallelizing of Quantum Convolutional Neural Networks for  Learning Translationally Symmetric Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chinzei%2C+K">Koki Chinzei</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tran%2C+Q+H">Quoc Hoan Tran</a>, 
<a href="/search/quant-ph?searchtype=author&query=Maruyama%2C+K">Kazunori Maruyama</a>, 
<a href="/search/quant-ph?searchtype=author&query=Oshima%2C+H">Hirotaka Oshima</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sato%2C+S">Shintaro Sato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07951" title="Abstract">arXiv:2306.07951</a> (replaced) [<a href="/pdf/2306.07951" title="Download PDF">pdf</a>, <a href="/format/2306.07951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Questioning the Survey Responses of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dominguez-Olmedo%2C+R">Ricardo Dominguez-Olmedo</a>, 
<a href="/search/cs?searchtype=author&query=Hardt%2C+M">Moritz Hardt</a>, 
<a href="/search/cs?searchtype=author&query=Mendler-D%C3%BCnner%2C+C">Celestine Mendler-D&#xfc;nner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08543" title="Abstract">arXiv:2306.08543</a> (replaced) [<a href="/pdf/2306.08543" title="Download PDF">pdf</a>, <a href="/format/2306.08543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MiniLLM: Knowledge Distillation of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuxian Gu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+L">Li Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Furu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Minlie Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper in ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09852" title="Abstract">arXiv:2306.09852</a> (replaced) [<a href="/pdf/2306.09852" title="Download PDF">pdf</a>, <a href="/format/2306.09852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Actor-Critic Model Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Romero%2C+A">Angel Romero</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yunlong Song</a>, 
<a href="/search/cs?searchtype=author&query=Scaramuzza%2C+D">Davide Scaramuzza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Conference on Robotics and Automation (ICRA 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10426" title="Abstract">arXiv:2306.10426</a> (replaced) [<a href="/pdf/2306.10426" title="Download PDF">pdf</a>, <a href="/format/2306.10426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Certified Training with Interval Bound Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yuhao Mao</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+M+N">Mark Niklas M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+M">Marc Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Vechev%2C+M">Martin Vechev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11180" title="Abstract">arXiv:2306.11180</a> (replaced) [<a href="/pdf/2306.11180" title="Download PDF">pdf</a>, <a href="/format/2306.11180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperbolic Active Learning for Semantic Segmentation under Domain Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Franco%2C+L">Luca Franco</a>, 
<a href="/search/cs?searchtype=author&query=Mandica%2C+P">Paolo Mandica</a>, 
<a href="/search/cs?searchtype=author&query=Kallidromitis%2C+K">Konstantinos Kallidromitis</a>, 
<a href="/search/cs?searchtype=author&query=Guillory%2C+D">Devin Guillory</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu-Teng Li</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>, 
<a href="/search/cs?searchtype=author&query=Galasso%2C+F">Fabio Galasso</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11943" title="Abstract">arXiv:2306.11943</a> (replaced) [<a href="/pdf/2306.11943" title="Download PDF">pdf</a>, <a href="/format/2306.11943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Understanding What Code Language Models Learned
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+T">Toufique Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chengxuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cathy Wang</a>, 
<a href="/search/cs?searchtype=author&query=Devanbu%2C+P">Prem Devanbu</a>, 
<a href="/search/cs?searchtype=author&query=Sagae%2C+K">Kenji Sagae</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15725" title="Abstract">arXiv:2306.15725</a> (replaced) [<a href="/pdf/2306.15725" title="Download PDF">pdf</a>, <a href="/format/2306.15725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supportive Fintech for Individuals with Bipolar Disorder: Financial Data  Sharing Preferences to Support Longitudinal Care Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brozena%2C+J">Jeff Brozena</a>, 
<a href="/search/cs?searchtype=author&query=Blair%2C+J">Johnna Blair</a>, 
<a href="/search/cs?searchtype=author&query=Richardson%2C+T">Thomas Richardson</a>, 
<a href="/search/cs?searchtype=author&query=Matthews%2C+M">Mark Matthews</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+D">Dahlia Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Saunders%2C+E+F+H">Erika F. H. Saunders</a>, 
<a href="/search/cs?searchtype=author&query=Abdullah%2C+S">Saeed Abdullah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures, Proceedings of the CHI Conference on Human Factors in Computing Systems, May 11-16, 2024, Honolulu, HI, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00761" title="Abstract">arXiv:2307.00761</a> (replaced) [<a href="/pdf/2307.00761" title="Download PDF">pdf</a>, <a href="/format/2307.00761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Degradation-Independent Representations for Camera ISP  Pipelines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yanhui Guo</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+F">Fangzhou Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaolin Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02074" title="Abstract">arXiv:2307.02074</a> (replaced) [<a href="/pdf/2307.02074" title="Download PDF">pdf</a>, <a href="/format/2307.02074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arbitrageurs&#x27; profits, LVR, and sandwich attacks: batch trading as an  AMM design response
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Canidio%2C+A">Andrea Canidio</a>, 
<a href="/search/cs?searchtype=author&query=Fritsch%2C+R">Robin Fritsch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Blockchain, Decentralized finance, Arbitrage profits, Loss-vs-Rebalancing (LVR), MEV, Sandwich attacks, AMM, Mechanism design, Batch trading
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06016" title="Abstract">arXiv:2307.06016</a> (replaced) [<a href="/pdf/2307.06016" title="Download PDF">pdf</a>, <a href="/format/2307.06016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safety and Liveness of Quantitative Properties and Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boker%2C+U">Udi Boker</a>, 
<a href="/search/cs?searchtype=author&query=Henzinger%2C+T+A">Thomas A. Henzinger</a>, 
<a href="/search/cs?searchtype=author&query=Mazzocchi%2C+N">Nicolas Mazzocchi</a>, 
<a href="/search/cs?searchtype=author&query=Sara%C3%A7%2C+N+E">N. Ege Sara&#xe7;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2301.11175">arXiv:2301.11175</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09055" title="Abstract">arXiv:2307.09055</a> (replaced) [<a href="/pdf/2307.09055" title="Download PDF">pdf</a>, <a href="/ps/2307.09055" title="Download PostScript">ps</a>, <a href="/format/2307.09055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Data Clustering with Outliers via Transformed Tensor Low-Rank  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wu%2C+T">Tong Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11543" title="Abstract">arXiv:2307.11543</a> (replaced) [<a href="/pdf/2307.11543" title="Download PDF">pdf</a>, <a href="/format/2307.11543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KVN: Keypoints Voting Network with Differentiable RANSAC for Stereo Pose  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Donadi%2C+I">Ivano Donadi</a>, 
<a href="/search/cs?searchtype=author&query=Pretto%2C+A">Alberto Pretto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in IEEE Robotics and Automation Letters, 2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12198" title="Abstract">arXiv:2307.12198</a> (replaced) [<a href="/pdf/2307.12198" title="Download PDF">pdf</a>, <a href="/format/2307.12198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NCART: Neural Classification and Regression Tree for Tabular Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiaqi Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shixin Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12545" title="Abstract">arXiv:2307.12545</a> (replaced) [<a href="/pdf/2307.12545" title="Download PDF">pdf</a>, <a href="/format/2307.12545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Video Anomaly Retrieval from Video Anomaly Detection: New  Benchmarks and Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Peng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangteng He</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yuxin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanning Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been accepted to the IEEE TIP. Copyright has been transferred
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13220" title="Abstract">arXiv:2307.13220</a> (replaced) [<a href="/pdf/2307.13220" title="Download PDF">pdf</a>, <a href="/ps/2307.13220" title="Download PostScript">ps</a>, <a href="/format/2307.13220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One for Multiple: Physics-informed Synthetic Data Boosts Generalizable  Deep Learning for Fast MRI Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+X">Xiaotong Yu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Chengyan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+W">Weibo Chen</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jiazheng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Chu%2C+Y">Ying-Hua Chu</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+H">Hongwei Sun</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+R">Rushuai Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+P">Peiyong Li</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+H">Haiwei Han</a>, 
<a href="/search/eess?searchtype=author&query=Kang%2C+T">Taishan Kang</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+J">Jianzhong Lin</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+C">Chen Yang</a>, 
<a href="/search/eess?searchtype=author&query=Chang%2C+S">Shufu Chang</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+Z">Zhang Shi</a>, 
<a href="/search/eess?searchtype=author&query=Hua%2C+S">Sha Hua</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yan Li</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+J">Juan Hu</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+L">Liuhong Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+J">Jianjun Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+M">Meijing Lin</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+J">Jiefeng Guo</a>, 
<a href="/search/eess?searchtype=author&query=Cai%2C+C">Congbo Cai</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Z">Zhong Chen</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+D">Di Guo</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+G">Guang Yang</a>, 
<a href="/search/eess?searchtype=author&query=Qu%2C+X">Xiaobo Qu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 19 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Medical Physics (physics.med-ph)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01184" title="Abstract">arXiv:2308.01184</a> (replaced) [<a href="/pdf/2308.01184" title="Download PDF">pdf</a>, <a href="/format/2308.01184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partial Label Supervision for Agnostic Generative Noisy Label Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fengbei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuanhong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Carneiro%2C+G">Gustavo Carneiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01750" title="Abstract">arXiv:2308.01750</a> (replaced) [<a href="/pdf/2308.01750" title="Download PDF">pdf</a>, <a href="/format/2308.01750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entropy-based detection of Twitter echo chambers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pratelli%2C+M">Manuel Pratelli</a>, 
<a href="/search/cs?searchtype=author&query=Saracco%2C+F">Fabio Saracco</a>, 
<a href="/search/cs?searchtype=author&query=Petrocchi%2C+M">Marinella Petrocchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 11 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Data Analysis, Statistics and Probability (physics.data-an); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04575" title="Abstract">arXiv:2308.04575</a> (replaced) [<a href="/pdf/2308.04575" title="Download PDF">pdf</a>, <a href="/format/2308.04575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding a Sparse Connected Spanning Subgraph in a non-Uniform Failure  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bentert%2C+M">Matthias Bentert</a>, 
<a href="/search/cs?searchtype=author&query=Schestag%2C+J">Jannik Schestag</a>, 
<a href="/search/cs?searchtype=author&query=Sommer%2C+F">Frank Sommer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IPEC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08796" title="Abstract">arXiv:2308.08796</a> (replaced) [<a href="/pdf/2308.08796" title="Download PDF">pdf</a>, <a href="/format/2308.08796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chinese Spelling Correction as Rephrasing Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Linfeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hongqiu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hai Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI'2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09831" title="Abstract">arXiv:2308.09831</a> (replaced) [<a href="/pdf/2308.09831" title="Download PDF">pdf</a>, <a href="/format/2308.09831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-modality Attention-based Multimodal Fusion for Non-small Cell Lung  Cancer (NSCLC) Patient Survival Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Deng%2C+R">Ruining Deng</a>, 
<a href="/search/eess?searchtype=author&query=Shaikh%2C+N">Nazim Shaikh</a>, 
<a href="/search/eess?searchtype=author&query=Shannon%2C+G">Gareth Shannon</a>, 
<a href="/search/eess?searchtype=author&query=Nie%2C+Y">Yao Nie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12532" title="Abstract">arXiv:2308.12532</a> (replaced) [<a href="/pdf/2308.12532" title="Download PDF">pdf</a>, <a href="/format/2308.12532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedSOL: Stabilized Orthogonal Learning in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Gihun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+M">Minchan Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sangmook Kim</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+J">Jaehoon Oh</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Se-Young Yun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The IEEE/CVF Conference on Computer Vision and Pattern Recognition 2024 (CVPR 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13294" title="Abstract">arXiv:2308.13294</a> (replaced) [<a href="/pdf/2308.13294" title="Download PDF">pdf</a>, <a href="/format/2308.13294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training normalizing flows with computationally intensive target  probability distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bialas%2C+P">Piotr Bialas</a>, 
<a href="/search/cs?searchtype=author&query=Korcyl%2C+P">Piotr Korcyl</a>, 
<a href="/search/cs?searchtype=author&query=Stebel%2C+T">Tomasz Stebel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 5 figures, 6 tables, 3 listings. Revised version as published in CPC. Added results for a other values of hoping parameter
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Physics Communications 2024 109094
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistical Mechanics (cond-mat.stat-mech); High Energy Physics - Lattice (hep-lat)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15808" title="Abstract">arXiv:2308.15808</a> (replaced) [<a href="/pdf/2308.15808" title="Download PDF">pdf</a>, <a href="/format/2308.15808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning the References of Online Model Predictive Control for Urban  Self-Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yubin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zengqi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yusen Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yulin Li</a>, 
<a href="/search/cs?searchtype=author&query=Ghazzai%2C+H">Hakim Ghazzai</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jun Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16572" title="Abstract">arXiv:2308.16572</a> (replaced) [<a href="/pdf/2308.16572" title="Download PDF">pdf</a>, <a href="/format/2308.16572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CL-MAE: Curriculum-Learned Masked Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madan%2C+N">Neelu Madan</a>, 
<a href="/search/cs?searchtype=author&query=Ristea%2C+N">Nicolae-Catalin Ristea</a>, 
<a href="/search/cs?searchtype=author&query=Nasrollahi%2C+K">Kamal Nasrollahi</a>, 
<a href="/search/cs?searchtype=author&query=Moeslund%2C+T+B">Thomas B. Moeslund</a>, 
<a href="/search/cs?searchtype=author&query=Ionescu%2C+R+T">Radu Tudor Ionescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16814" title="Abstract">arXiv:2308.16814</a> (replaced) [<a href="/pdf/2308.16814" title="Download PDF">pdf</a>, <a href="/format/2308.16814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cost-effective Planning of Decarbonized Power-Gas Infrastructure to Meet  the Challenges of Heating Electrification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Khorramfar%2C+R">Rahman Khorramfar</a>, 
<a href="/search/eess?searchtype=author&query=Santoni-Colvin%2C+M">Morgan Santoni-Colvin</a>, 
<a href="/search/eess?searchtype=author&query=Amin%2C+S">Saurabh Amin</a>, 
<a href="/search/eess?searchtype=author&query=Norford%2C+L+K">Leslie K. Norford</a>, 
<a href="/search/eess?searchtype=author&query=Botterud%2C+A">Audun Botterud</a>, 
<a href="/search/eess?searchtype=author&query=Mallapragada%2C+D">Dharik Mallapragada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00655" title="Abstract">arXiv:2309.00655</a> (replaced) [<a href="/pdf/2309.00655" title="Download PDF">pdf</a>, <a href="/format/2309.00655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RigNet++: Semantic Assisted Repetitive Image Guided Network for Depth  Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhiqiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+L">Le Hui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02691" title="Abstract">arXiv:2309.02691</a> (replaced) [<a href="/pdf/2309.02691" title="Download PDF">pdf</a>, <a href="/format/2309.02691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Joint Study of Phrase Grounding and Task Performance in Vision and  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kojima%2C+N">Noriyuki Kojima</a>, 
<a href="/search/cs?searchtype=author&query=Averbuch-Elor%2C+H">Hadar Averbuch-Elor</a>, 
<a href="/search/cs?searchtype=author&query=Artzi%2C+Y">Yoav Artzi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This was published in TMLR in 2024, on January 24th
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05388" title="Abstract">arXiv:2309.05388</a> (replaced) [<a href="/pdf/2309.05388" title="Download PDF">pdf</a>, <a href="/format/2309.05388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Single Rotation Averaging Revisited
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S+H">Seong Hun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Civera%2C+J">Javier Civera</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05638" title="Abstract">arXiv:2309.05638</a> (replaced) [<a href="/pdf/2309.05638" title="Download PDF">pdf</a>, <a href="/format/2309.05638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Errors are Robustly Tamed in Cumulative Knowledge Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brandenberger%2C+A">Anna Brandenberger</a>, 
<a href="/search/cs?searchtype=author&query=Marcussen%2C+C">Cassandra Marcussen</a>, 
<a href="/search/cs?searchtype=author&query=Mossel%2C+E">Elchanan Mossel</a>, 
<a href="/search/cs?searchtype=author&query=Sudan%2C+M">Madhu Sudan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 9 figures. Generalized arguments to a broader family of knowledge accumulation models
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Data Structures and Algorithms (cs.DS); Social and Information Networks (cs.SI); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08646" title="Abstract">arXiv:2309.08646</a> (replaced) [<a href="/pdf/2309.08646" title="Download PDF">pdf</a>, <a href="/format/2309.08646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoCA: Fusing Position Embedding with Collinear Constrained Attention in  Transformers for Long Context Window Extending
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shiyi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jing Ye</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+S">Siqiao Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yifan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianguo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10688" title="Abstract">arXiv:2309.10688</a> (replaced) [<a href="/pdf/2309.10688" title="Download PDF">pdf</a>, <a href="/format/2309.10688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the different regimes of Stochastic Gradient Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sclocchi%2C+A">Antonio Sclocchi</a>, 
<a href="/search/cs?searchtype=author&query=Wyart%2C+M">Matthieu Wyart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main: 8 pages, 4 figures; Appendix: 15 pages, 11 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the National Academy of Sciences 121.9 (2024):
  e2316301121
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11015" title="Abstract">arXiv:2309.11015</a> (replaced) [<a href="/e-print/2309.11015" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D-U-SAM Network For Few-shot Tooth Segmentation in CBCT Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yifu Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zuozhu Liu</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+Y">Yang Feng</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+R">Renjing Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper needs to be updated
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13904" title="Abstract">arXiv:2309.13904</a> (replaced) [<a href="/pdf/2309.13904" title="Download PDF">pdf</a>, <a href="/format/2309.13904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subspace-Guided Feature Reconstruction for Unsupervised Anomaly  Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hotta%2C+K">Katsuya Hotta</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hagihara%2C+Y">Yoshihiro Hagihara</a>, 
<a href="/search/cs?searchtype=author&query=Akashi%2C+T">Takuya Akashi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14150" title="Abstract">arXiv:2309.14150</a> (replaced) [<a href="/pdf/2309.14150" title="Download PDF">pdf</a>, <a href="/format/2309.14150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learned Contextual LiDAR Informed Visual Search in Unseen Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+R">Ryan Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Morgenstein%2C+K">Kyle Morgenstein</a>, 
<a href="/search/cs?searchtype=author&query=Ortega%2C+S">Steven Ortega</a>, 
<a href="/search/cs?searchtype=author&query=Sentis%2C+L">Luis Sentis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages + references. 6 figures. 1 algorithm. 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14685" title="Abstract">arXiv:2309.14685</a> (replaced) [<a href="/pdf/2309.14685" title="Download PDF">pdf</a>, <a href="/format/2309.14685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DriveSceneGen: Generating Diverse and Realistic Driving Scenarios from  Scratch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shuo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Z">Zekai Gu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Tianchen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiawei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chengran Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yuhang Han</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongen Li</a>, 
<a href="/search/cs?searchtype=author&query=Ang%2C+M+H">Marcelo H. Ang Jr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15669" title="Abstract">arXiv:2309.15669</a> (replaced) [<a href="/pdf/2309.15669" title="Download PDF">pdf</a>, <a href="/format/2309.15669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Computational Entanglement of Distant Features in Adversarial  Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">YenLung Lai</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xingbo Dong</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhe Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The latest version has titled updated
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16120" title="Abstract">arXiv:2309.16120</a> (replaced) [<a href="/pdf/2309.16120" title="Download PDF">pdf</a>, <a href="/format/2309.16120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Test-Case-Driven Programming Understanding in Large Language Models for  Better Code Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16639" title="Abstract">arXiv:2309.16639</a> (replaced) [<a href="/pdf/2309.16639" title="Download PDF">pdf</a>, <a href="/format/2309.16639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MindShift: Leveraging Large Language Models for Mental-States-Based  Problematic Smartphone Use Intervention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Ruolan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xiaole Pan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yujia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ningning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yue Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuhan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Q">Qiaolei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xuhai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuanchun Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ACM CHI'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17294" title="Abstract">arXiv:2309.17294</a> (replaced) [<a href="/pdf/2309.17294" title="Download PDF">pdf</a>, <a href="/format/2309.17294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-space dynamics of income segregation: a case study of Milan&#x27;s  neighbourhoods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Mori%2C+L+R">Lavinia Rossi Mori</a>, 
<a href="/search/physics?searchtype=author&query=Loreto%2C+V">Vittorio Loreto</a>, 
<a href="/search/physics?searchtype=author&query=Di+Clemente%2C+R">Riccardo Di Clemente</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01018" title="Abstract">arXiv:2310.01018</a> (replaced) [<a href="/pdf/2310.01018" title="Download PDF">pdf</a>, <a href="/format/2310.01018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controlling Vision-Language Models for Multi-Task Image Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Ziwei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Gustafsson%2C+F+K">Fredrik K. Gustafsson</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sj%C3%B6lund%2C+J">Jens Sj&#xf6;lund</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6n%2C+T+B">Thomas B. Sch&#xf6;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICLR 2024. Project page: <a href="https://algolzw.github.io/daclip-uir/index.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01840" title="Abstract">arXiv:2310.01840</a> (replaced) [<a href="/pdf/2310.01840" title="Download PDF">pdf</a>, <a href="/format/2310.01840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised High Dynamic Range Imaging with Multi-Exposure Images in  Dynamic Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhilu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaotao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+L">Lei Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02174" title="Abstract">arXiv:2310.02174</a> (replaced) [<a href="/pdf/2310.02174" title="Download PDF">pdf</a>, <a href="/format/2310.02174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ask Again, Then Fail: Large Language Models&#x27; Vacillations in Judgement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Qiming Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zengzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+R">Rui Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Update abstract and mitigation results of fine-tuning the model on synthesized high-quality preference data with DPO algorithm
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04329" title="Abstract">arXiv:2310.04329</a> (replaced) [<a href="/pdf/2310.04329" title="Download PDF">pdf</a>, <a href="/format/2310.04329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pika: Empowering Non-Programmers to Author Executable Governance  Policies in Online Communities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Leijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Vincent%2C+N">Nicolas Vincent</a>, 
<a href="/search/cs?searchtype=author&query=Rukanskait%C4%97%2C+J">Julija Rukanskait&#x117;</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A+X">Amy X. Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conditionally accepted by CHI'2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05227" title="Abstract">arXiv:2310.05227</a> (replaced) [<a href="/pdf/2310.05227" title="Download PDF">pdf</a>, <a href="/format/2310.05227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-aware Machine Learning Revolutionizes Scientific Paradigm for  Machine Learning and Process-based Hydrology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qingsong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yilei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Bamber%2C+J">Jonathan Bamber</a>, 
<a href="/search/cs?searchtype=author&query=Tuo%2C+Y">Ye Tuo</a>, 
<a href="/search/cs?searchtype=author&query=Ludwig%2C+R">Ralf Ludwig</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X+X">Xiao Xiang Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05333" title="Abstract">arXiv:2310.05333</a> (replaced) [<a href="/pdf/2310.05333" title="Download PDF">pdf</a>, <a href="/format/2310.05333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffCPS: Diffusion Model based Constrained Policy Search for Offline  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+L">Longxiang He</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Linrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+J">Junbo Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xueqian Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 9 figures, 6 tables. Submitted to ICML 2024. arXiv admin note: text overlap with <a href="/abs/1910.13393">arXiv:1910.13393</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06361" title="Abstract">arXiv:2310.06361</a> (replaced) [<a href="/pdf/2310.06361" title="Download PDF">pdf</a>, <a href="/ps/2310.06361" title="Download PostScript">ps</a>, <a href="/format/2310.06361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anticipating Impacts: Using Large-Scale Scenario Writing to Explore  Diverse Implications of Generative AI in the News Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kieslich%2C+K">Kimon Kieslich</a>, 
<a href="/search/cs?searchtype=author&query=Diakopoulos%2C+N">Nicholas Diakopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Helberger%2C+N">Natali Helberger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06474" title="Abstract">arXiv:2310.06474</a> (replaced) [<a href="/pdf/2310.06474" title="Download PDF">pdf</a>, <a href="/format/2310.06474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilingual Jailbreak Challenges in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yue Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S+J">Sinno Jialin Pan</a>, 
<a href="/search/cs?searchtype=author&query=Bing%2C+L">Lidong Bing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07555" title="Abstract">arXiv:2310.07555</a> (replaced) [<a href="/pdf/2310.07555" title="Download PDF">pdf</a>, <a href="/format/2310.07555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does resistance to Style-Transfer equal Shape Bias? Evaluating Shape  Bias by Distorted Shape
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Ziqi Wen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianqin Li</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+Z">Zhi Jing</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+T+S">Tai Sing Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07591" title="Abstract">arXiv:2310.07591</a> (replaced) [<a href="/pdf/2310.07591" title="Download PDF">pdf</a>, <a href="/format/2310.07591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PeP: a Point enhanced Painting method for unified point cloud tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zichao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Hang Ji</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xufeng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weikun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xin Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junbo Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09669" title="Abstract">arXiv:2310.09669</a> (replaced) [<a href="/pdf/2310.09669" title="Download PDF">pdf</a>, <a href="/format/2310.09669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Framework For Automated Dissection Along Tissue Boundary
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+K">Ki-Hwan Oh</a>, 
<a href="/search/cs?searchtype=author&query=Borgioli%2C+L">Leonardo Borgioli</a>, 
<a href="/search/cs?searchtype=author&query=Zefran%2C+M">Milos Zefran</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liaohai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Giulianotti%2C+P+C">Pier Cristoforo Giulianotti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, 7 tables, submitted to 2024 International Conference on Biomedical Robotics and Biomechatronics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10010" title="Abstract">arXiv:2310.10010</a> (replaced) [<a href="/pdf/2310.10010" title="Download PDF">pdf</a>, <a href="/format/2310.10010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Black-box Targeted Adversarial Attack on Segment Anything (SAM)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Sheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+X">Xinhong Hao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11730" title="Abstract">arXiv:2310.11730</a> (replaced) [<a href="/pdf/2310.11730" title="Download PDF">pdf</a>, <a href="/format/2310.11730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Heterogeneous Graph Neural Network for Privacy-preserving  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Bo Yan</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenchuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Junping Du</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chuan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WWW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14283" title="Abstract">arXiv:2310.14283</a> (replaced) [<a href="/pdf/2310.14283" title="Download PDF">pdf</a>, <a href="/ps/2310.14283" title="Download PostScript">ps</a>, <a href="/format/2310.14283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bandwidth Efficient Livestreaming in Mobile Wireless Networks: A  Peer-to-Peer ACIDE Solution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Negulescu%2C+A">Andrei Negulescu</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+W">Weijia Shang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 12 figures, 3 tables, This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Performance (cs.PF); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15036" title="Abstract">arXiv:2310.15036</a> (replaced) [<a href="/pdf/2310.15036" title="Download PDF">pdf</a>, <a href="/ps/2310.15036" title="Download PostScript">ps</a>, <a href="/format/2310.15036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UWB Based Static Gesture Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sebastian%2C+A">Abhishek Sebastian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15574" title="Abstract">arXiv:2310.15574</a> (replaced) [<a href="/pdf/2310.15574" title="Download PDF">pdf</a>, <a href="/format/2310.15574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Multi-Target Localization Via Intelligent Reflecting Surface:  Protocol and Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hua%2C+M">Meng Hua</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guangji Chen</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+K">Kaitao Meng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shaodan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yuen%2C+C">Chau Yuen</a>, 
<a href="/search/cs?searchtype=author&query=So%2C+H+C">Hing Cheung So</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been submitted to IEEE journal for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15745" title="Abstract">arXiv:2310.15745</a> (replaced) [<a href="/pdf/2310.15745" title="Download PDF">pdf</a>, <a href="/format/2310.15745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Battery-Less Energy Harvesting Devices in Multi-hop  Industrial Wireless Sensor Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+Leemput%2C+D">Dries Van Leemput</a>, 
<a href="/search/cs?searchtype=author&query=Hoebeke%2C+J">Jeroen Hoebeke</a>, 
<a href="/search/cs?searchtype=author&query=De+Poorter%2C+E">Eli De Poorter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> \copyright 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17273" title="Abstract">arXiv:2310.17273</a> (replaced) [<a href="/pdf/2310.17273" title="Download PDF">pdf</a>, <a href="/format/2310.17273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Looping in the Human Collaborative and Explainable Bayesian Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adachi%2C+M">Masaki Adachi</a>, 
<a href="/search/cs?searchtype=author&query=Planden%2C+B">Brady Planden</a>, 
<a href="/search/cs?searchtype=author&query=Howey%2C+D+A">David A. Howey</a>, 
<a href="/search/cs?searchtype=author&query=Osborne%2C+M+A">Michael A. Osborne</a>, 
<a href="/search/cs?searchtype=author&query=Orbell%2C+S">Sebastian Orbell</a>, 
<a href="/search/cs?searchtype=author&query=Ares%2C+N">Natalia Ares</a>, 
<a href="/search/cs?searchtype=author&query=Muandet%2C+K">Krikamol Muandet</a>, 
<a href="/search/cs?searchtype=author&query=Chau%2C+S+L">Siu Lun Chau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AISTATS 2024, 24 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17491" title="Abstract">arXiv:2310.17491</a> (replaced) [<a href="/pdf/2310.17491" title="Download PDF">pdf</a>, <a href="/format/2310.17491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedPEAT: Convergence of Federated Learning, Parameter-Efficient Fine  Tuning, and Emulator Assisted Tuning for Artificial Intelligence Foundation  Models with Mobile Edge Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chua%2C+T+J">Terence Jie Chua</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenhan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+K">Kwok-Yan Lam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19620" title="Abstract">arXiv:2310.19620</a> (replaced) [<a href="/pdf/2310.19620" title="Download PDF">pdf</a>, <a href="/format/2310.19620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Trajectory Models are Scalable Motion Predictors and Planners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qiao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiduo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+D">Danjiao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jingzhe Shi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Derun Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Simian Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+N">Ningyi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+G">Guangzhi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hang Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19670" title="Abstract">arXiv:2310.19670</a> (replaced) [<a href="/pdf/2310.19670" title="Download PDF">pdf</a>, <a href="/format/2310.19670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatiotemporal Attention Enhances Lidar-Based Robot Navigation in  Dynamic Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Heuvel%2C+J">Jorge de Heuvel</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xiangyu Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Weixian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Sethuraman%2C+T">Tharun Sethuraman</a>, 
<a href="/search/cs?searchtype=author&query=Bennewitz%2C+M">Maren Bennewitz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20329" title="Abstract">arXiv:2310.20329</a> (replaced) [<a href="/pdf/2310.20329" title="Download PDF">pdf</a>, <a href="/format/2310.20329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InstructCoder: Instruction Tuning Large Language Models for Code Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kaixin Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qisheng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuxi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tiedong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Qizhe Xie</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junxian He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00656" title="Abstract">arXiv:2311.00656</a> (replaced) [<a href="/pdf/2311.00656" title="Download PDF">pdf</a>, <a href="/format/2311.00656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Signal Estimation on the Graph Edges via Line Graph  Transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yan%2C+Y">Yi Yan</a>, 
<a href="/search/eess?searchtype=author&query=Kuruoglu%2C+E+E">Ercan Engin Kuruoglu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01614" title="Abstract">arXiv:2311.01614</a> (replaced) [<a href="/pdf/2311.01614" title="Download PDF">pdf</a>, <a href="/format/2311.01614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alleviating the Curse of Dimensionality in Minkowski Sum Approximations  of Storage Flexibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=%C3%96zt%C3%BCrk%2C+E">Emrah &#xd6;zt&#xfc;rk</a>, 
<a href="/search/math?searchtype=author&query=Faulwasser%2C+T">Timm Faulwasser</a>, 
<a href="/search/math?searchtype=author&query=Worthmann%2C+K">Karl Worthmann</a>, 
<a href="/search/math?searchtype=author&query=Prei%C3%9Finger%2C+M">Markus Prei&#xdf;inger</a>, 
<a href="/search/math?searchtype=author&query=Rheinberger%2C+K">Klaus Rheinberger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06906" title="Abstract">arXiv:2311.06906</a> (replaced) [<a href="/pdf/2311.06906" title="Download PDF">pdf</a>, <a href="/ps/2311.06906" title="Download PostScript">ps</a>, <a href="/format/2311.06906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Particle-based algorithm for stochastic optimal control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Reich%2C+S">Sebastian Reich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07237" title="Abstract">arXiv:2311.07237</a> (replaced) [<a href="/pdf/2311.07237" title="Download PDF">pdf</a>, <a href="/format/2311.07237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In Search of the Long-Tail: Systematic Generation of Long-Tail  Inferential Knowledge via Logical Rule Guided Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huihan Li</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+Y">Yuting Ning</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Z">Zeyi Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X+L">Xiang Lorraine Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Ximing Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenting Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Brahman%2C+F">Faeze Brahman</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiang Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08385" title="Abstract">arXiv:2311.08385</a> (replaced) [<a href="/pdf/2311.08385" title="Download PDF">pdf</a>, <a href="/format/2311.08385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChOiRe: Characterizing and Predicting Human Opinions with Chain of  Opinion Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Do%2C+X+L">Xuan Long Do</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+K">Kenji Kawaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Kan%2C+M">Min-Yen Kan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N+F">Nancy F. Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09015" title="Abstract">arXiv:2311.09015</a> (replaced) [<a href="/pdf/2311.09015" title="Download PDF">pdf</a>, <a href="/format/2311.09015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identification and Estimation for Nonignorable Missing Data: A Data  Fusion Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wang%2C+Z">Zixiao Wang</a>, 
<a href="/search/stat?searchtype=author&query=Ghassami%2C+A">AmirEmad Ghassami</a>, 
<a href="/search/stat?searchtype=author&query=Shpitser%2C+I">Ilya Shpitser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09154" title="Abstract">arXiv:2311.09154</a> (replaced) [<a href="/pdf/2311.09154" title="Download PDF">pdf</a>, <a href="/format/2311.09154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLEAN-EVAL: Clean Evaluation on Contaminated Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenhong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+H">Hongkun Hao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhiwei He</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yunze Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yumeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hanxu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yiran Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hongyuan Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09693" title="Abstract">arXiv:2311.09693</a> (replaced) [<a href="/pdf/2311.09693" title="Download PDF">pdf</a>, <a href="/format/2311.09693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BLT: Can Large Language Models Handle Basic Legal Text?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blair-Stanek%2C+A">Andrew Blair-Stanek</a>, 
<a href="/search/cs?searchtype=author&query=Holzenberger%2C+N">Nils Holzenberger</a>, 
<a href="/search/cs?searchtype=author&query=Van+Durme%2C+B">Benjamin Van Durme</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10593" title="Abstract">arXiv:2311.10593</a> (replaced) [<a href="/pdf/2311.10593" title="Download PDF">pdf</a>, <a href="/ps/2311.10593" title="Download PostScript">ps</a>, <a href="/format/2311.10593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generation and New Infinite Families of $K_2$-hypohamiltonian Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Goedgebeur%2C+J">Jan Goedgebeur</a>, 
<a href="/search/math?searchtype=author&query=Renders%2C+J">Jarne Renders</a>, 
<a href="/search/math?searchtype=author&query=Zamfirescu%2C+C+T">Carol T. Zamfirescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10845" title="Abstract">arXiv:2311.10845</a> (replaced) [<a href="/pdf/2311.10845" title="Download PDF">pdf</a>, <a href="/format/2311.10845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Generalization of 3D Object Detection by Density-Resampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuangzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingyu Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11890" title="Abstract">arXiv:2311.11890</a> (replaced) [<a href="/pdf/2311.11890" title="Download PDF">pdf</a>, <a href="/ps/2311.11890" title="Download PostScript">ps</a>, <a href="/format/2311.11890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Modular Approach to Unclonable Cryptography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ananth%2C+P">Prabhanjan Ananth</a>, 
<a href="/search/cs?searchtype=author&query=Behera%2C+A">Amit Behera</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added a direct construction of Unclonable encryption for bits from UPO, and added a construction of generalized UPO from QSIO and private-key unclonable encryption with a leakage-resilient security assumption
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13127" title="Abstract">arXiv:2311.13127</a> (replaced) [<a href="/pdf/2311.13127" title="Download PDF">pdf</a>, <a href="/format/2311.13127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Robust Imperceptible Perturbation against Unauthorized  Text-to-image Diffusion-based Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yixin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chenrui Fan</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yutong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14534" title="Abstract">arXiv:2311.14534</a> (replaced) [<a href="/pdf/2311.14534" title="Download PDF">pdf</a>, <a href="/format/2311.14534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Foundation Models for Time Series Classification with a PreText  Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ismail-Fawaz%2C+A">Ali Ismail-Fawaz</a>, 
<a href="/search/cs?searchtype=author&query=Devanne%2C+M">Maxime Devanne</a>, 
<a href="/search/cs?searchtype=author&query=Berretti%2C+S">Stefano Berretti</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+J">Jonathan Weber</a>, 
<a href="/search/cs?searchtype=author&query=Forestier%2C+G">Germain Forestier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14649" title="Abstract">arXiv:2311.14649</a> (replaced) [<a href="/pdf/2311.14649" title="Download PDF">pdf</a>, <a href="/format/2311.14649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning in Deep Factor Graphs with Gaussian Belief Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nabarro%2C+S">Seth Nabarro</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Wilk%2C+M">Mark van der Wilk</a>, 
<a href="/search/cs?searchtype=author&query=Davison%2C+A+J">Andrew J Davison</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15153" title="Abstract">arXiv:2311.15153</a> (replaced) [<a href="/pdf/2311.15153" title="Download PDF">pdf</a>, <a href="/format/2311.15153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Self-Supervised Learning for SAR ATR: A Knowledge-Guided  Predictive Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weijie Li</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianpeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yuenan Hou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yongxiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Li Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our codes at <a href="https://github.com/waterdisappear/SAR-KPGA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16503" title="Abstract">arXiv:2311.16503</a> (replaced) [<a href="/pdf/2311.16503" title="Download PDF">pdf</a>, <a href="/format/2311.16503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TFMQ-DM: Temporal Feature Maintenance Quantization for Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yushi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+R">Ruihao Gong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianlong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianglong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17119" title="Abstract">arXiv:2311.17119</a> (replaced) [<a href="/pdf/2311.17119" title="Download PDF">pdf</a>, <a href="/format/2311.17119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous Pose for Monocular Cameras in Neural Implicit Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Paudel%2C+D+P">Danda Pani Paudel</a>, 
<a href="/search/cs?searchtype=author&query=Chhatkuli%2C+A">Ajad Chhatkuli</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01661" title="Abstract">arXiv:2312.01661</a> (replaced) [<a href="/pdf/2312.01661" title="Download PDF">pdf</a>, <a href="/format/2312.01661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT as a Math Questioner? Evaluating ChatGPT on Generating  Pre-university Math Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+Long%2C+P+P">Phuoc Pham Van Long</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+D+A">Duc Anh Vu</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+N+M">Nhat M. Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+X+L">Xuan Long Do</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+A+T">Anh Tuan Luu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 39th ACM/SIGAPP Symposium On Applied Computing (SAC 2024), Main Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02614" title="Abstract">arXiv:2312.02614</a> (replaced) [<a href="/pdf/2312.02614" title="Download PDF">pdf</a>, <a href="/format/2312.02614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Optimization via Adversarial In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Do%2C+X+L">Xuan Long Do</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yiran Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+H">Hannah Brown</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuxi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J+X">James Xu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N+F">Nancy F. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+K">Kenji Kawaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+M+Q">Michael Qizhe Xie</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junxian He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02959" title="Abstract">arXiv:2312.02959</a> (replaced) [<a href="/pdf/2312.02959" title="Download PDF">pdf</a>, <a href="/format/2312.02959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting algorithmic bias in medical AI-models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Smith%2C+J">Jeffrey Smith</a>, 
<a href="/search/stat?searchtype=author&query=Holder%2C+A">Andre Holder</a>, 
<a href="/search/stat?searchtype=author&query=Kamaleswaran%2C+R">Rishikesan Kamaleswaran</a>, 
<a href="/search/stat?searchtype=author&query=Xie%2C+Y">Yao Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03102" title="Abstract">arXiv:2312.03102</a> (replaced) [<a href="/pdf/2312.03102" title="Download PDF">pdf</a>, <a href="/ps/2312.03102" title="Download PostScript">ps</a>, <a href="/format/2312.03102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully Convolutional Slice-to-Volume Reconstruction for Single-Stack MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Young%2C+S+I">Sean I. Young</a>, 
<a href="/search/eess?searchtype=author&query=Balbastre%2C+Y">Ya&#xeb;l Balbastre</a>, 
<a href="/search/eess?searchtype=author&query=Fischl%2C+B">Bruce Fischl</a>, 
<a href="/search/eess?searchtype=author&query=Golland%2C+P">Polina Golland</a>, 
<a href="/search/eess?searchtype=author&query=Iglesias%2C+J+E">Juan Eugenio Iglesias</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05440" title="Abstract">arXiv:2312.05440</a> (replaced) [<a href="/pdf/2312.05440" title="Download PDF">pdf</a>, <a href="/format/2312.05440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consistency Models for Scalable and Fast Simulation-Based Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmitt%2C+M">Marvin Schmitt</a>, 
<a href="/search/cs?searchtype=author&query=Pratz%2C+V">Valentin Pratz</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6the%2C+U">Ullrich K&#xf6;the</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%BCrkner%2C+P">Paul-Christian B&#xfc;rkner</a>, 
<a href="/search/cs?searchtype=author&query=Radev%2C+S+T">Stefan T Radev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07871" title="Abstract">arXiv:2312.07871</a> (replaced) [<a href="/pdf/2312.07871" title="Download PDF">pdf</a>, <a href="/format/2312.07871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MLNet: Mutual Learning Network with Neighborhood Invariance for  Universal Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yanzuo Lu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+M">Meng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+A+J">Andy J Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaohua Xie</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+J">Jian-Huang Lai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024 (Poster)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09554" title="Abstract">arXiv:2312.09554</a> (replaced) [<a href="/pdf/2312.09554" title="Download PDF">pdf</a>, <a href="/format/2312.09554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embodied Adversarial Attack: A Dynamic Robust Physical Attack in  Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yitong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xingxing Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09558" title="Abstract">arXiv:2312.09558</a> (replaced) [<a href="/pdf/2312.09558" title="Download PDF">pdf</a>, <a href="/format/2312.09558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Transferable Targeted 3D Adversarial Attack in the Physical  World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yinpeng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+S">Shouwei Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hang Su</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xingxing Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10126" title="Abstract">arXiv:2312.10126</a> (replaced) [<a href="/pdf/2312.10126" title="Download PDF">pdf</a>, <a href="/format/2312.10126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do Text Simplification Systems Preserve Meaning? A Human Evaluation via  Reading Comprehension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+S">Sweta Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Carpuat%2C+M">Marine Carpuat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at TACL (a pre-MIT Press publication version)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10797" title="Abstract">arXiv:2312.10797</a> (replaced) [<a href="/pdf/2312.10797" title="Download PDF">pdf</a>, <a href="/format/2312.10797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large-Scale Multi-Robot Coverage Path Planning via Local Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jingtao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Hang Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10893" title="Abstract">arXiv:2312.10893</a> (replaced) [<a href="/pdf/2312.10893" title="Download PDF">pdf</a>, <a href="/format/2312.10893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Metacognitive Demands and Opportunities of Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tankelevitch%2C+L">Lev Tankelevitch</a>, 
<a href="/search/cs?searchtype=author&query=Kewenig%2C+V">Viktor Kewenig</a>, 
<a href="/search/cs?searchtype=author&query=Simkute%2C+A">Auste Simkute</a>, 
<a href="/search/cs?searchtype=author&query=Scott%2C+A+E">Ava Elizabeth Scott</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+A">Advait Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Sellen%2C+A">Abigail Sellen</a>, 
<a href="/search/cs?searchtype=author&query=Rintel%2C+S">Sean Rintel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11576" title="Abstract">arXiv:2312.11576</a> (replaced) [<a href="/pdf/2312.11576" title="Download PDF">pdf</a>, <a href="/ps/2312.11576" title="Download PostScript">ps</a>, <a href="/format/2312.11576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emotion Based Prediction in the Context of Optimized Trajectory Planning  for Immersive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sungheetha%2C+A">Akey Sungheetha</a>, 
<a href="/search/cs?searchtype=author&query=R%2C+R+S">Rajesh Sharma R</a>, 
<a href="/search/cs?searchtype=author&query=R%2C+C">Chinnaiyan R</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11804" title="Abstract">arXiv:2312.11804</a> (replaced) [<a href="/pdf/2312.11804" title="Download PDF">pdf</a>, <a href="/format/2312.11804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gravity-aware Grasp Generation with Implicit Grasp Mode Selection for  Underactuated Hands
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ko%2C+T">Tianyi Ko</a>, 
<a href="/search/cs?searchtype=author&query=Ikeda%2C+T">Takuya Ikeda</a>, 
<a href="/search/cs?searchtype=author&query=Stewart%2C+T">Thomas Stewart</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+R">Robert Lee</a>, 
<a href="/search/cs?searchtype=author&query=Nishiwaki%2C+K">Koichi Nishiwaki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12874" title="Abstract">arXiv:2312.12874</a> (replaced) [<a href="/pdf/2312.12874" title="Download PDF">pdf</a>, <a href="/format/2312.12874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep-Unfolded Joint Activity and Data Detection for Grant-Free  Transmission in Cell-Free Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Gangle Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Studer%2C+C">Christoph Studer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ISWCS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14369" title="Abstract">arXiv:2312.14369</a> (replaced) [<a href="/pdf/2312.14369" title="Download PDF">pdf</a>, <a href="/format/2312.14369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quality-Diversity Generative Sampling for Learning with Synthetic Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+A">Allen Chang</a>, 
<a href="/search/cs?searchtype=author&query=Fontaine%2C+M+C">Matthew C. Fontaine</a>, 
<a href="/search/cs?searchtype=author&query=Booth%2C+S">Serena Booth</a>, 
<a href="/search/cs?searchtype=author&query=Matari%C4%87%2C+M+J">Maja J. Matari&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Nikolaidis%2C+S">Stefanos Nikolaidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024; 7 pages main, 12 pages total, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14388" title="Abstract">arXiv:2312.14388</a> (replaced) [<a href="/pdf/2312.14388" title="Download PDF">pdf</a>, <a href="/format/2312.14388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generalized Shuffle Framework for Privacy Amplification: Strengthening  Privacy Guarantees and Enhancing Utility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">E Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yifei Ge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17267" title="Abstract">arXiv:2312.17267</a> (replaced) [<a href="/pdf/2312.17267" title="Download PDF">pdf</a>, <a href="/format/2312.17267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Low-resource Prompt-based Relation Representation with  Multi-view Decoupling Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chenghao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+X">Xiaoye Qu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhenyi Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Wenfeng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dangyang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02982" title="Abstract">arXiv:2401.02982</a> (replaced) [<a href="/pdf/2401.02982" title="Download PDF">pdf</a>, <a href="/format/2401.02982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BIBench: Benchmarking Data Analysis Knowledge of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shangqing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+C">Chenghao Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+X">Xinlin Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+Z">Zhaoguang Long</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+M">Man Lan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingquan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chong Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03748" title="Abstract">arXiv:2401.03748</a> (replaced) [<a href="/pdf/2401.03748" title="Download PDF">pdf</a>, <a href="/format/2401.03748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Efficient Communication and Secure Federated Recommendation  System via Low-rank Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+N">Ngoc-Hieu Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Tuan-Anh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Tuan Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+V+T">Vu Tien Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+D+D">Dung D. Le</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kok-Seng Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06280" title="Abstract">arXiv:2401.06280</a> (replaced) [<a href="/pdf/2401.06280" title="Download PDF">pdf</a>, <a href="/format/2401.06280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stress-hybrid virtual element method on six-noded triangular meshes for  compressible and nearly-incompressible linear elasticity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+A">Alvin Chen</a>, 
<a href="/search/math?searchtype=author&query=Bishop%2C+J+E">Joseph E. Bishop</a>, 
<a href="/search/math?searchtype=author&query=Sukumar%2C+N">N. Sukumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 49 pages, 49 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08258" title="Abstract">arXiv:2401.08258</a> (replaced) [<a href="/pdf/2401.08258" title="Download PDF">pdf</a>, <a href="/format/2401.08258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time, Simultaneity, and Causality in Wireless Networks with Sensing and  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Popovski%2C+P">Petar Popovski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08876" title="Abstract">arXiv:2401.08876</a> (replaced) [<a href="/pdf/2401.08876" title="Download PDF">pdf</a>, <a href="/format/2401.08876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Utility of Conformal Prediction Sets for AI-Advised Image  Labeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chatzimparmpas%2C+A">Angelos Chatzimparmpas</a>, 
<a href="/search/cs?searchtype=author&query=Kamali%2C+N">Negar Kamali</a>, 
<a href="/search/cs?searchtype=author&query=Hullman%2C+J">Jessica Hullman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 11 figures, 9 tables. Accepted by ACM CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10187" title="Abstract">arXiv:2401.10187</a> (replaced) [<a href="/pdf/2401.10187" title="Download PDF">pdf</a>, <a href="/format/2401.10187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Kronecker Matrix-Matrix Multiplication on GPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jangda%2C+A">Abhinav Jangda</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+M">Mohit Yadav</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at PPoPP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11618" title="Abstract">arXiv:2401.11618</a> (replaced) [<a href="/pdf/2401.11618" title="Download PDF">pdf</a>, <a href="/format/2401.11618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient local linearity regularization to overcome catastrophic  overfitting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rocamora%2C+E+A">Elias Abad Rocamora</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fanghui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chrysos%2C+G+G">Grigorios G. Chrysos</a>, 
<a href="/search/cs?searchtype=author&query=Olmos%2C+P+M">Pablo M. Olmos</a>, 
<a href="/search/cs?searchtype=author&query=Cevher%2C+V">Volkan Cevher</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11824" title="Abstract">arXiv:2401.11824</a> (replaced) [<a href="/pdf/2401.11824" title="Download PDF">pdf</a>, <a href="/format/2401.11824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Centered Kernel Alignment in Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zikai Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yunhang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+S">Shitong Shao</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+L">Linrui Gong</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shaohui Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12258" title="Abstract">arXiv:2401.12258</a> (replaced) [<a href="/pdf/2401.12258" title="Download PDF">pdf</a>, <a href="/format/2401.12258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergent Dominance Hierarchies in Reinforcement Learning Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rachum%2C+R">Ram Rachum</a>, 
<a href="/search/cs?searchtype=author&query=Nakar%2C+Y">Yonatan Nakar</a>, 
<a href="/search/cs?searchtype=author&query=Tomlinson%2C+B">Bill Tomlinson</a>, 
<a href="/search/cs?searchtype=author&query=Alon%2C+N">Nitay Alon</a>, 
<a href="/search/cs?searchtype=author&query=Mirsky%2C+R">Reuth Mirsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13888" title="Abstract">arXiv:2401.13888</a> (replaced) [<a href="/pdf/2401.13888" title="Download PDF">pdf</a>, <a href="/format/2401.13888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Guided Entity-aware Video Captioning and A Basketball  Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xi%2C+Z">Zeyu Xi</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Ge Shi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuefen Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zun Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lifang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zilin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13934" title="Abstract">arXiv:2401.13934</a> (replaced) [<a href="/pdf/2401.13934" title="Download PDF">pdf</a>, <a href="/format/2401.13934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MambaMorph: a Mamba-based Framework for Medical MR-CT Deformable  Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Tao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yinuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+S">Shihao Shu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Diansheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhouping Tang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+C">Cai Meng</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiangzhi Bai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14173" title="Abstract">arXiv:2401.14173</a> (replaced) [<a href="/pdf/2401.14173" title="Download PDF">pdf</a>, <a href="/ps/2401.14173" title="Download PostScript">ps</a>, <a href="/format/2401.14173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multicasting Optical Reconfigurable Switch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Dinc%2C+N+U">Niyazi Ulas Dinc</a>, 
<a href="/search/physics?searchtype=author&query=Yildirim%2C+M">Mustafa Yildirim</a>, 
<a href="/search/physics?searchtype=author&query=Oguz%2C+I">Ilker Oguz</a>, 
<a href="/search/physics?searchtype=author&query=Moser%2C+C">Christophe Moser</a>, 
<a href="/search/physics?searchtype=author&query=Psaltis%2C+D">Demetri Psaltis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 4 figures, article
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15371" title="Abstract">arXiv:2401.15371</a> (replaced) [<a href="/e-print/2401.15371" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LegalDuet: Learning Effective Representations for Legal Judgment  Prediction through a Dual-View Legal Clue Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Pengjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xiaoyuan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liner Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Ge Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuang-hua Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> we will update this paper and revise this paper in the near future
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16725" title="Abstract">arXiv:2401.16725</a> (replaced) [<a href="/pdf/2401.16725" title="Download PDF">pdf</a>, <a href="/format/2401.16725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Equivariance in the Design of Tracking Controllers for  Euler-Poincare Systems on Matrix Lie Groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hampsey%2C+M">Matthew Hampsey</a>, 
<a href="/search/eess?searchtype=author&query=van+Goor%2C+P">Pieter van Goor</a>, 
<a href="/search/eess?searchtype=author&query=Banavar%2C+R">Ravi Banavar</a>, 
<a href="/search/eess?searchtype=author&query=Mahony%2C+R">Robert Mahony</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint for LHMNC2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00206" title="Abstract">arXiv:2402.00206</a> (replaced) [<a href="/pdf/2402.00206" title="Download PDF">pdf</a>, <a href="/ps/2402.00206" title="Download PostScript">ps</a>, <a href="/format/2402.00206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Unified Theory of Time-Varying Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bumpus%2C+B+M">Benjamin Merlin Bumpus</a>, 
<a href="/search/math?searchtype=author&query=Fairbanks%2C+J">James Fairbanks</a>, 
<a href="/search/math?searchtype=author&query=Karvonen%2C+M">Martti Karvonen</a>, 
<a href="/search/math?searchtype=author&query=Leal%2C+W">Wilmer Leal</a>, 
<a href="/search/math?searchtype=author&query=Simard%2C+F">Fr&#xe9;d&#xe9;ric Simard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Acknowledgements and related work added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00466" title="Abstract">arXiv:2402.00466</a> (replaced) [<a href="/pdf/2402.00466" title="Download PDF">pdf</a>, <a href="/format/2402.00466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a GPU-Parallelization of the neXtSIM-DG Dynamical Core
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jendersie%2C+R">Robert Jendersie</a>, 
<a href="/search/cs?searchtype=author&query=Lessig%2C+C">Christian Lessig</a>, 
<a href="/search/cs?searchtype=author&query=Richter%2C+T">Thomas Richter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> revision for PASC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00838" title="Abstract">arXiv:2402.00838</a> (replaced) [<a href="/pdf/2402.00838" title="Download PDF">pdf</a>, <a href="/format/2402.00838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OLMo: Accelerating the Science of Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Groeneveld%2C+D">Dirk Groeneveld</a>, 
<a href="/search/cs?searchtype=author&query=Beltagy%2C+I">Iz Beltagy</a>, 
<a href="/search/cs?searchtype=author&query=Walsh%2C+P">Pete Walsh</a>, 
<a href="/search/cs?searchtype=author&query=Bhagia%2C+A">Akshita Bhagia</a>, 
<a href="/search/cs?searchtype=author&query=Kinney%2C+R">Rodney Kinney</a>, 
<a href="/search/cs?searchtype=author&query=Tafjord%2C+O">Oyvind Tafjord</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+A+H">Ananya Harsh Jha</a>, 
<a href="/search/cs?searchtype=author&query=Ivison%2C+H">Hamish Ivison</a>, 
<a href="/search/cs?searchtype=author&query=Magnusson%2C+I">Ian Magnusson</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yizhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+S">Shane Arora</a>, 
<a href="/search/cs?searchtype=author&query=Atkinson%2C+D">David Atkinson</a>, 
<a href="/search/cs?searchtype=author&query=Authur%2C+R">Russell Authur</a>, 
<a href="/search/cs?searchtype=author&query=Chandu%2C+K+R">Khyathi Raghavi Chandu</a>, 
<a href="/search/cs?searchtype=author&query=Cohan%2C+A">Arman Cohan</a>, 
<a href="/search/cs?searchtype=author&query=Dumas%2C+J">Jennifer Dumas</a>, 
<a href="/search/cs?searchtype=author&query=Elazar%2C+Y">Yanai Elazar</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuling Gu</a>, 
<a href="/search/cs?searchtype=author&query=Hessel%2C+J">Jack Hessel</a>, 
<a href="/search/cs?searchtype=author&query=Khot%2C+T">Tushar Khot</a>, 
<a href="/search/cs?searchtype=author&query=Merrill%2C+W">William Merrill</a>, 
<a href="/search/cs?searchtype=author&query=Morrison%2C+J">Jacob Morrison</a>, 
<a href="/search/cs?searchtype=author&query=Muennighoff%2C+N">Niklas Muennighoff</a>, 
<a href="/search/cs?searchtype=author&query=Naik%2C+A">Aakanksha Naik</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+C">Crystal Nam</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+M+E">Matthew E. Peters</a>, 
<a href="/search/cs?searchtype=author&query=Pyatkin%2C+V">Valentina Pyatkin</a>, 
<a href="/search/cs?searchtype=author&query=Ravichander%2C+A">Abhilasha Ravichander</a>, 
<a href="/search/cs?searchtype=author&query=Schwenk%2C+D">Dustin Schwenk</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+S">Saurabh Shah</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+W">Will Smith</a>, 
<a href="/search/cs?searchtype=author&query=Strubell%2C+E">Emma Strubell</a>, 
<a href="/search/cs?searchtype=author&query=Subramani%2C+N">Nishant Subramani</a>, 
<a href="/search/cs?searchtype=author&query=Wortsman%2C+M">Mitchell Wortsman</a>, 
<a href="/search/cs?searchtype=author&query=Dasigi%2C+P">Pradeep Dasigi</a>, 
<a href="/search/cs?searchtype=author&query=Lambert%2C+N">Nathan Lambert</a>, 
<a href="/search/cs?searchtype=author&query=Richardson%2C+K">Kyle Richardson</a>, 
<a href="/search/cs?searchtype=author&query=Zettlemoyer%2C+L">Luke Zettlemoyer</a>, 
<a href="/search/cs?searchtype=author&query=Dodge%2C+J">Jesse Dodge</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+K">Kyle Lo</a>, 
<a href="/search/cs?searchtype=author&query=Soldaini%2C+L">Luca Soldaini</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+N+A">Noah A. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Hajishirzi%2C+H">Hannaneh Hajishirzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00868" title="Abstract">arXiv:2402.00868</a> (replaced) [<a href="/pdf/2402.00868" title="Download PDF">pdf</a>, <a href="/format/2402.00868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> We&#x27;re Not Using Videos Effectively: An Updated Domain Adaptive Video  Segmentation Baseline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kareer%2C+S">Simar Kareer</a>, 
<a href="/search/cs?searchtype=author&query=Vijaykumar%2C+V">Vivek Vijaykumar</a>, 
<a href="/search/cs?searchtype=author&query=Maheshwari%2C+H">Harsh Maheshwari</a>, 
<a href="/search/cs?searchtype=author&query=Chattopadhyay%2C+P">Prithvijit Chattopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Hoffman%2C+J">Judy Hoffman</a>, 
<a href="/search/cs?searchtype=author&query=Prabhu%2C+V">Viraj Prabhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TMLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.01440" title="Abstract">arXiv:2402.01440</a> (replaced) [<a href="/pdf/2402.01440" title="Download PDF">pdf</a>, <a href="/format/2402.01440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-Shot Learning on Graphs: from Meta-learning to Pre-training and  Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xingtong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zemin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuxia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Zhihao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Bo%2C+J">Jianyuan Bo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hoi%2C+S+C+H">Steven C.H. Hoi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02905" title="Abstract">arXiv:2402.02905</a> (replaced) [<a href="/pdf/2402.02905" title="Download PDF">pdf</a>, <a href="/format/2402.02905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational discretizations of ideal magnetohydrodynamics in smooth  regime using finite element exterior calculus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Carlier%2C+V">Valentin Carlier</a>, 
<a href="/search/math?searchtype=author&query=Campos-Pinto%2C+M">Martin Campos-Pinto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03671" title="Abstract">arXiv:2402.03671</a> (replaced) [<a href="/pdf/2402.03671" title="Download PDF">pdf</a>, <a href="/format/2402.03671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ARGO: An Auto-Tuning Runtime System for Scalable GNN Training on  Multi-Core Processor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yi-Chien Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gobriel%2C+S">Sameh Gobriel</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+N">Nilesh Jain</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+G+K">Gopi Krishna Jha</a>, 
<a href="/search/cs?searchtype=author&query=Prasanna%2C+V">Viktor Prasanna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in IEEE International Parallel and Distributed Processing Symposium (IPDPS) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04830" title="Abstract">arXiv:2402.04830</a> (replaced) [<a href="/pdf/2402.04830" title="Download PDF">pdf</a>, <a href="/format/2402.04830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Closing the Gap Between SGP4 and High-Precision Propagation via  Differentiable Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Acciarini%2C+G">Giacomo Acciarini</a>, 
<a href="/search/cs?searchtype=author&query=Baydin%2C+A+G">At&#x131;l&#x131;m G&#xfc;ne&#x15f; Baydin</a>, 
<a href="/search/cs?searchtype=author&query=Izzo%2C+D">Dario Izzo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Earth and Planetary Astrophysics (astro-ph.EP)

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05119" title="Abstract">arXiv:2402.05119</a> (replaced) [<a href="/pdf/2402.05119" title="Download PDF">pdf</a>, <a href="/format/2402.05119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Closer Look at the Limitations of Instruction Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Sreyan Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Evuru%2C+C+K+R">Chandra Kiran Reddy Evuru</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sonal Kumar</a>, 
<a href="/search/cs?searchtype=author&query=S%2C+R">Ramaneswaran S</a>, 
<a href="/search/cs?searchtype=author&query=Aneja%2C+D">Deepali Aneja</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zeyu Jin</a>, 
<a href="/search/cs?searchtype=author&query=Duraiswami%2C+R">Ramani Duraiswami</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07197" title="Abstract">arXiv:2402.07197</a> (replaced) [<a href="/pdf/2402.07197" title="Download PDF">pdf</a>, <a href="/format/2402.07197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphTranslator: Aligning Graph Model to Large Language Model for  Open-ended Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengmei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mingwei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Shen Fan</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+Y">Yanhu Mo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaoxiao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chuan Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.09662" title="Abstract">arXiv:2402.09662</a> (replaced) [<a href="/pdf/2402.09662" title="Download PDF">pdf</a>, <a href="/format/2402.09662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeoBotsVR: A Robotics Learning Game for Beginners with Hands-on Learning  Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mubarrat%2C+S+T">Syed T. Mubarrat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in Extended Abstracts of the CHI Conference on Human Factors in Computing Systems (CHI EA 2024). 6 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.10193" title="Abstract">arXiv:2402.10193</a> (replaced) [<a href="/pdf/2402.10193" title="Download PDF">pdf</a>, <a href="/format/2402.10193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BitDelta: Your Fine-Tune May Only Be Worth One Bit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">James Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+G">Guangxuan Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kai Li</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+D">Jason D. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Song Han</a>, 
<a href="/search/cs?searchtype=author&query=Dao%2C+T">Tri Dao</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+T">Tianle Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.10228" title="Abstract">arXiv:2402.10228</a> (replaced) [<a href="/pdf/2402.10228" title="Download PDF">pdf</a>, <a href="/format/2402.10228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperAgent: A Simple, Scalable, Efficient and Provable Reinforcement  Learning Framework for Complex Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingru Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiawei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Lei Han</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhi-Quan Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Bridging the theory and practice!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.10240" title="Abstract">arXiv:2402.10240</a> (replaced) [<a href="/pdf/2402.10240" title="Download PDF">pdf</a>, <a href="/format/2402.10240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Dynamical View of the Question of Why
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fatemi%2C+M">Mehdi Fatemi</a>, 
<a href="/search/cs?searchtype=author&query=Gowda%2C+S">Sindhu Gowda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the Twelfth International Conference on Learning Representations (ICLR'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.10693" title="Abstract">arXiv:2402.10693</a> (replaced) [<a href="/pdf/2402.10693" title="Download PDF">pdf</a>, <a href="/format/2402.10693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Precision and Recall to assess the quality and diversity of  LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bronnec%2C+F+L">Florian Le Bronnec</a>, 
<a href="/search/cs?searchtype=author&query=Verine%2C+A">Alexandre Verine</a>, 
<a href="/search/cs?searchtype=author&query=Negrevergne%2C+B">Benjamin Negrevergne</a>, 
<a href="/search/cs?searchtype=author&query=Chevaleyre%2C+Y">Yann Chevaleyre</a>, 
<a href="/search/cs?searchtype=author&query=Allauzen%2C+A">Alexandre Allauzen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 15 figures, Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.10906" title="Abstract">arXiv:2402.10906</a> (replaced) [<a href="/pdf/2402.10906" title="Download PDF">pdf</a>, <a href="/format/2402.10906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a sharper phase-field method: a hybrid diffuse-semisharp  approach for microstructure evolution problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dobrzanski%2C+J">Jedrzej Dobrzanski</a>, 
<a href="/search/math?searchtype=author&query=Stupkiewicz%2C+S">Stanislaw Stupkiewicz</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Methods in Applied Mechanics and Engineering 423, 116841
  (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11057" title="Abstract">arXiv:2402.11057</a> (replaced) [<a href="/pdf/2402.11057" title="Download PDF">pdf</a>, <a href="/format/2402.11057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are you Struggling? Dataset and Baselines for Struggle Determination in  Assembly Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+S">Shijia Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wray%2C+M">Michael Wray</a>, 
<a href="/search/cs?searchtype=author&query=Sullivan%2C+B">Brian Sullivan</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+Y">Youngkyoon Jang</a>, 
<a href="/search/cs?searchtype=author&query=Ludwig%2C+C">Casimir Ludwig</a>, 
<a href="/search/cs?searchtype=author&query=Gilchrist%2C+I">Iain Gilchrist</a>, 
<a href="/search/cs?searchtype=author&query=Mayol-Cuevas%2C+W">Walterio Mayol-Cuevas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11585" title="Abstract">arXiv:2402.11585</a> (replaced) [<a href="/pdf/2402.11585" title="Download PDF">pdf</a>, <a href="/format/2402.11585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PolypNextLSTM: A lightweight and fast polyp video segmentation network  using ConvNext and ConvLSTM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+D">Debayan Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Reuter%2C+K">Konrad Reuter</a>, 
<a href="/search/cs?searchtype=author&query=Behrendt%2C+F">Finn Behrendt</a>, 
<a href="/search/cs?searchtype=author&query=Maack%2C+L">Lennart Maack</a>, 
<a href="/search/cs?searchtype=author&query=Grube%2C+S">Sarah Grube</a>, 
<a href="/search/cs?searchtype=author&query=Schlaefer%2C+A">Alexander Schlaefer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11894" title="Abstract">arXiv:2402.11894</a> (replaced) [<a href="/pdf/2402.11894" title="Download PDF">pdf</a>, <a href="/format/2402.11894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Have Seen Me Before? Automating Dataset Updates Towards Reliable and  Timely Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ying%2C+J">Jiahao Ying</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yixin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wei Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yizhe Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shuicheng Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11917" title="Abstract">arXiv:2402.11917</a> (replaced) [<a href="/pdf/2402.11917" title="Download PDF">pdf</a>, <a href="/format/2402.11917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Mechanistic Analysis of a Transformer Trained on a Symbolic Multi-Step  Reasoning Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brinkmann%2C+J">Jannik Brinkmann</a>, 
<a href="/search/cs?searchtype=author&query=Sheshadri%2C+A">Abhay Sheshadri</a>, 
<a href="/search/cs?searchtype=author&query=Levoso%2C+V">Victor Levoso</a>, 
<a href="/search/cs?searchtype=author&query=Swoboda%2C+P">Paul Swoboda</a>, 
<a href="/search/cs?searchtype=author&query=Bartelt%2C+C">Christian Bartelt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.12921" title="Abstract">arXiv:2402.12921</a> (replaced) [<a href="/pdf/2402.12921" title="Download PDF">pdf</a>, <a href="/format/2402.12921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Right on Time: Revising Time Series Models by Constraining their  Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kraus%2C+M">Maurice Kraus</a>, 
<a href="/search/cs?searchtype=author&query=Steinmann%2C+D">David Steinmann</a>, 
<a href="/search/cs?searchtype=author&query=W%C3%BCst%2C+A">Antonia W&#xfc;st</a>, 
<a href="/search/cs?searchtype=author&query=Kokozinski%2C+A">Andre Kokozinski</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13250" title="Abstract">arXiv:2402.13250</a> (replaced) [<a href="/pdf/2402.13250" title="Download PDF">pdf</a>, <a href="/format/2402.13250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video ReCap: Recursive Captioning of Hour-Long Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+M">Md Mohaiminul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+N">Ngan Ho</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xitong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Nagarajan%2C+T">Tushar Nagarajan</a>, 
<a href="/search/cs?searchtype=author&query=Torresani%2C+L">Lorenzo Torresani</a>, 
<a href="/search/cs?searchtype=author&query=Bertasius%2C+G">Gedas Bertasius</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13301" title="Abstract">arXiv:2402.13301</a> (replaced) [<a href="/pdf/2402.13301" title="Download PDF">pdf</a>, <a href="/format/2402.13301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure-informed Positional Encoding for Music Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+M">Manvi Agarwal</a> (S2A, IDS), 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Changhong Wang</a> (S2A, IDS), 
<a href="/search/cs?searchtype=author&query=Richard%2C+G">Ga&#xeb;l Richard</a> (S2A, IDS)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP), Apr 2024, Seoul, South Korea
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13573" title="Abstract">arXiv:2402.13573</a> (replaced) [<a href="/pdf/2402.13573" title="Download PDF">pdf</a>, <a href="/format/2402.13573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ToDo: Token Downsampling for Efficient Generation of High-Resolution  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Smith%2C+E">Ethan Smith</a>, 
<a href="/search/cs?searchtype=author&query=Saxena%2C+N">Nayan Saxena</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+A">Aninda Saha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13640" title="Abstract">arXiv:2402.13640</a> (replaced) [<a href="/pdf/2402.13640" title="Download PDF">pdf</a>, <a href="/format/2402.13640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Green AI: A Preliminary Empirical Study on Energy Consumption in DL  Models Across Different Runtime Infrastructures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alizadeh%2C+N">Negar Alizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Castor%2C+F">Fernando Castor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13754" title="Abstract">arXiv:2402.13754</a> (replaced) [<a href="/pdf/2402.13754" title="Download PDF">pdf</a>, <a href="/format/2402.13754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement learning-assisted quantum architecture search for  variational quantum algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Kundu%2C+A">Akash Kundu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> With 154 pages and 46 figures, here lies my PhD thesis. Typos corrected
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14095" title="Abstract">arXiv:2402.14095</a> (replaced) [<a href="/pdf/2402.14095" title="Download PDF">pdf</a>, <a href="/format/2402.14095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot generalization across architectures for visual classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gerritz%2C+E">Evan Gerritz</a>, 
<a href="/search/cs?searchtype=author&query=Dyballa%2C+L">Luciano Dyballa</a>, 
<a href="/search/cs?searchtype=author&query=Zucker%2C+S+W">Steven W. Zucker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a Tiny Paper at ICLR 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14102" title="Abstract">arXiv:2402.14102</a> (replaced) [<a href="/pdf/2402.14102" title="Download PDF">pdf</a>, <a href="/format/2402.14102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning dynamic representations of the functional connectome in  neurobiological networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Dyballa%2C+L">Luciano Dyballa</a>, 
<a href="/search/q-bio?searchtype=author&query=Lang%2C+S">Samuel Lang</a>, 
<a href="/search/q-bio?searchtype=author&query=Haslund-Gourley%2C+A">Alexandra Haslund-Gourley</a>, 
<a href="/search/q-bio?searchtype=author&query=Yemini%2C+E">Eviatar Yemini</a>, 
<a href="/search/q-bio?searchtype=author&query=Zucker%2C+S+W">Steven W. Zucker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICLR 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14485" title="Abstract">arXiv:2402.14485</a> (replaced) [<a href="/pdf/2402.14485" title="Download PDF">pdf</a>, <a href="/format/2402.14485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine-Checked Categorical Diagrammatic Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guillemet%2C+B">Beno&#xee;t Guillemet</a>, 
<a href="/search/cs?searchtype=author&query=Mahboubi%2C+A">Assia Mahboubi</a>, 
<a href="/search/cs?searchtype=author&query=Piquerez%2C+M">Matthieu Piquerez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14658" title="Abstract">arXiv:2402.14658</a> (replaced) [<a href="/pdf/2402.14658" title="Download PDF">pdf</a>, <a href="/format/2402.14658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenCodeInterpreter: Integrating Code Generation with Execution and  Refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tianyu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Ge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+T">Tianhao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xueling Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B+Y">Bill Yuchen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenhu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+X">Xiang Yue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14798" title="Abstract">arXiv:2402.14798</a> (replaced) [<a href="/pdf/2402.14798" title="Download PDF">pdf</a>, <a href="/format/2402.14798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Systematic Decompositional Natural Language Inference Using  Informal Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weir%2C+N">Nathaniel Weir</a>, 
<a href="/search/cs?searchtype=author&query=Sanders%2C+K">Kate Sanders</a>, 
<a href="/search/cs?searchtype=author&query=Weller%2C+O">Orion Weller</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S">Shreya Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Dongwei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhengping Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+B+D">Bhavana Dalvi Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Tafjord%2C+O">Oyvind Tafjord</a>, 
<a href="/search/cs?searchtype=author&query=Jansen%2C+P">Peter Jansen</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+P">Peter Clark</a>, 
<a href="/search/cs?searchtype=author&query=Van+Durme%2C+B">Benjamin Van Durme</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14968" title="Abstract">arXiv:2402.14968</a> (replaced) [<a href="/pdf/2402.14968" title="Download PDF">pdf</a>, <a href="/format/2402.14968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Fine-tuning Jailbreak Attack with Backdoor Enhanced Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiongxiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiazhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiquan Li</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xiangyu Qi</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Junjie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yixuan Li</a>, 
<a href="/search/cs?searchtype=author&query=McDaniel%2C+P">Patrick McDaniel</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Muhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chaowei Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15027" title="Abstract">arXiv:2402.15027</a> (replaced) [<a href="/pdf/2402.15027" title="Download PDF">pdf</a>, <a href="/ps/2402.15027" title="Download PostScript">ps</a>, <a href="/format/2402.15027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-stakeholder Perspective on Responsible Artificial Intelligence and  Acceptability in Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karran%2C+A+J">A.J. Karran</a>, 
<a href="/search/cs?searchtype=author&query=Charland%2C+P">P. Charland</a>, 
<a href="/search/cs?searchtype=author&query=Martineau%2C+J">J-T. Martineau</a>, 
<a href="/search/cs?searchtype=author&query=de+Guinea+Lopez+de+Arana%2C+A+O">A. Ortiz de Guinea Lopez de Arana</a>, 
<a href="/search/cs?searchtype=author&query=Lesage%2C+A">AM. Lesage</a>, 
<a href="/search/cs?searchtype=author&query=Senecal%2C+S">S. Senecal</a>, 
<a href="/search/cs?searchtype=author&query=Leger%2C+P">P-M. Leger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 2 appendices, 3 figures, 5 tables, original research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15160" title="Abstract">arXiv:2402.15160</a> (replaced) [<a href="/pdf/2402.15160" title="Download PDF">pdf</a>, <a href="/format/2402.15160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatially-Aware Transformer Memory for Embodied Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+J">Junmo Cho</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J">Jaesik Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+S">Sungjin Ahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024 Spotlight. First two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15179" title="Abstract">arXiv:2402.15179</a> (replaced) [<a href="/pdf/2402.15179" title="Download PDF">pdf</a>, <a href="/format/2402.15179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Parameter Efficiency in Fine-tuning via Representation Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Muling Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaohua Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianlong Li</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+C">Changze Lv</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+Z">Zixuan Ling</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jianhao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cenyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiaoqing Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15194" title="Abstract">arXiv:2402.15194</a> (replaced) [<a href="/pdf/2402.15194" title="Download PDF">pdf</a>, <a href="/format/2402.15194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Tuning of Continuous-Time Diffusion Models as Entropy-Regularized  Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uehara%2C+M">Masatoshi Uehara</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yulai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Black%2C+K">Kevin Black</a>, 
<a href="/search/cs?searchtype=author&query=Hajiramezanali%2C+E">Ehsan Hajiramezanali</a>, 
<a href="/search/cs?searchtype=author&query=Scalia%2C+G">Gabriele Scalia</a>, 
<a href="/search/cs?searchtype=author&query=Diamant%2C+N+L">Nathaniel Lee Diamant</a>, 
<a href="/search/cs?searchtype=author&query=Tseng%2C+A+M">Alex M Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Biancalani%2C+T">Tommaso Biancalani</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review (codes will be released soon)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15276" title="Abstract">arXiv:2402.15276</a> (replaced) [<a href="/pdf/2402.15276" title="Download PDF">pdf</a>, <a href="/format/2402.15276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text2Pic Swift: Enhancing Long-Text to Image Retrieval for Large-Scale  Libraries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+Z">Zijun Long</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+X">Xuri Ge</a>, 
<a href="/search/cs?searchtype=author&query=Mccreadie%2C+R">Richard Mccreadie</a>, 
<a href="/search/cs?searchtype=author&query=Jose%2C+J">Joemon Jose</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15490" title="Abstract">arXiv:2402.15490</a> (replaced) [<a href="/pdf/2402.15490" title="Download PDF">pdf</a>, <a href="/format/2402.15490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Survey of Convolutions in Deep Learning: Applications,  Challenges, and Future Trends
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Younesi%2C+A">Abolfazl Younesi</a>, 
<a href="/search/cs?searchtype=author&query=Ansari%2C+M">Mohsen Ansari</a>, 
<a href="/search/cs?searchtype=author&query=Fazli%2C+M">MohammadAmin Fazli</a>, 
<a href="/search/cs?searchtype=author&query=Ejlali%2C+A">Alireza Ejlali</a>, 
<a href="/search/cs?searchtype=author&query=Shafique%2C+M">Muhammad Shafique</a>, 
<a href="/search/cs?searchtype=author&query=Henkel%2C+J">J&#xf6;rg Henkel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15514" title="Abstract">arXiv:2402.15514</a> (replaced) [<a href="/pdf/2402.15514" title="Download PDF">pdf</a>, <a href="/ps/2402.15514" title="Download PostScript">ps</a>, <a href="/format/2402.15514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Scale Generative AI Text Applied to Sports and Music
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baughman%2C+A">Aaron Baughman</a>, 
<a href="/search/cs?searchtype=author&query=Hammer%2C+S">Stephen Hammer</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+R">Rahul Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Akay%2C+G">Gozde Akay</a>, 
<a href="/search/cs?searchtype=author&query=Morales%2C+E">Eduardo Morales</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+T">Tony Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Karlinsky%2C+L">Leonid Karlinsky</a>, 
<a href="/search/cs?searchtype=author&query=Feris%2C+R">Rogerio Feris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15808" title="Abstract">arXiv:2402.15808</a> (replaced) [<a href="/pdf/2402.15808" title="Download PDF">pdf</a>, <a href="/format/2402.15808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Zero-Shot Detector for Multi-Armed Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Granese%2C+F">Federica Granese</a>, 
<a href="/search/cs?searchtype=author&query=Romanelli%2C+M">Marco Romanelli</a>, 
<a href="/search/cs?searchtype=author&query=Piantanida%2C+P">Pablo Piantanida</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to appear in the 27th International Conference on Artificial Intelligence and Statistics (AISTATS), May 2nd - May 4th, 2024 This article supersedes <a href="/abs/2302.02216">arXiv:2302.02216</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15838" title="Abstract">arXiv:2402.15838</a> (replaced) [<a href="/pdf/2402.15838" title="Download PDF">pdf</a>, <a href="/format/2402.15838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ListT5: Listwise Reranking with Fusion-in-Decoder Improves Zero-shot  Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Soyoung Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+E">Eunbi Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jiyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yireun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+H">Hyeongu Yun</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S">Seung-won Hwang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15861" title="Abstract">arXiv:2402.15861</a> (replaced) [<a href="/pdf/2402.15861" title="Download PDF">pdf</a>, <a href="/format/2402.15861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MATHWELL: Generating Educational Math Word Problems at Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Christ%2C+B+R">Bryan R Christ</a>, 
<a href="/search/cs?searchtype=author&query=Kropko%2C+J">Jonathan Kropko</a>, 
<a href="/search/cs?searchtype=author&query=Hartvigsen%2C+T">Thomas Hartvigsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15945" title="Abstract">arXiv:2402.15945</a> (replaced) [<a href="/pdf/2402.15945" title="Download PDF">pdf</a>, <a href="/ps/2402.15945" title="Download PostScript">ps</a>, <a href="/format/2402.15945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-GAN for Anomaly Detection: A Cutting-Edge Approach to  Cybersecurity Threat Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sen%2C+M+A">Mohammed Abo Sen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15990" title="Abstract">arXiv:2402.15990</a> (replaced) [<a href="/pdf/2402.15990" title="Download PDF">pdf</a>, <a href="/format/2402.15990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study of Challenges in Machine Learning Asset Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhimin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yihao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bangash%2C+A+A">Abdul Ali Bangash</a>, 
<a href="/search/cs?searchtype=author&query=Adams%2C+B">Bram Adams</a>, 
<a href="/search/cs?searchtype=author&query=Hassan%2C+A+E">Ahmed E. Hassan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16261" title="Abstract">arXiv:2402.16261</a> (replaced) [<a href="/pdf/2402.16261" title="Download PDF">pdf</a>, <a href="/format/2402.16261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniRetriever: Multi-task Candidates Selection for Various  Context-Adaptive Conversational Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongru Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+B">Boyang Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Baohang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+F">Fei Mi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weichao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yasheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kam-Fai Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16278" title="Abstract">arXiv:2402.16278</a> (replaced) [<a href="/pdf/2402.16278" title="Download PDF">pdf</a>, <a href="/format/2402.16278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Self-matching Training Method with Annotation Embedding Models for  Ontology Subsumption Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shiraishi%2C+Y">Yukihiro Shiraishi</a>, 
<a href="/search/cs?searchtype=author&query=Kaneiwa%2C+K">Ken Kaneiwa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16280" title="Abstract">arXiv:2402.16280</a> (replaced) [<a href="/pdf/2402.16280" title="Download PDF">pdf</a>, <a href="/format/2402.16280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-Shot Learning for Annotation-Efficient Nucleus Instance Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ming%2C+Y">Yu Ming</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zihao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Danyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Changxin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+G">Gui-Song Xia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanqing Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+L">Li Liang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jin-Gang Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16328" title="Abstract">arXiv:2402.16328</a> (replaced) [<a href="/pdf/2402.16328" title="Download PDF">pdf</a>, <a href="/format/2402.16328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Joint Communication and Computation Design for Probabilistic Semantic  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhouxiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhaohui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingzhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16363" title="Abstract">arXiv:2402.16363</a> (replaced) [<a href="/pdf/2402.16363" title="Download PDF">pdf</a>, <a href="/format/2402.16363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM Inference Unveiled: Survey and Roofline Model Insights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhihang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+Y">Yuzhang Shang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+C">Chenhao Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bingzhe Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhikai Li</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Qingyi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y+J">Yong Jae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Beidi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Guangyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Keutzer%2C+K">Kurt Keutzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16505" title="Abstract">arXiv:2402.16505</a> (replaced) [<a href="/pdf/2402.16505" title="Download PDF">pdf</a>, <a href="/format/2402.16505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory GAPS: Would LLMs pass the Tulving Test?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chauvet%2C+J">Jean-Marie Chauvet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16541" title="Abstract">arXiv:2402.16541</a> (replaced) [<a href="/pdf/2402.16541" title="Download PDF">pdf</a>, <a href="/format/2402.16541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integer Programming Using A Single Atom
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Goswami%2C+K">Kapil Goswami</a>, 
<a href="/search/quant-ph?searchtype=author&query=Schmelcher%2C+P">Peter Schmelcher</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mukherjee%2C+R">Rick Mukherjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Optimization and Control (math.OC); Atomic Physics (physics.atom-ph)

</div>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16567" title="Abstract">arXiv:2402.16567</a> (replaced) [<a href="/pdf/2402.16567" title="Download PDF">pdf</a>, <a href="/format/2402.16567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aligning Large Language Models to a Domain-specific Graph Database
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuanyuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+K">Keren Tan</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+T">Tingyu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+W">Wenbiao Tao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yunshi Lan</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+W">Weining Qian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages,2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16598" title="Abstract">arXiv:2402.16598</a> (replaced) [<a href="/pdf/2402.16598" title="Download PDF">pdf</a>, <a href="/format/2402.16598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PCR-99: A Practical Method for Point Cloud Registration with 99%  Outliers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S+H">Seong Hun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Civera%2C+J">Javier Civera</a>, 
<a href="/search/cs?searchtype=author&query=Vandewalle%2C+P">Patrick Vandewalle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16629" title="Abstract">arXiv:2402.16629</a> (replaced) [<a href="/pdf/2402.16629" title="Download PDF">pdf</a>, <a href="/format/2402.16629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SLIPT in Joint Dimming Multi-LED OWC Systems with Rate Splitting  Multiple Access
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Javadi%2C+S">Sepideh Javadi</a>, 
<a href="/search/cs?searchtype=author&query=Faramarzi%2C+S">Sajad Faramarzi</a>, 
<a href="/search/cs?searchtype=author&query=Zeinali%2C+F">Farshad Zeinali</a>, 
<a href="/search/cs?searchtype=author&query=Zarini%2C+H">Hosein Zarini</a>, 
<a href="/search/cs?searchtype=author&query=Mili%2C+M+R">Mohammad Robat Mili</a>, 
<a href="/search/cs?searchtype=author&query=Diamantoulakis%2C+P+D">Panagiotis D. Diamantoulakis</a>, 
<a href="/search/cs?searchtype=author&query=Jorswieck%2C+E">Eduard Jorswieck</a>, 
<a href="/search/cs?searchtype=author&query=Karagiannidis%2C+G+K">George K. Karagiannidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16643" title="Abstract">arXiv:2402.16643</a> (replaced) [<a href="/pdf/2402.16643" title="Download PDF">pdf</a>, <a href="/format/2402.16643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-projective two-weight codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kurz%2C+S">Sascha Kurz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 14 tables, appendix on parameters of projective two-weight codes added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16671" title="Abstract">arXiv:2402.16671</a> (replaced) [<a href="/pdf/2402.16671" title="Download PDF">pdf</a>, <a href="/format/2402.16671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StructLM: Towards Building Generalist Models for Structured Knowledge  Grounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+A">Alex Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Ge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tianyu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xinrun Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+W">Weiming Ren</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S+W">Stephen W. Huang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+X">Xiang Yue</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenhu Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16696" title="Abstract">arXiv:2402.16696</a> (replaced) [<a href="/pdf/2402.16696" title="Download PDF">pdf</a>, <a href="/format/2402.16696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Look Before You Leap: Towards Decision-Aware and Generalizable  Tool-Usage for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gui%2C+A">Anchun Gui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jian Li</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+N">Nan Du</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+H">Han Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16847" title="Abstract">arXiv:2402.16847</a> (replaced) [<a href="/e-print/2402.16847" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Art of Staying Ahead of Deadlines: Improved Algorithms for the  Minimum Tardy Processing Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stoian%2C+M">Mihail Stoian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The runtime analysis is incorrect: the contribution of the processing times in [d_j - p_j, d_{j - 1}] is not taken into account. We thank N. Fischer for pointing this out
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16897" title="Abstract">arXiv:2402.16897</a> (replaced) [<a href="/pdf/2402.16897" title="Download PDF">pdf</a>, <a href="/format/2402.16897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reliable Conflictive Multi-View Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Cai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+J">Jiajun Si</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Z">Ziyu Guan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiyue Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages and to be appeared in AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16972" title="Abstract">arXiv:2402.16972</a> (replaced) [<a href="/pdf/2402.16972" title="Download PDF">pdf</a>, <a href="/ps/2402.16972" title="Download PostScript">ps</a>, <a href="/format/2402.16972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Mechanisms for Consumer Surplus Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ezra%2C+T">Tomer Ezra</a>, 
<a href="/search/cs?searchtype=author&query=Schoepflin%2C+D">Daniel Schoepflin</a>, 
<a href="/search/cs?searchtype=author&query=Shaulker%2C+A">Ariel Shaulker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16977" title="Abstract">arXiv:2402.16977</a> (replaced) [<a href="/pdf/2402.16977" title="Download PDF">pdf</a>, <a href="/format/2402.16977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dealing with Data for RE: Mitigating Challenges while using NLP and  Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghaisas%2C+S">Smita Ghaisas</a>, 
<a href="/search/cs?searchtype=author&query=Singhal%2C+A">Anmol Singhal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 2 figures, to be published in NLP for Requirements Engineering Book
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17015" title="Abstract">arXiv:2402.17015</a> (replaced) [<a href="/pdf/2402.17015" title="Download PDF">pdf</a>, <a href="/format/2402.17015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tree-Verifiable Graph Grammars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chimes%2C+M">Mark Chimes</a>, 
<a href="/search/cs?searchtype=author&query=Iosif%2C+R">Radu Iosif</a>, 
<a href="/search/cs?searchtype=author&query=Zuleger%2C+F">Florian Zuleger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17039" title="Abstract">arXiv:2402.17039</a> (replaced) [<a href="/pdf/2402.17039" title="Download PDF">pdf</a>, <a href="/format/2402.17039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incorporating climate change effects into the European power system  adequacy assessment using a post-processing method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Harang%2C+I">In&#xe8;s Harang</a>, 
<a href="/search/physics?searchtype=author&query=Heymann%2C+F">Fabian Heymann</a>, 
<a href="/search/physics?searchtype=author&query=Stoop%2C+L+P">Laurens P. Stoop</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SEGAN, 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Computers and Society (cs.CY); Applied Physics (physics.app-ph)

</div>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17113" title="Abstract">arXiv:2402.17113</a> (replaced) [<a href="/pdf/2402.17113" title="Download PDF">pdf</a>, <a href="/format/2402.17113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transparent Image Layer Diffusion using Latent Transparency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lvmin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Agrawala%2C+M">Maneesh Agrawala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 37 figures, github.com/layerdiffusion/LayerDiffusion
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17128" title="Abstract">arXiv:2402.17128</a> (replaced) [<a href="/pdf/2402.17128" title="Download PDF">pdf</a>, <a href="/format/2402.17128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OSCaR: Object State Captioning and State Change Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+N">Nguyen Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+J">Jing Bi</a>, 
<a href="/search/cs?searchtype=author&query=Vosoughi%2C+A">Ali Vosoughi</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yapeng Tian</a>, 
<a href="/search/cs?searchtype=author&query=Fazli%2C+P">Pooyan Fazli</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenliang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17177" title="Abstract">arXiv:2402.17177</a> (replaced) [<a href="/pdf/2402.17177" title="Download PDF">pdf</a>, <a href="/format/2402.17177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sora: A Review on Background, Technology, Limitations, and Opportunities  of Large Vision Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yixin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhiling Yan</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chujie Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruoxi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhengqing Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yue Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hanchi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lifang He</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 18 figures; this is not an official report; GitHub: <a href="https://github.com/lichao-sun/SoraReview">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17204" title="Abstract">arXiv:2402.17204</a> (replaced) [<a href="/pdf/2402.17204" title="Download PDF">pdf</a>, <a href="/format/2402.17204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Generative Model Evaluation: A Novel Algorithm for Realistic  Image Synthesis and Comparison in OCR System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Memari%2C+M">Majid Memari</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+K+R">Khaled R. Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Rahimi%2C+S">Shahram Rahimi</a>, 
<a href="/search/cs?searchtype=author&query=Golilarz%2C+N+A">Noorbakhsh Amiri Golilarz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> My manuscript entitled "Advancing Generative Model Evaluation: A Novel Algorithm for Realistic Image Synthesis and Comparison in OCR Systems" has been submitted on 29-Jan-2024 to IEEE Access and is presently being given full consideration for publication in IEEE Access
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17214" title="Abstract">arXiv:2402.17214</a> (replaced) [<a href="/pdf/2402.17214" title="Download PDF">pdf</a>, <a href="/format/2402.17214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CharacterGen: Efficient 3D Character Generation from Single Images with  Multi-View Pose Canonicalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hao-Yang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jia-Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Meng-Hao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yan-Pei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shi-Min Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17242" title="Abstract">arXiv:2402.17242</a> (replaced) [<a href="/pdf/2402.17242" title="Download PDF">pdf</a>, <a href="/format/2402.17242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Community Search with Accuracy Guarantee on Attributed Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+S">Shuzhan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaoliang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+Y">Yuxia Geng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhenghe Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+X">Xiangyu Ke</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianxing Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17273" title="Abstract">arXiv:2402.17273</a> (replaced) [<a href="/pdf/2402.17273" title="Download PDF">pdf</a>, <a href="/format/2402.17273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time tracking of moving objects from scattering matrix in  real-world microwave imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Son%2C+S">Seong-Ho Son</a>, 
<a href="/search/math?searchtype=author&query=Lee%2C+K">Kwang-Jae Lee</a>, 
<a href="/search/math?searchtype=author&query=Park%2C+W">Won-Kwang Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17412" title="Abstract">arXiv:2402.17412</a> (replaced) [<a href="/pdf/2402.17412" title="Download PDF">pdf</a>, <a href="/format/2402.17412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffuseKronA: A Parameter Efficient Fine-tuning Method for Personalized  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marjit%2C+S">Shyam Marjit</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+H">Harshit Singh</a>, 
<a href="/search/cs?searchtype=author&query=Mathur%2C+N">Nityanand Mathur</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+S">Sayak Paul</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chia-Mu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pin-Yu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://diffusekrona.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17424" title="Abstract">arXiv:2402.17424</a> (replaced) [<a href="/pdf/2402.17424" title="Download PDF">pdf</a>, <a href="/ps/2402.17424" title="Download PostScript">ps</a>, <a href="/format/2402.17424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViTaL: An Advanced Framework for Automated Plant Disease Identification  in Leaf Images Using Vision Transformers and Linear Projection For Feature  Reduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sebastian%2C+A">Abhishek Sebastian</a>, 
<a href="/search/cs?searchtype=author&query=A%2C+A+F">Annis Fathima A</a>, 
<a href="/search/cs?searchtype=author&query=R%2C+P">Pragna R</a>, 
<a href="/search/cs?searchtype=author&query=S%2C+M+K">Madhan Kumar S</a>, 
<a href="/search/cs?searchtype=author&query=G%2C+Y+K">Yaswanth Kannan G</a>, 
<a href="/search/cs?searchtype=author&query=Murali%2C+V">Vinay Murali</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and scheduled for presentation at CML 2024, this work will be published as a book chapter in Lecture Notes in Networks and Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17433" title="Abstract">arXiv:2402.17433</a> (replaced) [<a href="/pdf/2402.17433" title="Download PDF">pdf</a>, <a href="/format/2402.17433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing EEG-to-Text Decoding through Transferable Representations from  Pre-trained Contrastive EEG-Text Masked Autoencoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhenxi Song</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhengyu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiguo Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17466" title="Abstract">arXiv:2402.17466</a> (replaced) [<a href="/pdf/2402.17466" title="Download PDF">pdf</a>, <a href="/ps/2402.17466" title="Download PostScript">ps</a>, <a href="/format/2402.17466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Estimation and Control for LTI Systems under Finite-Time  Agreement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fioravanti%2C+C">Camilla Fioravanti</a>, 
<a href="/search/eess?searchtype=author&query=Makridis%2C+E">Evagoras Makridis</a>, 
<a href="/search/eess?searchtype=author&query=Oliva%2C+G">Gabriele Oliva</a>, 
<a href="/search/eess?searchtype=author&query=Vrakopoulou%2C+M">Maria Vrakopoulou</a>, 
<a href="/search/eess?searchtype=author&query=Charalambous%2C+T">Themistoklis Charalambous</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17493" title="Abstract">arXiv:2402.17493</a> (replaced) [<a href="/pdf/2402.17493" title="Download PDF">pdf</a>, <a href="/ps/2402.17493" title="Download PostScript">ps</a>, <a href="/format/2402.17493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prescribing Large Language Models for Perioperative Care: What&#x27;s The  Right Dose for Pre-trained Models?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+B">Bing Xue</a>, 
<a href="/search/cs?searchtype=author&query=Alba%2C+C">Charles Alba</a>, 
<a href="/search/cs?searchtype=author&query=Abraham%2C+J">Joanna Abraham</a>, 
<a href="/search/cs?searchtype=author&query=Kannampallil%2C+T">Thomas Kannampallil</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chenyang Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Supplemental file available at: <a href="http://tinyurl.com/mszmjna9">this http URL</a> models publicly available at: <a href="https://huggingface.co/cja5553/BJH-perioperative-notes-bioGPT">this https URL</a> AND <a href="https://huggingface.co/cja5553/BJH-perioperative-notes-bioGPT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17533" title="Abstract">arXiv:2402.17533</a> (replaced) [<a href="/pdf/2402.17533" title="Download PDF">pdf</a>, <a href="/format/2402.17533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Black-box Adversarial Attacks Against Image Quality Assessment Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ran%2C+Y">Yu Ran</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Ao-Xiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Weixuan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuan-Gen Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17553" title="Abstract">arXiv:2402.17553</a> (replaced) [<a href="/pdf/2402.17553" title="Download PDF">pdf</a>, <a href="/format/2402.17553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist  Autonomous Agents for Desktop and Web
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kapoor%2C+R">Raghav Kapoor</a>, 
<a href="/search/cs?searchtype=author&query=Butala%2C+Y+P">Yash Parag Butala</a>, 
<a href="/search/cs?searchtype=author&query=Russak%2C+M">Melisa Russak</a>, 
<a href="/search/cs?searchtype=author&query=Koh%2C+J+Y">Jing Yu Koh</a>, 
<a href="/search/cs?searchtype=author&query=Kamble%2C+K">Kiran Kamble</a>, 
<a href="/search/cs?searchtype=author&query=Alshikh%2C+W">Waseem Alshikh</a>, 
<a href="/search/cs?searchtype=author&query=Salakhutdinov%2C+R">Ruslan Salakhutdinov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17570" title="Abstract">arXiv:2402.17570</a> (replaced) [<a href="/pdf/2402.17570" title="Download PDF">pdf</a>, <a href="/format/2402.17570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Variational Contaminated Noise Gaussian Process Regression for  Forecasting Geomagnetic Perturbations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Iong%2C+D">Daniel Iong</a>, 
<a href="/search/cs?searchtype=author&query=McAnear%2C+M">Matthew McAnear</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yuezhou Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+S">Shasha Zou</a>, 
<a href="/search/cs?searchtype=author&query=Toth%2C+G">Gabor Toth</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yang Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17593" title="Abstract">arXiv:2402.17593</a> (replaced) [<a href="/pdf/2402.17593" title="Download PDF">pdf</a>, <a href="/format/2402.17593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Shuttle Operation for Vulnerable Populations: Lessons and  Experiences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+R">Ren Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhaofeng Tian</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+J">Jinghui Liao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Weisong Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17599" title="Abstract">arXiv:2402.17599</a> (replaced) [<a href="/pdf/2402.17599" title="Download PDF">pdf</a>, <a href="/format/2402.17599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAGnosis: Localized Identification of Data Inconsistencies using  Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huynh%2C+N">Nicolas Huynh</a>, 
<a href="/search/cs?searchtype=author&query=Berrevoets%2C+J">Jeroen Berrevoets</a>, 
<a href="/search/cs?searchtype=author&query=Seedat%2C+N">Nabeel Seedat</a>, 
<a href="/search/cs?searchtype=author&query=Crabb%C3%A9%2C+J">Jonathan Crabb&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Z">Zhaozhi Qian</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AISTATS 2024; added correspondance email
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17652" title="Abstract">arXiv:2402.17652</a> (replaced) [<a href="/pdf/2402.17652" title="Download PDF">pdf</a>, <a href="/format/2402.17652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compass: A Decentralized Scheduler for Latency-Sensitive ML Workflows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuting Yang</a>, 
<a href="/search/cs?searchtype=author&query=Merlina%2C+A">Andrea Merlina</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+W">Weijia Song</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+T">Tiancheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Birman%2C+K">Ken Birman</a>, 
<a href="/search/cs?searchtype=author&query=Vitenberg%2C+R">Roman Vitenberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17690" title="Abstract">arXiv:2402.17690</a> (replaced) [<a href="/pdf/2402.17690" title="Download PDF">pdf</a>, <a href="/format/2402.17690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Vehicles: Evolution of Artificial Intelligence and Learning  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garikapati%2C+D">Divya Garikapati</a>, 
<a href="/search/cs?searchtype=author&query=Shetiya%2C+S+S">Sneha Sudhir Shetiya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item357">Cross-lists</a></li>
<li><a href="#item406">Replacements</a></li>
</ul>
<small>[ total of 667 entries:  <b>1-667</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2402">2402</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
