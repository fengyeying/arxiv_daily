<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Thu  8 Feb 24  to  Fri  9 Feb 24, announced Mon, 12 Feb 24</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item322">Cross-lists</a></li>
<li><a href="#item367">Replacements</a></li>
</ul>
<small>[ total of 559 entries:  <b>1-559</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Mon, 12 Feb 24</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05939" title="Abstract">arXiv:2402.05939</a> [<a href="/pdf/2402.05939" title="Download PDF">pdf</a>, <a href="/format/2402.05939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Awareness of Large Language Models Under Code Distribution  Shifts: A Benchmark Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yufei Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Simin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yanghong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yue Dong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) have been widely employed in programming
language analysis to enhance human productivity. Yet, their reliability can be
compromised by various code distribution shifts, leading to inconsistent
outputs. While probabilistic methods are known to mitigate such impact through
uncertainty calibration and estimation, their efficacy in the language domain
remains underexplored compared to their application in image-based tasks. In
this work, we first introduce a large-scale benchmark dataset, incorporating
three realistic patterns of code distribution shifts at varying intensities.
Then we thoroughly investigate state-of-the-art probabilistic methods applied
to CodeLlama using these shifted code snippets. We observe that these methods
generally improve the uncertainty awareness of CodeLlama, with increased
calibration quality and higher uncertainty estimation~(UE) precision. However,
our study further reveals varied performance dynamics across different criteria
(e.g., calibration error vs misclassification detection) and trade-off between
efficacy and efficiency, highlighting necessary methodological selection
tailored to specific contexts.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05940" title="Abstract">arXiv:2402.05940</a> [<a href="/pdf/2402.05940" title="Download PDF">pdf</a>, <a href="/ps/2402.05940" title="Download PostScript">ps</a>, <a href="/format/2402.05940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Relationship Network of Risk Factors Impacting Workday Loss in  Underground Coal Mines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Shangsi Ren</a>, 
<a href="/search/cs?searchtype=author&query=Beeche%2C+C+A">Cameron A. Beeche</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhiyi Shi</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+M+A">Maria Acevedo Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Zychowski%2C+K">Katherine Zychowski</a>, 
<a href="/search/cs?searchtype=author&query=Leng%2C+S">Shuguang Leng</a>, 
<a href="/search/cs?searchtype=author&query=Roghanchi%2C+P">Pedram Roghanchi</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+J">Jiantao Pu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 figures 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">This study aims to establish the causal relationship network between various
factors leading to workday loss in underground coal mines using a novel causal
artificial intelligence (AI) method. The analysis utilizes data obtained from
the National Institute for Occupational Safety and Health (NIOSH). A total of
101,010 injury records from 3,982 unique underground coal mines spanning the
years from 1990 to 2020 were extracted from the NIOSH database. Causal
relationships were analyzed and visualized using a novel causal AI method
called Grouped Greedy Equivalence Search (GGES). The impact of each variable on
workday loss was assessed through intervention do-calculus adjustment (IDA)
scores. Model training and validation were performed using the 10-fold
cross-validation technique. Performance metrics, including adjacency precision
(AP), adjacency recall (AR), arrowhead precision (AHP), and arrowhead recall
(AHR), were utilized to evaluate the models. Findings revealed that after 2006,
key direct causes of workday loss among mining employees included total mining
experience, mean office employees, mean underground employees, county, and
total mining experience (years). Total mining experience emerged as the most
influential factor, whereas mean employees per mine exhibited the least
influence. The analyses emphasized the significant role of total mining
experience in determining workday loss. The models achieved optimal
performance, with AP, AR, AHP, and AHR values measuring 0.694, 0.653, 0.386,
and 0.345, respectively. This study demonstrates the feasibility of utilizing
the new GGES method to clarify the causal factors behind the workday loss by
analyzing employment demographics and injury records and establish their causal
relationship network.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05941" title="Abstract">arXiv:2402.05941</a> [<a href="/pdf/2402.05941" title="Download PDF">pdf</a>, <a href="/format/2402.05941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Character-based Outfit Generation with Vision-augmented Style Extraction  via LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Forouzandehmehr%2C+N">Najmeh Forouzandehmehr</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yijie Cao</a>, 
<a href="/search/cs?searchtype=author&query=Thakurdesai%2C+N">Nikhil Thakurdesai</a>, 
<a href="/search/cs?searchtype=author&query=Giahi%2C+R">Ramin Giahi</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Luyi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Farrokhsiar%2C+N">Nima Farrokhsiar</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jianpeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Korpeoglu%2C+E">Evren Korpeoglu</a>, 
<a href="/search/cs?searchtype=author&query=Achan%2C+K">Kannan Achan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, IEEE Big Data 2023 3rd Workshop on Multimodal AI (MMAI 2023), IEEE BigData 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The outfit generation problem involves recommending a complete outfit to a
user based on their interests. Existing approaches focus on recommending items
based on anchor items or specific query styles but do not consider customer
interests in famous characters from movie, social media, etc. In this paper, we
define a new Character-based Outfit Generation (COG) problem, designed to
accurately interpret character information and generate complete outfit sets
according to customer specifications such as age and gender. To tackle this
problem, we propose a novel framework LVA-COG that leverages Large Language
Models (LLMs) to extract insights from customer interests (e.g., character
information) and employ prompt engineering techniques for accurate
understanding of customer preferences. Additionally, we incorporate
text-to-image models to enhance the visual understanding and generation
(factual or counterfactual) of cohesive outfits. Our framework integrates LLMs
with text-to-image models and improves the customer's approach to fashion by
generating personalized recommendations. With experiments and case studies, we
demonstrate the effectiveness of our solution from multiple dimensions.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05942" title="Abstract">arXiv:2402.05942</a> [<a href="/pdf/2402.05942" title="Download PDF">pdf</a>, <a href="/format/2402.05942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperative Knowledge Distillation: A Learner Agnostic Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Livanos%2C+M">Michael Livanos</a>, 
<a href="/search/cs?searchtype=author&query=Davidson%2C+I">Ian Davidson</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+S">Stephen Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures, AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Knowledge distillation is a simple but powerful way to transfer knowledge
between a teacher model to a student model. Existing work suffers from at least
one of the following key limitations in terms of direction and scope of
transfer which restrict its use: all knowledge is transferred from teacher to
student regardless of whether or not that knowledge is useful, the student is
the only one learning in this exchange, and typically distillation transfers
knowledge only from a single teacher to a single student. We formulate a novel
form of knowledge distillation in which many models can act as both students
and teachers which we call cooperative distillation. The models cooperate as
follows: a model (the student) identifies specific deficiencies in it's
performance and searches for another model (the teacher) who encodes learned
knowledge into instructional virtual instances via counterfactual instance
generation. Because different models may have different strengths and
weaknesses, all models can act as either students or teachers (cooperation)
when appropriate and only distill knowledge in areas specific to their
strengths (focus). Since counterfactuals as a paradigm are not tied to any
specific algorithm, we can use this method to distill knowledge between
learners of different architectures, algorithms, and even feature spaces. We
demonstrate that our approach not only outperforms baselines such as transfer
learning, self-supervised learning, and multiple knowledge distillation
algorithms on several datasets, but it can also be used in settings where the
aforementioned techniques cannot.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05943" title="Abstract">arXiv:2402.05943</a> [<a href="/pdf/2402.05943" title="Download PDF">pdf</a>, <a href="/ps/2402.05943" title="Download PostScript">ps</a>, <a href="/format/2402.05943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A hybrid IndRNNLSTM approach for real-time anomaly detection in  software-defined networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salem%2C+S">Sajjad Salem</a>, 
<a href="/search/cs?searchtype=author&query=Asoudeh%2C+S">Salman Asoudeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Anomaly detection in SDN using data flow prediction is a difficult task. This
problem is included in the category of time series and regression problems.
Machine learning approaches are challenging in this field due to the manual
selection of features. On the other hand, deep learning approaches have
important features due to the automatic selection of features. Meanwhile,
RNN-based approaches have been used the most. The LSTM and GRU approaches learn
dependent entities well; on the other hand, the IndRNN approach learns
non-dependent entities in time series. The proposed approach tried to use a
combination of IndRNN and LSTM approaches to learn dependent and non-dependent
features. Feature selection approaches also provide a suitable view of features
for the models; for this purpose, four feature selection models, Filter,
Wrapper, Embedded, and Autoencoder were used. The proposed IndRNNLSTM
algorithm, in combination with Embedded, was able to achieve MAE=1.22 and
RMSE=9.92 on NSL-KDD data.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05944" title="Abstract">arXiv:2402.05944</a> [<a href="/pdf/2402.05944" title="Download PDF">pdf</a>, <a href="/format/2402.05944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Todyformer: Towards Holistic Dynamic Graph Transformers with  Structure-Aware Tokenization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biparva%2C+M">Mahdi Biparva</a>, 
<a href="/search/cs?searchtype=author&query=Karimi%2C+R">Raika Karimi</a>, 
<a href="/search/cs?searchtype=author&query=Faez%2C+F">Faezeh Faez</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingxue Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Temporal Graph Neural Networks have garnered substantial attention for their
capacity to model evolving structural and temporal patterns while exhibiting
impressive performance. However, it is known that these architectures are
encumbered by issues that constrain their performance, such as over-squashing
and over-smoothing. Meanwhile, Transformers have demonstrated exceptional
computational capacity to effectively address challenges related to long-range
dependencies. Consequently, we introduce Todyformer-a novel Transformer-based
neural network tailored for dynamic graphs. It unifies the local encoding
capacity of Message-Passing Neural Networks (MPNNs) with the global encoding of
Transformers through i) a novel patchifying paradigm for dynamic graphs to
improve over-squashing, ii) a structure-aware parametric tokenization strategy
leveraging MPNNs, iii) a Transformer with temporal positional-encoding to
capture long-range dependencies, and iv) an encoding architecture that
alternates between local and global contextualization, mitigating
over-smoothing in MPNNs. Experimental evaluations on public benchmark datasets
demonstrate that Todyformer consistently outperforms the state-of-the-art
methods for downstream tasks. Furthermore, we illustrate the underlying aspects
of the proposed model in effectively capturing extensive temporal dependencies
in dynamic graphs.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05945" title="Abstract">arXiv:2402.05945</a> [<a href="/pdf/2402.05945" title="Download PDF">pdf</a>, <a href="/format/2402.05945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eliminating Information Leakage in Hard Concept Bottleneck Models with  Supervised, Hierarchical Concept Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+A">Ao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuanyuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+P">Pingchuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Concept Bottleneck Models (CBMs) aim to deliver interpretable and
interventionable predictions by bridging features and labels with
human-understandable concepts. While recent CBMs show promising potential, they
suffer from information leakage, where unintended information beyond the
concepts (either when concepts are represented with probabilities or binary
states) are leaked to the subsequent label prediction. Consequently, distinct
classes are falsely classified via indistinguishable concepts, undermining the
interpretation and intervention of CBMs.
<br />This paper alleviates the information leakage issue by introducing label
supervision in concept predication and constructing a hierarchical concept set.
Accordingly, we propose a new paradigm of CBMs, namely SupCBM, which achieves
label predication via predicted concepts and a deliberately-designed
intervention matrix. SupCBM focuses on concepts that are mostly relevant to the
predicted label and only distinguishes classes when different concepts are
presented. Our evaluations show that SupCBM outperforms SOTA CBMs over diverse
datasets. It also manifests better generality across different backbone models.
With proper quantification of information leakage in different CBMs, we
demonstrate that SupCBM significantly reduces the information leakage.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05946" title="Abstract">arXiv:2402.05946</a> [<a href="/pdf/2402.05946" title="Download PDF">pdf</a>, <a href="/format/2402.05946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Latent Causal Rules: A Temporal Point Process Approach for  Abnormal Event Explanation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuang%2C+Y">Yiling Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In high-stakes systems such as healthcare, it is critical to understand the
causal reasons behind unusual events, such as sudden changes in patient's
health. Unveiling the causal reasons helps with quick diagnoses and precise
treatment planning. In this paper, we propose an automated method for
uncovering "if-then" logic rules to explain observational events. We introduce
temporal point processes to model the events of interest, and discover the set
of latent rules to explain the occurrence of events. To achieve this, we employ
an Expectation-Maximization (EM) algorithm. In the E-step, we calculate the
likelihood of each event being explained by each discovered rule. In the
M-step, we update both the rule set and model parameters to enhance the
likelihood function's lower bound. Notably, we optimize the rule set in a
differential manner. Our approach demonstrates accurate performance in both
discovering rules and identifying root causes. We showcase its promising
results using synthetic and real healthcare datasets.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05947" title="Abstract">arXiv:2402.05947</a> [<a href="/pdf/2402.05947" title="Download PDF">pdf</a>, <a href="/format/2402.05947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Separable Multi-Concept Erasure from Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Mengnan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lihe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tianhang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Y">Yuqiu Kong</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+B">Baocai Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Large-scale diffusion models, known for their impressive image generation
capabilities, have raised concerns among researchers regarding social impacts,
such as the imitation of copyrighted artistic styles. In response, existing
approaches turn to machine unlearning techniques to eliminate unsafe concepts
from pre-trained models. However, these methods compromise the generative
performance and neglect the coupling among multi-concept erasures, as well as
the concept restoration problem. To address these issues, we propose a
Separable Multi-concept Eraser (SepME), which mainly includes two parts: the
generation of concept-irrelevant representations and the weight decoupling. The
former aims to avoid unlearning substantial information that is irrelevant to
forgotten concepts. The latter separates optimizable model weights, making each
weight increment correspond to a specific concept erasure without affecting
generative performance on other concepts. Specifically, the weight increment
for erasing a specified concept is formulated as a linear combination of
solutions calculated based on other known undesirable concepts. Extensive
experiments indicate the efficacy of our approach in eliminating concepts,
preserving model performance, and offering flexibility in the erasure or
recovery of various concepts.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05948" title="Abstract">arXiv:2402.05948</a> [<a href="/pdf/2402.05948" title="Download PDF">pdf</a>, <a href="/format/2402.05948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DE$^3$-BERT: Distance-Enhanced Early Exiting for BERT based on  Prototypical Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jianing He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Weiping Ding</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+D">Duoqian Miao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Liang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Longbing Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Early exiting has demonstrated its effectiveness in accelerating the
inference of pre-trained language models like BERT by dynamically adjusting the
number of layers executed. However, most existing early exiting methods only
consider local information from an individual test sample to determine their
exiting indicators, failing to leverage the global information offered by
sample population. This leads to suboptimal estimation of prediction
correctness, resulting in erroneous exiting decisions. To bridge the gap, we
explore the necessity of effectively combining both local and global
information to ensure reliable early exiting during inference. Purposefully, we
leverage prototypical networks to learn class prototypes and devise a distance
metric between samples and class prototypes. This enables us to utilize global
information for estimating the correctness of early predictions. On this basis,
we propose a novel Distance-Enhanced Early Exiting framework for BERT
(DE$^3$-BERT). DE$^3$-BERT implements a hybrid exiting strategy that
supplements classic entropy-based local information with distance-based global
information to enhance the estimation of prediction correctness for more
reliable early exiting decisions. Extensive experiments on the GLUE benchmark
demonstrate that DE$^3$-BERT consistently outperforms state-of-the-art models
under different speed-up ratios with minimal storage or computational overhead,
yielding a better trade-off between model performance and inference efficiency.
Additionally, an in-depth analysis further validates the generality and
interpretability of our method.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05949" title="Abstract">arXiv:2402.05949</a> [<a href="/pdf/2402.05949" title="Download PDF">pdf</a>, <a href="/ps/2402.05949" title="Download PostScript">ps</a>, <a href="/format/2402.05949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An explainable machine learning-based approach for analyzing customers&#x27;  online data to identify the importance of product attributes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karimzadeh%2C+A">Aigin Karimzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Zakery%2C+A">Amir Zakery</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadi%2C+M">Mohammadreza Mohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Yavari%2C+A">Ali Yavari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Online customer data provides valuable information for product design and
marketing research, as it can reveal the preferences of customers. However,
analyzing these data using artificial intelligence (AI) for data-driven design
is a challenging task due to potential concealed patterns. Moreover, in these
research areas, most studies are only limited to finding customers' needs. In
this study, we propose a game theory machine learning (ML) method that extracts
comprehensive design implications for product development. The method first
uses a genetic algorithm to select, rank, and combine product features that can
maximize customer satisfaction based on online ratings. Then, we use SHAP
(SHapley Additive exPlanations), a game theory method that assigns a value to
each feature based on its contribution to the prediction, to provide a
guideline for assessing the importance of each feature for the total
satisfaction. We apply our method to a real-world dataset of laptops from
Kaggle, and derive design implications based on the results. Our approach
tackles a major challenge in the field of multi-criteria decision making and
can help product designers and marketers, to understand customer preferences
better with less data and effort. The proposed method outperforms benchmark
methods in terms of relevant performance metrics.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05950" title="Abstract">arXiv:2402.05950</a> [<a href="/pdf/2402.05950" title="Download PDF">pdf</a>, <a href="/format/2402.05950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> \textit{SQT} -- \textit{std} $Q$-target
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soffair%2C+N">Nitsan Soffair</a>, 
<a href="/search/cs?searchtype=author&query=Di-Castro%2C+D">Dotan Di-Castro</a>, 
<a href="/search/cs?searchtype=author&query=Avner%2C+O">Orly Avner</a>, 
<a href="/search/cs?searchtype=author&query=Mannor%2C+S">Shie Mannor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">\textit{Std} $Q$-target is a \textit{conservative}, actor-critic, ensemble,
$Q$-learning-based algorithm, which is based on a single key $Q$-formula:
$Q$-networks standard deviation, which is an "uncertainty penalty", and, serves
as a minimalistic solution to the problem of \textit{overestimation} bias. We
implement \textit{SQT} on top of TD3/TD7 code and test it against the
state-of-the-art (SOTA) actor-critic algorithms, DDPG, TD3 and TD7 on seven
popular MuJoCo and Bullet tasks. Our results demonstrate \textit{SQT}'s
$Q$-target formula superiority over \textit{TD3}'s $Q$-target formula as a
\textit{conservative} solution to overestimation bias in RL, while \textit{SQT}
shows a clear performance advantage on a wide margin over DDPG, TD3, and TD7 on
all tasks.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05951" title="Abstract">arXiv:2402.05951</a> [<a href="/pdf/2402.05951" title="Download PDF">pdf</a>, <a href="/format/2402.05951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> \textit{MinMaxMin} $Q$-learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soffair%2C+N">Nitsan Soffair</a>, 
<a href="/search/cs?searchtype=author&query=Mannor%2C+S">Shie Mannor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">\textit{MinMaxMin} $Q$-learning is a novel \textit{optimistic} Actor-Critic
algorithm that addresses the problem of \textit{overestimation} bias
($Q$-estimations are overestimating the real $Q$-values) inherent in
\textit{conservative} RL algorithms. Its core formula relies on the
disagreement among $Q$-networks in the form of the min-batch MaxMin
$Q$-networks distance which is added to the $Q$-target and used as the priority
experience replay sampling-rule. We implement \textit{MinMaxMin} on top of TD3
and TD7, subjecting it to rigorous testing against state-of-the-art
continuous-space algorithms-DDPG, TD3, and TD7-across popular MuJoCo and Bullet
environments. The results show a consistent performance improvement of
\textit{MinMaxMin} over DDPG, TD3, and TD7 across all tested tasks.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05952" title="Abstract">arXiv:2402.05952</a> [<a href="/pdf/2402.05952" title="Download PDF">pdf</a>, <a href="/format/2402.05952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Graph Representation Learning with Large Language Models: A  Comprehensive Survey of Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+Q">Qiheng Mao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zemin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chenghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jianling Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">The integration of Large Language Models (LLMs) with Graph Representation
Learning (GRL) marks a significant evolution in analyzing complex data
structures. This collaboration harnesses the sophisticated linguistic
capabilities of LLMs to improve the contextual understanding and adaptability
of graph models, thereby broadening the scope and potential of GRL. Despite a
growing body of research dedicated to integrating LLMs into the graph domain, a
comprehensive review that deeply analyzes the core components and operations
within these models is notably lacking. Our survey fills this gap by proposing
a novel taxonomy that breaks down these models into primary components and
operation techniques from a novel technical perspective. We further dissect
recent literature into two primary components including knowledge extractors
and organizers, and two operation techniques including integration and training
stratigies, shedding light on effective model design and training strategies.
Additionally, we identify and explore potential future research avenues in this
nascent yet underexplored field, proposing paths for continued progress.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05954" title="Abstract">arXiv:2402.05954</a> [<a href="/pdf/2402.05954" title="Download PDF">pdf</a>, <a href="/format/2402.05954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EasyFS: an Efficient Model-free Feature Selection Framework via Elastic  Transformation of Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lv%2C+J">Jianming Lv</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Sijun Xia</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+D">Depin Liang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Traditional model-free feature selection methods treat each feature
independently while disregarding the interrelationships among features, which
leads to relatively poor performance compared with the model-aware methods. To
address this challenge, we propose an efficient model-free feature selection
framework via elastic expansion and compression of the features, namely EasyFS,
to achieve better performance than state-of-the-art model-aware methods while
sharing the characters of efficiency and flexibility with the existing
model-free methods. In particular, EasyFS expands the feature space by using
the random non-linear projection network to achieve the non-linear combinations
of the original features, so as to model the interrelationships among the
features and discover most correlated features. Meanwhile, a novel redundancy
measurement based on the change of coding rate is proposed for efficient
filtering of redundant features. Comprehensive experiments on 21 different
datasets show that EasyFS outperforms state-of-the art methods up to 10.9\% in
the regression tasks and 5.7\% in the classification tasks while saving more
than 94\% of the time.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05955" title="Abstract">arXiv:2402.05955</a> [<a href="/pdf/2402.05955" title="Download PDF">pdf</a>, <a href="/format/2402.05955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hyper-Transformer model for Controllable Pareto Front Learning with  Split Feasibility Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tuan%2C+T+A">Tran Anh Tuan</a>, 
<a href="/search/cs?searchtype=author&query=Dung%2C+N+V">Nguyen Viet Dung</a>, 
<a href="/search/cs?searchtype=author&query=Thang%2C+T+N">Tran Ngoc Thang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Controllable Pareto front learning (CPFL) approximates the Pareto solution
set and then locates a Pareto optimal solution with respect to a given
reference vector. However, decision-maker objectives were limited to a
constraint region in practice, so instead of training on the entire decision
space, we only trained on the constraint region. Controllable Pareto front
learning with Split Feasibility Constraints (SFC) is a way to find the best
Pareto solutions to a split multi-objective optimization problem that meets
certain constraints. In the previous study, CPFL used a Hypernetwork model
comprising multi-layer perceptron (Hyper-MLP) blocks. With the substantial
advancement of transformer architecture in deep learning, transformers can
outperform other architectures in various tasks. Therefore, we have developed a
hyper-transformer (Hyper-Trans) model for CPFL with SFC. We use the theory of
universal approximation for the sequence-to-sequence function to show that the
Hyper-Trans model makes MED errors smaller in computational experiments than
the Hyper-MLP model.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05956" title="Abstract">arXiv:2402.05956</a> [<a href="/pdf/2402.05956" title="Download PDF">pdf</a>, <a href="/format/2402.05956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pathformer: Multi-scale transformers with Adaptive Pathways for Time  Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yunyao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+Y">Yang Shu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yihang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Q">Qingsong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Chenjuan Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Transformer-based models have achieved some success in time series
forecasting. Existing methods mainly model time series from limited or fixed
scales, making it challenging to capture different characteristics spanning
various scales. In this paper, we propose multi-scale transformers with
adaptive pathways (Pathformer). The proposed Transformer integrates both
temporal resolution and temporal distance for multi-scale modeling. Multi-scale
division divides the time series into different temporal resolutions using
patches of various sizes. Based on the division of each scale, dual attention
is performed over these patches to capture global correlations and local
details as temporal dependencies. We further enrich the multi-scale transformer
with adaptive pathways, which adaptively adjust the multi-scale modeling
process based on the varying temporal dynamics in the input time series,
improving the prediction accuracy and generalization of Pathformer. Extensive
experiments on eleven real-world datasets demonstrate that Pathformer not only
achieves state-of-the-art performance by surpassing all current models but also
exhibits stronger generalization abilities under various transfer scenarios.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05957" title="Abstract">arXiv:2402.05957</a> [<a href="/pdf/2402.05957" title="Download PDF">pdf</a>, <a href="/format/2402.05957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating PDE Data Generation via Differential Operator Action in  Solution Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Huanshuo Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haoyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jian Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jie Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Recent advancements in data-driven approaches, such as Neural Operator (NO),
have demonstrated their effectiveness in reducing the solving time of Partial
Differential Equations (PDEs). However, one major challenge faced by these
approaches is the requirement for a large amount of high-precision training
data, which needs significant computational costs during the generation
process. To address this challenge, we propose a novel PDE dataset generation
algorithm, namely Differential Operator Action in Solution space (DiffOAS),
which speeds up the data generation process and enhances the precision of the
generated data simultaneously. Specifically, DiffOAS obtains a few basic PDE
solutions and then combines them to get solutions. It applies differential
operators on these solutions, a process we call 'operator action', to
efficiently generate precise PDE data points. Theoretical analysis shows that
the time complexity of DiffOAS method is one order lower than the existing
generation method. Experimental results show that DiffOAS accelerates the
generation of large-scale datasets with 10,000 instances by 300 times. Even
with just 5% of the generation time, NO trained on the data generated by
DiffOAS exhibits comparable performance to that using the existing generation
method, which highlights the efficiency of DiffOAS.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05958" title="Abstract">arXiv:2402.05958</a> [<a href="/pdf/2402.05958" title="Download PDF">pdf</a>, <a href="/ps/2402.05958" title="Download PostScript">ps</a>, <a href="/format/2402.05958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A comparative study on wearables and single-camera video for upper-limb  out-of-thelab activity recognition with different deep learning architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez-Zarzuela%2C+M">Mario Mart&#xed;nez-Zarzuela</a>, 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez-Ortega%2C+D">David Gonz&#xe1;lez-Ortega</a>, 
<a href="/search/cs?searchtype=author&query=Ant%C3%B3n-Rodr%C3%ADguez%2C+M">M&#xed;riam Ant&#xf3;n-Rodr&#xed;guez</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Pernas%2C+F+J">Francisco Javier D&#xed;az-Pernas</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+H">Henning M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Sim%C3%B3n-Mart%C3%ADnez%2C+C">Cristina Sim&#xf3;n-Mart&#xed;nez</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Gait &amp; Posture (2023) 106, p. 119-120
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">The use of a wide range of computer vision solutions, and more recently
high-end Inertial Measurement Units (IMU) have become increasingly popular for
assessing human physical activity in clinical and research settings.
Nevertheless, to increase the feasibility of patient tracking in out-of-the-lab
settings, it is necessary to use a reduced number of devices for movement
acquisition. Promising solutions in this context are IMU-based wearables and
single camera systems. Additionally, the development of machine learning
systems able to recognize and digest clinically relevant data in-the-wild is
needed, and therefore determining the ideal input to those is crucial.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05959" title="Abstract">arXiv:2402.05959</a> [<a href="/pdf/2402.05959" title="Download PDF">pdf</a>, <a href="/format/2402.05959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nature-Inspired Local Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Betti%2C+A">Alessandro Betti</a>, 
<a href="/search/cs?searchtype=author&query=Gori%2C+M">Marco Gori</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">The spectacular results achieved in machine learning, including the recent
advances in generative AI, rely on large data collections. On the opposite,
intelligent processes in nature arises without the need for such collections,
but simply by online processing of the environmental information. In
particular, natural learning processes rely on mechanisms where data
representation and learning are intertwined in such a way to respect
spatiotemporal locality. This paper shows that such a feature arises from a
pre-algorithmic view of learning that is inspired by related studies in
Theoretical Physics. We show that the algorithmic interpretation of the derived
"laws of learning", which takes the structure of Hamiltonian equations, reduces
to Backpropagation when the speed of propagation goes to infinity. This opens
the doors to machine learning studies based on full on-line information
processing that are based the replacement of Backpropagation with the proposed
spatiotemporal local algorithm.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05960" title="Abstract">arXiv:2402.05960</a> [<a href="/pdf/2402.05960" title="Download PDF">pdf</a>, <a href="/format/2402.05960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phase-driven Domain Generalizable Learning for Nonstationary Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohapatra%2C+P">Payal Mohapatra</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lixu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qi Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Monitoring and recognizing patterns in continuous sensing data is crucial for
many practical applications. These real-world time-series data are often
nonstationary, characterized by varying statistical and spectral properties
over time. This poses a significant challenge in developing learning models
that can effectively generalize across different distributions. In this work,
based on our observation that nonstationary statistics are intrinsically linked
to the phase information, we propose a time-series learning framework, PhASER.
It consists of three novel elements: 1) phase augmentation that diversifies
non-stationarity while preserving discriminatory semantics, 2) separate feature
encoding by viewing time-varying magnitude and phase as independent modalities,
and 3) feature broadcasting by incorporating phase with a novel residual
connection for inherent regularization to enhance distribution invariant
learning. Upon extensive evaluation on 5 datasets from human activity
recognition, sleep-stage classification, and gesture recognition against 10
state-of-the-art baseline methods, we demonstrate that PhASER consistently
outperforms the best baselines by an average of 5% and up to 13% in some cases.
Moreover, PhASER's principles can be applied broadly to boost the
generalization ability of existing time series classification models.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05962" title="Abstract">arXiv:2402.05962</a> [<a href="/pdf/2402.05962" title="Download PDF">pdf</a>, <a href="/format/2402.05962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EXGC: Bridging Efficiency and Explainability in Graph Condensation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Junfeng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinglin Li</a>, 
<a href="/search/cs?searchtype=author&query=Sui%2C+Y">Yongduo Sui</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guibin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangnan He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph representation learning on vast datasets, like web data, has made
significant strides. However, the associated computational and storage
overheads raise concerns. In sight of this, Graph condensation (GCond) has been
introduced to distill these large real datasets into a more concise yet
information-rich synthetic graph. Despite acceleration efforts, existing GCond
methods mainly grapple with efficiency, especially on expansive web data
graphs. Hence, in this work, we pinpoint two major inefficiencies of current
paradigms: (1) the concurrent updating of a vast parameter set, and (2)
pronounced parameter redundancy. To counteract these two limitations
correspondingly, we first (1) employ the Mean-Field variational approximation
for convergence acceleration, and then (2) propose the objective of Gradient
Information Bottleneck (GDIB) to prune redundancy. By incorporating the leading
explanation techniques (e.g., GNNExplainer and GSAT) to instantiate the GDIB,
our EXGC, the Efficient and eXplainable Graph Condensation method is proposed,
which can markedly boost efficiency and inject explainability. Our extensive
evaluations across eight datasets underscore EXGC's superiority and relevance.
Code is available at https://github.com/MangoKiller/EXGC.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05963" title="Abstract">arXiv:2402.05963</a> [<a href="/pdf/2402.05963" title="Download PDF">pdf</a>, <a href="/format/2402.05963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frugal Actor-Critic: Sample Efficient Off-Policy Deep Reinforcement  Learning Using Unique Experiences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+N+K">Nikhil Kumar Singh</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+I">Indranil Saha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO); Systems and Control (eess.SY)

</div>
<p class="mathjax">Efficient utilization of the replay buffer plays a significant role in the
off-policy actor-critic reinforcement learning (RL) algorithms used for
model-free control policy synthesis for complex dynamical systems. We propose a
method for achieving sample efficiency, which focuses on selecting unique
samples and adding them to the replay buffer during the exploration with the
goal of reducing the buffer size and maintaining the independent and
identically distributed (IID) nature of the samples. Our method is based on
selecting an important subset of the set of state variables from the
experiences encountered during the initial phase of random exploration,
partitioning the state space into a set of abstract states based on the
selected important state variables, and finally selecting the experiences with
unique state-reward combination by using a kernel density estimator. We
formally prove that the off-policy actor-critic algorithm incorporating the
proposed method for unique experience accumulation converges faster than the
vanilla off-policy actor-critic algorithm. Furthermore, we evaluate our method
by comparing it with two state-of-the-art actor-critic RL algorithms on several
continuous control benchmarks available in the Gym environment. Experimental
results demonstrate that our method achieves a significant reduction in the
size of the replay buffer for all the benchmarks while achieving either faster
convergent or better reward accumulation compared to the baseline algorithms.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05964" title="Abstract">arXiv:2402.05964</a> [<a href="/pdf/2402.05964" title="Download PDF">pdf</a>, <a href="/format/2402.05964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Transformer Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yehui Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jianyuan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhijun Tu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kai Han</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hailin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Large models based on the Transformer architecture play increasingly vital
roles in artificial intelligence, particularly within the realms of natural
language processing (NLP) and computer vision (CV). Model compression methods
reduce their memory and computational cost, which is a necessary step to
implement the transformer models on practical devices. Given the unique
architecture of transformer, featuring alternative attention and Feedforward
Neural Network (FFN) modules, specific compression techniques are required. The
efficiency of these compression methods is also paramount, as it is usually
impractical to retrain large models on the entire training dataset.This survey
provides a comprehensive review of recent compression methods, with a specific
focus on their application to transformer models. The compression methods are
primarily categorized into pruning, quantization, knowledge distillation, and
efficient architecture design. In each category, we discuss compression methods
for both CV and NLP tasks, highlighting common underlying principles. At last,
we delve into the relation between various compression methods, and discuss the
further directions in this domain.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05965" title="Abstract">arXiv:2402.05965</a> [<a href="/pdf/2402.05965" title="Download PDF">pdf</a>, <a href="/format/2402.05965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Neural Representations for Spherical Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyomin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+Y">Yunhui Jang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaeho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+S">Sungsoo Ahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we study hybrid neural representations for spherical data, a
domain of increasing relevance in scientific research. In particular, our work
focuses on weather and climate data as well as comic microwave background (CMB)
data. Although previous studies have delved into coordinate-based neural
representations for spherical signals, they often fail to capture the intricate
details of highly nonlinear signals. To address this limitation, we introduce a
novel approach named Hybrid Neural Representations for Spherical data (HNeR-S).
Our main idea is to use spherical feature-grids to obtain positional features
which are combined with a multilayer perception to predict the target signal.
We consider feature-grids with equirectangular and hierarchical equal area
isolatitude pixelization structures that align with weather data and CMB data,
respectively. We extensively verify the effectiveness of our HNeR-S for
regression, super-resolution, temporal interpolation, and compression tasks.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05966" title="Abstract">arXiv:2402.05966</a> [<a href="/pdf/2402.05966" title="Download PDF">pdf</a>, <a href="/format/2402.05966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethink Model Re-Basin and the Linear Mode Connectivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+X">Xingyu Qu</a>, 
<a href="/search/cs?searchtype=author&query=Horvath%2C+S">Samuel Horvath</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent studies suggest that with sufficiently wide models, most SGD solutions
can, up to permutation, converge into the same basin. This phenomenon, known as
the model re-basin regime, has significant implications for model averaging.
However, current re-basin strategies are limited in effectiveness due to a lack
of comprehensive understanding of underlying mechanisms. Addressing this gap,
our work revisits standard practices and uncovers the frequent inadequacies of
existing matching algorithms, which we show can be mitigated through proper
re-normalization. By introducing a more direct analytical approach, we expose
the interaction between matching algorithms and re-normalization processes.
This perspective not only clarifies and refines previous findings but also
facilitates novel insights. For instance, it connects the linear mode
connectivity to pruning, motivating a lightweight yet effective post-pruning
plug-in that can be directly merged with any existing pruning techniques. Our
implementation is available at https://github.com/XingyuQu/rethink-re-basin.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05967" title="Abstract">arXiv:2402.05967</a> [<a href="/pdf/2402.05967" title="Download PDF">pdf</a>, <a href="/format/2402.05967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The last Dance : Robust backdoor attack via diffusion models and  bayesian approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mengara%2C+O">Orson Mengara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint : audio backdoor attack performed on Hugging Face's Transformer pre-trained models, in particular for Audios (pre-trained model). This attack incorporates state-of-the-art Bayesian techniques, a modified Fokker-Planck equation, and a diffusion model approach
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Signal Processing (eess.SP)

</div>
<p class="mathjax">Diffusion models are state-of-the-art deep learning generative models that
are trained on the principle of learning forward and backward diffusion
processes via the progressive addition of noise and denoising. In this paper,
we seek to trick audio-based DNN models, such as those in the Hugging Face
framework, for example, those that focus on audio, in particular
transformer-based artificial intelligence models, which are powerful machine
learning models that save time and deliver faster, more efficient results. We
demonstrate the feasibility of backdoor attacks (called `BacKBayDiffMod`) on
audio transformers derived from Hugging Face, a popular framework in the world
of artificial intelligence (AI) research. The backdoor attack developed in this
paper is based on poisoning the model's training data by incorporating backdoor
diffusion sampling and a Bayesian approach to the distribution of poisoned
data.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05968" title="Abstract">arXiv:2402.05968</a> [<a href="/pdf/2402.05968" title="Download PDF">pdf</a>, <a href="/format/2402.05968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning Priorities Under the European Union Artificial  Intelligence Act
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Woisetschl%C3%A4ger%2C+H">Herbert Woisetschl&#xe4;ger</a>, 
<a href="/search/cs?searchtype=author&query=Erben%2C+A">Alexander Erben</a>, 
<a href="/search/cs?searchtype=author&query=Marino%2C+B">Bill Marino</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lane%2C+N+D">Nicholas D. Lane</a>, 
<a href="/search/cs?searchtype=author&query=Mayer%2C+R">Ruben Mayer</a>, 
<a href="/search/cs?searchtype=author&query=Jacobsen%2C+H">Hans-Arno Jacobsen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">The age of AI regulation is upon us, with the European Union Artificial
Intelligence Act (AI Act) leading the way. Our key inquiry is how this will
affect Federated Learning (FL), whose starting point of prioritizing data
privacy while performing ML fundamentally differs from that of centralized
learning. We believe the AI Act and future regulations could be the missing
catalyst that pushes FL toward mainstream adoption. However, this can only
occur if the FL community reprioritizes its research focus. In our position
paper, we perform a first-of-its-kind interdisciplinary analysis (legal and ML)
of the impact the AI Act may have on FL and make a series of observations
supporting our primary position through quantitative and qualitative analysis.
We explore data governance issues and the concern for privacy. We establish new
challenges regarding performance and energy efficiency within lifecycle
monitoring. Taken together, our analysis suggests there is a sizable
opportunity for FL to become a crucial component of AI Act-compliant ML systems
and for the new regulation to drive the adoption of FL techniques in general.
Most noteworthy are the opportunities to defend against data bias and enhance
private and secure computation
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05969" title="Abstract">arXiv:2402.05969</a> [<a href="/pdf/2402.05969" title="Download PDF">pdf</a>, <a href="/format/2402.05969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breaking Symmetry When Training Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuo%2C+C">Chunsheng Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Guerzhoy%2C+M">Michael Guerzhoy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">As we show in this paper, the prediction for output token $n+1$ of
Transformer architectures without one of the mechanisms of positional encodings
and causal attention is invariant to permutations of input tokens $1, 2, ...,
n-1$. Usually, both mechanisms are employed and the symmetry with respect to
the input tokens is broken. Recently, it has been shown that one can train
Transformers without positional encodings. This must be enabled by the causal
attention mechanism. In this paper, we elaborate on the argument that the
causal connection mechanism must be responsible for the fact that Transformers
are able to model input sequences where the order is important. Vertical
"slices" of Transformers are all encouraged to represent the same location $k$
in the input sequence. We hypothesize that residual connections contribute to
this phenomenon, and demonstrate evidence for this.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05970" title="Abstract">arXiv:2402.05970</a> [<a href="/pdf/2402.05970" title="Download PDF">pdf</a>, <a href="/format/2402.05970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Spatio-temporal Dynamical Systems with Neural Discrete Learning  and Levels-of-Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guibin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Junfeng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuxuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuankai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zimmermann%2C+R">Roger Zimmermann</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we address the issue of modeling and estimating changes in the
state of the spatio-temporal dynamical systems based on a sequence of
observations like video frames. Traditional numerical simulation systems depend
largely on the initial settings and correctness of the constructed partial
differential equations (PDEs). Despite recent efforts yielding significant
success in discovering data-driven PDEs with neural networks, the limitations
posed by singular scenarios and the absence of local insights prevent them from
performing effectively in a broader real-world context. To this end, this paper
propose the universal expert module -- that is, optical flow estimation
component, to capture the evolution laws of general physical processes in a
data-driven fashion. To enhance local insight, we painstakingly design a
finer-grained physical pipeline, since local characteristics may be influenced
by various internal contextual information, which may contradict the
macroscopic properties of the whole system. Further, we harness currently
popular neural discrete learning to unveil the underlying important features in
its latent space, this process better injects interpretability, which can help
us obtain a powerful prior over these discrete random variables. We conduct
extensive experiments and ablations to demonstrate that the proposed framework
achieves large performance margins, compared with the existing SOTA baselines.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05971" title="Abstract">arXiv:2402.05971</a> [<a href="/pdf/2402.05971" title="Download PDF">pdf</a>, <a href="/format/2402.05971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are we making much progress? Revisiting chemical reaction yield  prediction from an imbalanced regression perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yihong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaobao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Nan%2C+B">Bozhao Nan</a>, 
<a href="/search/cs?searchtype=author&query=Moniz%2C+N">Nuno Moniz</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wiest%2C+O">Olaf Wiest</a>, 
<a href="/search/cs?searchtype=author&query=Chawla%2C+N+V">Nitesh V. Chawla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Chemical Physics (physics.chem-ph)

</div>
<p class="mathjax">The yield of a chemical reaction quantifies the percentage of the target
product formed in relation to the reactants consumed during the chemical
reaction. Accurate yield prediction can guide chemists toward selecting
high-yield reactions during synthesis planning, offering valuable insights
before dedicating time and resources to wet lab experiments. While recent
advancements in yield prediction have led to overall performance improvement
across the entire yield range, an open challenge remains in enhancing
predictions for high-yield reactions, which are of greater concern to chemists.
In this paper, we argue that the performance gap in high-yield predictions
results from the imbalanced distribution of real-world data skewed towards
low-yield reactions, often due to unreacted starting materials and inherent
ambiguities in the reaction processes. Despite this data imbalance, existing
yield prediction methods continue to treat different yield ranges equally,
assuming a balanced training distribution. Through extensive experiments on
three real-world yield prediction datasets, we emphasize the urgent need to
reframe reaction yield prediction as an imbalanced regression problem. Finally,
we demonstrate that incorporating simple cost-sensitive re-weighting methods
can significantly enhance the performance of yield prediction models on
underrepresented high-yield regions.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05973" title="Abstract">arXiv:2402.05973</a> [<a href="/pdf/2402.05973" title="Download PDF">pdf</a>, <a href="/format/2402.05973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blockchain-enabled Clustered and Scalable Federated Learning (BCS-FL)  Framework in UAV Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hafeez%2C+S">Sana Hafeez</a>, 
<a href="/search/cs?searchtype=author&query=Mohjazi%2C+L">Lina Mohjazi</a>, 
<a href="/search/cs?searchtype=author&query=Imran%2C+M+A">Muhammad Ali Imran</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yao Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 7 figures, 2023 IEEE International Workshop on Computer Aided Modeling and Design of Communication Links and Networks (IEEE CAMAD), Edinburgh UK
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Privacy, scalability, and reliability are significant challenges in unmanned
aerial vehicle (UAV) networks as distributed systems, especially when employing
machine learning (ML) technologies with substantial data exchange. Recently,
the application of federated learning (FL) to UAV networks has improved
collaboration, privacy, resilience, and adaptability, making it a promising
framework for UAV applications. However, implementing FL for UAV networks
introduces drawbacks such as communication overhead, synchronization issues,
scalability limitations, and resource constraints. To address these challenges,
this paper presents the Blockchain-enabled Clustered and Scalable Federated
Learning (BCS-FL) framework for UAV networks. This improves the
decentralization, coordination, scalability, and efficiency of FL in
large-scale UAV networks. The framework partitions UAV networks into separate
clusters, coordinated by cluster head UAVs (CHs), to establish a connected
graph. Clustering enables efficient coordination of updates to the ML model.
Additionally, hybrid inter-cluster and intra-cluster model aggregation schemes
generate the global model after each training round, improving collaboration
and knowledge sharing among clusters. The numerical findings illustrate the
achievement of convergence while also emphasizing the trade-offs between the
effectiveness of training and communication efficiency.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05976" title="Abstract">arXiv:2402.05976</a> [<a href="/pdf/2402.05976" title="Download PDF">pdf</a>, <a href="/ps/2402.05976" title="Download PostScript">ps</a>, <a href="/format/2402.05976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RankSum An unsupervised extractive text summarization based on rank  fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joshi%2C+A">A. Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Fidalgo%2C+E">E. Fidalgo</a>, 
<a href="/search/cs?searchtype=author&query=Alegre%2C+E">E. Alegre</a>, 
<a href="/search/cs?searchtype=author&query=Alaiz-Rodriguez%2C+R">R. Alaiz-Rodriguez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we propose Ranksum, an approach for extractive text
summarization of single documents based on the rank fusion of four
multi-dimensional sentence features extracted for each sentence: topic
information, semantic content, significant keywords, and position. The Ranksum
obtains the sentence saliency rankings corresponding to each feature in an
unsupervised way followed by the weighted fusion of the four scores to rank the
sentences according to their significance. The scores are generated in
completely unsupervised way, and a labeled document set is required to learn
the fusion weights. Since we found that the fusion weights can generalize to
other datasets, we consider the Ranksum as an unsupervised approach. To
determine topic rank, we employ probabilistic topic models whereas semantic
information is captured using sentence embeddings. To derive rankings using
sentence embeddings, we utilize Siamese networks to produce abstractive
sentence representation and then we formulate a novel strategy to arrange them
in their order of importance. A graph-based strategy is applied to find the
significant keywords and related sentence rankings in the document. We also
formulate a sentence novelty measure based on bigrams, trigrams, and sentence
embeddings to eliminate redundant sentences from the summary. The ranks of all
the sentences computed for each feature are finally fused to get the final
score for each sentence in the document. We evaluate our approach on publicly
available summarization datasets CNN/DailyMail and DUC 2002. Experimental
results show that our approach outperforms other existing state-of-the-art
summarization methods.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05977" title="Abstract">arXiv:2402.05977</a> [<a href="/pdf/2402.05977" title="Download PDF">pdf</a>, <a href="/ps/2402.05977" title="Download PostScript">ps</a>, <a href="/format/2402.05977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tool wear monitoring using an online, automatic and low cost system  based on local texture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa-Ord%C3%A1s%2C+M+T">M. T. Garc&#xed;a-Ord&#xe1;s</a>, 
<a href="/search/cs?searchtype=author&query=Alegre-Guti%C3%A9rrez%2C+E">E. Alegre-Guti&#xe9;rrez</a>, 
<a href="/search/cs?searchtype=author&query=Alaiz-Rodr%C3%ADguez%2C+R">R. Alaiz-Rodr&#xed;guez</a>, 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez-Castro%2C+V">V. Gonz&#xe1;lez-Castro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work we propose a new online, low cost and fast approach based on
computer vision and machine learning to determine whether cutting tools used in
edge profile milling processes are serviceable or disposable based on their
wear level. We created a new dataset of 254 images of edge profile cutting
heads which is, to the best of our knowledge, the first publicly available
dataset with enough quality for this purpose. All the inserts were segmented
and their cutting edges were cropped, obtaining 577 images of cutting edges:
301 functional and 276 disposable. The proposed method is based on (1) dividing
the cutting edge image in different regions, called Wear Patches (WP), (2)
characterising each one as worn or serviceable using texture descriptors based
on different variants of Local Binary Patterns (LBP) and (3) determine, based
on the state of these WP, if the cutting edge (and, therefore, the tool) is
serviceable or disposable. We proposed and assessed five different patch
division configurations. The individual WP were classified by a Support Vector
Machine (SVM) with an intersection kernel. The best patch division
configuration and texture descriptor for the WP achieves an accuracy of 90.26%
in the detection of the disposable cutting edges. These results show a very
promising opportunity for automatic wear monitoring in edge profile milling
processes.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05978" title="Abstract">arXiv:2402.05978</a> [<a href="/pdf/2402.05978" title="Download PDF">pdf</a>, <a href="/ps/2402.05978" title="Download PostScript">ps</a>, <a href="/format/2402.05978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combining shape and contour features to improve tool wear monitoring in  milling processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa-Ord%C3%A1s%2C+M+T">M. T. Garc&#xed;a-Ord&#xe1;s</a>, 
<a href="/search/cs?searchtype=author&query=Alegre-Guti%C3%A9rrez%2C+E">E. Alegre-Guti&#xe9;rrez</a>, 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez-Castro%2C+V">V. Gonz&#xe1;lez-Castro</a>, 
<a href="/search/cs?searchtype=author&query=Alaiz-Rodr%C3%ADguez%2C+R">R. Alaiz-Rodr&#xed;guez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, a new system based on combinations of a shape descriptor and a
contour descriptor has been proposed for classifying inserts in milling
processes according to their wear level following a computer vision based
approach. To describe the wear region shape we have proposed a new descriptor
called ShapeFeat and its contour has been characterized using the method
BORCHIZ that, to the best of our knowledge, achieves the best performance for
tool wear monitoring following a computer vision-based approach. Results show
that the combination of BORCHIZ with ShapeFeat using a late fusion method
improves the classification performance significantly, obtaining an accuracy of
91.44% in the binary classification (i.e. the classification of the wear as
high or low) and 82.90% using three target classes (i.e. classification of the
wear as high, medium or low). These results outperform the ones obtained by
both descriptors used on their own, which achieve accuracies of 88.70 and
80.67% for two and three classes, respectively, using ShapeFeat and 87.06 and
80.24% with B-ORCHIZ. This study yielded encouraging results for the
manufacturing community in order to classify automatically the inserts in terms
of their wear for milling processes.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05979" title="Abstract">arXiv:2402.05979</a> [<a href="/pdf/2402.05979" title="Download PDF">pdf</a>, <a href="/format/2402.05979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Standardization of Behavioral Use Clauses and Their Adoption for  Responsible Licensing of AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McDuff%2C+D">Daniel McDuff</a>, 
<a href="/search/cs?searchtype=author&query=Korjakow%2C+T">Tim Korjakow</a>, 
<a href="/search/cs?searchtype=author&query=Cambo%2C+S">Scott Cambo</a>, 
<a href="/search/cs?searchtype=author&query=Benjamin%2C+J+J">Jesse Josua Benjamin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jenny Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jernite%2C+Y">Yacine Jernite</a>, 
<a href="/search/cs?searchtype=author&query=Ferrandis%2C+C+M">Carlos Mu&#xf1;oz Ferrandis</a>, 
<a href="/search/cs?searchtype=author&query=Gokaslan%2C+A">Aaron Gokaslan</a>, 
<a href="/search/cs?searchtype=author&query=Tarkowski%2C+A">Alek Tarkowski</a>, 
<a href="/search/cs?searchtype=author&query=Lindley%2C+J">Joseph Lindley</a>, 
<a href="/search/cs?searchtype=author&query=Cooper%2C+A+F">A. Feder Cooper</a>, 
<a href="/search/cs?searchtype=author&query=Contractor%2C+D">Danish Contractor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Growing concerns over negligent or malicious uses of AI have increased the
appetite for tools that help manage the risks of the technology. In 2018,
licenses with behaviorial-use clauses (commonly referred to as Responsible AI
Licenses) were proposed to give developers a framework for releasing AI assets
while specifying their users to mitigate negative applications. As of the end
of 2023, on the order of 40,000 software and model repositories have adopted
responsible AI licenses licenses. Notable models licensed with behavioral use
clauses include BLOOM (language) and LLaMA2 (language), Stable Diffusion
(image), and GRID (robotics). This paper explores why and how these licenses
have been adopted, and why and how they have been adapted to fit particular use
cases. We use a mixed-methods methodology of qualitative interviews, clustering
of license clauses, and quantitative analysis of license adoption. Based on
this evidence we take the position that responsible AI licenses need
standardization to avoid confusing users or diluting their impact. At the same
time, customization of behavioral restrictions is also appropriate in some
contexts (e.g., medical domains). We advocate for ``standardized
customization'' that can meet users' needs and can be supported via tooling.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05980" title="Abstract">arXiv:2402.05980</a> [<a href="/pdf/2402.05980" title="Download PDF">pdf</a>, <a href="/format/2402.05980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do Large Code Models Understand Programming Concepts? A Black-box  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hooda%2C+A">Ashish Hooda</a>, 
<a href="/search/cs?searchtype=author&query=Christodorescu%2C+M">Mihai Christodorescu</a>, 
<a href="/search/cs?searchtype=author&query=Allamanis%2C+M">Miltos Allamanis</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+A">Aaron Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Fawaz%2C+K">Kassem Fawaz</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+S">Somesh Jha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
<p class="mathjax">Large Language Models' success on text generation has also made them better
at code generation and coding tasks. While a lot of work has demonstrated their
remarkable performance on tasks such as code completion and editing, it is
still unclear as to why. We help bridge this gap by exploring to what degree
auto-regressive models understand the logical constructs of the underlying
programs. We propose Counterfactual Analysis for Programming Concept Predicates
(CACP) as a counterfactual testing framework to evaluate whether Large Code
Models understand programming concepts. With only black-box access to the
model, we use CACP to evaluate ten popular Large Code Models for four different
programming concepts. Our findings suggest that current models lack
understanding of concepts such as data flow and control flow.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05981" title="Abstract">arXiv:2402.05981</a> [<a href="/pdf/2402.05981" title="Download PDF">pdf</a>, <a href="/format/2402.05981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Impact of In-Browser Deep Learning Inference on Quality of  User Experience and Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qipeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shiqi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenpeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanchun Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Aoyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+T">Ting Cao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuanzhe Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Performance (cs.PF)

</div>
<p class="mathjax">Deep Learning (DL) is increasingly being integrated into Web applications
through a method known as "in-browser inference", where the DL processes occur
directly within Web browsers. However, the actual performance of this method
and its effect on user experience quality (QoE) is not well-understood. This
gap in knowledge necessitates new forms of QoE measurement, going beyond
traditional metrics such as page load time. To address this, we conducted the
first extensive performance evaluation of in-browser inference. We introduced
new metrics for this purpose: responsiveness, smoothness, and inference
accuracy.
<br />Our thorough study included 9 widely-used DL models and tested them across 50
popular PC Web browsers. The findings show a significant latency issue with
in-browser inference: it's on average 16.9 times slower on CPU and 4.9 times
slower on GPU than native inference methods. Several factors contribute to this
latency, including underused hardware instruction sets, inherent delays in the
runtime environment, resource competition within the browser, and
inefficiencies in software libraries and GPU abstractions.
<br />Moreover, in-browser inference demands a lot of memory, sometimes up to 334.6
times more than the size of the DL models themselves. This excessive memory
usage is partly due to suboptimal memory management. Additionally, we noticed
that in-browser inference increases the time it takes for graphical user
interface (GUI) components to load in web browsers by a significant 67.2\%,
which severely impacts the overall QoE for users of web applications that
depend on this technology.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06004" title="Abstract">arXiv:2402.06004</a> [<a href="/pdf/2402.06004" title="Download PDF">pdf</a>, <a href="/format/2402.06004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory-Efficient Vision Transformers: An Activation-Aware Mixed-Rank  Compression Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azizi%2C+S">Seyedarmin Azizi</a>, 
<a href="/search/cs?searchtype=author&query=Nazemi%2C+M">Mahdi Nazemi</a>, 
<a href="/search/cs?searchtype=author&query=Pedram%2C+M">Massoud Pedram</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">As Vision Transformers (ViTs) increasingly set new benchmarks in computer
vision, their practical deployment on inference engines is often hindered by
their significant memory bandwidth and (on-chip) memory footprint requirements.
This paper addresses this memory limitation by introducing an activation-aware
model compression methodology that uses selective low-rank weight tensor
approximations of different layers to reduce the parameter count of ViTs. The
key idea is to decompose the weight tensors into a sum of two
parameter-efficient tensors while minimizing the error between the product of
the input activations with the original weight tensor and the product of the
input activations with the approximate tensor sum. This approximation is
further refined by adopting an efficient layer-wise error compensation
technique that uses the gradient of the layer's output loss. The combination of
these techniques achieves excellent results while it avoids being trapped in a
shallow local minimum early in the optimization process and strikes a good
balance between the model compression and output accuracy. Notably, the
presented method significantly reduces the parameter count of DeiT-B by 60%
with less than 1% accuracy drop on the ImageNet dataset, overcoming the usual
accuracy degradation seen in low-rank approximations. In addition to this, the
presented compression technique can compress large DeiT/ViT models to have
about the same model size as smaller DeiT/ViT variants while yielding up to
1.8% accuracy gain. These results highlight the efficacy of our approach,
presenting a viable solution for embedding ViTs in memory-constrained
environments without compromising their performance.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06010" title="Abstract">arXiv:2402.06010</a> [<a href="/pdf/2402.06010" title="Download PDF">pdf</a>, <a href="/format/2402.06010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NPSVC++: Nonparallel Classifiers Encounter Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Z">Zhihui Lai</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+G">Guangfei Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper focuses on a specific family of classifiers called nonparallel
support vector classifiers (NPSVCs). Different from typical classifiers, the
training of an NPSVC involves the minimization of multiple objectives,
resulting in the potential concerns of feature suboptimality and class
dependency. Consequently, no effective learning scheme has been established to
improve NPSVCs' performance through representation learning, especially deep
learning. To break this bottleneck, we develop NPSVC++ based on multi-objective
optimization, enabling the end-to-end learning of NPSVC and its features. By
pursuing Pareto optimality, NPSVC++ theoretically ensures feature optimality
across classes, hence effectively overcoming the two issues above. A general
learning procedure via duality optimization is proposed, based on which we
provide two applicable instances, K-NPSVC++ and D-NPSVC++. The experiments show
their superiority over the existing methods and verify the efficacy of NPSVC++.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06011" title="Abstract">arXiv:2402.06011</a> [<a href="/pdf/2402.06011" title="Download PDF">pdf</a>, <a href="/format/2402.06011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Antenna system for trilateral drone precise vertical landing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ara%C3%B1a-Pulido%2C+V">V&#xed;ctor Ara&#xf1;a-Pulido</a>, 
<a href="/search/eess?searchtype=author&query=Jim%C3%A9nez-Ygu%C3%A1cel%2C+E">Eugenio Jim&#xe9;nez-Ygu&#xe1;cel</a>, 
<a href="/search/eess?searchtype=author&query=Cabrera-Almeida%2C+F">Francisco Cabrera-Almeida</a>, 
<a href="/search/eess?searchtype=author&query=Quintana-Morales%2C+P">Pedro Quintana-Morales</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been accepted by IEEE Transactions on Instrumentation and Measurement, vol. 71, pp. 1-8, 2022
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Instrumentation and Measurement, vol. 71, pp.
  1-8, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This article presents a radio frequency system that can be used to perform
precise vertical landings of drones. The system is based on the three-way phase
shift detection of a signal transmitted from the landing point. The antenna
system is designed by taking into account parameters such as landing tracking
area, analog-to-digital converter (ADC) resolution, phase detector output
range, antenna polarization, and the effect of antenna axial ratio. The
fabricated prototype consists of a landing point antenna that transmits a
signal at 2.46 GHz, as well as a drone triantenna system that includes a phase
shift detection circuitry, ADC, and a simple control program that provides the
correction instructions for landing. The prototype provides an averaged output
data rate (ODR) suitable for landing maneuvers (&gt;300 Hz). A simple system
calibration procedure (detector output zeroing) is performed by aligning the
antenna system. The measurements performed at different altitudes demonstrate
both the correct operation of the proposed solution and its viability as an
instrument for precision vertical landings.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06012" title="Abstract">arXiv:2402.06012</a> [<a href="/pdf/2402.06012" title="Download PDF">pdf</a>, <a href="/format/2402.06012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balancing a 3D Inverted Pendulum using Remote Magnetic Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zughaibi%2C+J">Jasan Zughaibi</a>, 
<a href="/search/eess?searchtype=author&query=Nelson%2C+B+J">Bradley J. Nelson</a>, 
<a href="/search/eess?searchtype=author&query=Muehlebach%2C+M">Michael Muehlebach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Remote magnetic manipulation offers wireless control over magnetic objects,
which has important medical applications, such as targeted drug delivery and
minimally invasive surgeries. Magnetic manipulation systems are categorized
into systems using permanent magnets and systems based on electromagnets.
Electro-Magnetic Navigation Systems (eMNSs) are believed to have a superior
actuation bandwidth, facilitating trajectory tracking and disturbance
rejection. This greatly expands the range of potential medical applications and
includes even dynamic environments as encountered in cardiovascular
interventions. In order to highlight the dynamic capabilities of eMNSs, we
successfully stabilize a (non-magnetic) inverted pendulum on the tip of a
magnetically driven arm. Our method employs a model-based design approach,
where we capture the dynamics that describe the interaction of the pendulum
system and the magnetic field through Lagrangian mechanics. Using system
identification we estimate the system parameters, the actuation bandwidth, and
characterize the system's nonlinearity. We design a state-feedback controller
to stabilize the inherently unstable dynamics, and compensate for errors
arising from the calibration of the magnetic field and the angle measurement
system. Additionally, we integrate an iterative learning control scheme that
allows us to accurately track non-equilibrium trajectories while concurrently
maintaining stability of the inverted pendulum. To our knowledge, this is the
first effort to stabilize a 3D inverted pendulum through remote magnetic
manipulation.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06013" title="Abstract">arXiv:2402.06013</a> [<a href="/pdf/2402.06013" title="Download PDF">pdf</a>, <a href="/format/2402.06013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Refactor this Code? An Exploratory Study on Developer-ChatGPT  Refactoring Conversations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=AlOmar%2C+E+A">Eman Abdullah AlOmar</a>, 
<a href="/search/cs?searchtype=author&query=Venkatakrishnan%2C+A">Anushkrishna Venkatakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Mkaouer%2C+M+W">Mohamed Wiem Mkaouer</a>, 
<a href="/search/cs?searchtype=author&query=Newman%2C+C+D">Christian D. Newman</a>, 
<a href="/search/cs?searchtype=author&query=Ouni%2C+A">Ali Ouni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Large Language Models (LLMs), like ChatGPT, have gained widespread popularity
and usage in various software engineering tasks, including refactoring,
testing, code review, and program comprehension. Despite recent studies delving
into refactoring documentation in commit messages, issues, and code review,
little is known about how developers articulate their refactoring needs when
interacting with ChatGPT. In this paper, our goal is to explore conversations
between developers and ChatGPT related to refactoring to better understand how
developers identify areas for improvement in code and how ChatGPT addresses
developers' needs. Our approach relies on text mining refactoring-related
conversations from 17,913 ChatGPT prompts and responses, and investigating
developers' explicit refactoring intention. Our results reveal that (1)
developer-ChatGPT conversations commonly involve generic and specific
terms/phrases; (2) developers often make generic refactoring requests, while
ChatGPT typically includes the refactoring intention; and (3) various learning
settings when prompting ChatGPT in the context of refactoring. We envision that
our findings contribute to a broader understanding of the collaboration between
developers and AI models, in the context of code refactoring, with implications
for model improvement, tool development, and best practices in software
engineering.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06014" title="Abstract">arXiv:2402.06014</a> [<a href="/pdf/2402.06014" title="Download PDF">pdf</a>, <a href="/format/2402.06014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trustful Coopetitive Infrastructures for the New Space Exploration Era
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baima%2C+R+L">Renan Lima Baima</a> (1), 
<a href="/search/cs?searchtype=author&query=Chovet%2C+L">Lo&#xef;ck Chovet</a> (2), 
<a href="/search/cs?searchtype=author&query=Hartwich%2C+E">Eduard Hartwich</a> (1), 
<a href="/search/cs?searchtype=author&query=Bera%2C+A">Abhishek Bera</a> (2), 
<a href="/search/cs?searchtype=author&query=Sedlmeir%2C+J">Johannes Sedlmeir</a> (1), 
<a href="/search/cs?searchtype=author&query=Fridgen%2C+G">Gilbert Fridgen</a> (1), 
<a href="/search/cs?searchtype=author&query=Olivares-Mendez%2C+M+A">Miguel Angel Olivares-Mendez</a> (2) ((1) FINATRAX - Digital Financial Services and Cross-Organisational Digital Transformations, (2) SpaceR - Space Robotics, SnT - Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures, accepted for conference (SAC24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computational Engineering, Finance, and Science (cs.CE); Multiagent Systems (cs.MA); Software Engineering (cs.SE); Systems and Control (eess.SY)

</div>
<p class="mathjax">In the new space economy, space agencies, large enterprises, and start-ups
aim to launch space multi-robot systems (MRS) for various in-situ resource
utilization (ISRU) purposes, such as mapping, soil evaluation, and utility
provisioning. However, these stakeholders' competing economic interests may
hinder effective collaboration on a centralized digital platform. To address
this issue, neutral and transparent infrastructures could facilitate
coordination and value exchange among heterogeneous space MRS. While related
work has expressed legitimate concerns about the technical challenges
associated with blockchain use in space, we argue that weighing its potential
economic benefits against its drawbacks is necessary. This paper presents a
novel architectural framework and a comprehensive set of requirements for
integrating blockchain technology in MRS, aiming to enhance coordination and
data integrity in space exploration missions. We explored distributed ledger
technology (DLT) to design a non-proprietary architecture for heterogeneous MRS
and validated the prototype in a simulated lunar environment. The analyses of
our implementation suggest global ISRU efficiency improvements for map
exploration, compared to a corresponding group of individually acting robots,
and that fostering a coopetitive environment may provide additional revenue
opportunities for stakeholders.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06015" title="Abstract">arXiv:2402.06015</a> [<a href="/pdf/2402.06015" title="Download PDF">pdf</a>, <a href="/format/2402.06015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Visual Culture Awareness in GPT-4V: A Comprehensive Probing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenyan Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yifei Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Hershcovich%2C+D">Daniel Hershcovich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in process
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Pretrained large Vision-Language models have drawn considerable interest in
recent years due to their remarkable performance. Despite considerable efforts
to assess these models from diverse perspectives, the extent of visual cultural
awareness in the state-of-the-art GPT-4V model remains unexplored. To tackle
this gap, we extensively probed GPT-4V using the MaRVL benchmark dataset,
aiming to investigate its capabilities and limitations in visual understanding
with a focus on cultural aspects. Specifically, we introduced three visual
related tasks, i.e. caption classification, pairwise captioning, and culture
tag selection, to systematically delve into fine-grained visual cultural
evaluation. Experimental results indicate that GPT-4V excels at identifying
cultural concepts but still exhibits weaker performance in low-resource
languages, such as Tamil and Swahili. Notably, through human evaluation, GPT-4V
proves to be more culturally relevant in image captioning tasks than the
original MaRVL human annotations, suggesting a promising solution for future
visual cultural benchmark construction.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06018" title="Abstract">arXiv:2402.06018</a> [<a href="/pdf/2402.06018" title="Download PDF">pdf</a>, <a href="/format/2402.06018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A versatile robotic hand with 3D perception, force sensing for  autonomous manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Correll%2C+N">Nikolaus Correll</a>, 
<a href="/search/cs?searchtype=author&query=Kriegman%2C+D">Dylan Kriegman</a>, 
<a href="/search/cs?searchtype=author&query=Otto%2C+S">Stephen Otto</a>, 
<a href="/search/cs?searchtype=author&query=Watson%2C+J">James Watson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> RSS Workshop on Perception and Manipulation Challenges for Warehouse Automation, Daejeon, Korea
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We describe a force-controlled robotic gripper with built-in tactile and 3D
perception. We also describe a complete autonomous manipulation pipeline
consisting of object detection, segmentation, point cloud processing,
force-controlled manipulation, and symbolic (re)-planning. The design
emphasizes versatility in terms of applications, manufacturability, use of
commercial off-the-shelf parts, and open-source software. We validate the
design by characterizing force control (achieving up to 32N, controllable in
steps of 0.08N), force measurement, and two manipulation demonstrations:
assembly of the Siemens gear assembly problem, and a sensor-based stacking task
requiring replanning. These demonstrate robust execution of long sequences of
sensor-based manipulation tasks, which makes the resulting platform a solid
foundation for researchers in task-and-motion planning, educators, and quick
prototyping of household, industrial and warehouse automation tasks.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06019" title="Abstract">arXiv:2402.06019</a> [<a href="/pdf/2402.06019" title="Download PDF">pdf</a>, <a href="/format/2402.06019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Checking the Sufficiently Scattered Condition using a Global Non-Convex  Optimization Software
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gillis%2C+N">Nicolas Gillis</a>, 
<a href="/search/cs?searchtype=author&query=Luce%2C+R">Robert Luce</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, code available from <a href="https://gitlab.com/ngillis/check-ssc">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">The sufficiently scattered condition (SSC) is a key condition in the study of
identifiability of various matrix factorization problems, including
nonnegative, minimum-volume, symmetric, simplex-structured, and polytopic
matrix factorizations. The SSC allows one to guarantee that the computed matrix
factorization is unique/identifiable, up to trivial ambiguities. However, this
condition is NP-hard to check in general. In this paper, we show that it can
however be checked in a reasonable amount of time in realistic scenarios, when
the factorization rank is not too large. This is achieved by formulating the
problem as a non-convex quadratic optimization problem over a bounded set. We
use the global non-convex optimization software Gurobi, and showcase the
usefulness of this code on synthetic data sets and on real-world hyperspectral
images.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06020" title="Abstract">arXiv:2402.06020</a> [<a href="/pdf/2402.06020" title="Download PDF">pdf</a>, <a href="/format/2402.06020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Active Teaching Methodology for Learning Development: A  Self-assessment Case Study Report in Computer Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baima%2C+R+L">Renan Lima Baima</a> (1 and 4), 
<a href="/search/cs?searchtype=author&query=Caetano%2C+T+M+B">Tiago Miguel Barao Caetano</a> (2), 
<a href="/search/cs?searchtype=author&query=Lima%2C+A+C+O">Ana Carolina Oliveira Lima</a> (3 and 4), 
<a href="/search/cs?searchtype=author&query=Leal%2C+E+O+L">Emilia Oliveira Lima Leal</a> (5), 
<a href="/search/cs?searchtype=author&query=Candeias%2C+T+M+P">Tiago Miguel Pereira Candeias</a> (3), 
<a href="/search/cs?searchtype=author&query=Rebou%C3%A7as%2C+S+M+D+P">Silvia Maria Dias Pedro Rebou&#xe7;as</a> (3 and 6) ((1) SnT - Interdisciplinary Centre for Security, Reliability and Trust / FINATRAX - Digital Financial Services and Cross-Organisational Digital Transformations, University of Luxembourg, (2) Instituto Superior Manuel Teixeira Gomes, (3) COPELABS, Lusofona University, (4) CICARI - Innovation Centre for Industrial Control, Automation and Robotics, (5) Facultad de Humanidades y Artes - Escuela de Posgrado, Universidad Nacional de Ros&#xe1;rio, (6) CEAUL, University of Lisbon)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages, 2 figures, accepted for conference (SAC24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The primary objective is to emphasize the merits of active methodologies and
cross-disciplinary curricula in Requirement Engineering. This direction
promises a holistic and applied trajectory for Computer Engineering education,
supported by the outcomes of our case study, where artifact-centric learning
proved effective, with 73% of students achieving the highest grade.
Self-assessments further corroborated academic excellence, emphasizing
students' engagement in skill enhancement and knowledge acquisition.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06021" title="Abstract">arXiv:2402.06021</a> [<a href="/pdf/2402.06021" title="Download PDF">pdf</a>, <a href="/format/2402.06021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-Shot Coding over General Noisy Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanxiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C+T">Cheuk Ting Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We present a unified one-shot coding framework designed for communication and
compression of messages among multiple nodes across a general acyclic noisy
network. Our setting can be seen as a one-shot version of the acyclic discrete
memoryless network studied by Lee and Chung, and noisy network coding studied
by Lim, Kim, El Gamal and Chung. We design a proof technique, called the
exponential process refinement lemma, that is rooted in the Poisson matching
lemma by Li and Anantharam, and can significantly simplify the analyses of
one-shot coding over multi-hop networks. Our one-shot coding theorem not only
recovers a wide range of existing asymptotic results, but also yields novel
one-shot achievability results in different multi-hop network information
theory problems. In a broader context, our framework provides a unified
one-shot bound applicable to any combination of source coding, channel coding
and coding for computing problems.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06023" title="Abstract">arXiv:2402.06023</a> [<a href="/pdf/2402.06023" title="Download PDF">pdf</a>, <a href="/format/2402.06023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decision Theory-Guided Deep Reinforcement Learning for Fast Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Zelin Wan</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+J">Jin-Hee Cho</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Mu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Anwar%2C+A+H">Ahmed H. Anwar</a>, 
<a href="/search/cs?searchtype=author&query=Kamhoua%2C+C">Charles Kamhoua</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+M+P">Munindar P. Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">This paper introduces a novel approach, Decision Theory-guided Deep
Reinforcement Learning (DT-guided DRL), to address the inherent cold start
problem in DRL. By integrating decision theory principles, DT-guided DRL
enhances agents' initial performance and robustness in complex environments,
enabling more efficient and reliable convergence during learning. Our
investigation encompasses two primary problem contexts: the cart pole and maze
navigation challenges. Experimental results demonstrate that the integration of
decision theory not only facilitates effective initial guidance for DRL agents
but also promotes a more structured and informed exploration strategy,
particularly in environments characterized by large and intricate state spaces.
The results of experiment demonstrate that DT-guided DRL can provide
significantly higher rewards compared to regular DRL. Specifically, during the
initial phase of training, the DT-guided DRL yields up to an 184% increase in
accumulated reward. Moreover, even after reaching convergence, it maintains a
superior performance, ending with up to 53% more reward than standard DRL in
large maze problems. DT-guided DRL represents an advancement in mitigating a
fundamental challenge of DRL by leveraging functions informed by human
(designer) knowledge, setting a foundation for further research in this
promising interdisciplinary domain.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06025" title="Abstract">arXiv:2402.06025</a> [<a href="/pdf/2402.06025" title="Download PDF">pdf</a>, <a href="/format/2402.06025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Doing Experiments and Revising Rules with Natural Language and  Probabilistic Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piriyakulkij%2C+T">Top Piriyakulkij</a>, 
<a href="/search/cs?searchtype=author&query=Ellis%2C+K">Kevin Ellis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">We build a computational model of how humans actively infer hidden rules by
doing experiments. The basic principles behind the model is that, even if the
rule is deterministic, the learner considers a broader space of fuzzy
probabilistic rules, which it represents in natural language, and updates its
hypotheses online after each experiment according to approximately Bayesian
principles. In the same framework we also model experiment design according to
information-theoretic criteria. We find that the combination of these three
principles -- explicit hypotheses, probabilistic rules, and online updates --
can explain human performance on a Zendo-style task, and that removing any of
these components leaves the model unable to account for the data.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06030" title="Abstract">arXiv:2402.06030</a> [<a href="/pdf/2402.06030" title="Download PDF">pdf</a>, <a href="/format/2402.06030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Game-theoretic Counterfactual Explanation for Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chhablani%2C+C">Chirag Chhablani</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Sarthak Jain</a>, 
<a href="/search/cs?searchtype=author&query=Channesh%2C+A">Akshay Channesh</a>, 
<a href="/search/cs?searchtype=author&query=Kash%2C+I+A">Ian A. Kash</a>, 
<a href="/search/cs?searchtype=author&query=Medya%2C+S">Sourav Medya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WWW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph Neural Networks (GNNs) have been a powerful tool for node
classification tasks in complex networks. However, their decision-making
processes remain a black-box to users, making it challenging to understand the
reasoning behind their predictions. Counterfactual explanations (CFE) have
shown promise in enhancing the interpretability of machine learning models.
Prior approaches to compute CFE for GNNS often are learning-based approaches
that require training additional graphs. In this paper, we propose a
semivalue-based, non-learning approach to generate CFE for node classification
tasks, eliminating the need for any additional training. Our results reveals
that computing Banzhaf values requires lower sample complexity in identifying
the counterfactual explanations compared to other popular methods such as
computing Shapley values. Our empirical evidence indicates computing Banzhaf
values can achieve up to a fourfold speed up compared to Shapley values. We
also design a thresholding method for computing Banzhaf values and show
theoretical and empirical results on its robustness in noisy environments,
making it superior to Shapley values. Furthermore, the thresholded Banzhaf
values are shown to enhance efficiency without compromising the quality (i.e.,
fidelity) in the explanations in three popular graph datasets.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06031" title="Abstract">arXiv:2402.06031</a> [<a href="/pdf/2402.06031" title="Download PDF">pdf</a>, <a href="/format/2402.06031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An operator learning perspective on parameter-to-observable maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+D+Z">Daniel Zhengyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Nelsen%2C+N+H">Nicholas H. Nelsen</a>, 
<a href="/search/cs?searchtype=author&query=Trautner%2C+M">Margaret Trautner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 58 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">Computationally efficient surrogates for parametrized physical models play a
crucial role in science and engineering. Operator learning provides data-driven
surrogates that map between function spaces. However, instead of full-field
measurements, often the available data are only finite-dimensional
parametrizations of model inputs or finite observables of model outputs.
Building off of Fourier Neural Operators, this paper introduces the Fourier
Neural Mappings (FNMs) framework that is able to accommodate such
finite-dimensional inputs and outputs. The paper develops universal
approximation theorems for the method. Moreover, in many applications the
underlying parameter-to-observable (PtO) map is defined implicitly through an
infinite-dimensional operator, such as the solution operator of a partial
differential equation. A natural question is whether it is more data-efficient
to learn the PtO map end-to-end or first learn the solution operator and
subsequently compute the observable from the full-field solution. A theoretical
analysis of Bayesian nonparametric regression of linear functionals, which is
of independent interest, suggests that the end-to-end approach can actually
have worse sample complexity. Extending beyond the theory, numerical results
for the FNM approximation of three nonlinear PtO maps demonstrate the benefits
of the operator learning perspective that this paper adopts.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06034" title="Abstract">arXiv:2402.06034</a> [<a href="/pdf/2402.06034" title="Download PDF">pdf</a>, <a href="/ps/2402.06034" title="Download PostScript">ps</a>, <a href="/format/2402.06034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Predictive AI in Physical Design Flows with Mini Pixel Batch  Gradient Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haoyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Agnesina%2C+A">Anthony Agnesina</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Haoxing Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures, preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Exploding predictive AI has enabled fast yet effective evaluation and
decision-making in modern chip physical design flows. State-of-the-art
frameworks typically include the objective of minimizing the mean square error
(MSE) between the prediction and the ground truth. We argue the averaging
effect of MSE induces limitations in both model training and deployment, and
good MSE behavior does not guarantee the capability of these models to assist
physical design flows which are likely sabotaged due to a small portion of
prediction error. To address this, we propose mini-pixel batch gradient descent
(MPGD), a plug-and-play optimization algorithm that takes the most informative
entries into consideration, offering probably faster and better convergence.
Experiments on representative benchmark suits show the significant benefits of
MPGD on various physical design prediction tasks using CNN or Graph-based
models.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06035" title="Abstract">arXiv:2402.06035</a> [<a href="/pdf/2402.06035" title="Download PDF">pdf</a>, <a href="/format/2402.06035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AntiCopyPaster 2.0: Whitebox just-in-time code duplicates extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=AlOmar%2C+E+A">Eman Abdullah AlOmar</a>, 
<a href="/search/cs?searchtype=author&query=Knobloch%2C+B">Benjamin Knobloch</a>, 
<a href="/search/cs?searchtype=author&query=Kain%2C+T">Thomas Kain</a>, 
<a href="/search/cs?searchtype=author&query=Kalish%2C+C">Christopher Kalish</a>, 
<a href="/search/cs?searchtype=author&query=Mkaouer%2C+M+W">Mohamed Wiem Mkaouer</a>, 
<a href="/search/cs?searchtype=author&query=Ouni%2C+A">Ali Ouni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">AntiCopyPaster is an IntelliJ IDEA plugin, implemented to detect and refactor
duplicate code interactively as soon as a duplicate is introduced. The plugin
only recommends the extraction of a duplicate when it is worth it. In contrast
to current Extract Method refactoring approaches, our tool seamlessly
integrates with the developer's workflow and actively provides recommendations
for refactorings. This work extends our tool to allow developers to customize
the detection rules, i.e., metrics, based on their needs and preferences. The
plugin and its source code are publicly available on GitHub at
https://github.com/refactorings/anti-copy-paster. The demonstration video can
be found on YouTube: https://youtu.be/ Y1sbfpds2Ms.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06036" title="Abstract">arXiv:2402.06036</a> [<a href="/pdf/2402.06036" title="Download PDF">pdf</a>, <a href="/format/2402.06036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing Trustful Cooperation Ecosystems is Key to the New Space  Exploration Era
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baima%2C+R+L">Renan Lima Baima</a> (1), 
<a href="/search/cs?searchtype=author&query=Chovet%2C+L">Lo&#xef;ck Chovet</a> (2), 
<a href="/search/cs?searchtype=author&query=Sedlmeir%2C+J">Johannes Sedlmeir</a> (1), 
<a href="/search/cs?searchtype=author&query=Fridgen%2C+G">Gilbert Fridgen</a> (1), 
<a href="/search/cs?searchtype=author&query=Olivares-Mendez%2C+M+A">Miguel Angel Olivares-Mendez</a> (2) ((1) FINATRAX - Digital Financial Services and Cross-Organisational Digital Transformations, (2) SpaceR - Space Robotics, SnT - Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure, 1 table, accepted for conference (ICSE24-NIER)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computers and Society (cs.CY); Multiagent Systems (cs.MA); Networking and Internet Architecture (cs.NI); Systems and Control (eess.SY)

</div>
<p class="mathjax">In the emerging space economy, autonomous robotic missions with specialized
goals such as mapping and mining are gaining traction, with agencies and
enterprises increasingly investing resources. Multirobot systems (MRS) research
has provided many approaches to establish control and communication layers to
facilitate collaboration from a technical perspective, such as granting more
autonomy to heterogeneous robotic groups through auction-based interactions in
mesh networks. However, stakeholders' competing economic interests often
prevent them from cooperating within a proprietary ecosystem. Related work
suggests that distributed ledger technology (DLT) might serve as a mechanism
for enterprises to coordinate workflows and trade services to explore space
resources through a transparent, reliable, non-proprietary digital platform. We
challenge this perspective by pointing to the core technical weaknesses of
blockchains, in particular, increased energy consumption, low throughput, and
full transparency through redundancy. Our objective is to advance the
discussion in a direction where the benefits of DLT from an economic
perspective are weighted against the drawbacks from a technical perspective. We
finally present a possible DLT-driven heterogeneous MRS for map exploration to
study the opportunities for economic collaboration and competitiveness.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06038" title="Abstract">arXiv:2402.06038</a> [<a href="/pdf/2402.06038" title="Download PDF">pdf</a>, <a href="/format/2402.06038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Approach to Prior Free Positive Unlabeled Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Acharya%2C+A">Anish Acharya</a>, 
<a href="/search/cs?searchtype=author&query=Sanghavi%2C+S">Sujay Sanghavi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Positive Unlabeled (PU) learning refers to the task of learning a binary
classifier given a few labeled positive samples, and a set of unlabeled samples
(which could be positive or negative). In this paper, we propose a novel PU
learning framework, that starts by learning a feature space through
pretext-invariant representation learning and then applies pseudo-labeling to
the unlabeled examples, leveraging the concentration property of the
embeddings. Overall, our proposed approach handily outperforms state-of-the-art
PU learning methods across several standard PU benchmark datasets, while not
requiring a-priori knowledge or estimate of class prior. Remarkably, our method
remains effective even when labeled data is scant, where most PU learning
algorithms falter. We also provide simple theoretical analysis motivating our
proposed algorithms and establish generalization guarantee for our approach.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06041" title="Abstract">arXiv:2402.06041</a> [<a href="/pdf/2402.06041" title="Download PDF">pdf</a>, <a href="/format/2402.06041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Prompt Response to the Demand for Automatic Gender-Neutral Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Savoldi%2C+B">Beatrice Savoldi</a>, 
<a href="/search/cs?searchtype=author&query=Piergentili%2C+A">Andrea Piergentili</a>, 
<a href="/search/cs?searchtype=author&query=Fucci%2C+D">Dennis Fucci</a>, 
<a href="/search/cs?searchtype=author&query=Negri%2C+M">Matteo Negri</a>, 
<a href="/search/cs?searchtype=author&query=Bentivogli%2C+L">Luisa Bentivogli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Gender-neutral translation (GNT) that avoids biased and undue binary
assumptions is a pivotal challenge for the creation of more inclusive
translation technologies. Advancements for this task in Machine Translation
(MT), however, are hindered by the lack of dedicated parallel data, which are
necessary to adapt MT systems to satisfy neutral constraints. For such a
scenario, large language models offer hitherto unforeseen possibilities, as
they come with the distinct advantage of being versatile in various (sub)tasks
when provided with explicit instructions. In this paper, we explore this
potential to automate GNT by comparing MT with the popular GPT-4 model. Through
extensive manual analyses, our study empirically reveals the inherent
limitations of current MT systems in generating GNTs and provides valuable
insights into the potential and challenges associated with prompting for
neutrality.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06043" title="Abstract">arXiv:2402.06043</a> [<a href="/pdf/2402.06043" title="Download PDF">pdf</a>, <a href="/format/2402.06043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MusicTraces: A collaborative music and paint activity for autistic  people
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bauer%2C+V">Valentin Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Padovano%2C+T">Tommaso Padovano</a>, 
<a href="/search/cs?searchtype=author&query=Gianotti%2C+M">Mattia Gianotti</a>, 
<a href="/search/cs?searchtype=author&query=Caslini%2C+G">Giacomo Caslini</a>, 
<a href="/search/cs?searchtype=author&query=Garzotto%2C+F">Franca Garzotto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Painting and music therapy approaches can help to foster social interaction
for autistic people. However, the tools sometimes lack of flexibility and fail
to keep people's attention. Unknowns also remain about the effect of combining
these approaches. Though, very few studies have investigated how Multisensory
Environments (MSEs) could help to address these issues. This paper presents the
design of a full-body music and painting activity called "MusicTraces" which
aims to foster collaboration between people with moderate to severe learning
disabilities and complex needs, and in particular autism, within an MSE. The
co-design process with caregivers and people neurodevelopmental conditions is
detailed, including a workshop, the initial design, remote iterations, and a
design critique.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06044" title="Abstract">arXiv:2402.06044</a> [<a href="/pdf/2402.06044" title="Download PDF">pdf</a>, <a href="/format/2402.06044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenToM: A Comprehensive Benchmark for Evaluating Theory-of-Mind  Reasoning Capabilities of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hainiu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Runcong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lixing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Jinhua Du</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yulan He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Neural Theory-of-Mind (N-ToM), machine's ability to understand and keep track
of the mental states of others, is pivotal in developing socially intelligent
agents. However, prevalent N-ToM benchmarks have several shortcomings,
including the presence of ambiguous and artificial narratives, absence of
personality traits and preferences, a lack of questions addressing characters'
psychological mental states, and limited diversity in the questions posed. In
response to these issues, we construct OpenToM, a new benchmark for assessing
N-ToM with (1) longer and clearer narrative stories, (2) characters with
explicit personality traits, (3) actions that are triggered by character
intentions, and (4) questions designed to challenge LLMs' capabilities of
modeling characters' mental states of both the physical and psychological
world. Using OpenToM, we reveal that state-of-the-art LLMs thrive at modeling
certain aspects of mental states in the physical world but fall short when
tracking characters' mental states in the psychological world.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06045" title="Abstract">arXiv:2402.06045</a> [<a href="/pdf/2402.06045" title="Download PDF">pdf</a>, <a href="/format/2402.06045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Direct Acquisition Optimization for Low-Budget Active Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhuokai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yibo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxin Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Active Learning (AL) has gained prominence in integrating data-intensive
machine learning (ML) models into domains with limited labeled data. However,
its effectiveness diminishes significantly when the labeling budget is low. In
this paper, we first empirically observe the performance degradation of
existing AL algorithms in the low-budget settings, and then introduce Direct
Acquisition Optimization (DAO), a novel AL algorithm that optimizes sample
selections based on expected true loss reduction. Specifically, DAO utilizes
influence functions to update model parameters and incorporates an additional
acquisition strategy to mitigate bias in loss estimation. This approach
facilitates a more accurate estimation of the overall error reduction, without
extensive computations or reliance on labeled data. Experiments demonstrate
DAO's effectiveness in low budget settings, outperforming state-of-the-arts
approaches across seven benchmarks.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06046" title="Abstract">arXiv:2402.06046</a> [<a href="/pdf/2402.06046" title="Download PDF">pdf</a>, <a href="/ps/2402.06046" title="Download PostScript">ps</a>, <a href="/format/2402.06046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anatomy of a Robotaxi Crash: Lessons from the Cruise Pedestrian Dragging  Mishap
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koopman%2C+P">Philip Koopman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">An October 2023 crash between a GM Cruise robotaxi and a pedestrian in San
Francisco resulted not only in a severe injury, but also dramatic upheaval at
that company that will likely have lasting effects throughout the industry. The
issues stem not just from the crash facts themselves, but also how Cruise
mishandled dealing with their robotaxi dragging a pedestrian under the vehicle
after the initial post-crash stop. A pair of external investigation reports
provide raw material describing the incident and critique the company response
from a regulatory interaction point of view, but did not include potential
safety recommendations in scope. We use that report material to highlight
specific facts and relationships between events by tying together different
pieces of the report material. We then explore safety lessons that might be
learned with regard to technology, operational safety practices, and
organizational reaction to incidents.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06047" title="Abstract">arXiv:2402.06047</a> [<a href="/pdf/2402.06047" title="Download PDF">pdf</a>, <a href="/format/2402.06047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent Mode-switching Framework for Teleoperation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kizilkaya%2C+B">Burak Kizilkaya</a>, 
<a href="/search/cs?searchtype=author&query=She%2C+C">Changyang She</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+G">Guodong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Imran%2C+M+A">Muhammad Ali Imran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 2024 IEEE International Conference on Robotics and Automation (ICRA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Teleoperation can be very difficult due to limited perception, high
communication latency, and limited degrees of freedom (DoFs) at the operator
side. Autonomous teleoperation is proposed to overcome this difficulty by
predicting user intentions and performing some parts of the task autonomously
to decrease the demand on the operator and increase the task completion rate.
However, decision-making for mode-switching is generally assumed to be done by
the operator, which brings an extra DoF to be controlled by the operator and
introduces extra mental demand. On the other hand, the communication
perspective is not investigated in the current literature, although
communication imperfections and resource limitations are the main bottlenecks
for teleoperation. In this study, we propose an intelligent mode-switching
framework by jointly considering mode-switching and communication systems. User
intention recognition is done at the operator side. Based on user intention
recognition, a deep reinforcement learning (DRL) agent is trained and deployed
at the operator side to seamlessly switch between autonomous and teleoperation
modes. A real-world data set is collected from our teleoperation testbed to
train both user intention recognition and DRL algorithms. Our results show that
the proposed framework can achieve up to 50% communication load reduction with
improved task completion probability.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06048" title="Abstract">arXiv:2402.06048</a> [<a href="/pdf/2402.06048" title="Download PDF">pdf</a>, <a href="/format/2402.06048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coherence-based Input Design for Sparse System Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Parsa%2C+J">Javad Parsa</a>, 
<a href="/search/eess?searchtype=author&query=Rojas%2C+C+R">Cristian R. Rojas</a>, 
<a href="/search/eess?searchtype=author&query=Hjalmarsson%2C+H">H&#xe5;kan Hjalmarsson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE Transactions on Automatic Control for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">The maximum absolute correlation between regressors, which is called mutual
coherence, plays an essential role in sparse estimation. A regressor matrix
whose columns are highly correlated may result from optimal input design, since
there is no constraint on the mutual coherence, so when this regressor is used
to estimate sparse parameter vectors of a system, it may yield a large
estimation error. This paper aims to tackle this issue for fixed denominator
models, which include Laguerre, Kautz, and generalized orthonormal basis
function expansion models, for example. The paper proposes an optimal input
design method where the achieved Fisher information matrix is fitted to the
desired Fisher matrix, together with a coordinate transformation designed to
make the regressors in the transformed coordinates have low mutual coherence.
The method can be used together with any sparse estimation method and in a
numerical study we show its potential for alleviating the problem of model
order selection when used in conjunction with, for example, classical methods
such as AIC and BIC.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06049" title="Abstract">arXiv:2402.06049</a> [<a href="/pdf/2402.06049" title="Download PDF">pdf</a>, <a href="/format/2402.06049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Limits of Large Language Models in Debating Humans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Flamino%2C+J">James Flamino</a>, 
<a href="/search/cs?searchtype=author&query=Modi%2C+M+S">Mohammed Shahid Modi</a>, 
<a href="/search/cs?searchtype=author&query=Szymanski%2C+B+K">Boleslaw K. Szymanski</a>, 
<a href="/search/cs?searchtype=author&query=Cross%2C+B">Brendan Cross</a>, 
<a href="/search/cs?searchtype=author&query=Mikolajczyk%2C+C">Colton Mikolajczyk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 6 figures, 3 tables, 21 pages of supplemental materials, 8 supplemental figures, 6 supplemental tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Applications (stat.AP)

</div>
<p class="mathjax">Large Language Models (LLMs) have shown remarkable promise in their ability
to interact proficiently with humans. Subsequently, their potential use as
artificial confederates and surrogates in sociological experiments involving
conversation is an exciting prospect. But how viable is this idea? This paper
endeavors to test the limits of current-day LLMs with a pre-registered study
integrating real people with LLM agents acting as people. The study focuses on
debate-based opinion consensus formation in three environments: humans only,
agents and humans, and agents only. Our goal is to understand how LLM agents
influence humans, and how capable they are in debating like humans. We find
that LLMs can blend in and facilitate human productivity but are less
convincing in debate, with their behavior ultimately deviating from human's. We
elucidate these primary failings and anticipate that LLMs must evolve further
before being viable debaters.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06053" title="Abstract">arXiv:2402.06053</a> [<a href="/pdf/2402.06053" title="Download PDF">pdf</a>, <a href="/format/2402.06053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Randomness Is All You Need: Semantic Traversal of Problem-Solution  Spaces with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sandholm%2C+T">Thomas Sandholm</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+S">Sayandev Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Huberman%2C+B+A">Bernardo A. Huberman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">We present a novel approach to exploring innovation problem and solution
domains using LLM fine-tuning with a custom idea database. By semantically
traversing the bi-directional problem and solution tree at different
temperature levels we achieve high diversity in solution edit distance while
still remaining close to the original problem statement semantically. In
addition to finding a variety of solutions to a given problem, this method can
also be used to refine and clarify the original problem statement. As further
validation of the approach, we implemented a proof-of-concept Slack bot to
serve as an innovation assistant.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06055" title="Abstract">arXiv:2402.06055</a> [<a href="/pdf/2402.06055" title="Download PDF">pdf</a>, <a href="/ps/2402.06055" title="Download PostScript">ps</a>, <a href="/format/2402.06055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gliding in extreme waters: Dynamic Modeling and Nonlinear Control of an  Agile Underwater Glider
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hanzhi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Mahmoudian%2C+N">Nina Mahmoudian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures, submitted to IFAC CAMS 2024. This version is processed in Word because arXiv would not accept tex-generated pdf and failed to process the tex files
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper describes the modeling of a custom-made underwater glider capable
of flexible maneuvers in constrained areas and proposes a control system. Due
to the lack of external actuators, underwater gliders can be greatly influenced
by environmental disturbance. In addition, the nonlinearity of the system
affects the motions during the transition between each flight segment. Here, a
data-driven parameter estimation experimental methodology is proposed to
identify the nonlinear dynamics model for our underwater glider using an
underwater motion capture system. Then, a nonlinear system controller is
designed based on Lyapunov function to overcome environmental disturbance,
potential modeling errors, and nonlinearity during flight state transitions.
The capability of lowering the impact of environmental disturbance is validated
in simulations. A hybrid control system applying PID controller to maintain
steady state flights and the proposed controller to switch between states is
also demonstrated by performing complex maneuvers in simulation. The proposed
control system can be applied to gliders for reliable navigation in dynamic
water areas such as fjords where the sea conditions may vary from calm to rough
seasonally.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06056" title="Abstract">arXiv:2402.06056</a> [<a href="/pdf/2402.06056" title="Download PDF">pdf</a>, <a href="/format/2402.06056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ActiveDP: Bridging Active Learning and Data Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+N">Naiqing Guan</a>, 
<a href="/search/cs?searchtype=author&query=Koudas%2C+N">Nick Koudas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by EDBT 2024 research track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Modern machine learning models require large labelled datasets to achieve
good performance, but manually labelling large datasets is expensive and
time-consuming. The data programming paradigm enables users to label large
datasets efficiently but produces noisy labels, which deteriorates the
downstream model's performance. The active learning paradigm, on the other
hand, can acquire accurate labels but only for a small fraction of instances.
In this paper, we propose ActiveDP, an interactive framework bridging active
learning and data programming together to generate labels with both high
accuracy and coverage, combining the strengths of both paradigms. Experiments
show that ActiveDP outperforms previous weak supervision and active learning
approaches and consistently performs well under different labelling budgets.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06059" title="Abstract">arXiv:2402.06059</a> [<a href="/pdf/2402.06059" title="Download PDF">pdf</a>, <a href="/format/2402.06059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact on Public Health Decision Making by Utilizing Big Data Without  Domain Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Miao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+S">Salman Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Mhasawade%2C+V">Vishwali Mhasawade</a>, 
<a href="/search/cs?searchtype=author&query=Chunara%2C+R">Rumi Chunara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">New data sources, and artificial intelligence (AI) methods to extract
information from them are becoming plentiful, and relevant to decision making
in many societal applications. An important example is street view imagery,
available in over 100 countries, and considered for applications such as
assessing built environment aspects in relation to community health outcomes.
Relevant to such uses, important examples of bias in the use of AI are evident
when decision-making based on data fails to account for the robustness of the
data, or predictions are based on spurious correlations. To study this risk, we
utilize 2.02 million GSV images along with health, demographic, and
socioeconomic data from New York City. Initially, we demonstrate that built
environment characteristics inferred from GSV labels at the intra-city level
may exhibit inadequate alignment with the ground truth. We also find that the
average individual-level behavior of physical inactivity significantly mediates
the impact of built environment features by census tract, as measured through
GSV. Finally, using a causal framework which accounts for these mediators of
environmental impacts on health, we find that altering 10% of samples in the
two lowest tertiles would result in a 4.17 (95% CI 3.84 to 4.55) or 17.2 (95%
CI 14.4 to 21.3) times bigger decrease on the prevalence of obesity or
diabetes, than the same proportional intervention on the number of crosswalks
by census tract. This work illustrates important issues of robustness and model
specification for informing effective allocation of interventions using new
data sources.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06062" title="Abstract">arXiv:2402.06062</a> [<a href="/pdf/2402.06062" title="Download PDF">pdf</a>, <a href="/ps/2402.06062" title="Download PostScript">ps</a>, <a href="/format/2402.06062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Peer Expectation in Robust Forecast Aggregation: The  Possibility/Impossibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+Y">Yuqing Kong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Statistics Theory (math.ST)

</div>
<p class="mathjax">Recently a growing literature study a new forecast aggregation setting where
each forecaster is additionally asked ``what's your expectation for the average
of other forecasters' forecasts?''. However, most theoretic results in this
setting focus on the scenarios where the additional second-order information
helps optimally aggregate the forecasts. Here we adopt an adversarial approach
and follow the robust forecast aggregation framework proposed by Arielia,
Babichenkoa, and Smorodinsky 2018. We delicately analyze the
possibility/impossibility of the new setting when there are two forecasters
that either are refinement-ordered or receive conditionally independent and
identically distributed (c.i.i.d.) signals. We also extend the setting to a
higher level of expectation setting where we can additionally ask ``what's your
expectation for the other forecaster's expectation for ...''. The results show
that in the above settings, the additional second-order information can
significantly improve the aggregation accuracy, and the higher the order, the
higher the improvement.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06064" title="Abstract">arXiv:2402.06064</a> [<a href="/pdf/2402.06064" title="Download PDF">pdf</a>, <a href="/format/2402.06064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formalizing Automated Market Makers in the Lean 4 Theorem Prover
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pusceddu%2C+D">Daniele Pusceddu</a>, 
<a href="/search/cs?searchtype=author&query=Bartoletti%2C+M">Massimo Bartoletti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Automated Market Makers (AMMs) are an integral component of the decentralized
finance (DeFi) ecosystem, as they allow users to exchange crypto-assets without
the need for trusted authorities or external price oracles. Although these
protocols are based on relatively simple mechanisms, e.g., to algorithmically
determine the exchange rate between crypto-assets, they give rise to complex
economic behaviours. This complexity is witnessed by the proliferation of
models that study their structural and economic properties. Currently, most of
theoretical results obtained on these models are supported by pen-and-paper
proofs. This work proposes a formalization of constant-product AMMs in the Lean
4 Theorem Prover. To demonstrate the utility of our model, we provide
mechanized proofs of key economic properties like arbitrage, that at the best
of our knowledge have only been proved by pen-and-paper before.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06067" title="Abstract">arXiv:2402.06067</a> [<a href="/pdf/2402.06067" title="Download PDF">pdf</a>, <a href="/format/2402.06067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Body Schema Acquisition through Active Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martinez-Cantin%2C+R">Ruben Martinez-Cantin</a>, 
<a href="/search/cs?searchtype=author&query=Lopes%2C+M">Manuel Lopes</a>, 
<a href="/search/cs?searchtype=author&query=Montesano%2C+L">Luis Montesano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Robotics and Automation (ICRA) 2010
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Published in proceedings of the IEEE ICRA 2010
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present an active learning algorithm for the problem of body schema
learning, i.e. estimating a kinematic model of a serial robot. The learning
process is done online using Recursive Least Squares (RLS) estimation, which
outperforms gradient methods usually applied in the literature. In addiction,
the method provides the required information to apply an active learning
algorithm to find the optimal set of robot configurations and observations to
improve the learning process. By selecting the most informative observations,
the proposed method minimizes the required amount of data. We have developed an
efficient version of the active learning algorithm to select the points in
real-time. The algorithms have been tested and compared using both simulated
environments and a real humanoid robot.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06068" title="Abstract">arXiv:2402.06068</a> [<a href="/pdf/2402.06068" title="Download PDF">pdf</a>, <a href="/ps/2402.06068" title="Download PostScript">ps</a>, <a href="/format/2402.06068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing a 3-role assignment is polynomial-time solvable on  complementary prisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castonguay%2C+D">Diane Castonguay</a>, 
<a href="/search/cs?searchtype=author&query=Dias%2C+E+S">Elis&#xe2;ngela S. Dias</a>, 
<a href="/search/cs?searchtype=author&query=Mesquita%2C+F+N">Fernanda N. Mesquita</a>, 
<a href="/search/cs?searchtype=author&query=Nascimento%2C+J+R">Julliano R. Nascimento</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">A $r$-role assignment of a simple graph $G$ is an assignment of $r$ distinct
roles to the vertices of $G$, such that two vertices with the same role have
the same set of roles assigned to related vertices. Furthermore, a specific
$r$-role assignment defines a role graph, in which the vertices are the
distinct $r$ roles, and there is an edge between two roles whenever there are
two related vertices in the graph $G$ that correspond to these roles. We
consider complementary prisms, which are graphs formed from the disjoint union
of the graph with its respective complement, adding the edges of a perfect
matching between their corresponding vertices. In this work, we characterize
the complementary prisms that do not admit a $3$-role assignment. We highlight
that all of them are complementary prisms of disconnected bipartite graphs.
Moreover, using our findings, we show that the problem of deciding whether a
complementary prism has a $3$-role assignment can be solved in polynomial time.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06071" title="Abstract">arXiv:2402.06071</a> [<a href="/pdf/2402.06071" title="Download PDF">pdf</a>, <a href="/format/2402.06071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Keyframer: Empowering Animation Design using Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tseng%2C+T">Tiffany Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+R">Ruijia Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Nichols%2C+J">Jeffrey Nichols</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Large language models (LLMs) have the potential to impact a wide range of
creative domains, but the application of LLMs to animation is underexplored and
presents novel challenges such as how users might effectively describe motion
in natural language. In this paper, we present Keyframer, a design tool for
animating static images (SVGs) with natural language. Informed by interviews
with professional animation designers and engineers, Keyframer supports
exploration and refinement of animations through the combination of prompting
and direct editing of generated output. The system also enables users to
request design variants, supporting comparison and ideation. Through a user
study with 13 participants, we contribute a characterization of user prompting
strategies, including a taxonomy of semantic prompt types for describing motion
and a 'decomposed' prompting style where users continually adapt their goals in
response to generated output.We share how direct editing along with prompting
enables iteration beyond one-shot prompting interfaces common in generative
tools today. Through this work, we propose how LLMs might empower a range of
audiences to engage with animation creation.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06073" title="Abstract">arXiv:2402.06073</a> [<a href="/pdf/2402.06073" title="Download PDF">pdf</a>, <a href="/ps/2402.06073" title="Download PostScript">ps</a>, <a href="/format/2402.06073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LightCAM: A Fast and Light Implementation of Context-Aware Masking based  D-Tdnn for Speaker Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+D">Di Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xianchen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Junfeng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiakai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Y">Yanjing Lei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenpeng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Traditional Time Delay Neural Networks (TDNN) have achieved state-of-the-art
performance at the cost of high computational complexity and slower inference
speed, making them difficult to implement in an industrial environment. The
Densely Connected Time Delay Neural Network (D-TDNN) with Context Aware Masking
(CAM) module has proven to be an efficient structure to reduce complexity while
maintaining system performance. In this paper, we propose a fast and
lightweight model, LightCAM, which further adopts a depthwise separable
convolution module (DSM) and uses multi-scale feature aggregation (MFA) for
feature fusion at different levels. Extensive experiments are conducted on
VoxCeleb dataset, the comparative results show that it has achieved an EER of
0.83 and MinDCF of 0.0891 in VoxCeleb1-O, which outperforms the other
mainstream speaker verification methods. In addition, complexity analysis
further demonstrates that the proposed architecture has lower computational
cost and faster inference speed.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06075" title="Abstract">arXiv:2402.06075</a> [<a href="/pdf/2402.06075" title="Download PDF">pdf</a>, <a href="/ps/2402.06075" title="Download PostScript">ps</a>, <a href="/format/2402.06075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Artificial Intelligence for Digital Wargaming in Support of  Decision-Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Black%2C+S">Scotty Black</a>, 
<a href="/search/cs?searchtype=author&query=Darken%2C+C">Christian Darken</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NATO STO-MP-MSG-207 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this unprecedented era of technology-driven transformation, it becomes
more critical than ever that we aggressively invest in developing robust
artificial intelligence (AI) for wargaming in support of decision-making. By
advancing AI-enabled systems and pairing these with human judgment, we will be
able to enhance all-domain awareness, improve the speed and quality of our
decision cycles, offer recommendations for novel courses of action, and more
rapidly counter our adversary's actions. It therefore becomes imperative that
we accelerate the development of AI to help us better address the complexity of
modern challenges and dilemmas that currently requires human intelligence and,
if possible, attempt to surpass human intelligence--not to replace humans, but
to augment and better inform human decision-making at machine speed. Although
deep reinforcement learning continues to show promising results in intelligent
agent behavior development for the long-horizon, complex tasks typically found
in combat modeling and simulation, further research is needed to enable the
scaling of AI to deal with these intricate and expansive state-spaces
characteristic of wargaming for either concept development, education, or
analysis. To help address this challenge, in our research, we are developing
and implementing a hierarchical reinforcement learning framework that includes
a multi-model approach and dimension-invariant observation abstractions.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06078" title="Abstract">arXiv:2402.06078</a> [<a href="/pdf/2402.06078" title="Download PDF">pdf</a>, <a href="/format/2402.06078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Mixture Models for Affordance Learning using Bayesian Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Os%C3%B3rio%2C+P">Pedro Os&#xf3;rio</a>, 
<a href="/search/cs?searchtype=author&query=Bernardino%2C+A">Alexandre Bernardino</a>, 
<a href="/search/cs?searchtype=author&query=Martinez-Cantin%2C+R">Ruben Martinez-Cantin</a>, 
<a href="/search/cs?searchtype=author&query=Santos-Victor%2C+J">Jos&#xe9; Santos-Victor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE/RSJ International Conference on Intelligent Robots and Systems 2010
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Published on the Proceedings of the IEEE/RSJ International
  Conference on Intelligent Robots and Systems 2010
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Affordances are fundamental descriptors of relationships between actions,
objects and effects. They provide the means whereby a robot can predict
effects, recognize actions, select objects and plan its behavior according to
desired goals. This paper approaches the problem of an embodied agent exploring
the world and learning these affordances autonomously from its sensory
experiences. Models exist for learning the structure and the parameters of a
Bayesian Network encoding this knowledge. Although Bayesian Networks are
capable of dealing with uncertainty and redundancy, previous work considered
complete observability of the discrete sensory data, which may lead to hard
errors in the presence of noise. In this paper we consider a probabilistic
representation of the sensors by Gaussian Mixture Models (GMMs) and explicitly
taking into account the probability distribution contained in each discrete
affordance concept, which can lead to a more correct learning.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06081" title="Abstract">arXiv:2402.06081</a> [<a href="/pdf/2402.06081" title="Download PDF">pdf</a>, <a href="/format/2402.06081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Primitive OBZCPs of Lengths up to 49
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kazakov%2C+P">Peter Kazakov</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zilong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Number Theory (math.NT)

</div>
<p class="mathjax">This paper aims to search for new primitive optimal and sub-optimal Odd
Binary Z-Complimentary Pairs (OBZCPs) for lengths up to 49. As an alternative
to the celebrated binary Golay complementary pairs, optimal OBZCPs are the best
almost-complementary sequence pairs having odd lengths. We introduce a computer
search algorithm with complexity $O(2^N)$, where $N$ denotes the sequence
length and then show optimal results for all $27 \le N \le 33$ and
$N=37,41,49$. For those sequence lengths (i.e., $N=35,39,43,45,47$) with no
optimal pairs, we show OBZCPs with largest zero-correlation zone (ZCZ) widths
(i.e., $Z$-optimal). Finally, based on the Pursley-Sarwate criterion, we
present a table of OBZCPs with smallest demerit factors in terms of the
combined auto-correlation and cross-correlation.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06082" title="Abstract">arXiv:2402.06082</a> [<a href="/pdf/2402.06082" title="Download PDF">pdf</a>, <a href="/format/2402.06082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SubGen: Token Generation in Sublinear Time and Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zandieh%2C+A">Amir Zandieh</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+I">Insu Han</a>, 
<a href="/search/cs?searchtype=author&query=Mirrokni%2C+V">Vahab Mirrokni</a>, 
<a href="/search/cs?searchtype=author&query=Karbasi%2C+A">Amin Karbasi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Despite the significant success of large language models (LLMs), their
extensive memory requirements pose challenges for deploying them in
long-context token generation. The substantial memory footprint of LLM decoders
arises from the necessity to store all previous tokens in the attention module,
a requirement imposed by key-value (KV) caching. In this work, our focus is on
developing an efficient compression technique for the KV cache. Empirical
evidence indicates a significant clustering tendency within key embeddings in
the attention module. Building on this key insight, we have devised a novel
caching method with sublinear complexity, employing online clustering on key
tokens and online $\ell_2$ sampling on values. The result is a provably
accurate and efficient attention decoding algorithm, termed SubGen. Not only
does this algorithm ensure a sublinear memory footprint and sublinear time
complexity, but we also establish a tight error bound for our approach.
Empirical evaluations on long-context question-answering tasks demonstrate that
SubGen significantly outperforms existing and state-of-the-art KV cache
compression methods in terms of performance and efficiency.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06083" title="Abstract">arXiv:2402.06083</a> [<a href="/pdf/2402.06083" title="Download PDF">pdf</a>, <a href="/format/2402.06083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to split a tera-polynomial
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Vigneron%2C+F">Fran&#xe7;ois Vigneron</a>, 
<a href="/search/math?searchtype=author&query=Mihalache%2C+N">Nicolae Mihalache</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Dynamical Systems (math.DS)

</div>
<p class="mathjax">This article presents a new algorithm to compute all the roots of two
families of polynomials that are of interest for the Mandelbrot set
$\mathcal{M}$ : the roots of those polynomials are respectively the parameters
$c\in\mathcal{M}$ associated with periodic critical dynamics for $f_c(z)=z^2+c$
(hyperbolic centers) or with pre-periodic dynamics (Misiurewicz-Thurston
parameters). The algorithm is based on the computation of discrete level lines
that provide excellent starting points for the Newton method. In practice, we
observe that these polynomials can be split in linear time of the degree.
<br />This article is paired with a code library \citelib{MLib} that implements
this algorithm. Using this library and about 723 000 core-hours on the HPC
center \textit{Rom\'eo} (Reims), we have successfully found all hyperbolic
centers of period $\leq 41$ and all Misiurewicz-Thurston parameters whose
period and pre-period sum to $\leq 35$. Concretely, this task involves
splitting a tera-polynomial, i.e. a polynomial of degree $\sim10^{12}$, which
is orders of magnitude ahead of the previous state of the art. It also involves
dealing with the certifiability of our numerical results, which is an issue
that we address in detail, both mathematically and along the production chain.
The certified database is available to the scientific community.
<br />For the smaller periods that can be represented using only hardware
arithmetic (floating points FP80), the implementation of our algorithm can
split the corresponding polynomials of degree $\sim10^{9}$ in less than one
day-core. We complement these benchmarks with a statistical analysis of the
separation of the roots, which confirms that no other polynomial in these
families can be split without using higher precision arithmetic.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06085" title="Abstract">arXiv:2402.06085</a> [<a href="/pdf/2402.06085" title="Download PDF">pdf</a>, <a href="/format/2402.06085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Objective Optimization of Consumer Group Autoscaling in Message  Broker Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Landau%2C+D">Diogo Landau</a>, 
<a href="/search/cs?searchtype=author&query=Saurabh%2C+N">Nishant Saurabh</a>, 
<a href="/search/cs?searchtype=author&query=Andrade%2C+X">Xavier Andrade</a>, 
<a href="/search/cs?searchtype=author&query=Barbosa%2C+J+G">Jorge G Barbosa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages. arXiv admin note: substantial text overlap with <a href="/abs/2206.11170">arXiv:2206.11170</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Message brokers often mediate communication between data producers and
consumers by adding variable-sized messages to ordered distributed queues. Our
goal is to determine the number of consumers and consumer-partition assignments
needed to ensure that the rate of data consumption keeps up with the rate of
data production. We model the problem as a variable item size bin packing
problem. As the rate of production varies, new consumer-partition assignments
are computed, which may require rebalancing a partition from one consumer to
another. While rebalancing a queue, the data being produced into the queue is
not read leading to additional latency costs. As such, we focus on the
multi-objective optimization cost of minimizing both the number of consumers
and queue migrations. We present a variety of algorithms and compare them to
established bin packing heuristics for this application. Comparing our proposed
consumer group assignment strategy with Kafka's, a commonly employed strategy,
our strategy presents a 90th percentile latency of 4.52s compared to Kafka's
217s with both using the same amount of consumers. Kafka's assignment strategy
only improved the consumer group's performance with regards to latency with
configurations that used at least 60% more resources than our approach.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06086" title="Abstract">arXiv:2402.06086</a> [<a href="/pdf/2402.06086" title="Download PDF">pdf</a>, <a href="/format/2402.06086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rhizomes to Load Balance Skewed In-Degree Distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chandio%2C+B+Q">Bibrak Qamar Chandio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">The paper aims to address load imbalance caused by high in-degree
distribution in graphs by applying the idea of rhizome to vertex-centric
message-driven graph processing. Rhizome construction of the graph creates
multiple named vertex address for any number of single large in-degree
vertices. It then allows other vertices to point to any of the named addresses
thus sharing the in-degree load. The rhizomes internally communicate and remain
consistent to provide a unified and correct view of the vertex. Simulated
experimental results show performance speed ups for BFS graph traversal on
large chip sizes for the tested input graph datasets containing highly skewed
in-degree distribution. The improvements come from sharing the in-degree
compute workload among memory-processing elements and also lowering contention
on the network-on-chip.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06087" title="Abstract">arXiv:2402.06087</a> [<a href="/pdf/2402.06087" title="Download PDF">pdf</a>, <a href="/format/2402.06087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Descriptive Kernel Convolution Network with Improved Random Walk Kernel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Meng-Chieh Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lingxiao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Akoglu%2C+L">Leman Akoglu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WWW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph kernels used to be the dominant approach to feature engineering for
structured data, which are superseded by modern GNNs as the former lacks
learnability. Recently, a suite of Kernel Convolution Networks (KCNs)
successfully revitalized graph kernels by introducing learnability, which
convolves input with learnable hidden graphs using a certain graph kernel. The
random walk kernel (RWK) has been used as the default kernel in many KCNs,
gaining increasing attention. In this paper, we first revisit the RWK and its
current usage in KCNs, revealing several shortcomings of the existing designs,
and propose an improved graph kernel RWK+, by introducing color-matching random
walks and deriving its efficient computation. We then propose RWK+CN, a KCN
that uses RWK+ as the core kernel to learn descriptive graph features with an
unsupervised objective, which can not be achieved by GNNs. Further, by
unrolling RWK+, we discover its connection with a regular GCN layer, and
propose a novel GNN layer RWK+Conv. In the first part of experiments, we
demonstrate the descriptive learning ability of RWK+CN with the improved random
walk kernel RWK+ on unsupervised pattern mining tasks; in the second part, we
show the effectiveness of RWK+ for a variety of KCN architectures and
supervised graph learning tasks, and demonstrate the expressiveness of RWK+Conv
layer, especially on the graph-level tasks. RWK+ and RWK+Conv adapt to various
real-world applications, including web applications such as bot detection in a
web-scale Twitter social network, and community classification in Reddit social
interaction networks.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06088" title="Abstract">arXiv:2402.06088</a> [<a href="/pdf/2402.06088" title="Download PDF">pdf</a>, <a href="/format/2402.06088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Animated Stickers: Bringing Stickers to Life with Video Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+D">David Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Winnie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Luxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kalia%2C+A">Anmol Kalia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dingkang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ramchandani%2C+A">Ankit Ramchandani</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Miao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pumarola%2C+A">Albert Pumarola</a>, 
<a href="/search/cs?searchtype=author&query=Schoenfeld%2C+E">Edgar Schoenfeld</a>, 
<a href="/search/cs?searchtype=author&query=Blanchard%2C+E">Elliot Blanchard</a>, 
<a href="/search/cs?searchtype=author&query=Narni%2C+K">Krishna Narni</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yaqiao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lawrence Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+G">Guan Pang</a>, 
<a href="/search/cs?searchtype=author&query=Thabet%2C+A">Ali Thabet</a>, 
<a href="/search/cs?searchtype=author&query=Vajda%2C+P">Peter Vajda</a>, 
<a href="/search/cs?searchtype=author&query=Bearman%2C+A">Amy Bearman</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Licheng Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce animated stickers, a video diffusion model which generates an
animation conditioned on a text prompt and static sticker image. Our model is
built on top of the state-of-the-art Emu text-to-image model, with the addition
of temporal layers to model motion. Due to the domain gap, i.e. differences in
visual and motion style, a model which performed well on generating natural
videos can no longer generate vivid videos when applied to stickers. To bridge
this gap, we employ a two-stage finetuning pipeline: first with weakly
in-domain data, followed by human-in-the-loop (HITL) strategy which we term
ensemble-of-teachers. It distills the best qualities of multiple teachers into
a smaller student model. We show that this strategy allows us to specifically
target improvements to motion quality while maintaining the style from the
static image. With inference optimizations, our model is able to generate an
eight-frame video with high-quality, interesting, and relevant motion in under
one second.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06089" title="Abstract">arXiv:2402.06089</a> [<a href="/pdf/2402.06089" title="Download PDF">pdf</a>, <a href="/format/2402.06089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Assistance for UX: A Literature Review Through Human-Centered AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yuwen Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuewen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qinyi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chengzhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T+J">Toby Jia-Jun Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Recent advancements in HCI and AI research attempt to support user experience
(UX) practitioners with AI-enabled tools. Despite the potential of emerging
models and new interaction mechanisms, mainstream adoption of such tools
remains limited. We took the lens of Human-Centered AI and presented a
systematic literature review of 359 papers, aiming to synthesize the current
landscape, identify trends, and uncover UX practitioners' unmet needs in AI
support. Guided by the Double Diamond design framework, our analysis uncovered
that UX practitioners' unique focuses on empathy building and experiences
across UI screens are often overlooked. Simplistic AI automation can obstruct
the valuable empathy-building process. Furthermore, focusing solely on
individual UI screens without considering interactions and user flows reduces
the system's practical value for UX designers. Based on these findings, we call
for a deeper understanding of UX mindsets and more designer-centric datasets
and evaluation metrics, for HCI and AI communities to collaboratively work
toward effective AI support for UX.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06091" title="Abstract">arXiv:2402.06091</a> [<a href="/pdf/2402.06091" title="Download PDF">pdf</a>, <a href="/format/2402.06091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Early Fusion of Features for Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Anupam Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+A">Ashok Krishnamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+L">Lisa Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper introduces a novel segmentation framework that integrates a
classifier network with a reverse HRNet architecture for efficient image
segmentation. Our approach utilizes a ResNet-50 backbone, pretrained in a
semi-supervised manner, to generate feature maps at various scales. These maps
are then processed by a reverse HRNet, which is adapted to handle varying
channel dimensions through 1x1 convolutions, to produce the final segmentation
output. We strategically avoid fine-tuning the backbone network to minimize
memory consumption during training. Our methodology is rigorously tested across
several benchmark datasets including Mapillary Vistas, Cityscapes, CamVid,
COCO, and PASCAL-VOC2012, employing metrics such as pixel accuracy and mean
Intersection over Union (mIoU) to evaluate segmentation performance. The
results demonstrate the effectiveness of our proposed model in achieving high
segmentation accuracy, indicating its potential for various applications in
image analysis. By leveraging the strengths of both the ResNet-50 and reverse
HRNet within a unified framework, we present a robust solution to the
challenges of image segmentation.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06092" title="Abstract">arXiv:2402.06092</a> [<a href="/pdf/2402.06092" title="Download PDF">pdf</a>, <a href="/format/2402.06092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIP-Loc: Multi-modal Landmark Association for Global Localization in  Object-based Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Matsuzaki%2C+S">Shigemichi Matsuzaki</a>, 
<a href="/search/cs?searchtype=author&query=Sugino%2C+T">Takuma Sugino</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+K">Kazuhito Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Sha%2C+Z">Zijun Sha</a>, 
<a href="/search/cs?searchtype=author&query=Nakaoka%2C+S">Shintaro Nakaoka</a>, 
<a href="/search/cs?searchtype=author&query=Yoshizawa%2C+S">Shintaro Yoshizawa</a>, 
<a href="/search/cs?searchtype=author&query=Shintani%2C+K">Kazuhiro Shintani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures. Accepted to IEEE International Conference on Robotics and Automation (ICRA) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This paper describes a multi-modal data association method for global
localization using object-based maps and camera images. In global localization,
or relocalization, using object-based maps, existing methods typically resort
to matching all possible combinations of detected objects and landmarks with
the same object category, followed by inlier extraction using RANSAC or
brute-force search. This approach becomes infeasible as the number of landmarks
increases due to the exponential growth of correspondence candidates. In this
paper, we propose labeling landmarks with natural language descriptions and
extracting correspondences based on conceptual similarity with image
observations using a Vision Language Model (VLM). By leveraging detailed text
information, our approach efficiently extracts correspondences compared to
methods using only object categories. Through experiments, we demonstrate that
the proposed method enables more accurate global localization with fewer
iterations compared to baseline methods, exhibiting its efficiency.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06093" title="Abstract">arXiv:2402.06093</a> [<a href="/pdf/2402.06093" title="Download PDF">pdf</a>, <a href="/ps/2402.06093" title="Download PostScript">ps</a>, <a href="/format/2402.06093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formal Verification of the Sumcheck Protocol
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bosshard%2C+A+G">Azucena Garv&#xed;a Bosshard</a>, 
<a href="/search/cs?searchtype=author&query=Bootle%2C+J">Jonathan Bootle</a>, 
<a href="/search/cs?searchtype=author&query=Sprenger%2C+C">Christoph Sprenger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of CSF 2024 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">The sumcheck protocol, introduced in 1992, is an interactive proof which is a
key component of many probabilistic proof systems in computational complexity
theory and cryptography, some of which have been deployed. However, none of
these proof systems based on the sumcheck protocol enjoy a formally-verified
security analysis. In this paper, we make progress in this direction by
providing a formally verified security analysis of the sumcheck protocol using
the interactive theorem prover Isabelle/HOL. We follow a general and modular
approach.
<br />First, we give a general formalization of public-coin interactive proofs. We
then define a generalized sumcheck protocol for which we axiomatize the
underlying mathematical structure and we establish its soundness and
completeness. Finally, we prove that these axioms hold for multivariate
polynomials, the original setting of the sumcheck protocol. Our modular
analysis facilitates formal verification of sumcheck instances based on
different mathematical structures with little effort, by simply proving that
these structures satisfy the axioms. Moreover, the analysis supports the
development and formal verification of future cryptographic protocols using the
sumcheck protocol as a building block.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06094" title="Abstract">arXiv:2402.06094</a> [<a href="/pdf/2402.06094" title="Download PDF">pdf</a>, <a href="/format/2402.06094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Data Selection for Supervised Fine-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+M">Ming Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Although supervised finetuning (SFT) has emerged as an essential technique to
align large language models with humans, it is considered superficial, with
style learning being its nature. At the same time, recent works indicate the
importance of data selection for SFT, showing that finetuning with high-quality
and diverse subsets of the original dataset leads to superior downstream
performance. In this work, we rethink the intuition behind data selection for
SFT. Considering SFT is superficial, we propose that essential demonstrations
for SFT should focus on reflecting human-like interactions instead of data
quality or diversity. However, it is not straightforward to directly assess to
what extent a demonstration reflects human styles. Towards an initial attempt
in this direction, we find selecting instances with long responses is
surprisingly more effective for SFT than utilizing full datasets or instances
selected based on quality and diversity. We hypothesize that such a simple
heuristic implicitly mimics a crucial aspect of human-style conversation:
detailed responses are usually more helpful.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06097" title="Abstract">arXiv:2402.06097</a> [<a href="/pdf/2402.06097" title="Download PDF">pdf</a>, <a href="/format/2402.06097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TWIG: Towards pre-hoc Hyperparameter Optimisation and Cross-Graph  Generalisation via Simulated KGE Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sardina%2C+J">Jeffrey Sardina</a>, 
<a href="/search/cs?searchtype=author&query=Kelleher%2C+J+D">John D. Kelleher</a>, 
<a href="/search/cs?searchtype=author&query=O%27Sullivan%2C+D">Declan O&#x27;Sullivan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article was accepted for publication at IEEE ICSC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper we introduce TWIG (Topologically-Weighted Intelligence
Generation), a novel, embedding-free paradigm for simulating the output of KGEs
that uses a tiny fraction of the parameters. TWIG learns weights from inputs
that consist of topological features of the graph data, with no coding for
latent representations of entities or edges. Our experiments on the UMLS
dataset show that a single TWIG neural network can predict the results of
state-of-the-art ComplEx-N3 KGE model nearly exactly on across all
hyperparameter configurations. To do this it uses a total of 2590 learnable
parameters, but accurately predicts the results of 1215 different
hyperparameter combinations with a combined cost of 29,322,000 parameters.
Based on these results, we make two claims: 1) that KGEs do not learn latent
semantics, but only latent representations of structural patterns; 2) that
hyperparameter choice in KGEs is a deterministic function of the KGE model and
graph structure. We further hypothesise that, as TWIG can simulate KGEs without
embeddings, that node and edge embeddings are not needed to learn to accurately
predict new facts in KGs. Finally, we formulate all of our findings under the
umbrella of the ``Structural Generalisation Hypothesis", which suggests that
``twiggy" embedding-free / data-structure-based learning methods can allow a
single neural network to simulate KGE performance, and perhaps solve the Link
Prediction task, across many KGs from diverse domains and with different
semantics.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06098" title="Abstract">arXiv:2402.06098</a> [<a href="/pdf/2402.06098" title="Download PDF">pdf</a>, <a href="/format/2402.06098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Veni, Vidi, Vici: Solving the Myriad of Challenges before Knowledge  Graph Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sardina%2C+J">Jeffrey Sardina</a>, 
<a href="/search/cs?searchtype=author&query=Costabello%2C+L">Luca Costabello</a>, 
<a href="/search/cs?searchtype=author&query=Gu%C3%A9ret%2C+C">Christophe Gu&#xe9;ret</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article was accepted for publication at IEEE ICSC 2024, and is being made available as an author preprint. As soon as it is published by IEEE, this registry will be updated in accordance with the IEEE copyright agreement
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Knowledge Graphs (KGs) have become increasingly common for representing
large-scale linked data. However, their immense size has required graph
learning systems to assist humans in analysis, interpretation, and pattern
detection. While there have been promising results for researcher- and
clinician- empowerment through a variety of KG learning systems, we identify
four key deficiencies in state-of-the-art graph learning that simultaneously
limit KG learning performance and diminish the ability of humans to interface
optimally with these learning systems. These deficiencies are: 1) lack of
expert knowledge integration, 2) instability to node degree extremity in the
KG, 3) lack of consideration for uncertainty and relevance while learning, and
4) lack of explainability. Furthermore, we characterise state-of-the-art
attempts to solve each of these problems and note that each attempt has largely
been isolated from attempts to solve the other problems. Through a
formalisation of these problems and a review of the literature that addresses
them, we adopt the position that not only are deficiencies in these four key
areas holding back human-KG empowerment, but that the divide-and-conquer
approach to solving these problems as individual units rather than a whole is a
significant barrier to the interface between humans and KG learning systems. We
propose that it is only through integrated, holistic solutions to the
limitations of KG learning systems that human and KG learning co-empowerment
will be efficiently affected. We finally present our "Veni, Vidi, Vici"
framework that sets a roadmap for effectively and efficiently shifting to a
holistic co-empowerment model in both the KG learning and the broader machine
learning domain.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06099" title="Abstract">arXiv:2402.06099</a> [<a href="/pdf/2402.06099" title="Download PDF">pdf</a>, <a href="/format/2402.06099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CATO: End-to-End Optimization of ML-Based Traffic Analysis Pipelines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+G">Gerry Wan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shinan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bronzino%2C+F">Francesco Bronzino</a>, 
<a href="/search/cs?searchtype=author&query=Feamster%2C+N">Nick Feamster</a>, 
<a href="/search/cs?searchtype=author&query=Durumeric%2C+Z">Zakir Durumeric</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Machine learning has shown tremendous potential for improving the
capabilities of network traffic analysis applications, often outperforming
simpler rule-based heuristics. However, ML-based solutions remain difficult to
deploy in practice. Many existing approaches only optimize the predictive
performance of their models, overlooking the practical challenges of running
them against network traffic in real time. This is especially problematic in
the domain of traffic analysis, where the efficiency of the serving pipeline is
a critical factor in determining the usability of a model. In this work, we
introduce CATO, a framework that addresses this problem by jointly optimizing
the predictive performance and the associated systems costs of the serving
pipeline. CATO leverages recent advances in multi-objective Bayesian
optimization to efficiently identify Pareto-optimal configurations, and
automatically compiles end-to-end optimized serving pipelines that can be
deployed in real networks. Our evaluations show that compared to popular
feature optimization techniques, CATO can provide up to 3600x lower inference
latency and 3.7x higher zero-loss throughput while simultaneously achieving
better model performance.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06102" title="Abstract">arXiv:2402.06102</a> [<a href="/pdf/2402.06102" title="Download PDF">pdf</a>, <a href="/format/2402.06102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-World Fluid Directed Rigid Body Control via Deep Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhardwaj%2C+M">Mohak Bhardwaj</a>, 
<a href="/search/cs?searchtype=author&query=Lampe%2C+T">Thomas Lampe</a>, 
<a href="/search/cs?searchtype=author&query=Neunert%2C+M">Michael Neunert</a>, 
<a href="/search/cs?searchtype=author&query=Romano%2C+F">Francesco Romano</a>, 
<a href="/search/cs?searchtype=author&query=Abdolmaleki%2C+A">Abbas Abdolmaleki</a>, 
<a href="/search/cs?searchtype=author&query=Byravan%2C+A">Arunkumar Byravan</a>, 
<a href="/search/cs?searchtype=author&query=Wulfmeier%2C+M">Markus Wulfmeier</a>, 
<a href="/search/cs?searchtype=author&query=Riedmiller%2C+M">Martin Riedmiller</a>, 
<a href="/search/cs?searchtype=author&query=Buchli%2C+J">Jonas Buchli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advances in real-world applications of reinforcement learning (RL)
have relied on the ability to accurately simulate systems at scale. However,
domains such as fluid dynamical systems exhibit complex dynamic phenomena that
are hard to simulate at high integration rates, limiting the direct application
of modern deep RL algorithms to often expensive or safety critical hardware. In
this work, we introduce "Box o Flows", a novel benchtop experimental control
system for systematically evaluating RL algorithms in dynamic real-world
scenarios. We describe the key components of the Box o Flows, and through a
series of experiments demonstrate how state-of-the-art model-free RL algorithms
can synthesize a variety of complex behaviors via simple reward specifications.
Furthermore, we explore the role of offline RL in data-efficient hypothesis
testing by reusing past experiences. We believe that the insights gained from
this preliminary study and the availability of systems like the Box o Flows
support the way forward for developing systematic RL algorithms that can be
generally applied to complex, dynamical systems. Supplementary material and
videos of experiments are available at
https://sites.google.com/view/box-o-flows/home.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06104" title="Abstract">arXiv:2402.06104</a> [<a href="/pdf/2402.06104" title="Download PDF">pdf</a>, <a href="/format/2402.06104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Function Aligned Regression: A Method Explicitly Learns Functional  Derivatives from Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Dixian Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Jerby-Arnon%2C+L">Livnat Jerby-Arnon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages excluding references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Regression is a fundamental task in machine learning that has garnered
extensive attention over the past decades. The conventional approach for
regression involves employing loss functions that primarily concentrate on
aligning model prediction with the ground truth for each individual data
sample, which, as we show, can result in sub-optimal prediction of the
relationships between the different samples. Recent research endeavors have
introduced novel perspectives by incorporating label similarity information to
regression. However, a notable gap persists in these approaches when it comes
to fully capturing the intricacies of the underlying ground truth function. In
this work, we propose FAR (Function Aligned Regression) as a arguably better
and more efficient solution to fit the underlying function of ground truth by
capturing functional derivatives. We demonstrate the effectiveness of the
proposed method practically on 2 synthetic datasets and on 8 extensive
real-world tasks from 6 benchmark datasets with other 8 competitive baselines.
The code is open-sourced at \url{https://github.com/DixianZhu/FAR}.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06106" title="Abstract">arXiv:2402.06106</a> [<a href="/pdf/2402.06106" title="Download PDF">pdf</a>, <a href="/format/2402.06106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLR-Face: Conditional Latent Refinement for Blind Face Restoration Using  Score-Based Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suin%2C+M">Maitreya Suin</a>, 
<a href="/search/cs?searchtype=author&query=Chellappa%2C+R">Rama Chellappa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent generative-prior-based methods have shown promising blind face
restoration performance. They usually project the degraded images to the latent
space and then decode high-quality faces either by single-stage latent
optimization or directly from the encoding. Generating fine-grained facial
details faithful to inputs remains a challenging problem. Most existing methods
produce either overly smooth outputs or alter the identity as they attempt to
balance between generation and reconstruction. This may be attributed to the
typical trade-off between quality and resolution in the latent space. If the
latent space is highly compressed, the decoded output is more robust to
degradations but shows worse fidelity. On the other hand, a more flexible
latent space can capture intricate facial details better, but is extremely
difficult to optimize for highly degraded faces using existing techniques. To
address these issues, we introduce a diffusion-based-prior inside a VQGAN
architecture that focuses on learning the distribution over uncorrupted latent
embeddings. With such knowledge, we iteratively recover the clean embedding
conditioning on the degraded counterpart. Furthermore, to ensure the reverse
diffusion trajectory does not deviate from the underlying identity, we train a
separate Identity Recovery Network and use its output to constrain the reverse
diffusion process. Specifically, using a learnable latent mask, we add
gradients from a face-recognition network to a subset of latent features that
correlates with the finer identity-related details in the pixel space, leaving
the other features untouched. Disentanglement between perception and fidelity
in the latent space allows us to achieve the best of both worlds. We perform
extensive evaluations on multiple real and synthetic datasets to validate the
superiority of our approach.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06107" title="Abstract">arXiv:2402.06107</a> [<a href="/pdf/2402.06107" title="Download PDF">pdf</a>, <a href="/format/2402.06107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple Instance Learning for Cheating Detection and Localization in  Online Examinations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yemeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jing Ren</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jianshuo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiaomei Bai</a>, 
<a href="/search/cs?searchtype=author&query=Kaur%2C+R">Roopdeep Kaur</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+F">Feng Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Cognitive and Developmental Systems 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">The spread of the Coronavirus disease-2019 epidemic has caused many courses
and exams to be conducted online. The cheating behavior detection model in
examination invigilation systems plays a pivotal role in guaranteeing the
equality of long-distance examinations. However, cheating behavior is rare, and
most researchers do not comprehensively take into account features such as head
posture, gaze angle, body posture, and background information in the task of
cheating behavior detection. In this paper, we develop and present CHEESE, a
CHEating detection framework via multiplE inStancE learning. The framework
consists of a label generator that implements weak supervision and a feature
encoder to learn discriminative features. In addition, the framework combines
body posture and background features extracted by 3D convolution with eye gaze,
head posture and facial features captured by OpenFace 2.0. These features are
fed into the spatio-temporal graph module by stitching to analyze the
spatio-temporal changes in video clips to detect the cheating behaviors. Our
experiments on three datasets, UCF-Crime, ShanghaiTech and Online Exam
Proctoring (OEP), prove the effectiveness of our method as compared to the
state-of-the-art approaches, and obtain the frame-level AUC score of 87.58% on
the OEP dataset.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06108" title="Abstract">arXiv:2402.06108</a> [<a href="/pdf/2402.06108" title="Download PDF">pdf</a>, <a href="/format/2402.06108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> United We Fall: On the Nash Equilibria of Multiplex and Multilayer  Network Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ebrahimi%2C+R">Raman Ebrahimi</a>, 
<a href="/search/cs?searchtype=author&query=Naghizadeh%2C+P">Parinaz Naghizadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Network games provide a framework to study strategic decision making
processes that are governed by structured interdependencies among agents.
However, existing models do not account for environments in which agents
simultaneously interact over multiple networks, or when agents operate over
multiple action dimensions. In this paper, we propose new models of multiplex
network games to capture the different modalities of interactions among
strategic agents, and multilayer network games to capture their interactions
over multiple action dimensions. We explore how the properties of the
constituent networks of a multiplex/multilayer network can undermine or support
the existence, uniqueness, and stability of the game's Nash equilibria.
Notably, we highlight that both the largest and smallest eigenvalues of the
constituent networks (reflecting their connectivity and two-sidedness,
respectively) are instrumental in determining the uniqueness of the
multiplex/multilayer network game's equilibrium. Together, our findings shed
light on the reasons for the fragility of equilibria when agents interact over
networks of networks, and point out potential interventions to alleviate them.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06110" title="Abstract">arXiv:2402.06110</a> [<a href="/pdf/2402.06110" title="Download PDF">pdf</a>, <a href="/format/2402.06110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI enhanced data assimilation and uncertainty quantification applied to  Geological Carbon Storage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seabra%2C+G+S">G. S. Seabra</a> (1, 2), 
<a href="/search/cs?searchtype=author&query=M%C3%BCcke%2C+N+T">N. T. M&#xfc;cke</a> (3, 4), 
<a href="/search/cs?searchtype=author&query=Silva%2C+V+L+S">V. L. S. Silva</a> (2, 5), 
<a href="/search/cs?searchtype=author&query=Voskov%2C+D">D. Voskov</a> (1, 6), 
<a href="/search/cs?searchtype=author&query=Vossepoel%2C+F">F. Vossepoel</a> (1) ((1) TU Delft, Netherlands, (2) Petrobras, Brazil, (3) Centrum Wiskunde &amp; Informatica, Netherlands, (4) Utrecht University, Netherlands, (5) Imperial College London, United Kingdom, (6) Stanford University, USA)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 20 figures, submited to the International Journal of Greenhouse Gas Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This study investigates the integration of machine learning (ML) and data
assimilation (DA) techniques, focusing on implementing surrogate models for
Geological Carbon Storage (GCS) projects while maintaining high fidelity
physical results in posterior states. Initially, we evaluate the surrogate
modeling capability of two distinct machine learning models, Fourier Neural
Operators (FNOs) and Transformer UNet (T-UNet), in the context of CO$_2$
injection simulations within channelized reservoirs. We introduce the
Surrogate-based hybrid ESMDA (SH-ESMDA), an adaptation of the traditional
Ensemble Smoother with Multiple Data Assimilation (ESMDA). This method uses
FNOs and T-UNet as surrogate models and has the potential to make the standard
ESMDA process at least 50% faster or more, depending on the number of
assimilation steps. Additionally, we introduce Surrogate-based Hybrid RML
(SH-RML), a variational data assimilation approach that relies on the
randomized maximum likelihood (RML) where both the FNO and the T-UNet enable
the computation of gradients for the optimization of the objective function,
and a high-fidelity model is employed for the computation of the posterior
states. Our comparative analyses show that SH-RML offers better uncertainty
quantification compared to conventional ESMDA for the case study.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06111" title="Abstract">arXiv:2402.06111</a> [<a href="/pdf/2402.06111" title="Download PDF">pdf</a>, <a href="/format/2402.06111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Observation-based unit test generation at Meta
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alshahwan%2C+N">Nadia Alshahwan</a>, 
<a href="/search/cs?searchtype=author&query=Harman%2C+M">Mark Harman</a>, 
<a href="/search/cs?searchtype=author&query=Marginean%2C+A">Alexandru Marginean</a>, 
<a href="/search/cs?searchtype=author&query=Tal%2C+R">Rotem Tal</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+E">Eddy Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures, FSE 2024, Mon 15 - Fri 19 July 2024, Porto de Galinhas, Brazil
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">TestGen automatically generates unit tests, carved from serialized
observations of complex objects, observed during app execution. We describe the
development and deployment of TestGen at Meta. In particular, we focus on the
scalability challenges overcome during development in order to deploy
observation-based test carving at scale in industry. So far, TestGen has landed
518 tests into production, which have been executed 9,617,349 times in
continuous integration, finding 5,702 faults. Meta is currently in the process
of more widespread deployment. Our evaluation reveals that, when carving its
observations from 4,361 reliable end-to-end tests, TestGen was able to generate
tests for at least 86\% of the classes covered by end-to-end tests. Testing on
16 Kotlin Instagram app-launch-blocking tasks demonstrated that the TestGen
tests would have trapped 13 of these before they became launch blocking.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06116" title="Abstract">arXiv:2402.06116</a> [<a href="/pdf/2402.06116" title="Download PDF">pdf</a>, <a href="/format/2402.06116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMs for Coding and Robotics Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shu%2C+P">Peng Shu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Huaqin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hanqi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shaochen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yi Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zihao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+G">Guoyu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+L">Le Guan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Gong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X+W+T">Xianqiao Wang Tianming Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 6 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models and multimodal large language models have
revolutionized artificial intelligence recently. An increasing number of
regions are now embracing these advanced technologies. Within this context,
robot coding education is garnering increasing attention. To teach young
children how to code and compete in robot challenges, large language models are
being utilized for robot code explanation, generation, and modification. In
this paper, we highlight an important trend in robot coding education. We test
several mainstream large language models on both traditional coding tasks and
the more challenging task of robot code generation, which includes block
diagrams. Our results show that GPT-4V outperforms other models in all of our
tests but struggles with generating block diagram images.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06117" title="Abstract">arXiv:2402.06117</a> [<a href="/pdf/2402.06117" title="Download PDF">pdf</a>, <a href="/format/2402.06117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatially-Attentive Patch-Hierarchical Network with Adaptive Sampling  for Motion Deblurring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suin%2C+M">Maitreya Suin</a>, 
<a href="/search/cs?searchtype=author&query=Purohit%2C+K">Kuldeep Purohit</a>, 
<a href="/search/cs?searchtype=author&query=Rajagopalan%2C+A+N">A. N. Rajagopalan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2004.05343">arXiv:2004.05343</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper tackles the problem of motion deblurring of dynamic scenes.
Although end-to-end fully convolutional designs have recently advanced the
state-of-the-art in non-uniform motion deblurring, their performance-complexity
trade-off is still sub-optimal. Most existing approaches achieve a large
receptive field by increasing the number of generic convolution layers and
kernel size. In this work, we propose a pixel adaptive and feature attentive
design for handling large blur variations across different spatial locations
and process each test image adaptively. We design a content-aware global-local
filtering module that significantly improves performance by considering not
only global dependencies but also by dynamically exploiting neighboring pixel
information. We further introduce a pixel-adaptive non-uniform sampling
strategy that implicitly discovers the difficult-to-restore regions present in
the image and, in turn, performs fine-grained refinement in a progressive
manner. Extensive qualitative and quantitative comparisons with prior art on
deblurring benchmarks demonstrate that our approach performs favorably against
the state-of-the-art deblurring algorithms.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06118" title="Abstract">arXiv:2402.06118</a> [<a href="/pdf/2402.06118" title="Download PDF">pdf</a>, <a href="/format/2402.06118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViGoR: Improving Visual Grounding of Large Vision Language Models with  Fine-Grained Reward Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Siming Yan</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+M">Min Bai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qixing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L+E">Li Erran Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">By combining natural language understanding and the generation capabilities
and breadth of knowledge of large language models with image perception, recent
large vision language models (LVLMs) have shown unprecedented reasoning
capabilities in the real world. However, the generated text often suffers from
inaccurate grounding in the visual input, resulting in errors such as
hallucinating nonexistent scene elements, missing significant parts of the
scene, and inferring incorrect attributes and relationships between objects. To
address these issues, we introduce a novel framework, ViGoR (Visual Grounding
Through Fine-Grained Reward Modeling) that utilizes fine-grained reward
modeling to significantly enhance the visual grounding of LVLMs over
pre-trained baselines. This improvement is efficiently achieved using much
cheaper human evaluations instead of full supervisions, as well as automated
methods. We show the effectiveness of our approach through numerous metrics on
several benchmarks. Additionally, we construct a comprehensive and challenging
dataset specifically designed to validate the visual grounding capabilities of
LVLMs. Finally, we plan to release our human annotation comprising
approximately 16,000 images and generated text pairs with fine-grained
evaluations to contribute to related research in the community.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06119" title="Abstract">arXiv:2402.06119</a> [<a href="/pdf/2402.06119" title="Download PDF">pdf</a>, <a href="/format/2402.06119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ContPhy: Continuum Physical Concept Learning and Reasoning from Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhicheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xin Yan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenfang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingzhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+Q+Z+E">Qin Zhi Eddie Lim</a>, 
<a href="/search/cs?searchtype=author&query=Tenenbaum%2C+J+B">Joshua B. Tenenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chuang Gan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first three authors contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce the Continuum Physical Dataset (ContPhy), a novel benchmark for
assessing machine physical commonsense. ContPhy complements existing physical
reasoning benchmarks by encompassing the inference of diverse physical
properties, such as mass and density, across various scenarios and predicting
corresponding dynamics. We evaluated a range of AI models and found that they
still struggle to achieve satisfactory performance on ContPhy, which shows that
the current AI models still lack physical commonsense for the continuum,
especially soft-bodies, and illustrates the value of the proposed dataset. We
also introduce an oracle model (ContPRO) that marries the particle-based
physical dynamic models with the recent large language models, which enjoy the
advantages of both models, precise dynamic predictions, and interpretable
reasoning. ContPhy aims to spur progress in perception and reasoning within
diverse physical settings, narrowing the divide between human and machine
intelligence in understanding the physical world. Project page:
https://physical-reasoning-project.github.io.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06120" title="Abstract">arXiv:2402.06120</a> [<a href="/pdf/2402.06120" title="Download PDF">pdf</a>, <a href="/format/2402.06120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Group and Symmetry Principles in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Imani%2C+S">Shima Imani</a>, 
<a href="/search/cs?searchtype=author&query=Palangi%2C+H">Hamid Palangi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have demonstrated impressive performance across
a wide range of applications; however, assessing their reasoning capabilities
remains a significant challenge. In this paper, we introduce a framework
grounded in group and symmetry principles, which have played a crucial role in
fields such as physics and mathematics, and offer another way to evaluate their
capabilities. While the proposed framework is general, to showcase the benefits
of employing these properties, we focus on arithmetic reasoning and investigate
the performance of these models on four group properties: closure, identity,
inverse, and associativity. Our findings reveal that LLMs studied in this work
struggle to preserve group properties across different test regimes. In the
closure test, we observe biases towards specific outputs and an abrupt
degradation in their performance from 100% to 0% after a specific sequence
length. They also perform poorly in the identity test, which represents adding
irrelevant information in the context, and show sensitivity when subjected to
inverse test, which examines the robustness of the model with respect to
negation. In addition, we demonstrate that breaking down problems into smaller
steps helps LLMs in the associativity test that we have conducted. To support
these tests we have developed a synthetic dataset which will be released.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06121" title="Abstract">arXiv:2402.06121</a> [<a href="/pdf/2402.06121" title="Download PDF">pdf</a>, <a href="/format/2402.06121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterated Denoising Energy Matching for Sampling from Boltzmann Densities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akhound-Sadegh%2C+T">Tara Akhound-Sadegh</a>, 
<a href="/search/cs?searchtype=author&query=Rector-Brooks%2C+J">Jarrid Rector-Brooks</a>, 
<a href="/search/cs?searchtype=author&query=Bose%2C+A+J">Avishek Joey Bose</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+S">Sarthak Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Lemos%2C+P">Pablo Lemos</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cheng-Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sendera%2C+M">Marcin Sendera</a>, 
<a href="/search/cs?searchtype=author&query=Ravanbakhsh%2C+S">Siamak Ravanbakhsh</a>, 
<a href="/search/cs?searchtype=author&query=Gidel%2C+G">Gauthier Gidel</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>, 
<a href="/search/cs?searchtype=author&query=Malkin%2C+N">Nikolay Malkin</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+A">Alexander Tong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code for iDEM is available at <a href="https://github.com/jarridrb/dem">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Efficiently generating statistically independent samples from an unnormalized
probability distribution, such as equilibrium samples of many-body systems, is
a foundational problem in science. In this paper, we propose Iterated Denoising
Energy Matching (iDEM), an iterative algorithm that uses a novel stochastic
score matching objective leveraging solely the energy function and its gradient
-- and no data samples -- to train a diffusion-based sampler. Specifically,
iDEM alternates between (I) sampling regions of high model density from a
diffusion-based sampler and (II) using these samples in our stochastic matching
objective to further improve the sampler. iDEM is scalable to high dimensions
as the inner matching objective, is simulation-free, and requires no MCMC
samples. Moreover, by leveraging the fast mode mixing behavior of diffusion,
iDEM smooths out the energy landscape enabling efficient exploration and
learning of an amortized sampler. We evaluate iDEM on a suite of tasks ranging
from standard synthetic energy functions to invariant $n$-body particle
systems. We show that the proposed approach achieves state-of-the-art
performance on all metrics and trains $2-5\times$ faster, which allows it to be
the first method to train using energy on the challenging $55$-particle
Lennard-Jones system.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06123" title="Abstract">arXiv:2402.06123</a> [<a href="/pdf/2402.06123" title="Download PDF">pdf</a>, <a href="/format/2402.06123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Proactive Model Offloading and Resource Allocation for  Split and Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Binbin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hailiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lingbin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+W">Wenzhuo Qian</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yuyu Yin</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Shuiguang Deng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">In the resource-constrained IoT-edge environment, Split Federated (SplitFed)
learning is implemented to enhance training efficiency. This method involves
each IoT device dividing its full DNN model at a designated layer into a
device-side model and a server-side model, then offloading the latter to the
edge server. However, existing research overlooks four critical issues as
follows: (1) the heterogeneity of IoT devices' resource capacities and the
sizes of their local data samples impact training efficiency; (2) the influence
of the edge server's computation and network resource allocation on training
efficiency; (3) the data leakage risk associated with the offloaded server-side
sub-model; (4) the privacy drawbacks of current centralized algorithms.
Consequently, proactively identifying the optimal cut layer and server resource
requirements for each IoT device to minimize training latency while adhering to
data leakage risk rate constraint remains a challenging issue. To address these
problems, this paper first formulates the latency and data leakage risk of
training DNN models using Split Federated learning. Next, we frame the Split
Federated learning problem as a mixed-integer nonlinear programming challenge.
To tackle this, we propose a decentralized Proactive Model Offloading and
Resource Allocation (DP-MORA) scheme, empowering each IoT device to determine
its cut layer and resource requirements based on its local multidimensional
training configuration, without knowledge of other devices' configurations.
Extensive experiments on two real-world datasets demonstrate that the DP-MORA
scheme effectively reduces DNN model training latency, enhances training
efficiency, and complies with data leakage risk constraints compared to several
baseline algorithms across various experimental settings.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06124" title="Abstract">arXiv:2402.06124</a> [<a href="/pdf/2402.06124" title="Download PDF">pdf</a>, <a href="/format/2402.06124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teleoscope: Exploring Themes in Large Document Sets By Example
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bucci%2C+P">Paul Bucci</a>, 
<a href="/search/cs?searchtype=author&query=Foord-Kelcey%2C+L">Leo Foord-Kelcey</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+P+Y+K">Patrick Yung Kang Lee</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Alamjeet Singh</a>, 
<a href="/search/cs?searchtype=author&query=Beschastnikh%2C+I">Ivan Beschastnikh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 9 figures, pre-print
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Qualitative thematic exploration of data by hand does not scale and
researchers create and update a personalized point of view as they explore
data. As a result, machine learning (ML) approaches that might help with
exploration are challenging to apply. We developed Teleoscope, a web-based
system that supports interactive exploration of large corpora (100K-1M) of
short documents (1-3 paragraphs). Teleoscope provides visual programming
workflows that have semantic and computational meaning; helping researchers to
retrace, share, and recompute their sense-making process. Attempting to create
qualitative "themes" rather than "topics," our NLP approach tunes an ML model
to "think like you" without significant retraining. Here, we present our
two-year design process and validation of Teleoscope, including a multi-week
study with qualitative researchers (N = 5), a six-month field deployment with a
qualitative research group, and an on-going public release.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06125" title="Abstract">arXiv:2402.06125</a> [<a href="/pdf/2402.06125" title="Download PDF">pdf</a>, <a href="/format/2402.06125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Model Sentence Completion with a Parser-Driven Rhetorical  Control Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zingale%2C+J">Joshua Zingale</a>, 
<a href="/search/cs?searchtype=author&query=Kalita%2C+J">Jugal Kalita</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the main proceedings of the Association for Computational Linguistics, European Chapter (EACL 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Controlled text generation (CTG) seeks to guide large language model (LLM)
output to produce text that conforms to desired criteria. The current study
presents a novel CTG algorithm that enforces adherence toward specific
rhetorical relations in an LLM sentence-completion context by a parser-driven
decoding scheme that requires no model fine-tuning. The method is validated
both with automatic and human evaluation. The code is accessible on GitHub.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06126" title="Abstract">arXiv:2402.06126</a> [<a href="/pdf/2402.06126" title="Download PDF">pdf</a>, <a href="/format/2402.06126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learn To be Efficient: Build Structured Sparsity in Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Haizhong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiaoyan Bai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Beidi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+F">Fan Lai</a>, 
<a href="/search/cs?searchtype=author&query=Prakash%2C+A">Atul Prakash</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) have achieved remarkable success with their
billion-level parameters, yet they incur high inference overheads. The
emergence of activation sparsity in LLMs provides a natural approach to reduce
this cost by involving only parts of the parameters for inference. Existing
methods only focus on utilizing this naturally formed activation sparsity,
overlooking the potential for further amplifying this inherent sparsity. In
this paper, we hypothesize that LLMs can learn to be efficient by achieving
more structured activation sparsity.To achieve this, we introduce a novel
algorithm, Learn-To-be-Efficient (LTE), designed to train efficiency-aware LLMs
to learn to activate fewer neurons and achieve a better trade-off between
sparsity and performance. Furthermore, unlike SOTA MoEfication methods, which
mainly focus on ReLU-based models, LTE can also be applied to LLMs like GPT and
LLaMA with soft activation functions. We evaluate LTE on four models and eleven
datasets. The experiments show that LTE achieves a better trade-off between
sparsity and task performance. For instance, LTE with LLaMA provides a
1.83x-2.59x FLOPs speed-up on language generation tasks, outperforming the
state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06127" title="Abstract">arXiv:2402.06127</a> [<a href="/pdf/2402.06127" title="Download PDF">pdf</a>, <a href="/format/2402.06127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CityFlowER: An Efficient and Realistic Traffic Simulator with Embedded  Machine Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Da%2C+L">Longchao Da</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+C">Chen Chu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hua Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Traffic simulation is an essential tool for transportation infrastructure
planning, intelligent traffic control policy learning, and traffic flow
analysis. Its effectiveness relies heavily on the realism of the simulators
used. Traditional traffic simulators, such as SUMO and CityFlow, are often
limited by their reliance on rule-based models with hyperparameters that
oversimplify driving behaviors, resulting in unrealistic simulations. To
enhance realism, some simulators have provided Application Programming
Interfaces (APIs) to interact with Machine Learning (ML) models, which learn
from observed data and offer more sophisticated driving behavior models.
However, this approach faces challenges in scalability and time efficiency as
vehicle numbers increase. Addressing these limitations, we introduce
CityFlowER, an advancement over the existing CityFlow simulator, designed for
efficient and realistic city-wide traffic simulation. CityFlowER innovatively
pre-embeds ML models within the simulator, eliminating the need for external
API interactions and enabling faster data computation. This approach allows for
a blend of rule-based and ML behavior models for individual vehicles, offering
unparalleled flexibility and efficiency, particularly in large-scale
simulations. We provide detailed comparisons with existing simulators,
implementation insights, and comprehensive experiments to demonstrate
CityFlowER's superiority in terms of realism, efficiency, and adaptability.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06128" title="Abstract">arXiv:2402.06128</a> [<a href="/pdf/2402.06128" title="Download PDF">pdf</a>, <a href="/format/2402.06128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Node-wise Propagation for Large-scale Graph Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xunkai Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jingyuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhengyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+D">Daohan Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wentao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rong-Hua Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoren Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WWW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Scalable graph neural networks (GNNs) have emerged as a promising technique,
which exhibits superior predictive performance and high running efficiency
across numerous large-scale graph-based web applications. However, (i) Most
scalable GNNs tend to treat all nodes in graphs with the same propagation
rules, neglecting their topological uniqueness; (ii) Existing node-wise
propagation optimization strategies are insufficient on web-scale graphs with
intricate topology, where a full portrayal of nodes' local properties is
required. Intuitively, different nodes in web-scale graphs possess distinct
topological roles, and therefore propagating them indiscriminately or neglect
local contexts may compromise the quality of node representations. This
intricate topology in web-scale graphs cannot be matched by small-scale
scenarios. To address the above issues, we propose \textbf{A}daptive
\textbf{T}opology-aware \textbf{P}ropagation (ATP), which reduces potential
high-bias propagation and extracts structural patterns of each node in a
scalable manner to improve running efficiency and predictive performance.
Remarkably, ATP is crafted to be a plug-and-play node-wise propagation
optimization strategy, allowing for offline execution independent of the graph
learning process in a new perspective. Therefore, this approach can be
seamlessly integrated into most scalable GNNs while remain orthogonal to
existing node-wise propagation optimization strategies. Extensive experiments
on 12 datasets, including the most representative large-scale ogbn-papers100M,
have demonstrated the effectiveness of ATP. Specifically, ATP has proven to be
efficient in improving the performance of prevalent scalable GNNs for
semi-supervised node classification while addressing redundant computational
costs.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06129" title="Abstract">arXiv:2402.06129</a> [<a href="/pdf/2402.06129" title="Download PDF">pdf</a>, <a href="/format/2402.06129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mesh-robust stability and convergence of variable-step deferred  correction methods based on the BDF2 formula
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yue%2C+J">Jiahe Yue</a>, 
<a href="/search/math?searchtype=author&query=Liao%2C+H">Hong-lin Liao</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+N">Nan Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 12 tables, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We provide a new theoretical framework for the variable-step deferred
correction (DC) methods based on the well-known BDF2 formula. By using the
discrete orthogonal convolution kernels, some high-order BDF2-DC methods are
proven to be stable on arbitrary time grids according to the recent definition
of stability (SINUM, 60: 2253-2272). It significantly relaxes the existing
step-ratio restrictions for the BDF2-DC methods (BIT, 62: 1789-1822). The
associated sharp error estimates are established by taking the numerical
effects of the starting approximations into account, and they suggest that the
BDF2-DC methods have no aftereffect, that is, the lower-order starting scheme
for the BDF2 scheme will not cause a loss in the accuracy of the high-order
BDF2-DC methods. Extensive tests on the graded and random time meshes are
presented to support the new theory.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06131" title="Abstract">arXiv:2402.06131</a> [<a href="/pdf/2402.06131" title="Download PDF">pdf</a>, <a href="/format/2402.06131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PAS-SLAM: A Visual SLAM System for Planar Ambiguous Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xinggang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yanmin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Mingyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Linghao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangkui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xiangyang Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Visual SLAM (Simultaneous Localization and Mapping) based on planar features
has found widespread applications in fields such as environmental structure
perception and augmented reality. However, current research faces challenges in
accurately localizing and mapping in planar ambiguous scenes, primarily due to
the poor accuracy of the employed planar features and data association methods.
In this paper, we propose a visual SLAM system based on planar features
designed for planar ambiguous scenes, encompassing planar processing, data
association, and multi-constraint factor graph optimization. We introduce a
planar processing strategy that integrates semantic information with planar
features, extracting the edges and vertices of planes to be utilized in tasks
such as plane selection, data association, and pose optimization. Next, we
present an integrated data association strategy that combines plane parameters,
semantic information, projection IoU (Intersection over Union), and
non-parametric tests, achieving accurate and robust plane data association in
planar ambiguous scenes. Finally, we design a set of multi-constraint factor
graphs for camera pose optimization. Qualitative and quantitative experiments
conducted on publicly available datasets demonstrate that our proposed system
competes effectively in both accuracy and robustness in terms of map
construction and camera localization compared to state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06132" title="Abstract">arXiv:2402.06132</a> [<a href="/pdf/2402.06132" title="Download PDF">pdf</a>, <a href="/format/2402.06132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TETRIS: Towards Exploring the Robustness of Interactive Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moskalenko%2C+A">Andrey Moskalenko</a>, 
<a href="/search/cs?searchtype=author&query=Shakhuro%2C+V">Vlad Shakhuro</a>, 
<a href="/search/cs?searchtype=author&query=Vorontsova%2C+A">Anna Vorontsova</a>, 
<a href="/search/cs?searchtype=author&query=Konushin%2C+A">Anton Konushin</a>, 
<a href="/search/cs?searchtype=author&query=Antonov%2C+A">Anton Antonov</a>, 
<a href="/search/cs?searchtype=author&query=Krapukhin%2C+A">Alexander Krapukhin</a>, 
<a href="/search/cs?searchtype=author&query=Shepelev%2C+D">Denis Shepelev</a>, 
<a href="/search/cs?searchtype=author&query=Soshin%2C+K">Konstantin Soshin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Interactive segmentation methods rely on user inputs to iteratively update
the selection mask. A click specifying the object of interest is arguably the
most simple and intuitive interaction type, and thereby the most common choice
for interactive segmentation. However, user clicking patterns in the
interactive segmentation context remain unexplored. Accordingly, interactive
segmentation evaluation strategies rely more on intuition and common sense
rather than empirical studies (e.g., assuming that users tend to click in the
center of the area with the largest error). In this work, we conduct a real
user study to investigate real user clicking patterns. This study reveals that
the intuitive assumption made in the common evaluation strategy may not hold.
As a result, interactive segmentation models may show high scores in the
standard benchmarks, but it does not imply that they would perform well in a
real world scenario. To assess the applicability of interactive segmentation
methods, we propose a novel evaluation strategy providing a more comprehensive
analysis of a model's performance. To this end, we propose a methodology for
finding extreme user inputs by a direct optimization in a white-box adversarial
attack on the interactive segmentation model. Based on the performance with
such adversarial user inputs, we assess the robustness of interactive
segmentation models w.r.t click positions. Besides, we introduce a novel
benchmark for measuring the robustness of interactive segmentation, and report
the results of an extensive evaluation of dozens of models.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06135" title="Abstract">arXiv:2402.06135</a> [<a href="/pdf/2402.06135" title="Download PDF">pdf</a>, <a href="/format/2402.06135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jointly Learning Representations for Map Entities via Heterogeneous  Graph Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jiawei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yifan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Junjie Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The electronic map plays a crucial role in geographic information systems,
serving various urban managerial scenarios and daily life services. Developing
effective Map Entity Representation Learning (MERL) methods is crucial to
extracting embedding information from electronic maps and converting map
entities into representation vectors for downstream applications. However,
existing MERL methods typically focus on one specific category of map entities,
such as POIs, road segments, or land parcels, which is insufficient for
real-world diverse map-based applications and might lose latent structural and
semantic information interacting between entities of different types. Moreover,
using representations generated by separate models for different map entities
can introduce inconsistencies. Motivated by this, we propose a novel method
named HOME-GCL for learning representations of multiple categories of map
entities. Our approach utilizes a heterogeneous map entity graph (HOME graph)
that integrates both road segments and land parcels into a unified framework. A
HOME encoder with parcel-segment joint feature encoding and heterogeneous graph
transformer is then deliberately designed to convert segments and parcels into
representation vectors. Moreover, we introduce two types of contrastive
learning tasks, namely intra-entity and inter-entity tasks, to train the
encoder in a self-supervised manner. Extensive experiments on three large-scale
datasets covering road segment-based, land parcel-based, and trajectory-based
tasks demonstrate the superiority of our approach. To the best of our
knowledge, HOME-GCL is the first attempt to jointly learn representations for
road segments and land parcels using a unified model.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06136" title="Abstract">arXiv:2402.06136</a> [<a href="/pdf/2402.06136" title="Download PDF">pdf</a>, <a href="/format/2402.06136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SIR: Multi-view Inverse Rendering with Decomposable Shadow for Indoor  Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiaokang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhuoman Liu</a>, 
<a href="/search/cs?searchtype=author&query=Luximon%2C+Y">Yan Luximon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose SIR, an efficient method to decompose differentiable shadows for
inverse rendering on indoor scenes using multi-view data, addressing the
challenges in accurately decomposing the materials and lighting conditions.
Unlike previous methods that struggle with shadow fidelity in complex lighting
environments, our approach explicitly learns shadows for enhanced realism in
material estimation under unknown light positions. Utilizing posed HDR images
as input, SIR employs an SDF-based neural radiance field for comprehensive
scene representation. Then, SIR integrates a shadow term with a three-stage
material estimation approach to improve SVBRDF quality. Specifically, SIR is
designed to learn a differentiable shadow, complemented by BRDF regularization,
to optimize inverse rendering accuracy. Extensive experiments on both synthetic
and real-world indoor scenes demonstrate the superior performance of SIR over
existing methods in both quantitative metrics and qualitative analysis. The
significant decomposing ability of SIR enables sophisticated editing
capabilities like free-view relighting, object insertion, and material
replacement.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06137" title="Abstract">arXiv:2402.06137</a> [<a href="/pdf/2402.06137" title="Download PDF">pdf</a>, <a href="/format/2402.06137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Privacy of Selection Mechanisms with Gaussian Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lebensold%2C+J">Jonathan Lebensold</a>, 
<a href="/search/cs?searchtype=author&query=Precup%2C+D">Doina Precup</a>, 
<a href="/search/cs?searchtype=author&query=Balle%2C+B">Borja Balle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Report Noisy Max and Above Threshold are two classical differentially private
(DP) selection mechanisms. Their output is obtained by adding noise to a
sequence of low-sensitivity queries and reporting the identity of the query
whose (noisy) answer satisfies a certain condition. Pure DP guarantees for
these mechanisms are easy to obtain when Laplace noise is added to the queries.
On the other hand, when instantiated using Gaussian noise, standard analyses
only yield approximate DP guarantees despite the fact that the outputs of these
mechanisms lie in a discrete space. In this work, we revisit the analysis of
Report Noisy Max and Above Threshold with Gaussian noise and show that, under
the additional assumption that the underlying queries are bounded, it is
possible to provide pure ex-ante DP bounds for Report Noisy Max and pure
ex-post DP bounds for Above Threshold. The resulting bounds are tight and
depend on closed-form expressions that can be numerically evaluated using
standard methods. Empirically we find these lead to tighter privacy accounting
in the high privacy, low data regime. Further, we propose a simple privacy
filter for composing pure ex-post DP guarantees, and use it to derive a fully
adaptive Gaussian Sparse Vector Technique mechanism. Finally, we provide
experiments on mobility and energy consumption datasets demonstrating that our
Sparse Vector Technique is practically competitive with previous approaches and
requires less hyper-parameter tuning.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06143" title="Abstract">arXiv:2402.06143</a> [<a href="/pdf/2402.06143" title="Download PDF">pdf</a>, <a href="/format/2402.06143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning for Blind Stair Climbing with Legged and  Wheeled-Legged Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chamorro%2C+S">Simon Chamorro</a>, 
<a href="/search/cs?searchtype=author&query=Klemm%2C+V">Victor Klemm</a>, 
<a href="/search/cs?searchtype=author&query=de+la+Iglesia+Valls%2C+M">Miguel de la Iglesia Valls</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+C">Christopher Pal</a>, 
<a href="/search/cs?searchtype=author&query=Siegwart%2C+R">Roland Siegwart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Video: <a href="https://youtu.be/Ec6ar8BVJh4">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In recent years, legged and wheeled-legged robots have gained prominence for
tasks in environments predominantly created for humans across various domains.
One significant challenge faced by many of these robots is their limited
capability to navigate stairs, which hampers their functionality in multi-story
environments. This study proposes a method aimed at addressing this limitation,
employing reinforcement learning to develop a versatile controller applicable
to a wide range of robots. In contrast to the conventional velocity-based
controllers, our approach builds upon a position-based formulation of the RL
task, which we show to be vital for stair climbing. Furthermore, the
methodology leverages an asymmetric actor-critic structure, enabling the
utilization of privileged information from simulated environments during
training while eliminating the reliance on exteroceptive sensors during
real-world deployment. Another key feature of the proposed approach is the
incorporation of a boolean observation within the controller, enabling the
activation or deactivation of a stair-climbing mode. We present our results on
different quadrupeds and bipedal robots in simulation and showcase how our
method allows the balancing robot Ascento to climb 15cm stairs in the real
world, a task that was previously impossible for this robot.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06147" title="Abstract">arXiv:2402.06147</a> [<a href="/pdf/2402.06147" title="Download PDF">pdf</a>, <a href="/format/2402.06147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeAL: Decoding-time Alignment for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J+Y">James Y. Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+S">Sailik Sengupta</a>, 
<a href="/search/cs?searchtype=author&query=Bonadiman%2C+D">Daniele Bonadiman</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yi-an Lai</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Arshit Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Pappas%2C+N">Nikolaos Pappas</a>, 
<a href="/search/cs?searchtype=author&query=Mansour%2C+S">Saab Mansour</a>, 
<a href="/search/cs?searchtype=author&query=Kirchoff%2C+K">Katrin Kirchoff</a>, 
<a href="/search/cs?searchtype=author&query=Roth%2C+D">Dan Roth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The appendix contains data that is offensive / disturbing in nature
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Language Models (LLMs) are nowadays expected to generate content
aligned with human preferences. Current work focuses on alignment at model
training time, through techniques such as Reinforcement Learning with Human
Feedback (RLHF). However, it is unclear if such methods are an effective choice
to teach alignment objectives to the model. First, the inability to incorporate
multiple, custom rewards and reliance on a model developer's view of universal
and static principles are key limitations. Second, the residual gaps in model
training and the reliability of such approaches are also questionable (e.g.
susceptibility to jail-breaking even after safety training). To address these,
we propose DeAL, a framework that allows the user to customize reward functions
and enables Decoding-time Alignment of LLMs (DeAL). At its core, we view
decoding as a heuristic-guided search process and facilitate the use of a wide
variety of alignment objectives. Our experiments with programmatic constraints
such as keyword and length constraints (studied widely in the pre-LLM era) and
abstract objectives such as harmlessness and helpfulness (proposed in the
post-LLM era) show that we can DeAL with fine-grained trade-offs, improve
adherence to alignment objectives, and address residual gaps in LLMs. Lastly,
while DeAL can be effectively paired with RLHF and prompting techniques, its
generality makes decoding slower, an optimization we leave for future work.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06149" title="Abstract">arXiv:2402.06149</a> [<a href="/pdf/2402.06149" title="Download PDF">pdf</a>, <a href="/format/2402.06149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HeadStudio: Text to Animatable Head Avatars with 3D Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhenglin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+F">Fan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Hehe Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Creating digital avatars from textual prompts has long been a desirable yet
challenging task. Despite the promising outcomes obtained through 2D diffusion
priors in recent works, current methods face challenges in achieving
high-quality and animated avatars effectively. In this paper, we present
$\textbf{HeadStudio}$, a novel framework that utilizes 3D Gaussian splatting to
generate realistic and animated avatars from text prompts. Our method drives 3D
Gaussians semantically to create a flexible and achievable appearance through
the intermediate FLAME representation. Specifically, we incorporate the FLAME
into both 3D representation and score distillation: 1) FLAME-based 3D Gaussian
splatting, driving 3D Gaussian points by rigging each point to a FLAME mesh. 2)
FLAME-based score distillation sampling, utilizing FLAME-based fine-grained
control signal to guide score distillation from the text prompt. Extensive
experiments demonstrate the efficacy of HeadStudio in generating animatable
avatars from textual prompts, exhibiting visually appealing appearances. The
avatars are capable of rendering high-quality real-time ($\geq 40$ fps) novel
views at a resolution of 1024. They can be smoothly controlled by real-world
speech and video. We hope that HeadStudio can advance digital avatar creation
and that the present method can widely be applied across various domains.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06150" title="Abstract">arXiv:2402.06150</a> [<a href="/pdf/2402.06150" title="Download PDF">pdf</a>, <a href="/format/2402.06150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Generalization with Small Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kecheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gal%2C+E">Elena Gal</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoliang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by International Journal of Computer Vision
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this work, we propose to tackle the problem of domain generalization in
the context of \textit{insufficient samples}. Instead of extracting latent
feature embeddings based on deterministic models, we propose to learn a
domain-invariant representation based on the probabilistic framework by mapping
each data point into probabilistic embeddings. Specifically, we first extend
empirical maximum mean discrepancy (MMD) to a novel probabilistic MMD that can
measure the discrepancy between mixture distributions (i.e., source domains)
consisting of a series of latent distributions rather than latent points.
Moreover, instead of imposing the contrastive semantic alignment (CSA) loss
based on pairs of latent points, a novel probabilistic CSA loss encourages
positive probabilistic embedding pairs to be closer while pulling other
negative ones apart. Benefiting from the learned representation captured by
probabilistic models, our proposed method can marriage the measurement on the
\textit{distribution over distributions} (i.e., the global perspective
alignment) and the distribution-based contrastive semantic alignment (i.e., the
local perspective alignment). Extensive experimental results on three
challenging medical datasets show the effectiveness of our proposed method in
the context of insufficient data compared with state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06152" title="Abstract">arXiv:2402.06152</a> [<a href="/pdf/2402.06152" title="Download PDF">pdf</a>, <a href="/ps/2402.06152" title="Download PostScript">ps</a>, <a href="/format/2402.06152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Target Recognition Algorithm for Monitoring Images in Electric Power  Construction Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hao Song</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Wei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+W">Wei Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Man Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">To enhance precision and comprehensiveness in identifying targets in electric
power construction monitoring video, a novel target recognition algorithm
utilizing infrared imaging is explored. This algorithm employs a color
processing technique based on a local linear mapping method to effectively
recolor monitoring images. The process involves three key steps: color space
conversion, color transfer, and pseudo-color encoding. It is designed to
accentuate targets in the infrared imaging. For the refined identification of
these targets, the algorithm leverages a support vector machine approach,
utilizing an optimal hyperplane to accurately predict target types. We
demonstrate the efficacy of the algorithm, which achieves high target
recognition accuracy in both outdoor and indoor electric power construction
monitoring scenarios. It maintains a false recognition rate below 3% across
various environments.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06154" title="Abstract">arXiv:2402.06154</a> [<a href="/pdf/2402.06154" title="Download PDF">pdf</a>, <a href="/format/2402.06154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coverage and Rate Analysis for Distributed RISs-Assisted mmWave  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chongwen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yongxu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhaohui Yang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiguang He</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yuen%2C+C">Chau Yuen</a>, 
<a href="/search/cs?searchtype=author&query=Debbah%2C+M">Merouane Debbah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The millimeter wave (mmWave) has received considerable interest due to its
expansive bandwidth and high frequency. However, a noteworthy challenge arises
from its vulnerability to blockages, leading to reduced coverage and achievable
rates. To address these limitations, a potential solution is to deploy
distributed reconfigurable intelligent surfaces (RISs), which comprise many
low-cost and passively reflected elements, and can facilitate the establishment
of extra communication links. In this paper, we leverage stochastic geometry to
investigate the ergodic coverage probability and the achievable rate in both
distributed RISs-assisted single-cell and multi-cell mmWave wireless
communication systems. Specifically, we first establish the system model
considering the stochastically distributed blockages, RISs and users by the
Poisson point process. Then we give the association criterion and derive the
association probabilities, the distance distributions, and the conditional
coverage probabilities for two cases of associations between base stations and
users without or with RISs. Finally, we use Campbell's theorem and the total
probability theorem to obtain the closed-form expressions of the ergodic
coverage probability and the achievable rate. Simulation results verify the
effectiveness of our analysis method, and demonstrate that by deploying
distributed RISs, the ergodic coverage probability is significantly improved by
approximately 50%, and the achievable rate is increased by more than 1.5 times.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06155" title="Abstract">arXiv:2402.06155</a> [<a href="/pdf/2402.06155" title="Download PDF">pdf</a>, <a href="/format/2402.06155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Editing with Canonical Examples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hewitt%2C+J">John Hewitt</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sarah Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L+L">Lanruo Lora Xie</a>, 
<a href="/search/cs?searchtype=author&query=Adams%2C+E">Edward Adams</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Percy Liang</a>, 
<a href="/search/cs?searchtype=author&query=Manning%2C+C+D">Christopher D. Manning</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We introduce model editing with canonical examples, a setting in which (1) a
single learning example is provided per desired behavior, (2) evaluation is
performed exclusively out-of-distribution, and (3) deviation from an initial
model is strictly limited. A canonical example is a simple instance of good
behavior, e.g., The capital of Mauritius is Port Louis) or bad behavior, e.g.,
An aspect of researchers is coldhearted). The evaluation set contains more
complex examples of each behavior (like a paragraph in which the capital of
Mauritius is called for.) We create three datasets and modify three more for
model editing with canonical examples, covering knowledge-intensive
improvements, social bias mitigation, and syntactic edge cases. In our
experiments on Pythia language models, we find that LoRA outperforms full
finetuning and MEMIT. We then turn to the Backpack language model architecture
because it is intended to enable targeted improvement. The Backpack defines a
large bank of sense vectors--a decomposition of the different uses of each
word--which are weighted and summed to form the output logits of the model. We
propose sense finetuning, which selects and finetunes a few ($\approx$ 10)
sense vectors for each canonical example, and find that it outperforms other
finetuning methods, e.g., 4.8% improvement vs 0.3%. Finally, we improve
GPT-J-6B by an inference-time ensemble with just the changes from sense
finetuning of a 35x smaller Backpack, in one setting outperforming editing
GPT-J itself (4.1% vs 1.0%).
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06158" title="Abstract">arXiv:2402.06158</a> [<a href="/pdf/2402.06158" title="Download PDF">pdf</a>, <a href="/format/2402.06158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assortment Planning with Sponsored Products
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shaojie Tang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+S">Shuzhang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jing Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kai Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">In the rapidly evolving landscape of retail, assortment planning plays a
crucial role in determining the success of a business. With the rise of
sponsored products and their increasing prominence in online marketplaces,
retailers face new challenges in effectively managing their product assortment
in the presence of sponsored products. Remarkably, previous research in
assortment planning largely overlooks the existence of sponsored products and
their potential impact on overall recommendation effectiveness. Instead, they
commonly make the simplifying assumption that all products are either organic
or non-sponsored. This research gap underscores the necessity for a more
thorough investigation of the assortment planning challenge when sponsored
products are in play. We formulate the assortment planning problem in the
presence of sponsored products as a combinatorial optimization task. The
ultimate objective is to compute an assortment plan that optimizes expected
revenue while considering the specific requirements of placing sponsored
products strategically.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06159" title="Abstract">arXiv:2402.06159</a> [<a href="/pdf/2402.06159" title="Download PDF">pdf</a>, <a href="/format/2402.06159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Passwords Are Meant to Be Secret: A Practical Secure Password Entry  Channel for Web Browsers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gautam%2C+A">Anuj Gautam</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+T+K">Tarun Kumar Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Seamons%2C+K">Kent Seamons</a>, 
<a href="/search/cs?searchtype=author&query=Ruoti%2C+S">Scott Ruoti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Password-based authentication faces various security and usability issues.
Password managers help alleviate some of these issues by enabling users to
manage their passwords effectively. However, malicious client-side scripts and
browser extensions can steal passwords after they have been autofilled by the
manager into the web page. In this paper, we explore what role the password
manager can take in preventing the theft of autofilled credentials without
requiring a change to user behavior. To this end, we identify a threat model
for password exfiltration and then use this threat model to explore the design
space for secure password entry implemented using a password manager. We
identify five potential designs that address this issue, each with varying
security and deployability tradeoffs. Our analysis shows the design that best
balances security and usability is for the manager to autofill a fake password
and then rely on the browser to replace the fake password with the actual
password immediately before the web request is handed over to the operating
system to be transmitted over the network. This removes the ability for
malicious client-side scripts or browser extensions to access and exfiltrate
the real password. We implement our design in the Firefox browser and conduct
experiments, which show that it successfully thwarts malicious scripts and
extensions on 97\% of the Alexa top 1000 websites, while also maintaining the
capability to revert to default behavior on the remaining websites, avoiding
functionality regressions. Most importantly, this design is transparent to
users, requiring no change to user behavior.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06160" title="Abstract">arXiv:2402.06160</a> [<a href="/pdf/2402.06160" title="Download PDF">pdf</a>, <a href="/format/2402.06160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Evidential Deep Learning via a Mixture of Dirichlet  Distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ryu%2C+J+J">J. Jon Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+M">Maohao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Soumya Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Bu%2C+Y">Yuheng Bu</a>, 
<a href="/search/cs?searchtype=author&query=Sattigeri%2C+P">Prasanna Sattigeri</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Subhro Das</a>, 
<a href="/search/cs?searchtype=author&query=Wornell%2C+G+W">Gregory W. Wornell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper explores a modern predictive uncertainty estimation approach,
called evidential deep learning (EDL), in which a single neural network model
is trained to learn a meta distribution over the predictive distribution by
minimizing a specific objective function. Despite their strong empirical
performance, recent studies by Bengs et al. identify a fundamental pitfall of
the existing methods: the learned epistemic uncertainty may not vanish even in
the infinite-sample limit. We corroborate the observation by providing a
unifying view of a class of widely used objectives from the literature. Our
analysis reveals that the EDL methods essentially train a meta distribution by
minimizing a certain divergence measure between the distribution and a
sample-size-independent target distribution, resulting in spurious epistemic
uncertainty. Grounded in theoretical principles, we propose learning a
consistent target distribution by modeling it with a mixture of Dirichlet
distributions and learning via variational inference. Afterward, a final meta
distribution model distills the learned uncertainty from the target model.
Experimental results across various uncertainty-based downstream tasks
demonstrate the superiority of our proposed method, and illustrate the
practical implications arising from the consistency and inconsistency of
learned epistemic uncertainty.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06161" title="Abstract">arXiv:2402.06161</a> [<a href="/pdf/2402.06161" title="Download PDF">pdf</a>, <a href="/ps/2402.06161" title="Download PostScript">ps</a>, <a href="/format/2402.06161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource Allocation for Channel Estimation in Reconfigurable Intelligent  Surface-Aided Multi-Cell Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yining Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Sheng Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The key message we deliver in this paper is that: RIS deployment is not `the more, the better', only when blockage objects are dense should one deploy more RISs
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Reconfigurable intelligent surface (RIS) is a promising solution to deal with
the blockage-sensitivity of millimeter wave band and reduce the high energy
consumption caused by network densification. However, deploying large scale
RISs may not bring expected performance gain due to significant channel
estimation overhead and non-negligible reflected interference. In this paper,
we derive the analytical expressions of the coverage probability, area spectrum
efficiency (ASE) and energy efficiency (EE) of a downlink RIS-aided multi-cell
network. In order to optimize the network performance, we investigate the
conditions for the optimal number of training symbols of each
antenna-to-antenna and antenna-to-element path (referred to as the optimal unit
training overhead) in channel estimation. Our study shows that: 1) RIS
deployment is not `the more, the better', only when blockage objects are dense
should one deploy more RISs; 2) the coverage probability is maximized when the
unit training overhead is designed as large as possible; 3) however, the
ASE-and-EE-optimal unit training overhead exists. It is a monotonically
increasing function of the frame length and a monotonically decreasing function
of the average signal-to-noise-ratio (in the high signal-to-noise-ratio
region). Additionally, the optimal unit training overhead is smaller when
communication ends deploy particularly few or many antennas.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06164" title="Abstract">arXiv:2402.06164</a> [<a href="/pdf/2402.06164" title="Download PDF">pdf</a>, <a href="/format/2402.06164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithm-hardware co-design for Energy-Efficient A/D conversion in  ReRAM-based accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenguang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhihang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingchen Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Guangyu Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages; 7 figures; to be published in DATE 2024 - Design, Automation and Test in Europe
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Deep neural networks are widely deployed in many fields. Due to the in-situ
computation (known as processing in memory) capacity of the Resistive Random
Access Memory (ReRAM) crossbar, ReRAM-based accelerator shows potential in
accelerating DNN with low power and high performance. However, despite power
advantage, such kind of accelerators suffer from the high power consumption of
peripheral circuits, especially Analog-to-Digital Converter (ADC), which
account for over 60 percent of total power consumption. This problem hinders
the ReRAM-based accelerator to achieve higher efficiency.
<br />Some redundant Analog-to-Digital conversion operations have no contribution
to maintaining inference accuracy, and such operations can be eliminated by
modifying the ADC searching logic. Based on such observations, we propose an
algorithm-hardware co-design method and explore the co-design approach in both
hardware design and quantization algorithms. Firstly, we focus on the
distribution output along the crossbar's bit-lines and identify the
fine-grained redundant ADC sampling bits. % of weight and To further compress
ADC bits, we propose a hardware-friendly quantization method and coding scheme,
in which different quantization strategy was applied to the partial results in
different intervals. To support the two features above, we propose a
lightweight architectural design based on SAR-ADC\@. It's worth mentioning that
our method is not only more energy efficient but also retains the flexibility
of the algorithm. Experiments demonstrate that our method can reduce about $1.6
\sim 2.3 \times$ ADC power reduction.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06165" title="Abstract">arXiv:2402.06165</a> [<a href="/pdf/2402.06165" title="Download PDF">pdf</a>, <a href="/format/2402.06165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Contrastive Feature Representations for Facial Action Unit  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shang%2C+Z">Ziqiao Shang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+F">Fei Teng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianrui Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures, submitted to an IEEE journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The predominant approach to facial action unit (AU) detection revolves around
a supervised multi-label binary classification problem. Existing methodologies
often encode pixel-level information of AUs, thereby imposing substantial
demands on model complexity and expressiveness. Moreover, this practice
elevates the susceptibility to overfitting due to the presence of noisy AU
labels. In the present study, we introduce a contrastive learning framework
enhanced by both supervised and self-supervised signals. The objective is to
acquire discriminative features, deviating from the conventional pixel-level
learning paradigm within the domain of AU detection. To address the challenge
posed by noisy AU labels, we augment the supervised signal through the
introduction of a self-supervised signal. This augmentation is achieved through
positive sample sampling, encompassing three distinct types of positive sample
pairs. Furthermore, to mitigate the imbalanced distribution of each AU type, we
employ an importance re-weighting strategy tailored for minority AUs. The
resulting loss, denoted as AUNCE, is proposed to encapsulate this strategy. Our
experimental assessments, conducted on two widely-utilized benchmark datasets
(BP4D and DISFA), underscore the superior performance of our approach compared
to state-of-the-art methods in the realm of AU detection.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06168" title="Abstract">arXiv:2402.06168</a> [<a href="/pdf/2402.06168" title="Download PDF">pdf</a>, <a href="/format/2402.06168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconfigurable Stochastic Neurons Based on Strain Engineered Low Barrier  Nanomagnets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahman%2C+R">Rahnuma Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Ganguly%2C+S">Samiran Ganguly</a>, 
<a href="/search/cs?searchtype=author&query=Bandyopadhyay%2C+S">Supriyo Bandyopadhyay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Mesoscale and Nanoscale Physics (cond-mat.mes-hall); Systems and Control (eess.SY)

</div>
<p class="mathjax">Stochastic neurons are efficient hardware accelerators for solving a large
variety of combinatorial optimization problems. "Binary" stochastic neurons
(BSN) are those whose states fluctuate randomly between two levels +1 and -1,
with the probability of being in either level determined by an external bias.
"Analog" stochastic neurons (ASNs), in contrast, can assume any state between
the two levels randomly (hence "analog") and can perform analog signal
processing. They may be leveraged for such tasks as temporal sequence learning,
processing and prediction. Both BSNs and ASNs can be used to build efficient
and scalable neural networks. Both can be implemented with low (potential
energy) barrier nanomagnets (LBMs) whose random magnetization orientations
encode the binary or analog state variables. The difference between them is
that the potential energy barrier in a BSN LBM, albeit low, is much higher than
that in an ASN LBM. As a result, a BSN LBM has a clear double well potential
profile, which makes its magnetization orientation assume one of two
orientations at any time, resulting in the binary behavior. ASN nanomagnets, on
the other hand, hardly have any energy barrier at all and hence lack the double
well feature. That makes their magnetizations fluctuate in an analog fashion.
Hence, one can reconfigure an ASN to a BSN, and vice-versa, by simply raising
and lowering the energy barrier. If the LBM is magnetostrictive, then this can
be done with local (electrically generated) strain. Such a reconfiguration
capability heralds a powerful field programmable architecture for a p-computer,
and the energy cost for this type of reconfiguration is miniscule.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06170" title="Abstract">arXiv:2402.06170</a> [<a href="/pdf/2402.06170" title="Download PDF">pdf</a>, <a href="/format/2402.06170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task Supportive and Personalized Human-Large Language Model Interaction:  A User Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Ben Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiqun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Karimnazarov%2C+J">Jamshed Karimnazarov</a>, 
<a href="/search/cs?searchtype=author&query=Thompson%2C+N">Nicolas Thompson</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 2024 ACM SIGIR Conference on Human Information
  Interaction and Retrieval
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Large language model (LLM) applications, such as ChatGPT, are a powerful tool
for online information-seeking (IS) and problem-solving tasks. However, users
still face challenges initializing and refining prompts, and their cognitive
barriers and biased perceptions further impede task completion. These issues
reflect broader challenges identified within the fields of IS and interactive
information retrieval (IIR). To address these, our approach integrates task
context and user perceptions into human-ChatGPT interactions through prompt
engineering. We developed a ChatGPT-like platform integrated with supportive
functions, including perception articulation, prompt suggestion, and
conversation explanation. Our findings of a user study demonstrate that the
supportive functions help users manage expectations, reduce cognitive loads,
better refine prompts, and increase user engagement. This research enhances our
comprehension of designing proactive and user-centric systems with LLMs. It
offers insights into evaluating human-LLM interactions and emphasizes potential
challenges for under served users.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06171" title="Abstract">arXiv:2402.06171</a> [<a href="/pdf/2402.06171" title="Download PDF">pdf</a>, <a href="/format/2402.06171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pushing Boundaries: Mixup&#x27;s Influence on Neural Collapse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fisher%2C+Q">Quinn Fisher</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+H">Haoming Meng</a>, 
<a href="/search/cs?searchtype=author&query=Papyan%2C+V">Vardan Papyan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at the International Conference on Learning Representations (ICLR 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Mixup is a data augmentation strategy that employs convex combinations of
training instances and their respective labels to augment the robustness and
calibration of deep neural networks. Despite its widespread adoption, the
nuanced mechanisms that underpin its success are not entirely understood. The
observed phenomenon of Neural Collapse, where the last-layer activations and
classifier of deep networks converge to a simplex equiangular tight frame
(ETF), provides a compelling motivation to explore whether mixup induces
alternative geometric configurations and whether those could explain its
success. In this study, we delve into the last-layer activations of training
data for deep networks subjected to mixup, aiming to uncover insights into its
operational efficacy. Our investigation, spanning various architectures and
dataset pairs, reveals that mixup's last-layer activations predominantly
converge to a distinctive configuration different than one might expect. In
this configuration, activations from mixed-up examples of identical classes
align with the classifier, while those from different classes delineate
channels along the decision boundary. Moreover, activations in earlier layers
exhibit patterns, as if trained with manifold mixup. These findings are
unexpected, as mixed-up features are not simple convex combinations of feature
class means (as one might get, for example, by training mixup with the mean
squared error loss). By analyzing this distinctive geometric configuration, we
elucidate the mechanisms by which mixup enhances model calibration. To further
validate our empirical observations, we conduct a theoretical analysis under
the assumption of an unconstrained features model, utilizing the mixup loss.
Through this, we characterize and derive the optimal last-layer features under
the assumption that the classifier forms a simplex ETF.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06174" title="Abstract">arXiv:2402.06174</a> [<a href="/pdf/2402.06174" title="Download PDF">pdf</a>, <a href="/format/2402.06174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous-Time Radar-Inertial and Lidar-Inertial Odometry using a  Gaussian Process Motion Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Burnett%2C+K">Keenan Burnett</a>, 
<a href="/search/cs?searchtype=author&query=Schoellig%2C+A+P">Angela P. Schoellig</a>, 
<a href="/search/cs?searchtype=author&query=Barfoot%2C+T+D">Timothy D. Barfoot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions on Robotics (2024-02-08)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this work, we demonstrate continuous-time radar-inertial and
lidar-inertial odometry using a Gaussian process motion prior. Using a sparse
prior, we demonstrate improved computational complexity during preintegration
and interpolation. We use a white-noise-on-acceleration motion prior and treat
the gyroscope as a direct measurement of the state while preintegrating
accelerometer measurements to form relative velocity factors. Our odometry is
implemented using sliding-window batch trajectory estimation. To our knowledge,
our work is the first to demonstrate radar-inertial odometry with a spinning
mechanical radar using both gyroscope and accelerometer measurements. We
improve the performance of our radar odometry by 19\% by incorporating an IMU.
Our approach is efficient and we demonstrate real-time performance. Code for
this project can be found at: https://github.com/utiasASRL/steam_icp
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06176" title="Abstract">arXiv:2402.06176</a> [<a href="/pdf/2402.06176" title="Download PDF">pdf</a>, <a href="/format/2402.06176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperative Nonlinear Guidance Strategies for Guaranteed Pursuit-Evasion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kumar%2C+S">Saurabh Kumar</a>, 
<a href="/search/eess?searchtype=author&query=Kumar%2C+S+R">Shashi Ranjan Kumar</a>, 
<a href="/search/eess?searchtype=author&query=Sinha%2C+A">Abhinav Sinha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Multiagent Systems (cs.MA); Robotics (cs.RO); Dynamical Systems (math.DS); Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper addresses the pursuit-evasion problem involving three agents -- a
purser, an evader, and a defender. We develop cooperative guidance laws for the
evader-defender team that guarantee that the defender intercepts the pursuer
before it reaches the vicinity of the evader. Unlike heuristic methods, optimal
control, differential game formulation, and recently proposed time-constrained
guidance techniques, we propose a geometric solution to safeguard the evader
from the pursuer's incoming threat. The proposed strategy is computationally
efficient and expected to be scalable as the number of agents increases.
Another alluring feature of the proposed strategy is that the evader-defender
team does not require the knowledge of the pursuer's strategy and that the
pursuer's interception is guaranteed from arbitrary initial engagement
geometries. We further show that the necessary error variables for the
evader-defender team vanish within a time that can be exactly prescribed prior
to the three-body engagement. Finally, we demonstrate the efficacy of the
proposed cooperative defense strategy via simulation in diverse engagement
scenarios.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06178" title="Abstract">arXiv:2402.06178</a> [<a href="/pdf/2402.06178" title="Download PDF">pdf</a>, <a href="/format/2402.06178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MusicMagus: Zero-Shot Text-to-Music Editing via Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yixiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ikemiya%2C+Y">Yukara Ikemiya</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+G">Gus Xia</a>, 
<a href="/search/cs?searchtype=author&query=Murata%2C+N">Naoki Murata</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez%2C+M">Marco Mart&#xed;nez</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+W">Wei-Hsiang Liao</a>, 
<a href="/search/cs?searchtype=author&query=Mitsufuji%2C+Y">Yuki Mitsufuji</a>, 
<a href="/search/cs?searchtype=author&query=Dixon%2C+S">Simon Dixon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://bit.ly/musicmagus-demo">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recent advances in text-to-music generation models have opened new avenues in
musical creativity. However, music generation usually involves iterative
refinements, and how to edit the generated music remains a significant
challenge. This paper introduces a novel approach to the editing of music
generated by such models, enabling the modification of specific attributes,
such as genre, mood and instrument, while maintaining other aspects unchanged.
Our method transforms text editing to \textit{latent space manipulation} while
adding an extra constraint to enforce consistency. It seamlessly integrates
with existing pretrained text-to-music diffusion models without requiring
additional training. Experimental results demonstrate superior performance over
both zero-shot and certain supervised baselines in style and timbre transfer
evaluations. Additionally, we showcase the practical applicability of our
approach in real-world music editing scenarios.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06184" title="Abstract">arXiv:2402.06184</a> [<a href="/pdf/2402.06184" title="Download PDF">pdf</a>, <a href="/format/2402.06184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The boundary of neural network trainability is fractal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sohl-Dickstein%2C+J">Jascha Sohl-Dickstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages, mesmerizing fractals
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Chaotic Dynamics (nlin.CD)

</div>
<p class="mathjax">Some fractals -- for instance those associated with the Mandelbrot and
quadratic Julia sets -- are computed by iterating a function, and identifying
the boundary between hyperparameters for which the resulting series diverges or
remains bounded. Neural network training similarly involves iterating an update
function (e.g. repeated steps of gradient descent), can result in convergent or
divergent behavior, and can be extremely sensitive to small changes in
hyperparameters. Motivated by these similarities, we experimentally examine the
boundary between neural network hyperparameters that lead to stable and
divergent training. We find that this boundary is fractal over more than ten
decades of scale in all tested configurations.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06185" title="Abstract">arXiv:2402.06185</a> [<a href="/pdf/2402.06185" title="Download PDF">pdf</a>, <a href="/format/2402.06185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Development and validation of an artificial intelligence model to  accurately predict spinopelvic parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harake%2C+E+S">Edward S. Harake</a>, 
<a href="/search/cs?searchtype=author&query=Linzey%2C+J+R">Joseph R. Linzey</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Cheng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+R+S">Rushikesh S. Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Zaki%2C+M+M">Mark M. Zaki</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+J+C">Jaes C. Jones</a>, 
<a href="/search/cs?searchtype=author&query=Khalsa%2C+S+S">Siri S. Khalsa</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+H">John H. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Wilseck%2C+Z">Zachary Wilseck</a>, 
<a href="/search/cs?searchtype=author&query=Joseph%2C+J+R">Jacob R. Joseph</a>, 
<a href="/search/cs?searchtype=author&query=Hollon%2C+T+C">Todd C. Hollon</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+P">Paul Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, to appear in Journal of Neurosurgery: Spine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Objective. Achieving appropriate spinopelvic alignment has been shown to be
associated with improved clinical symptoms. However, measurement of spinopelvic
radiographic parameters is time-intensive and interobserver reliability is a
concern. Automated measurement tools have the promise of rapid and consistent
measurements, but existing tools are still limited by some degree of manual
user-entry requirements. This study presents a novel artificial intelligence
(AI) tool called SpinePose that automatically predicts spinopelvic parameters
with high accuracy without the need for manual entry.
<br />Methods. SpinePose was trained and validated on 761 sagittal whole-spine
X-rays to predict sagittal vertical axis (SVA), pelvic tilt (PT), pelvic
incidence (PI), sacral slope (SS), lumbar lordosis (LL), T1-pelvic angle
(T1PA), and L1-pelvic angle (L1PA). A separate test set of 40 X-rays was
labeled by 4 reviewers, including fellowship-trained spine surgeons and a
fellowship-trained radiologist with neuroradiology subspecialty certification.
Median errors relative to the most senior reviewer were calculated to determine
model accuracy on test images. Intraclass correlation coefficients (ICC) were
used to assess inter-rater reliability.
<br />Results. SpinePose exhibited the following median (interquartile range)
parameter errors: SVA: 2.2(2.3)mm, p=0.93; PT: 1.3(1.2){\deg}, p=0.48; SS:
1.7(2.2){\deg}, p=0.64; PI: 2.2(2.1){\deg}, p=0.24; LL: 2.6(4.0){\deg}, p=0.89;
T1PA: 1.1(0.9){\deg}, p=0.42; and L1PA: 1.4(1.6){\deg}, p=0.49. Model
predictions also exhibited excellent reliability at all parameters (ICC:
0.91-1.0).
<br />Conclusions. SpinePose accurately predicted spinopelvic parameters with
excellent reliability comparable to fellowship-trained spine surgeons and
neuroradiologists. Utilization of predictive AI tools in spinal imaging can
substantially aid in patient selection and surgical planning.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06187" title="Abstract">arXiv:2402.06187</a> [<a href="/pdf/2402.06187" title="Download PDF">pdf</a>, <a href="/format/2402.06187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Premier-TACO: Pretraining Multitask Representation via Temporal  Action-Driven Contrastive Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Ruijie Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yongyuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiyao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shuang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Daum%C3%A9%2C+H">Hal Daum&#xe9; III</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huazhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Langford%2C+J">John Langford</a>, 
<a href="/search/cs?searchtype=author&query=Palanisamy%2C+P">Praveen Palanisamy</a>, 
<a href="/search/cs?searchtype=author&query=Basu%2C+K+S">Kalyan Shankar Basu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Furong Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">We present Premier-TACO, a multitask feature representation learning approach
designed to improve few-shot policy learning efficiency in sequential
decision-making tasks. Premier-TACO leverages a subset of multitask offline
datasets for pretraining a general feature representation, which captures
critical environmental dynamics and is fine-tuned using minimal expert
demonstrations. It advances the temporal action contrastive learning (TACO)
objective, known for state-of-the-art results in visual control tasks, by
incorporating a novel negative example sampling strategy. This strategy is
crucial in significantly boosting TACO's computational efficiency, making
large-scale multitask offline pretraining feasible. Our extensive empirical
evaluation in a diverse set of continuous control benchmarks including Deepmind
Control Suite, MetaWorld, and LIBERO demonstrate Premier-TACO's effectiveness
in pretraining visual representations, significantly enhancing few-shot
imitation learning of novel tasks. Our code, pretraining data, as well as
pretrained model checkpoints will be released at
https://github.com/PremierTACO/premier-taco.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06188" title="Abstract">arXiv:2402.06188</a> [<a href="/pdf/2402.06188" title="Download PDF">pdf</a>, <a href="/format/2402.06188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A self-supervised framework for learning whole slide representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+X">Xinhai Hou</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Cheng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Kondepudi%2C+A">Akhil Kondepudi</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Y">Yiwei Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Chowdury%2C+A+Z">Asadur Zaman Chowdury</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Honglak Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hollon%2C+T+C">Todd C. Hollon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Whole slide imaging is fundamental to biomedical microscopy and computational
pathology. However, whole slide images (WSIs) present a complex computer vision
challenge due to their gigapixel size, diverse histopathologic features,
spatial heterogeneity, and limited/absent data annotations. These challenges
highlight that supervised training alone can result in suboptimal whole slide
representations. Self-supervised representation learning can achieve
high-quality WSI visual feature learning for downstream diagnostic tasks, such
as cancer diagnosis or molecular genetic prediction. Here, we present a general
self-supervised whole slide learning (S3L) framework for gigapixel-scale
self-supervision of WSIs. S3L combines data transformation strategies from
transformer-based vision and language modeling into a single unified framework
to generate paired views for self-supervision. S3L leverages the inherent
regional heterogeneity, histologic feature variability, and information
redundancy within WSIs to learn high-quality whole-slide representations. We
benchmark S3L visual representations on two diagnostic tasks for two biomedical
microscopy modalities. S3L significantly outperforms WSI baselines for cancer
diagnosis and genetic mutation prediction. Additionally, S3L achieves good
performance using both in-domain and out-of-distribution patch encoders,
demonstrating good flexibility and generalizability.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06190" title="Abstract">arXiv:2402.06190</a> [<a href="/pdf/2402.06190" title="Download PDF">pdf</a>, <a href="/format/2402.06190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked LoGoNet: Fast and Accurate 3D Image Analysis for Medical Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Monsefi%2C+A+K">Amin Karimi Monsefi</a>, 
<a href="/search/cs?searchtype=author&query=Karisani%2C+P">Payam Karisani</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mengxi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Stacey Choi</a>, 
<a href="/search/cs?searchtype=author&query=Doble%2C+N">Nathan Doble</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Heng Ji</a>, 
<a href="/search/cs?searchtype=author&query=Parthasarathy%2C+S">Srinivasan Parthasarathy</a>, 
<a href="/search/cs?searchtype=author&query=Ramnath%2C+R">Rajiv Ramnath</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Standard modern machine-learning-based imaging methods have faced challenges
in medical applications due to the high cost of dataset construction and,
thereby, the limited labeled training data available. Additionally, upon
deployment, these methods are usually used to process a large volume of data on
a daily basis, imposing a high maintenance cost on medical facilities. In this
paper, we introduce a new neural network architecture, termed LoGoNet, with a
tailored self-supervised learning (SSL) method to mitigate such challenges.
LoGoNet integrates a novel feature extractor within a U-shaped architecture,
leveraging Large Kernel Attention (LKA) and a dual encoding strategy to capture
both long-range and short-range feature dependencies adeptly. This is in
contrast to existing methods that rely on increasing network capacity to
enhance feature extraction. This combination of novel techniques in our model
is especially beneficial in medical image segmentation, given the difficulty of
learning intricate and often irregular body organ shapes, such as the spleen.
Complementary, we propose a novel SSL method tailored for 3D images to
compensate for the lack of large labeled datasets. The method combines masking
and contrastive learning techniques within a multi-task learning framework and
is compatible with both Vision Transformer (ViT) and CNN-based models. We
demonstrate the efficacy of our methods in numerous tasks across two standard
datasets (i.e., BTCV and MSD). Benchmark comparisons with eight
state-of-the-art models highlight LoGoNet's superior performance in both
inference time and accuracy.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06191" title="Abstract">arXiv:2402.06191</a> [<a href="/pdf/2402.06191" title="Download PDF">pdf</a>, <a href="/format/2402.06191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Berkeley Single Cell Computational Microscopy (BSCCM) Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pinkard%2C+H">Henry Pinkard</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cherry Liu</a>, 
<a href="/search/cs?searchtype=author&query=Nyatigo%2C+F">Fanice Nyatigo</a>, 
<a href="/search/cs?searchtype=author&query=Fletcher%2C+D+A">Daniel A. Fletcher</a>, 
<a href="/search/cs?searchtype=author&query=Waller%2C+L">Laura Waller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Computational microscopy, in which hardware and algorithms of an imaging
system are jointly designed, shows promise for making imaging systems that cost
less, perform more robustly, and collect new types of information. Often, the
performance of computational imaging systems, especially those that incorporate
machine learning, is sample-dependent. Thus, standardized datasets are an
essential tool for comparing the performance of different approaches. Here, we
introduce the Berkeley Single Cell Computational Microscopy (BSCCM) dataset,
which contains over ~12,000,000 images of 400,000 of individual white blood
cells. The dataset contains images captured with multiple illumination patterns
on an LED array microscope and fluorescent measurements of the abundance of
surface proteins that mark different cell types. We hope this dataset will
provide a valuable resource for the development and testing of new algorithms
in computational microscopy and computer vision with practical biomedical
applications.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06194" title="Abstract">arXiv:2402.06194</a> [<a href="/pdf/2402.06194" title="Download PDF">pdf</a>, <a href="/format/2402.06194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anubis: Towards Reliable Cloud AI Infrastructure via Proactive  Validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yifan Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuting Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ziyue Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+L">Lei Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+G">Guoshuai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuguang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+D">Dong Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Pinzur%2C+B">Boris Pinzur</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jose%2C+J">Jithin Jose</a>, 
<a href="/search/cs?searchtype=author&query=Pourreza%2C+H">Hossein Pourreza</a>, 
<a href="/search/cs?searchtype=author&query=Baxter%2C+J">Jeff Baxter</a>, 
<a href="/search/cs?searchtype=author&query=Datta%2C+K">Kushal Datta</a>, 
<a href="/search/cs?searchtype=author&query=Ram%2C+P">Prabhat Ram</a>, 
<a href="/search/cs?searchtype=author&query=Melton%2C+L">Luke Melton</a>, 
<a href="/search/cs?searchtype=author&query=Chau%2C+J">Joe Chau</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Peng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yongqiang Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Lidong Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Reliability in cloud AI infrastructure is crucial for cloud service
providers, prompting the widespread use of hardware redundancies. However,
these redundancies can inadvertently lead to hidden degradation, so called
"gray failure", for AI workloads, significantly affecting end-to-end
performance and concealing performance issues, which complicates root cause
analysis for failures and regressions.
<br />We introduce Anubis, a proactive validation system for AI infrastructure that
mitigates hidden degradation caused by hardware redundancies and enhances
overall reliability. Anubis features a comprehensive benchmark suite, capable
of evaluating individual hardware components and representing most real AI
workloads. It comprises a Validator which learns benchmark criteria to clearly
pinpoint defective components. Additionally, Anubis incorporates a Selector to
balance validation time and issue-related penalties, enabling optimal timing
for validation execution with a tailored subset of benchmarks. Through testbed
evaluation and simulation, we demonstrate that Anubis can increase the mean
time between incidents by up to 22.61x. Anubis has been successfully deployed
in Azure production, validating hundreds of thousands of GPUs over the last two
years.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06195" title="Abstract">arXiv:2402.06195</a> [<a href="/pdf/2402.06195" title="Download PDF">pdf</a>, <a href="/format/2402.06195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Safe Navigation of Multi-Agent Systems using Control Barrier  Function-Based Optimal Controllers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mestres%2C+P">Pol Mestres</a>, 
<a href="/search/eess?searchtype=author&query=Nieto-Granda%2C+C">Carlos Nieto-Granda</a>, 
<a href="/search/eess?searchtype=author&query=Cort%C3%A9s%2C+J">Jorge Cort&#xe9;s</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper proposes a distributed controller synthesis framework for safe
navigation of multi-agent systems. We leverage control barrier functions to
formulate collision avoidance with obstacles and teammates as constraints on
the control input for a state-dependent network optimization problem that
encodes team formation and the navigation task. Our algorithmic solution is
valid for general nonlinear control dynamics and optimization problems. The
resulting controller is distributed, satisfies the safety constraints at all
times, and is asymptotically optimal. We illustrate its performance in a team
of differential-drive robots in a variety of complex environments, both in
simulation and in hardware.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06196" title="Abstract">arXiv:2402.06196</a> [<a href="/pdf/2402.06196" title="Download PDF">pdf</a>, <a href="/format/2402.06196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Minaee%2C+S">Shervin Minaee</a>, 
<a href="/search/cs?searchtype=author&query=Mikolov%2C+T">Tomas Mikolov</a>, 
<a href="/search/cs?searchtype=author&query=Nikzad%2C+N">Narjes Nikzad</a>, 
<a href="/search/cs?searchtype=author&query=Chenaghlu%2C+M">Meysam Chenaghlu</a>, 
<a href="/search/cs?searchtype=author&query=Socher%2C+R">Richard Socher</a>, 
<a href="/search/cs?searchtype=author&query=Amatriain%2C+X">Xavier Amatriain</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2401.14423">arXiv:2401.14423</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) have drawn a lot of attention due to their
strong performance on a wide range of natural language tasks, since the release
of ChatGPT in November 2022. LLMs' ability of general-purpose language
understanding and generation is acquired by training billions of model's
parameters on massive amounts of text data, as predicted by scaling laws
\cite{kaplan2020scaling,hoffmann2022training}. The research area of LLMs, while
very recent, is evolving rapidly in many different ways. In this paper, we
review some of the most prominent LLMs, including three popular LLM families
(GPT, LLaMA, PaLM), and discuss their characteristics, contributions and
limitations. We also give an overview of techniques developed to build, and
augment LLMs. We then survey popular datasets prepared for LLM training,
fine-tuning, and evaluation, review widely used LLM evaluation metrics, and
compare the performance of several popular LLMs on a set of representative
benchmarks. Finally, we conclude the paper by discussing open challenges and
future research directions.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06198" title="Abstract">arXiv:2402.06198</a> [<a href="/pdf/2402.06198" title="Download PDF">pdf</a>, <a href="/ps/2402.06198" title="Download PostScript">ps</a>, <a href="/format/2402.06198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GS-CLIP: Gaussian Splatting for Contrastive Language-Image-3D  Pretraining from Real-World Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yanpeng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yihan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaodan Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6-page technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D Shape represented as point cloud has achieve advancements in multimodal
pre-training to align image and language descriptions, which is curial to
object identification, classification, and retrieval. However, the discrete
representations of point cloud lost the object's surface shape information and
creates a gap between rendering results and 2D correspondences. To address this
problem, we propose GS-CLIP for the first attempt to introduce 3DGS (3D
Gaussian Splatting) into multimodal pre-training to enhance 3D representation.
GS-CLIP leverages a pre-trained vision-language model for a learned common
visual and textual space on massive real world image-text pairs and then learns
a 3D Encoder for aligning 3DGS optimized per object. Additionally, a novel
Gaussian-Aware Fusion is proposed to extract and fuse global explicit feature.
As a general framework for language-image-3D pre-training, GS-CLIP is agnostic
to 3D backbone networks. Experiments on challenging shows that GS-CLIP
significantly improves the state-of-the-art, outperforming the previously best
results.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06199" title="Abstract">arXiv:2402.06199</a> [<a href="/pdf/2402.06199" title="Download PDF">pdf</a>, <a href="/format/2402.06199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A generalized formulation for gradient schemes in unstructured finite  volume method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Deka%2C+M">Mandeep Deka</a>, 
<a href="/search/math?searchtype=author&query=Assam%2C+A">Ashwani Assam</a>, 
<a href="/search/math?searchtype=author&query=Natarajan%2C+G">Ganesh Natarajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">We present a generic framework for gradient reconstruction schemes on
unstructured meshes using the notion of a dyadic sum-vector product. The
proposed formulation reconstructs centroidal gradients of a scalar from its
directional derivatives along specific directions in a suitably defined
neighbourhood. We show that existing gradient reconstruction schemes can be
encompassed within this framework by a suitable choice of the geometric vectors
that define the dyadic sum tensor. The proposed framework also allows us to
re-interpret certain hybrid schemes, which might not be derivable through
traditional routes. Additionally, a generalization of flexible gradient schemes
is proposed that can be employed to enhance the robustness of consistent
gradient schemes without compromising on the accuracy of the computed
gradients.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06201" title="Abstract">arXiv:2402.06201</a> [<a href="/pdf/2402.06201" title="Download PDF">pdf</a>, <a href="/format/2402.06201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximizing Consistent Force Output for Shape Memory Alloy Artificial  Muscles in Soft Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anderson%2C+M+L">Meredith L. Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+R">Ran Jing</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+J+C+P">Juan C. Pacheco Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+I">Ilyoung Yang</a>, 
<a href="/search/cs?searchtype=author&query=Alizadeh-Shabdiz%2C+S">Sarah Alizadeh-Shabdiz</a>, 
<a href="/search/cs?searchtype=author&query=DeLorey%2C+C">Charles DeLorey</a>, 
<a href="/search/cs?searchtype=author&query=Sabelhaus%2C+A+P">Andrew P. Sabelhaus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures, accepted by 2024 IEEE International Conference on Soft Robotics (RoboSoft)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Soft robots have immense potential given their inherent safety and
adaptability, but challenges in soft actuator forces and design constraints
have limited scaling up soft robots to larger sizes. Electrothermal shape
memory alloy (SMA) artificial muscles have the potential to create these large
forces and high displacements, but consistently using these muscles under a
well-defined model, in-situ in a soft robot, remains an open challenge. This
article provides a system for maintaining the highest-possible consistent SMA
forces, over long lifetimes, by combining a fatigue testing protocol with a
supervisory control system for the muscles' internal temperature state. We
propose a design of a soft limb with swap-able SMA muscles, and deploy the limb
in a blocked-force test to quantify the relationship between the measured
maximum force at different temperatures over different lifetimes. Then, by
applying an invariance-based control system to maintain temperatures under our
long-life limit, we demonstrate consistent high forces in a practical task over
hundreds of cycles. The method we developed allows for practical implementation
of SMAs in soft robots through characterizing and controlling their behavior
in-situ, and provides a method to impose limits that maximize their consistent,
repeatable behavior.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06203" title="Abstract">arXiv:2402.06203</a> [<a href="/pdf/2402.06203" title="Download PDF">pdf</a>, <a href="/ps/2402.06203" title="Download PostScript">ps</a>, <a href="/format/2402.06203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Virtual and Remote Robotic Laboratory Using EJS, MATLAB and LabVIEW
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaos%2C+D">Dictino Chaos</a>, 
<a href="/search/cs?searchtype=author&query=Chac%C3%B3n%2C+J">Jes&#xfa;s Chac&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Lopez-Orozco%2C+J+A">Jose Antonio Lopez-Orozco</a>, 
<a href="/search/cs?searchtype=author&query=Dormido%2C+S">Sebastian Dormido</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper describes the design and implementation of a virtual and remote
laboratory based on Easy Java Simulations (EJS) and LabVIEW. The main
application of this laboratory is to improve the study of sensors in Mobile
Robotics, dealing with the problems that arise on the real world experiments.
This laboratory allows the user to work from their homes, tele-operating a real
robot that takes measurements from its sensors in order to obtain a map of its
environment. In addition, the application allows interacting with a robot
simulation (virtual laboratory) or with a real robot (remote laboratory), with
the same simple and intuitive graphical user interface in EJS. Thus, students
can develop signal processing and control algorithms for the robot in
simulation and then deploy them on the real robot for testing purposes.
Practical examples of application of the laboratory on the inter University
Master of Systems Engineering and Automatic Control are presented.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06204" title="Abstract">arXiv:2402.06204</a> [<a href="/pdf/2402.06204" title="Download PDF">pdf</a>, <a href="/format/2402.06204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Generative AI Paradox on Evaluation: What It Can Solve, It May Not  Evaluate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+J">Juhyun Oh</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+E">Eunsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Cha%2C+I">Inha Cha</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+A">Alice Oh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper explores the assumption that Large Language Models (LLMs) skilled
in generation tasks are equally adept as evaluators. We assess the performance
of three LLMs and one open-source LM in Question-Answering (QA) and evaluation
tasks using the TriviaQA (Joshi et al., 2017) dataset. Results indicate a
significant disparity, with LLMs exhibiting lower performance in evaluation
tasks compared to generation tasks. Intriguingly, we discover instances of
unfaithful evaluation where models accurately evaluate answers in areas where
they lack competence, underscoring the need to examine the faithfulness and
trustworthiness of LLMs as evaluators. This study contributes to the
understanding of "the Generative AI Paradox" (West et al., 2023), highlighting
a need to explore the correlation between generative excellence and evaluation
proficiency, and the necessity to scrutinize the faithfulness aspect in model
evaluations.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06206" title="Abstract">arXiv:2402.06206</a> [<a href="/pdf/2402.06206" title="Download PDF">pdf</a>, <a href="/ps/2402.06206" title="Download PostScript">ps</a>, <a href="/format/2402.06206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EJS, JIL Server, and LabVIEW: An Architecture for Rapid Development of  Remote Labs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chac%C3%B3n%2C+J">Jes&#xfa;s Chac&#xf3;n</a>, 
<a href="/search/eess?searchtype=author&query=Vargas%2C+H">Hector Vargas</a>, 
<a href="/search/eess?searchtype=author&query=Farias%2C+G">Gonzalo Farias</a>, 
<a href="/search/eess?searchtype=author&query=S%C3%A1nchez%2C+J">Jose S&#xe1;nchez</a>, 
<a href="/search/eess?searchtype=author&query=Dormido%2C+S">Sebasti&#xe1;n Dormido</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Designing and developing web-enabled remote laboratories for pedagogical
purposes is not an easy task. Often, developers (generally, educators who know
the subjects they teach but lack of the technical and programming skills
required to build Internet-based educational applications) end up discarding
the idea of exploring these new teaching and learning experiences mainly due to
the technical issues that must be mastered. To tackle this problem, authors
present a novel technique that allows developers to create remote labs in a
quick, didactical, and straightforward way. This framework is based on the use
of two well-known software tools in the scope of engineering education, Easy
Java Simulations and LabVIEW. The development exploits a new feature of Easy
Java Simulations known as EJS-elements that enables Java developers to create
and integrate their own authoring libraries (elements) into EJS, thus
increasing its application possibilities. Particularly, the EJS element here
presented allows to LabVIEW programs be controlled from EJS applications
through a communication network. This paper presents the element creation
details and how this can be used to create web-enabled experimentation
environments for educational purposes. A step by step example of development of
a remote lab for automatic control education is described.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06210" title="Abstract">arXiv:2402.06210</a> [<a href="/pdf/2402.06210" title="Download PDF">pdf</a>, <a href="/format/2402.06210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PULSE: Parametric Hardware Units for Low-power Sparsity-Aware  Convolution Engine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aliyev%2C+I">Ilkin Aliyev</a>, 
<a href="/search/cs?searchtype=author&query=Adegbija%2C+T">Tosiron Adegbija</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE International Symposium on Circuits and Systems (ISCAS) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Spiking Neural Networks (SNNs) have become popular for their more
bio-realistic behavior than Artificial Neural Networks (ANNs). However,
effectively leveraging the intrinsic, unstructured sparsity of SNNs in hardware
is challenging, especially due to the variability in sparsity across network
layers. This variability depends on several factors, including the input
dataset, encoding scheme, and neuron model. Most existing SNN accelerators fail
to account for the layer-specific workloads of an application (model +
dataset), leading to high energy consumption. To address this, we propose a
design-time parametric hardware generator that takes layer-wise sparsity and
the number of processing elements as inputs and synthesizes the corresponding
hardware. The proposed design compresses sparse spike trains using a priority
encoder and efficiently shifts the activations across the network's layers. We
demonstrate the robustness of our proposed approach by first profiling a given
application's characteristics followed by performing efficient resource
allocation. Results on a Xilinx Kintex FPGA (Field Programmable Gate Arrays)
using MNIST, FashionMNIST, and SVHN datasets show a 3.14x improvement in
accelerator efficiency (FPS/W) compared to a sparsity-oblivious systolic
array-based accelerator. Compared to the most recent sparsity-aware work, our
solution improves efficiency by 1.72x.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06211" title="Abstract">arXiv:2402.06211</a> [<a href="/pdf/2402.06211" title="Download PDF">pdf</a>, <a href="/format/2402.06211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Tuning Surrogate Gradient Learning for Optimal Hardware Performance  in Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aliyev%2C+I">Ilkin Aliyev</a>, 
<a href="/search/cs?searchtype=author&query=Adegbija%2C+T">Tosiron Adegbija</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">The highly sparse activations in Spiking Neural Networks (SNNs) can provide
tremendous energy efficiency benefits when carefully exploited in hardware. The
behavior of sparsity in SNNs is uniquely shaped by the dataset and training
hyperparameters. This work reveals novel insights into the impacts of training
on hardware performance. Specifically, we explore the trade-offs between model
accuracy and hardware efficiency. We focus on three key hyperparameters:
surrogate gradient functions, beta, and membrane threshold. Results on an
FPGA-based hardware platform show that the fast sigmoid surrogate function
yields a lower firing rate with similar accuracy compared to the arctangent
surrogate on the SVHN dataset. Furthermore, by cross-sweeping the beta and
membrane threshold hyperparameters, we can achieve a 48% reduction in
hardware-based inference latency with only 2.88% trade-off in inference
accuracy compared to the default setting. Overall, this study highlights the
importance of fine-tuning model hyperparameters as crucial for designing
efficient SNN hardware accelerators, evidenced by the fine-tuned model
achieving a 1.72x improvement in accelerator efficiency (FPS/W) compared to the
most recent work.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06212" title="Abstract">arXiv:2402.06212</a> [<a href="/pdf/2402.06212" title="Download PDF">pdf</a>, <a href="/ps/2402.06212" title="Download PostScript">ps</a>, <a href="/format/2402.06212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Halo Reduction in Display Systems through Smoothed Local Histogram  Equalization and Human Visual System Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ambalathankandy%2C+P">Prasoon Ambalathankandy</a>, 
<a href="/search/cs?searchtype=author&query=Ou%2C+Y">Yafei Ou</a>, 
<a href="/search/cs?searchtype=author&query=Ikebe%2C+M">Masayuki Ikebe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Halo artifacts significantly impact display quality. We propose a method to
reduce halos in Local Histogram Equalization (LHE) algorithms by separately
addressing dark and light variants. This approach results in visually natural
images by exploring the relationship between lateral inhibition and halo
artifacts in the human visual system.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06213" title="Abstract">arXiv:2402.06213</a> [<a href="/pdf/2402.06213" title="Download PDF">pdf</a>, <a href="/format/2402.06213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-source-free Domain Adaptation via Uncertainty-aware Adaptive  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yaxuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jianan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dongnan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Weidong Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ISBI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Source-free domain adaptation (SFDA) alleviates the domain discrepancy among
data obtained from domains without accessing the data for the awareness of data
privacy. However, existing conventional SFDA methods face inherent limitations
in medical contexts, where medical data are typically collected from multiple
institutions using various equipment. To address this problem, we propose a
simple yet effective method, named Uncertainty-aware Adaptive Distillation
(UAD) for the multi-source-free unsupervised domain adaptation (MSFDA) setting.
UAD aims to perform well-calibrated knowledge distillation from (i) model level
to deliver coordinated and reliable base model initialisation and (ii) instance
level via model adaptation guided by high-quality pseudo-labels, thereby
obtaining a high-performance target domain model. To verify its general
applicability, we evaluate UAD on two image-based diagnosis benchmarks among
two multi-centre datasets, where our method shows a significant performance
gain compared with existing works. The code will be available soon.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06216" title="Abstract">arXiv:2402.06216</a> [<a href="/pdf/2402.06216" title="Download PDF">pdf</a>, <a href="/format/2402.06216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fairly Evaluating Large Language Model-based Recommendation Needs  Revisit the Cross-Entropy Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Cong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhangchi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianyong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Large language models (LLMs) have gained much attention in the recommendation
community; some studies have observed that LLMs, fine-tuned by the
cross-entropy loss with a full softmax, could achieve state-of-the-art
performance already. However, these claims are drawn from unobjective and
unfair comparisons. In view of the substantial quantity of items in reality,
conventional recommenders typically adopt a pointwise/pairwise loss function
instead for training. This substitute however causes severe performance
degradation, leading to under-estimation of conventional methods and
over-confidence in the ranking capability of LLMs.
<br />In this work, we theoretically justify the superiority of cross-entropy, and
showcase that it can be adequately replaced by some elementary approximations
with certain necessary modifications. The remarkable results across three
public datasets corroborate that even in a practical sense, existing LLM-based
methods are not as effective as claimed for next-item recommendation. We hope
that these theoretical understandings in conjunction with the empirical results
will facilitate an objective evaluation of LLM-based recommendation in the
future.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06220" title="Abstract">arXiv:2402.06220</a> [<a href="/pdf/2402.06220" title="Download PDF">pdf</a>, <a href="/format/2402.06220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Causal View of Instruction Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiafeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Instruction tuning on a mixture of tasks has improved zero-shot capabilities
in natural language processing (NLP). Nevertheless, existing methods often
learn features that exhibit correlations between instruction-formatted samples
and target labels, rather than causal relationships. Termed as ``spurious
correlation'' in statistics, such a correlation may change drastically in a new
task, making the effect from the learned features to be misleading. To this
end, we develop a meta Structural Causal Model (meta-SCM) to integrate
different NLP tasks under a single causal structure of the data. Specifically,
the meta-SCM introduces multiple latent factors that represent properties of
source context, only some of which causally influence the target labels for a
specific task. The key idea is to learn task-required causal factors and only
use those to make predictions for a given task. Theoretically, we prove the
causal factor can be identified without mixing information from others. Guided
by the identifiability, we propose a Structural Instruction Tuning (SIT) method
to learn the task-required causal representations that can mimic the causal
factors for each task. The utility of our approach is verified by improvements
of zero-shot ability on a range of unseen datasets and tasks.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06221" title="Abstract">arXiv:2402.06221</a> [<a href="/pdf/2402.06221" title="Download PDF">pdf</a>, <a href="/format/2402.06221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ResumeFlow: An LLM-facilitated Pipeline for Personalized Resume  Generation and Refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zinjad%2C+S+B">Saurabh Bhausaheb Zinjad</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharjee%2C+A">Amrita Bhattacharjee</a>, 
<a href="/search/cs?searchtype=author&query=Bhilegaonkar%2C+A">Amey Bhilegaonkar</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huan Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Crafting the ideal, job-specific resume is a challenging task for many job
applicants, especially for early-career applicants. While it is highly
recommended that applicants tailor their resume to the specific role they are
applying for, manually tailoring resumes to job descriptions and role-specific
requirements is often (1) extremely time-consuming, and (2) prone to human
errors. Furthermore, performing such a tailoring step at scale while applying
to several roles may result in a lack of quality of the edited resumes. To
tackle this problem, in this demo paper, we propose ResumeFlow: a Large
Language Model (LLM) aided tool that enables an end user to simply provide
their detailed resume and the desired job posting, and obtain a personalized
resume specifically tailored to that specific job posting in the matter of a
few seconds. Our proposed pipeline leverages the language understanding and
information extraction capabilities of state-of-the-art LLMs such as OpenAI's
GPT-4 and Google's Gemini, in order to (1) extract details from a job
description, (2) extract role-specific details from the user-provided resume,
and then (3) use these to refine and generate a role-specific resume for the
user. Our easy-to-use tool leverages the user-chosen LLM in a completely
off-the-shelf manner, thus requiring no fine-tuning. We demonstrate the
effectiveness of our tool via a video demo and propose novel task-specific
evaluation metrics to control for alignment and hallucination. Our tool is
available at https://job-aligned-resume.streamlit.app.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06223" title="Abstract">arXiv:2402.06223</a> [<a href="/pdf/2402.06223" title="Download PDF">pdf</a>, <a href="/format/2402.06223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revealing Multimodal Contrastive Representation Learning through Latent  Partial Causal Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuhang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+D">Dong Gong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Biwei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+M">Mingming Gong</a>, 
<a href="/search/cs?searchtype=author&query=van+den+Hengel%2C+A">Anton van den Hengel</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J+Q">Javen Qinfeng Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
<p class="mathjax">Multimodal contrastive representation learning methods have proven successful
across a range of domains, partly due to their ability to generate meaningful
shared representations of complex phenomena. To enhance the depth of analysis
and understanding of these acquired representations, we introduce a unified
causal model specifically designed for multimodal data. By examining this
model, we show that multimodal contrastive representation learning excels at
identifying latent coupled variables within the proposed unified model, up to
linear or permutation transformations resulting from different assumptions. Our
findings illuminate the potential of pre-trained multimodal models, eg, CLIP,
in learning disentangled representations through a surprisingly simple yet
highly effective tool: linear independent component analysis. Experiments
demonstrate the robustness of our findings, even when the assumptions are
violated, and validate the effectiveness of the proposed method in learning
disentangled representations.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06226" title="Abstract">arXiv:2402.06226</a> [<a href="/pdf/2402.06226" title="Download PDF">pdf</a>, <a href="/ps/2402.06226" title="Download PostScript">ps</a>, <a href="/format/2402.06226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> N-1 Reduced Optimal Power Flow Using Augmented Hierarchical Graph Neural  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pham%2C+T">Thuan Pham</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xingpeng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Optimal power flow (OPF) is used to perform generation redispatch in power
system real-time operations. N-1 OPF can ensure safe grid operations under
diverse contingency scenarios. For large and intricate power networks with
numerous variables and constraints, achieving an optimal solution for real-time
N-1 OPF necessitates substantial computational resources. To mitigate this
challenge, machine learning (ML) is introduced as an additional tool for
predicting congested or heavily loaded lines dynamically. In this paper, an
advanced ML model known as the augmented hierarchical graph neural network
(AHGNN) was proposed to predict critical congested lines and create N-1 reduced
OPF (N-1 ROPF). The proposed AHGNN-enabled N-1 ROPF can result in a remarkable
reduction in computing time while retaining the solution quality. Several
variations of GNN-based ML models are also implemented as benchmark to
demonstrate effectiveness of the proposed AHGNN approach. Case studies prove
the proposed AHGNN and the associated N-1 ROPF are highly effective in reducing
computation time while preserving solution quality, highlighting the promising
potential of ML, particularly GNN in enhancing power system operations.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06229" title="Abstract">arXiv:2402.06229</a> [<a href="/pdf/2402.06229" title="Download PDF">pdf</a>, <a href="/format/2402.06229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Interaction Patterns for Debugging: Enhancing Conversational  Capabilities of AI-assistants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chopra%2C+B">Bhavya Chopra</a>, 
<a href="/search/cs?searchtype=author&query=Bajpai%2C+Y">Yasharth Bajpai</a>, 
<a href="/search/cs?searchtype=author&query=Biyani%2C+P">Param Biyani</a>, 
<a href="/search/cs?searchtype=author&query=Soares%2C+G">Gustavo Soares</a>, 
<a href="/search/cs?searchtype=author&query=Radhakrishna%2C+A">Arjun Radhakrishna</a>, 
<a href="/search/cs?searchtype=author&query=Parnin%2C+C">Chris Parnin</a>, 
<a href="/search/cs?searchtype=author&query=Gulwani%2C+S">Sumit Gulwani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
<p class="mathjax">The widespread availability of Large Language Models (LLMs) within Integrated
Development Environments (IDEs) has led to their speedy adoption.
Conversational interactions with LLMs enable programmers to obtain natural
language explanations for various software development tasks. However, LLMs
often leap to action without sufficient context, giving rise to implicit
assumptions and inaccurate responses. Conversations between developers and LLMs
are primarily structured as question-answer pairs, where the developer is
responsible for asking the the right questions and sustaining conversations
across multiple turns. In this paper, we draw inspiration from interaction
patterns and conversation analysis -- to design Robin, an enhanced
conversational AI-assistant for debugging. Through a within-subjects user study
with 12 industry professionals, we find that equipping the LLM to -- (1)
leverage the insert expansion interaction pattern, (2) facilitate turn-taking,
and (3) utilize debugging workflows -- leads to lowered conversation barriers,
effective fault localization, and 5x improvement in bug resolution rates.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06233" title="Abstract">arXiv:2402.06233</a> [<a href="/pdf/2402.06233" title="Download PDF">pdf</a>, <a href="/ps/2402.06233" title="Download PostScript">ps</a>, <a href="/format/2402.06233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative filtering, K-nearest neighbor and cosine similarity in  home decor recommender systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Munkholm%2C+N+B">Nanna Bach Munkholm</a>, 
<a href="/search/cs?searchtype=author&query=Alphinas%2C+R">Robert Alphinas</a>, 
<a href="/search/cs?searchtype=author&query=Tambo%2C+T">Torben Tambo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Co-thinking of recommender systems and entrepreneurship
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">An architectural framework, based on collaborative filtering using K-nearest
neighbor and cosine similarity, was developed and implemented to fit the
requirements for the company DecorRaid. The aim of the paper is to test
different evaluation techniques within the environment to research the
recommender systems performance. Three perspectives were found relevant for
evaluating a recommender system in the specific environment, namely dataset,
system and user perspective. With these perspectives it was possible to gain a
broader view of the recommender systems performance. Online A/B split testing
was conducted to compare the performance of small adjustments to the RS and to
test the relevance of the evaluation techniques. Key factors are solving the
sparsity and cold start problem, where the suggestion is to research a hybrid
RS combining Content-based and CF based techniques.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06244" title="Abstract">arXiv:2402.06244</a> [<a href="/pdf/2402.06244" title="Download PDF">pdf</a>, <a href="/format/2402.06244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying and Enhancing Multi-modal Robustness with Modality  Preference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zequn Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yake Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+C">Ce Liang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+D">Di Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Multi-modal models have shown a promising capability to effectively integrate
information from various sources, yet meanwhile, they are found vulnerable to
pervasive perturbations, such as uni-modal attacks and missing conditions. To
counter these perturbations, robust multi-modal representations are highly
expected, which are positioned well away from the discriminative multi-modal
decision boundary. In this paper, different from conventional empirical
studies, we focus on a commonly used joint multi-modal framework and
theoretically discover that larger uni-modal representation margins and more
reliable integration for modalities are essential components for achieving
higher robustness. This discovery can further explain the limitation of
multi-modal robustness and the phenomenon that multi-modal models are often
vulnerable to attacks on the specific modality. Moreover, our analysis reveals
how the widespread issue, that the model has different preferences for
modalities, limits the multi-modal robustness by influencing the essential
components and could lead to attacks on the specific modality highly effective.
Inspired by our theoretical finding, we introduce a training procedure called
Certifiable Robust Multi-modal Training (CRMT), which can alleviate this
influence from modality preference and explicitly regulate essential components
to significantly improve robustness in a certifiable manner. Our method
demonstrates substantial improvements in performance and robustness compared
with existing methods. Furthermore, our training procedure can be easily
extended to enhance other robust training strategies, highlighting its
credibility and flexibility.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06247" title="Abstract">arXiv:2402.06247</a> [<a href="/pdf/2402.06247" title="Download PDF">pdf</a>, <a href="/format/2402.06247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Delving into Parameter-Efficient Fine-Tuning in Code Change Learning: An  Empirical Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Keung%2C+J">Jacky Keung</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qilin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yihan Liao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures, accepted by SANER 2024 (International Conference on Software Analysis, Evolution, and Reengineering)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Compared to Full-Model Fine-Tuning (FMFT), Parameter Efficient Fine-Tuning
(PEFT) has demonstrated superior performance and lower computational overhead
in several code understanding tasks, such as code summarization and code
search. This advantage can be attributed to PEFT's ability to alleviate the
catastrophic forgetting issue of Pre-trained Language Models (PLMs) by updating
only a small number of parameters. As a result, PEFT effectively harnesses the
pre-trained general-purpose knowledge for downstream tasks. However, existing
studies primarily involve static code comprehension, aligning with the
pre-training paradigm of recent PLMs and facilitating knowledge transfer, but
they do not account for dynamic code changes. Thus, it remains unclear whether
PEFT outperforms FMFT in task-specific adaptation for code-change-related
tasks. To address this question, we examine two prevalent PEFT methods, namely
Adapter Tuning (AT) and Low-Rank Adaptation (LoRA), and compare their
performance with FMFT on five popular PLMs. Specifically, we evaluate their
performance on two widely-studied code-change-related tasks: Just-In-Time
Defect Prediction (JIT-DP) and Commit Message Generation (CMG). The results
demonstrate that both AT and LoRA achieve state-of-the-art (SOTA) results in
JIT-DP and exhibit comparable performances in CMG when compared to FMFT and
other SOTA approaches. Furthermore, AT and LoRA exhibit superiority in
cross-lingual and low-resource scenarios. We also conduct three probing tasks
to explain the efficacy of PEFT techniques on JIT-DP and CMG tasks from both
static and dynamic perspectives. The study indicates that PEFT, particularly
through the use of AT and LoRA, offers promising advantages in
code-change-related tasks, surpassing FMFT in certain aspects.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06249" title="Abstract">arXiv:2402.06249</a> [<a href="/pdf/2402.06249" title="Download PDF">pdf</a>, <a href="/format/2402.06249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anomaly Unveiled: Securing Image Classification against Adversarial  Patch Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chattopadhyay%2C+N">Nandish Chattopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Guesmi%2C+A">Amira Guesmi</a>, 
<a href="/search/cs?searchtype=author&query=Shafique%2C+M">Muhammad Shafique</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Adversarial patch attacks pose a significant threat to the practical
deployment of deep learning systems. However, existing research primarily
focuses on image pre-processing defenses, which often result in reduced
classification accuracy for clean images and fail to effectively counter
physically feasible attacks. In this paper, we investigate the behavior of
adversarial patches as anomalies within the distribution of image information
and leverage this insight to develop a robust defense strategy. Our proposed
defense mechanism utilizes a clustering-based technique called DBSCAN to
isolate anomalous image segments, which is carried out by a three-stage
pipeline consisting of Segmenting, Isolating, and Blocking phases to identify
and mitigate adversarial noise. Upon identifying adversarial components, we
neutralize them by replacing them with the mean pixel value, surpassing
alternative replacement options. Our model-agnostic defense mechanism is
evaluated across multiple models and datasets, demonstrating its effectiveness
in countering various adversarial patch attacks in image classification tasks.
Our proposed approach significantly improves accuracy, increasing from 38.8\%
without the defense to 67.1\% with the defense against LaVAN and GoogleAp
attacks, surpassing prominent state-of-the-art methods such as LGS (53.86\%)
and Jujutsu (60\%)
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06251" title="Abstract">arXiv:2402.06251</a> [<a href="/pdf/2402.06251" title="Download PDF">pdf</a>, <a href="/ps/2402.06251" title="Download PostScript">ps</a>, <a href="/format/2402.06251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Insomnia Identification via Electroencephalography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Udeshika%2C+O">Olviya Udeshika</a>, 
<a href="/search/cs?searchtype=author&query=Lakshitha%2C+D">Dilshan Lakshitha</a>, 
<a href="/search/cs?searchtype=author&query=Premakumara%2C+N">Nilantha Premakumara</a>, 
<a href="/search/cs?searchtype=author&query=Bandara%2C+S">Surangani Bandara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 9 figures and 12 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Insomnia is a serious sleep disorder caused by abnormal or excessive neural
activity in the brain. An estimated 50 million people worldwide are thought to
be affected by this condition, which is the second most severe neurological
disease after stroke. In order to ensure a quick recovery, an early and
accurate diagnosis of insomnia enables more effective drug and treatment
administration. This study proposes a method that uses deep learning to
automatically identify patients with insomnia. A set of optimal features are
extracted from spectral and temporal domains, including the relative power of
{\sigma}, \b{eta} and {\gamma} bands, the total power, the absolute slow wave
power, the power ratios of {\theta}, {\alpha}, {\gamma}, \b{eta},
{\theta}/{\alpha}, {\theta}/\b{eta}, {\alpha}/{\gamma} and {\alpha}/\b{eta},
mean, zero crossing rate, mobility, complexity, sleep efficiency and total
sleep time, to accurately quantify the differences between insomnia patients
and healthy subjects and develops a 1D CNN model for the classification
process. With the experiments use Fp2 and C4 EEG channels with 50 insomnia
patients and 50 healthy subjects, the proposed model arrives 99.34% accuracy
without sleep stage annotation. Using the features only from a single channel,
the study proposes a smart solution for insomnia patients which allows machine
learning to be to simplify current sleep monitoring hardware and improve
in-home ambulatory monitoring.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06255" title="Abstract">arXiv:2402.06255</a> [<a href="/pdf/2402.06255" title="Download PDF">pdf</a>, <a href="/format/2402.06255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Studious Bob Fight Back Against Jailbreaking via Prompt Adversarial  Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mo%2C+Y">Yichuan Mo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuji Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zeming Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yisen Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Although Large Language Models (LLMs) have achieved tremendous success in
various applications, they are also susceptible to certain prompts that can
induce them to bypass built-in safety measures and provide dangerous or illegal
content, a phenomenon known as jailbreak. To protect LLMs from producing
harmful information, various defense strategies are proposed, with most
focusing on content filtering or adversarial training of models. In this paper,
we propose an approach named Prompt Adversarial Tuning (PAT) to train a defense
control mechanism, which is then embedded as a prefix to user prompts to
implement our defense strategy. We design a training process similar to
adversarial training to achieve our optimized goal, alternating between
updating attack and defense controls. To our knowledge, we are the first to
implement defense from the perspective of prompt tuning. Once employed, our
method will hardly impact the operational efficiency of LLMs. Experiments show
that our method is effective in both black-box and white-box settings, reducing
the success rate of advanced attacks to nearly 0 while maintaining the benign
answer rate of 80% to simple benign questions. Our work might potentially chart
a new perspective for future explorations in LLM security.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06261" title="Abstract">arXiv:2402.06261</a> [<a href="/pdf/2402.06261" title="Download PDF">pdf</a>, <a href="/format/2402.06261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-based PINNs for solving coupled field problems: concepts and  application to the optimal design of an induction heater
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baldan%2C+M">Marco Baldan</a>, 
<a href="/search/cs?searchtype=author&query=Di+Barba%2C+P">Paolo Di Barba</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Physics-informed neural networks (PINNs) are neural networks (NNs) that
directly encode model equations, like Partial Differential Equations (PDEs), in
the network itself. While most of the PINN algorithms in the literature
minimize the local residual of the governing equations, there are energy-based
approaches that take a different path by minimizing the variational energy of
the model. We show that in the case of the steady thermal equation weakly
coupled to magnetic equation, the energy-based approach displays multiple
advantages compared to the standard residual-based PINN: it is more
computationally efficient, it requires a lower order of derivatives to compute,
and it involves less hyperparameters. The analyzed benchmark problem is the
optimal design of an inductor for the controlled heating of a graphite plate.
The optimized device is designed involving a multi-physics problem: a
time-harmonic magnetic problem and a steady thermal problem. For the former, a
deep neural network solving the direct problem is supervisedly trained on
Finite Element Analysis (FEA) data. In turn, the solution of the latter relies
on a hypernetwork that takes as input the inductor geometry parameters and
outputs the model weights of an energy-based PINN (or ePINN). Eventually, the
ePINN predicts the temperature field within the graphite plate.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06262" title="Abstract">arXiv:2402.06262</a> [<a href="/pdf/2402.06262" title="Download PDF">pdf</a>, <a href="/format/2402.06262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Efficacy of Eviction Policy for Key-Value Constrained Generative  Language Model Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Siyu Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K+Q">Kenny Q. Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite the recent success associated with Large Language Models~(LLMs), they
are notably cost-prohibitive to deploy in resource-constrained environments due
to their excessive memory and computational demands. In addition to model
parameters, the key-value cache is also stored in GPU memory, growing linearly
with batch size and sequence length. As a remedy, recent works have proposed
various eviction policies for maintaining the overhead of key-value cache under
a given budget. This paper embarks on the efficacy of existing eviction
policies in terms of \textit{importance score calculation} and \textit{eviction
scope construction}. We identify the deficiency of prior policies in these two
aspects and introduce RoCo, a \underline{r}\underline{o}bust \underline{c}ache
\underline{o}mission policy based on temporal attention scores and robustness
measures. Extensive experimentation spanning prefilling and auto-regressive
decoding stages validates the superiority of RoCo. Finally, we release EasyKV,
a versatile software package dedicated to user-friendly key-value constrained
generative inference. Code available at \url{https://github.com/DRSY/EasyKV}.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06263" title="Abstract">arXiv:2402.06263</a> [<a href="/pdf/2402.06263" title="Download PDF">pdf</a>, <a href="/format/2402.06263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASAP-MPC: An Asynchronous Update Scheme for Online Motion Planning with  Nonlinear Model Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dirckx%2C+D">Dries Dirckx</a>, 
<a href="/search/cs?searchtype=author&query=Bos%2C+M">Mathias Bos</a>, 
<a href="/search/cs?searchtype=author&query=Vandewal%2C+B">Bastiaan Vandewal</a>, 
<a href="/search/cs?searchtype=author&query=Vanroye%2C+L">Lander Vanroye</a>, 
<a href="/search/cs?searchtype=author&query=Decr%C3%A9%2C+W">Wilm Decr&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Swevers%2C+J">Jan Swevers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper presents a Nonlinear Model Predictive Control (NMPC) scheme
targeted at motion planning for mechatronic motion systems, such as drones and
mobile platforms. NMPC-based motion planning typically requires low computation
times to be able to provide control inputs at the required rate for system
stability, disturbance rejection, and overall performance. Although there exist
various ways in literature to reduce the solution times in NMPC, such times may
not be low enough to allow real-time implementations. This paper presents
ASAP-MPC, an approach to handle varying, sometimes restrictively large,
solution times with an asynchronous update scheme, always allowing for full
convergence and real-time execution. The NMPC algorithm is combined with a
linear state feedback controller tracking the optimised trajectories for
improved robustness against possible disturbances and plant-model mismatch.
ASAP-MPC seamlessly merges trajectories, resulting from subsequent NMPC
solutions, providing a smooth and continuous overall trajectory for the motion
system. This frameworks applicability to embedded applications is shown on two
different experiment setups where a state-of-the-art method fails: a quadcopter
flying through a cluttered environment in hardware-in-the-loop simulation and a
scale model truck-trailer manoeuvring in a structured lab environment.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06264" title="Abstract">arXiv:2402.06264</a> [<a href="/pdf/2402.06264" title="Download PDF">pdf</a>, <a href="/ps/2402.06264" title="Download PostScript">ps</a>, <a href="/format/2402.06264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLaVA-Docent: Instruction Tuning with Multimodal Large Language Model to  Support Art Appreciation Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+U">Unggi Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+M">Minji Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yunseo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Byun%2C+G">Gyuri Byun</a>, 
<a href="/search/cs?searchtype=author&query=Son%2C+Y">Yoorim Son</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+J">Jaeyoon Shin</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+H">Hongkyu Ko</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyeoncheol Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 4 figures, 10 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Art appreciation is vital in nurturing critical thinking and emotional
intelligence among learners. However, traditional art appreciation education
has often been hindered by limited access to art resources, especially for
disadvantaged students, and an imbalanced emphasis on STEM subjects in
mainstream education. In response to these challenges, recent technological
advancements have paved the way for innovative solutions. This study explores
the application of multi-modal large language models (MLLMs) in art
appreciation education, focusing on developing LLaVA-Docent, a model that
leverages these advancements. Our approach involved a comprehensive literature
review and consultations with experts in the field, leading to developing a
robust data framework. Utilizing this framework, we generated a virtual
dialogue dataset that was leveraged by GPT-4. This dataset was instrumental in
training the MLLM, named LLaVA-Docent. Six researchers conducted quantitative
and qualitative evaluations of LLaVA-Docent to assess its effectiveness,
benchmarking it against the GPT-4 model in a few-shot setting. The evaluation
process revealed distinct strengths and weaknesses of the LLaVA-Docent model.
Our findings highlight the efficacy of LLaVA-Docent in enhancing the
accessibility and engagement of art appreciation education. By harnessing the
potential of MLLMs, this study makes a significant contribution to the field of
art education, proposing a novel methodology that reimagines the way art
appreciation is taught and experienced.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06266" title="Abstract">arXiv:2402.06266</a> [<a href="/pdf/2402.06266" title="Download PDF">pdf</a>, <a href="/format/2402.06266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Value function interference and greedy action selection in value-based  multi-objective reinforcement learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vamplew%2C+P">Peter Vamplew</a>, 
<a href="/search/cs?searchtype=author&query=Foale%2C+C">Cameron Foale</a>, 
<a href="/search/cs?searchtype=author&query=Dazeley%2C+R">Richard Dazeley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Multi-objective reinforcement learning (MORL) algorithms extend conventional
reinforcement learning (RL) to the more general case of problems with multiple,
conflicting objectives, represented by vector-valued rewards. Widely-used
scalar RL methods such as Q-learning can be modified to handle multiple
objectives by (1) learning vector-valued value functions, and (2) performing
action selection using a scalarisation or ordering operator which reflects the
user's utility with respect to the different objectives. However, as we
demonstrate here, if the user's utility function maps widely varying
vector-values to similar levels of utility, this can lead to interference in
the value-function learned by the agent, leading to convergence to sub-optimal
policies. This will be most prevalent in stochastic environments when
optimising for the Expected Scalarised Return criterion, but we present a
simple example showing that interference can also arise in deterministic
environments. We demonstrate empirically that avoiding the use of random
tie-breaking when identifying greedy actions can ameliorate, but not fully
overcome, the problems caused by value function interference.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06268" title="Abstract">arXiv:2402.06268</a> [<a href="/pdf/2402.06268" title="Download PDF">pdf</a>, <a href="/format/2402.06268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YAMLE: Yet Another Machine Learning Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferianc%2C+M">Martin Ferianc</a>, 
<a href="/search/cs?searchtype=author&query=Rodrigues%2C+M">Miguel Rodrigues</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Find it at: <a href="https://github.com/martinferianc/yamle">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">YAMLE: Yet Another Machine Learning Environment is an open-source framework
that facilitates rapid prototyping and experimentation with machine learning
(ML) models and methods. The key motivation is to reduce repetitive work when
implementing new approaches and improve reproducibility in ML research. YAMLE
includes a command-line interface and integrations with popular and
well-maintained PyTorch-based libraries to streamline training, hyperparameter
optimisation, and logging. The ambition for YAMLE is to grow into a shared
ecosystem where researchers and practitioners can quickly build on and compare
existing implementations. Find it at: https://github.com/martinferianc/yamle.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06276" title="Abstract">arXiv:2402.06276</a> [<a href="/pdf/2402.06276" title="Download PDF">pdf</a>, <a href="/format/2402.06276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Active Learning for Time-Series Modeling with Gaussian Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zimmer%2C+C">Christoph Zimmer</a>, 
<a href="/search/cs?searchtype=author&query=Meister%2C+M">Mona Meister</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen-Tuong%2C+D">Duy Nguyen-Tuong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Clarification / Errata of article originally published at NeurIPS: <a href="https://proceedings.neurips.cc/paper/2018/hash/b197ffdef2ddc3308584dce7afa3661b-Abstract.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Learning time-series models is useful for many applications, such as
simulation and forecasting. In this study, we consider the problem of actively
learning time-series models while taking given safety constraints into account.
For time-series modeling we employ a Gaussian process with a nonlinear
exogenous input structure. The proposed approach generates data appropriate for
time series model learning, i.e. input and output trajectories, by dynamically
exploring the input space. The approach parametrizes the input trajectory as
consecutive trajectory sections, which are determined stepwise given safety
requirements and past observations. We analyze the proposed algorithm and
evaluate it empirically on a technical application. The results show the
effectiveness of our approach in a realistic technical use case.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06281" title="Abstract">arXiv:2402.06281</a> [<a href="/pdf/2402.06281" title="Download PDF">pdf</a>, <a href="/ps/2402.06281" title="Download PostScript">ps</a>, <a href="/format/2402.06281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Optimization Framework for Resource Allocation in Virtual Sensor  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delgado%2C+C">Carmen Delgado</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%A1llego%2C+J+R">Jos&#xe9; Ram&#xf3;n G&#xe1;llego</a>, 
<a href="/search/cs?searchtype=author&query=Canales%2C+M">Mar&#xed;a Canales</a>, 
<a href="/search/cs?searchtype=author&query=Ort%C3%ADn%2C+J">Jorge Ort&#xed;n</a>, 
<a href="/search/cs?searchtype=author&query=Bousnina%2C+S">Sonda Bousnina</a>, 
<a href="/search/cs?searchtype=author&query=Cesana%2C+M">Matteo Cesana</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2015 IEEE Global Communications Conference (GLOBECOM)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">We propose an optimization framework to perform resource allocation in
virtual sensor networks. Sensor network virtualization is a promising paradigm
to improve flexibility of wireless sensor networks which allows to dynamically
assign physical resources to multiple stakeholder applications. The proposed
optimization framework aims at maximizing the total number of applications
which can share a common physical network, while accounting for the
distinguishing characteristics and limitations of the wireless sensor
environment (limited storage, limited processing power, limited bandwidth,
tight energy consumption requirements). The proposed framework is finally
applied to realistic network topologies to assess the gain involved in letting
multiple applications share a common physical network with respect to
one-application, one-network vertical design approaches.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06282" title="Abstract">arXiv:2402.06282</a> [<a href="/pdf/2402.06282" title="Download PDF">pdf</a>, <a href="/format/2402.06282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieve, Merge, Predict: Augmenting Tables with Data Lakes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cappuzzo%2C+R">Riccardo Cappuzzo</a> (1), 
<a href="/search/cs?searchtype=author&query=Varoquaux%2C+G">Gael Varoquaux</a> (1), 
<a href="/search/cs?searchtype=author&query=Coelho%2C+A">Aimee Coelho</a> (2), 
<a href="/search/cs?searchtype=author&query=Papotti%2C+P">Paolo Papotti</a> (3) ((1) SODA Team - Inria Saclay, (2) Dataiku, (3) EURECOM)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages + references, 11 figures. Under submission at VLDB2024 (EA&amp;B track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present an in-depth analysis of data discovery in data lakes, focusing on
table augmentation for given machine learning tasks. We analyze alternative
methods used in the three main steps: retrieving joinable tables, merging
information, and predicting with the resultant table. As data lakes, the paper
uses YADL (Yet Another Data Lake) -- a novel dataset we developed as a tool for
benchmarking this data discovery task -- and Open Data US, a well-referenced
real data lake. Through systematic exploration on both lakes, our study
outlines the importance of accurately retrieving join candidates and the
efficiency of simple merging methods. We report new insights on the benefits of
existing solutions and on their limitations, aiming at guiding future research
in this space.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06284" title="Abstract">arXiv:2402.06284</a> [<a href="/pdf/2402.06284" title="Download PDF">pdf</a>, <a href="/format/2402.06284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Chip-in-the-loop Spiking Neural Network Training via  Metropolis-Hastings Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Safa%2C+A">Ali Safa</a>, 
<a href="/search/cs?searchtype=author&query=Jaltare%2C+V">Vikrant Jaltare</a>, 
<a href="/search/cs?searchtype=author&query=Sebt%2C+S">Samira Sebt</a>, 
<a href="/search/cs?searchtype=author&query=Gano%2C+K">Kameron Gano</a>, 
<a href="/search/cs?searchtype=author&query=Leugering%2C+J">Johannes Leugering</a>, 
<a href="/search/cs?searchtype=author&query=Gielen%2C+G">Georges Gielen</a>, 
<a href="/search/cs?searchtype=author&query=Cauwenberghs%2C+G">Gert Cauwenberghs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper studies the use of Metropolis-Hastings sampling for training
Spiking Neural Network (SNN) hardware subject to strong unknown non-idealities,
and compares the proposed approach to the common use of the backpropagation of
error (backprop) algorithm and surrogate gradients, widely used to train SNNs
in literature. Simulations are conducted within a chip-in-the-loop training
context, where an SNN subject to unknown distortion must be trained to detect
cancer from measurements, within a biomedical application context. Our results
show that the proposed approach strongly outperforms the use of backprop by up
to $27\%$ higher accuracy when subject to strong hardware non-idealities.
Furthermore, our results also show that the proposed approach outperforms
backprop in terms of SNN generalization, needing $&gt;10 \times$ less training
data for achieving effective accuracy. These findings make the proposed
training approach well-suited for SNN implementations in analog subthreshold
circuits and other emerging technologies where unknown hardware non-idealities
can jeopardize backprop.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06287" title="Abstract">arXiv:2402.06287</a> [<a href="/pdf/2402.06287" title="Download PDF">pdf</a>, <a href="/format/2402.06287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI, Meet Human: Learning Paradigms for Hybrid Decision Making Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Punzi%2C+C">Clara Punzi</a>, 
<a href="/search/cs?searchtype=author&query=Pellungrini%2C+R">Roberto Pellungrini</a>, 
<a href="/search/cs?searchtype=author&query=Setzu%2C+M">Mattia Setzu</a>, 
<a href="/search/cs?searchtype=author&query=Giannotti%2C+F">Fosca Giannotti</a>, 
<a href="/search/cs?searchtype=author&query=Pedreschi%2C+D">Dino Pedreschi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Everyday we increasingly rely on machine learning models to automate and
support high-stake tasks and decisions. This growing presence means that humans
are now constantly interacting with machine learning-based systems, training
and using models everyday. Several different techniques in computer science
literature account for the human interaction with machine learning systems, but
their classification is sparse and the goals varied. This survey proposes a
taxonomy of Hybrid Decision Making Systems, providing both a conceptual and
technical framework for understanding how current computer science literature
models interaction between humans and machines.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06288" title="Abstract">arXiv:2402.06288</a> [<a href="/pdf/2402.06288" title="Download PDF">pdf</a>, <a href="/format/2402.06288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MLS2LoD3: Refining low LoDs building models with MLS point clouds to  reconstruct semantic LoD3 building models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wysocki%2C+O">Olaf Wysocki</a>, 
<a href="/search/cs?searchtype=author&query=Hoegner%2C+L">Ludwig Hoegner</a>, 
<a href="/search/cs?searchtype=author&query=Stilla%2C+U">Uwe Stilla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the Recent Advances in 3D Geoinformation Science, Proceedings of the 18th 3D GeoInfo Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Although highly-detailed LoD3 building models reveal great potential in
various applications, they have yet to be available. The primary challenges in
creating such models concern not only automatic detection and reconstruction
but also standard-consistent modeling. In this paper, we introduce a novel
refinement strategy enabling LoD3 reconstruction by leveraging the ubiquity of
lower LoD building models and the accuracy of MLS point clouds. Such a strategy
promises at-scale LoD3 reconstruction and unlocks LoD3 applications, which we
also describe and illustrate in this paper. Additionally, we present guidelines
for reconstructing LoD3 facade elements and their embedding into the CityGML
standard model, disseminating gained knowledge to academics and professionals.
We believe that our method can foster development of LoD3 reconstruction
algorithms and subsequently enable their wider adoption.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06289" title="Abstract">arXiv:2402.06289</a> [<a href="/pdf/2402.06289" title="Download PDF">pdf</a>, <a href="/format/2402.06289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Membership Inference Attacks and Defenses in Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+G">Gongxi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Donghao Li</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hanlin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yuxing Han</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lixin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qiang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Membership Inference Attacks (MIAs) pose a growing threat to privacy
preservation in federated learning. The semi-honest attacker, e.g., the server,
may determine whether a particular sample belongs to a target client according
to the observed model information. This paper conducts an evaluation of
existing MIAs and corresponding defense strategies. Our evaluation on MIAs
reveals two important findings about the trend of MIAs. Firstly, combining
model information from multiple communication rounds (Multi-temporal) enhances
the overall effectiveness of MIAs compared to utilizing model information from
a single epoch. Secondly, incorporating models from non-target clients
(Multi-spatial) significantly improves the effectiveness of MIAs, particularly
when the clients' data is homogeneous. This highlights the importance of
considering the temporal and spatial model information in MIAs. Next, we assess
the effectiveness via privacy-utility tradeoff for two type defense mechanisms
against MIAs: Gradient Perturbation and Data Replacement. Our results
demonstrate that Data Replacement mechanisms achieve a more optimal balance
between preserving privacy and maintaining model utility. Therefore, we
recommend the adoption of Data Replacement methods as a defense strategy
against MIAs. Our code is available in https://github.com/Liar-Mask/FedMIA.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06290" title="Abstract">arXiv:2402.06290</a> [<a href="/pdf/2402.06290" title="Download PDF">pdf</a>, <a href="/format/2402.06290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Feasibility of Battery-Less LoRaWAN Communications using Energy  Harvesting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delgado%2C+C">Carmen Delgado</a>, 
<a href="/search/cs?searchtype=author&query=Sanz%2C+J+%C3%A9+M">Jos &#xe9; Mar&#xed;a Sanz</a>, 
<a href="/search/cs?searchtype=author&query=Famaey%2C+J">Jeroen Famaey</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2019 IEEE Global Communications Conference (GLOBECOM)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">From the outset, batteries have been the main power source for the Internet
of Things (IoT). However, replacing and disposing of billions of dead batteries
per year is costly in terms of maintenance and ecologically irresponsible.
Since batteries are one of the greatest threats to a sustainable IoT,
battery-less devices are the solution to this problem. These devices run on
long-lived capacitors charged using various forms of energy harvesting, which
results in intermittent on-off device behaviour. In this work, we model this
intermittent battery-less behaviour for LoRaWAN devices. This model allows us
to characterize the performance with the aim to determine under which
conditions a LoRaWAN device can work without batteries, and how its parameters
should be configured. Results show that the reliability directly depends on
device configurations (i.e., capacitor size, turn-on voltage threshold),
application behaviour (i.e., transmission interval, packet size) and
environmental conditions (i.e., energy harvesting rate).
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06291" title="Abstract">arXiv:2402.06291</a> [<a href="/pdf/2402.06291" title="Download PDF">pdf</a>, <a href="/format/2402.06291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably Safe Finite-Time Guidance for Marine Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Singh%2C+B">Bhawana Singh</a>, 
<a href="/search/eess?searchtype=author&query=Dastgerdi%2C+K+A">Karim Ahmadi Dastgerdi</a>, 
<a href="/search/eess?searchtype=author&query=Athanasopoulos%2C+N">Nikolaos Athanasopoulos</a>, 
<a href="/search/eess?searchtype=author&query=Naeem%2C+W">Wasif Naeem</a>, 
<a href="/search/eess?searchtype=author&query=Lecallard%2C+B">Benoit Lecallard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">We consider a new control strategy for marine navigation, equipped with
finite-time convergence characteristics. We provide mathematical guarantees for
waypoint reaching and obstacle avoidance for different encounter scenarios, by
deriving conditions under which (i) convergence to waypoint and (ii) safe
obstacle avoidance is achieved while (iii) satisfying input constraints. We
propose a predefined-time heading control to enforce ship heading error
convergence and waypoint reaching in finite time. Using this as a building
block, we develop a provably safe algorithm for safe waypoint navigation by
strategically and automatically introducing intermediate virtual waypoints.
Using Imazu problems as benchmarks, we show that the proposed method is better
than other existing strategies such as Velocity Obstacle Avoidance and biased
Line-of-Sight methods, in terms of the safe distance between the ship and the
obstacles, cross track error, control effort, waypoint reaching time and ship
path length.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06293" title="Abstract">arXiv:2402.06293</a> [<a href="/pdf/2402.06293" title="Download PDF">pdf</a>, <a href="/format/2402.06293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Forecasting of Irregular Time Series via Conditional Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yalavarthi%2C+V+K">Vijaya Krishna Yalavarthi</a>, 
<a href="/search/cs?searchtype=author&query=Scholz%2C+R">Randolf Scholz</a>, 
<a href="/search/cs?searchtype=author&query=Born%2C+S">Stefan Born</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt-Thieme%2C+L">Lars Schmidt-Thieme</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Probabilistic forecasting of irregularly sampled multivariate time series
with missing values is an important problem in many fields, including health
care, astronomy, and climate. State-of-the-art methods for the task estimate
only marginal distributions of observations in single channels and at single
timepoints, assuming a fixed-shape parametric distribution. In this work, we
propose a novel model, ProFITi, for probabilistic forecasting of irregularly
sampled time series with missing values using conditional normalizing flows.
The model learns joint distributions over the future values of the time series
conditioned on past observations and queried channels and times, without
assuming any fixed shape of the underlying distribution. As model components,
we introduce a novel invertible triangular attention layer and an invertible
non-linear activation function on and onto the whole real line. We conduct
extensive experiments on four datasets and demonstrate that the proposed model
provides $4$ times higher likelihood over the previously best model.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06294" title="Abstract">arXiv:2402.06294</a> [<a href="/pdf/2402.06294" title="Download PDF">pdf</a>, <a href="/format/2402.06294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complexity of Boolean automata networks under block-parallel update  modes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perrot%2C+K">K&#xe9;vin Perrot</a>, 
<a href="/search/cs?searchtype=author&query=Sen%C3%A9%2C+S">Sylvain Sen&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Tapin%2C+L">L&#xe9;ah Tapin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">Boolean automata networks (aka Boolean networks) are space-time discrete
dynamical systems, studied as a model of computation and as a representative
model of natural phenomena. A collection of simple entities (the automata)
update their 0-1 states according to local rules. The dynamics of the network
is highly sensitive to update modes, i.e., to the schedule according to which
the automata apply their local rule. A new family of update modes appeared
recently, called block-parallel, which is dual to the well studied
block-sequential. Although basic, it embeds the rich feature of update
repetitions among a temporal updating period, allowing for atypical asymptotic
behaviors. In this paper, we prove that it is able to breed complex
computations, squashing almost all decision problems on the dynamics to the
traditionally highest (for reachability questions) class PSPACE. Despite
obtaining these complexity bounds for a broad set of local and global
properties, we also highlight a surprising gap: bijectivity is still coNP.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06295" title="Abstract">arXiv:2402.06295</a> [<a href="/pdf/2402.06295" title="Download PDF">pdf</a>, <a href="/format/2402.06295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Interpretable Data-Driven Models for Early Prediction of  Antimicrobial Multidrug Resistance Using Multivariate Time-Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez-Ag%C3%BCero%2C+S">Sergio Mart&#xed;nez-Ag&#xfc;ero</a>, 
<a href="/search/cs?searchtype=author&query=Marques%2C+A+G">Antonio G. Marques</a>, 
<a href="/search/cs?searchtype=author&query=Mora-Jim%C3%A9nez%2C+I">Inmaculada Mora-Jim&#xe9;nez</a>, 
<a href="/search/cs?searchtype=author&query=Alv%C3%A1rez-Rodr%C3%ADguez%2C+J">Joaqu&#xed;n Alv&#xe1;rez-Rodr&#xed;guez</a>, 
<a href="/search/cs?searchtype=author&query=Soguero-Ruiza%2C+C">Cristina Soguero-Ruiza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Electronic health records (EHR) is an inherently multimodal register of the
patient's health status characterized by static data and multivariate time
series (MTS). While MTS are a valuable tool for clinical prediction, their
fusion with other data modalities can possibly result in more thorough insights
and more accurate results. Deep neural networks (DNNs) have emerged as
fundamental tools for identifying and defining underlying patterns in the
healthcare domain. However, fundamental improvements in interpretability are
needed for DNN models to be widely used in the clinical setting. In this study,
we present an approach built on a collection of interpretable multimodal
data-driven models that may anticipate and understand the emergence of
antimicrobial multidrug resistance (AMR) germs in the intensive care unit (ICU)
of the University Hospital of Fuenlabrada (Madrid, Spain). The profile and
initial health status of the patient are modeled using static variables, while
the evolution of the patient's health status during the ICU stay is modeled
using several MTS, including mechanical ventilation and antibiotics intake. The
multimodal DNNs models proposed in this paper include interpretable principles
in addition to being effective at predicting AMR and providing an explainable
prediction support system for AMR in the ICU. Furthermore, our proposed
methodology based on multimodal models and interpretability schemes can be
leveraged in additional clinical problems dealing with EHR data, broadening the
impact and applicability of our results.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06297" title="Abstract">arXiv:2402.06297</a> [<a href="/pdf/2402.06297" title="Download PDF">pdf</a>, <a href="/format/2402.06297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Q-planning for Online UAV Path Planning in Unknown and Complex  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=da+Rocha%2C+L+G+S">Lidia Gianne Souza da Rocha</a>, 
<a href="/search/cs?searchtype=author&query=Caldas%2C+K+A+Q">Kenny Anderson Queiroz Caldas</a>, 
<a href="/search/cs?searchtype=author&query=Terra%2C+M+H">Marco Henrique Terra</a>, 
<a href="/search/cs?searchtype=author&query=Ramos%2C+F">Fabio Ramos</a>, 
<a href="/search/cs?searchtype=author&query=Vivaldini%2C+K+C+T">Kelen Cristiane Teixeira Vivaldini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Unmanned Aerial Vehicles need an online path planning capability to move in
high-risk missions in unknown and complex environments to complete them safely.
However, many algorithms reported in the literature may not return reliable
trajectories to solve online problems in these scenarios. The Q-Learning
algorithm, a Reinforcement Learning Technique, can generate trajectories in
real-time and has demonstrated fast and reliable results. This technique,
however, has the disadvantage of defining the iteration number. If this value
is not well defined, it will take a long time or not return an optimal
trajectory. Therefore, we propose a method to dynamically choose the number of
iterations to obtain the best performance of Q-Learning. The proposed method is
compared to the Q-Learning algorithm with a fixed number of iterations, A*,
Rapid-Exploring Random Tree, and Particle Swarm Optimization. As a result, the
proposed Q-learning algorithm demonstrates the efficacy and reliability of
online path planning with a dynamic number of iterations to carry out online
missions in unknown and complex environments.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06298" title="Abstract">arXiv:2402.06298</a> [<a href="/pdf/2402.06298" title="Download PDF">pdf</a>, <a href="/format/2402.06298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mergeable weighted majority games and characterizations of some power  indices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Armijos-Toro%2C+L+M">Livino M. Armijos-Toro</a>, 
<a href="/search/cs?searchtype=author&query=Alonso-Meijide%2C+J+M">Jos&#xe9; M. Alonso-Meijide</a>, 
<a href="/search/cs?searchtype=author&query=Mosquera%2C+M+A">Manuel A. Mosquera</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article was published on April 15, 2023 in Open Access in the journal Annals of Operations Research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper, we introduce a notion of mergeable weighted majority games
with the aim of providing the first characterization of the Colomer-Mart\'inez
power index (Colomer and Mart\'inez in J Theor Polit 7(1):41-63, 1995).
Furthermore, we define and characterize a new power index for the family of
weighted majority games that combines ideas of the Public Good (Holler in Polit
Stud 30(2):262-271, 1982) and Colomer-Mart\'inez power indices. Finally, we
analyze the National Assembly of Ecuador using these and some other well-known
power indices.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06299" title="Abstract">arXiv:2402.06299</a> [<a href="/pdf/2402.06299" title="Download PDF">pdf</a>, <a href="/format/2402.06299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Functional Analysis Approach to Symbolic Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Antonov%2C+K">Kirill Antonov</a>, 
<a href="/search/cs?searchtype=author&query=Kalkreuth%2C+R">Roman Kalkreuth</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kaifeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%A4ck%2C+T">Thomas B&#xe4;ck</a>, 
<a href="/search/cs?searchtype=author&query=van+Stein%2C+N">Niki van Stein</a>, 
<a href="/search/cs?searchtype=author&query=Kononova%2C+A+V">Anna V Kononova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 3 figures. Submitted to Genetic and Evolutionary Computation Conference (GECCO-2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Symbolic regression (SR) poses a significant challenge for randomized search
heuristics due to its reliance on the synthesis of expressions for input-output
mappings. Although traditional genetic programming (GP) algorithms have
achieved success in various domains, they exhibit limited performance when
tree-based representations are used for SR. To address these limitations, we
introduce a novel SR approach called Fourier Tree Growing (FTG) that draws
insights from functional analysis. This new perspective enables us to perform
optimization directly in a different space, thus avoiding intricate symbolic
expressions. Our proposed algorithm exhibits significant performance
improvements over traditional GP methods on a range of classical
one-dimensional benchmarking problems. To identify and explain limiting factors
of GP and FTG, we perform experiments on a large-scale polynomials benchmark
with high-order polynomials up to degree 100. To the best of the authors'
knowledge, this work represents the pioneering application of functional
analysis in addressing SR problems. The superior performance of the proposed
algorithm and insights into the limitations of GP open the way for further
advancing GP for SR and related areas of explainable machine learning.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06304" title="Abstract">arXiv:2402.06304</a> [<a href="/pdf/2402.06304" title="Download PDF">pdf</a>, <a href="/ps/2402.06304" title="Download PostScript">ps</a>, <a href="/format/2402.06304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Approach to Voice Authenticity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+N+M">Nicolas M. M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Kawa%2C+P">Piotr Kawa</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Neu%2C+M">Matthias Neu</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+J">Jennifer Williams</a>, 
<a href="/search/cs?searchtype=author&query=Sperl%2C+P">Philip Sperl</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%B6ttinger%2C+K">Konstantin B&#xf6;ttinger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Voice faking, driven primarily by recent advances in text-to-speech (TTS)
synthesis technology, poses significant societal challenges. Currently, the
prevailing assumption is that unaltered human speech can be considered genuine,
while fake speech comes from TTS synthesis. We argue that this binary
distinction is oversimplified. For instance, altered playback speeds can be
used for malicious purposes, like in the 'Drunken Nancy Pelosi' incident.
Similarly, editing of audio clips can be done ethically, e.g., for brevity or
summarization in news reporting or podcasts, but editing can also create
misleading narratives. In this paper, we propose a conceptual shift away from
the binary paradigm of audio being either 'fake' or 'real'. Instead, our focus
is on pinpointing 'voice edits', which encompass traditional modifications like
filters and cuts, as well as TTS synthesis and VC systems. We delineate 6
categories and curate a new challenge dataset rooted in the M-AILABS corpus,
for which we present baseline detection systems. And most importantly, we argue
that merely categorizing audio as fake or real is a dangerous
over-simplification that will fail to move the field of speech technology
forward.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06306" title="Abstract">arXiv:2402.06306</a> [<a href="/pdf/2402.06306" title="Download PDF">pdf</a>, <a href="/format/2402.06306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Modal Concurrent Transmission
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khormuji%2C+M+N">Majid Nasiri Khormuji</a>, 
<a href="/search/cs?searchtype=author&query=Perotti%2C+A+G">Alberto Giuseppe Perotti</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+Q">Qin Yi</a>, 
<a href="/search/cs?searchtype=author&query=Popovic%2C+B">Branislav Popovic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, 1 table
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2024 IEEE Wireless Communications and Networking Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper introduces a novel physical-layer method labelled as Multi-Modal
Concurrent Transmission (MMCT) for efficient transmission of multiple data
streams with different reliability-latency performance requirements. The MMCT
arranges data from multiple streams within a same physical-layer transport
block wherein stream-specific modulation and coding scheme (MCS) selection is
combined with joint mapping of modulated codewords to Multiple-Input
Multiple-Output spatial layers and frequency resources. Mapping to
spatial-frequency resources with higher Signal-to-Noise Ratios (SNRs) provides
the required performance boost for the more demanding streams. In tactile
internet applications, wherein haptic feedback/actuation and audio-video
streams flow in parallel, the method provides significant SNR and spectral
efficiency enhancements compared to conventional 3GPP New Radio (NR)
transmission methods.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06308" title="Abstract">arXiv:2402.06308</a> [<a href="/pdf/2402.06308" title="Download PDF">pdf</a>, <a href="/format/2402.06308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An integrated heart-torso electromechanical model for the simulation of  electrophysiogical outputs accounting for myocardial deformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zappon%2C+E">Elena Zappon</a>, 
<a href="/search/math?searchtype=author&query=Salvador%2C+M">Matteo Salvador</a>, 
<a href="/search/math?searchtype=author&query=Piersanti%2C+R">Roberto Piersanti</a>, 
<a href="/search/math?searchtype=author&query=Regazzoni%2C+F">Francesco Regazzoni</a>, 
<a href="/search/math?searchtype=author&query=Dede%27%2C+L">Luca Dede&#x27;</a>, 
<a href="/search/math?searchtype=author&query=Quarteroni%2C+A">Alfio Quarteroni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 20 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">When generating in-silico clinical electrophysiological outputs, such as
electrocardiograms (ECGs) and body surface potential maps (BSPMs), mathematical
models have relied on single physics, i.e. of the cardiac electrophysiology
(EP), neglecting the role of the heart motion. Since the heart is the most
powerful source of electrical activity in the human body, its motion
dynamically shifts the position of the principal electrical sources in the
torso, influencing electrical potential distribution and potentially altering
the EP outputs. In this work, we propose a computational model for the
simulation of ECGs and BSPMs by coupling a cardiac electromechanical model with
a model that simulates the propagation of the EP signal in the torso, thanks to
a flexible numerical approach, that simulates the torso domain deformation
induced by the myocardial displacement. Our model accounts for the major
mechano-electrical feedbacks, along with unidirectional displacement and
potential couplings from the heart to the surrounding body. For the numerical
discretization, we employ a versatile intergrid transfer operator that allows
for the use of different Finite Element spaces to be used in the cardiac and
torso domains. Our numerical results are obtained on a realistic 3D
biventricular-torso geometry, and cover both cases of sinus rhythm and
ventricular tachycardia (VT), solving both the electromechanical-torso model in
dynamical domains, and the classical electrophysiology-torso model in static
domains. By comparing standard 12-lead ECG and BSPMs, we highlight the
non-negligible effects of the myocardial contraction on the EP-outputs,
especially in pathological conditions, such as the VT.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06311" title="Abstract">arXiv:2402.06311</a> [<a href="/pdf/2402.06311" title="Download PDF">pdf</a>, <a href="/format/2402.06311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed finite elements for the Gross-Pitaevskii eigenvalue problem: a  priori error analysis and guaranteed lower energy bound
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gallistl%2C+D">Dietmar Gallistl</a>, 
<a href="/search/math?searchtype=author&query=Hauck%2C+M">Moritz Hauck</a>, 
<a href="/search/math?searchtype=author&query=Liang%2C+Y">Yizhou Liang</a>, 
<a href="/search/math?searchtype=author&query=Peterseim%2C+D">Daniel Peterseim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We establish an a priori error analysis for the lowest-order Raviart-Thomas
finite element discretisation of the nonlinear Gross-Pitaevskii eigenvalue
problem. Optimal convergence rates are obtained for the primal and dual
variables as well as for the eigenvalue and energy approximations. In contrast
to conformal approaches, which naturally imply upper energy bounds, the
proposed mixed discretisation provides a guaranteed and asymptotically exact
lower bound for the ground state energy. The theoretical results are
illustrated by a series of numerical experiments.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06313" title="Abstract">arXiv:2402.06313</a> [<a href="/pdf/2402.06313" title="Download PDF">pdf</a>, <a href="/format/2402.06313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A plastic correction algorithm for full-field elasto-plastic finite  element simulations : critical assessment of predictive capabilities and  improvement by machine learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Palchoudhary%2C+A">Abhishek Palchoudhary</a>, 
<a href="/search/cs?searchtype=author&query=Peter%2C+S">Simone Peter</a>, 
<a href="/search/cs?searchtype=author&query=Maurel%2C+V">Vincent Maurel</a>, 
<a href="/search/cs?searchtype=author&query=Ovalle%2C+C">Cristian Ovalle</a>, 
<a href="/search/cs?searchtype=author&query=Kerfriden%2C+P">Pierre Kerfriden</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 16 figures. Submitted to Springer Nature - Computational Mechanics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">This paper introduces a new local plastic correction algorithm developed to
accelerate finite element simulations for structures with elasto-plastic
constitutive laws. The proposed method belongs to the category of generalized
multiaxial Neuber-type methods enabled by pointwise proportional evolution
rules. The algorithm numerically integrates J2 plasticity laws as a function of
the finite element elastic response of the structure, to obtain full-field 3D
elasto-plastic quantities for any proportionally applied loading. Examples of
the numerical capabilities of this algorithm are shown on a structure
containing a distribution of pores, for monotonic and fatigue loading. The
approximation errors due to the proposed local plastic correction are also
investigated. As a second point of innovation, we show that the proposed local
plastic correction can be accelerated when dealing with large-scale structures
by employing a simple meta-model, with virtually no added errors. Finally, we
develop and investigate the merits of an additional deep-learning-based
corrective layer to reduce approximations errors on a subset of structures for
which full elasto-plastic FE simulations are performed, the solutions of which
are subsequently used as training set for a Convolutional Neural Network
algorithm designed to learn the error between full FE and plastic correction
approximations.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06315" title="Abstract">arXiv:2402.06315</a> [<a href="/pdf/2402.06315" title="Download PDF">pdf</a>, <a href="/format/2402.06315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multisource Semisupervised Adversarial Domain Generalization Network for  Cross-Scene Sea\textendash Land Clutter Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Q">Quan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa%2C+S">Salvador Garc&#xed;a</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 8 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning (DL)-based sea\textendash land clutter classification for
sky-wave over-the-horizon-radar (OTHR) has become a novel research topic. In
engineering applications, real-time predictions of sea\textendash land clutter
with existing distribution discrepancies are crucial. To solve this problem,
this article proposes a novel Multisource Semisupervised Adversarial Domain
Generalization Network (MSADGN) for cross-scene sea\textendash land clutter
classification. MSADGN can extract domain-invariant and domain-specific
features from one labeled source domain and multiple unlabeled source domains,
and then generalize these features to an arbitrary unseen target domain for
real-time prediction of sea\textendash land clutter. Specifically, MSADGN
consists of three modules: domain-related pseudolabeling module,
domain-invariant module, and domain-specific module. The first module
introduces an improved pseudolabel method called domain-related pseudolabel,
which is designed to generate reliable pseudolabels to fully exploit unlabeled
source domains. The second module utilizes a generative adversarial network
(GAN) with a multidiscriminator to extract domain-invariant features, to
enhance the model's transferability in the target domain. The third module
employs a parallel multiclassifier branch to extract domain-specific features,
to enhance the model's discriminability in the target domain. The effectiveness
of our method is validated in twelve domain generalizations (DG) scenarios.
Meanwhile, we selected 10 state-of-the-art DG methods for comparison. The
experimental results demonstrate the superiority of our method.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06318" title="Abstract">arXiv:2402.06318</a> [<a href="/pdf/2402.06318" title="Download PDF">pdf</a>, <a href="/format/2402.06318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TimEHR: Image-based Time Series Generation for Electronic Health Records
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karami%2C+H">Hojjat Karami</a>, 
<a href="/search/cs?searchtype=author&query=Hartley%2C+M">Mary-Anne Hartley</a>, 
<a href="/search/cs?searchtype=author&query=Atienza%2C+D">David Atienza</a>, 
<a href="/search/cs?searchtype=author&query=Ionescu%2C+A">Anisoara Ionescu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Time series in Electronic Health Records (EHRs) present unique challenges for
generative models, such as irregular sampling, missing values, and high
dimensionality. In this paper, we propose a novel generative adversarial
network (GAN) model, TimEHR, to generate time series data from EHRs. In
particular, TimEHR treats time series as images and is based on two conditional
GANs. The first GAN generates missingness patterns, and the second GAN
generates time series values based on the missingness pattern. Experimental
results on three real-world EHR datasets show that TimEHR outperforms
state-of-the-art methods in terms of fidelity, utility, and privacy metrics.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06319" title="Abstract">arXiv:2402.06319</a> [<a href="/pdf/2402.06319" title="Download PDF">pdf</a>, <a href="/format/2402.06319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy efficiency optimization of task-parallel codes on asymmetric  architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Costero%2C+L">Luis Costero</a>, 
<a href="/search/cs?searchtype=author&query=Igual%2C+F+D">Francisco D. Igual</a>, 
<a href="/search/cs?searchtype=author&query=Olcoz%2C+K">Katzalin Olcoz</a>, 
<a href="/search/cs?searchtype=author&query=Tirado%2C+F">Francisco Tirado</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">We present a family of policies that, integrated within a runtime task
scheduler (Nanox), pursue the goal of improving the energy efficiency of
task-parallel executions with no intervention from the programmer. The proposed
policies tackle the problem by modifying the core operating frequency via DVFS
mechanisms, or by enabling/disabling the mapping of tasks to specific cores at
selected execution points, depending on the internal status of the scheduler.
Experimental results on an asymmetric SoC (Exynos 5422) and for a specific
operation (Cholesky factorization) reveal gains up to 29% in terms of energy
efficiency and considerable reductions in average power.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06323" title="Abstract">arXiv:2402.06323</a> [<a href="/pdf/2402.06323" title="Download PDF">pdf</a>, <a href="/format/2402.06323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Uniform Random Weights Induce Non-uniform Bias: Typical  Interpolating Neural Networks Generalize with Narrow Teachers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Buzaglo%2C+G">Gon Buzaglo</a>, 
<a href="/search/cs?searchtype=author&query=Harel%2C+I">Itamar Harel</a>, 
<a href="/search/cs?searchtype=author&query=Nacson%2C+M+S">Mor Shpigel Nacson</a>, 
<a href="/search/cs?searchtype=author&query=Brutzkus%2C+A">Alon Brutzkus</a>, 
<a href="/search/cs?searchtype=author&query=Srebro%2C+N">Nathan Srebro</a>, 
<a href="/search/cs?searchtype=author&query=Soudry%2C+D">Daniel Soudry</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Background. A main theoretical puzzle is why over-parameterized Neural
Networks (NNs) generalize well when trained to zero loss (i.e., so they
interpolate the data). Usually, the NN is trained with Stochastic Gradient
Descent (SGD) or one of its variants. However, recent empirical work examined
the generalization of a random NN that interpolates the data: the NN was
sampled from a seemingly uniform prior over the parameters, conditioned on that
the NN perfectly classifying the training set. Interestingly, such a NN sample
typically generalized as well as SGD-trained NNs.
<br />Contributions. We prove that such a random NN interpolator typically
generalizes well if there exists an underlying narrow ``teacher NN" that agrees
with the labels. Specifically, we show that such a `flat' prior over the NN
parametrization induces a rich prior over the NN functions, due to the
redundancy in the NN structure. In particular, this creates a bias towards
simpler functions, which require less relevant parameters to represent --
enabling learning with a sample complexity approximately proportional to the
complexity of the teacher (roughly, the number of non-redundant parameters),
rather than the student's.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06325" title="Abstract">arXiv:2402.06325</a> [<a href="/pdf/2402.06325" title="Download PDF">pdf</a>, <a href="/format/2402.06325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Effect of Haptic Guidance during Robotic-assisted Motor Training is  Modulated by Personality Traits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garz%C3%A1s-Villar%2C+A">Alberto Garz&#xe1;s-Villar</a>, 
<a href="/search/cs?searchtype=author&query=Boersma%2C+C">Caspar Boersma</a>, 
<a href="/search/cs?searchtype=author&query=Derumigny%2C+A">Alexis Derumigny</a>, 
<a href="/search/cs?searchtype=author&query=Zgonnikov%2C+A">Arkady Zgonnikov</a>, 
<a href="/search/cs?searchtype=author&query=Marchal-Crespo%2C+L">Laura Marchal-Crespo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, 1 table, this paper has been submitted to IEEE RAS EMBS 10th International Conference on Biomedical Robotics and Biomechatronics (BioRob 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The provision of robotic assistance during motor training has proven to be
effective in enhancing motor learning in some healthy trainee groups as well as
patients. Personalizing such robotic assistance can help further improve motor
(re)learning outcomes and cater better to the trainee's needs and desires.
However, the development of personalized haptic assistance is hindered by the
lack of understanding of the link between the trainee's personality and the
effects of haptic guidance during human-robot interaction. To address this gap,
we ran an experiment with 42 healthy participants who trained with a robotic
device to control a virtual pendulum to hit incoming targets either with or
without haptic guidance. We found that certain personal traits affected how
users adapt and interact with the guidance during training. In particular,
those participants with an 'Achiever gaming style' performed better and applied
lower interaction forces to the robotic device than the average participant as
the training progressed. Conversely, participants with the 'Free spirit game
style' increased the interaction force in the course of training. We also found
an interaction between some personal characteristics and haptic guidance.
Specifically, participants with a higher 'Transformation of challenge' trait
exhibited poorer performance during training while receiving haptic guidance
compared to an average participant receiving haptic guidance. Furthermore,
individuals with an external Locus of Control tended to increase their
interaction force with the device, deviating from the pattern observed in an
average participant under the same guidance. These findings suggest that
individual characteristics may play a crucial role in the effectiveness of
haptic guidance training strategies.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06326" title="Abstract">arXiv:2402.06326</a> [<a href="/pdf/2402.06326" title="Download PDF">pdf</a>, <a href="/format/2402.06326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Learning on Temporal Interaction Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Siwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yun Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xixi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiawei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiangguo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yinglong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yulin Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Temporal Interaction Graphs (TIGs) are widely utilized to represent
real-world systems. To facilitate representation learning on TIGs, researchers
have proposed a series of TIG models. However, these models are still facing
two tough gaps between the pre-training and downstream predictions in their
``pre-train, predict'' training paradigm. First, the temporal discrepancy
between the pre-training and inference data severely undermines the models'
applicability in distant future predictions on the dynamically evolving data.
Second, the semantic divergence between pretext and downstream tasks hinders
their practical applications, as they struggle to align with their learning and
prediction capabilities across application scenarios.
<br />Recently, the ``pre-train, prompt'' paradigm has emerged as a lightweight
mechanism for model generalization. Applying this paradigm is a potential
solution to solve the aforementioned challenges. However, the adaptation of
this paradigm to TIGs is not straightforward. The application of prompting in
static graph contexts falls short in temporal settings due to a lack of
consideration for time-sensitive dynamics and a deficiency in expressive power.
To address this issue, we introduce Temporal Interaction Graph Prompting
(TIGPrompt), a versatile framework that seamlessly integrates with TIG models,
bridging both the temporal and semantic gaps. In detail, we propose a temporal
prompt generator to offer temporally-aware prompts for different tasks. These
prompts stand out for their minimalistic design, relying solely on the tuning
of the prompt generator with very little supervision data. To cater to varying
computational resource demands, we propose an extended ``pre-train,
prompt-based fine-tune'' paradigm, offering greater flexibility. Through
extensive experiments, the TIGPrompt demonstrates the SOTA performance and
remarkable efficiency advantages.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06329" title="Abstract">arXiv:2402.06329</a> [<a href="/pdf/2402.06329" title="Download PDF">pdf</a>, <a href="/ps/2402.06329" title="Download PostScript">ps</a>, <a href="/format/2402.06329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Network for structural dense displacement based on 3D deformable mesh  model and optical flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+P">Peimian Du</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qicheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanru Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper for the 3rd International Competition for Structural Health Monitoring (IC-SHM 2022): 15 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">This study proposes a Network to recognize displacement of a RC frame
structure from a video by a monocular camera. The proposed Network consists of
two modules which is FlowNet2 and POFRN-Net. FlowNet2 is used to generate dense
optical flow as well as POFRN-Net is to extract pose parameter H. FlowNet2
convert two video frames into dense optical flow. POFRN-Net is inputted dense
optical flow from FlowNet2 to output the pose parameter H. The displacement of
any points of structure can be calculated from parameter H. The Fast Fourier
Transform (FFT) is applied to obtain frequency domain signal from corresponding
displacement signal. Furthermore, the comparison of the truth displacement on
the First floor of the First video is shown in this study. Finally, the
predicted displacements on four floors of RC frame structure of given three
videos are exhibited in the last of this study.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06330" title="Abstract">arXiv:2402.06330</a> [<a href="/pdf/2402.06330" title="Download PDF">pdf</a>, <a href="/format/2402.06330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Learning on Graphs: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zonggui Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Du Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Hong-Ning Dai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Recently, continual graph learning has been increasingly adopted for diverse
graph-structured data processing tasks in non-stationary environments. Despite
its promising learning capability, current studies on continual graph learning
mainly focus on mitigating the catastrophic forgetting problem while ignoring
continuous performance improvement. To bridge this gap, this article aims to
provide a comprehensive survey of recent efforts on continual graph learning.
Specifically, we introduce a new taxonomy of continual graph learning from the
perspective of overcoming catastrophic forgetting. Moreover, we systematically
analyze the challenges of applying these continual graph learning methods in
improving performance continuously and then discuss the possible solutions.
Finally, we present open issues and future directions pertaining to the
development of continual graph learning and discuss how they impact continuous
performance improvement.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06331" title="Abstract">arXiv:2402.06331</a> [<a href="/pdf/2402.06331" title="Download PDF">pdf</a>, <a href="/format/2402.06331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taking Class Imbalance Into Account in Open Set Recognition Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Komorniczak%2C+J">Joanna Komorniczak</a>, 
<a href="/search/cs?searchtype=author&query=Ksieniewicz%2C+P">Pawel Ksieniewicz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In recent years Deep Neural Network-based systems are not only increasing in
popularity but also receive growing user trust. However, due to the
closed-world assumption of such systems, they cannot recognize samples from
unknown classes and often induce an incorrect label with high confidence.
Presented work looks at the evaluation of methods for Open Set Recognition,
focusing on the impact of class imbalance, especially in the dichotomy between
known and unknown samples. As an outcome of problem analysis, we present a set
of guidelines for evaluation of methods in this field.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06332" title="Abstract">arXiv:2402.06332</a> [<a href="/pdf/2402.06332" title="Download PDF">pdf</a>, <a href="/format/2402.06332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InternLM-Math: Open Math Large Language Models Toward Verifiable  Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ying%2C+H">Huaiyuan Ying</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhejian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yunfan Shao</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+Z">Zhaoye Fei</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yichuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Jiawei Hong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kuikun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yudong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zijian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuaibin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Fengzhe Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Songyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiayu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The math abilities of large language models can represent their abstract
reasoning ability. In this paper, we introduce and open-source our math
reasoning LLMs InternLM-Math which is continue pre-trained from InternLM2. We
unify chain-of-thought reasoning, reward modeling, formal reasoning, data
augmentation, and code interpreter in a unified seq2seq format and supervise
our model to be a versatile math reasoner, verifier, prover, and augmenter.
These abilities can be used to develop the next math LLMs or self-iteration.
InternLM-Math obtains open-sourced state-of-the-art performance under the
setting of in-context learning, supervised fine-tuning, and code-assisted
reasoning in various informal and formal benchmarks including GSM8K, MATH,
Hungary math exam, MathBench-ZH, and MiniF2F. Our pre-trained model achieves
30.3 on the MiniF2F test set without fine-tuning. We further explore how to use
LEAN to solve math problems and study its performance under the setting of
multi-task learning which shows the possibility of using LEAN as a unified
platform for solving and proving in math. Our models, codes, and data are
released at \url{https://github.com/InternLM/InternLM-Math}.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06333" title="Abstract">arXiv:2402.06333</a> [<a href="/pdf/2402.06333" title="Download PDF">pdf</a>, <a href="/format/2402.06333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An application of power indices for the family of weighted majority  games in partition function form
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alonso-Meijide%2C+J+M">Jos&#xe9; M. Alonso-Meijide</a>, 
<a href="/search/cs?searchtype=author&query=Armijos-Toro%2C+L+M">Livino M. Armijos-Toro</a>, 
<a href="/search/cs?searchtype=author&query=Casas-M%C3%A9ndez%2C+B+V">Balbina V. Casas-M&#xe9;ndez</a>, 
<a href="/search/cs?searchtype=author&query=Mosquera%2C+M+A">Manuel A. Mosquera</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Power and Responsibility: Interdisciplinary Perspectives for the
  21st Century in Honor of Manfred J. Holler (2023) 143-164
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Based on Holler (1982) and Armijos-Toro et al. (2021) we propose two power
indices to measure the influence of the players in the class of weighted
majority games in partition function form. We compare these new power indices
with their original versions on the class of games in characteristic function
form. Finally, we use both pairs of power indices for games in partition
function form to study the distribution of power in the National Assembly of
Ecuador that emerged after the elections of February 7, 2021.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06334" title="Abstract">arXiv:2402.06334</a> [<a href="/pdf/2402.06334" title="Download PDF">pdf</a>, <a href="/format/2402.06334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ExaRanker-Open: Synthetic Explanation for IR using Open-Source LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferraretto%2C+F">Fernando Ferraretto</a>, 
<a href="/search/cs?searchtype=author&query=Laitz%2C+T">Thiago Laitz</a>, 
<a href="/search/cs?searchtype=author&query=Lotufo%2C+R">Roberto Lotufo</a>, 
<a href="/search/cs?searchtype=author&query=Nogueira%2C+R">Rodrigo Nogueira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">ExaRanker recently introduced an approach to training information retrieval
(IR) models, incorporating natural language explanations as additional labels.
The method addresses the challenge of limited labeled examples, leading to
improvements in the effectiveness of IR models. However, the initial results
were based on proprietary language models such as GPT-3.5, which posed
constraints on dataset size due to its cost and data privacy. In this paper, we
introduce ExaRanker-Open, where we adapt and explore the use of open-source
language models to generate explanations. The method has been tested using
different LLMs and datasets sizes to better comprehend the effective
contribution of data augmentation. Our findings reveal that incorporating
explanations consistently enhances neural rankers, with benefits escalating as
the LLM size increases. Notably, the data augmentation method proves
advantageous even with large datasets, as evidenced by ExaRanker surpassing the
target baseline by 0.6 nDCG@10 points in our study. To encourage further
advancements by the research community, we have open-sourced both the code and
datasets at https://github.com/unicamp-dl/ExaRanker.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06341" title="Abstract">arXiv:2402.06341</a> [<a href="/pdf/2402.06341" title="Download PDF">pdf</a>, <a href="/format/2402.06341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RareBench: Can LLMs Serve as Rare Diseases Specialists?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuanzhong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+X">Xiaohao Mao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qihan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Ting Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Generalist Large Language Models (LLMs), such as GPT-4, have shown
considerable promise in various domains, including medical diagnosis. Rare
diseases, affecting approximately 300 million people worldwide, often have
unsatisfactory clinical diagnosis rates primarily due to a lack of experienced
physicians and the complexity of differentiating among many rare diseases. In
this context, recent news such as "ChatGPT correctly diagnosed a 4-year-old's
rare disease after 17 doctors failed" underscore LLMs' potential, yet
underexplored, role in clinically diagnosing rare diseases. To bridge this
research gap, we introduce RareBench, a pioneering benchmark designed to
systematically evaluate the capabilities of LLMs on 4 critical dimensions
within the realm of rare diseases. Meanwhile, we have compiled the largest
open-source dataset on rare disease patients, establishing a benchmark for
future studies in this domain. To facilitate differential diagnosis of rare
diseases, we develop a dynamic few-shot prompt methodology, leveraging a
comprehensive rare disease knowledge graph synthesized from multiple knowledge
bases, significantly enhancing LLMs' diagnostic performance. Moreover, we
present an exhaustive comparative study of GPT-4's diagnostic capabilities
against those of specialist physicians. Our experimental findings underscore
the promising potential of integrating LLMs into the clinical diagnostic
process for rare diseases. This paves the way for exciting possibilities in
future advancements in this field.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06342" title="Abstract">arXiv:2402.06342</a> [<a href="/pdf/2402.06342" title="Download PDF">pdf</a>, <a href="/ps/2402.06342" title="Download PostScript">ps</a>, <a href="/format/2402.06342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Promoting Target Data in Context-aware Neural Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gete%2C+H">Harritxu Gete</a>, 
<a href="/search/cs?searchtype=author&query=Etchegoyhen%2C+T">Thierry Etchegoyhen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Standard context-aware neural machine translation (NMT) typically relies on
parallel document-level data, exploiting both source and target contexts.
Concatenation-based approaches in particular, still a strong baseline for
document-level NMT, prepend source and/or target context sentences to the
sentences to be translated, with model variants that exploit equal amounts of
source and target data on each side achieving state-of-the-art results. In this
work, we investigate whether target data should be further promoted within
standard concatenation-based approaches, as most document-level phenomena rely
on information that is present on the target language side. We evaluate novel
concatenation-based variants where the target context is prepended to the
source language, either in isolation or in combination with the source context.
Experimental results in English-Russian and Basque-Spanish show that including
target context in the source leads to large improvements on target language
phenomena. On source-dependent phenomena, using only target language context in
the source achieves parity with state-of-the-art concatenation approaches, or
slightly underperforms, whereas combining source and target context on the
source side leads to significant gains across the board.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06346" title="Abstract">arXiv:2402.06346</a> [<a href="/pdf/2402.06346" title="Download PDF">pdf</a>, <a href="/format/2402.06346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Analysis of Energy Consumption Between The Widespread  Unreal and Unity Video Game Engines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+C">Carlos P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Ver%C3%B3n%2C+J">Javier Ver&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa%2C+F">F&#xe9;lix Garc&#xed;a</a>, 
<a href="/search/cs?searchtype=author&query=Moraga%2C+M+%C3%81">M &#xc1;ngeles Moraga</a>, 
<a href="/search/cs?searchtype=author&query=Calero%2C+C">Coral Calero</a>, 
<a href="/search/cs?searchtype=author&query=Cetina%2C+C">Carlos Cetina</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The total energy cost of computing activities is steadily increasing and
projections indicate that it will be one of the dominant global energy
consumers in the coming decades. However, perhaps due to its relative youth,
the video game sector has not yet developed the same level of environmental
awareness as other computing technologies despite the estimated three billion
regular video game players in the world. This work evaluates the energy
consumption of the most widely used industry-scale video game engines: Unity
and Unreal Engine. Specifically, our work uses three scenarios representing
relevant aspects of video games (Physics, Statics Meshes, and Dynamic Meshes)
to compare the energy consumption of the engines. The aim is to determine the
influence of using each of the two engines on energy consumption. Our research
has confirmed significant differences in the energy consumption of video game
engines: 351% in Physics in favor of Unity, 17% in Statics Meshes in favor of
Unity, and 26% in Dynamic Meshes in favor of Unreal Engine. These results
represent an opportunity for worldwide potential savings of at least 51 TWh per
year, equivalent to the annual consumption of nearly 13 million European
households, that might encourage a new branch of research on energy-efficient
video game engines.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06348" title="Abstract">arXiv:2402.06348</a> [<a href="/pdf/2402.06348" title="Download PDF">pdf</a>, <a href="/format/2402.06348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fairness of Exposure in Online Restless Multi-armed Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sood%2C+A">Archit Sood</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Shweta Jain</a>, 
<a href="/search/cs?searchtype=author&query=Gujar%2C+S">Sujit Gujar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as extended abstract in AAMAS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Restless multi-armed bandits (RMABs) generalize the multi-armed bandits where
each arm exhibits Markovian behavior and transitions according to their
transition dynamics. Solutions to RMAB exist for both offline and online cases.
However, they do not consider the distribution of pulls among the arms. Studies
have shown that optimal policies lead to unfairness, where some arms are not
exposed enough. Existing works in fairness in RMABs focus heavily on the
offline case, which diminishes their application in real-world scenarios where
the environment is largely unknown. In the online scenario, we propose the
first fair RMAB framework, where each arm receives pulls in proportion to its
merit. We define the merit of an arm as a function of its stationary reward
distribution. We prove that our algorithm achieves sublinear fairness regret in
the single pull case $O(\sqrt{T\ln T})$, with $T$ being the total number of
episodes. Empirically, we show that our algorithm performs well in the
multi-pull scenario as well.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06351" title="Abstract">arXiv:2402.06351</a> [<a href="/pdf/2402.06351" title="Download PDF">pdf</a>, <a href="/ps/2402.06351" title="Download PostScript">ps</a>, <a href="/format/2402.06351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SWITCH: An Exemplar for Evaluating Self-Adaptive ML-Enabled Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marda%2C+A">Arya Marda</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+S">Shubham Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Vaidhyanathan%2C+K">Karthik Vaidhyanathan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for SEAMS 2024 - Artifact Track (<a href="https://conf.researchr.org/track/seams-2024/seams-2024-artifact-track?">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Addressing runtime uncertainties in Machine Learning-Enabled Systems (MLS) is
crucial for maintaining Quality of Service (QoS). The Machine Learning Model
Balancer is a concept that addresses these uncertainties by facilitating
dynamic ML model switching, showing promise in improving QoS in MLS. Leveraging
this concept, this paper introduces SWITCH, an exemplar developed to enhance
self-adaptive capabilities in such systems through dynamic model switching in
runtime. SWITCH is designed as a comprehensive web service catering to a broad
range of ML scenarios, with its implementation demonstrated through an object
detection use case. SWITCH provides researchers with a flexible platform to
apply and evaluate their ML model switching strategies, aiming to enhance QoS
in MLS. SWITCH features advanced input handling, real-time data processing, and
logging for adaptation metrics supplemented with an interactive real-time
dashboard for enhancing system observability. This paper details SWITCH's
architecture, self-adaptation strategies through ML model switching, and its
empirical validation through a case study, illustrating its potential to
improve QoS in MLS. By enabling a hands-on approach to explore adaptive
behaviors in ML systems, SWITCH contributes a valuable tool to the SEAMS
community for research into self-adaptive mechanisms for MLS and their
practical applications.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06352" title="Abstract">arXiv:2402.06352</a> [<a href="/pdf/2402.06352" title="Download PDF">pdf</a>, <a href="/ps/2402.06352" title="Download PostScript">ps</a>, <a href="/format/2402.06352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blockchain Bribing Attacks and the Efficacy of Counterincentives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karakostas%2C+D">Dimitris Karakostas</a>, 
<a href="/search/cs?searchtype=author&query=Kiayias%2C+A">Aggelos Kiayias</a>, 
<a href="/search/cs?searchtype=author&query=Zacharias%2C+T">Thomas Zacharias</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">We analyze bribing attacks in distributed ledgers from a game theoretic
perspective. In bribing attacks, an adversary offers to maintainers a financial
reward, in exchange for instructing them on how to behave, with the goal of
attacking the protocol's properties. We consider two types of bribing,
depending on how the bribes are awarded: i) guided bribing, where the bribe is
given as long as the bribed party behaves as instructed; ii) effective bribing,
where bribes are conditional on the attack's success, w.r.t. well-defined
metrics. We analyze each type of attack in a game theoretic setting and
identify relevant equilibria. In guided bribing, we show that the protocol is
not an equilibrium and then describe good equilibria, where the attack is
unsuccessful, and a negative one, where all parties are bribed such that the
attack succeeds. In effective bribing, we show that both the protocol and the
"all bribed" setting are equilibria. Using the identified equilibria, we then
compute bounds on the Prices of Stability and Anarchy. Our results indicate
that additional mitigations are needed for guided bribing, so our analysis
concludes with incentive-based mitigation techniques, namely slashing and
dilution. Here, we present two positive results, that both render the protocol
an equilibrium and achieve maximal welfare for all parties, and a negative
result, wherein an attack becomes more plausible if it severely affects the
ledger's token's market price.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06353" title="Abstract">arXiv:2402.06353</a> [<a href="/pdf/2402.06353" title="Download PDF">pdf</a>, <a href="/format/2402.06353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards actionability for open medical imaging datasets: lessons from  community-contributed platforms for data management and stewardship
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jim%C3%A9nez-S%C3%A1nchez%2C+A">Amelia Jim&#xe9;nez-S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Avlona%2C+N">Natalia-Rozalia Avlona</a>, 
<a href="/search/cs?searchtype=author&query=Juodelyte%2C+D">Dovile Juodelyte</a>, 
<a href="/search/cs?searchtype=author&query=Sourget%2C+T">Th&#xe9;o Sourget</a>, 
<a href="/search/cs?searchtype=author&query=Vang-Larsen%2C+C">Caroline Vang-Larsen</a>, 
<a href="/search/cs?searchtype=author&query=Zaj%C4%85c%2C+H+D">Hubert Dariusz Zaj&#x105;c</a>, 
<a href="/search/cs?searchtype=author&query=Cheplygina%2C+V">Veronika Cheplygina</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Manuscript under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Medical imaging datasets are fundamental to artificial intelligence (AI) in
healthcare. The accuracy, robustness and fairness of diagnostic algorithms
depend on the data (and its quality) on which the models are trained and
evaluated. Medical imaging datasets have become increasingly available to the
public, and are often hosted on Community-Contributed Platforms (CCP),
including private companies like Kaggle or HuggingFace. While open data is
important to enhance the redistribution of data's public value, we find that
the current CCP governance model fails to uphold the quality needed and
recommended practices for sharing, documenting, and evaluating datasets. In
this paper we investigate medical imaging datasets on CCPs and how they are
documented, shared, and maintained. We first highlight some differences between
medical imaging and computer vision, particularly in the potentially harmful
downstream effects due to poor adoption of recommended dataset management
practices. We then analyze 20 (10 medical and 10 computer vision) popular
datasets on CCPs and find vague licenses, lack of persistent identifiers and
storage, duplicates and missing metadata, with differences between the
platforms. We present "actionability" as a conceptual metric to reveal the data
quality gap between characteristics of data on CCPs and the desired
characteristics of data for AI in healthcare. Finally, we propose a
commons-based stewardship model for documenting, sharing and maintaining
datasets on CCPs and end with a discussion of limitations and open questions.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06357" title="Abstract">arXiv:2402.06357</a> [<a href="/pdf/2402.06357" title="Download PDF">pdf</a>, <a href="/format/2402.06357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The SpongeNet Attack: Sponge Weight Poisoning of Deep Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lintelo%2C+J+t">Jona te Lintelo</a>, 
<a href="/search/cs?searchtype=author&query=Koffas%2C+S">Stefanos Koffas</a>, 
<a href="/search/cs?searchtype=author&query=Picek%2C+S">Stjepan Picek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Sponge attacks aim to increase the energy consumption and computation time of
neural networks deployed on hardware accelerators. Existing sponge attacks can
be performed during inference via sponge examples or during training via Sponge
Poisoning. Sponge examples leverage perturbations added to the model's input to
increase energy and latency, while Sponge Poisoning alters the objective
function of a model to induce inference-time energy/latency effects.
<br />In this work, we propose a novel sponge attack called SpongeNet. SpongeNet is
the first sponge attack that is performed directly on the parameters of a
pre-trained model. Our experiments show that SpongeNet can successfully
increase the energy consumption of vision models with fewer samples required
than Sponge Poisoning. Our experiments indicate that poisoning defenses are
ineffective if not adjusted specifically for the defense against Sponge
Poisoning (i.e., they decrease batch normalization bias values). Our work shows
that SpongeNet is more effective on StarGAN than the state-of-the-art.
Additionally, SpongeNet is stealthier than the previous Sponge Poisoning attack
as it does not require significant changes in the victim model's weights. Our
experiments indicate that the SpongeNet attack can be performed even when an
attacker has access to only 1% of the entire dataset and reach up to 11% energy
increase.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06359" title="Abstract">arXiv:2402.06359</a> [<a href="/pdf/2402.06359" title="Download PDF">pdf</a>, <a href="/format/2402.06359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modelling Human Values for AI Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Osman%2C+N">Nardine Osman</a>, 
<a href="/search/cs?searchtype=author&query=d%27Inverno%2C+M">Mark d&#x27;Inverno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">One of today's most significant societal challenges is building AI systems
whose behaviour, or the behaviour it enables within communities of interacting
agents (human and artificial), aligns with human values. To address this
challenge, we detail a formal model of human values for their explicit
computational representation. To our knowledge, this has not been attempted as
yet, which is surprising given the growing volume of research integrating
values within AI. Taking as our starting point the wealth of research
investigating the nature of human values from social psychology over the last
few decades, we set out to provide such a formal model. We show how this model
can provide the foundational apparatus for AI-based reasoning over values, and
demonstrate its applicability in real-world use cases. We illustrate how our
model captures the key ideas from social psychology research and propose a
roadmap for future integrated, and interdisciplinary, research into human
values in AI. The ability to automatically reason over values not only helps
address the value alignment problem but also facilitates the design of AI
systems that can support individuals and communities in making more informed,
value-aligned decisions. More and more, individuals and organisations are
motivated to understand their values more explicitly and explore whether their
behaviours and attitudes properly reflect them. Our work on modelling human
values will enable AI systems to be designed and deployed to meet this growing
need.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06360" title="Abstract">arXiv:2402.06360</a> [<a href="/pdf/2402.06360" title="Download PDF">pdf</a>, <a href="/format/2402.06360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoSearchAgent: A Lightweight Collaborative Search Agent with Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+P">Peiyuan Gong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiamian Li</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Jiaxin Mao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, demo
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Collaborative search supports multiple users working together to accomplish a
specific search task. Research has found that designing lightweight
collaborative search plugins within instant messaging platforms aligns better
with users' collaborative habits. However, due to the complexity of multi-user
interaction scenarios, it is challenging to implement a fully functioning
lightweight collaborative search system. Therefore, previous studies on
lightweight collaborative search had to rely on the Wizard of Oz paradigm. In
recent years, large language models (LLMs) have been demonstrated to interact
naturally with users and achieve complex information-seeking tasks through
LLM-based agents. Hence, to better support the research in collaborative
search, in this demo, we propose CoSearchAgent, a lightweight collaborative
search agent powered by LLMs. CoSearchAgent is designed as a Slack plugin that
can support collaborative search during multi-party conversations on this
platform. Equipped with the capacity to understand the queries and context in
multi-user conversations and the ability to search the Web for relevant
information via APIs, CoSearchAgent can respond to user queries with answers
grounded on the relevant search results. It can also ask clarifying questions
when the information needs are unclear. The proposed CoSearchAgent is highly
flexible and would be useful for supporting further research on collaborative
search. The code and demo video are accessible.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06363" title="Abstract">arXiv:2402.06363</a> [<a href="/pdf/2402.06363" title="Download PDF">pdf</a>, <a href="/format/2402.06363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StruQ: Defending Against Prompt Injection with Structured Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sizhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Piet%2C+J">Julien Piet</a>, 
<a href="/search/cs?searchtype=author&query=Sitawarin%2C+C">Chawin Sitawarin</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+D">David Wagner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> prompt injections, LLM security
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Recent advances in Large Language Models (LLMs) enable exciting
LLM-integrated applications, which perform text-based tasks by utilizing their
advanced language understanding capabilities. However, as LLMs have improved,
so have the attacks against them. Prompt injection attacks are an important
threat: they trick the model to deviate from the original application's
instructions and instead follow user directives. These attacks rely on the
LLM's ability to follow instructions and inability to separate the prompts and
user data. We introduce structured queries, a general approach to tackle this
problem. Structured queries separate prompts and data into two channels. We
implement a system that supports structured queries. This system is made of (1)
a secure front-end that formats a prompt and user data into a special format,
and (2) a specially trained LLM that can produce high-quality outputs from
these inputs. The LLM is trained using a novel fine-tuning strategy: we convert
a base (non-instruction-tuned) LLM to a structured instruction-tuned model that
will only follow instructions in the prompt portion of a query. To do so, we
augment standard instruction tuning datasets with examples that also include
instructions in the data portion of the query, and fine-tune the model to
ignore these. Our system significantly improves resistance to prompt injection
attacks, with little or no impact on utility. Our code is released at
https://github.com/Sizhe-Chen/PromptInjectionDefense.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06366" title="Abstract">arXiv:2402.06366</a> [<a href="/pdf/2402.06366" title="Download PDF">pdf</a>, <a href="/ps/2402.06366" title="Download PostScript">ps</a>, <a href="/format/2402.06366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAT-based Learning of Computation Tree Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pommellet%2C+A">Adrien Pommellet</a>, 
<a href="/search/cs?searchtype=author&query=Stan%2C+D">Daniel Stan</a>, 
<a href="/search/cs?searchtype=author&query=Scatton%2C+S">Simon Scatton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IJCAR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">The CTL learning problem consists in finding for a given sample of positive
and negative Kripke structures a distinguishing CTL formula that is verified by
the former but not by the latter. Further constraints may bound the size and
shape of the desired formula or even ask for its minimality in terms of
syntactic size. This synthesis problem is motivated by explanation generation
for dissimilar models, e.g. comparing a faulty implementation with the original
protocol. We devise a SAT-based encoding for a fixed size CTL formula, then
provide an incremental approach that guarantees minimality. We further report
on a prototype implementation whose contribution is twofold: first, it allows
us to assess the efficiency of various output fragments and optimizations.
Secondly, we can experimentally evaluate this tool by randomly mutating Kripke
structures or syntactically introducing errors in higher-level models, then
learning CTL distinguishing formulas.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06367" title="Abstract">arXiv:2402.06367</a> [<a href="/pdf/2402.06367" title="Download PDF">pdf</a>, <a href="/format/2402.06367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TEE4EHR: Transformer Event Encoder for Better Representation Learning in  Electronic Health Records
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karami%2C+H">Hojjat Karami</a>, 
<a href="/search/cs?searchtype=author&query=Atienza%2C+D">David Atienza</a>, 
<a href="/search/cs?searchtype=author&query=Ionescu%2C+A">Anisoara Ionescu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Irregular sampling of time series in electronic health records (EHRs) is one
of the main challenges for developing machine learning models. Additionally,
the pattern of missing data in certain clinical variables is not at random but
depends on the decisions of clinicians and the state of the patient. Point
process is a mathematical framework for analyzing event sequence data that is
consistent with irregular sampling patterns. Our model, TEE4EHR, is a
transformer event encoder (TEE) with point process loss that encodes the
pattern of laboratory tests in EHRs. The utility of our TEE has been
investigated in a variety of benchmark event sequence datasets. Additionally,
we conduct experiments on two real-world EHR databases to provide a more
comprehensive evaluation of our model. Firstly, in a self-supervised learning
approach, the TEE is jointly learned with an existing attention-based deep
neural network which gives superior performance in negative log-likelihood and
future event prediction. Besides, we propose an algorithm for aggregating
attention weights that can reveal the interaction between the events. Secondly,
we transfer and freeze the learned TEE to the downstream task for the outcome
prediction, where it outperforms state-of-the-art models for handling
irregularly sampled time series. Furthermore, our results demonstrate that our
approach can improve representation learning in EHRs and can be useful for
clinical prediction tasks.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06368" title="Abstract">arXiv:2402.06368</a> [<a href="/pdf/2402.06368" title="Download PDF">pdf</a>, <a href="/ps/2402.06368" title="Download PostScript">ps</a>, <a href="/format/2402.06368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Downlink Localization and User Tracking in Near-Field and  Far-Field: A Trade-Off Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mylonopoulos%2C+G">Georgios Mylonopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Makki%2C+B">Behrooz Makki</a>, 
<a href="/search/cs?searchtype=author&query=Buzzi%2C+S">Stefano Buzzi</a>, 
<a href="/search/cs?searchtype=author&query=Fodor%2C+G">G&#xe1;bor Fodor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2402.02473">arXiv:2402.02473</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper considers the problem of downlink localization and user equipments
(UEs) tracking with an adaptive procedure for a range of distances. We provide
the base station (BS) with two signaling schemes and the UEs with two
localization algorithms, assuming far-field (FF) and near-field (NF)
conditions, respectively. The proposed schemes employ different beam-sweep
patterns, where their compatibility depends on the UE range. Consequently, the
FF-NF distinction transcends the traditional definition. Our proposed NF scheme
requires beam-focusing on specific spots and more transmissions are required to
sweep the area. Instead, the FF scheme assumes distant UEs, and fewer beams are
sufficient. We derive a low-complexity algorithm that exploits the FF channel
model and highlight its practical benefits and the limitations. Also, we
propose an iterative adaptive procedure, where the signaling scheme is depends
on the expected accuracy-complexity trade-off. Multiple iterations introduce a
tracking application, where the formed trajectory dictates the validity of our
assumptions. Moreover, the range from the BS, where the FF signaling scheme can
be successfully employed, is investigated. We show that the conventional
Fraunhofer distance is not sufficient for adaptive localization and tracking
algorithms in the mixed NF and FF environment.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06373" title="Abstract">arXiv:2402.06373</a> [<a href="/pdf/2402.06373" title="Download PDF">pdf</a>, <a href="/format/2402.06373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new edge betweenness measure using a game theoretical approach: an  application to hierarchical community detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez%2C+D">Daniel G&#xf3;mez</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+J">Javier Castro</a>, 
<a href="/search/cs?searchtype=author&query=Guti%C3%A9rrez%2C+I">Inmaculada Guti&#xe9;rrez</a>, 
<a href="/search/cs?searchtype=author&query=Esp%C3%ADnola%2C+R">Rosa Esp&#xed;nola</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Mathematics, 2021, 9, 2666
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Statistics Theory (math.ST)

</div>
<p class="mathjax">In this paper we formally define the hierarchical clustering network problem
(HCNP) as the problem to find a good hierarchical partition of a network. This
new problem focuses on the dynamic process of the clustering rather than on the
final picture of the clustering process. To address it, we introduce a new
ierarchical clustering algorithm in networks, based on a new shortest path
betweenness measure. To calculate it, the communication between each pair of
nodes is weighed by he importance of the nodes that establish this
communication. The weights or importance associated to each pair of nodes are
calculated as the Shapley value of a game, named as the linear modularity game.
This new measure, (the node-game shortest path betweenness measure), is used to
obtain a hierarchical partition of the network by eliminating the link with the
highest value. To evaluate the performance of our algorithm, we introduce
several criteria that allow us to compare different dendrograms of a network
from two point of view: modularity and homogeneity. Finally, we propose a
faster algorithm based on a simplification of the node-game shortest path
betweenness measure, whose order is quadratic on sparse networks. This fast
version is competitive from a computational point of view with other
hierarchical fast algorithms, and, in general, it provides better results.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06377" title="Abstract">arXiv:2402.06377</a> [<a href="/pdf/2402.06377" title="Download PDF">pdf</a>, <a href="/format/2402.06377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Precision Geosteering via Reinforcement Learning and Particle  Filters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muhammad%2C+R+B">Ressi Bonti Muhammad</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+A">Apoorv Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Alyaev%2C+S">Sergey Alyaev</a>, 
<a href="/search/cs?searchtype=author&query=Bratvold%2C+R+B">Reidar Brumer Bratvold</a>, 
<a href="/search/cs?searchtype=author&query=Tartakovsky%2C+D+M">Daniel M. Tartakovsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Geophysics (physics.geo-ph)

</div>
<p class="mathjax">Geosteering, a key component of drilling operations, traditionally involves
manual interpretation of various data sources such as well-log data. This
introduces subjective biases and inconsistent procedures. Academic attempts to
solve geosteering decision optimization with greedy optimization and
Approximate Dynamic Programming (ADP) showed promise but lacked adaptivity to
realistic diverse scenarios. Reinforcement learning (RL) offers a solution to
these challenges, facilitating optimal decision-making through reward-based
iterative learning. State estimation methods, e.g., particle filter (PF),
provide a complementary strategy for geosteering decision-making based on
online information. We integrate an RL-based geosteering with PF to address
realistic geosteering scenarios. Our framework deploys PF to process real-time
well-log data to estimate the location of the well relative to the
stratigraphic layers, which then informs the RL-based decision-making process.
We compare our method's performance with that of using solely either RL or PF.
Our findings indicate a synergy between RL and PF in yielding optimized
geosteering decisions.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06378" title="Abstract">arXiv:2402.06378</a> [<a href="/pdf/2402.06378" title="Download PDF">pdf</a>, <a href="/format/2402.06378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FD-Vision Mamba for Endoscopic Exposure Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhuoran Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2402.04139">arXiv:2402.04139</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In endoscopic imaging, the recorded images are prone to exposure
abnormalities, so maintaining high-quality images is important to assist
healthcare professionals in performing decision-making. To overcome this issue,
We design a frequency-domain based network, called FD-Vision Mamba (FDVM-Net),
which achieves high-quality image exposure correction by reconstructing the
frequency domain of endoscopic images. Specifically, inspired by the State
Space Sequence Models (SSMs), we develop a C-SSM block that integrates the
local feature extraction ability of the convolutional layer with the ability of
the SSM to capture long-range dependencies. A two-path network is built using
C-SSM as the basic function cell, and these two paths deal with the phase and
amplitude information of the image, respectively. Finally, a degraded
endoscopic image is reconstructed by FDVM-Net to obtain a high-quality clear
image. Extensive experimental results demonstrate that our method achieves
state-of-the-art results in terms of speed and accuracy, and it is noteworthy
that our method can enhance endoscopic images of arbitrary resolution. The URL
of the code is \url{https://github.com/zzr-idam/FDVM-Net}.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06379" title="Abstract">arXiv:2402.06379</a> [<a href="/pdf/2402.06379" title="Download PDF">pdf</a>, <a href="/format/2402.06379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning using privileged information for segmenting tumors on digital  mammograms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tzortzis%2C+I+N">Ioannis N. Tzortzis</a>, 
<a href="/search/cs?searchtype=author&query=Makantasis%2C+K">Konstantinos Makantasis</a>, 
<a href="/search/cs?searchtype=author&query=Rallis%2C+I">Ioannis Rallis</a>, 
<a href="/search/cs?searchtype=author&query=Bakalos%2C+N">Nikolaos Bakalos</a>, 
<a href="/search/cs?searchtype=author&query=Doulamis%2C+A">Anastasios Doulamis</a>, 
<a href="/search/cs?searchtype=author&query=Doulamis%2C+N">Nikolaos Doulamis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Limited amount of data and data sharing restrictions, due to GDPR compliance,
constitute two common factors leading to reduced availability and accessibility
when referring to medical data. To tackle these issues, we introduce the
technique of Learning Using Privileged Information. Aiming to substantiate the
idea, we attempt to build a robust model that improves the segmentation quality
of tumors on digital mammograms, by gaining privileged information knowledge
during the training procedure. Towards this direction, a baseline model, called
student, is trained on patches extracted from the original mammograms, while an
auxiliary model with the same architecture, called teacher, is trained on the
corresponding enhanced patches accessing, in this way, privileged information.
We repeat the student training procedure by providing the assistance of the
teacher model this time. According to the experimental results, it seems that
the proposed methodology performs better in the most of the cases and it can
achieve 10% higher F1 score in comparison with the baseline.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06380" title="Abstract">arXiv:2402.06380</a> [<a href="/pdf/2402.06380" title="Download PDF">pdf</a>, <a href="/format/2402.06380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal estimation of Gaussian (poly)trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Ming Gao</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+W+M">Wai Ming Tai</a>, 
<a href="/search/cs?searchtype=author&query=Aragam%2C+B">Bryon Aragam</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharyya%2C+A">Arnab Bhattacharyya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We develop optimal algorithms for learning undirected Gaussian trees and
directed Gaussian polytrees from data. We consider both problems of
distribution learning (i.e. in KL distance) and structure learning (i.e. exact
recovery). The first approach is based on the Chow-Liu algorithm, and learns an
optimal tree-structured distribution efficiently. The second approach is a
modification of the PC algorithm for polytrees that uses partial correlation as
a conditional independence tester for constraint-based structure learning. We
derive explicit finite-sample guarantees for both approaches, and show that
both approaches are optimal by deriving matching lower bounds. Additionally, we
conduct numerical experiments to compare the performance of various algorithms,
providing further insights and empirical evidence.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06384" title="Abstract">arXiv:2402.06384</a> [<a href="/pdf/2402.06384" title="Download PDF">pdf</a>, <a href="/format/2402.06384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> pSTL-Bench: A Micro-Benchmark Suite for Assessing Scalability of C++  Parallel STL Implementations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laso%2C+R">Ruben Laso</a>, 
<a href="/search/cs?searchtype=author&query=Krupitza%2C+D">Diego Krupitza</a>, 
<a href="/search/cs?searchtype=author&query=Hunold%2C+S">Sascha Hunold</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 24 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF); Programming Languages (cs.PL)

</div>
<p class="mathjax">Since the advent of parallel algorithms in the C++17 Standard Template
Library (STL), the STL has become a viable framework for creating
performance-portable applications. Given multiple existing implementations of
the parallel algorithms, a systematic, quantitative performance comparison is
essential for choosing the appropriate implementation for a particular hardware
configuration.
<br />In this work, we introduce a specialized set of micro-benchmarks to assess
the scalability of the parallel algorithms in the STL. By selecting different
backends, our micro-benchmarks can be used on multi-core systems and GPUs.
<br />Using the suite, in a case study on AMD and Intel CPUs and NVIDIA GPUs, we
were able to identify substantial performance disparities among different
implementations, including GCC+TBB, GCC+HPX, Intel's compiler with TBB, or
NVIDIA's compiler with OpenMP and CUDA.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06385" title="Abstract">arXiv:2402.06385</a> [<a href="/pdf/2402.06385" title="Download PDF">pdf</a>, <a href="/format/2402.06385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maia: A Real-time Non-Verbal Chat for Human-AI Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Costea%2C+D">Dragos Costea</a>, 
<a href="/search/cs?searchtype=author&query=Marcu%2C+A">Alina Marcu</a>, 
<a href="/search/cs?searchtype=author&query=Lazar%2C+C">Cristina Lazar</a>, 
<a href="/search/cs?searchtype=author&query=Leordeanu%2C+M">Marius Leordeanu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Face-to-face communication modeling in computer vision is an area of research
focusing on developing algorithms that can recognize and analyze non-verbal
cues and behaviors during face-to-face interactions. We propose an alternative
to text chats for Human-AI interaction, based on non-verbal visual
communication only, using facial expressions and head movements that mirror,
but also improvise over the human user, to efficiently engage with the users,
and capture their attention in a low-cost and real-time fashion. Our goal is to
track and analyze facial expressions, and other non-verbal cues in real-time,
and use this information to build models that can predict and understand human
behavior. We offer three different complementary approaches, based on
retrieval, statistical, and deep learning techniques. We provide human as well
as automatic evaluations and discuss the advantages and disadvantages of each
direction.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06389" title="Abstract">arXiv:2402.06389</a> [<a href="/pdf/2402.06389" title="Download PDF">pdf</a>, <a href="/format/2402.06389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Aesthetic Preference-Based Large Text-to-Image Model  Personalization: Kandinsky Generation as an Example
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Aven-Le Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Ao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC); Multimedia (cs.MM)

</div>
<p class="mathjax">With the advancement of neural generative capabilities, the art community has
actively embraced GenAI (generative artificial intelligence) for creating
painterly content. Large text-to-image models can quickly generate
aesthetically pleasing outcomes. However, the process can be non-deterministic
and often involves tedious trial-and-error, as users struggle with formulating
effective prompts to achieve their desired results. This paper introduces a
prompting-free generative approach that empowers users to automatically
generate personalized painterly content that incorporates their aesthetic
preferences in a customized artistic style. This approach involves utilizing
``semantic injection'' to customize an artist model in a specific artistic
style, and further leveraging a genetic algorithm to optimize the prompt
generation process through real-time iterative human feedback. By solely
relying on the user's aesthetic evaluation and preference for the artist
model-generated images, this approach creates the user a personalized model
that encompasses their aesthetic preferences and the customized artistic style.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06390" title="Abstract">arXiv:2402.06390</a> [<a href="/pdf/2402.06390" title="Download PDF">pdf</a>, <a href="/format/2402.06390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ImplicitDeepfake: Plausible Face-Swapping through Implicit Deepfake  Generation using NeRF and Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stanishevskii%2C+G">Georgii Stanishevskii</a>, 
<a href="/search/cs?searchtype=author&query=Steczkiewicz%2C+J">Jakub Steczkiewicz</a>, 
<a href="/search/cs?searchtype=author&query=Szczepanik%2C+T">Tomasz Szczepanik</a>, 
<a href="/search/cs?searchtype=author&query=Tadeja%2C+S">S&#x142;awomir Tadeja</a>, 
<a href="/search/cs?searchtype=author&query=Tabor%2C+J">Jacek Tabor</a>, 
<a href="/search/cs?searchtype=author&query=Spurek%2C+P">Przemys&#x142;aw Spurek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Numerous emerging deep-learning techniques have had a substantial impact on
computer graphics. Among the most promising breakthroughs are the recent rise
of Neural Radiance Fields (NeRFs) and Gaussian Splatting (GS). NeRFs encode the
object's shape and color in neural network weights using a handful of images
with known camera positions to generate novel views. In contrast, GS provides
accelerated training and inference without a decrease in rendering quality by
encoding the object's characteristics in a collection of Gaussian
distributions. These two techniques have found many use cases in spatial
computing and other domains. On the other hand, the emergence of deepfake
methods has sparked considerable controversy. Such techniques can have a form
of artificial intelligence-generated videos that closely mimic authentic
footage. Using generative models, they can modify facial features, enabling the
creation of altered identities or facial expressions that exhibit a remarkably
realistic appearance to a real person. Despite these controversies, deepfake
can offer a next-generation solution for avatar creation and gaming when of
desirable quality. To that end, we show how to combine all these emerging
technologies to obtain a more plausible outcome. Our ImplicitDeepfake1 uses the
classical deepfake algorithm to modify all training images separately and then
train NeRF and GS on modified faces. Such relatively simple strategies can
produce plausible 3D deepfake-based avatars.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06397" title="Abstract">arXiv:2402.06397</a> [<a href="/pdf/2402.06397" title="Download PDF">pdf</a>, <a href="/format/2402.06397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding hardness reductions automatically using SAT solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bergold%2C+H">Helena Bergold</a>, 
<a href="/search/cs?searchtype=author&query=Scheucher%2C+M">Manfred Scheucher</a>, 
<a href="/search/cs?searchtype=author&query=Schr%C3%B6der%2C+F">Felix Schr&#xf6;der</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS); Logic in Computer Science (cs.LO); Combinatorics (math.CO)

</div>
<p class="mathjax">In this article, we show that the completion problem, i.e. the decision
problem whether a partial structure can be completed to a full structure, is
NP-complete for many combinatorial structures. While the gadgets for most
reductions in literature are found by hand, we present an algorithm to
construct gadgets in a fully automated way. Using our framework which is based
on SAT, we present the first thorough study of the completion problem on sign
mappings with forbidden substructures by classifying thousands of structures
for which the completion problem is NP-complete. Our list in particular
includes interior triple systems, which were introduced by Knuth towards an
axiomatization of planar point configurations. Last but not least, we give an
infinite family of structures generalizing interior triple system to higher
dimensions for which the completion problem is NP-complete.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06402" title="Abstract">arXiv:2402.06402</a> [<a href="/pdf/2402.06402" title="Download PDF">pdf</a>, <a href="/format/2402.06402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Transformers are Efficient Meta-Reinforcement Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shala%2C+G">Gresa Shala</a>, 
<a href="/search/cs?searchtype=author&query=Biedenkapp%2C+A">Andr&#xe9; Biedenkapp</a>, 
<a href="/search/cs?searchtype=author&query=Grabocka%2C+J">Josif Grabocka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We introduce Hierarchical Transformers for Meta-Reinforcement Learning
(HTrMRL), a powerful online meta-reinforcement learning approach. HTrMRL aims
to address the challenge of enabling reinforcement learning agents to perform
effectively in previously unseen tasks. We demonstrate how past episodes serve
as a rich source of information, which our model effectively distills and
applies to new contexts. Our learned algorithm is capable of outperforming the
previous state-of-the-art and provides more efficient meta-training while
significantly improving generalization capabilities. Experimental results,
obtained across various simulated tasks of the Meta-World Benchmark, indicate a
significant improvement in learning efficiency and adaptability compared to the
state-of-the-art on a variety of tasks. Our approach not only enhances the
agent's ability to generalize from limited data but also paves the way for more
robust and versatile AI systems.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06407" title="Abstract">arXiv:2402.06407</a> [<a href="/pdf/2402.06407" title="Download PDF">pdf</a>, <a href="/ps/2402.06407" title="Download PostScript">ps</a>, <a href="/format/2402.06407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quick-Sort Style Approximation Algorithms for Generalizations of  Feedback Vertex Set in Tournaments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Sushmita Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Modak%2C+S">Sounak Modak</a>, 
<a href="/search/cs?searchtype=author&query=Saurabh%2C+S">Saket Saurabh</a>, 
<a href="/search/cs?searchtype=author&query=Seetharaman%2C+S">Sanjay Seetharaman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Latin American Theoretical Informatics 2024(LATIN 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">A feedback vertex set (FVS) in a digraph is a subset of vertices whose
removal makes the digraph acyclic. In other words, it hits all cycles in the
digraph. Lokshtanov et al. [TALG '21] gave a factor 2 randomized approximation
algorithm for finding a minimum weight FVS in tournaments. We generalize the
result by presenting a factor $2\alpha$ randomized approximation algorithm for
finding a minimum weight FVS in digraphs of independence number $\alpha$; a
generalization of tournaments which are digraphs with independence number $1$.
Using the same framework, we present a factor $2$ randomized approximation
algorithm for finding a minimum weight Subset FVS in tournaments: given a
vertex subset $S$ in addition to the graph, find a subset of vertices that hits
all cycles containing at least one vertex in $S$. Note that FVS in tournaments
is a special case of Subset FVS in tournaments in which $S = V(T)$.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06411" title="Abstract">arXiv:2402.06411</a> [<a href="/pdf/2402.06411" title="Download PDF">pdf</a>, <a href="/ps/2402.06411" title="Download PostScript">ps</a>, <a href="/format/2402.06411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting spatial diversity for increasing the robustness of sound  source localization systems against reverberation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garcia-Barrios%2C+G">Guillermo Garcia-Barrios</a>, 
<a href="/search/cs?searchtype=author&query=Iglesias%2C+E+L">Eduardo Latorre Iglesias</a>, 
<a href="/search/cs?searchtype=author&query=Gutierrez-Arriola%2C+J+M">Juana M. Gutierrez-Arriola</a>, 
<a href="/search/cs?searchtype=author&query=Fraile%2C+R">Ruben Fraile</a>, 
<a href="/search/cs?searchtype=author&query=Saenz-Lechon%2C+N">Nicolas Saenz-Lechon</a>, 
<a href="/search/cs?searchtype=author&query=Osma-Ruiz%2C+V+J">Victor Jose Osma-Ruiz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)

</div>
<p class="mathjax">Acoustic reverberation is one of the most relevant factors that hampers the
localization of a sound source inside a room. To date, several approaches have
been proposed to deal with it, but have not always been evaluated under
realistic conditions. This paper proposes exploiting spatial diversity as an
alternative approach to achieve robustness against reverberation. The
theoretical arguments supporting this approach are first presented and later
confirmed by means of simulation results and real measurements. Simulations are
run for reverberation times up to 2 s, thus providing results with a wider
range of validity than in other previous research works. It is concluded that
the use of systems consisting of several, sufficiently separated, small arrays
leads to the best results in reverberant environments. Some recommendations are
given regarding the choice of the array sizes, the separation among them, and
the way to combine SRP-PHAT maps obtained from diverse arrays.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06414" title="Abstract">arXiv:2402.06414</a> [<a href="/pdf/2402.06414" title="Download PDF">pdf</a>, <a href="/ps/2402.06414" title="Download PostScript">ps</a>, <a href="/format/2402.06414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trust the Process: Zero-Knowledge Machine Learning to Enhance Trust in  Generative AI Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ganescu%2C+B">Bianca-Mihaela Ganescu</a>, 
<a href="/search/cs?searchtype=author&query=Passerat-Palmbach%2C+J">Jonathan Passerat-Palmbach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at PPAI-24: The 5th AAAI Workshop on Privacy-Preserving Artificial Intelligence 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Generative AI, exemplified by models like transformers, has opened up new
possibilities in various domains but also raised concerns about fairness,
transparency and reliability, especially in fields like medicine and law. This
paper emphasizes the urgency of ensuring fairness and quality in these domains
through generative AI. It explores using cryptographic techniques, particularly
Zero-Knowledge Proofs (ZKPs), to address concerns regarding performance
fairness and accuracy while protecting model privacy. Applying ZKPs to Machine
Learning models, known as ZKML (Zero-Knowledge Machine Learning), enables
independent validation of AI-generated content without revealing sensitive
model information, promoting transparency and trust. ZKML enhances AI fairness
by providing cryptographic audit trails for model predictions and ensuring
uniform performance across users. We introduce snarkGPT, a practical ZKML
implementation for transformers, to empower users to verify output accuracy and
quality while preserving model privacy. We present a series of empirical
results studying snarkGPT's scalability and performance to assess the
feasibility and challenges of adopting a ZKML-powered approach to capture
quality and performance fairness problems in generative AI models.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06420" title="Abstract">arXiv:2402.06420</a> [<a href="/pdf/2402.06420" title="Download PDF">pdf</a>, <a href="/format/2402.06420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Findings of the First Workshop on Simulating Conversational Intelligence  in Chat
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Graham%2C+Y">Yvette Graham</a>, 
<a href="/search/cs?searchtype=author&query=Qureshi%2C+M+R">Mohammed Rameez Qureshi</a>, 
<a href="/search/cs?searchtype=author&query=Khalid%2C+H">Haider Khalid</a>, 
<a href="/search/cs?searchtype=author&query=Lampouras%2C+G">Gerasimos Lampouras</a>, 
<a href="/search/cs?searchtype=author&query=Iacobacci%2C+I">Ignacio Iacobacci</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qun Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The aim of this workshop is to bring together experts working on open-domain
dialogue research. In this speedily advancing research area many challenges
still exist, such as learning information from conversations, engaging in
realistic and convincing simulation of human intelligence and reasoning.
SCI-CHAT follows previous workshops on open domain dialogue but with a focus on
the simulation of intelligent conversation as judged in a live human
evaluation. Models aim to include the ability to follow a challenging topic
over a multi-turn conversation, while positing, refuting and reasoning over
arguments. The workshop included both a research track and shared task. The
main goal of this paper is to provide an overview of the shared task and a link
to an additional paper that will include an in depth analysis of the shared
task results following presentation at the workshop.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06421" title="Abstract">arXiv:2402.06421</a> [<a href="/pdf/2402.06421" title="Download PDF">pdf</a>, <a href="/ps/2402.06421" title="Download PostScript">ps</a>, <a href="/format/2402.06421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What&#x27;s in People&#x27;s Digital File Collections?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dinneen%2C+J+D">Jesse David Dinneen</a>, 
<a href="/search/cs?searchtype=author&query=Julien%2C+C">Charles-Antoine Julien</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 82nd Annual Meeting of the Association for
  Information Science &amp; Technology, 56(1), 68-77 (2019)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Thoughtfully designing services and rigorously testing software to support
personal information management (PIM) requires understanding the relevant
collections, but relatively little is known about what people keep in their
file collections, especially personal collections. Complementing recent work on
the structure of 348 file collections, we examine those collections' contents,
how much content is duplicated, and how collections used for personal matters
differ from those used for study and work. Though all collections contain many
images, some intuitively common file types are surprisingly scarce. Personal
collections contain more audio than others, knowledge workers' collections
contain more text documents but far fewer folders, and IT collections exhibit
unusual traits. Collection duplication is correlated to collections' structural
traits, but surprisingly, not to collection age. We discuss our findings in
light of prior works and provide implications for various kinds of information
research.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06423" title="Abstract">arXiv:2402.06423</a> [<a href="/pdf/2402.06423" title="Download PDF">pdf</a>, <a href="/format/2402.06423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CurveFormer++: 3D Lane Detection by Curve Propagation with Temporal  Curve Queries and Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yifeng Bai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhirong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Pengpeng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+E">Erkang Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2209.07989">arXiv:2209.07989</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In autonomous driving, 3D lane detection using monocular cameras is an
important task for various downstream planning and control tasks. Recent CNN
and Transformer approaches usually apply a two-stage scheme in the model
design. The first stage transforms the image feature from a front image into a
bird's-eye-view (BEV) representation. Subsequently, a sub-network processes the
BEV feature map to generate the 3D detection results. However, these approaches
heavily rely on a challenging image feature transformation module from a
perspective view to a BEV representation. In our work, we present
CurveFormer++, a single-stage Transformer-based method that does not require
the image feature view transform module and directly infers 3D lane detection
results from the perspective image features. Specifically, our approach models
the 3D detection task as a curve propagation problem, where each lane is
represented by a curve query with a dynamic and ordered anchor point set. By
employing a Transformer decoder, the model can iteratively refine the 3D lane
detection results. A curve cross-attention module is introduced in the
Transformer decoder to calculate similarities between image features and curve
queries of lanes. To handle varying lane lengths, we employ context sampling
and anchor point restriction techniques to compute more relevant image features
for a curve query. Furthermore, we apply a temporal fusion module that
incorporates selected informative sparse curve queries and their corresponding
anchor point sets to leverage historical lane information. In the experiments,
we evaluate our approach for the 3D lane detection task on two publicly
available real-world datasets. The results demonstrate that our method provides
outstanding performance compared with both CNN and Transformer based methods.
We also conduct ablation studies to analyze the impact of each component in our
approach.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06424" title="Abstract">arXiv:2402.06424</a> [<a href="/pdf/2402.06424" title="Download PDF">pdf</a>, <a href="/ps/2402.06424" title="Download PostScript">ps</a>, <a href="/format/2402.06424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing Latency for Multimedia Broadcast Services Over Mobile Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lentisco%2C+C+M">C. M. Lentisco</a>, 
<a href="/search/cs?searchtype=author&query=Bellido%2C+L">L. Bellido</a>, 
<a href="/search/cs?searchtype=author&query=C%C3%A1rdenas%2C+A">A. C&#xe1;rdenas</a>, 
<a href="/search/cs?searchtype=author&query=Moyano%2C+R+F">R. F. Moyano</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez%2C+D">D. Fern&#xe1;ndez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Multimedia, vol. 19, no. 1, pp. 173-182, Jan.
  2017
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">Multimedia services over mobile networks pose several challenges, such as the
efficient management of radio resources or the latency induced by network
delays and buffering requirements on the multimedia players. In Long Term
Evolution (LTE) networks, the definition of multimedia broadcast services over
a common radio channel addresses the shortage of radio resources but introduces
the problem of network error recovery. In order to address network errors on
LTE multimedia broadcast services, the current standards propose the combined
use of forward error correction and unicast recovery techniques at the
application level. This paper shows how to efficiently synchronize the
broadcasting server and the multimedia players and how to reduce service
latency by limiting the multimedia player buffer length. This is accomplished
by analyzing the relation between the different parameters of the LTE
multimedia broadcast service, the multimedia player buffer length, and service
interruptions. A case study is simulated to confirm how the quality of the
multimedia service is improved by applying our proposals.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06425" title="Abstract">arXiv:2402.06425</a> [<a href="/pdf/2402.06425" title="Download PDF">pdf</a>, <a href="/format/2402.06425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure-Preserving Discretization and Model Order Reduction of  Boundary-Controlled 1D Port-Hamiltonian Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Toledo-Zucco%2C+J">Jesus-Pablo Toledo-Zucco</a>, 
<a href="/search/math?searchtype=author&query=Matignon%2C+D">Denis Matignon</a>, 
<a href="/search/math?searchtype=author&query=Poussot-Vassal%2C+C">Charles Poussot-Vassal</a>, 
<a href="/search/math?searchtype=author&query=Gorrec%2C+Y+L">Yann Le Gorrec</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper presents a methodology for the discretization and reduction of a
class of one-dimensional Partial Differential Equations (PDEs) with inputs and
outputs collocated at the spatial boundaries. The class of system that we
consider is known as Boundary-Controlled Port-Hamiltonian Systems (BC-PHSs) and
covers a wide class of Hyperbolic PDEs with a large type of boundary inputs and
outputs. This is for instance the case of waves and beams with Neumann or
Dirichlet boundary conditions at both sides and mixed boundary conditions. In
addition, we recall the Loewner framework to reduce the discretized model. We
show that if the initial PDE is {\it passive}, the discretized model is also.
Moreover, if the initial PDE is {\it impedance energy preserving}, the
discretized model is also. The {\it passive} structure is also preserved in the
reduced-order if the selected frequency data has positive real part. We use the
one-dimensional wave equation and the Timoshenko beam as examples to show the
versatility of the proposed approach.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06429" title="Abstract">arXiv:2402.06429</a> [<a href="/pdf/2402.06429" title="Download PDF">pdf</a>, <a href="/format/2402.06429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact a posteriori error control for variational problems via convex  duality and explicit flux reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bartels%2C+S">S&#xf6;ren Bartels</a>, 
<a href="/search/math?searchtype=author&query=Kaltenbach%2C+A">Alex Kaltenbach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in Advances in Applied Mechanics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">A posteriori error estimates are an important tool to bound discretization
errors in terms of computable quantities avoiding regularity conditions that
are often difficult to establish. For non-linear and non-differentiable
problems, problems involving jumping coefficients, and finite element methods
using anisotropic triangulations, such estimates often involve large factors,
leading to sub-optimal error estimates. By making use of convex duality
arguments, exact and explicit error representations are derived that avoid such
effects.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06430" title="Abstract">arXiv:2402.06430</a> [<a href="/pdf/2402.06430" title="Download PDF">pdf</a>, <a href="/format/2402.06430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polyarc bounded complex interval arithmetic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ger%C3%A9b%2C+G">G&#xe1;bor Ger&#xe9;b</a>, 
<a href="/search/math?searchtype=author&query=S%C3%A1ndor%2C+A">Andr&#xe1;s S&#xe1;ndor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages (plus 48 pages of supplemetary material), 8 figures (plus 21 supplementary)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Algebraic Geometry (math.AG)

</div>
<p class="mathjax">Complex interval arithmetic is a powerful tool for the analysis of
computational errors. The naturally arising rectangular, polar, and circular
(together called primitive) interval types are not closed under simple
arithmetic operations and their use yields overly relaxed bounds. The later
introduced polygonal type, on the other hand, allows for arbitrarily precise
representaion of the above operations for a higher computational cost. We
propose the polyarcular interval type as an effective extension of the previous
types. The polyarcular interval can represent all primitive intervals and most
of their arithmetic combinations precisely and has a approximation capability
competing with that of the polygonal interval. In particular, in antenna
tolerance analysis it can achieve perfect accuracy for lower computational cost
then the polygonal type, which we show in a relevant case study. In this paper,
we present a rigorous analysis of the arithmetic properties of all five
interval types, involving a new algebro-geometric method of boundary analysis.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06434" title="Abstract">arXiv:2402.06434</a> [<a href="/pdf/2402.06434" title="Download PDF">pdf</a>, <a href="/format/2402.06434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Where is the Truth? The Risk of Getting Confounded in a Continual World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Busch%2C+F+P">Florian Peter Busch</a>, 
<a href="/search/cs?searchtype=author&query=Kamath%2C+R">Roshni Kamath</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+R">Rupert Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Stammer%2C+W">Wolfgang Stammer</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>, 
<a href="/search/cs?searchtype=author&query=Mundt%2C+M">Martin Mundt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">A dataset is confounded if it is most easily solved via a spurious
correlation which fails to generalize to new data. We will show that, in a
continual learning setting where confounders may vary in time across tasks, the
resulting challenge far exceeds the standard forgetting problem normally
considered. In particular, we derive mathematically the effect of such
confounders on the space of valid joint solutions to sets of confounded tasks.
Interestingly, our theory predicts that for many such continual datasets,
spurious correlations are easily ignored when the tasks are trained on jointly,
but it is far harder to avoid confounding when they are considered
sequentially. We construct such a dataset and demonstrate empirically that
standard continual learning methods fail to ignore confounders, while training
jointly on all tasks is successful. Our continually confounded dataset, ConCon,
is based on CLEVR images and demonstrates the need for continual learning
methods with more robust behavior with respect to confounding.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06436" title="Abstract">arXiv:2402.06436</a> [<a href="/pdf/2402.06436" title="Download PDF">pdf</a>, <a href="/format/2402.06436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving 2D-3D Dense Correspondences with Diffusion Models for 6D  Object Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=H%C3%B6nig%2C+P">Peter H&#xf6;nig</a>, 
<a href="/search/cs?searchtype=author&query=Thalhammer%2C+S">Stefan Thalhammer</a>, 
<a href="/search/cs?searchtype=author&query=Vincze%2C+M">Markus Vincze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the First Austrian Symposium on AI, Robotics, and Vision 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Estimating 2D-3D correspondences between RGB images and 3D space is a
fundamental problem in 6D object pose estimation. Recent pose estimators use
dense correspondence maps and Point-to-Point algorithms to estimate object
poses. The accuracy of pose estimation depends heavily on the quality of the
dense correspondence maps and their ability to withstand occlusion, clutter,
and challenging material properties. Currently, dense correspondence maps are
estimated using image-to-image translation models based on GANs, Autoencoders,
or direct regression models. However, recent advancements in image-to-image
translation have led to diffusion models being the superior choice when
evaluated on benchmarking datasets. In this study, we compare image-to-image
translation networks based on GANs and diffusion models for the downstream task
of 6D object pose estimation. Our results demonstrate that the diffusion-based
image-to-image translation model outperforms the GAN, revealing potential for
further improvements in 6D object pose estimation models.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06437" title="Abstract">arXiv:2402.06437</a> [<a href="/pdf/2402.06437" title="Download PDF">pdf</a>, <a href="/ps/2402.06437" title="Download PostScript">ps</a>, <a href="/format/2402.06437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design of a 5G Multimedia Broadcast Application Function Supporting  Adaptive Error Recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lentisco%2C+C+M">C. M. Lentisco</a>, 
<a href="/search/cs?searchtype=author&query=Bellido%2C+L">L. Bellido</a>, 
<a href="/search/cs?searchtype=author&query=C%C3%A1rdenas%2C+A">A. C&#xe1;rdenas</a>, 
<a href="/search/cs?searchtype=author&query=Moyano%2C+R+F">R. F. Moyano</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez%2C+D">D. Fern&#xe1;ndez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 10 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in IEEE Transactions on Multimedia, vol. 25, pp. 378-388, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">The demand for mobile multimedia streaming services has been steadily growing
in recent years. Mobile multimedia broadcasting addresses the shortage of radio
resources but introduces a network error recovery problem. Retransmitting
multimedia segments that are not correctly broadcast can cause service
disruptions and increased service latency, affecting the quality of experience
perceived by end users. With the advent of networking paradigms based on
virtualization technologies, mobile networks have been enabled with more
flexibility and agility to deploy innovative services that improve the
utilization of available network resources. This paper discusses how mobile
multimedia broadcast services can be designed to prevent service degradation by
using the computing capabilities provided by multiaccess edge computing (MEC)
platforms in the context of a 5G network architecture. An experimental platform
has been developed to evaluate the feasibility of a MEC application to provide
adaptive error recovery for multimedia broadcast services. The results of the
experiments carried out show that the proposal provides a flexible mechanism
that can be deployed at the network edge to lower the impact of transmission
errors on latency and service disruptions.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06440" title="Abstract">arXiv:2402.06440</a> [<a href="/pdf/2402.06440" title="Download PDF">pdf</a>, <a href="/format/2402.06440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Method for Decrypting Data Infected with Rhysida Ransomware
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+G">Giyoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Soojin Kang</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+S">Seungjun Baek</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kimoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jongsung Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Ransomware is malicious software that is a prominent global cybersecurity
threat. Typically, ransomware encrypts data on a system, rendering the victim
unable to decrypt it without the attacker's private key. Subsequently, victims
often pay a substantial ransom to recover their data, yet some may still incur
damage or loss. This study examines Rhysida ransomware, which caused
significant damage in the second half of 2023, and proposes a decryption
method. Rhysida ransomware employed a secure random number generator to
generate the encryption key and subsequently encrypt the data. However, an
implementation vulnerability existed that enabled us to regenerate the internal
state of the random number generator at the time of infection. We successfully
decrypted the data using the regenerated random number generator. To the best
of our knowledge, this is the first successful decryption of Rhysida
ransomware. We aspire for our work to contribute to mitigating the damage
inflicted by the Rhysida ransomware.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06441" title="Abstract">arXiv:2402.06441</a> [<a href="/pdf/2402.06441" title="Download PDF">pdf</a>, <a href="/format/2402.06441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incorporating Taylor Series and Recursive Structure in Neural Networks  for Time Series Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mau%2C+J">Jarrod Mau</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+K">Kevin Moon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Time series analysis is relevant in various disciplines such as physics,
biology, chemistry, and finance. In this paper, we present a novel neural
network architecture that integrates elements from ResNet structures, while
introducing the innovative incorporation of the Taylor series framework. This
approach demonstrates notable enhancements in test accuracy across many of the
baseline datasets investigated. Furthermore, we extend our method to
incorporate a recursive step, which leads to even further improvements in test
accuracy. Our findings underscore the potential of our proposed model to
significantly advance time series analysis methodologies, offering promising
avenues for future research and application.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06443" title="Abstract">arXiv:2402.06443</a> [<a href="/pdf/2402.06443" title="Download PDF">pdf</a>, <a href="/format/2402.06443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explaining Veracity Predictions with Evidence Summarization: A  Multi-Task Model Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cekinel%2C+R+F">Recep Firat Cekinel</a>, 
<a href="/search/cs?searchtype=author&query=Karagoz%2C+P">Pinar Karagoz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The rapid dissemination of misinformation through social media increased the
importance of automated fact-checking. Furthermore, studies on what deep neural
models pay attention to when making predictions have increased in recent years.
While significant progress has been made in this field, it has not yet reached
a level of reasoning comparable to human reasoning. To address these gaps, we
propose a multi-task explainable neural model for misinformation detection.
Specifically, this work formulates an explanation generation process of the
model's veracity prediction as a text summarization problem. Additionally, the
performance of the proposed model is discussed on publicly available datasets
and the findings are evaluated with related studies.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06445" title="Abstract">arXiv:2402.06445</a> [<a href="/pdf/2402.06445" title="Download PDF">pdf</a>, <a href="/format/2402.06445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Deep Equilibrium Algorithmic Reasoner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Georgiev%2C+D">Dobrik Georgiev</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Buffelli%2C+D">Davide Buffelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Recent work on neural algorithmic reasoning has demonstrated that graph
neural networks (GNNs) could learn to execute classical algorithms. Doing so,
however, has always used a recurrent architecture, where each iteration of the
GNN aligns with an algorithm's iteration. Since an algorithm's solution is
often an equilibrium, we conjecture and empirically validate that one can train
a network to solve algorithmic problems by directly finding the equilibrium.
Note that this does not require matching each GNN iteration with a step of the
algorithm.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06446" title="Abstract">arXiv:2402.06446</a> [<a href="/pdf/2402.06446" title="Download PDF">pdf</a>, <a href="/format/2402.06446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ControlUDA: Controllable Diffusion-assisted Unsupervised Domain  Adaptation for Cross-Weather Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+F">Fengyi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Li Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Kucukaytekin%2C+K">Kagan Kucukaytekin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">He Wang</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+A">Alois Knoll</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Data generation is recognized as a potent strategy for unsupervised domain
adaptation (UDA) pertaining semantic segmentation in adverse weathers.
Nevertheless, these adverse weather scenarios encompass multiple possibilities,
and high-fidelity data synthesis with controllable weather is under-researched
in previous UDA works. The recent strides in large-scale text-to-image
diffusion models (DM) have ushered in a novel avenue for research, enabling the
generation of realistic images conditioned on semantic labels. This capability
proves instrumental for cross-domain data synthesis from source to target
domain owing to their shared label space. Thus, source domain labels can be
paired with those generated pseudo target data for training UDA. However, from
the UDA perspective, there exists several challenges for DM training: (i)
ground-truth labels from target domain are missing; (ii) the prompt generator
may produce vague or noisy descriptions of images from adverse weathers; (iii)
existing arts often struggle to well handle the complex scene structure and
geometry of urban scenes when conditioned only on semantic labels. To tackle
the above issues, we propose ControlUDA, a diffusion-assisted framework
tailored for UDA segmentation under adverse weather conditions. It first
leverages target prior from a pre-trained segmentor for tuning the DM,
compensating the missing target domain labels; It also contains UDAControlNet,
a condition-fused multi-scale and prompt-enhanced network targeted at
high-fidelity data generation in adverse weathers. Training UDA with our
generated data brings the model performances to a new milestone (72.0 mIoU) on
the popular Cityscapes-to-ACDC benchmark for adverse weathers. Furthermore,
ControlUDA helps to achieve good model generalizability on unseen data.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06452" title="Abstract">arXiv:2402.06452</a> [<a href="/pdf/2402.06452" title="Download PDF">pdf</a>, <a href="/format/2402.06452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Algorithmic Framework for Constructing Multiple Decision Trees by  Evaluating Their Combination Performance Throughout the Construction Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tajima%2C+K">Keito Tajima</a>, 
<a href="/search/cs?searchtype=author&query=Ichijo%2C+N">Naoki Ichijo</a>, 
<a href="/search/cs?searchtype=author&query=Nakahara%2C+Y">Yuta Nakahara</a>, 
<a href="/search/cs?searchtype=author&query=Matsushima%2C+T">Toshiyasu Matsushima</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Predictions using a combination of decision trees are known to be effective
in machine learning. Typical ideas for constructing a combination of decision
trees for prediction are bagging and boosting. Bagging independently constructs
decision trees without evaluating their combination performance and averages
them afterward. Boosting constructs decision trees sequentially, only
evaluating a combination performance of a new decision tree and the fixed past
decision trees at each step. Therefore, neither method directly constructs nor
evaluates a combination of decision trees for the final prediction. When the
final prediction is based on a combination of decision trees, it is natural to
evaluate the appropriateness of the combination when constructing them. In this
study, we propose a new algorithmic framework that constructs decision trees
simultaneously and evaluates their combination performance throughout the
construction process. Our framework repeats two procedures. In the first
procedure, we construct new candidates of combinations of decision trees to
find a proper combination of decision trees. In the second procedure, we
evaluate each combination performance of decision trees under some criteria and
select a better combination. To confirm the performance of the proposed
framework, we perform experiments on synthetic and benchmark data.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06457" title="Abstract">arXiv:2402.06457</a> [<a href="/pdf/2402.06457" title="Download PDF">pdf</a>, <a href="/format/2402.06457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> V-STaR: Training Verifiers for Self-Taught Reasoners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hosseini%2C+A">Arian Hosseini</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xingdi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Malkin%2C+N">Nikolay Malkin</a>, 
<a href="/search/cs?searchtype=author&query=Courville%2C+A">Aaron Courville</a>, 
<a href="/search/cs?searchtype=author&query=Sordoni%2C+A">Alessandro Sordoni</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+R">Rishabh Agarwal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Common self-improvement approaches for large language models (LLMs), such as
STaR (Zelikman et al., 2022), iteratively fine-tune LLMs on self-generated
solutions to improve their problem-solving ability. However, these approaches
discard the large amounts of incorrect solutions generated during this process,
potentially neglecting valuable information in such solutions. To address this
shortcoming, we propose V-STaR that utilizes both the correct and incorrect
solutions generated during the self-improvement process to train a verifier
using DPO that judges correctness of model-generated solutions. This verifier
is used at inference time to select one solution among many candidate
solutions. Running V-STaR for multiple iterations results in progressively
better reasoners and verifiers, delivering a 4% to 17% test accuracy
improvement over existing self-improvement and verification approaches on
common code generation and math reasoning benchmarks with LLaMA2 models.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06459" title="Abstract">arXiv:2402.06459</a> [<a href="/pdf/2402.06459" title="Download PDF">pdf</a>, <a href="/format/2402.06459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximizing NFT Incentives: References Make You Rich
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Guangsheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Caijun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+L+D">Lam Duc Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Bandara%2C+H+M+N+D">H.M.N. Dilum Bandara</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shiping Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Computational Engineering, Finance, and Science (cs.CE); Cryptography and Security (cs.CR); Computers and Society (cs.CY); General Economics (econ.GN)

</div>
<p class="mathjax">In this paper, we study how to optimize existing Non-Fungible Token (NFT)
incentives. Upon exploring a large number of NFT-related standards and
real-world projects, we come across an unexpected finding. That is, the current
NFT incentive mechanisms, often organized in an isolated and one-time-use
fashion, tend to overlook their potential for scalable organizational
structures.
<br />We propose, analyze, and implement a novel reference incentive model, which
is inherently structured as a Directed Acyclic Graph (DAG)-based NFT network.
This model aims to maximize connections (or references) between NFTs, enabling
each isolated NFT to expand its network and accumulate rewards derived from
subsequent or subscribed ones. We conduct both theoretical and practical
analyses of the model, demonstrating its optimal utility.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06461" title="Abstract">arXiv:2402.06461</a> [<a href="/pdf/2402.06461" title="Download PDF">pdf</a>, <a href="/format/2402.06461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sequential Flow Matching for Generative Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J">Jongmin Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Juho Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 13 figures. Under review by ICML 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
<p class="mathjax">Straightening the probability flow of the continuous-time generative models,
such as diffusion models or flow-based models, is the key to fast sampling
through the numerical solvers, existing methods learn a linear path by directly
generating the probability path the joint distribution between the noise and
data distribution. One key reason for the slow sampling speed of the ODE-based
solvers that simulate these generative models is the global truncation error of
the ODE solver, caused by the high curvature of the ODE trajectory, which
explodes the truncation error of the numerical solvers in the low-NFE regime.
To address this challenge, We propose a novel method called SeqRF, a learning
technique that straightens the probability flow to reduce the global truncation
error and hence enable acceleration of sampling and improve the synthesis
quality. In both theoretical and empirical studies, we first observe the
straightening property of our SeqRF. Through empirical evaluations via SeqRF
over flow-based generative models, We achieve surpassing results on CIFAR-10,
CelebA-$64 \times 64$, and LSUN-Church datasets.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06465" title="Abstract">arXiv:2402.06465</a> [<a href="/pdf/2402.06465" title="Download PDF">pdf</a>, <a href="/ps/2402.06465" title="Download PostScript">ps</a>, <a href="/format/2402.06465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Differentially Private Subspace Estimation Without Distributional  Assumptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsfadia%2C+E">Eliad Tsfadia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Private data analysis faces a significant challenge known as the curse of
dimensionality, leading to increased costs. However, many datasets possess an
inherent low-dimensional structure. For instance, during optimization via
gradient descent, the gradients frequently reside near a low-dimensional
subspace. If the low-dimensional structure could be privately identified using
a small amount of points, we could avoid paying (in terms of privacy and
accuracy) for the high ambient dimension.
<br />On the negative side, Dwork, Talwar, Thakurta, and Zhang (STOC 2014) proved
that privately estimating subspaces, in general, requires an amount of points
that depends on the dimension. But Singhal and Steinke (NeurIPS 2021) bypassed
this limitation by considering points that are i.i.d. samples from a Gaussian
distribution whose covariance matrix has a certain eigenvalue gap. Yet, it was
still left unclear whether we could provide similar upper bounds without
distributional assumptions and whether we could prove lower bounds that depend
on similar eigenvalue gaps.
<br />In this work, we make progress in both directions. We formulate the problem
of private subspace estimation under two different types of singular value gaps
of the input data and prove new upper and lower bounds for both types. In
particular, our results determine what type of gap is sufficient and necessary
for estimating a subspace with an amount of points that is independent of the
dimension.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06470" title="Abstract">arXiv:2402.06470</a> [<a href="/pdf/2402.06470" title="Download PDF">pdf</a>, <a href="/format/2402.06470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Environmental Awareness Dynamic 5G QoS for Retaining Real Time  Constraints in Robotic Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Damigos%2C+G">Gerasimos Damigos</a>, 
<a href="/search/cs?searchtype=author&query=Saradagi%2C+A">Akshit Saradagi</a>, 
<a href="/search/cs?searchtype=author&query=Sandberg%2C+S">Sara Sandberg</a>, 
<a href="/search/cs?searchtype=author&query=Nikolakopoulos%2C+G">George Nikolakopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICRA 2024 -&amp;gt; to be available in conference proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The fifth generation (5G) cellular network technology is mature and
increasingly utilized in many industrial and robotics applications, while an
important functionality is the advanced Quality of Service (QoS) features.
Despite the prevalence of 5G QoS discussions in the related literature, there
is a notable absence of real-life implementations and studies concerning their
application in time-critical robotics scenarios. This article considers the
operation of time-critical applications for 5G-enabled unmanned aerial vehicles
(UAVs) and how their operation can be improved by the possibility to
dynamically switch between QoS data flows with different priorities. As such,
we introduce a robotics oriented analysis on the impact of the 5G QoS
functionality on the performance of 5G-enabled UAVs. Furthermore, we introduce
a novel framework for the dynamic selection of distinct 5G QoS data flows that
is autonomously managed by the 5G-enabled UAV. This problem is addressed in a
novel feedback loop fashion utilizing a probabilistic finite state machine
(PFSM). Finally, the efficacy of the proposed scheme is experimentally
validated with a 5G-enabled UAV in a real-world 5G stand-alone (SA) network.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06471" title="Abstract">arXiv:2402.06471</a> [<a href="/pdf/2402.06471" title="Download PDF">pdf</a>, <a href="/ps/2402.06471" title="Download PostScript">ps</a>, <a href="/format/2402.06471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Population Protocols for Exact Plurality Consensus -- How a small chance  of failure helps to eliminate insignificant opinions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bankhamer%2C+G">Gregor Bankhamer</a>, 
<a href="/search/cs?searchtype=author&query=Berenbrink%2C+P">Petra Berenbrink</a>, 
<a href="/search/cs?searchtype=author&query=Biermeier%2C+F">Felix Biermeier</a>, 
<a href="/search/cs?searchtype=author&query=Els%C3%A4sser%2C+R">Robert Els&#xe4;sser</a>, 
<a href="/search/cs?searchtype=author&query=Hosseinpour%2C+H">Hamed Hosseinpour</a>, 
<a href="/search/cs?searchtype=author&query=Kaaser%2C+D">Dominik Kaaser</a>, 
<a href="/search/cs?searchtype=author&query=Kling%2C+P">Peter Kling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">We consider the \emph{exact plurality consensus} problem for \emph{population
protocols}. Here, $n$ anonymous agents start each with one of $k$ opinions.
Their goal is to agree on the initially most frequent opinion (the
\emph{plurality opinion}) via random, pairwise interactions. The case of $k =
2$ opinions is known as the \emph{majority problem}. Recent breakthroughs led
to an always correct, exact majority population protocol that is both time- and
space-optimal, needing $O(\log n)$ states per agent and, with high probability,
$O(\log n)$ time~[Doty, Eftekhari, Gasieniec, Severson, Stachowiak, and
Uznanski; 2021]. We know that any always correct protocol requires
$\Omega(k^2)$ states, while the currently best protocol needs $O(k^{11})$
states~[Natale and Ramezani; 2019]. For ordered opinions, this can be improved
to $O(k^6)$~[Gasieniec, Hamilton, Martin, Spirakis, and Stachowiak; 2016]. We
design protocols for plurality consensus that beat the quadratic lower bound by
allowing a negligible failure probability. While our protocols might fail, they
identify the plurality opinion with high probability even if the bias is $1$.
Our first protocol achieves this via $k-1$ tournaments in time $O(k \cdot \log
n)$ using $O(k + \log n)$ states. While it assumes an ordering on the opinions,
we remove this restriction in our second protocol, at the cost of a slightly
increased time $O(k \cdot \log n + \log^2 n)$. By efficiently pruning
insignificant opinions, our final protocol reduces the number of tournaments at
the cost of a slightly increased state complexity $O(k \cdot \log\log n + \log
n)$. This improves the time to $O(n / x_{\max} \cdot \log n + \log^2 n)$, where
$x_{\max}$ is the initial size of the plurality. Note that $n/x_{\max}$ is at
most $k$ and can be much smaller (e.g., in case of a large bias or if there are
many small opinions).
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06472" title="Abstract">arXiv:2402.06472</a> [<a href="/pdf/2402.06472" title="Download PDF">pdf</a>, <a href="/format/2402.06472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;When He Feels Cold, He Goes to the Seahorse&quot;-Blending Generative AI  into Multimaterial Storymaking for Family Expressive Arts Therapy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Di Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hanqing Zhou</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+P">Pengcheng An</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to appear at ACM CHI '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Storymaking, as an integrative form of expressive arts therapy, is an
effective means to foster family communication. Yet, the integration of
generative AI as expressive materials in therapeutic storymaking remains
underexplored. And there is a lack of HCI implications on how to support
families and therapists in this context. Addressing this, our study involved
five weeks of storymaking sessions with seven families guided by a professional
therapist. In these sessions, the families used both traditional art-making
materials and image-based generative AI to create and evolve their family
stories. Via the rich empirical data and commentaries from four expert
therapists, we contextualize how families creatively melded AI and traditional
expressive materials to externalize their ideas and feelings. Through the lens
of Expressive Therapies Continuum (ETC), we characterize the therapeutic
implications of AI as expressive materials. Desirable interaction qualities to
support children, parents, and therapists are distilled for future HCI
research.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06473" title="Abstract">arXiv:2402.06473</a> [<a href="/pdf/2402.06473" title="Download PDF">pdf</a>, <a href="/format/2402.06473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conservative polynomial approximations and applications to Fokker-Planck  equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Laidin%2C+T">Tino Laidin</a>, 
<a href="/search/math?searchtype=author&query=Pareschi%2C+L">Lorenzo Pareschi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 14 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We address the problem of constructing approximations based on orthogonal
polynomials that preserve an arbitrary set of moments of a given function
without loosing the spectral convergence property. To this aim, we compute the
constrained polynomial of best approximation for a generic basis of orthogonal
polynomials. The construction is entirely general and allows us to derive
structure preserving numerical methods for partial differential equations that
require the conservation of some moments of the solution, typically
representing relevant physical quantities of the problem. These properties are
essential to capture with high accuracy the long-time behavior of the solution.
We illustrate with the aid of several numerical applications to Fokker-Planck
equations the generality and the performances of the present approach.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06475" title="Abstract">arXiv:2402.06475</a> [<a href="/pdf/2402.06475" title="Download PDF">pdf</a>, <a href="/format/2402.06475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Captioning and Retrieving Remote Sensing  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Silva%2C+J+D">Jo&#xe3;o Daniel Silva</a>, 
<a href="/search/cs?searchtype=author&query=Magalh%C3%A3es%2C+J">Jo&#xe3;o Magalh&#xe3;es</a>, 
<a href="/search/cs?searchtype=author&query=Tuia%2C+D">Devis Tuia</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+B">Bruno Martins</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image captioning and cross-modal retrieval are examples of tasks that involve
the joint analysis of visual and linguistic information. In connection to
remote sensing imagery, these tasks can help non-expert users in extracting
relevant Earth observation information for a variety of applications. Still,
despite some previous efforts, the development and application of vision and
language models to the remote sensing domain have been hindered by the
relatively small size of the available datasets and models used in previous
studies. In this work, we propose RS-CapRet, a Vision and Language method for
remote sensing tasks, in particular image captioning and text-image retrieval.
We specifically propose to use a highly capable large decoder language model
together with image encoders adapted to remote sensing imagery through
contrastive language-image pre-training. To bridge together the image encoder
and language decoder, we propose training simple linear layers with examples
from combining different remote sensing image captioning datasets, keeping the
other parameters frozen. RS-CapRet can then generate descriptions for remote
sensing images and retrieve images from textual descriptions, achieving SOTA or
competitive performance with existing methods. Qualitative results illustrate
that RS-CapRet can effectively leverage the pre-trained large language model to
describe remote sensing images, retrieve them based on different types of
queries, and also show the ability to process interleaved sequences of images
and text in a dialogue manner.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06482" title="Abstract">arXiv:2402.06482</a> [<a href="/pdf/2402.06482" title="Download PDF">pdf</a>, <a href="/format/2402.06482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DASH Adaptation Algorithm Based on Adaptive Forgetting Factor Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aguayo%2C+M">M. Aguayo</a>, 
<a href="/search/cs?searchtype=author&query=Bellido%2C+L">L. Bellido</a>, 
<a href="/search/cs?searchtype=author&query=Lentisco%2C+C+M">C. M. Lentisco</a>, 
<a href="/search/cs?searchtype=author&query=Pastor%2C+E">E. Pastor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Multimedia, vol. 20, no. 5, pp. 1224-1232,
  May 2018
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The wide adoption of multimedia service capable mobile devices, the
availability of better networks with higher bandwidths, and the availability of
platforms offering digital content has led to an increasing popularity of
multimedia streaming services. However, multimedia streaming services can be
subject to different factors that affect the quality perceived by the users,
such as service interruptions or quality oscillations due to changing network
conditions, particularly in mobile networks. Dynamic Adaptive Streaming over
HTTP (DASH), leverages the use of content-distribution networks and the
capabilities of the multimedia devices to allow multimedia players to
dynamically adapt the quality of the media streaming to the available bandwidth
and the device characteristics. While many elements of DASH are standardized,
the algorithms providing the dynamic adaptation of the streaming are not. The
adaptation is often based on the estimation of the throughput or a buffer
control mechanism. In this paper, we present a new throughput estimation
adaptation algorithm based on a statistical method named Adaptive Forgetting
Factor (AFF). Using this method, the adaptation logic is able to react
appropriately to the different conditions of different types of networks. A set
of experiments with different traffic profiles show that the proposed algorithm
improves video quality performance in both wired and wireless environments.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06487" title="Abstract">arXiv:2402.06487</a> [<a href="/pdf/2402.06487" title="Download PDF">pdf</a>, <a href="/format/2402.06487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Le Nozze di Giustizia. Interactions between Artificial Intelligence,  Law, Logic, Language and Computation with some case studies in Traffic  Regulations and Health Care
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joosten%2C+J+J">Joost J. Joosten</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa%2C+M+M">Manuela Montoya Garc&#xed;a</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">An important aim of this paper is to convey some basics of mathematical logic
to the legal community working with Artificial Intelligence. After analysing
what AI is, we decide to delimit ourselves to rule-based AI leaving Neural
Networks and Machine Learning aside. Rule based AI allows for Formal methods
which are described in a rudimentary form. We will then see how mathematical
logic interacts with legal rule-based AI practice. We shall see how
mathematical logic imposes limitations and complications to AI applications. We
classify the limitations and interactions between mathematical logic and legal
AI in three categories: logical, computational and mathematical. The examples
to showcase the interactions will largely come from European traffic
regulations. The paper closes off with some reflections on how and where AI
could be used and on basic mechanisms that shape society.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06491" title="Abstract">arXiv:2402.06491</a> [<a href="/pdf/2402.06491" title="Download PDF">pdf</a>, <a href="/ps/2402.06491" title="Download PostScript">ps</a>, <a href="/format/2402.06491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new parallel solver suited for arbitrary semilinear parabolic partial  differential equations based on generalized random trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Acebron%2C+J+A">Juan A. Acebron</a>, 
<a href="/search/math?searchtype=author&query=Rodriguez-Rozas%2C+A">Angel Rodriguez-Rozas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">A probabilistic representation for initial value semilinear parabolic
problems based on generalized random trees has been derived. Two different
strategies have been proposed, both requiring generating suitable random trees
combined with a Pade approximant for approximating accurately a given divergent
series. Such series are obtained by summing the partial contribution to the
solution coming from trees with arbitrary number of branches. The new
representation greatly expands the class of problems amenable to be solved
probabilistically, and was used successfully to develop a generalized
probabilistic domain decomposition method. Such a method has been shown to be
suited for massively parallel computers, enjoying full scalability and fault
tolerance. Finally, a few numerical examples are given to illustrate the
remarkable performance of the algorithm, comparing the results with those
obtained with a classical method.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06492" title="Abstract">arXiv:2402.06492</a> [<a href="/pdf/2402.06492" title="Download PDF">pdf</a>, <a href="/format/2402.06492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inducing Systematicity in Transformers by Attending to Structurally  Quantized Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yichen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+M">Mohit Bansal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, code: <a href="https://github.com/jiangycTarheel/SQ-Transformer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Transformers generalize to novel compositions of structures and entities
after being trained on a complex dataset, but easily overfit on datasets of
insufficient complexity. We observe that when the training set is sufficiently
complex, the model encodes sentences that have a common syntactic structure
using a systematic attention pattern. Inspired by this observation, we propose
SQ-Transformer (Structurally Quantized) that explicitly encourages
systematicity in the embeddings and attention layers, even with a training set
of low complexity. At the embedding level, we introduce Structure-oriented
Vector Quantization (SoVQ) to cluster word embeddings into several classes of
structurally equivalent entities. At the attention level, we devise the
Systematic Attention Layer (SAL) and an alternative, Systematically Regularized
Layer (SRL) that operate on the quantized word embeddings so that sentences of
the same structure are encoded with invariant or similar attention patterns.
Empirically, we show that SQ-Transformer achieves stronger compositional
generalization than the vanilla Transformer on multiple low-complexity semantic
parsing and machine translation datasets. In our analysis, we show that SoVQ
indeed learns a syntactically clustered embedding space and SAL/SRL induces
generalizable attention patterns, which lead to improved systematicity.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06493" title="Abstract">arXiv:2402.06493</a> [<a href="/pdf/2402.06493" title="Download PDF">pdf</a>, <a href="/format/2402.06493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse-grid Discontinuous Galerkin Methods for the  Vlasov-Poisson-Lenard-Bernstein Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Schnake%2C+S">Stefan Schnake</a>, 
<a href="/search/math?searchtype=author&query=Kendrick%2C+C">Coleman Kendrick</a>, 
<a href="/search/math?searchtype=author&query=Endeve%2C+E">Eirik Endeve</a>, 
<a href="/search/math?searchtype=author&query=Stoyanov%2C+M">Miroslav Stoyanov</a>, 
<a href="/search/math?searchtype=author&query=Hahn%2C+S">Steven Hahn</a>, 
<a href="/search/math?searchtype=author&query=Hauck%2C+C+D">Cory D Hauck</a>, 
<a href="/search/math?searchtype=author&query=Green%2C+D+L">David L Green</a>, 
<a href="/search/math?searchtype=author&query=Snyder%2C+P">Phil Snyder</a>, 
<a href="/search/math?searchtype=author&query=Canik%2C+J">John Canik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Sparse-grid methods have recently gained interest in reducing the
computational cost of solving high-dimensional kinetic equations. In this
paper, we construct adaptive and hybrid sparse-grid methods for the
Vlasov-Poisson-Lenard-Bernstein (VPLB) model. This model has applications to
plasma physics and is simulated in two reduced geometries: a 0x3v space
homogeneous geometry and a 1x3v slab geometry. We use the discontinuous
Galerkin (DG) method as a base discretization due to its high-order accuracy
and ability to preserve important structural properties of partial differential
equations. We utilize a multiwavelet basis expansion to determine the
sparse-grid basis and the adaptive mesh criteria. We analyze the proposed
sparse-grid methods on a suite of three test problems by computing the savings
afforded by sparse-grids in comparison to standard solutions of the DG method.
The results are obtained using the adaptive sparse-grid discretization library
ASGarD.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06494" title="Abstract">arXiv:2402.06494</a> [<a href="/pdf/2402.06494" title="Download PDF">pdf</a>, <a href="/format/2402.06494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-Based Auto-Segmentation of Planning Target Volume for  Total Marrow and Lymph Node Irradiation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brioso%2C+R+C">Ricardo Coimbra Brioso</a>, 
<a href="/search/cs?searchtype=author&query=Dei%2C+D">Damiano Dei</a>, 
<a href="/search/cs?searchtype=author&query=Lambri%2C+N">Nicola Lambri</a>, 
<a href="/search/cs?searchtype=author&query=Loiacono%2C+D">Daniele Loiacono</a>, 
<a href="/search/cs?searchtype=author&query=Mancosu%2C+P">Pietro Mancosu</a>, 
<a href="/search/cs?searchtype=author&query=Scorsetti%2C+M">Marta Scorsetti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2304.02353">arXiv:2304.02353</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In order to optimize the radiotherapy delivery for cancer treatment,
especially when dealing with complex treatments such as Total Marrow and Lymph
Node Irradiation (TMLI), the accurate contouring of the Planning Target Volume
(PTV) is crucial. Unfortunately, relying on manual contouring for such
treatments is time-consuming and prone to errors. In this paper, we investigate
the application of Deep Learning (DL) to automate the segmentation of the PTV
in TMLI treatment, building upon previous work that introduced a solution to
this problem based on a 2D U-Net model. We extend the previous research (i) by
employing the nnU-Net framework to develop both 2D and 3D U-Net models and (ii)
by evaluating the trained models on the PTV with the exclusion of bones, which
consist mainly of lymp-nodes and represent the most challenging region of the
target volume to segment. Our result show that the introduction of nnU-NET
framework led to statistically significant improvement in the segmentation
performance. In addition, the analysis on the PTV after the exclusion of bones
showed that the models are quite robust also on the most challenging areas of
the target volume. Overall, our study is a significant step forward in the
application of DL in a complex radiotherapy treatment such as TMLI, offering a
viable and scalable solution to increase the number of patients who can benefit
from this treatment.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06497" title="Abstract">arXiv:2402.06497</a> [<a href="/pdf/2402.06497" title="Download PDF">pdf</a>, <a href="/format/2402.06497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iris-SAM: Iris Segmentation Using a Foundational Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farmanifard%2C+P">Parisa Farmanifard</a>, 
<a href="/search/cs?searchtype=author&query=Ross%2C+A">Arun Ross</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 12 figures (some of them have two figures together), Submitted to ICPRAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Iris segmentation is a critical component of an iris biometric system and it
involves extracting the annular iris region from an ocular image. In this work,
we develop a pixel-level iris segmentation model from a foundational model,
viz., Segment Anything Model (SAM), that has been successfully used for
segmenting arbitrary objects. The primary contribution of this work lies in the
integration of different loss functions during the fine-tuning of SAM on ocular
images. In particular, the importance of Focal Loss is borne out in the
fine-tuning process since it strategically addresses the class imbalance
problem (i.e., iris versus non-iris pixels). Experiments on ND-IRIS-0405,
CASIA-Iris-Interval-v3, and IIT-Delhi-Iris datasets convey the efficacy of the
trained model for the task of iris segmentation. For instance, on the
ND-IRIS-0405 dataset, an average segmentation accuracy of 99.58% was achieved,
compared to the best baseline performance of 89.75%.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06499" title="Abstract">arXiv:2402.06499</a> [<a href="/pdf/2402.06499" title="Download PDF">pdf</a>, <a href="/format/2402.06499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BarlowTwins-CXR : Enhancing Chest X-Ray abnormality localization in  heterogeneous data with cross-domain self-supervised learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheng%2C+H">Haoyue Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Linrui Ma</a>, 
<a href="/search/cs?searchtype=author&query=Samson%2C+J">Jean-Francois Samson</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dianbo Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Background: Chest X-ray imaging-based abnormality localization, essential in
diagnosing various diseases, faces significant clinical challenges due to
complex interpretations and the growing workload of radiologists. While recent
advances in deep learning offer promising solutions, there is still a critical
issue of domain inconsistency in cross-domain transfer learning, which hampers
the efficiency and accuracy of diagnostic processes. This study aims to address
the domain inconsistency problem and improve autonomic abnormality localization
performance of heterogeneous chest X-ray image analysis, by developing a
self-supervised learning strategy called "BarlwoTwins-CXR". Methods: We
utilized two publicly available datasets: the NIH Chest X-ray Dataset and the
VinDr-CXR. The BarlowTwins-CXR approach was conducted in a two-stage training
process. Initially, self-supervised pre-training was performed using an
adjusted Barlow Twins algorithm on the NIH dataset with a Resnet50 backbone
pre-trained on ImageNet. This was followed by supervised fine-tuning on the
VinDr-CXR dataset using Faster R-CNN with Feature Pyramid Network (FPN).
Results: Our experiments showed a significant improvement in model performance
with BarlowTwins-CXR. The approach achieved a 3% increase in mAP50 accuracy
compared to traditional ImageNet pre-trained models. In addition, the Ablation
CAM method revealed enhanced precision in localizing chest abnormalities.
Conclusion: BarlowTwins-CXR significantly enhances the efficiency and accuracy
of chest X-ray image-based abnormality localization, outperforming traditional
transfer learning methods and effectively overcoming domain inconsistency in
cross-domain scenarios. Our experiment results demonstrate the potential of
using self-supervised learning to improve the generalizability of models in
medical settings with limited amounts of heterogeneous data.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06500" title="Abstract">arXiv:2402.06500</a> [<a href="/pdf/2402.06500" title="Download PDF">pdf</a>, <a href="/format/2402.06500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Fly Detection of Root Causes from Observed Data with Application  to IT Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zan%2C+L">Lei Zan</a>, 
<a href="/search/cs?searchtype=author&query=Assaad%2C+C+K">Charles K. Assaad</a>, 
<a href="/search/cs?searchtype=author&query=Devijver%2C+E">Emilie Devijver</a>, 
<a href="/search/cs?searchtype=author&query=Gaussier%2C+E">Eric Gaussier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This paper introduces a new structural causal model tailored for representing
threshold-based IT systems and presents a new algorithm designed to rapidly
detect root causes of anomalies in such systems. When root causes are not
causally related, the method is proven to be correct; while an extension is
proposed based on the intervention of an agent to relax this assumption. Our
algorithm and its agent-based extension leverage causal discovery from offline
data and engage in subgraph traversal when encountering new anomalies in online
data. Our extensive experiments demonstrate the superior performance of our
methods, even when applied to data generated from alternative structural causal
models or real IT monitoring data.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06501" title="Abstract">arXiv:2402.06501</a> [<a href="/pdf/2402.06501" title="Download PDF">pdf</a>, <a href="/format/2402.06501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Interactive Machine Learning for Future Command and Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madison%2C+A">Anna Madison</a>, 
<a href="/search/cs?searchtype=author&query=Novoseller%2C+E">Ellen Novoseller</a>, 
<a href="/search/cs?searchtype=author&query=Goecks%2C+V+G">Vinicius G. Goecks</a>, 
<a href="/search/cs?searchtype=author&query=Files%2C+B+T">Benjamin T. Files</a>, 
<a href="/search/cs?searchtype=author&query=Waytowich%2C+N">Nicholas Waytowich</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+A">Alfred Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lawhern%2C+V+J">Vernon J. Lawhern</a>, 
<a href="/search/cs?searchtype=author&query=Thurman%2C+S">Steven Thurman</a>, 
<a href="/search/cs?searchtype=author&query=Kelshaw%2C+C">Christopher Kelshaw</a>, 
<a href="/search/cs?searchtype=author&query=McDowell%2C+K">Kaleb McDowell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the NATO Science and Technology Organization Symposium (ICMCIS) organized by the Information Systems Technology (IST) Panel, IST-205-RSY - the ICMCIS, held in Koblenz, Germany, 23-24 April 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Future warfare will require Command and Control (C2) personnel to make
decisions at shrinking timescales in complex and potentially ill-defined
situations. Given the need for robust decision-making processes and
decision-support tools, integration of artificial and human intelligence holds
the potential to revolutionize the C2 operations process to ensure adaptability
and efficiency in rapidly changing operational environments. We propose to
leverage recent promising breakthroughs in interactive machine learning, in
which humans can cooperate with machine learning algorithms to guide machine
learning algorithm behavior. This paper identifies several gaps in
state-of-the-art science and technology that future work should address to
extend these approaches to function in complex C2 contexts. In particular, we
describe three research focus areas that together, aim to enable scalable
interactive machine learning (SIML): 1) developing human-AI interaction
algorithms to enable planning in complex, dynamic situations; 2) fostering
resilient human-AI teams through optimizing roles, configurations, and trust;
and 3) scaling algorithms and human-AI teams for flexibility across a range of
potential contexts and situations.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06503" title="Abstract">arXiv:2402.06503</a> [<a href="/pdf/2402.06503" title="Download PDF">pdf</a>, <a href="/format/2402.06503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ACTER: Diverse and Actionable Counterfactual Sequences for Explaining  and Diagnosing RL Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gajcin%2C+J">Jasmina Gajcin</a>, 
<a href="/search/cs?searchtype=author&query=Dusparic%2C+I">Ivana Dusparic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 4 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Understanding how failure occurs and how it can be prevented in reinforcement
learning (RL) is necessary to enable debugging, maintain user trust, and
develop personalized policies. Counterfactual reasoning has often been used to
assign blame and understand failure by searching for the closest possible world
in which the failure is avoided. However, current counterfactual state
explanations in RL can only explain an outcome using just the current state
features and offer no actionable recourse on how a negative outcome could have
been prevented. In this work, we propose ACTER (Actionable Counterfactual
Sequences for Explaining Reinforcement Learning Outcomes), an algorithm for
generating counterfactual sequences that provides actionable advice on how
failure can be avoided. ACTER investigates actions leading to a failure and
uses the evolutionary algorithm NSGA-II to generate counterfactual sequences of
actions that prevent it with minimal changes and high certainty even in
stochastic environments. Additionally, ACTER generates a set of multiple
diverse counterfactual sequences that enable users to correct failure in the
way that best fits their preferences. We also introduce three diversity metrics
that can be used for evaluating the diversity of counterfactual sequences. We
evaluate ACTER in two RL environments, with both discrete and continuous
actions, and show that it can generate actionable and diverse counterfactual
sequences. We conduct a user study to explore how explanations generated by
ACTER help users identify and correct failure.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06504" title="Abstract">arXiv:2402.06504</a> [<a href="/pdf/2402.06504" title="Download PDF">pdf</a>, <a href="/format/2402.06504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Complex Multi-UAV Mission Planning Problems using  Multi-objective Genetic Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramirez-Atencia%2C+C">Cristian Ramirez-Atencia</a>, 
<a href="/search/cs?searchtype=author&query=Bello-Orgaz%2C+G">Gema Bello-Orgaz</a>, 
<a href="/search/cs?searchtype=author&query=R-Moreno%2C+M+D">Maria D R-Moreno</a>, 
<a href="/search/cs?searchtype=author&query=Camacho%2C+D">David Camacho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a preprint version of the article submitted and published in Soft Computing
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Soft Computing 21, 4883-4900, 2017
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Due to recent booming of UAVs technologies, these are being used in many
fields involving complex tasks. Some of them involve a high risk to the vehicle
driver, such as fire monitoring and rescue tasks, which make UAVs excellent for
avoiding human risks. Mission Planning for UAVs is the process of planning the
locations and actions (loading/dropping a load, taking videos/pictures,
acquiring information) for the vehicles, typically over a time period. These
vehicles are controlled from Ground Control Stations (GCSs) where human
operators use rudimentary systems. This paper presents a new Multi-Objective
Genetic Algorithm for solving complex Mission Planning Problems (MPP) involving
a team of UAVs and a set of GCSs. A hybrid fitness function has been designed
using a Constraint Satisfaction Problem (CSP) to check if solutions are valid
and Pareto-based measures to look for optimal solutions. The algorithm has been
tested on several datasets optimizing different variables of the mission, such
as the makespan, the fuel consumption, distance, etc. Experimental results show
that the new algorithm is able to obtain good solutions, however as the problem
becomes more complex, the optimal solutions also become harder to find.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06506" title="Abstract">arXiv:2402.06506</a> [<a href="/pdf/2402.06506" title="Download PDF">pdf</a>, <a href="/format/2402.06506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classifying point clouds at the facade-level using geometric features  and deep learning networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yue Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wysocki%2C+O">Olaf Wysocki</a>, 
<a href="/search/cs?searchtype=author&query=Hoegner%2C+L">Ludwig Hoegner</a>, 
<a href="/search/cs?searchtype=author&query=Stilla%2C+U">Uwe Stilla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the Recent Advances in 3D Geoinformation Science, Proceedings of the 18th 3D GeoInfo Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">3D building models with facade details are playing an important role in many
applications now. Classifying point clouds at facade-level is key to create
such digital replicas of the real world. However, few studies have focused on
such detailed classification with deep neural networks. We propose a method
fusing geometric features with deep learning networks for point cloud
classification at facade-level. Our experiments conclude that such early-fused
features improve deep learning methods' performance. This method can be applied
for compensating deep learning networks' ability in capturing local geometric
information and promoting the advancement of semantic segmentation.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06509" title="Abstract">arXiv:2402.06509</a> [<a href="/pdf/2402.06509" title="Download PDF">pdf</a>, <a href="/format/2402.06509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asking the Right Question at the Right Time: Human and Model Uncertainty  Guidance to Ask Clarification Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Testoni%2C+A">Alberto Testoni</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez%2C+R">Raquel Fern&#xe1;ndez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Clarification questions are an essential dialogue tool to signal
misunderstanding, ambiguities, and under-specification in language use. While
humans are able to resolve uncertainty by asking questions since childhood,
modern dialogue systems struggle to generate effective questions. To make
progress in this direction, in this work we take a collaborative dialogue task
as a testbed and study how model uncertainty relates to human uncertainty -- an
as yet under-explored problem. We show that model uncertainty does not mirror
human clarification-seeking behavior, which suggests that using human
clarification questions as supervision for deciding when to ask may not be the
most effective way to resolve model uncertainty. To address this issue, we
propose an approach to generating clarification questions based on model
uncertainty estimation, compare it to several alternatives, and show that it
leads to significant improvements in terms of task success. Our findings
highlight the importance of equipping dialogue systems with the ability to
assess their own uncertainty and exploit in interaction.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06511" title="Abstract">arXiv:2402.06511</a> [<a href="/pdf/2402.06511" title="Download PDF">pdf</a>, <a href="/format/2402.06511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Building a Semantic Network Inventory for Model-Driven Telemetry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez-Casanueva%2C+I+D">I. D. Mart&#xed;nez-Casanueva</a>, 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez-Sanchez%2C+D">D. Gonz&#xe1;lez-Sanchez</a>, 
<a href="/search/cs?searchtype=author&query=Bellido%2C+L">L. Bellido</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez%2C+D">D. Fern&#xe1;ndez</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+D+R">D. R. L&#xf3;pez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Communications Magazine, vol. 61, no. 3, pp. 60-66, March
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Network telemetry based on data models is expected to become the standard
mechanism for collecting operational data from network devices efficiently. But
the wide variety of standard and proprietary data models along with the
different implementations of telemetry protocols offered by network vendors,
become a barrier when monitoring heterogeneous network infrastructures. To
facilitate the integration and sharing of context information related to
model-driven telemetry, this work proposes a semantic network inventory that
integrates new information models specifically developed to capture context
information in a vendor-agnostic fashion using current standards defined for
context management. To automate the integration of this context information
within the network inventory, a reference architecture is designed. Finally, a
prototype of the solution is implemented and validated through a case study
that illustrates how the network inventory can ease the operation of
model-driven telemetry in multi-vendor networks.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06512" title="Abstract">arXiv:2402.06512</a> [<a href="/pdf/2402.06512" title="Download PDF">pdf</a>, <a href="/format/2402.06512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Clinical Trial Outcome Prediction with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wenhao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+D">Dongsheng Peng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongxia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hongtu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+T">Tianfan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Huaxiu Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The clinical trial is a pivotal and costly process, often spanning multiple
years and requiring substantial financial resources. Therefore, the development
of clinical trial outcome prediction models aims to exclude drugs likely to
fail and holds the potential for significant cost savings. Recent data-driven
attempts leverage deep learning methods to integrate multimodal data for
predicting clinical trial outcomes. However, these approaches rely on manually
designed modal-specific encoders, which limits both the extensibility to adapt
new modalities and the ability to discern similar information patterns across
different modalities. To address these issues, we propose a multimodal
mixture-of-experts (LIFTED) approach for clinical trial outcome prediction.
Specifically, LIFTED unifies different modality data by transforming them into
natural language descriptions. Then, LIFTED constructs unified noise-resilient
encoders to extract information from modal-specific language descriptions.
Subsequently, a sparse Mixture-of-Experts framework is employed to further
refine the representations, enabling LIFTED to identify similar information
patterns across different modalities and extract more consistent
representations from those patterns using the same expert model. Finally, a
mixture-of-experts module is further employed to dynamically integrate
different modality representations for prediction, which gives LIFTED the
ability to automatically weigh different modalities and pay more attention to
critical information. The experiments demonstrate that LIFTED significantly
enhances performance in predicting clinical trial outcomes across all three
phases compared to the best baseline, showcasing the effectiveness of our
proposed key components.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06515" title="Abstract">arXiv:2402.06515</a> [<a href="/pdf/2402.06515" title="Download PDF">pdf</a>, <a href="/format/2402.06515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Decisive Power of Indecision: Low-Variance Risk-Limiting Audits and  Election Contestation via Marginal Mark Recording
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fuller%2C+B">Benjamin Fuller</a>, 
<a href="/search/cs?searchtype=author&query=Pai%2C+R">Rashmi Pai</a>, 
<a href="/search/cs?searchtype=author&query=Russell%2C+A">Alexander Russell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, no prior publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Risk-limiting audits (RLAs) are the established techniques for verifying
large elections. While they provide rigorous guarantees of correctness,
widespread adoption has been impeded by both efficiency concerns and the fact
they offer statistical, rather than absolute, conclusions. We define new
families of audits that help to address these issues. Our new audits are
enabled by revisiting the standard notion of a cast-vote record so that it can
declare multiple possible mark interpretations rather than a single decision;
this can reflect the presence of ambiguous marks, which appear regularly on
hand-marked ballots. We show that this simple expedient can offer significant
efficiency improvements with only minor changes to existing auditing
infrastructure. We establish that these "Bayesian" comparison audits are indeed
risk-limiting in the formal sense of (Fuller, Harrison, and Russell, 2022). We
then define a new type of post-election audit we call a contested audit. These
call for each candidate to provide a cast-vote record table advancing their own
claim to victory. We prove that these audits offer remarkable sample
efficiency: they guarantee negligible risk with only a constant number of
ballot inspections. This is a first for an audit with provable soundness. These
results are formulated in a game-based security model that specify quantitative
soundness and completeness guarantees. Finally, we observe that these audits
provide a direct means to handle contestation of election results affirmed by
conventional RLAs.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06516" title="Abstract">arXiv:2402.06516</a> [<a href="/pdf/2402.06516" title="Download PDF">pdf</a>, <a href="/ps/2402.06516" title="Download PostScript">ps</a>, <a href="/format/2402.06516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HoneyDOC: An Efficient Honeypot Architecture Enabling All-Round Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+W">Wenjun Fan</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zhihui Du</a>, 
<a href="/search/cs?searchtype=author&query=Smith-Creasey%2C+M">Max Smith-Creasey</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez%2C+D">David Fern&#xe1;ndez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> None
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> W. Fan, Z. Du, M. Smith-Creasey, D. Fern\'andez, "HoneyDOC: An
  Efficient Honeypot Architecture Enabling All-Round Design", IEEE Journal on
  Selected Areas in Communications, vol. 37, issue 3, March 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Honeypots are designed to trap the attacker with the purpose of investigating
its malicious behavior. Owing to the increasing variety and sophistication of
cyber attacks, how to capture high-quality attack data has become a challenge
in the context of honeypot area. All-round honeypots, which mean significant
improvement in sensibility, countermeasure and stealth, are necessary to tackle
the problem. In this paper, we propose a novel honeypot architecture termed
HoneyDOC to support all-round honeypot design and implementation. Our HoneyDOC
architecture clearly identifies three essential independent and collaborative
modules, Decoy, Captor and Orchestrator. Based on the efficient architecture, a
Software-Defined Networking (SDN) enabled honeypot system is designed, which
supplies high programmability for technically sustaining the features for
capturing high-quality data. A proof-of-concept system is implemented to
validate its feasibility and effectiveness. The experimental results show the
benefits by using the proposed architecture comparing to the previous honeypot
solutions.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06521" title="Abstract">arXiv:2402.06521</a> [<a href="/pdf/2402.06521" title="Download PDF">pdf</a>, <a href="/format/2402.06521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstructing facade details using MLS point clouds and Bag-of-Words  approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Froech%2C+T">Thomas Froech</a>, 
<a href="/search/cs?searchtype=author&query=Wysocki%2C+O">Olaf Wysocki</a>, 
<a href="/search/cs?searchtype=author&query=Hoegner%2C+L">Ludwig Hoegner</a>, 
<a href="/search/cs?searchtype=author&query=Stilla%2C+U">Uwe Stilla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the Recent Advances in 3D Geoinformation Science, Proceedings of the 18th 3D GeoInfo Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the reconstruction of fa\c{c}ade elements, the identification of specific
object types remains challenging and is often circumvented by rectangularity
assumptions or the use of bounding boxes. We propose a new approach for the
reconstruction of 3D fa\c{c}ade details. We combine MLS point clouds and a
pre-defined 3D model library using a BoW concept, which we augment by
incorporating semi-global features. We conduct experiments on the models
superimposed with random noise and on the TUM-FA\c{C}ADE dataset. Our method
demonstrates promising results, improving the conventional BoW approach. It
holds the potential to be utilized for more realistic facade reconstruction
without rectangularity assumptions, which can be used in applications such as
testing automated driving functions or estimating fa\c{c}ade solar potential.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06529" title="Abstract">arXiv:2402.06529</a> [<a href="/pdf/2402.06529" title="Download PDF">pdf</a>, <a href="/format/2402.06529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introspective Planning: Guiding Language-Enabled Agents to Refine Their  Own Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+K">Kaiqu Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zixu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fisac%2C+J+F">Jaime Fern&#xe1;ndez Fisac</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) exhibit advanced reasoning skills, enabling
robots to comprehend natural language instructions and strategically plan
high-level actions through proper grounding. However, LLM hallucination may
result in robots confidently executing plans that are misaligned with user
goals or, in extreme cases, unsafe. Additionally, inherent ambiguity in natural
language instructions can induce task uncertainty, particularly in situations
where multiple valid options exist. To address this issue, LLMs must identify
such uncertainty and proactively seek clarification. This paper explores the
concept of introspective planning as a systematic method for guiding LLMs in
forming uncertainty--aware plans for robotic task execution without the need
for fine-tuning. We investigate uncertainty quantification in task-level robot
planning and demonstrate that introspection significantly improves both success
rates and safety compared to state-of-the-art LLM-based planning approaches.
Furthermore, we assess the effectiveness of introspective planning in
conjunction with conformal prediction, revealing that this combination yields
tighter confidence bounds, thereby maintaining statistical success guarantees
with fewer superfluous user clarification queries.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06530" title="Abstract">arXiv:2402.06530</a> [<a href="/pdf/2402.06530" title="Download PDF">pdf</a>, <a href="/format/2402.06530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Refining Myocardial Infarction Detection: A Novel Multi-Modal Composite  Kernel Strategy in One-Class Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zahid%2C+M+U">Muhammad Uzair Zahid</a>, 
<a href="/search/cs?searchtype=author&query=Degerli%2C+A">Aysen Degerli</a>, 
<a href="/search/cs?searchtype=author&query=Sohrab%2C+F">Fahad Sohrab</a>, 
<a href="/search/cs?searchtype=author&query=Kiranyaz%2C+S">Serkan Kiranyaz</a>, 
<a href="/search/cs?searchtype=author&query=Gabbouj%2C+M">Moncef Gabbouj</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Early detection of myocardial infarction (MI), a critical condition arising
from coronary artery disease (CAD), is vital to prevent further myocardial
damage. This study introduces a novel method for early MI detection using a
one-class classification (OCC) algorithm in echocardiography. Our study
overcomes the challenge of limited echocardiography data availability by
adopting a novel approach based on Multi-modal Subspace Support Vector Data
Description. The proposed technique involves a specialized MI detection
framework employing multi-view echocardiography incorporating a composite
kernel in the non-linear projection trick, fusing Gaussian and Laplacian
sigmoid functions. Additionally, we enhance the update strategy of the
projection matrices by adapting maximization for both or one of the modalities
in the optimization process. Our method boosts MI detection capability by
efficiently transforming features extracted from echocardiography data into an
optimized lower-dimensional subspace. The OCC model trained specifically on
target class instances from the comprehensive HMC-QU dataset that includes
multiple echocardiography views indicates a marked improvement in MI detection
accuracy. Our findings reveal that our proposed multi-view approach achieves a
geometric mean of 71.24\%, signifying a substantial advancement in
echocardiography-based MI diagnosis and offering more precise and efficient
diagnostic tools.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06531" title="Abstract">arXiv:2402.06531</a> [<a href="/pdf/2402.06531" title="Download PDF">pdf</a>, <a href="/format/2402.06531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transferring facade labels between point clouds with semantic octrees  while considering change detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schwarz%2C+S">Sophia Schwarz</a>, 
<a href="/search/cs?searchtype=author&query=Pilz%2C+T">Tanja Pilz</a>, 
<a href="/search/cs?searchtype=author&query=Wysocki%2C+O">Olaf Wysocki</a>, 
<a href="/search/cs?searchtype=author&query=Hoegner%2C+L">Ludwig Hoegner</a>, 
<a href="/search/cs?searchtype=author&query=Stilla%2C+U">Uwe Stilla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the Recent Advances in 3D Geoinformation Science, Proceedings of the 18th 3D GeoInfo Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Point clouds and high-resolution 3D data have become increasingly important
in various fields, including surveying, construction, and virtual reality.
However, simply having this data is not enough; to extract useful information,
semantic labeling is crucial. In this context, we propose a method to transfer
annotations from a labeled to an unlabeled point cloud using an octree
structure. The structure also analyses changes between the point clouds. Our
experiments confirm that our method effectively transfers annotations while
addressing changes. The primary contribution of this project is the development
of the method for automatic label transfer between two different point clouds
that represent the same real-world object. The proposed method can be of great
importance for data-driven deep learning algorithms as it can also allow
circumventing stochastic transfer learning by deterministic label transfer
between datasets depicting the same objects.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06532" title="Abstract">arXiv:2402.06532</a> [<a href="/pdf/2402.06532" title="Download PDF">pdf</a>, <a href="/format/2402.06532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Adversarial Bayesian Optimization for Surrogate Objectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+M+S">Michael S. Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yimeng Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Bastani%2C+H">Hamsa Bastani</a>, 
<a href="/search/cs?searchtype=author&query=Gardner%2C+J">Jacob Gardner</a>, 
<a href="/search/cs?searchtype=author&query=Gee%2C+J+C">James C. Gee</a>, 
<a href="/search/cs?searchtype=author&query=Bastani%2C+O">Osbert Bastani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Offline model-based policy optimization seeks to optimize a learned surrogate
objective function without querying the true oracle objective during
optimization. However, inaccurate surrogate model predictions are frequently
encountered along the optimization trajectory. To address this limitation, we
propose generative adversarial Bayesian optimization (GABO) using adaptive
source critic regularization, a task-agnostic framework for Bayesian
optimization that employs a Lipschitz-bounded source critic model to constrain
the optimization trajectory to regions where the surrogate function is
reliable. We show that under certain assumptions for the continuous input space
prior, our algorithm dynamically adjusts the strength of the source critic
regularization. GABO outperforms existing baselines on a number of different
offline optimization tasks across a variety of scientific domains. Our code is
available at https://github.com/michael-s-yao/gabo
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06537" title="Abstract">arXiv:2402.06537</a> [<a href="/pdf/2402.06537" title="Download PDF">pdf</a>, <a href="/format/2402.06537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Density Estimation for Out-of-Distribution Detection via  Normalizing Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cook%2C+E+D">Evan D. Cook</a>, 
<a href="/search/cs?searchtype=author&query=Lavoie%2C+M">Marc-Antoine Lavoie</a>, 
<a href="/search/cs?searchtype=author&query=Waslander%2C+S+L">Steven L. Waslander</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to CRV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Out-of-distribution (OOD) detection is a critical task for safe deployment of
learning systems in the open world setting. In this work, we investigate the
use of feature density estimation via normalizing flows for OOD detection and
present a fully unsupervised approach which requires no exposure to OOD data,
avoiding researcher bias in OOD sample selection. This is a post-hoc method
which can be applied to any pretrained model, and involves training a
lightweight auxiliary normalizing flow model to perform the out-of-distribution
detection via density thresholding. Experiments on OOD detection in image
classification show strong results for far-OOD data detection with only a
single epoch of flow training, including 98.2% AUROC for ImageNet-1k vs.
Textures, which exceeds the state of the art by 7.8%. We additionally explore
the connection between the feature space distribution of the pretrained model
and the performance of our method. Finally, we provide insights into training
pitfalls that have plagued normalizing flows for use in OOD detection.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06538" title="Abstract">arXiv:2402.06538</a> [<a href="/pdf/2402.06538" title="Download PDF">pdf</a>, <a href="/format/2402.06538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Exercise in Tournament Design: When Some Matches Must Be Scheduled
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Sushmita Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Ramanujan%2C+M+S">M. S. Ramanujan</a>, 
<a href="/search/cs?searchtype=author&query=Strulo%2C+P">Peter Strulo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of AAAI 2024 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Single-elimination (SE) tournaments are a popular format used in competitive
environments and decision making. Algorithms for SE tournament manipulation
have been an active topic of research in recent years. In this paper, we
initiate the algorithmic study of a novel variant of SE tournament manipulation
that aims to model the fact that certain matchups are highly desired in a
sporting context, incentivizing an organizer to manipulate the bracket to make
such matchups take place. We obtain both hardness and tractability results. We
show that while the problem of computing a bracket enforcing a given set of
matches in an SE tournament is NP-hard, there are natural restrictions that
lead to polynomial-time solvability. In particular, we show polynomial-time
solvability if there is a linear ordering on the ability of players with only a
constant number of exceptions where a player with lower ability beats a player
with higher ability.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06539" title="Abstract">arXiv:2402.06539</a> [<a href="/pdf/2402.06539" title="Download PDF">pdf</a>, <a href="/ps/2402.06539" title="Download PostScript">ps</a>, <a href="/format/2402.06539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybridnet for depth estimation and semantic segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez-Escobedo%2C+D">Dalila S&#xe1;nchez-Escobedo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Casas%2C+J+R">Josep R. Casas</a>, 
<a href="/search/cs?searchtype=author&query=Pard%C3%A0s%2C+M">Montse Pard&#xe0;s</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2018
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semantic segmentation and depth estimation are two important tasks in the
area of image processing. Traditionally, these two tasks are addressed in an
independent manner. However, for those applications where geometric and
semantic information is required, such as robotics or autonomous
navigation,depth or semantic segmentation alone are not sufficient. In this
paper, depth estimation and semantic segmentation are addressed together from a
single input image through a hybrid convolutional network. Different from the
state of the art methods where features are extracted by a sole feature
extraction network for both tasks, the proposed HybridNet improves the features
extraction by separating the relevant features for one task from those which
are relevant for both. Experimental results demonstrate that HybridNet results
are comparable with the state of the art methods, as well as the single task
methods that HybridNet is based on.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06544" title="Abstract">arXiv:2402.06544</a> [<a href="/pdf/2402.06544" title="Download PDF">pdf</a>, <a href="/format/2402.06544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibrating Long-form Generations from Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yukun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yixin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Thirukovalluru%2C+R">Raghuveer Thirukovalluru</a>, 
<a href="/search/cs?searchtype=author&query=Cohan%2C+A">Arman Cohan</a>, 
<a href="/search/cs?searchtype=author&query=Dhingra%2C+B">Bhuwan Dhingra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">To enhance Large Language Models' (LLMs) reliability, calibration is
essential -- the model's assessed confidence scores should align with the
actual likelihood of its responses being correct. However, current confidence
elicitation methods and calibration metrics typically rely on a binary
true/false assessment of response correctness. This approach does not apply to
long-form generation, where an answer can be partially correct. Addressing this
gap, we introduce a unified calibration framework, in which both the
correctness of the LLMs' responses and their associated confidence levels are
treated as distributions across a range of scores. Within this framework, we
develop three metrics to precisely evaluate LLM calibration and further propose
two confidence elicitation methods based on self-consistency and
self-evaluation. Our experiments, which include long-form QA and summarization
tasks, demonstrate that larger models don't necessarily guarantee better
calibration, that calibration performance is found to be metric-dependent, and
that self-consistency methods excel in factoid datasets. We also find that
calibration can be enhanced through techniques such as fine-tuning, integrating
relevant source documents, scaling the temperature, and combining
self-consistency with self-evaluation. Lastly, we showcase a practical
application of our system: selecting and cascading open-source models and
ChatGPT to optimize correctness given a limited API budget. This research not
only challenges existing notions of LLM calibration but also offers practical
methodologies for improving trustworthiness in long-form generation.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06545" title="Abstract">arXiv:2402.06545</a> [<a href="/pdf/2402.06545" title="Download PDF">pdf</a>, <a href="/format/2402.06545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the impact of items and cooperation in inventory models with  exemptable ordering costs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fiestras-Janeiro%2C+M+G">M. Gloria Fiestras-Janeiro</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa-Jurado%2C+I">Ignacio Garc&#xed;a-Jurado</a>, 
<a href="/search/cs?searchtype=author&query=Meca%2C+A">Ana Meca</a>, 
<a href="/search/cs?searchtype=author&query=Mosquera%2C+M+A">Manuel A. Mosquera</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Production Economics 269 (2024) 109151
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper we introduce and analyse, from a game theoretical perspective,
several multi-agent or multi-item continuous review inventory models in which
the buyers are exempted from ordering costs if the price of their orders is
greater than or equal to a certain amount. For all models we obtain the optimal
ordering policy. We first analyse a simple model with one firm and one item.
Then, we study a model with one firm and several items, for which we design a
procedure based on cooperative game theory to evaluate the impact of each item
on the total cost. Then, we deal with a model with several firms and one item
for each firm, for which we characterise a rule to allocate the total cost
among the firms in a coalitionally stable way. Finally, we discuss a model with
several firms and several items, for which we characterise a rule to allocate
the total cost among the firms in a coalitionally stable way and to evaluate
the impact of each item on the cost that would be payable to each firm when
using the allocation rule. All the concepts and results of this article are
illustrated using data from a case study.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06549" title="Abstract">arXiv:2402.06549</a> [<a href="/pdf/2402.06549" title="Download PDF">pdf</a>, <a href="/format/2402.06549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bryndza at ClimateActivism 2024: Stance, Target and Hate Event Detection  via Retrieval-Augmented GPT-4 and LLaMA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C5%A0uppa%2C+M">Marek &#x160;uppa</a>, 
<a href="/search/cs?searchtype=author&query=Skala%2C+D">Daniel Skala</a>, 
<a href="/search/cs?searchtype=author&query=Ja%C5%A1%C5%A1%2C+D">Daniela Ja&#x161;&#x161;</a>, 
<a href="/search/cs?searchtype=author&query=Su%C4%8D%C3%ADk%2C+S">Samuel Su&#x10d;&#xed;k</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0vec%2C+A">Andrej &#x160;vec</a>, 
<a href="/search/cs?searchtype=author&query=Hra%C5%A1ka%2C+P">Peter Hra&#x161;ka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 7th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study details our approach for the CASE 2024 Shared Task on Climate
Activism Stance and Hate Event Detection, focusing on Hate Speech Detection,
Hate Speech Target Identification, and Stance Detection as classification
challenges. We explored the capability of Large Language Models (LLMs),
particularly GPT-4, in zero- or few-shot settings enhanced by retrieval
augmentation and re-ranking for Tweet classification. Our goal was to determine
if LLMs could match or surpass traditional methods in this context.
<br />We conducted an ablation study with LLaMA for comparison, and our results
indicate that our models significantly outperformed the baselines, securing
second place in the Target Detection task. The code for our submission is
available at https://github.com/NaiveNeuron/bryndza-case-2024
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06552" title="Abstract">arXiv:2402.06552</a> [<a href="/pdf/2402.06552" title="Download PDF">pdf</a>, <a href="/format/2402.06552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deceptive Path Planning via Reinforcement Learning with Graph Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fatemi%2C+M+Y">Michael Y. Fatemi</a>, 
<a href="/search/cs?searchtype=author&query=Suttle%2C+W+A">Wesley A. Suttle</a>, 
<a href="/search/cs?searchtype=author&query=Sadler%2C+B+M">Brian M. Sadler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deceptive path planning (DPP) is the problem of designing a path that hides
its true goal from an outside observer. Existing methods for DPP rely on
unrealistic assumptions, such as global state observability and perfect model
knowledge, and are typically problem-specific, meaning that even minor changes
to a previously solved problem can force expensive computation of an entirely
new solution. Given these drawbacks, such methods do not generalize to unseen
problem instances, lack scalability to realistic problem sizes, and preclude
both on-the-fly tunability of deception levels and real-time adaptivity to
changing environments. In this paper, we propose a reinforcement learning
(RL)-based scheme for training policies to perform DPP over arbitrary weighted
graphs that overcomes these issues. The core of our approach is the
introduction of a local perception model for the agent, a new state space
representation distilling the key components of the DPP problem, the use of
graph neural network-based policies to facilitate generalization and scaling,
and the introduction of new deception bonuses that translate the deception
objectives of classical methods to the RL setting. Through extensive
experimentation we show that, without additional fine-tuning, at test time the
resulting policies successfully generalize, scale, enjoy tunable levels of
deception, and adapt in real-time to changes in the environment.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06557" title="Abstract">arXiv:2402.06557</a> [<a href="/pdf/2402.06557" title="Download PDF">pdf</a>, <a href="/format/2402.06557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Quantified Boolean Bayesian Network: Theory and Experiments with a  Logical Graphical Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coppola%2C+G">Gregory Coppola</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">This paper introduces the Quantified Boolean Bayesian Network (QBBN), which
provides a unified view of logical and probabilistic reasoning. The QBBN is
meant to address a central problem with the Large Language Model (LLM), which
has become extremely popular in Information Retrieval, which is that the LLM
hallucinates. A Bayesian Network, by construction, cannot hallucinate, because
it can only return answers that it can explain. We show how a Bayesian Network
over an unbounded number of boolean variables can be configured to represent
the logical reasoning underlying human language. We do this by creating a
key-value version of the First-Order Calculus, for which we can prove
consistency and completeness. We show that the model is trivially trained over
fully observed data, but that inference is non-trivial. Exact inference in a
Bayesian Network is intractable (i.e. $\Omega(2^N)$ for $N$ variables). For
inference, we investigate the use of Loopy Belief Propagation (LBP), which is
not guaranteed to converge, but which has been shown to often converge in
practice. Our experiments show that LBP indeed does converge very reliably, and
our analysis shows that a round of LBP takes time $O(N2^n)$, where $N$ bounds
the number of variables considered, and $n$ bounds the number of incoming
connections to any factor, and further improvements may be possible. Our
network is specifically designed to alternate between AND and OR gates in a
Boolean Algebra, which connects more closely to logical reasoning, allowing a
completeness proof for an expanded version of our network, and also allows
inference to follow specific but adequate pathways, that turn out to be fast.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06559" title="Abstract">arXiv:2402.06559</a> [<a href="/pdf/2402.06559" title="Download PDF">pdf</a>, <a href="/format/2402.06559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous  Driving and Zero-Shot Instruction Following
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Brian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Huangyuan Su</a>, 
<a href="/search/cs?searchtype=author&query=Gkanatsios%2C+N">Nikolaos Gkanatsios</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+T">Tsung-Wei Ke</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Ayush Jain</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+J">Jeff Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Fragkiadaki%2C+K">Katerina Fragkiadaki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Robotics (cs.RO)

</div>
<p class="mathjax">Diffusion models excel at modeling complex and multimodal trajectory
distributions for decision-making and control. Reward-gradient guided denoising
has been recently proposed to generate trajectories that maximize both a
differentiable reward function and the likelihood under the data distribution
captured by a diffusion model. Reward-gradient guided denoising requires a
differentiable reward function fitted to both clean and noised samples,
limiting its applicability as a general trajectory optimizer. In this paper, we
propose DiffusionES, a method that combines gradient-free optimization with
trajectory denoising to optimize black-box non-differentiable objectives while
staying in the data manifold. Diffusion-ES samples trajectories during
evolutionary search from a diffusion model and scores them using a black-box
reward function. It mutates high-scoring trajectories using a truncated
diffusion process that applies a small number of noising and denoising steps,
allowing for much more efficient exploration of the solution space. We show
that DiffusionES achieves state-of-the-art performance on nuPlan, an
established closed-loop planning benchmark for autonomous driving. Diffusion-ES
outperforms existing sampling-based planners, reactive deterministic or
diffusion-based policies, and reward-gradient guidance. Additionally, we show
that unlike prior guidance methods, our method can optimize non-differentiable
language-shaped reward functions generated by few-shot LLM prompting. When
guided by a human teacher that issues instructions to follow, our method can
generate novel, highly complex behaviors, such as aggressive lane weaving,
which are not present in the training data. This allows us to solve the hardest
nuPlan scenarios which are beyond the capabilities of existing trajectory
optimization methods and driving policies.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06560" title="Abstract">arXiv:2402.06560</a> [<a href="/pdf/2402.06560" title="Download PDF">pdf</a>, <a href="/format/2402.06560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Annotator: A framework for efficiently building video classifiers  using vision-language models and active learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ziai%2C+A">Amir Ziai</a>, 
<a href="/search/cs?searchtype=author&query=Vartakavi%2C+A">Aneesh Vartakavi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for review to KDD '24 (ADS Track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">High-quality and consistent annotations are fundamental to the successful
development of robust machine learning models. Traditional data annotation
methods are resource-intensive and inefficient, often leading to a reliance on
third-party annotators who are not the domain experts. Hard samples, which are
usually the most informative for model training, tend to be difficult to label
accurately and consistently without business context. These can arise
unpredictably during the annotation process, requiring a variable number of
iterations and rounds of feedback, leading to unforeseen expenses and time
commitments to guarantee quality.
<br />We posit that more direct involvement of domain experts, using a
human-in-the-loop system, can resolve many of these practical challenges. We
propose a novel framework we call Video Annotator (VA) for annotating,
managing, and iterating on video classification datasets. Our approach offers a
new paradigm for an end-user-centered model development process, enhancing the
efficiency, usability, and effectiveness of video classifiers. Uniquely, VA
allows for a continuous annotation process, seamlessly integrating data
collection and model training.
<br />We leverage the zero-shot capabilities of vision-language foundation models
combined with active learning techniques, and demonstrate that VA enables the
efficient creation of high-quality models. VA achieves a median 6.8 point
improvement in Average Precision relative to the most competitive baseline
across a wide-ranging assortment of tasks. We release a dataset with 153k
labels across 56 video understanding tasks annotated by three professional
video editors using VA, and also release code to replicate our experiments at:
<a href="http://github.com/netflix/videoannotator.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06562" title="Abstract">arXiv:2402.06562</a> [<a href="/pdf/2402.06562" title="Download PDF">pdf</a>, <a href="/format/2402.06562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Guaranteed Exploration for Non-linear Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Prajapat%2C+M">Manish Prajapat</a>, 
<a href="/search/eess?searchtype=author&query=K%C3%B6hler%2C+J">Johannes K&#xf6;hler</a>, 
<a href="/search/eess?searchtype=author&query=Turchetta%2C+M">Matteo Turchetta</a>, 
<a href="/search/eess?searchtype=author&query=Krause%2C+A">Andreas Krause</a>, 
<a href="/search/eess?searchtype=author&query=Zeilinger%2C+M+N">Melanie N. Zeilinger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Robotics (cs.RO); Optimization and Control (math.OC)

</div>
<p class="mathjax">Safely exploring environments with a-priori unknown constraints is a
fundamental challenge that restricts the autonomy of robots. While safety is
paramount, guarantees on sufficient exploration are also crucial for ensuring
autonomous task completion. To address these challenges, we propose a novel
safe guaranteed exploration framework using optimal control, which achieves
first-of-its-kind results: guaranteed exploration for non-linear systems with
finite time sample complexity bounds, while being provably safe with
arbitrarily high probability. The framework is general and applicable to many
real-world scenarios with complex non-linear dynamics and unknown domains.
Based on this framework we propose an efficient algorithm, SageMPC, SAfe
Guaranteed Exploration using Model Predictive Control. SageMPC improves
efficiency by incorporating three techniques: i) exploiting a Lipschitz bound,
ii) goal-directed exploration, and iii) receding horizon style re-planning, all
while maintaining the desired sample complexity, safety and exploration
guarantees of the framework. Lastly, we demonstrate safe efficient exploration
in challenging unknown environments using SageMPC with a car model.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06563" title="Abstract">arXiv:2402.06563</a> [<a href="/pdf/2402.06563" title="Download PDF">pdf</a>, <a href="/ps/2402.06563" title="Download PostScript">ps</a>, <a href="/format/2402.06563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What is Hiding in Medicine&#x27;s Dark Matter? Learning with Missing Data in  Medical Practices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suzen%2C+N">Neslihan Suzen</a>, 
<a href="/search/cs?searchtype=author&query=Mirkes%2C+E+M">Evgeny M. Mirkes</a>, 
<a href="/search/cs?searchtype=author&query=Roland%2C+D">Damian Roland</a>, 
<a href="/search/cs?searchtype=author&query=Levesley%2C+J">Jeremy Levesley</a>, 
<a href="/search/cs?searchtype=author&query=Gorban%2C+A+N">Alexander N. Gorban</a>, 
<a href="/search/cs?searchtype=author&query=Coats%2C+T+J">Tim J. Coats</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Conference on Big Data (BigData),
  4979-4986
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Information Theory (cs.IT)

</div>
<p class="mathjax">Electronic patient records (EPRs) produce a wealth of data but contain
significant missing information. Understanding and handling this missing data
is an important part of clinical data analysis and if left unaddressed could
result in bias in analysis and distortion in critical conclusions. Missing data
may be linked to health care professional practice patterns and imputation of
missing data can increase the validity of clinical decisions. This study
focuses on statistical approaches for understanding and interpreting the
missing data and machine learning based clinical data imputation using a single
centre's paediatric emergency data and the data from UK's largest clinical
audit for traumatic injury database (TARN). In the study of 56,961 data points
related to initial vital signs and observations taken on children presenting to
an Emergency Department, we have shown that missing data are likely to be
non-random and how these are linked to health care professional practice
patterns. We have then examined 79 TARN fields with missing values for 5,791
trauma cases. Singular Value Decomposition (SVD) and k-Nearest Neighbour (kNN)
based missing data imputation methods are used and imputation results against
the original dataset are compared and statistically tested. We have concluded
that the 1NN imputer is the best imputation which indicates a usual pattern of
clinical decision making: find the most similar patients and take their
attributes as imputation.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06568" title="Abstract">arXiv:2402.06568</a> [<a href="/pdf/2402.06568" title="Download PDF">pdf</a>, <a href="/format/2402.06568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained multi-objective optimization for multi-UAV planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramirez-Atencia%2C+C">Cristian Ramirez-Atencia</a>, 
<a href="/search/cs?searchtype=author&query=Camacho%2C+D">David Camacho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint of the article submitted and published in Journal of Ambient Intelligence and Humanized Computing
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Ambient Intelligence and Humanized Computing 10,
  2467-2484, 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Over the last decade, developments in unmanned aerial vehicles (UAVs) has
greatly increased, and they are being used in many fields including
surveillance, crisis management or automated mission planning. This last field
implies the search of plans for missions with multiple tasks, UAVs and ground
control stations; and the optimization of several objectives, including
makespan, fuel consumption or cost, among others. In this work, this problem
has been solved using a multi-objective evolutionary algorithm combined with a
constraint satisfaction problem model, which is used in the fitness function of
the algorithm. The algorithm has been tested on several missions of increasing
complexity, and the computational complexity of the different element
considered in the missions has been studied.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06570" title="Abstract">arXiv:2402.06570</a> [<a href="/pdf/2402.06570" title="Download PDF">pdf</a>, <a href="/format/2402.06570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distilling Morphology-Conditioned Hypernetworks for Efficient Universal  Morphology Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zheng Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Vuorio%2C+R">Risto Vuorio</a>, 
<a href="/search/cs?searchtype=author&query=Beck%2C+J">Jacob Beck</a>, 
<a href="/search/cs?searchtype=author&query=Zimmer%2C+M">Matthieu Zimmer</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+K">Kun Shao</a>, 
<a href="/search/cs?searchtype=author&query=Whiteson%2C+S">Shimon Whiteson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Learning a universal policy across different robot morphologies can
significantly improve learning efficiency and enable zero-shot generalization
to unseen morphologies. However, learning a highly performant universal policy
requires sophisticated architectures like transformers (TF) that have larger
memory and computational cost than simpler multi-layer perceptrons (MLP). To
achieve both good performance like TF and high efficiency like MLP at inference
time, we propose HyperDistill, which consists of: (1) A morphology-conditioned
hypernetwork (HN) that generates robot-wise MLP policies, and (2) A policy
distillation approach that is essential for successful training. We show that
on UNIMAL, a benchmark with hundreds of diverse morphologies, HyperDistill
performs as well as a universal TF teacher policy on both training and unseen
test robots, but reduces model size by 6-14 times, and computational cost by
67-160 times in different environments. Our analysis attributes the efficiency
advantage of HyperDistill at inference time to knowledge decoupling, i.e., the
ability to decouple inter-task and intra-task knowledge, a general principle
that could also be applied to improve inference efficiency in other domains.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06575" title="Abstract">arXiv:2402.06575</a> [<a href="/pdf/2402.06575" title="Download PDF">pdf</a>, <a href="/ps/2402.06575" title="Download PostScript">ps</a>, <a href="/format/2402.06575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Microstrip Antenna
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ramirez%2C+L+A+R">Luis Alberto Rabanal Ramirez</a>, 
<a href="/search/math?searchtype=author&query=de+Freitas+Silva%2C+C+M">Cl&#xe1;udio M&#xe1;rcio de Freitas Silva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages, six figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this work, a rectangular microstrip antenna with inset is designed,
simulated and optimized. In the optimization process the patch is deformed, it
new antenna present a amorphous patch. The optimization process was conducted
with Genetic Algorithm (GA), S11 parameters was obtained with full wave
Finite-Differences Time-Domain (FDTD-3D), and the initial configuration
(design) was obtained with line transmission and cavite method.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06576" title="Abstract">arXiv:2402.06576</a> [<a href="/pdf/2402.06576" title="Download PDF">pdf</a>, <a href="/format/2402.06576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Value-based Resource Matching with Fairness Criteria: Application to  Agricultural Water Trading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adiga%2C+A">Abhijin Adiga</a>, 
<a href="/search/cs?searchtype=author&query=Trabelsi%2C+Y">Yohai Trabelsi</a>, 
<a href="/search/cs?searchtype=author&query=Ferdousi%2C+T">Tanvir Ferdousi</a>, 
<a href="/search/cs?searchtype=author&query=Marathe%2C+M">Madhav Marathe</a>, 
<a href="/search/cs?searchtype=author&query=Ravi%2C+S+S">S. S. Ravi</a>, 
<a href="/search/cs?searchtype=author&query=Swarup%2C+S">Samarth Swarup</a>, 
<a href="/search/cs?searchtype=author&query=Vullikanti%2C+A+K">Anil Kumar Vullikanti</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+M+L">Mandy L. Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Kraus%2C+S">Sarit Kraus</a>, 
<a href="/search/cs?searchtype=author&query=Basu%2C+R">Reetwika Basu</a>, 
<a href="/search/cs?searchtype=author&query=Savalkar%2C+S">Supriya Savalkar</a>, 
<a href="/search/cs?searchtype=author&query=Yourek%2C+M">Matthew Yourek</a>, 
<a href="/search/cs?searchtype=author&query=Brady%2C+M">Michael Brady</a>, 
<a href="/search/cs?searchtype=author&query=Rajagopalan%2C+K">Kirti Rajagopalan</a>, 
<a href="/search/cs?searchtype=author&query=Yoder%2C+J">Jonathan Yoder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Optimal allocation of agricultural water in the event of droughts is an
important global problem. In addressing this problem, many aspects, including
the welfare of farmers, the economy, and the environment, must be considered.
Under this backdrop, our work focuses on several resource-matching problems
accounting for agents with multi-crop portfolios, geographic constraints, and
fairness. First, we address a matching problem where the goal is to maximize a
welfare function in two-sided markets where buyers' requirements and sellers'
supplies are represented by value functions that assign prices (or costs) to
specified volumes of water. For the setting where the value functions satisfy
certain monotonicity properties, we present an efficient algorithm that
maximizes a social welfare function. When there are minimum water requirement
constraints, we present a randomized algorithm which ensures that the
constraints are satisfied in expectation. For a single seller--multiple buyers
setting with fairness constraints, we design an efficient algorithm that
maximizes the minimum level of satisfaction of any buyer. We also present
computational complexity results that highlight the limits on the
generalizability of our results. We evaluate the algorithms developed in our
work with experiments on both real-world and synthetic data sets with respect
to drought severity, value functions, and seniority of agents.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06578" title="Abstract">arXiv:2402.06578</a> [<a href="/pdf/2402.06578" title="Download PDF">pdf</a>, <a href="/format/2402.06578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Universality of Coupling-based Normalizing Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Draxler%2C+F">Felix Draxler</a>, 
<a href="/search/cs?searchtype=author&query=Wahl%2C+S">Stefan Wahl</a>, 
<a href="/search/cs?searchtype=author&query=Schn%C3%B6rr%2C+C">Christoph Schn&#xf6;rr</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6the%2C+U">Ullrich K&#xf6;the</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We present a novel theoretical framework for understanding the expressive
power of coupling-based normalizing flows such as RealNVP. Despite their
prevalence in scientific applications, a comprehensive understanding of
coupling flows remains elusive due to their restricted architectures. Existing
theorems fall short as they require the use of arbitrarily ill-conditioned
neural networks, limiting practical applicability. Additionally, we demonstrate
that these constructions inherently lead to volume-preserving flows, a property
which we show to be a fundamental constraint for expressivity. We propose a new
distributional universality theorem for coupling-based normalizing flows, which
overcomes several limitations of prior work. Our results support the general
wisdom that the coupling architecture is expressive and provide a nuanced view
for choosing the expressivity of coupling functions, bridging a gap between
empirical results and theoretical understanding.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06580" title="Abstract">arXiv:2402.06580</a> [<a href="/pdf/2402.06580" title="Download PDF">pdf</a>, <a href="/format/2402.06580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAE: Single Architecture Ensemble Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferianc%2C+M">Martin Ferianc</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Hongxiang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Rodrigues%2C+M">Miguel Rodrigues</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Ensembles of separate neural networks (NNs) have shown superior accuracy and
confidence calibration over single NN across tasks. Recent methods compress
ensembles within a single network via early exits or multi-input multi-output
frameworks. However, the landscape of these methods is fragmented thus far,
making it difficult to choose the right approach for a given task. Furthermore,
the algorithmic performance of these methods is behind the ensemble of separate
NNs and requires extensive architecture tuning. We propose a novel methodology
unifying these approaches into a Single Architecture Ensemble (SAE). Our method
learns the optimal number and depth of exits per ensemble input in a single NN.
This enables the SAE framework to flexibly tailor its configuration for a given
architecture or application. We evaluate SAEs on image classification and
regression across various network architecture types and sizes. We demonstrate
competitive accuracy or confidence calibration to baselines while reducing the
compute operations or parameter count by up to $1.5{\sim}3.7\times$.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06581" title="Abstract">arXiv:2402.06581</a> [<a href="/pdf/2402.06581" title="Download PDF">pdf</a>, <a href="/format/2402.06581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> More than the Sum of Its Parts: Ensembling Backbone Networks for  Few-Shot Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Catalano%2C+N">Nico Catalano</a>, 
<a href="/search/cs?searchtype=author&query=Maranelli%2C+A">Alessandro Maranelli</a>, 
<a href="/search/cs?searchtype=author&query=Chiatti%2C+A">Agnese Chiatti</a>, 
<a href="/search/cs?searchtype=author&query=Matteucci%2C+M">Matteo Matteucci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Semantic segmentation is a key prerequisite to robust image understanding for
applications in \acrlong{ai} and Robotics. \acrlong{fss}, in particular,
concerns the extension and optimization of traditional segmentation methods in
challenging conditions where limited training examples are available. A
predominant approach in \acrlong{fss} is to rely on a single backbone for
visual feature extraction. Choosing which backbone to leverage is a deciding
factor contributing to the overall performance. In this work, we interrogate on
whether fusing features from different backbones can improve the ability of
\acrlong{fss} models to capture richer visual features. To tackle this
question, we propose and compare two ensembling techniques-Independent Voting
and Feature Fusion. Among the available \acrlong{fss} methods, we implement the
proposed ensembling techniques on PANet. The module dedicated to predicting
segmentation masks from the backbone embeddings in PANet avoids trainable
parameters, creating a controlled `in vitro' setting for isolating the impact
of different ensembling strategies. Leveraging the complementary strengths of
different backbones, our approach outperforms the original single-backbone
PANet across standard benchmarks even in challenging one-shot learning
scenarios. Specifically, it achieved a performance improvement of +7.37\% on
PASCAL-5\textsuperscript{i} and of +10.68\% on COCO-20\textsuperscript{i} in
the top-performing scenario where three backbones are combined. These results,
together with the qualitative inspection of the predicted subject masks,
suggest that relying on multiple backbones in PANet leads to a more
comprehensive feature representation, thus expediting the successful
application of \acrlong{fss} methods in challenging, data-scarce environments.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06584" title="Abstract">arXiv:2402.06584</a> [<a href="/pdf/2402.06584" title="Download PDF">pdf</a>, <a href="/format/2402.06584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> G-SciEdBERT: A Contextualized LLM for Science Assessment Tasks in German
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Latif%2C+E">Ehsan Latif</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Gyeong-Geon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Neuman%2C+K">Knut Neuman</a>, 
<a href="/search/cs?searchtype=author&query=Kastorff%2C+T">Tamara Kastorff</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaoming Zhai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First German Science Education LLM, Submitted to AIED2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The advancement of natural language processing has paved the way for
automated scoring systems in various languages, such as German (e.g., German
BERT [G-BERT]). Automatically scoring written responses to science questions in
German is a complex task and challenging for standard G-BERT as they lack
contextual knowledge in the science domain and may be unaligned with student
writing styles. This paper developed a contextualized German Science Education
BERT (G-SciEdBERT), an innovative large language model tailored for scoring
German-written responses to science tasks. Using G-BERT, we pre-trained
G-SciEdBERT on a corpus of 50K German written science responses with 5M tokens
to the Programme for International Student Assessment (PISA) 2015. We
fine-tuned G-SciEdBERT on 59 assessment items and examined the scoring
accuracy. We then compared its performance with G-BERT. Our findings reveal a
substantial improvement in scoring accuracy with G-SciEdBERT, demonstrating a
10% increase of quadratic weighted kappa compared to G-BERT (mean accuracy
difference = 0.096, SD = 0.024). These insights underline the significance of
specialized language models like G-SciEdBERT, which is trained to enhance the
accuracy of automated scoring, offering a substantial contribution to the field
of AI in education.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06586" title="Abstract">arXiv:2402.06586</a> [<a href="/pdf/2402.06586" title="Download PDF">pdf</a>, <a href="/format/2402.06586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analytical model for the relation between signal bandwidth and spatial  resolution in Steered-Response Power Phase Transform (SRP-PHAT) maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garcia-Barrios%2C+G">Guillermo Garcia-Barrios</a>, 
<a href="/search/cs?searchtype=author&query=Gutierrez-Arriola%2C+J+M">Juana M. Gutierrez-Arriola</a>, 
<a href="/search/cs?searchtype=author&query=Saenz-Lechon%2C+N">Nicolas Saenz-Lechon</a>, 
<a href="/search/cs?searchtype=author&query=Osma-Ruiz%2C+V+J">Victor Jose Osma-Ruiz</a>, 
<a href="/search/cs?searchtype=author&query=Fraile%2C+R">Ruben Fraile</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Any paper that cite this one has to thank IEEE for easing the open access of the article
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)

</div>
<p class="mathjax">An analysis of the relationship between the bandwidth of acoustic signals and
the required resolution of steered-response power phase transform (SRP-PHAT)
maps used for sound source localization is presented. This relationship does
not rely on the far-field assumption, nor does it depend on any specific array
topology. The proposed analysis considers the computation of a SRP map as a
process of sampling a set of generalized cross-correlation (GCC) functions,
each one corresponding to a different microphone pair. From this approach, we
derive a rule that relates GCC bandwidth with inter-microphone distance,
resolution of the SRP map, and the potential position of the sound source
relative to the array position. This rule is a sufficient condition for an
aliasing-free calculation of the specified SRP-PHAT map. Simulation results
show that limiting the bandwidth of the GCC according to such rule leads to
significant reductions in sound source localization errors when sources are not
in the immediate vicinity of the microphone array. These error reductions are
more relevant for coarser resolutions of the SRP map, and they happen in both
anechoic and reverberant environments.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06589" title="Abstract">arXiv:2402.06589</a> [<a href="/pdf/2402.06589" title="Download PDF">pdf</a>, <a href="/format/2402.06589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modular Redesign of Mechatronic Systems: Formulation of Module  Specifications Guaranteeing System Dynamics Specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Janssen%2C+L+A+L">Lars A. L. Janssen</a>, 
<a href="/search/eess?searchtype=author&query=Fey%2C+R+H+B">Rob H. B. Fey</a>, 
<a href="/search/eess?searchtype=author&query=Besselink%2C+B">Bart Besselink</a>, 
<a href="/search/eess?searchtype=author&query=van+de+Wouw%2C+N">Nathan van de Wouw</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Complex mechatronic systems are typically composed of interconnected modules,
often developed by independent teams. This development process challenges the
verification of system specifications before all modules are integrated. To
address this challenge, a modular redesign framework is proposed in this paper.
Herein, first, allowed changes in the dynamics (represented by frequency
response functions (FRFs)) of the redesigned system are defined with respect to
the original system model, which already satisfies system specifications.
Second, these allowed changes in the overall system dynamics (or system
redesign specifications) are automatically translated to dynamics (FRF)
specifications on module level that, when satisfied, guarantee overall system
dynamics (FRF) specifications. This modularity in specification management
supports local analysis and verification of module design changes, enabling
design teams to work in parallel without the need to iteratively rebuild the
system model to check fulfilment of system FRF specifications. A modular
redesign process results that shortens time-to-market and decreases redesign
costs. The framework's effectiveness is demonstrated through three examples of
increasing complexity, highlighting its potential to enable modular mechatronic
system (re)design.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06590" title="Abstract">arXiv:2402.06590</a> [<a href="/pdf/2402.06590" title="Download PDF">pdf</a>, <a href="/format/2402.06590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predictive representations: building blocks of intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carvalho%2C+W">Wilka Carvalho</a>, 
<a href="/search/cs?searchtype=author&query=Tomov%2C+M+S">Momchil S. Tomov</a>, 
<a href="/search/cs?searchtype=author&query=de+Cothi%2C+W">William de Cothi</a>, 
<a href="/search/cs?searchtype=author&query=Barry%2C+C">Caswell Barry</a>, 
<a href="/search/cs?searchtype=author&query=Gershman%2C+S+J">Samuel J. Gershman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Adaptive behavior often requires predicting future events. The theory of
reinforcement learning prescribes what kinds of predictive representations are
useful and how to compute them. This paper integrates these theoretical ideas
with work on cognition and neuroscience. We pay special attention to the
successor representation (SR) and its generalizations, which have been widely
applied both as engineering tools and models of brain function. This
convergence suggests that particular kinds of predictive representations may
function as versatile building blocks of intelligence.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06591" title="Abstract">arXiv:2402.06591</a> [<a href="/pdf/2402.06591" title="Download PDF">pdf</a>, <a href="/format/2402.06591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random DFA With One Added Transition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carayol%2C+A">Arnaud Carayol</a>, 
<a href="/search/cs?searchtype=author&query=Duchon%2C+P">Philippe Duchon</a>, 
<a href="/search/cs?searchtype=author&query=Koechlin%2C+F">Florent Koechlin</a>, 
<a href="/search/cs?searchtype=author&query=Nicaud%2C+C">Cyril Nicaud</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 4 figures, extended version of STACS'2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Every language recognized by a non-deterministic finite automaton can be
recognized by a deterministic automaton, at the cost of a potential increase of
the number of states, which in the worst case can go from $n$ states to $2^n$
states. In this article, we investigate this classical result in a
probabilistic setting where we take a deterministic automaton with $n$ states
uniformly at random and add just one random transition. These automata are
almost deterministic in the sense that only one state has a non-deterministic
choice when reading an input letter. In our model, each state has a fixed
probability to be final. We prove that for any $d\geq 1$, with non-negligible
probability the minimal (deterministic) automaton of the language recognized by
such an automaton has more than $n^d$ states; as a byproduct, the expected size
of its minimal automaton grows faster than any polynomial. Our result also
holds when each state is final with some probability that depends on $n$, as
long as it is not too close to $0$ and $1$, at distance at least
$\Omega(\frac1{\sqrt{n}})$ to be precise, therefore allowing models with a
sublinear number of final states in expectation.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06592" title="Abstract">arXiv:2402.06592</a> [<a href="/pdf/2402.06592" title="Download PDF">pdf</a>, <a href="/format/2402.06592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-consistent context aware conformer transducer for speech  recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kolokolov%2C+K">Konstantin Kolokolov</a>, 
<a href="/search/cs?searchtype=author&query=Pekichev%2C+P">Pavel Pekichev</a>, 
<a href="/search/cs?searchtype=author&query=Raghunathan%2C+K">Karthik Raghunathan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We propose a novel neural network architecture based on conformer transducer
that adds contextual information flow to the ASR systems. Our method improves
the accuracy of recognizing uncommon words while not harming the word error
rate of regular words. We explore the uncommon words accuracy improvement when
we use the new model and/or shallow fusion with context language model. We
found that combination of both provides cumulative gain in uncommon words
recognition accuracy.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06596" title="Abstract">arXiv:2402.06596</a> [<a href="/pdf/2402.06596" title="Download PDF">pdf</a>, <a href="/format/2402.06596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Weakness of Large Language Model Agents within a  Complex Android Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+M">Mingzhe Xing</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rongkai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Hui Xue</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zhen Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC); Software Engineering (cs.SE)

</div>
<p class="mathjax">Large language models (LLMs) have empowered intelligent agents to execute
intricate tasks within domain-specific software such as browsers and games.
However, when applied to general-purpose software systems like operating
systems, LLM agents face three primary challenges. Firstly, the action space is
vast and dynamic, posing difficulties for LLM agents to maintain an up-to-date
understanding and deliver accurate responses. Secondly, real-world tasks often
require inter-application cooperation}, demanding farsighted planning from LLM
agents. Thirdly, agents need to identify optimal solutions aligning with user
constraints, such as security concerns and preferences. These challenges
motivate AndroidArena, an environment and benchmark designed to evaluate LLM
agents on a modern operating system. To address high-cost of manpower, we
design a scalable and semi-automated method to construct the benchmark. In the
task evaluation, AndroidArena incorporates accurate and adaptive metrics to
address the issue of non-unique solutions. Our findings reveal that even
state-of-the-art LLM agents struggle in cross-APP scenarios and adhering to
specific constraints. Additionally, we identify a lack of four key
capabilities, i.e., understanding, reasoning, exploration, and reflection, as
primary reasons for the failure of LLM agents. Furthermore, we provide
empirical analysis on the failure of reflection, and improve the success rate
by 27% with our proposed exploration strategy. This work is the first to
present valuable insights in understanding fine-grained weakness of LLM agents,
and offers a path forward for future research in this area. Environment,
benchmark, and evaluation code for AndroidArena are released at
https://github.com/AndroidArenaAgent/AndroidArena.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06598" title="Abstract">arXiv:2402.06598</a> [<a href="/pdf/2402.06598" title="Download PDF">pdf</a>, <a href="/format/2402.06598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CigaR: Cost-efficient Program Repair with LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hidv%C3%A9gi%2C+D">D&#xe1;vid Hidv&#xe9;gi</a>, 
<a href="/search/cs?searchtype=author&query=Etemadi%2C+K">Khashayar Etemadi</a>, 
<a href="/search/cs?searchtype=author&query=Bobadilla%2C+S">Sofia Bobadilla</a>, 
<a href="/search/cs?searchtype=author&query=Monperrus%2C+M">Martin Monperrus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Large language models (LLM) have proven to be effective at automated program
repair (APR). However, using LLMs can be highly costly, with companies
invoicing users by the number of tokens. In this paper, we propose CigaR, the
first LLM-based APR tool that focuses on minimizing the repair cost. CigaR
works in two major steps: generating a plausible patch and multiplying
plausible patches. CigaR optimizes the prompts and the prompt setting to
maximize the information given to LLMs in the smallest possible number of
tokens. Our experiments on 267 bugs from the widely used Defects4J dataset
shows that CigaR reduces the token cost by 62. On average, CigaR spends 171k
tokens per bug while the baseline uses 451k tokens. On the subset of bugs that
are fixed by both, CigaR spends 20k per bug while the baseline uses 695k
tokens, a cost saving of 97. Our extensive experiments show that CigaR is a
cost-effective LLM-based program repair tool that uses a low number of tokens
to generate automatic patches.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06599" title="Abstract">arXiv:2402.06599</a> [<a href="/pdf/2402.06599" title="Download PDF">pdf</a>, <a href="/format/2402.06599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Out-Of-Distribution Generalization of Multimodal Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiansheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+W">Wenjing Chu</a>, 
<a href="/search/cs?searchtype=author&query=Hai%2C+J">Junjia Hai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Renzhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuqing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+S">Shikai Guan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiazheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+P">Peng Cui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We investigate the generalization boundaries of current Multimodal Large
Language Models (MLLMs) via comprehensive evaluation under out-of-distribution
scenarios and domain-specific tasks. We evaluate their zero-shot generalization
across synthetic images, real-world distributional shifts, and specialized
datasets like medical and molecular imagery. Empirical results indicate that
MLLMs struggle with generalization beyond common training domains, limiting
their direct application without adaptation. To understand the cause of
unreliable performance, we analyze three hypotheses: semantic
misinterpretation, visual feature extraction insufficiency, and mapping
deficiency. Results identify mapping deficiency as the primary hurdle. To
address this problem, we show that in-context learning (ICL) can significantly
enhance MLLMs' generalization, opening new avenues for overcoming
generalization barriers. We further explore the robustness of ICL under
distribution shifts and show its vulnerability to domain shifts, label shifts,
and spurious correlation shifts between in-context examples and test data.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06606" title="Abstract">arXiv:2402.06606</a> [<a href="/pdf/2402.06606" title="Download PDF">pdf</a>, <a href="/format/2402.06606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RQP-SGD: Differential Private Machine Learning through Noisy SGD and  Randomized Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Ce Feng</a>, 
<a href="/search/cs?searchtype=author&query=Venkitasubramaniam%2C+P">Parv Venkitasubramaniam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is accepted by the 5th AAAI Workshop on Privacy-Preserving Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The rise of IoT devices has prompted the demand for deploying machine
learning at-the-edge with real-time, efficient, and secure data processing. In
this context, implementing machine learning (ML) models with real-valued weight
parameters can prove to be impractical particularly for large models, and there
is a need to train models with quantized discrete weights. At the same time,
these low-dimensional models also need to preserve privacy of the underlying
dataset. In this work, we present RQP-SGD, a new approach for
privacy-preserving quantization to train machine learning models for low-memory
ML-at-the-edge. This approach combines differentially private stochastic
gradient descent (DP-SGD) with randomized quantization, providing a measurable
privacy guarantee in machine learning. In particular, we study the utility
convergence of implementing RQP-SGD on ML tasks with convex objectives and
quantization constraints and demonstrate its efficacy over deterministic
quantization. Through experiments conducted on two datasets, we show the
practical effectiveness of RQP-SGD.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06608" title="Abstract">arXiv:2402.06608</a> [<a href="/pdf/2402.06608" title="Download PDF">pdf</a>, <a href="/format/2402.06608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TIC: Translate-Infer-Compile for accurate &#x27;text to plan&#x27; using LLMs and  logical intermediate representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+S">Sudhir Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Sreepathy%2C+A">Anu Sreepathy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages (7 main + 2 references + 11 appendix), 4 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We study the problem of generating plans for given natural language planning
task requests. On one hand, LLMs excel at natural language processing but do
not perform well on planning. On the other hand, classical planning tools excel
at planning tasks but require input in a structured language such as the
Planning Domain Definition Language (PDDL). We leverage the strengths of both
the techniques by using an LLM for generating the PDDL representation (task
PDDL) of planning task requests followed by using a classical planner for
computing a plan. Unlike previous approaches that use LLMs for generating task
PDDLs directly, our approach comprises of (a) translate: using an LLM only for
generating a logically interpretable intermediate representation of natural
language task descriptions, (b) infer: deriving additional logically dependent
information from the intermediate representation using a logic reasoner
(currently, Answer Set Programming solver), and (c) compile: generating the
target task PDDL from the base and inferred information. We observe that using
an LLM to only output the intermediate representation significantly reduces LLM
errors. Consequently, TIC approach achieves, for at least one LLM, high
accuracy on task PDDL generation for all seven domains of our evaluation
dataset.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06609" title="Abstract">arXiv:2402.06609</a> [<a href="/pdf/2402.06609" title="Download PDF">pdf</a>, <a href="/format/2402.06609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> You Still See Me: How Data Protection Supports the Architecture of ML  Surveillance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yew%2C+R">Rui-Jie Yew</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+L">Lucy Qin</a>, 
<a href="/search/cs?searchtype=author&query=Venkatasubramanian%2C+S">Suresh Venkatasubramanian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Data forms the backbone of machine learning. Thus, data protection law has
strong bearing on how ML systems are governed. Given that most requirements
accompany the processing of personal data, organizations have an incentive to
keep their data out of legal scope. Privacy-preserving techniques incentivized
by data protection law -- data protection techniques -- constitute an important
strategy for ML development because they are used to distill data until it
potentially falls outside the scope of data protection laws.
<br />In this paper, we examine the impact of a rhetoric that deems data wrapped in
privacy-preserving techniques as data that is "good-to-go". We show how the
application of data protection techniques in the development of ML systems --
from private set intersection as part of dataset curation to homomorphic
encryption and federated learning as part of model computation to the framing
of the privacy-utility trade-off as part of model updating -- can further
support individual monitoring and data consolidation. With data accumulation at
the core of how the ML pipeline is configured, we argue that data protection
techniques are often instrumentalized in ways that support infrastructures of
surveillance, rather than to protect individuals associated with data. Finally,
we propose technology and policy strategies to evaluate data protection
techniques in light of the protections they actually confer. We conclude by
highlighting the role that security technologists might play in devising
policies that combat surveillance ML technologies -- recommending the
adversarial mindset inherent to the profession to more precisely articulate and
prevent the use of "privacy-preserving" scaffoldings that support surveillance.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06611" title="Abstract">arXiv:2402.06611</a> [<a href="/pdf/2402.06611" title="Download PDF">pdf</a>, <a href="/format/2402.06611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image-based Deep Learning for the time-dependent prediction of fresh  concrete properties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meyer%2C+M">Max Meyer</a>, 
<a href="/search/cs?searchtype=author&query=Langer%2C+A">Amadeus Langer</a>, 
<a href="/search/cs?searchtype=author&query=Mehltretter%2C+M">Max Mehltretter</a>, 
<a href="/search/cs?searchtype=author&query=Beyer%2C+D">Dries Beyer</a>, 
<a href="/search/cs?searchtype=author&query=Coenen%2C+M">Max Coenen</a>, 
<a href="/search/cs?searchtype=author&query=Schack%2C+T">Tobias Schack</a>, 
<a href="/search/cs?searchtype=author&query=Haist%2C+M">Michael Haist</a>, 
<a href="/search/cs?searchtype=author&query=Heipke%2C+C">Christian Heipke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Increasing the degree of digitisation and automation in the concrete
production process can play a crucial role in reducing the CO$_2$ emissions
that are associated with the production of concrete. In this paper, a method is
presented that makes it possible to predict the properties of fresh concrete
during the mixing process based on stereoscopic image sequences of the
concretes flow behaviour. A Convolutional Neural Network (CNN) is used for the
prediction, which receives the images supported by information on the mix
design as input. In addition, the network receives temporal information in the
form of the time difference between the time at which the images are taken and
the time at which the reference values of the concretes are carried out. With
this temporal information, the network implicitly learns the time-dependent
behaviour of the concretes properties. The network predicts the slump flow
diameter, the yield stress and the plastic viscosity. The time-dependent
prediction potentially opens up the pathway to determine the temporal
development of the fresh concrete properties already during mixing. This
provides a huge advantage for the concrete industry. As a result,
countermeasures can be taken in a timely manner. It is shown that an approach
based on depth and optical flow images, supported by information of the mix
design, achieves the best results.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06614" title="Abstract">arXiv:2402.06614</a> [<a href="/pdf/2402.06614" title="Download PDF">pdf</a>, <a href="/format/2402.06614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Complexity of Sequential Prediction in Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raman%2C+V">Vinod Raman</a>, 
<a href="/search/cs?searchtype=author&query=Subedi%2C+U">Unique Subedi</a>, 
<a href="/search/cs?searchtype=author&query=Tewari%2C+A">Ambuj Tewari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the problem of learning to predict the next state of a dynamical
system when the underlying evolution function is unknown. Unlike previous work,
we place no parametric assumptions on the dynamical system, and study the
problem from a learning theory perspective. We define new combinatorial
measures and dimensions and show that they quantify the optimal mistake and
regret bounds in the realizable and agnostic setting respectively.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06617" title="Abstract">arXiv:2402.06617</a> [<a href="/pdf/2402.06617" title="Download PDF">pdf</a>, <a href="/format/2402.06617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FaBERT: Pre-training BERT on Persian Blogs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Masumi%2C+M">Mostafa Masumi</a>, 
<a href="/search/cs?searchtype=author&query=Majd%2C+S+S">Seyed Soroush Majd</a>, 
<a href="/search/cs?searchtype=author&query=Shamsfard%2C+M">Mehrnoush Shamsfard</a>, 
<a href="/search/cs?searchtype=author&query=Beigy%2C+H">Hamid Beigy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We introduce FaBERT, a Persian BERT-base model pre-trained on the HmBlogs
corpus, encompassing both informal and formal Persian texts. FaBERT is designed
to excel in traditional Natural Language Understanding (NLU) tasks, addressing
the intricacies of diverse sentence structures and linguistic styles prevalent
in the Persian language. In our comprehensive evaluation of FaBERT on 12
datasets in various downstream tasks, encompassing Sentiment Analysis (SA),
Named Entity Recognition (NER), Natural Language Inference (NLI), Question
Answering (QA), and Question Paraphrasing (QP), it consistently demonstrated
improved performance, all achieved within a compact model size. The findings
highlight the importance of utilizing diverse and cleaned corpora, such as
HmBlogs, to enhance the performance of language models like BERT in Persian
Natural Language Processing (NLP) applications. FaBERT is openly accessible at
https://huggingface.co/sbunlp/fabert
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06619" title="Abstract">arXiv:2402.06619</a> [<a href="/pdf/2402.06619" title="Download PDF">pdf</a>, <a href="/format/2402.06619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aya Dataset: An Open-Access Collection for Multilingual Instruction  Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Shivalika Singh</a>, 
<a href="/search/cs?searchtype=author&query=Vargus%2C+F">Freddie Vargus</a>, 
<a href="/search/cs?searchtype=author&query=Dsouza%2C+D">Daniel Dsouza</a>, 
<a href="/search/cs?searchtype=author&query=Karlsson%2C+B+F">B&#xf6;rje F. Karlsson</a>, 
<a href="/search/cs?searchtype=author&query=Mahendiran%2C+A">Abinaya Mahendiran</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+W">Wei-Yin Ko</a>, 
<a href="/search/cs?searchtype=author&query=Shandilya%2C+H">Herumb Shandilya</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+J">Jay Patel</a>, 
<a href="/search/cs?searchtype=author&query=Mataciunas%2C+D">Deividas Mataciunas</a>, 
<a href="/search/cs?searchtype=author&query=OMahony%2C+L">Laura OMahony</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mike Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hettiarachchi%2C+R">Ramith Hettiarachchi</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+J">Joseph Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Machado%2C+M">Marina Machado</a>, 
<a href="/search/cs?searchtype=author&query=Moura%2C+L+S">Luisa Souza Moura</a>, 
<a href="/search/cs?searchtype=author&query=Krzemi%C5%84ski%2C+D">Dominik Krzemi&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Fadaei%2C+H">Hakimeh Fadaei</a>, 
<a href="/search/cs?searchtype=author&query=Erg%C3%BCn%2C+I">Irem Erg&#xfc;n</a>, 
<a href="/search/cs?searchtype=author&query=Okoh%2C+I">Ifeoma Okoh</a>, 
<a href="/search/cs?searchtype=author&query=Alaagib%2C+A">Aisha Alaagib</a>, 
<a href="/search/cs?searchtype=author&query=Mudannayake%2C+O">Oshan Mudannayake</a>, 
<a href="/search/cs?searchtype=author&query=Alyafeai%2C+Z">Zaid Alyafeai</a>, 
<a href="/search/cs?searchtype=author&query=Chien%2C+V+M">Vu Minh Chien</a>, 
<a href="/search/cs?searchtype=author&query=Ruder%2C+S">Sebastian Ruder</a>, 
<a href="/search/cs?searchtype=author&query=Guthikonda%2C+S">Surya Guthikonda</a>, 
<a href="/search/cs?searchtype=author&query=Alghamdi%2C+E+A">Emad A. Alghamdi</a>, 
<a href="/search/cs?searchtype=author&query=Gehrmann%2C+S">Sebastian Gehrmann</a>, 
<a href="/search/cs?searchtype=author&query=Muennighoff%2C+N">Niklas Muennighoff</a>, 
<a href="/search/cs?searchtype=author&query=Bartolo%2C+M">Max Bartolo</a>, 
<a href="/search/cs?searchtype=author&query=Kreutzer%2C+J">Julia Kreutzer</a>, 
<a href="/search/cs?searchtype=author&query=%C3%9Cst%C3%BCn%2C+A">Ahmet &#xdc;st&#xfc;n</a>, 
<a href="/search/cs?searchtype=author&query=Fadaee%2C+M">Marzieh Fadaee</a>, 
<a href="/search/cs?searchtype=author&query=Hooker%2C+S">Sara Hooker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Datasets are foundational to many breakthroughs in modern artificial
intelligence. Many recent achievements in the space of natural language
processing (NLP) can be attributed to the finetuning of pre-trained models on a
diverse set of tasks that enables a large language model (LLM) to respond to
instructions. Instruction fine-tuning (IFT) requires specifically constructed
and annotated datasets. However, existing datasets are almost all in the
English language. In this work, our primary goal is to bridge the language gap
by building a human-curated instruction-following dataset spanning 65
languages. We worked with fluent speakers of languages from around the world to
collect natural instances of instructions and completions. Furthermore, we
create the most extensive multilingual collection to date, comprising 513
million instances through templating and translating existing datasets across
114 languages. In total, we contribute four key resources: we develop and
open-source the Aya Annotation Platform, the Aya Dataset, the Aya Collection,
and the Aya Evaluation Suite. The Aya initiative also serves as a valuable case
study in participatory research, involving collaborators from 119 countries. We
see this as a valuable framework for future research collaborations that aim to
bridge gaps in resources.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06622" title="Abstract">arXiv:2402.06622</a> [<a href="/pdf/2402.06622" title="Download PDF">pdf</a>, <a href="/ps/2402.06622" title="Download PostScript">ps</a>, <a href="/format/2402.06622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A two-stage algorithm in evolutionary product unit neural networks for  classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tall%C3%B3n-Ballesteros%2C+A+J">Antonio J. Tall&#xf3;n-Ballesteros</a>, 
<a href="/search/cs?searchtype=author&query=Herv%C3%A1s-Mart%C3%ADnez%2C+C">C&#xe9;sar Herv&#xe1;s-Mart&#xed;nez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Tall\'on-Ballesteros, A. J., &amp; Herv\'as-Mart\'inez, C. (2011). A
  two-stage algorithm in evolutionary product unit neural networks for
  classification. Expert Systems with Applications, 38(1), 743-754
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">This paper presents a procedure to add broader diversity at the beginning of
the evolutionary process. It consists of creating two initial populations with
different parameter settings, evolving them for a small number of generations,
selecting the best individuals from each population in the same proportion and
combining them to constitute a new initial population. At this point the main
loop of an evolutionary algorithm is applied to the new population. The results
show that our proposal considerably improves both the efficiency of previous
methodologies and also, significantly, their efficacy in most of the data sets.
We have carried out our experimentation on twelve data sets from the UCI
repository and two complex real-world problems which differ in their number of
instances, features and classes.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06624" title="Abstract">arXiv:2402.06624</a> [<a href="/pdf/2402.06624" title="Download PDF">pdf</a>, <a href="/format/2402.06624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empirically Exploring How Novices Write Software Models in Alloy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jovanovic%2C+A">Ana Jovanovic</a>, 
<a href="/search/cs?searchtype=author&query=Sullivan%2C+A">Allison Sullivan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Writing declarative models has numerous benefits, ranging from automated
reasoning and correction of design-level properties before systems are built,
to automated testing and debugging of their implementations after they are
built. Alloy is a declarative modeling language that is well-suited for
verifying system designs. A key strength of Alloy is its scenario-finding
toolset, the Analyzer, which allows users to explore all valid scenarios that
adhere to the model's constraints up to a user-provided scope. However, even
with visualized scenarios, it is difficult to write correct Alloy models. To
address this, a growing body of work explores different techniques for
debugging Alloy models. In order to develop and evaluate these techniques in an
effective manor, this paper presents an empirical study of over 97,000 models
written by novice users trying to learn Alloy. We investigate how users write
both correct and incorrect models in order to produce a comprehensive benchmark
for future use as well as a series of observations to guide debugging and
educational efforts for Alloy model development.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06625" title="Abstract">arXiv:2402.06625</a> [<a href="/pdf/2402.06625" title="Download PDF">pdf</a>, <a href="/format/2402.06625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Effects of Iterative Prompting on Truthfulness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishna%2C+S">Satyapriya Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+C">Chirag Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Lakkaraju%2C+H">Himabindu Lakkaraju</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The development of Large Language Models (LLMs) has notably transformed
numerous sectors, offering impressive text generation capabilities. Yet, the
reliability and truthfulness of these models remain pressing concerns. To this
end, we investigate iterative prompting, a strategy hypothesized to refine LLM
responses, assessing its impact on LLM truthfulness, an area which has not been
thoroughly explored. Our extensive experiments delve into the intricacies of
iterative prompting variants, examining their influence on the accuracy and
calibration of model responses. Our findings reveal that naive prompting
methods significantly undermine truthfulness, leading to exacerbated
calibration errors. In response to these challenges, we introduce several
prompting variants designed to address the identified issues. These variants
demonstrate marked improvements over existing baselines, signaling a promising
direction for future research. Our work provides a nuanced understanding of
iterative prompting and introduces novel approaches to enhance the truthfulness
of LLMs, thereby contributing to the development of more accurate and
trustworthy AI systems.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06626" title="Abstract">arXiv:2402.06626</a> [<a href="/pdf/2402.06626" title="Download PDF">pdf</a>, <a href="/ps/2402.06626" title="Download PostScript">ps</a>, <a href="/format/2402.06626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Optimal Commitments to Strategies and Outcome-Conditional  Utility Transfers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sauerberg%2C+N">Nathaniel Sauerberg</a>, 
<a href="/search/cs?searchtype=author&query=Oesterheld%2C+C">Caspar Oesterheld</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAMAS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Prior work has studied the computational complexity of computing optimal
strategies to commit to in Stackelberg or leadership games, where a leader
commits to a strategy which is observed by one or more followers. We extend
this setting to one where the leader can additionally commit to
outcome-conditional utility transfers. We characterize the computational
complexity of finding optimal strategies in normal-form and Bayesian games,
giving a mix of efficient algorithms and NP-hardness results. Finally, we allow
the leader to also commit to a signaling scheme which induces a correlated
equilibrium. In this setting, optimal commitments can be found in polynomial
time for arbitrarily many players.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06627" title="Abstract">arXiv:2402.06627</a> [<a href="/pdf/2402.06627" title="Download PDF">pdf</a>, <a href="/format/2402.06627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feedback Loops With Language Models Drive In-Context Reward Hacking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+A">Alexander Pan</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+E">Erik Jones</a>, 
<a href="/search/cs?searchtype=author&query=Jagadeesan%2C+M">Meena Jagadeesan</a>, 
<a href="/search/cs?searchtype=author&query=Steinhardt%2C+J">Jacob Steinhardt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Language models influence the external world: they query APIs that read and
write to web pages, generate content that shapes human behavior, and run system
commands as autonomous agents. These interactions form feedback loops: LLM
outputs affect the world, which in turn affect subsequent LLM outputs. In this
work, we show that feedback loops can cause in-context reward hacking (ICRH),
where the LLM at test-time optimizes a (potentially implicit) objective but
creates negative side effects in the process. For example, consider an LLM
agent deployed to increase Twitter engagement; the LLM may retrieve its
previous tweets into the context window and make them more controversial,
increasing engagement but also toxicity. We identify and study two processes
that lead to ICRH: output-refinement and policy-refinement. For these
processes, evaluations on static datasets are insufficient -- they miss the
feedback effects and thus cannot capture the most harmful behavior. In
response, we provide three recommendations for evaluation to capture more
instances of ICRH. As AI development accelerates, the effects of feedback loops
will proliferate, increasing the need to understand their role in shaping LLM
behavior.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Mon, 12 Feb 24</h3>
<dl>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05953" title="Abstract">arXiv:2402.05953</a> (cross-list from q-bio.QM) [<a href="/pdf/2402.05953" title="Download PDF">pdf</a>, <a href="/format/2402.05953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> idMotif: An Interactive Motif Identification in Protein Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Park%2C+J+H">Ji Hwan Park</a>, 
<a href="/search/q-bio?searchtype=author&query=Prasad%2C+V">Vikash Prasad</a>, 
<a href="/search/q-bio?searchtype=author&query=Newsom%2C+S">Sydney Newsom</a>, 
<a href="/search/q-bio?searchtype=author&query=Najar%2C+F">Fares Najar</a>, 
<a href="/search/q-bio?searchtype=author&query=Rajan%2C+R">Rakhi Rajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE CGA
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> idMotif: An Interactive Motif Identification in Protein
  Sequences," in IEEE Computer Graphics and Applications, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Graphics (cs.GR); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">This article introduces idMotif, a visual analytics framework designed to aid
domain experts in the identification of motifs within protein sequences.
Motifs, short sequences of amino acids, are critical for understanding the
distinct functions of proteins. Identifying these motifs is pivotal for
predicting diseases or infections. idMotif employs a deep learning-based method
for the categorization of protein sequences, enabling the discovery of
potential motif candidates within protein groups through local explanations of
deep learning model decisions. It offers multiple interactive views for the
analysis of protein clusters or groups and their sequences. A case study,
complemented by expert feedback, illustrates idMotif's utility in facilitating
the analysis and identification of protein sequences and motifs.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05961" title="Abstract">arXiv:2402.05961</a> (cross-list from q-bio.BM) [<a href="/pdf/2402.05961" title="Download PDF">pdf</a>, <a href="/format/2402.05961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Genetic-guided GFlowNets: Advancing in Practical Molecular Optimization  Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Kim%2C+H">Hyeonah Kim</a>, 
<a href="/search/q-bio?searchtype=author&query=Kim%2C+M">Minsu Kim</a>, 
<a href="/search/q-bio?searchtype=author&query=Choi%2C+S">Sanghyeok Choi</a>, 
<a href="/search/q-bio?searchtype=author&query=Park%2C+J">Jinkyoo Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages (including 9 pages of appendix)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">This paper proposes a novel variant of GFlowNet, genetic-guided GFlowNet
(Genetic GFN), which integrates an iterative genetic search into GFlowNet.
Genetic search effectively guides the GFlowNet to high-rewarded regions,
addressing global over-exploration that results in training inefficiency and
exploring limited regions. In addition, training strategies, such as rank-based
replay training and unsupervised maximum likelihood pre-training, are further
introduced to improve the sample efficiency of Genetic GFN. The proposed method
shows a state-of-the-art score of 16.213, significantly outperforming the
reported best score in the benchmark of 15.185, in practical molecular
optimization (PMO), which is an official benchmark for sample-efficient
molecular optimization. Remarkably, ours exceeds all baselines, including
reinforcement learning, Bayesian optimization, generative models, GFlowNets,
and genetic algorithms, in 14 out of 23 tasks.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05972" title="Abstract">arXiv:2402.05972</a> (cross-list from quant-ph) [<a href="/pdf/2402.05972" title="Download PDF">pdf</a>, <a href="/format/2402.05972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian-process-regression-based method for the localization of  exceptional points in complex resonance spectra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Egenlauf%2C+P">Patrick Egenlauf</a>, 
<a href="/search/quant-ph?searchtype=author&query=Rommel%2C+P">Patric Rommel</a>, 
<a href="/search/quant-ph?searchtype=author&query=Main%2C+J">J&#xf6;rg Main</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 10 figures, submitted to Machine Learning: Science and Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Mesoscale and Nanoscale Physics (cond-mat.mes-hall); Machine Learning (cs.LG)

</div>
<p class="mathjax">Resonances in open quantum systems depending on at least two controllable
parameters can show the phenomenon of exceptional points (EPs), where not only
the eigenvalues but also the eigenvectors of two or more resonances coalesce.
Their exact localization in the parameter space is challenging, in particular
in systems, where the computation of the quantum spectra and resonances is
numerically very expensive. We introduce an efficient machine learning
algorithm to find exceptional points based on Gaussian process regression
(GPR). The GPR-model is trained with an initial set of eigenvalue pairs
belonging to an EP and used for a first estimation of the EP position via a
numerically cheap root search. The estimate is then improved iteratively by
adding selected exact eigenvalue pairs as training points to the GPR-model. The
GPR-based method is developed and tested on a simple low-dimensional matrix
model and then applied to a challenging real physical system, viz., the
localization of EPs in the resonance spectra of excitons in cuprous oxide in
external electric and magnetic fields. The precise computation of EPs, by
taking into account the complete valence band structure and central-cell
corrections of the crystal, can be the basis for the experimental observation
of EPs in this system.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05974" title="Abstract">arXiv:2402.05974</a> (cross-list from eess.IV) [<a href="/pdf/2402.05974" title="Download PDF">pdf</a>, <a href="/format/2402.05974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RAGE for the Machine: Image Compression with Low-Cost Random Access for  Embedded Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rask%2C+C+D">Christian D. Rask</a>, 
<a href="/search/eess?searchtype=author&query=Lucani%2C+D+E">Daniel E. Lucani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, submitted, 10 figures, submitted to IEEE International Conference on Image Processing (ICIP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR); Information Theory (cs.IT)

</div>
<p class="mathjax">We introduce RAGE, an image compression framework that achieves four
generally conflicting objectives: 1) good compression for a wide variety of
color images, 2) computationally efficient, fast decompression, 3) fast random
access of images with pixel-level granularity without the need to decompress
the entire image, 4) support for both lossless and lossy compression. To
achieve these, we rely on the recent concept of generalized deduplication (GD),
which is known to provide efficient lossless (de)compression and fast random
access in time-series data, and deliver key expansions suitable for image
compression, both lossless and lossy. Using nine different datasets, incl.
graphics, logos, natural images, we show that RAGE has similar or better
compression ratios to state-of-the-art lossless image compressors, while
delivering pixel-level random access capabilities. Tests in an ARM Cortex-M33
platform show seek times between 9.9 and 40.6~ns and average decoding time per
pixel between 274 and 1226~ns. Our measurements also show that RAGE's lossy
variant, RAGE-Q, outperforms JPEG by several fold in terms of distortion in
embedded graphics and has reasonable compression and distortion for natural
images.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05975" title="Abstract">arXiv:2402.05975</a> (cross-list from eess.IV) [<a href="/pdf/2402.05975" title="Download PDF">pdf</a>, <a href="/ps/2402.05975" title="Download PostScript">ps</a>, <a href="/format/2402.05975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deep Learning Approach for Brain Tumor Classification and Segmentation  Using a Multiscale Convolutional Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=D%C3%ADaz-Pernas%2C+F+J">Francisco Javier D&#xed;az-Pernas</a>, 
<a href="/search/eess?searchtype=author&query=Mart%C3%ADnez-Zarzuela%2C+M">Mario Mart&#xed;nez-Zarzuela</a>, 
<a href="/search/eess?searchtype=author&query=Ant%C3%B3n-Rodr%C3%ADguez%2C+M">M&#xed;riam Ant&#xf3;n-Rodr&#xed;guez</a>, 
<a href="/search/eess?searchtype=author&query=Gonz%C3%A1lez-Ortega%2C+D">David Gonz&#xe1;lez-Ortega</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Healthcare 2021, 9, 153
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we present a fully automatic brain tumor segmentation and
classification model using a Deep Convolutional Neural Network that includes a
multiscale approach. One of the differences of our proposal with respect to
previous works is that input images are processed in three spatial scales along
different processing pathways. This mechanism is inspired in the inherent
operation of the Human Visual System. The proposed neural model can analyze MRI
images containing three types of tumors: meningioma, glioma, and pituitary
tumor, over sagittal, coronal, and axial views and does not need preprocessing
of input images to remove skull or vertebral column parts in advance. The
performance of our method on a publicly available MRI image dataset of 3064
slices from 233 patients is compared with previously classical machine learning
and deep learning published methods. In the comparison, our method remarkably
obtained a tumor classification accuracy of 0.973, higher than the other
approaches using the same database.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05982" title="Abstract">arXiv:2402.05982</a> (cross-list from q-bio.QM) [<a href="/pdf/2402.05982" title="Download PDF">pdf</a>, <a href="/format/2402.05982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anfinsen Goes Neural: a Graphical Model for Conditional Antibody Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Kim%2C+N">Nayoung Kim</a>, 
<a href="/search/q-bio?searchtype=author&query=Kim%2C+M">Minsu Kim</a>, 
<a href="/search/q-bio?searchtype=author&query=Park%2C+J">Jinkyoo Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Antibody design plays a pivotal role in advancing therapeutics. Although deep
learning has made rapid progress in this field, existing methods make limited
use of general protein knowledge and assume a graphical model (GM) that
violates empirical findings on proteins. To address these limitations, we
present Anfinsen Goes Neural (AGN), a graphical model that uses a pre-trained
protein language model (pLM) and encodes a seminal finding on proteins called
Anfinsen's dogma. Our framework follows a two-step process of sequence
generation with pLM and structure prediction with graph neural network (GNN).
Experiments show that our approach outperforms state-of-the-art results on
benchmark experiments. We also address a critical limitation of
non-autoregressive models -- namely, that they tend to generate unrealistic
sequences with overly repeating tokens. To resolve this, we introduce a
composition-based regularization term to the cross-entropy objective that
allows an efficient trade-off between high performance and low token
repetition. We demonstrate that our approach establishes a Pareto frontier over
the current state-of-the-art. Our code is available at
https://github.com/lkny123/AGN.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05983" title="Abstract">arXiv:2402.05983</a> (cross-list from eess.IV) [<a href="/pdf/2402.05983" title="Download PDF">pdf</a>, <a href="/format/2402.05983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Capability enhancement of the X-ray micro-tomography system via  ML-assisted approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shah%2C+D">Dhruvi Shah</a>, 
<a href="/search/eess?searchtype=author&query=Mehta%2C+S">Shruti Mehta</a>, 
<a href="/search/eess?searchtype=author&query=Agrawal%2C+A">Ashish Agrawal</a>, 
<a href="/search/eess?searchtype=author&query=Purohit%2C+S">Shishir Purohit</a>, 
<a href="/search/eess?searchtype=author&query=Chaudhury%2C+B">Bhaskar Chaudhury</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG); Applied Physics (physics.app-ph); Instrumentation and Detectors (physics.ins-det)

</div>
<p class="mathjax">Ring artifacts in X-ray micro-CT images are one of the primary causes of
concern in their accurate visual interpretation and quantitative analysis. The
geometry of X-ray micro-CT scanners is similar to the medical CT machines,
except the sample is rotated with a stationary source and detector. The ring
artifacts are caused by a defect or non-linear responses in detector pixels
during the MicroCT data acquisition. Artifacts in MicroCT images can often be
so severe that the images are no longer useful for further analysis. Therefore,
it is essential to comprehend the causes of artifacts and potential solutions
to maximize image quality. This article presents a convolution neural network
(CNN)-based Deep Learning (DL) model inspired by UNet with a series of encoder
and decoder units with skip connections for removal of ring artifacts. The
proposed architecture has been evaluated using the Structural Similarity Index
Measure (SSIM) and Mean Squared Error (MSE). Additionally, the results are
compared with conventional filter-based non-ML techniques and are found to be
better than the latter.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06026" title="Abstract">arXiv:2402.06026</a> (cross-list from quant-ph) [<a href="/pdf/2402.06026" title="Download PDF">pdf</a>, <a href="/format/2402.06026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum neural network with ensemble learning to mitigate barren  plateaus and cost function concentration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Friedrich%2C+L">Lucas Friedrich</a>, 
<a href="/search/quant-ph?searchtype=author&query=Maziero%2C+J">Jonas Maziero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The rapid development of quantum computers promises transformative impacts
across diverse fields of science and technology. Quantum neural networks
(QNNs), as a forefront application, hold substantial potential. Despite the
multitude of proposed models in the literature, persistent challenges, notably
the vanishing gradient (VG) and cost function concentration (CFC) problems,
impede their widespread success. In this study, we introduce a novel approach
to quantum neural network construction, specifically addressing the issues of
VG and CFC. Our methodology employs ensemble learning, advocating for the
simultaneous deployment of multiple quantum circuits with a depth equal to $1$,
a departure from the conventional use of a single quantum circuit with depth
$L$. We assess the efficacy of our proposed model through a comparative
analysis with a conventionally constructed QNN. The evaluation unfolds in the
context of a classification problem, yielding valuable insights into the
potential advantages of our innovative approach.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06033" title="Abstract">arXiv:2402.06033</a> (cross-list from math.OC) [<a href="/pdf/2402.06033" title="Download PDF">pdf</a>, <a href="/ps/2402.06033" title="Download PostScript">ps</a>, <a href="/format/2402.06033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Inexact Halpern Iteration for with Application to Distributionally  Robust Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liang%2C+L">Ling Liang</a>, 
<a href="/search/math?searchtype=author&query=Toh%2C+K">Kim-Chuan Toh</a>, 
<a href="/search/math?searchtype=author&query=Zhu%2C+J">Jia-Jie Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The Halpern iteration for solving monotone inclusion problems has gained
increasing interests in recent years due to its simple form and appealing
convergence properties. In this paper, we investigate the inexact variants of
the scheme in both deterministic and stochastic settings. We conduct extensive
convergence analysis and show that by choosing the inexactness tolerances
appropriately, the inexact schemes admit an $O(k^{-1})$ convergence rate in
terms of the (expected) residue norm. Our results relax the state-of-the-art
inexactness conditions employed in the literature while sharing the same
competitive convergence properties. We then demonstrate how the proposed
methods can be applied for solving two classes of data-driven Wasserstein
distributionally robust optimization problems that admit convex-concave min-max
optimization reformulations. We highlight its capability of performing inexact
computations for distributionally robust learning with stochastic first-order
methods.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06057" title="Abstract">arXiv:2402.06057</a> (cross-list from math.AG) [<a href="/pdf/2402.06057" title="Download PDF">pdf</a>, <a href="/ps/2402.06057" title="Download PostScript">ps</a>, <a href="/format/2402.06057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subalgebra and Khovanskii bases equivalence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Alstad%2C+C">Colin Alstad</a>, 
<a href="/search/math?searchtype=author&query=Burr%2C+M">Michael Burr</a>, 
<a href="/search/math?searchtype=author&query=Clarke%2C+O">Oliver Clarke</a>, 
<a href="/search/math?searchtype=author&query=Duff%2C+T">Timothy Duff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 2 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Geometry (math.AG)</span>; Symbolic Computation (cs.SC)

</div>
<p class="mathjax">The main results of this paper establish a partial correspondence between two
previously-studied analogues of Groebner bases in the setting of algebras:
namely, subalgebra (aka SAGBI) bases for quotients of polynomial rings and
Khovanskii bases for valued algebras. We aim to bridge the gap between the
concrete, computational aspects of the former and the more abstract theory of
the latter. Our philosophy is that most interesting examples of Khovanskii
bases can also be realized as subalgebra bases and vice-versa. We also discuss
the computation of Newton-Okounkov bodies, illustrating how interpreting
Khovanskii bases as subalgebra bases makes them more amenable to the existing
computer algebra tools.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06063" title="Abstract">arXiv:2402.06063</a> (cross-list from physics.optics) [<a href="/pdf/2402.06063" title="Download PDF">pdf</a>, <a href="/ps/2402.06063" title="Download PostScript">ps</a>, <a href="/format/2402.06063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D-2D Neural Nets for Phase Retrieval in Noisy Interferometric Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Proppe%2C+A+H">Andrew H. Proppe</a>, 
<a href="/search/physics?searchtype=author&query=Thekkadath%2C+G">Guillaume Thekkadath</a>, 
<a href="/search/physics?searchtype=author&query=England%2C+D">Duncan England</a>, 
<a href="/search/physics?searchtype=author&query=Bustard%2C+P+J">Philip J. Bustard</a>, 
<a href="/search/physics?searchtype=author&query=Bouchard%2C+F">Fr&#xe9;d&#xe9;ric Bouchard</a>, 
<a href="/search/physics?searchtype=author&query=Lundeen%2C+J+S">Jeff S. Lundeen</a>, 
<a href="/search/physics?searchtype=author&query=Sussman%2C+B+J">Benjamin J. Sussman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">In recent years, neural networks have been used to solve phase retrieval
problems in imaging with superior accuracy and speed than traditional
techniques, especially in the presence of noise. However, in the context of
interferometric imaging, phase noise has been largely unaddressed by existing
neural network architectures. Such noise arises naturally in an interferometer
due to mechanical instabilities or atmospheric turbulence, limiting measurement
acquisition times and posing a challenge in scenarios with limited light
intensity, such as remote sensing. Here, we introduce a 3D-2D Phase Retrieval
U-Net (PRUNe) that takes noisy and randomly phase-shifted interferograms as
inputs, and outputs a single 2D phase image. A 3D downsampling convolutional
encoder captures correlations within and between frames to produce a 2D latent
space, which is upsampled by a 2D decoder into a phase image. We test our model
against a state-of-the-art singular value decomposition algorithm and find
PRUNe reconstructions consistently show more accurate and smooth
reconstructions, with a x2.5 - 4 lower mean squared error at multiple
signal-to-noise ratios for interferograms with low (&lt; 1 photon/pixel) and high
(~100 photons/pixel) signal intensity. Our model presents a faster and more
accurate approach to perform phase retrieval in extremely low light intensity
interferometry in presence of phase noise, and will find application in other
multi-frame noisy imaging techniques.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06079" title="Abstract">arXiv:2402.06079</a> (cross-list from q-bio.GN) [<a href="/pdf/2402.06079" title="Download PDF">pdf</a>, <a href="/format/2402.06079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiscDiff: Latent Diffusion Model for DNA Sequence Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Li%2C+Z">Zehui Li</a>, 
<a href="/search/q-bio?searchtype=author&query=Ni%2C+Y">Yuhao Ni</a>, 
<a href="/search/q-bio?searchtype=author&query=Beardall%2C+W+A+V">William A V Beardall</a>, 
<a href="/search/q-bio?searchtype=author&query=Xia%2C+G">Guoxuan Xia</a>, 
<a href="/search/q-bio?searchtype=author&query=Das%2C+A">Akashaditya Das</a>, 
<a href="/search/q-bio?searchtype=author&query=Stan%2C+G">Guy-Bart Stan</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhao%2C+Y">Yiren Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Different from the prior work "Latent Diffusion Model for DNA Sequence Generation" (<a href="/abs/2310.06150">arXiv:2310.06150</a>), we updated the evaluation framework and compared the DiscDiff with other methods comprehensively. In addition, a post-training framework is proposed to increase the quality of generated sequences
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper introduces a novel framework for DNA sequence generation,
comprising two key components: DiscDiff, a Latent Diffusion Model (LDM)
tailored for generating discrete DNA sequences, and Absorb-Escape, a
post-training algorithm designed to refine these sequences. Absorb-Escape
enhances the realism of the generated sequences by correcting `round errors'
inherent in the conversion process between latent and input spaces. Our
approach not only sets new standards in DNA sequence generation but also
demonstrates superior performance over existing diffusion models, in generating
both short and long DNA sequences. Additionally, we introduce EPD-GenDNA, the
first comprehensive, multi-species dataset for DNA generation, encompassing
160,000 unique sequences from 15 species. We hope this study will advance the
generative modelling of DNA, with potential implications for gene therapy and
protein production.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06122" title="Abstract">arXiv:2402.06122</a> (cross-list from stat.ME) [<a href="/pdf/2402.06122" title="Download PDF">pdf</a>, <a href="/format/2402.06122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Peeking with PEAK: Sequential, Nonparametric Composite Hypothesis Tests  for Means of Multiple Data Streams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cho%2C+B">Brian Cho</a>, 
<a href="/search/stat?searchtype=author&query=Gan%2C+K">Kyra Gan</a>, 
<a href="/search/stat?searchtype=author&query=Kallus%2C+N">Nathan Kallus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">We propose a novel nonparametric sequential test for composite hypotheses for
means of multiple data streams. Our proposed method, \emph{peeking with
expectation-based averaged capital} (PEAK), builds upon the testing-as-betting
framework and provides a non-asymptotic $\alpha$-level test across any stopping
time. PEAK is computationally tractable and efficiently rejects hypotheses that
are incorrect across all potential distributions that satisfy our nonparametric
assumption, enabling joint composite hypothesis testing on multiple streams of
data. We numerically validate our theoretical findings under the best arm
identification and threshold identification in the bandit setting, illustrating
the computational efficiency of our method against state-of-the-art testing
methods.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06151" title="Abstract">arXiv:2402.06151</a> (cross-list from stat.ML) [<a href="/pdf/2402.06151" title="Download PDF">pdf</a>, <a href="/format/2402.06151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> POTEC: Off-Policy Learning for Large Action Spaces via Two-Stage Policy  Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Saito%2C+Y">Yuta Saito</a>, 
<a href="/search/stat?searchtype=author&query=Yao%2C+J">Jihan Yao</a>, 
<a href="/search/stat?searchtype=author&query=Joachims%2C+T">Thorsten Joachims</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2305.08062">arXiv:2305.08062</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We study off-policy learning (OPL) of contextual bandit policies in large
discrete action spaces where existing methods -- most of which rely crucially
on reward-regression models or importance-weighted policy gradients -- fail due
to excessive bias or variance. To overcome these issues in OPL, we propose a
novel two-stage algorithm, called Policy Optimization via Two-Stage Policy
Decomposition (POTEC). It leverages clustering in the action space and learns
two different policies via policy- and regression-based approaches,
respectively. In particular, we derive a novel low-variance gradient estimator
that enables to learn a first-stage policy for cluster selection efficiently
via a policy-based approach. To select a specific action within the cluster
sampled by the first-stage policy, POTEC uses a second-stage policy derived
from a regression-based approach within each cluster. We show that a local
correctness condition, which only requires that the regression model preserves
the relative expected reward differences of the actions within each cluster,
ensures that our policy-gradient estimator is unbiased and the second-stage
policy is optimal. We also show that POTEC provides a strict generalization of
policy- and regression-based approaches and their associated assumptions.
Comprehensive experiments demonstrate that POTEC provides substantial
improvements in OPL effectiveness particularly in large and structured action
spaces.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06156" title="Abstract">arXiv:2402.06156</a> (cross-list from quant-ph) [<a href="/pdf/2402.06156" title="Download PDF">pdf</a>, <a href="/ps/2402.06156" title="Download PostScript">ps</a>, <a href="/format/2402.06156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Barycentric and Pairwise Renyi Quantum Leakage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Farokhi%2C+F">Farhad Farokhi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR); Information Theory (cs.IT)

</div>
<p class="mathjax">Barycentric and pairwise quantum Renyi leakages are proposed as two measures
of information leakage for privacy and security analysis in quantum computing
and communication systems. These quantities both require minimal assumptions on
the eavesdropper, i.e., they do not make any assumptions on the eavesdropper's
attack strategy or the statistical prior on the secret or private classical
data encoded in the quantum system. They also satisfy important properties of
positivity, independence, post-processing inequality, and unitary invariance.
The barycentric quantum Renyi leakage can be computed by solving a
semi-definite program and the pairwise quantum Renyi leakage possesses an
explicit formula. The barycentric and pairwise quantum Renyi leakages form
upper bounds on the maximal quantum leakage, the sandwiched quantum
$\alpha$-mutual information, the accessible information, and the Holevo's
information. Furthermore, differentially-private quantum channels are shown to
bound these measures of information leakage. Global and local depolarizing
channels, that are common models of noise in quantum computing and
communication, restrict private or secure information leakage. Finally, a
privacy-utility trade-off formula in quantum machine learning using variational
circuits is developed. The privacy guarantees can only be strengthened, i.e.,
information leakage can only be reduced, if the performance degradation grows
larger and vice versa.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06162" title="Abstract">arXiv:2402.06162</a> (cross-list from stat.ML) [<a href="/pdf/2402.06162" title="Download PDF">pdf</a>, <a href="/format/2402.06162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wasserstein proximal operators describe score-based generative models  and resolve memorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhang%2C+B+J">Benjamin J. Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Liu%2C+S">Siting Liu</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+W">Wuchen Li</a>, 
<a href="/search/stat?searchtype=author&query=Katsoulakis%2C+M+A">Markos A. Katsoulakis</a>, 
<a href="/search/stat?searchtype=author&query=Osher%2C+S+J">Stanley J. Osher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We focus on the fundamental mathematical structure of score-based generative
models (SGMs). We first formulate SGMs in terms of the Wasserstein proximal
operator (WPO) and demonstrate that, via mean-field games (MFGs), the WPO
formulation reveals mathematical structure that describes the inductive bias of
diffusion and score-based models. In particular, MFGs yield optimality
conditions in the form of a pair of coupled partial differential equations: a
forward-controlled Fokker-Planck (FP) equation, and a backward
Hamilton-Jacobi-Bellman (HJB) equation. Via a Cole-Hopf transformation and
taking advantage of the fact that the cross-entropy can be related to a linear
functional of the density, we show that the HJB equation is an uncontrolled FP
equation. Second, with the mathematical structure at hand, we present an
interpretable kernel-based model for the score function which dramatically
improves the performance of SGMs in terms of training samples and training
time. In addition, the WPO-informed kernel model is explicitly constructed to
avoid the recently studied memorization effects of score-based generative
models. The mathematical form of the new kernel-based models in combination
with the use of the terminal condition of the MFG reveals new explanations for
the manifold learning and generalization properties of SGMs, and provides a
resolution to their memorization effects. Finally, our mathematically informed,
interpretable kernel-based model suggests new scalable bespoke neural network
architectures for high-dimensional applications.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06173" title="Abstract">arXiv:2402.06173</a> (cross-list from stat.ML) [<a href="/pdf/2402.06173" title="Download PDF">pdf</a>, <a href="/format/2402.06173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SMC Is All You Need: Parallel Strong Scaling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Liang%2C+X">Xinzhu Liang</a>, 
<a href="/search/stat?searchtype=author&query=Lohani%2C+S">Sanjaya Lohani</a>, 
<a href="/search/stat?searchtype=author&query=Lukens%2C+J+M">Joseph M. Lukens</a>, 
<a href="/search/stat?searchtype=author&query=Kirby%2C+B+T">Brian T. Kirby</a>, 
<a href="/search/stat?searchtype=author&query=Searles%2C+T+A">Thomas A. Searles</a>, 
<a href="/search/stat?searchtype=author&query=Law%2C+K+J+H">Kody J.H. Law</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Computation (stat.CO)

</div>
<p class="mathjax">In the general framework of Bayesian inference, the target distribution can
only be evaluated up-to a constant of proportionality. Classical consistent
Bayesian methods such as sequential Monte Carlo (SMC) and Markov chain Monte
Carlo (MCMC) have unbounded time complexity requirements. We develop a fully
parallel sequential Monte Carlo (pSMC) method which provably delivers parallel
strong scaling, i.e. the time complexity (and per-node memory) remains bounded
if the number of asynchronous processes is allowed to grow. More precisely, the
pSMC has a theoretical convergence rate of MSE$ = O(1/NR)$, where $N$ denotes
the number of communicating samples in each processor and $R$ denotes the
number of processors. In particular, for suitably-large problem-dependent $N$,
as $R \rightarrow \infty$ the method converges to infinitesimal accuracy
MSE$=O(\varepsilon^2)$ with a fixed finite time-complexity Cost$=O(1)$ and with
no efficiency leakage, i.e. computational complexity
Cost$=O(\varepsilon^{-2})$. A number of Bayesian inference problems are taken
into consideration to compare the pSMC and MCMC methods.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06180" title="Abstract">arXiv:2402.06180</a> (cross-list from math.OC) [<a href="/pdf/2402.06180" title="Download PDF">pdf</a>, <a href="/format/2402.06180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven Estimation of the Algebraic Riccati Equation for the  Discrete-Time Inverse Linear Quadratic Regulator Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sugiura%2C+S">Shuhei Sugiura</a>, 
<a href="/search/math?searchtype=author&query=Ariizumi%2C+R">Ryo Ariizumi</a>, 
<a href="/search/math?searchtype=author&query=Tanemura%2C+M">Masaya Tanemura</a>, 
<a href="/search/math?searchtype=author&query=Asai%2C+T">Toru Asai</a>, 
<a href="/search/math?searchtype=author&query=Azuma%2C+S">Shun-ichi Azuma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In this paper, we propose a method for estimating the algebraic Riccati
equation (ARE) with respect to an unknown discrete-time system from the system
state and input observation. The inverse optimal control (IOC) problem asks,
``What objective function is optimized by a given control system?'' The inverse
linear quadratic regulator (ILQR) problem is an IOC problem that assumes a
linear system and quadratic objective function. The ILQR problem can be solved
by solving a linear matrix inequality that contains the ARE. However, the
system model is required to obtain the ARE, and it is often unknown in fields
in which the IOC problem occurs, for example, biological system analysis. Our
method directly estimates the ARE from the observation data without identifying
the system. This feature enables us to economize the observation data using
prior information about the objective function. We provide a data condition
that is sufficient for our method to estimate the ARE. We conducted a numerical
experiment to demonstrate that our method can estimate the ARE with less data
than system identification if the prior information is sufficient.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06224" title="Abstract">arXiv:2402.06224</a> (cross-list from math.OC) [<a href="/pdf/2402.06224" title="Download PDF">pdf</a>, <a href="/format/2402.06224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive multi-gradient methods for quasiconvex vector optimization and  applications to multi-task learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Minh%2C+N+A">Nguyen Anh Minh</a>, 
<a href="/search/math?searchtype=author&query=Muu%2C+L+D">Le Dung Muu</a>, 
<a href="/search/math?searchtype=author&query=Thang%2C+T+N">Tran Ngoc Thang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present an adaptive step-size method, which does not include line-search
techniques, for solving a wide class of nonconvex multiobjective programming
problems on an unbounded constraint set. We also prove convergence of a general
approach under modest assumptions. More specifically, the convexity criterion
might not be satisfied by the objective function. Unlike descent line-search
algorithms, it does not require an initial step-size to be determined by a
previously determined Lipschitz constant. The process's primary characteristic
is its gradual step-size reduction up until a predetermined condition is met.
It can be specifically applied to offer an innovative multi-gradient projection
method for unbounded constrained optimization issues. Preliminary findings from
a few computational examples confirm the accuracy of the strategy. We apply the
proposed technique to some multi-task learning experiments to show its efficacy
for large-scale challenges.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06228" title="Abstract">arXiv:2402.06228</a> (cross-list from stat.ME) [<a href="/pdf/2402.06228" title="Download PDF">pdf</a>, <a href="/format/2402.06228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards participatory multi-modeling for policy support across domains  and scales: a systematic procedure for integral multi-model design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Nespeca%2C+V">Vittorio Nespeca</a> (1 and 2 and 3), 
<a href="/search/stat?searchtype=author&query=Quax%2C+R">Rick Quax</a> (1 and 2), 
<a href="/search/stat?searchtype=author&query=Rikkert%2C+M+G+M+O">Marcel G. M. Olde Rikkert</a> (4), 
<a href="/search/stat?searchtype=author&query=Korzilius%2C+H+P+L+M">Hubert P. L. M. Korzilius</a> (5), 
<a href="/search/stat?searchtype=author&query=Marchau%2C+V+A+W+J">Vincent A. W. J. Marchau</a> (5), 
<a href="/search/stat?searchtype=author&query=Hadijsotiriou%2C+S">Sophie Hadijsotiriou</a> (4), 
<a href="/search/stat?searchtype=author&query=Oreel%2C+T">Tom Oreel</a> (4), 
<a href="/search/stat?searchtype=author&query=Coenen%2C+J">Jannie Coenen</a> (5), 
<a href="/search/stat?searchtype=author&query=Wertheim%2C+H">Heiman Wertheim</a> (6), 
<a href="/search/stat?searchtype=author&query=Voinov%2C+A">Alexey Voinov</a> (7), 
<a href="/search/stat?searchtype=author&query=Rouwette%2C+E+A+J+A">Eti&#xeb;nne A.J.A. Rouwette</a> (5), 
<a href="/search/stat?searchtype=author&query=Vasconcelos%2C+V+V">V&#xed;tor V. Vasconcelos</a> (1 and 2 and 8) ((1) Computational Science Lab - University of Amsterdam, (2) POLDER - Institute for Advanced Study - University of Amsterdam, (3) Faculty of Technology Policy and Management - Delft University of Technology, (4) Department Geriatrics - Radboud University Medical Center, (5) Institute for Management Research - Radboud University, (6) Department Medical Microbiology - Radboud University Medical Center, (7) Faculty of Engineering Technology - Twente University, (8) Centre for Urban Mental Health - University of Amsterdam)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Computational Engineering, Finance, and Science (cs.CE); Computers and Society (cs.CY); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Policymaking for complex challenges such as pandemics necessitates the
consideration of intricate implications across multiple domains and scales.
Computational models can support policymaking, but a single model is often
insufficient for such multidomain and scale challenges. Multi-models comprising
several interacting computational models at different scales or relying on
different modeling paradigms offer a potential solution. Such multi-models can
be assembled from existing computational models (i.e., integrated modeling) or
be designed conceptually as a whole before their computational implementation
(i.e., integral modeling). Integral modeling is particularly valuable for novel
policy problems, such as those faced in the early stages of a pandemic, where
relevant models may be unavailable or lack standard documentation. Designing
such multi-models through an integral approach is, however, a complex task
requiring the collaboration of modelers and experts from various domains. In
this collaborative effort, modelers must precisely define the domain knowledge
needed from experts and establish a systematic procedure for translating such
knowledge into a multi-model. Yet, these requirements and systematic procedures
are currently lacking for multi-models that are both multiscale and
multi-paradigm. We address this challenge by introducing a procedure for
developing multi-models with an integral approach based on clearly defined
domain knowledge requirements derived from literature. We illustrate this
procedure using the case of school closure policies in the Netherlands during
the COVID-19 pandemic, revealing their potential implications in the short and
long term and across the healthcare and educational domains. The requirements
and procedure provided in this article advance the application of integral
multi-modeling for policy support in multiscale and multidomain contexts.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06246" title="Abstract">arXiv:2402.06246</a> (cross-list from eess.AS) [<a href="/pdf/2402.06246" title="Download PDF">pdf</a>, <a href="/format/2402.06246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven Joint Detection and Localization of Acoustic Reflectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bicer%2C+H+N">H. Nazim Bicer</a>, 
<a href="/search/eess?searchtype=author&query=Tuna%2C+C">Cagdas Tuna</a>, 
<a href="/search/eess?searchtype=author&query=Walther%2C+A">Andreas Walther</a>, 
<a href="/search/eess?searchtype=author&query=Habets%2C+E+A+P">Emanu&#xeb;l A. P. Habets</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4+1(bib) Pages. Accepted to ICASSP Satellite Workshop - HSCMA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Room geometry inference algorithms rely on the localization of acoustic
reflectors to identify boundary surfaces of an enclosure. Rooms with highly
absorptive walls or walls at large distances from the measurement setup pose
challenges for such algorithms. As it is not always possible to localize all
walls, we present a data-driven method to jointly detect and localize acoustic
reflectors that correspond to nearby and/or reflective walls. A multi-branch
convolutional recurrent neural network is employed for this purpose. The
network's input consists of a time-domain acoustic beamforming map, obtained
via Radon transform from multi-channel room impulse responses. A modified loss
function is proposed that forces the network to pay more attention to walls
that can be estimated with a small error. Simulation results show that the
proposed method can detect nearby and/or reflective walls and improve the
localization performance for the detected walls.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06250" title="Abstract">arXiv:2402.06250</a> (cross-list from eess.SP) [<a href="/pdf/2402.06250" title="Download PDF">pdf</a>, <a href="/format/2402.06250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An experimental study: RF Fingerprinting of Bluetooth devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ru%C5%A1i%C5%86%C5%A1%2C+A">Artis Ru&#x161;i&#x146;&#x161;</a>, 
<a href="/search/eess?searchtype=author&query=Nesenbergs%2C+K">Kri&#x161;j&#x101;nis Nesenbergs</a>, 
<a href="/search/eess?searchtype=author&query=Ti%C5%A1%C4%8Denko%2C+D">Deniss Ti&#x161;&#x10d;enko</a>, 
<a href="/search/eess?searchtype=author&query=Paikens%2C+P">P&#x113;teris Paikens</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to and presented in International Conference on Embedded Wireless Systems and Networks (EWSN) 2023. The EWSN proceedings are indexed, among others, in the ACM Digital Library, SCOPUS, and DBLP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">This paper presents an experimental study on radio frequency (RF)
fingerprinting of Bluetooth Classic devices. Our research aims to provide a
practical evaluation of the possibilities for RF fingerprinting of everyday
Bluetooth connected devices that may cause privacy risks. We have built an
experimental setup for recording Bluetooth connection in a radio frequency
isolated environment using commercially available SDR (software defined radio)
systems, extracted fingerprints of the Bluetooth radio data in the form of
carrier frequency offset and scaling factor from 6 different devices, and
performed k-nearest neighbors (kNN) classification achieving 84\% accuracy. The
experiment demonstrates that no matter what privacy measures are being taken in
the protocol layer, the physical layer leaks significant information about the
device to unauthorized listeners. In the context of the ever-growing Bluetooth
device market, this research serves as a clarion call for device manufacturers,
regulators, and end-users to acknowledge the privacy risks posed by RF
fingerprinting and lays a foundation for more sizeable Bluetooth fingerprinting
analysis research.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06260" title="Abstract">arXiv:2402.06260</a> (cross-list from quant-ph) [<a href="/pdf/2402.06260" title="Download PDF">pdf</a>, <a href="/format/2402.06260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vertex-minor universal graphs for generating entangled quantum  subsystems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Cautr%C3%A8s%2C+M">Maxime Cautr&#xe8;s</a>, 
<a href="/search/quant-ph?searchtype=author&query=Claudet%2C+N">Nathan Claudet</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mhalla%2C+M">Mehdi Mhalla</a>, 
<a href="/search/quant-ph?searchtype=author&query=Perdrix%2C+S">Simon Perdrix</a>, 
<a href="/search/quant-ph?searchtype=author&query=Savin%2C+V">Valentin Savin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Thomass%C3%A9%2C+S">St&#xe9;phane Thomass&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We study the notion of $k$-stabilizer universal quantum state, that is, an
$n$-qubit quantum state, such that it is possible to induce any stabilizer
state on any $k$ qubits, by using only local operations and classical
communications. These states generalize the notion of $k$-pairable states
introduced by Bravyi et al., and can be studied from a combinatorial
perspective using graph states and $k$-vertex-minor universal graphs. First, we
demonstrate the existence of $k$-stabilizer universal graph states that are
optimal in size with $n=\Theta(k^2)$ qubits. We also provide parameters for
which a random graph state on $\Theta(k^2)$ qubits is $k$-stabilizer universal
with high probability. Our second contribution consists of two explicit
constructions of $k$-stabilizer universal graph states on $n = O(k^4)$ qubits.
Both rely upon the incidence graph of the projective plane over a finite field
$\mathbb{F}_q$. This provides a major improvement over the previously known
explicit construction of $k$-pairable graph states with $n = O(2^{3k})$,
bringing forth a new and potentially powerful family of multipartite quantum
resources.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06271" title="Abstract">arXiv:2402.06271</a> (cross-list from math.OC) [<a href="/pdf/2402.06271" title="Download PDF">pdf</a>, <a href="/format/2402.06271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive proximal gradient methods are universal without approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Oikonomidis%2C+K+A">Konstantinos A. Oikonomidis</a>, 
<a href="/search/math?searchtype=author&query=Laude%2C+E">Emanuel Laude</a>, 
<a href="/search/math?searchtype=author&query=Latafat%2C+P">Puya Latafat</a>, 
<a href="/search/math?searchtype=author&query=Themelis%2C+A">Andreas Themelis</a>, 
<a href="/search/math?searchtype=author&query=Patrinos%2C+P">Panagiotis Patrinos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We show that adaptive proximal gradient methods for convex problems are not
restricted to traditional Lipschitzian assumptions. Our analysis reveals that a
class of linesearch-free methods is still convergent under mere local H\"older
gradient continuity, covering in particular continuously differentiable
semi-algebraic functions. To mitigate the lack of local Lipschitz continuity,
popular approaches revolve around $\varepsilon$-oracles and/or linesearch
procedures. In contrast, we exploit plain H\"older inequalities not entailing
any approximation, all while retaining the linesearch-free nature of adaptive
schemes. Furthermore, we prove full sequence convergence without prior
knowledge of local H\"older constants nor of the order of H\"older continuity.
In numerical experiments we present comparisons to baseline methods on diverse
tasks from machine learning covering both the locally and the globally H\"older
setting.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06275" title="Abstract">arXiv:2402.06275</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2402.06275" title="Download PDF">pdf</a>, <a href="/format/2402.06275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural SPH: Improved Neural Modeling of Lagrangian Fluid Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Toshev%2C+A+P">Artur P. Toshev</a>, 
<a href="/search/physics?searchtype=author&query=Erbesdobler%2C+J+A">Jonas A. Erbesdobler</a>, 
<a href="/search/physics?searchtype=author&query=Adams%2C+N+A">Nikolaus A. Adams</a>, 
<a href="/search/physics?searchtype=author&query=Brandstetter%2C+J">Johannes Brandstetter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Smoothed particle hydrodynamics (SPH) is omnipresent in modern engineering
and scientific disciplines. SPH is a class of Lagrangian schemes that
discretize fluid dynamics via finite material points that are tracked through
the evolving velocity field. Due to the particle-like nature of the simulation,
graph neural networks (GNNs) have emerged as appealing and successful
surrogates. However, the practical utility of such GNN-based simulators relies
on their ability to faithfully model physics, providing accurate and stable
predictions over long time horizons - which is a notoriously hard problem. In
this work, we identify particle clustering originating from tensile
instabilities as one of the primary pitfalls. Based on these insights, we
enhance both training and rollout inference of state-of-the-art GNN-based
simulators with varying components from standard SPH solvers, including
pressure, viscous, and external force components. All neural SPH-enhanced
simulators achieve better performance, often by orders of magnitude, than the
baseline GNNs, allowing for significantly longer rollouts and significantly
better physics modeling. Code available under
(https://github.com/tumaer/neuralsph).
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06277" title="Abstract">arXiv:2402.06277</a> (cross-list from physics.geo-ph) [<a href="/pdf/2402.06277" title="Download PDF">pdf</a>, <a href="/format/2402.06277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllable seismic velocity synthesis using generative diffusion  models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Wang%2C+F">Fu Wang</a>, 
<a href="/search/physics?searchtype=author&query=Huang%2C+X">Xinquan Huang</a>, 
<a href="/search/physics?searchtype=author&query=Alkhalifah%2C+T">Tariq Alkhalifah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Accurate seismic velocity estimations are vital to understanding Earth's
subsurface structures, assessing natural resources, and evaluating seismic
hazards. Machine learning-based inversion algorithms have shown promising
performance in regional (i.e., for exploration) and global velocity estimation,
while their effectiveness hinges on access to large and diverse training
datasets whose distributions generally cover the target solutions.
Additionally, enhancing the precision and reliability of velocity estimation
also requires incorporating prior information, e.g., geological classes, well
logs, and subsurface structures, but current statistical or neural
network-based methods are not flexible enough to handle such multi-modal
information. To address both challenges, we propose to use conditional
generative diffusion models for seismic velocity synthesis, in which we readily
incorporate those priors. This approach enables the generation of seismic
velocities that closely match the expected target distribution, offering
datasets informed by both expert knowledge and measured data to support
training for data-driven geophysical methods. We demonstrate the flexibility
and effectiveness of our method through training diffusion models on the
OpenFWI dataset under various conditions, including class labels, well logs,
reflectivity images, as well as the combination of these priors. The
performance of the approach under out-of-distribution conditions further
underscores its generalization ability, showcasing its potential to provide
tailored priors for velocity inverse problems and create specific training
datasets for machine learning-based geophysical applications.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06320" title="Abstract">arXiv:2402.06320</a> (cross-list from stat.ML) [<a href="/pdf/2402.06320" title="Download PDF">pdf</a>, <a href="/format/2402.06320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Particle Denoising Diffusion Sampler
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Phillips%2C+A">Angus Phillips</a>, 
<a href="/search/stat?searchtype=author&query=Dau%2C+H">Hai-Dang Dau</a>, 
<a href="/search/stat?searchtype=author&query=Hutchinson%2C+M+J">Michael John Hutchinson</a>, 
<a href="/search/stat?searchtype=author&query=De+Bortoli%2C+V">Valentin De Bortoli</a>, 
<a href="/search/stat?searchtype=author&query=Deligiannidis%2C+G">George Deligiannidis</a>, 
<a href="/search/stat?searchtype=author&query=Doucet%2C+A">Arnaud Doucet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 12 figures, 3 tables, 4 algorithms
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Computation (stat.CO)

</div>
<p class="mathjax">Denoising diffusion models have become ubiquitous for generative modeling.
The core idea is to transport the data distribution to a Gaussian by using a
diffusion. Approximate samples from the data distribution are then obtained by
estimating the time-reversal of this diffusion using score matching ideas. We
follow here a similar strategy to sample from unnormalized probability
densities and compute their normalizing constants. However, the time-reversed
diffusion is here simulated by using an original iterative particle scheme
relying on a novel score matching loss. Contrary to standard denoising
diffusion models, the resulting Particle Denoising Diffusion Sampler (PDDS)
provides asymptotically consistent estimates under mild assumptions. We
demonstrate PDDS on multimodal and high dimensional sampling tasks.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06337" title="Abstract">arXiv:2402.06337</a> (cross-list from eess.SP) [<a href="/pdf/2402.06337" title="Download PDF">pdf</a>, <a href="/format/2402.06337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Outage performance of the $&#x3b1;$-Beaulieu-Xie Shadowed Fading  Channel Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gvozdarev%2C+A+S">Aleksey S. Gvozdarev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for 2023 20th International Conference on Electrical Engineering, Computing Science and Automatic Control (CCE) <a href="https://ieeexplore.ieee.org/abstract/document/10332841">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">The research presents the closed-form outage analysis of the newly presented
$\alpha$-modification of the shadowed Beaulieu-Xie fading model for wireless
communications. For the considered channel, the closed-form analytical
expressions for the outage probability (including its upper and lower bounds),
raw moments, amount of fading, and channel quality estimation indicator are
derived. The carried out thorough numerical simulation and analysis
demonstrates strong agreement with the presented closed-form solutions and
illustrates the relationship between the outage probability and channel
parameters.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06338" title="Abstract">arXiv:2402.06338</a> (cross-list from math.CO) [<a href="/pdf/2402.06338" title="Download PDF">pdf</a>, <a href="/format/2402.06338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graphs without a 3-connected subgraph are 4-colorable
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bonnet%2C+%C3%89">&#xc9;douard Bonnet</a>, 
<a href="/search/math?searchtype=author&query=Feghali%2C+C">Carl Feghali</a>, 
<a href="/search/math?searchtype=author&query=Thomass%C3%A9%2C+S">St&#xe9;phan Thomass&#xe9;</a>, 
<a href="/search/math?searchtype=author&query=Trotignon%2C+N">Nicolas Trotignon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">In 1972, Mader showed that every graph without a 3-connected subgraph is
4-degenerate and thus 5-colorable}. We show that the number 5 of colors can be
replaced by 4, which is best possible.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06386" title="Abstract">arXiv:2402.06386</a> (cross-list from stat.ML) [<a href="/pdf/2402.06386" title="Download PDF">pdf</a>, <a href="/format/2402.06386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting-Based Sequential Meta-Tree Ensemble Construction for Improved  Decision Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Maniwa%2C+R">Ryota Maniwa</a>, 
<a href="/search/stat?searchtype=author&query=Ichijo%2C+N">Naoki Ichijo</a>, 
<a href="/search/stat?searchtype=author&query=Nakahara%2C+Y">Yuta Nakahara</a>, 
<a href="/search/stat?searchtype=author&query=Matsushima%2C+T">Toshiyasu Matsushima</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">A decision tree is one of the most popular approaches in machine learning
fields. However, it suffers from the problem of overfitting caused by overly
deepened trees. Then, a meta-tree is recently proposed. It solves the problem
of overfitting caused by overly deepened trees. Moreover, the meta-tree
guarantees statistical optimality based on Bayes decision theory. Therefore,
the meta-tree is expected to perform better than the decision tree. In contrast
to a single decision tree, it is known that ensembles of decision trees, which
are typically constructed boosting algorithms, are more effective in improving
predictive performance. Thus, it is expected that ensembles of meta-trees are
more effective in improving predictive performance than a single meta-tree, and
there are no previous studies that construct multiple meta-trees in boosting.
Therefore, in this study, we propose a method to construct multiple meta-trees
using a boosting approach. Through experiments with synthetic and benchmark
datasets, we conduct a performance comparison between the proposed methods and
the conventional methods using ensembles of decision trees. Furthermore, while
ensembles of decision trees can cause overfitting as well as a single decision
tree, experiments confirmed that ensembles of meta-trees can prevent
overfitting due to the tree depth.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06387" title="Abstract">arXiv:2402.06387</a> (cross-list from eess.AS) [<a href="/pdf/2402.06387" title="Download PDF">pdf</a>, <a href="/ps/2402.06387" title="Download PostScript">ps</a>, <a href="/format/2402.06387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Transversal Study of Fundamental Frequency Contours in Parkinsonian  Voices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rodriguez-Perez%2C+P">Pablo Rodriguez-Perez</a>, 
<a href="/search/eess?searchtype=author&query=Fraile%2C+R">Ruben Fraile</a>, 
<a href="/search/eess?searchtype=author&query=Garcia-Escrig%2C+M">Miguel Garcia-Escrig</a>, 
<a href="/search/eess?searchtype=author&query=Saenz-Lechon%2C+N">Nicolas Saenz-Lechon</a>, 
<a href="/search/eess?searchtype=author&query=Gutierrez-Arriola%2C+J+M">Juana M. Gutierrez-Arriola</a>, 
<a href="/search/eess?searchtype=author&query=Osma-Ruiz%2C+V">Victor Osma-Ruiz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">A transversal study of the pitch variability of parkinsonian voices in read
speech is presented. 30 patients suffering from Parkinson's disease (PD) and 32
healthy speakers were recorded while reading a text without voiceless phonemes.
The fundamental frequency contours were calculated from the recordings, and the
following measures were used for describing them: mean, minimum, maximum, and
standard deviation of the estimated fundamental frequencies. Results based on
these measures indicate that the influence of PD on some aspects of intonation
can be masked by the effects of aging, especially for male voices. However,
some parameters such as the relative fundamental frequency range exhibit lower
correlations with age than with PD stage, as evaluated using the Hoehn and Yahr
scale. These correlations between relative fundamental frequency range and PD
stage reach moderate-to-high values in the case of women. Additionally, three
parameters describing the form of the fundamental frequency modulation spectrum
were investigated for correlation with age and PD stage. The study of this
modulation spectrum provides some insight into the ability of the speakers to
plan the intonation of full phrases. For both male and female populations,
significant correlations were found between parameters obtained from the
modulation spectrum of fundamental frequency and the PD stage. Nevertheless,
the quantitative assessment of the performance of regression models built from
these modulation parameters and fundamental frequency range suggests that such
measures are likely to be of limited value in the early diagnosis of PD due to
inter-speaker variability.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06388" title="Abstract">arXiv:2402.06388</a> (cross-list from stat.ML) [<a href="/pdf/2402.06388" title="Download PDF">pdf</a>, <a href="/ps/2402.06388" title="Download PostScript">ps</a>, <a href="/format/2402.06388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Convergence Rate of the Stochastic Gradient Descent (SGD) and  application to a modified policy gradient for the Multi Armed Bandit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Anita%2C+S">Stefana Anita</a>, 
<a href="/search/stat?searchtype=author&query=Turinici%2C+G">Gabriel Turinici</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">We present a self-contained proof of the convergence rate of the Stochastic
Gradient Descent (SGD) when the learning rate follows an inverse time decays
schedule; we next apply the results to the convergence of a modified form of
policy gradient Multi-Armed Bandit (MAB) with $L2$ regularization.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06412" title="Abstract">arXiv:2402.06412</a> (cross-list from math.OC) [<a href="/pdf/2402.06412" title="Download PDF">pdf</a>, <a href="/format/2402.06412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the Worst-Case Bidirectional Communication Complexity for  Nonconvex Distributed Optimization under Function Similarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gruntkowska%2C+K">Kaja Gruntkowska</a>, 
<a href="/search/math?searchtype=author&query=Tyurin%2C+A">Alexander Tyurin</a>, 
<a href="/search/math?searchtype=author&query=Richt%C3%A1rik%2C+P">Peter Richt&#xe1;rik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Effective communication between the server and workers plays a key role in
distributed optimization. In this paper, we focus on optimizing the
server-to-worker communication, uncovering inefficiencies in prevalent downlink
compression approaches. Considering first the pure setup where the uplink
communication costs are negligible, we introduce MARINA-P, a novel method for
downlink compression, employing a collection of correlated compressors.
Theoretical analyses demonstrates that MARINA-P with permutation compressors
can achieve a server-to-worker communication complexity improving with the
number of workers, thus being provably superior to existing algorithms. We
further show that MARINA-P can serve as a starting point for extensions such as
methods supporting bidirectional compression. We introduce M3, a method
combining MARINA-P with uplink compression and a momentum step, achieving
bidirectional compression with provable improvements in total communication
complexity as the number of workers increases. Theoretical findings align
closely with empirical experiments, underscoring the efficiency of the proposed
algorithms.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06455" title="Abstract">arXiv:2402.06455</a> (cross-list from quant-ph) [<a href="/pdf/2402.06455" title="Download PDF">pdf</a>, <a href="/format/2402.06455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Computing and Tensor Networks for Laminate Design: A Novel  Approach to Stacking Sequence Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Wulff%2C+A">Arne Wulff</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+B">Boyang Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Steinberg%2C+M">Matthew Steinberg</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tang%2C+Y">Yinglu Tang</a>, 
<a href="/search/quant-ph?searchtype=author&query=M%C3%B6ller%2C+M">Matthias M&#xf6;ller</a>, 
<a href="/search/quant-ph?searchtype=author&query=Feld%2C+S">Sebastian Feld</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages, 7 figures. Accompanying code repository: <a href="https://github.com/ArneWulff/stacking-sequence-retrieval-with-dmrg">this https URL</a> . Accompanying data repository: <a href="https://doi.org/10.4121/ae276609-55b0-4af1-88c0-1102b1b58990">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Engineering, Finance, and Science (cs.CE); Emerging Technologies (cs.ET)

</div>
<p class="mathjax">As with many tasks in engineering, structural design frequently involves
navigating complex and computationally expensive problems. A prime example is
the weight optimization of laminated composite materials, which to this day
remains a formidable task, due to an exponentially large configuration space
and non-linear constraints. The rapidly developing field of quantum computation
may offer novel approaches for addressing these intricate problems. However,
before applying any quantum algorithm to a given problem, it must be translated
into a form that is compatible with the underlying operations on a quantum
computer. Our work specifically targets stacking sequence retrieval with
lamination parameters. To adapt this problem for quantum computational methods,
we map the possible stacking sequences onto a quantum state space. We further
derive a linear operator, the Hamiltonian, within this state space that
encapsulates the loss function inherent to the stacking sequence retrieval
problem. Additionally, we demonstrate the incorporation of manufacturing
constraints on stacking sequences as penalty terms in the Hamiltonian. This
quantum representation is suitable for a variety of classical and quantum
algorithms for finding the ground state of a quantum Hamiltonian. For a
practical demonstration, we chose a classical tensor network algorithm, the
DMRG algorithm, to numerically validate our approach. For this purpose, we
derived a matrix product operator representation of the loss function
Hamiltonian and the penalty terms. Numerical trials with this algorithm
successfully yielded approximate solutions, while exhibiting a tradeoff between
accuracy and runtime. Although this work primarily concentrates on quantum
computation, the application of tensor network algorithms presents a novel
quantum-inspired approach for stacking sequence retrieval.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06463" title="Abstract">arXiv:2402.06463</a> (cross-list from eess.IV) [<a href="/pdf/2402.06463" title="Download PDF">pdf</a>, <a href="/format/2402.06463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cardiac ultrasound simulation for autonomous ultrasound navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Amadou%2C+A+A">Abdoul Aziz Amadou</a>, 
<a href="/search/eess?searchtype=author&query=Peralta%2C+L">Laura Peralta</a>, 
<a href="/search/eess?searchtype=author&query=Dryburgh%2C+P">Paul Dryburgh</a>, 
<a href="/search/eess?searchtype=author&query=Klein%2C+P">Paul Klein</a>, 
<a href="/search/eess?searchtype=author&query=Petkov%2C+K">Kaloian Petkov</a>, 
<a href="/search/eess?searchtype=author&query=Housden%2C+R+J">Richard James Housden</a>, 
<a href="/search/eess?searchtype=author&query=Singh%2C+V">Vivek Singh</a>, 
<a href="/search/eess?searchtype=author&query=Liao%2C+R">Rui Liao</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+Y">Young-Ho Kim</a>, 
<a href="/search/eess?searchtype=author&query=Ghesu%2C+F+C">Florin Christian Ghesu</a>, 
<a href="/search/eess?searchtype=author&query=Mansi%2C+T">Tommaso Mansi</a>, 
<a href="/search/eess?searchtype=author&query=Rajani%2C+R">Ronak Rajani</a>, 
<a href="/search/eess?searchtype=author&query=Young%2C+A">Alistair Young</a>, 
<a href="/search/eess?searchtype=author&query=Rhode%2C+K">Kawal Rhode</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 10 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Ultrasound is well-established as an imaging modality for diagnostic and
interventional purposes. However, the image quality varies with operator skills
as acquiring and interpreting ultrasound images requires extensive training due
to the imaging artefacts, the range of acquisition parameters and the
variability of patient anatomies. Automating the image acquisition task could
improve acquisition reproducibility and quality but training such an algorithm
requires large amounts of navigation data, not saved in routine examinations.
Thus, we propose a method to generate large amounts of ultrasound images from
other modalities and from arbitrary positions, such that this pipeline can
later be used by learning algorithms for navigation. We present a novel
simulation pipeline which uses segmentations from other modalities, an
optimized volumetric data representation and GPU-accelerated Monte Carlo path
tracing to generate view-dependent and patient-specific ultrasound images. We
extensively validate the correctness of our pipeline with a phantom experiment,
where structures' sizes, contrast and speckle noise properties are assessed.
Furthermore, we demonstrate its usability to train neural networks for
navigation in an echocardiography view classification experiment by generating
synthetic images from more than 1000 patients. Networks pre-trained with our
simulations achieve significantly superior performance in settings where large
real datasets are not available, especially for under-represented classes. The
proposed approach allows for fast and accurate patient-specific ultrasound
image generation, and its usability for training networks for
navigation-related tasks is demonstrated.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06485" title="Abstract">arXiv:2402.06485</a> (cross-list from physics.soc-ph) [<a href="/pdf/2402.06485" title="Download PDF">pdf</a>, <a href="/format/2402.06485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The structural evolution of temporal hypergraphs through the lens of  hyper-cores
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Mancastroppa%2C+M">Marco Mancastroppa</a>, 
<a href="/search/physics?searchtype=author&query=Iacopini%2C+I">Iacopo Iacopini</a>, 
<a href="/search/physics?searchtype=author&query=Petri%2C+G">Giovanni Petri</a>, 
<a href="/search/physics?searchtype=author&query=Barrat%2C+A">Alain Barrat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main document: 21 pages, 10 figures; Supplementary Material: 52 pages, 47 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The richness of many complex systems stems from the interactions among their
components. The higher-order nature of these interactions, involving many units
at once, and their temporal dynamics constitute crucial properties that shape
the behaviour of the system itself. An adequate description of these systems is
offered by temporal hypergraphs, that integrate these features within the same
framework. However, tools for their temporal and topological characterization
are still scarce. Here we develop a series of methods specifically designed to
analyse the structural properties of temporal hypergraphs at multiple scales.
Leveraging the hyper-core decomposition of hypergraphs, we follow the evolution
of the hyper-cores through time, characterizing the hypergraph structure and
its temporal dynamics at different topological scales, and quantifying the
multi-scale structural stability of the system. We also define two static
hypercoreness centrality measures that provide an overall description of the
nodes aggregated structural behaviour. We apply the characterization methods to
several data sets, establishing connections between structural properties and
specific activities within the systems. Finally, we show how the proposed
method can be used as a model-validation tool for synthetic temporal
hypergraphs, distinguishing the higher-order structures and dynamics generated
by different models from the empirical ones, and thus identifying the essential
model mechanisms to reproduce the empirical hypergraph structure and evolution.
Our work opens several research directions, from the understanding of dynamic
processes on temporal higher-order networks to the design of new models of
time-varying hypergraphs.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06522" title="Abstract">arXiv:2402.06522</a> (cross-list from cond-mat.soft) [<a href="/pdf/2402.06522" title="Download PDF">pdf</a>, <a href="/format/2402.06522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing model complexity by means of the Optimal Scaling: Population  Balance Model for latex particles morphology formation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Rusconi%2C+S">Simone Rusconi</a>, 
<a href="/search/cond-mat?searchtype=author&query=Schenk%2C+C">Christina Schenk</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zarnescu%2C+A">Arghir Zarnescu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Akhmatskaya%2C+E">Elena Akhmatskaya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Soft Condensed Matter (cond-mat.soft)</span>; Computational Engineering, Finance, and Science (cs.CE); Numerical Analysis (math.NA); Chemical Physics (physics.chem-ph)

</div>
<p class="mathjax">Rational computer-aided design of multiphase polymer materials is vital for
rapid progress in many important applications, such as: diagnostic tests, drug
delivery, coatings, additives for constructing materials, cosmetics, etc.
Several property predictive models, including the prospective Population
Balance Model for Latex Particles Morphology Formation (LPMF PBM), have already
been developed for such materials. However, they lack computational efficiency,
and the accurate prediction of materials' properties still remains a great
challenge. To enhance performance of the LPMF PBM, we explore the feasibility
of reducing its complexity through disregard of the aggregation terms of the
model. The introduced nondimensionalization approach, which we call Optimal
Scaling with Constraints, suggests a quantitative criterion for locating
regions of slow and fast aggregation and helps to derive a family of
dimensionless LPMF PBM of reduced complexity. The mathematical analysis of this
new family is also provided. When compared with the original LPMF PBM, the
resulting models demonstrate several orders of magnitude better computational
efficiency.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06525" title="Abstract">arXiv:2402.06525</a> (cross-list from stat.ML) [<a href="/pdf/2402.06525" title="Download PDF">pdf</a>, <a href="/format/2402.06525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flexible infinite-width graph convolutional networks and the importance  of representation learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Anson%2C+B">Ben Anson</a>, 
<a href="/search/stat?searchtype=author&query=Milsom%2C+E">Edward Milsom</a>, 
<a href="/search/stat?searchtype=author&query=Aitchison%2C+L">Laurence Aitchison</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">A common theoretical approach to understanding neural networks is to take an
infinite-width limit, at which point the outputs become Gaussian process (GP)
distributed. This is known as a neural network Gaussian process (NNGP).
However, the NNGP kernel is fixed, and tunable only through a small number of
hyperparameters, eliminating any possibility of representation learning. This
contrasts with finite-width NNs, which are often believed to perform well
precisely because they are able to learn representations. Thus in simplifying
NNs to make them theoretically tractable, NNGPs may eliminate precisely what
makes them work well (representation learning). This motivated us to understand
whether representation learning is necessary in a range of graph classification
tasks. We develop a precise tool for this task, the graph convolutional deep
kernel machine. This is very similar to an NNGP, in that it is an infinite
width limit and uses kernels, but comes with a `knob' to control the amount of
representation learning. We found that representation learning is necessary (in
the sense that it gives dramatic performance improvements) in graph
classification tasks and heterophilous node classification tasks, but not in
homophilous node classification tasks.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06535" title="Abstract">arXiv:2402.06535</a> (cross-list from math.OC) [<a href="/pdf/2402.06535" title="Download PDF">pdf</a>, <a href="/format/2402.06535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bandit Convex Optimisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lattimore%2C+T">Tor Lattimore</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 158 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Bandit convex optimisation is a fundamental framework for studying
zeroth-order convex optimisation. These notes cover the many tools used for
this problem, including cutting plane methods, interior point methods,
continuous exponential weights, gradient descent and online Newton step. The
nuances between the many assumptions and setups are explained. Although there
is not much truly new here, some existing tools are applied in novel ways to
obtain new algorithms. A few bounds are improved in minor ways.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06536" title="Abstract">arXiv:2402.06536</a> (cross-list from stat.CO) [<a href="/pdf/2402.06536" title="Download PDF">pdf</a>, <a href="/ps/2402.06536" title="Download PostScript">ps</a>, <a href="/format/2402.06536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relative frequencies of constrained events in stochastic processes: An  analytical approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Rusconi%2C+S">S. Rusconi</a>, 
<a href="/search/stat?searchtype=author&query=Akhmatskaya%2C+E">E. Akhmatskaya</a>, 
<a href="/search/stat?searchtype=author&query=Sokolovski%2C+D">D. Sokolovski</a>, 
<a href="/search/stat?searchtype=author&query=Ballard%2C+N">N. Ballard</a>, 
<a href="/search/stat?searchtype=author&query=de+la+Cal%2C+J+C">J. C. de la Cal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation (stat.CO)</span>; Materials Science (cond-mat.mtrl-sci); Soft Condensed Matter (cond-mat.soft); Computational Engineering, Finance, and Science (cs.CE); Chemical Physics (physics.chem-ph)

</div>
<p class="mathjax">The stochastic simulation algorithm (SSA) and the corresponding Monte Carlo
(MC) method are among the most common approaches for studying stochastic
processes. They rely on knowledge of interevent probability density functions
(PDFs) and on information about dependencies between all possible events.
Analytical representations of a PDF are difficult to specify in advance, in
many real life applications. Knowing the shapes of PDFs, and using experimental
data, different optimization schemes can be applied in order to evaluate
probability density functions and, therefore, the properties of the studied
system. Such methods, however, are computationally demanding, and often not
feasible. We show that, in the case where experimentally accessed properties
are directly related to the frequencies of events involved, it may be possible
to replace the heavy Monte Carlo core of optimization schemes with an
analytical solution. Such a replacement not only provides a more accurate
estimation of the properties of the process, but also reduces the simulation
time by a factor of order of the sample size (at least $\approx 10^4$). The
proposed analytical approach is valid for any choice of PDF. The accuracy,
computational efficiency, and advantages of the method over MC procedures are
demonstrated in the exactly solvable case and in the evaluation of branching
fractions in controlled radical polymerization (CRP) of acrylic monomers. This
polymerization can be modeled by a constrained stochastic process. Constrained
systems are quite common, and this makes the method useful for various
applications.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06564" title="Abstract">arXiv:2402.06564</a> (cross-list from math.AP) [<a href="/pdf/2402.06564" title="Download PDF">pdf</a>, <a href="/ps/2402.06564" title="Download PostScript">ps</a>, <a href="/format/2402.06564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review on the Analysis and Optimal Control of Chemotaxis-Consumption  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Filho%2C+A+L+C+V">Andr&#xe9; Luiz Corr&#xea;a Vianna Filho</a>, 
<a href="/search/math?searchtype=author&query=Guill%C3%A9n-Gonz%C3%A1lez%2C+F">Francisco Guill&#xe9;n-Gonz&#xe1;lez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA); Optimization and Control (math.OC)

</div>
<p class="mathjax">In the present review we focus on the chemotaxis-consumption model
$\partial_t u - \Delta u = - \nabla \cdot (u \nabla v)$ and $\partial_t v -
\Delta v = - u^s v$ in $(0,T) \times \Omega$, for any fixed $s \geq 1$, endowed
with isolated boundary conditions and nonnegative initial conditions, where
$(u,v)$ model cell density and chemical signal concentration. Our objective is
to present an overview of the related literature and latest results on the
aforementioned model concerning the following three distinct research lines we
have obtained in [12,24-26]: the mathematical analysis, the numerical analysis
and the related optimal control theory with a bilinear control acting on the
chemical equation.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06588" title="Abstract">arXiv:2402.06588</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2402.06588" title="Download PDF">pdf</a>, <a href="/format/2402.06588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Precision Air Flow Control via EHD Actuator: A Co-simulation and Control  Design Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Shaygani%2C+A">Afshin Shaygani</a>, 
<a href="/search/physics?searchtype=author&query=Adamiak%2C+K">Kazimierz Adamiak</a>, 
<a href="/search/physics?searchtype=author&query=Kermani%2C+M+R">Mehrdad R. Kermani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Systems and Control (eess.SY); Plasma Physics (physics.plasm-ph)

</div>
<p class="mathjax">A Dielectric Barrier Discharge (DBD) plasma actuator for controlling airflow
is proposed. It consists of diverging and converging nozzles, two concentric
cylinders and an actuator mounted in-between the two cylinders. The actuator
employs electrohydrodynamic (EHD) body force to induce an air jet within the
air gap between the two cylinders, effectively creating a suction area while
passing through the diverging nozzle, due to the Coanda effect. While merging
with the air stream inside the inner cylinder, the Coanda jet effectively
enhances amplification of the airflow. The outflow rate is measured by a
velocity sensor at the outlet and controlled by the plasma actuator. The
control strategy is based on the Active Disturbance Rejection Control (ADRC)
and compared to the baseline PID controller. The actuator was modelled by
seamlessly linking two modeling platforms for a co-simulation study. The CFD
simulation of the plasma and airflow was carried out in the COMSOL
multi-physics commercial software, and the control was implemented in the
Simulink. The DBD plasma model was based on the two-species model of discharge,
and the electric body force, calculated from the plasma simulation, was used in
the Navier-Stokes equation for the turbulent flow simulation. The plasma-air
flow system was analyzed using the input (the actuator voltage) and output (the
outlet flow rate) data for the control design. Finally, the performance of the
system of air flow control device was tested and discussed in the co-simulation
process.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06600" title="Abstract">arXiv:2402.06600</a> (cross-list from math.LO) [<a href="/pdf/2402.06600" title="Download PDF">pdf</a>, <a href="/ps/2402.06600" title="Download PostScript">ps</a>, <a href="/format/2402.06600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> First-Order Fischer Servi Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Christensen%2C+A">Ahmee Christensen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">We prove the completeness of a first-order analogue of the Fischer Servi
logic $\mathsf{FS}$ with respect to its expected birelational semantics. To
this end we introduce the notion of the $\textit{trace model}$ and, much like
in a canonical model argument, prove a truth lemma. We conclude by examining a
number of other first-order Fischer Servi logics, including the first-order
analogue of $\mathsf{FSS4}$, whose completeness can be similarly proved.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06616" title="Abstract">arXiv:2402.06616</a> (cross-list from physics.comp-ph) [<a href="/pdf/2402.06616" title="Download PDF">pdf</a>, <a href="/format/2402.06616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bakry-&#xc9;mery-Ricci curvature: An alternative network geometry measure  in the expanding toolbox of graph Ricci curvatures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Mondal%2C+M">Madhumita Mondal</a>, 
<a href="/search/physics?searchtype=author&query=Samal%2C+A">Areejit Samal</a>, 
<a href="/search/physics?searchtype=author&query=M%C3%BCnch%2C+F">Florentin M&#xfc;nch</a>, 
<a href="/search/physics?searchtype=author&query=Jost%2C+J">J&#xfc;rgen Jost</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 9 main figures, 12 supplementary tables, 1 supplementary figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">The characterization of complex networks with tools originating in geometry,
for instance through the statistics of so-called Ricci curvatures, is a well
established tool of network science. There exist various types of such Ricci
curvatures, capturing different aspects of network geometry. In the present
work, we investigate Bakry-\'Emery-Ricci curvature, a notion of discrete Ricci
curvature that has been studied much in geometry, but so far has not been
applied to networks. We explore on standard classes of artificial networks as
well as on selected empirical ones to what the statistics of that curvature are
similar to or different from that of other curvatures, how it is correlated to
other important network measures, and what it tells us about the underlying
network. We observe that most vertices typically have negative curvature.
Random and small-world networks exhibit a narrow curvature distribution whereas
other classes and most of the real-world networks possess a wide curvature
distribution. When we compare Bakry-\'Emery-Ricci curvature with two other
discrete notions of Ricci-curvature, Forman-Ricci and Ollivier-Ricci curvature
for both model and real-world networks, we observe a high positive correlation
between Bakry-\'Emery-Ricci and both Forman-Ricci and Ollivier-Ricci curvature,
and in particular with the augmented version of Forman-Ricci curvature.
Bakry-\'Emery-Ricci curvature also exhibits a high negative correlation with
the vertex centrality measure and degree for most of the model and real-world
networks. However, it does not correlate with the clustering coefficient. Also,
we investigate the importance of vertices with highly negative curvature values
to maintain communication in the network. The computational time for
Bakry-\'Emery-Ricci curvature is shorter than that required for Ollivier-Ricci
curvature but higher than for Augmented Forman-Ricci curvature.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06618" title="Abstract">arXiv:2402.06618</a> (cross-list from math.CO) [<a href="/pdf/2402.06618" title="Download PDF">pdf</a>, <a href="/format/2402.06618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial parametrisation of the canonical iterates to the solution of  $-&#x3b3;g&#x27;= g^{-1}$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Miyamoto%2C+R">Roland Miyamoto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 1 figure, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Classical Analysis and ODEs (math.CA); Numerical Analysis (math.NA)

</div>
<p class="mathjax">The iterates $h_0,h_1,h_2,\dotsc$ constructed in [6] and converging to the
(only) solution $g=h\colon[0,1]\to[0,1]$ of the iterative differential equation
$-\gamma g'= g^{-1}$, $\gamma&gt;0$, are parametrised by polynomials over $\Bbb
Q$, and the corresponding constant $\gamma=\kappa\approx0.278877$ is estimated
by rational numbers.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Mon, 12 Feb 24</h3>
<dl>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2006.07841" title="Abstract">arXiv:2006.07841</a> (replaced) [<a href="/pdf/2006.07841" title="Download PDF">pdf</a>, <a href="/format/2006.07841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classify and Generate Reciprocally: Simultaneous Positive-Unlabelled  Learning and Conditional Generation with Extra Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+K">Ke Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">He Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhouchen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhanxing Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2007.06007" title="Abstract">arXiv:2007.06007</a> (replaced) [<a href="/pdf/2007.06007" title="Download PDF">pdf</a>, <a href="/ps/2007.06007" title="Download PostScript">ps</a>, <a href="/format/2007.06007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Approximation Power of Deep Residual Neural Networks via  Nonlinear Control Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tabuada%2C+P">Paulo Tabuada</a>, 
<a href="/search/cs?searchtype=author&query=Gharesifard%2C+B">Bahman Gharesifard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Sejun Park and Geonho Hwang brought to our atention a mistake in the proof of Theorem 5.1. This mistake is corrected in this version with the consequence of increasing the number of neurons per layer from n+1 to 2n+1
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICLR 2021, TAC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.11856" title="Abstract">arXiv:2103.11856</a> (replaced) [<a href="/pdf/2103.11856" title="Download PDF">pdf</a>, <a href="/format/2103.11856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Link between Coding Theory and Cross-Validation with Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pahikkala%2C+T">Tapio Pahikkala</a>, 
<a href="/search/cs?searchtype=author&query=Movahedi%2C+P">Parisa Movahedi</a>, 
<a href="/search/cs?searchtype=author&query=Montoya%2C+I">Ileana Montoya</a>, 
<a href="/search/cs?searchtype=author&query=Miikonen%2C+H">Havu Miikonen</a>, 
<a href="/search/cs?searchtype=author&query=Foldes%2C+S">Stephan Foldes</a>, 
<a href="/search/cs?searchtype=author&query=Airola%2C+A">Antti Airola</a>, 
<a href="/search/cs?searchtype=author&query=Major%2C+L">Laszlo Major</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.12892" title="Abstract">arXiv:2106.12892</a> (replaced) [<a href="/pdf/2106.12892" title="Download PDF">pdf</a>, <a href="/format/2106.12892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semiring Provenance for B&#xfc;chi Games: Strategy Analysis with Absorptive  Polynomials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gr%C3%A4del%2C+E">Erich Gr&#xe4;del</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BCcking%2C+N">Niels L&#xfc;cking</a>, 
<a href="/search/cs?searchtype=author&query=Naaf%2C+M">Matthias Naaf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is an extended version of a paper at GandALF 2021, see <a href="/abs/2109.08327">arXiv:2109.08327</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.12981" title="Abstract">arXiv:2108.12981</a> (replaced) [<a href="/pdf/2108.12981" title="Download PDF">pdf</a>, <a href="/ps/2108.12981" title="Download PostScript">ps</a>, <a href="/format/2108.12981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The ensmallen library for flexible numerical optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Curtin%2C+R+R">Ryan R. Curtin</a>, 
<a href="/search/cs?searchtype=author&query=Edel%2C+M">Marcus Edel</a>, 
<a href="/search/cs?searchtype=author&query=Prabhu%2C+R+G">Rahul Ganesh Prabhu</a>, 
<a href="/search/cs?searchtype=author&query=Basak%2C+S">Suryoday Basak</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+Z">Zhihao Lou</a>, 
<a href="/search/cs?searchtype=author&query=Sanderson%2C+C">Conrad Sanderson</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Machine Learning Research, Vol. 22, No. 166, 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Software (cs.MS)</span>; Software Engineering (cs.SE); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.13975" title="Abstract">arXiv:2108.13975</a> (replaced) [<a href="/pdf/2108.13975" title="Download PDF">pdf</a>, <a href="/format/2108.13975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extrapolated DIscontinuity Tracking for complex 2D shock interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ciallella%2C+M">Mirco Ciallella</a>, 
<a href="/search/math?searchtype=author&query=Ricchiuto%2C+M">Mario Ricchiuto</a>, 
<a href="/search/math?searchtype=author&query=Paciorri%2C+R">Renato Paciorri</a>, 
<a href="/search/math?searchtype=author&query=Bonfiglioli%2C+A">Aldo Bonfiglioli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph); Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.00972" title="Abstract">arXiv:2109.00972</a> (replaced) [<a href="/pdf/2109.00972" title="Download PDF">pdf</a>, <a href="/ps/2109.00972" title="Download PostScript">ps</a>, <a href="/format/2109.00972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Weihrauch degree of finding Nash equilibria in multiplayer games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Crook%2C+T">Tonicha Crook</a>, 
<a href="/search/cs?searchtype=author&query=Pauly%2C+A">Arno Pauly</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.07962" title="Abstract">arXiv:2109.07962</a> (replaced) [<a href="/pdf/2109.07962" title="Download PDF">pdf</a>, <a href="/format/2109.07962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Modelling of Symmetric Positive Definite Material Tensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shivanand%2C+S+K">Sharana Kumar Shivanand</a>, 
<a href="/search/math?searchtype=author&query=Rosi%C4%87%2C+B">Bojana Rosi&#x107;</a>, 
<a href="/search/math?searchtype=author&query=Matthies%2C+H+G">Hermann G. Matthies</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.14764" title="Abstract">arXiv:2109.14764</a> (replaced) [<a href="/pdf/2109.14764" title="Download PDF">pdf</a>, <a href="/ps/2109.14764" title="Download PostScript">ps</a>, <a href="/format/2109.14764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaps, Ambiguity, and Establishing Complexity-Class Containments via  Iterative Constant-Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hemaspaandra%2C+L+A">Lane A. Hemaspaandra</a>, 
<a href="/search/cs?searchtype=author&query=Juvekar%2C+M">Mandar Juvekar</a>, 
<a href="/search/cs?searchtype=author&query=Nadjimzadah%2C+A">Arian Nadjimzadah</a>, 
<a href="/search/cs?searchtype=author&query=Phillips%2C+P+A">Patrick A. Phillips</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.01429" title="Abstract">arXiv:2201.01429</a> (replaced) [<a href="/pdf/2201.01429" title="Download PDF">pdf</a>, <a href="/format/2201.01429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlocking the Secrets of Software Configuration Landscapes-Ruggedness,  Accessibility, Escapability, and Transferability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Mingyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+P">Peili Mao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.10027" title="Abstract">arXiv:2202.10027</a> (replaced) [<a href="/pdf/2202.10027" title="Download PDF">pdf</a>, <a href="/format/2202.10027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward More Generalized Malicious URL Detection Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y">YunDa Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Liow%2C+C">Cayon Liow</a>, 
<a href="/search/cs?searchtype=author&query=Siang%2C+Y+S">Yin Sheng Siang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shou-De Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.12887" title="Abstract">arXiv:2202.12887</a> (replaced) [<a href="/pdf/2202.12887" title="Download PDF">pdf</a>, <a href="/format/2202.12887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fault-Tolerant Neural Networks from Biological Error Correction Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zlokapa%2C+A">Alexander Zlokapa</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+A+K">Andrew K. Tan</a>, 
<a href="/search/cs?searchtype=author&query=Martyn%2C+J+M">John M. Martyn</a>, 
<a href="/search/cs?searchtype=author&query=Fiete%2C+I+R">Ila R. Fiete</a>, 
<a href="/search/cs?searchtype=author&query=Tegmark%2C+M">Max Tegmark</a>, 
<a href="/search/cs?searchtype=author&query=Chuang%2C+I+L">Isaac L. Chuang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Neurons and Cognition (q-bio.NC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.00444" title="Abstract">arXiv:2203.00444</a> (replaced) [<a href="/pdf/2203.00444" title="Download PDF">pdf</a>, <a href="/format/2203.00444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter-free Mirror Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jacobsen%2C+A">Andrew Jacobsen</a>, 
<a href="/search/cs?searchtype=author&query=Cutkosky%2C+A">Ashok Cutkosky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 59 pages. v4: Added a new section (7. Trade-offs in the Horizon Dependence) discussing how to achieve an alternative type of parameter-free bound using our framework; v3: published at COLT 2022 + fixed typos; v2: improved the algorithms in sections 3, 5, and 6 (tighter regret, simpler updates and analysis), corrected minor technical details and fixed typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.00782" title="Abstract">arXiv:2203.00782</a> (replaced) [<a href="/pdf/2203.00782" title="Download PDF">pdf</a>, <a href="/ps/2203.00782" title="Download PostScript">ps</a>, <a href="/format/2203.00782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Connecting Gaits in Energetically Conservative Legged Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raff%2C+M">Maximilian Raff</a>, 
<a href="/search/cs?searchtype=author&query=Rosa%2C+N">Nelson Rosa Jr.</a>, 
<a href="/search/cs?searchtype=author&query=Remy%2C+C+D">C. David Remy</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters, vol. 7 no. 3, pp. 8407-8414,
  2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.03535" title="Abstract">arXiv:2206.03535</a> (replaced) [<a href="/pdf/2206.03535" title="Download PDF">pdf</a>, <a href="/format/2206.03535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multiplex Approach Against Disturbance Propagation in Nonlinear  Networks with Delays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xie%2C+S">Shihao Xie</a>, 
<a href="/search/eess?searchtype=author&query=Russo%2C+G">Giovanni Russo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an authors' version of the work that is published in IEEE Open Journal of Control Systems, 2024. The final version of record is available at this <a href="https://ieeexplore.ieee.org/abstract/document/10415106">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.01136" title="Abstract">arXiv:2207.01136</a> (replaced) [<a href="/pdf/2207.01136" title="Download PDF">pdf</a>, <a href="/format/2207.01136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Visual Field of View: Perceiving 3D Environment with Echoes and  Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lingyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Rahtu%2C+E">Esa Rahtu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hang Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.04284" title="Abstract">arXiv:2208.04284</a> (replaced) [<a href="/pdf/2208.04284" title="Download PDF">pdf</a>, <a href="/format/2208.04284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Rademacher Complexity-based Generalization Bounds for Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Truong%2C+L+V">Lan V. Truong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.06449" title="Abstract">arXiv:2208.06449</a> (replaced) [<a href="/pdf/2208.06449" title="Download PDF">pdf</a>, <a href="/format/2208.06449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When CNN Meet with ViT: Towards Semi-Supervised Learning for Multi-Class  Medical Image Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Ziyang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+T">Tianze Li</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+J">Jian-Qing Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+B">Baoru Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.10078" title="Abstract">arXiv:2208.10078</a> (replaced) [<a href="/pdf/2208.10078" title="Download PDF">pdf</a>, <a href="/ps/2208.10078" title="Download PostScript">ps</a>, <a href="/format/2208.10078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Filon-Clenshaw-Curtis-Smolyak rule for multi-dimensional oscillatory  integrals with application to a UQ problem for the Helmholtz equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wu%2C+Z">Zhizhang Wu</a>, 
<a href="/search/math?searchtype=author&query=Graham%2C+I+G">Ivan G. Graham</a>, 
<a href="/search/math?searchtype=author&query=Ma%2C+D">Dingjiong Ma</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Z">Zhiwen Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.11665" title="Abstract">arXiv:2208.11665</a> (replaced) [<a href="/pdf/2208.11665" title="Download PDF">pdf</a>, <a href="/format/2208.11665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical exploration of the Manifold Hypothesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Whiteley%2C+N">Nick Whiteley</a>, 
<a href="/search/stat?searchtype=author&query=Gray%2C+A">Annie Gray</a>, 
<a href="/search/stat?searchtype=author&query=Rubin-Delanchy%2C+P">Patrick Rubin-Delanchy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.07274" title="Abstract">arXiv:2209.07274</a> (replaced) [<a href="/pdf/2209.07274" title="Download PDF">pdf</a>, <a href="/format/2209.07274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introducing Grid WAR: Rethinking WAR for Starting Pitchers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brill%2C+R+S">Ryan S. Brill</a>, 
<a href="/search/cs?searchtype=author&query=Wyner%2C+A+J">Abraham J. Wyner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.09034" title="Abstract">arXiv:2209.09034</a> (replaced) [<a href="/pdf/2209.09034" title="Download PDF">pdf</a>, <a href="/format/2209.09034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ALEXSIS-PT: A New Resource for Portuguese Lexical Simplification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=North%2C+K">Kai North</a>, 
<a href="/search/cs?searchtype=author&query=Zampieri%2C+M">Marcos Zampieri</a>, 
<a href="/search/cs?searchtype=author&query=Ranasinghe%2C+T">Tharindu Ranasinghe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.09441" title="Abstract">arXiv:2209.09441</a> (replaced) [<a href="/pdf/2209.09441" title="Download PDF">pdf</a>, <a href="/format/2209.09441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Locally Constrained Representations in Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nath%2C+S">Somjit Nath</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+R">Rushiv Arora</a>, 
<a href="/search/cs?searchtype=author&query=Kahou%2C+S+E">Samira Ebrahimi Kahou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.08106" title="Abstract">arXiv:2210.08106</a> (replaced) [<a href="/pdf/2210.08106" title="Download PDF">pdf</a>, <a href="/format/2210.08106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Primal-Dual Algorithm for Hybrid Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Overman%2C+T">Tom Overman</a>, 
<a href="/search/cs?searchtype=author&query=Blum%2C+G">Garrett Blum</a>, 
<a href="/search/cs?searchtype=author&query=Klabjan%2C+D">Diego Klabjan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024. To appear in AAAI proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.11634" title="Abstract">arXiv:2210.11634</a> (replaced) [<a href="/pdf/2210.11634" title="Download PDF">pdf</a>, <a href="/format/2210.11634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Polynomial-time Algorithm for the Large Scale of Aircraft Refueling  Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jinchuan Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoya Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.11663" title="Abstract">arXiv:2210.11663</a> (replaced) [<a href="/pdf/2210.11663" title="Download PDF">pdf</a>, <a href="/format/2210.11663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InfraRed Investigation in Singapore (IRIS) Observatory: Urban heat  island contributors and mitigators analysis using neighborhood-scale thermal  imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Martin%2C+M">Miguel Martin</a>, 
<a href="/search/physics?searchtype=author&query=Ramani%2C+V">Vasantha Ramani</a>, 
<a href="/search/physics?searchtype=author&query=Miller%2C+C">Clayton Miller</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Energy Build. 2024;307: 113973
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.11846" title="Abstract">arXiv:2210.11846</a> (replaced) [<a href="/pdf/2210.11846" title="Download PDF">pdf</a>, <a href="/format/2210.11846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Redefining Counterfactual Explanations for Reinforcement Learning:  Overview, Challenges and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gajcin%2C+J">Jasmina Gajcin</a>, 
<a href="/search/cs?searchtype=author&query=Dusparic%2C+I">Ivana Dusparic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.04134" title="Abstract">arXiv:2211.04134</a> (replaced) [<a href="/pdf/2211.04134" title="Download PDF">pdf</a>, <a href="/format/2211.04134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consistent Query Answering for Primary Keys and Conjunctive Queries with  Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khalfioui%2C+A+A+E">Aziz Amezian El Khalfioui</a>, 
<a href="/search/cs?searchtype=author&query=Wijsen%2C+J">Jef Wijsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.05309" title="Abstract">arXiv:2211.05309</a> (replaced) [<a href="/pdf/2211.05309" title="Download PDF">pdf</a>, <a href="/ps/2211.05309" title="Download PostScript">ps</a>, <a href="/format/2211.05309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generic Cryo-CMOS Device Modeling and EDACompatible Platform for  Reliable Cryogenic IC Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tang%2C+Z">Zhidong Tang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zewei Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yuan%2C+Y">Yumeng Yuan</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+C">Chang He</a>, 
<a href="/search/eess?searchtype=author&query=Luo%2C+X">Xin Luo</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+A">Ao Guo</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+R">Renhe Chen</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+Y">Yongqi Hu</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+L">Longfei Yang</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+C">Chengwei Cao</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+L">Linlin Liu</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+L">Liujiang Yu</a>, 
<a href="/search/eess?searchtype=author&query=Shang%2C+G">Ganbing Shang</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+Y">Yongfeng Cao</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+S">Shoumian Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Y">Yuhang Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+S">Shaojian Hu</a>, 
<a href="/search/eess?searchtype=author&query=Kou%2C+X">Xufeng Kou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12203" title="Abstract">arXiv:2211.12203</a> (replaced) [<a href="/pdf/2211.12203" title="Download PDF">pdf</a>, <a href="/format/2211.12203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge Multiway Cut and Node Multiway Cut are NP-complete on subcubic  graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Johnson%2C+M">Matthew Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+B">Barnaby Martin</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+S">Siani Smith</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+S">Sukanya Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Paulusma%2C+D">Daniel Paulusma</a>, 
<a href="/search/cs?searchtype=author&query=van+Leeuwen%2C+E+J">Erik Jan van Leeuwen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.04083" title="Abstract">arXiv:2212.04083</a> (replaced) [<a href="/pdf/2212.04083" title="Download PDF">pdf</a>, <a href="/ps/2212.04083" title="Download PostScript">ps</a>, <a href="/format/2212.04083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of the Fourier-Galerkin spectral method for the Boltzmann  equation with uncertainties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+L">Liu Liu</a>, 
<a href="/search/math?searchtype=author&query=Qi%2C+K">Kunlun Qi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.04382" title="Abstract">arXiv:2212.04382</a> (replaced) [<a href="/pdf/2212.04382" title="Download PDF">pdf</a>, <a href="/format/2212.04382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure of Classifier Boundaries: Case Study for a Naive Bayes  Classifier
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Karr%2C+A+F">Alan F. Karr</a>, 
<a href="/search/stat?searchtype=author&query=Bowen%2C+Z">Zac Bowen</a>, 
<a href="/search/stat?searchtype=author&query=Porter%2C+A+A">Adam A. Porter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.04745" title="Abstract">arXiv:2212.04745</a> (replaced) [<a href="/pdf/2212.04745" title="Download PDF">pdf</a>, <a href="/format/2212.04745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SLAM for Visually Impaired People: a Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bamdad%2C+M">Marziyeh Bamdad</a>, 
<a href="/search/cs?searchtype=author&query=Scaramuzza%2C+D">Davide Scaramuzza</a>, 
<a href="/search/cs?searchtype=author&query=Darvishy%2C+A">Alireza Darvishy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 14 tables, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06520" title="Abstract">arXiv:2301.06520</a> (replaced) [<a href="/pdf/2301.06520" title="Download PDF">pdf</a>, <a href="/ps/2301.06520" title="Download PostScript">ps</a>, <a href="/format/2301.06520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UL-DL duality for cell-free massive MIMO with per-AP power and  information constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miretti%2C+L">Lorenzo Miretti</a>, 
<a href="/search/cs?searchtype=author&query=Cavalcante%2C+R+L+G">Renato L. G. Cavalcante</a>, 
<a href="/search/cs?searchtype=author&query=Bj%C3%B6rnson%2C+E">Emil Bj&#xf6;rnson</a>, 
<a href="/search/cs?searchtype=author&query=Sta%C5%84czak%2C+S">S&#x142;awomir Sta&#x144;czak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06625" title="Abstract">arXiv:2301.06625</a> (replaced) [<a href="/pdf/2301.06625" title="Download PDF">pdf</a>, <a href="/format/2301.06625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TDSTF: Transformer-based Diffusion probabilistic model for Sparse Time  series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+P">Ping Chang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huayu Li</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+S+F">Stuart F. Quan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shuyang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wung%2C+S">Shu-Fen Wung</a>, 
<a href="/search/cs?searchtype=author&query=Roveda%2C+J">Janet Roveda</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Ao Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11048" title="Abstract">arXiv:2301.11048</a> (replaced) [<a href="/pdf/2301.11048" title="Download PDF">pdf</a>, <a href="/ps/2301.11048" title="Download PostScript">ps</a>, <a href="/format/2301.11048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decidability of well quasi-order and atomicity for equivalence relations  under embedding orderings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ironmonger%2C+V">V. Ironmonger</a>, 
<a href="/search/math?searchtype=author&query=Ruskuc%2C+N">N. Ruskuc</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11584" title="Abstract">arXiv:2301.11584</a> (replaced) [<a href="/pdf/2301.11584" title="Download PDF">pdf</a>, <a href="/format/2301.11584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust variance-regularized risk minimization with concomitant scaling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Holland%2C+M+J">Matthew J. Holland</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revised version accepted to AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04320" title="Abstract">arXiv:2302.04320</a> (replaced) [<a href="/pdf/2302.04320" title="Download PDF">pdf</a>, <a href="/format/2302.04320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entropy production in communication channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Tasnim%2C+F">Farita Tasnim</a>, 
<a href="/search/cond-mat?searchtype=author&query=Freitas%2C+N">Nahuel Freitas</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wolpert%2C+D+H">David H. Wolpert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Mechanics (cond-mat.stat-mech)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05262" title="Abstract">arXiv:2302.05262</a> (replaced) [<a href="/pdf/2302.05262" title="Download PDF">pdf</a>, <a href="/format/2302.05262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of Data Augmentation and Loss Functions in Semantic Image  Segmentation for Drilling Tool Wear Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schlager%2C+E">Elke Schlager</a>, 
<a href="/search/cs?searchtype=author&query=Windisch%2C+A">Andreas Windisch</a>, 
<a href="/search/cs?searchtype=author&query=Hanna%2C+L">Lukas Hanna</a>, 
<a href="/search/cs?searchtype=author&query=Kl%C3%BCnsner%2C+T">Thomas Kl&#xfc;nsner</a>, 
<a href="/search/cs?searchtype=author&query=Hagendorfer%2C+E+J">Elias Jan Hagendorfer</a>, 
<a href="/search/cs?searchtype=author&query=Teppernegg%2C+T">Tamara Teppernegg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this article is published in Journal of Intelligent Manufacturing, and is available online at <a href="https://doi.org/10.1007/s10845-023-02313-y">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06018" title="Abstract">arXiv:2302.06018</a> (replaced) [<a href="/pdf/2302.06018" title="Download PDF">pdf</a>, <a href="/format/2302.06018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Floors in First Price Auctions: an Empirical Study of Yahoo  Advertising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alcobendas%2C+M">Miguel Alcobendas</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Jonathan Ji</a>, 
<a href="/search/cs?searchtype=author&query=Gokulakannan%2C+H">Hemakumar Gokulakannan</a>, 
<a href="/search/cs?searchtype=author&query=Wami%2C+D">Dawit Wami</a>, 
<a href="/search/cs?searchtype=author&query=Kapchits%2C+B">Boris Kapchits</a>, 
<a href="/search/cs?searchtype=author&query=Duteil%2C+E+P">Emilien Pouradier Duteil</a>, 
<a href="/search/cs?searchtype=author&query=Satow%2C+K">Korby Satow</a>, 
<a href="/search/cs?searchtype=author&query=Roman%2C+M+R+L">Maria Rosario Levy Roman</a>, 
<a href="/search/cs?searchtype=author&query=Diaz%2C+O">Oriol Diaz</a>, 
<a href="/search/cs?searchtype=author&query=Diaz%2C+A+A">Amado A. Diaz Jr.</a>, 
<a href="/search/cs?searchtype=author&query=Kavoori%2C+R">Rabi Kavoori</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10890" title="Abstract">arXiv:2302.10890</a> (replaced) [<a href="/pdf/2302.10890" title="Download PDF">pdf</a>, <a href="/format/2302.10890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Interpretable Low-dimensional Representation via Physical  Symmetry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuanjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chin%2C+D">Daniel Chin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yichen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+G">Gus Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01734" title="Abstract">arXiv:2303.01734</a> (replaced) [<a href="/pdf/2303.01734" title="Download PDF">pdf</a>, <a href="/format/2303.01734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdvART: Adversarial Art for Camouflaged Object Detection Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guesmi%2C+A">Amira Guesmi</a>, 
<a href="/search/cs?searchtype=author&query=Bilasco%2C+I+M">Ioan Marius Bilasco</a>, 
<a href="/search/cs?searchtype=author&query=Shafique%2C+M">Muhammad Shafique</a>, 
<a href="/search/cs?searchtype=author&query=Alouani%2C+I">Ihsen Alouani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02131" title="Abstract">arXiv:2303.02131</a> (replaced) [<a href="/pdf/2303.02131" title="Download PDF">pdf</a>, <a href="/format/2303.02131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spacetime-Efficient Low-Depth Quantum State Preparation with  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Gui%2C+K">Kaiwen Gui</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dalzell%2C+A+M">Alexander M. Dalzell</a>, 
<a href="/search/quant-ph?searchtype=author&query=Achille%2C+A">Alessandro Achille</a>, 
<a href="/search/quant-ph?searchtype=author&query=Suchara%2C+M">Martin Suchara</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chong%2C+F+T">Frederic T. Chong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08204" title="Abstract">arXiv:2303.08204</a> (replaced) [<a href="/pdf/2303.08204" title="Download PDF">pdf</a>, <a href="/format/2303.08204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAILOR: Perceptual Anchoring For Robotic Cognitive Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez-Santamarta%2C+M+%C3%81">Miguel &#xc1;. Gonz&#xe1;lez-Santamarta</a>, 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez-Lera%2C+F+J">Francisco J. Rodr&#xed;guez-Lera</a>, 
<a href="/search/cs?searchtype=author&query=Olivera%2C+V+M">Vicente Matell&#xe1;n Olivera</a>, 
<a href="/search/cs?searchtype=author&query=Del+Castillo%2C+V+R">Virginia Riego Del Castillo</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez-Gonz%C3%A1lez%2C+L">Lidia S&#xe1;nchez-Gonz&#xe1;lez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 5 figures, 7 tables, 3 algorithms, Submitted to Scientific Reports
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09669" title="Abstract">arXiv:2303.09669</a> (replaced) [<a href="/pdf/2303.09669" title="Download PDF">pdf</a>, <a href="/format/2303.09669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting discrete-time bifurcations with deep learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Bury%2C+T+M">Thomas M. Bury</a>, 
<a href="/search/q-bio?searchtype=author&query=Dylewsky%2C+D">Daniel Dylewsky</a>, 
<a href="/search/q-bio?searchtype=author&query=Bauch%2C+C+T">Chris T. Bauch</a>, 
<a href="/search/q-bio?searchtype=author&query=Anand%2C+M">Madhur Anand</a>, 
<a href="/search/q-bio?searchtype=author&query=Glass%2C+L">Leon Glass</a>, 
<a href="/search/q-bio?searchtype=author&query=Shrier%2C+A">Alvin Shrier</a>, 
<a href="/search/q-bio?searchtype=author&query=Bub%2C+G">Gil Bub</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Nat Commun 14, 6331 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14971" title="Abstract">arXiv:2303.14971</a> (replaced) [<a href="/pdf/2303.14971" title="Download PDF">pdf</a>, <a href="/format/2303.14971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On CNF Conversion for SAT and SMT Enumeration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Masina%2C+G">Gabriele Masina</a>, 
<a href="/search/cs?searchtype=author&query=Spallitta%2C+G">Giuseppe Spallitta</a>, 
<a href="/search/cs?searchtype=author&query=Sebastiani%2C+R">Roberto Sebastiani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 5 figures (38 pages, 12 figures with appendix)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15495" title="Abstract">arXiv:2303.15495</a> (replaced) [<a href="/pdf/2303.15495" title="Download PDF">pdf</a>, <a href="/format/2303.15495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Bus Arrival Prediction: A Deep Learning Approach for Enhanced  Urban Mobility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rashvand%2C+N">Narges Rashvand</a>, 
<a href="/search/cs?searchtype=author&query=Hosseini%2C+S+S">Sanaz Sadat Hosseini</a>, 
<a href="/search/cs?searchtype=author&query=Azarbayjani%2C+M">Mona Azarbayjani</a>, 
<a href="/search/cs?searchtype=author&query=Tabkhi%2C+H">Hamed Tabkhi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01235" title="Abstract">arXiv:2304.01235</a> (replaced) [<a href="/pdf/2304.01235" title="Download PDF">pdf</a>, <a href="/format/2304.01235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Graph Structure and Label Dependencies Contribute to Node  Classification in a Large Network of Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lemberger%2C+P">Pirmin Lemberger</a>, 
<a href="/search/cs?searchtype=author&query=Saillenfest%2C+A">Antoine Saillenfest</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02621" title="Abstract">arXiv:2304.02621</a> (replaced) [<a href="/pdf/2304.02621" title="Download PDF">pdf</a>, <a href="/format/2304.02621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-fidelity Pseudo-labels for Boosting Weakly-Supervised Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jonnarth%2C+A">Arvi Jonnarth</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yushan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Felsberg%2C+M">Michael Felsberg</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the IEEE/CVF Winter Conference on Applications of
  Computer Vision (WACV), 2024, pp. 1010-1019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07162" title="Abstract">arXiv:2304.07162</a> (replaced) [<a href="/pdf/2304.07162" title="Download PDF">pdf</a>, <a href="/ps/2304.07162" title="Download PostScript">ps</a>, <a href="/format/2304.07162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Operations on Fixpoint Equation Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neele%2C+T">Thomas Neele</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Pol%2C+J">Jaco van de Pol</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07944" title="Abstract">arXiv:2304.07944</a> (replaced) [<a href="/pdf/2304.07944" title="Download PDF">pdf</a>, <a href="/format/2304.07944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An In-depth Investigation of User Response Simulation for Conversational  Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhenduo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhichao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+Q">Qingyao Ai</a>, 
<a href="/search/cs?searchtype=author&query=Srikumar%2C+V">Vivek Srikumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in The Web Conference 2024, 8 pages with Appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09872" title="Abstract">arXiv:2304.09872</a> (replaced) [<a href="/pdf/2304.09872" title="Download PDF">pdf</a>, <a href="/format/2304.09872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Depth Functions for Partial Orders with a Descriptive Analysis of  Machine Learning Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blocher%2C+H">Hannah Blocher</a>, 
<a href="/search/cs?searchtype=author&query=Schollmeyer%2C+G">Georg Schollmeyer</a>, 
<a href="/search/cs?searchtype=author&query=Jansen%2C+C">Christoph Jansen</a>, 
<a href="/search/cs?searchtype=author&query=Nalenz%2C+M">Malte Nalenz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ISIPTA 2023; Forthcoming in: Proceedings of Machine Learning Research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11004" title="Abstract">arXiv:2304.11004</a> (replaced) [<a href="/pdf/2304.11004" title="Download PDF">pdf</a>, <a href="/format/2304.11004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Distillation Under Ideal Joint Classifier Assumption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huayu Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ditzler%2C+G">Gregory Ditzler</a>, 
<a href="/search/cs?searchtype=author&query=Roveda%2C+J">Janet Roveda</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Ao Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12522" title="Abstract">arXiv:2304.12522</a> (replaced) [<a href="/pdf/2304.12522" title="Download PDF">pdf</a>, <a href="/format/2304.12522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Inexact Proximal Linear Algorithm with Adaptive Stopping Criteria  for Robust Phase Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zheng%2C+Z">Zhong Zheng</a>, 
<a href="/search/math?searchtype=author&query=Ma%2C+S">Shiqian Ma</a>, 
<a href="/search/math?searchtype=author&query=Xue%2C+L">Lingzhou Xue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP); Computation (stat.CO); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07572" title="Abstract">arXiv:2305.07572</a> (replaced) [<a href="/pdf/2305.07572" title="Download PDF">pdf</a>, <a href="/format/2305.07572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Convergence Rates for Parameter Estimation in Gaussian-gated  Mixture of Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Nguyen%2C+H">Huy Nguyen</a>, 
<a href="/search/stat?searchtype=author&query=Nguyen%2C+T">TrungTin Nguyen</a>, 
<a href="/search/stat?searchtype=author&query=Nguyen%2C+K">Khai Nguyen</a>, 
<a href="/search/stat?searchtype=author&query=Ho%2C+N">Nhat Ho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 9 figures; Huy Nguyen and TrungTin Nguyen contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12707" title="Abstract">arXiv:2305.12707</a> (replaced) [<a href="/pdf/2305.12707" title="Download PDF">pdf</a>, <a href="/format/2305.12707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying Association Capabilities of Large Language Models and Its  Implications on Privacy Leakage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+H">Hanyin Shao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K+C">Kevin Chen-Chuan Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EACL 2024 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13179" title="Abstract">arXiv:2305.13179</a> (replaced) [<a href="/pdf/2305.13179" title="Download PDF">pdf</a>, <a href="/format/2305.13179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teaching Probabilistic Logical Reasoning to Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nafar%2C+A">Aliakbar Nafar</a>, 
<a href="/search/cs?searchtype=author&query=Venable%2C+K+B">Kristen Brent Venable</a>, 
<a href="/search/cs?searchtype=author&query=Kordjamshidi%2C+P">Parisa Kordjamshidi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is part of the proceedings of EACL Findings 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15984" title="Abstract">arXiv:2305.15984</a> (replaced) [<a href="/pdf/2305.15984" title="Download PDF">pdf</a>, <a href="/format/2305.15984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Inter-treatment Information Sharing for Individualized Treatment  Effects Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chauhan%2C+V+K">Vinod Kumar Chauhan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiandong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ghosheh%2C+G">Ghadeer Ghosheh</a>, 
<a href="/search/cs?searchtype=author&query=Molaei%2C+S">Soheila Molaei</a>, 
<a href="/search/cs?searchtype=author&query=Clifton%2C+D+A">David A. Clifton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to The 27th International Conference on Artificial Intelligence and Statistics (AISTATS) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18288" title="Abstract">arXiv:2305.18288</a> (replaced) [<a href="/pdf/2305.18288" title="Download PDF">pdf</a>, <a href="/format/2305.18288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linearizability of flows by embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kvalheim%2C+M+D">Matthew D. Kvalheim</a>, 
<a href="/search/math?searchtype=author&query=Arathoon%2C+P">Philip Arathoon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 1 figure; v5 contains reference updates and fixes an error in Theorem 3
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18582" title="Abstract">arXiv:2305.18582</a> (replaced) [<a href="/pdf/2305.18582" title="Download PDF">pdf</a>, <a href="/format/2305.18582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Association for Language Model Updating by Mitigating  LM-Logical Discrepancy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+P">Pengfei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Heng Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02611" title="Abstract">arXiv:2306.02611</a> (replaced) [<a href="/pdf/2306.02611" title="Download PDF">pdf</a>, <a href="/format/2306.02611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Population Update Can Provably Be Helpful in Multi-Objective  Evolutionary Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bian%2C+C">Chao Bian</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yawen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Miqing Li</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chao Qian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06881" title="Abstract">arXiv:2306.06881</a> (replaced) [<a href="/pdf/2306.06881" title="Download PDF">pdf</a>, <a href="/format/2306.06881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unmasking Deepfakes: Masked Autoencoding Spatiotemporal Transformers for  Enhanced Video Forgery Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Sayantan Das</a>, 
<a href="/search/cs?searchtype=author&query=Kolahdouzi%2C+M">Mojtaba Kolahdouzi</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96zparlak%2C+L">Levent &#xd6;zparlak</a>, 
<a href="/search/cs?searchtype=author&query=Hickie%2C+W">Will Hickie</a>, 
<a href="/search/cs?searchtype=author&query=Etemad%2C+A">Ali Etemad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by IEEE International Joint Conference on Biometrics (IJCB 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08167" title="Abstract">arXiv:2306.08167</a> (replaced) [<a href="/pdf/2306.08167" title="Download PDF">pdf</a>, <a href="/format/2306.08167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Where Does My Model Underperform? A Human Evaluation of Slice Discovery  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Johnson%2C+N">Nari Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Cabrera%2C+%C3%81+A">&#xc1;ngel Alexander Cabrera</a>, 
<a href="/search/cs?searchtype=author&query=Plumb%2C+G">Gregory Plumb</a>, 
<a href="/search/cs?searchtype=author&query=Talwalkar%2C+A">Ameet Talwalkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the AAAI Conference on Human Computation and Crowdsourcing, 11(1), 65-76. Best Paper Award
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09805" title="Abstract">arXiv:2306.09805</a> (replaced) [<a href="/pdf/2306.09805" title="Download PDF">pdf</a>, <a href="/format/2306.09805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mimicking Better by Matching the Approximate Action Distribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramos%2C+J+A+C">Jo&#xe3;o A. C&#xe2;ndido Ramos</a>, 
<a href="/search/cs?searchtype=author&query=Blond%C3%A9%2C+L">Lionel Blond&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Takeishi%2C+N">Naoya Takeishi</a>, 
<a href="/search/cs?searchtype=author&query=Kalousis%2C+A">Alexandros Kalousis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10943" title="Abstract">arXiv:2306.10943</a> (replaced) [<a href="/pdf/2306.10943" title="Download PDF">pdf</a>, <a href="/format/2306.10943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Matching of Real and Generated Data Statistics in  Generative Adversarial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Pilar%2C+P">Philipp Pilar</a>, 
<a href="/search/stat?searchtype=author&query=Wahlstr%C3%B6m%2C+N">Niklas Wahlstr&#xf6;m</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11128" title="Abstract">arXiv:2306.11128</a> (replaced) [<a href="/pdf/2306.11128" title="Download PDF">pdf</a>, <a href="/format/2306.11128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAMMARL: Conformal Action Modeling in Multi Agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+N">Nikunj Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Nath%2C+S">Somjit Nath</a>, 
<a href="/search/cs?searchtype=author&query=Kahou%2C+S+E">Samira Ebrahimi Kahou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12569" title="Abstract">arXiv:2306.12569</a> (replaced) [<a href="/pdf/2306.12569" title="Download PDF">pdf</a>, <a href="/format/2306.12569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trotter error bounds and dynamic multi-product formulas for Hamiltonian  simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Zhuk%2C+S">Sergiy Zhuk</a>, 
<a href="/search/quant-ph?searchtype=author&query=Robertson%2C+N">Niall Robertson</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bravyi%2C+S">Sergey Bravyi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Mathematical Physics (math-ph); Numerical Analysis (math.NA); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16593" title="Abstract">arXiv:2306.16593</a> (replaced) [<a href="/pdf/2306.16593" title="Download PDF">pdf</a>, <a href="/format/2306.16593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autoregressive with Slack Time Series Model for Forecasting a  Partially-Observed Dynamical Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Okuno%2C+A">Akifumi Okuno</a>, 
<a href="/search/stat?searchtype=author&query=Morishita%2C+Y">Yuya Morishita</a>, 
<a href="/search/stat?searchtype=author&query=Mototake%2C+Y">Yoh-ichi Mototake</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 6 figures, accepted to IEEE Access
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16978" title="Abstract">arXiv:2306.16978</a> (replaced) [<a href="/pdf/2306.16978" title="Download PDF">pdf</a>, <a href="/format/2306.16978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Coverage Paths in Unknown Environments with Deep Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jonnarth%2C+A">Arvi Jonnarth</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Felsberg%2C+M">Michael Felsberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17302" title="Abstract">arXiv:2306.17302</a> (replaced) [<a href="/pdf/2306.17302" title="Download PDF">pdf</a>, <a href="/format/2306.17302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Roadside Perception: an Automated Data Synthesis Pipeline  Minimizing Human Annotation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rusheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+D">Depu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Bassett%2C+L">Lance Bassett</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Shengyin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Z">Zhengxia Zou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H+X">Henry X. Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Intelligent Vehicles
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03177" title="Abstract">arXiv:2307.03177</a> (replaced) [<a href="/pdf/2307.03177" title="Download PDF">pdf</a>, <a href="/format/2307.03177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PanoDiffusion: 360-degree Panorama Outpainting via Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chuanxia Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Cham%2C+T">Tat-Jen Cham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://sm0kywu.github.io/panodiffusion/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03789" title="Abstract">arXiv:2307.03789</a> (replaced) [<a href="/pdf/2307.03789" title="Download PDF">pdf</a>, <a href="/format/2307.03789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthesizing Forestry Images Conditioned on Plant Phenotype Using a  Generative Adversarial Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pal%2C+D">Debasmita Pal</a>, 
<a href="/search/cs?searchtype=author&query=Ross%2C+A">Arun Ross</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03816" title="Abstract">arXiv:2307.03816</a> (replaced) [<a href="/pdf/2307.03816" title="Download PDF">pdf</a>, <a href="/ps/2307.03816" title="Download PostScript">ps</a>, <a href="/format/2307.03816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Combinatorial Characterization of Supervised Online Learnability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raman%2C+V">Vinod Raman</a>, 
<a href="/search/cs?searchtype=author&query=Subedi%2C+U">Unique Subedi</a>, 
<a href="/search/cs?searchtype=author&query=Tewari%2C+A">Ambuj Tewari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages. arXiv admin note: text overlap with <a href="/abs/2306.06247">arXiv:2306.06247</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04296" title="Abstract">arXiv:2307.04296</a> (replaced) [<a href="/pdf/2307.04296" title="Download PDF">pdf</a>, <a href="/format/2307.04296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> K-Space-Aware Cross-Modality Score for Synthesized Neuroimage Quality  Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xie%2C+G">Guoyang Xie</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jinbao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yawen Huang</a>, 
<a href="/search/eess?searchtype=author&query=Lyu%2C+J">Jiayi Lyu</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+F">Feng Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+Y">Yefeng Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+Y">Yaochu Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04385" title="Abstract">arXiv:2307.04385</a> (replaced) [<a href="/pdf/2307.04385" title="Download PDF">pdf</a>, <a href="/format/2307.04385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Exponential Growth of Geometric Shapes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almalki%2C+N">Nada Almalki</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Siddharth Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Michail%2C+O">Othon Michail</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages with 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Geometry (cs.CG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04526" title="Abstract">arXiv:2307.04526</a> (replaced) [<a href="/pdf/2307.04526" title="Download PDF">pdf</a>, <a href="/format/2307.04526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Expanding Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+R">Rupert Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Menzenbach%2C+R">Robin Menzenbach</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>, 
<a href="/search/cs?searchtype=author&query=Mundt%2C+M">Martin Mundt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05811" title="Abstract">arXiv:2307.05811</a> (replaced) [<a href="/pdf/2307.05811" title="Download PDF">pdf</a>, <a href="/ps/2307.05811" title="Download PostScript">ps</a>, <a href="/format/2307.05811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Twin-width of graphs on surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kr%C3%A1%C4%BE%2C+D">Daniel Kr&#xe1;&#x13e;</a>, 
<a href="/search/math?searchtype=author&query=Pek%C3%A1rkov%C3%A1%2C+K">Krist&#xfd;na Pek&#xe1;rkov&#xe1;</a>, 
<a href="/search/math?searchtype=author&query=%C5%A0torgel%2C+K">Kenny &#x160;torgel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07514" title="Abstract">arXiv:2307.07514</a> (replaced) [<a href="/pdf/2307.07514" title="Download PDF">pdf</a>, <a href="/ps/2307.07514" title="Download PostScript">ps</a>, <a href="/format/2307.07514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainability is NOT a Game
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marques-Silva%2C+J">Joao Marques-Silva</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanxiang Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08948" title="Abstract">arXiv:2307.08948</a> (replaced) [<a href="/pdf/2307.08948" title="Download PDF">pdf</a>, <a href="/format/2307.08948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial-Delay Enumeration of Large Maximal Common Independent Sets in  Two Matroids and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kobayashi%2C+Y">Yasuaki Kobayashi</a>, 
<a href="/search/math?searchtype=author&query=Kurita%2C+K">Kazuhiro Kurita</a>, 
<a href="/search/math?searchtype=author&query=Wasa%2C+K">Kunihiro Wasa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10635" title="Abstract">arXiv:2307.10635</a> (replaced) [<a href="/pdf/2307.10635" title="Download PDF">pdf</a>, <a href="/format/2307.10635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SciBench: Evaluating College-Level Scientific Problem-Solving Abilities  of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Ziniu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+P">Pan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yanqiao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jieyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Subramaniam%2C+S">Satyen Subramaniam</a>, 
<a href="/search/cs?searchtype=author&query=Loomba%2C+A+R">Arjun R. Loomba</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shichang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yizhou Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Results updated; multimodal dataset added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12609" title="Abstract">arXiv:2307.12609</a> (replaced) [<a href="/pdf/2307.12609" title="Download PDF">pdf</a>, <a href="/format/2307.12609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AndroLibZoo: A Reliable Dataset of Libraries Based on Software  Dependency Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Samhi%2C+J">Jordan Samhi</a>, 
<a href="/search/cs?searchtype=author&query=Bissyand%C3%A9%2C+T+F">Tegawend&#xe9; F. Bissyand&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+J">Jacques Klein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13566" title="Abstract">arXiv:2307.13566</a> (replaced) [<a href="/pdf/2307.13566" title="Download PDF">pdf</a>, <a href="/format/2307.13566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Imperfect XAI on Human-AI Decision-Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morrison%2C+K">Katelyn Morrison</a>, 
<a href="/search/cs?searchtype=author&query=Spitzer%2C+P">Philipp Spitzer</a>, 
<a href="/search/cs?searchtype=author&query=Turri%2C+V">Violet Turri</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+M">Michelle Feng</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BChl%2C+N">Niklas K&#xfc;hl</a>, 
<a href="/search/cs?searchtype=author&query=Perer%2C+A">Adam Perer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACM CSCW 2024. 27 pages, 9 figures, 1 table, additional figures/table in the appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04451" title="Abstract">arXiv:2308.04451</a> (replaced) [<a href="/pdf/2308.04451" title="Download PDF">pdf</a>, <a href="/format/2308.04451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vulnerabilities in AI Code Generators: Exploring Targeted Data Poisoning  Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cotroneo%2C+D">Domenico Cotroneo</a>, 
<a href="/search/cs?searchtype=author&query=Improta%2C+C">Cristina Improta</a>, 
<a href="/search/cs?searchtype=author&query=Liguori%2C+P">Pietro Liguori</a>, 
<a href="/search/cs?searchtype=author&query=Natella%2C+R">Roberto Natella</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the International Conference on Program Comprehension 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05078" title="Abstract">arXiv:2308.05078</a> (replaced) [<a href="/pdf/2308.05078" title="Download PDF">pdf</a>, <a href="/format/2308.05078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On The Capacity of Low-Rank Dyadic Fading Channels in the Low-SNR Regime
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+K">Kamal Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10873" title="Abstract">arXiv:2308.10873</a> (replaced) [<a href="/pdf/2308.10873" title="Download PDF">pdf</a>, <a href="/format/2308.10873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpikingBERT: Distilling BERT to Train Spiking Language Models Using  Implicit Differentiation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bal%2C+M">Malyaban Bal</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+A">Abhronil Sengupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11736" title="Abstract">arXiv:2308.11736</a> (replaced) [<a href="/pdf/2308.11736" title="Download PDF">pdf</a>, <a href="/format/2308.11736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smooth min-entropy lower bounds for approximation chains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Marwah%2C+A">Ashutosh Marwah</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dupuis%2C+F">Fr&#xe9;d&#xe9;ric Dupuis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Section on source correlations is split off into a separate paper; Testing for approximate EAT has been added; total number of pages= 65, pages 42-61 are appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13425" title="Abstract">arXiv:2308.13425</a> (replaced) [<a href="/pdf/2308.13425" title="Download PDF">pdf</a>, <a href="/format/2308.13425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe and Quasi-Optimal Autonomous Navigation in Environments with Convex  Obstacles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cheniouni%2C+I">Ishak Cheniouni</a>, 
<a href="/search/eess?searchtype=author&query=Berkane%2C+S">Soulaimane Berkane</a>, 
<a href="/search/eess?searchtype=author&query=Tayebi%2C+A">Abdelhamid Tayebi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2302.12309">arXiv:2302.12309</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15515" title="Abstract">arXiv:2308.15515</a> (replaced) [<a href="/pdf/2308.15515" title="Download PDF">pdf</a>, <a href="/format/2308.15515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Algorithms for 2-Packing Sets on Arbitrary Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borowitz%2C+J">Jannick Borowitz</a>, 
<a href="/search/cs?searchtype=author&query=Gro%C3%9Fmann%2C+E">Ernestine Gro&#xdf;mann</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+C">Christian Schulz</a>, 
<a href="/search/cs?searchtype=author&query=Schweisgut%2C+D">Dominik Schweisgut</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16406" title="Abstract">arXiv:2308.16406</a> (replaced) [<a href="/pdf/2308.16406" title="Download PDF">pdf</a>, <a href="/format/2308.16406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CktGNN: Circuit Graph Neural Network for Electronic Design Automation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zehao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+W">Weidong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Muhan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yixin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICLR (International Conference on Learning Representations) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00155" title="Abstract">arXiv:2309.00155</a> (replaced) [<a href="/pdf/2309.00155" title="Download PDF">pdf</a>, <a href="/format/2309.00155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM in the Shell: Generative Honeypots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sladi%C4%87%2C+M">Muris Sladi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Valeros%2C+V">Veronica Valeros</a>, 
<a href="/search/cs?searchtype=author&query=Catania%2C+C">Carlos Catania</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+S">Sebastian Garcia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages. 2 figures. 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00588" title="Abstract">arXiv:2309.00588</a> (replaced) [<a href="/pdf/2309.00588" title="Download PDF">pdf</a>, <a href="/format/2309.00588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discrete Morphological Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marcondes%2C+D">Diego Marcondes</a>, 
<a href="/search/cs?searchtype=author&query=Barrera%2C+J">Junior Barrera</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00738" title="Abstract">arXiv:2309.00738</a> (replaced) [<a href="/pdf/2309.00738" title="Download PDF">pdf</a>, <a href="/format/2309.00738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking the Power of Graph Canonization in Graph Representation  Learning with Stability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zehao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Muhan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Payne%2C+P+R+O">Philip R.O. Payne</a>, 
<a href="/search/cs?searchtype=author&query=Province%2C+M+A">Michael A Province</a>, 
<a href="/search/cs?searchtype=author&query=Cruchaga%2C+C">Carlos Cruchaga</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tianyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fuhai Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yixin Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01765" title="Abstract">arXiv:2309.01765</a> (replaced) [<a href="/pdf/2309.01765" title="Download PDF">pdf</a>, <a href="/format/2309.01765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BLiSS: Bootstrapped Linear Shape Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muralikrishnan%2C+S">Sanjeev Muralikrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C+P">Chun-Hao Paul Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ceylan%2C+D">Duygu Ceylan</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+N+J">Niloy J. Mitra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03631" title="Abstract">arXiv:2309.03631</a> (replaced) [<a href="/pdf/2309.03631" title="Download PDF">pdf</a>, <a href="/format/2309.03631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Insights Into the Inner Workings of Transformer Models for Protein  Function Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wenzel%2C+M">Markus Wenzel</a>, 
<a href="/search/cs?searchtype=author&query=Gr%C3%BCner%2C+E">Erik Gr&#xfc;ner</a>, 
<a href="/search/cs?searchtype=author&query=Strodthoff%2C+N">Nils Strodthoff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 12 figures, 5 tables, source code available at <a href="https://github.com/markuswenzel/xai-proteins">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Bioinformatics (2024) btae031
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06358" title="Abstract">arXiv:2309.06358</a> (replaced) [<a href="/pdf/2309.06358" title="Download PDF">pdf</a>, <a href="/format/2309.06358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Data Augmentation using LLMs improves Distributional  Robustness in Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+A+G">Arijit Ghosh Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Chadha%2C+A">Aman Chadha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 tables, 1 figure, To appear at EACL 2024 Student Research Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08345" title="Abstract">arXiv:2309.08345</a> (replaced) [<a href="/pdf/2309.08345" title="Download PDF">pdf</a>, <a href="/format/2309.08345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Distribution Bottlenecks in Grounding Language Models to Knowledge  Bases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shu%2C+Y">Yiheng Shu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhiwei Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08968" title="Abstract">arXiv:2309.08968</a> (replaced) [<a href="/pdf/2309.08968" title="Download PDF">pdf</a>, <a href="/format/2309.08968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sorted LLaMA: Unlocking the Potential of Intermediate Layers of Large  Language Models for Dynamic Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kavehzadeh%2C+P">Parsa Kavehzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Valipour%2C+M">Mojtaba Valipour</a>, 
<a href="/search/cs?searchtype=author&query=Tahaei%2C+M">Marzieh Tahaei</a>, 
<a href="/search/cs?searchtype=author&query=Ghodsi%2C+A">Ali Ghodsi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Boxing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Rezagholizadeh%2C+M">Mehdi Rezagholizadeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EACL 2024 - Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11641" title="Abstract">arXiv:2309.11641</a> (replaced) [<a href="/pdf/2309.11641" title="Download PDF">pdf</a>, <a href="/format/2309.11641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attentive VQ-VAE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoyos%2C+A">Angello Hoyos</a>, 
<a href="/search/cs?searchtype=author&query=Rivera%2C+M">Mariano Rivera</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, 2 table2, 1 pseudo-code
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16575" title="Abstract">arXiv:2309.16575</a> (replaced) [<a href="/pdf/2309.16575" title="Download PDF">pdf</a>, <a href="/ps/2309.16575" title="Download PostScript">ps</a>, <a href="/format/2309.16575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Benchmark for Learning to Translate a New Language from One Grammar  Book
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tanzer%2C+G">Garrett Tanzer</a>, 
<a href="/search/cs?searchtype=author&query=Suzgun%2C+M">Mirac Suzgun</a>, 
<a href="/search/cs?searchtype=author&query=Visser%2C+E">Eline Visser</a>, 
<a href="/search/cs?searchtype=author&query=Jurafsky%2C+D">Dan Jurafsky</a>, 
<a href="/search/cs?searchtype=author&query=Melas-Kyriazi%2C+L">Luke Melas-Kyriazi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project site: <a href="https://lukemelas.github.io/mtob/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17179" title="Abstract">arXiv:2309.17179</a> (replaced) [<a href="/pdf/2309.17179" title="Download PDF">pdf</a>, <a href="/format/2309.17179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alphazero-like Tree-Search can Guide Large Language Model Decoding and  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xidong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Ziyu Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+M">Muning Wen</a>, 
<a href="/search/cs?searchtype=author&query=McAleer%2C+S+M">Stephen Marcus McAleer</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Ying Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03094" title="Abstract">arXiv:2310.03094</a> (replaced) [<a href="/pdf/2310.03094" title="Download PDF">pdf</a>, <a href="/format/2310.03094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model Cascades with Mixture of Thoughts Representations  for Cost-efficient Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+M">Murong Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Liang Du</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Ziyu Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05207" title="Abstract">arXiv:2310.05207</a> (replaced) [<a href="/pdf/2310.05207" title="Download PDF">pdf</a>, <a href="/format/2310.05207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Facial Action Unit Detection Based on Multi-task Learning Strategy for  Unlabeled Facial Images in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shang%2C+Z">Ziqiao Shang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 6 figure, submitted to an Elsevier journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07160" title="Abstract">arXiv:2310.07160</a> (replaced) [<a href="/pdf/2310.07160" title="Download PDF">pdf</a>, <a href="/format/2310.07160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLark: A Multimodal Instruction-Following Language Model for Music
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gardner%2C+J">Josh Gardner</a>, 
<a href="/search/cs?searchtype=author&query=Durand%2C+S">Simon Durand</a>, 
<a href="/search/cs?searchtype=author&query=Stoller%2C+D">Daniel Stoller</a>, 
<a href="/search/cs?searchtype=author&query=Bittner%2C+R+M">Rachel M. Bittner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07665" title="Abstract">arXiv:2310.07665</a> (replaced) [<a href="/pdf/2310.07665" title="Download PDF">pdf</a>, <a href="/format/2310.07665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Backtracking Counterfactuals for Causally Compliant Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kladny%2C+K">Klaus-Rudolf Kladny</a>, 
<a href="/search/cs?searchtype=author&query=von+K%C3%BCgelgen%2C+J">Julius von K&#xfc;gelgen</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>, 
<a href="/search/cs?searchtype=author&query=Muehlebach%2C+M">Michael Muehlebach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10461" title="Abstract">arXiv:2310.10461</a> (replaced) [<a href="/pdf/2310.10461" title="Download PDF">pdf</a>, <a href="/format/2310.10461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Selection of Zero-shot Anomaly Detectors in the Absence of Labeled  Validation Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fung%2C+C">Clement Fung</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+C">Chen Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Aodong Li</a>, 
<a href="/search/cs?searchtype=author&query=Rudolph%2C+M">Maja Rudolph</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11781" title="Abstract">arXiv:2310.11781</a> (replaced) [<a href="/pdf/2310.11781" title="Download PDF">pdf</a>, <a href="/format/2310.11781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blind estimation of audio effects using an auto-encoder approach and  differentiable digital signal processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peladeau%2C+C">C&#xf4;me Peladeau</a>, 
<a href="/search/cs?searchtype=author&query=Peeters%2C+G">Geoffroy Peeters</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13475" title="Abstract">arXiv:2310.13475</a> (replaced) [<a href="/pdf/2310.13475" title="Download PDF">pdf</a>, <a href="/ps/2310.13475" title="Download PostScript">ps</a>, <a href="/format/2310.13475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Magnetization of Flat Superconducting Films on Ferromagnetic Substrates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Prigozhin%2C+L">Leonid Prigozhin</a>, 
<a href="/search/cond-mat?searchtype=author&query=Sokolovsky%2C+V">Vladimir Sokolovsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Superconductivity (cond-mat.supr-con)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14751" title="Abstract">arXiv:2310.14751</a> (replaced) [<a href="/pdf/2310.14751" title="Download PDF">pdf</a>, <a href="/format/2310.14751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient and Interpretable Bandit Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+S">Subhojyoti Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+R">Ruihao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Kveton%2C+B">Branislav Kveton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14894" title="Abstract">arXiv:2310.14894</a> (replaced) [<a href="/pdf/2310.14894" title="Download PDF">pdf</a>, <a href="/format/2310.14894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Universal Explainer (LUX) -- a rule-based explainer with factual,  counterfactual and visual explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bobek%2C+S">Szymon Bobek</a>, 
<a href="/search/cs?searchtype=author&query=Nalepa%2C+G+J">Grzegorz J. Nalepa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16355" title="Abstract">arXiv:2310.16355</a> (replaced) [<a href="/pdf/2310.16355" title="Download PDF">pdf</a>, <a href="/format/2310.16355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RedCoast: A Lightweight Tool to Automate Distributed Training of LLMs on  Any GPU/TPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+B">Bowen Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lijuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yonghao Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jindong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+E">Eric Xing</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhiting Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> RedCoast (Redco) has been released under Apache License 2.0 at <a href="https://github.com/tanyuqian/redco">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17042" title="Abstract">arXiv:2310.17042</a> (replaced) [<a href="/pdf/2310.17042" title="Download PDF">pdf</a>, <a href="/format/2310.17042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StochGradAdam: Accelerating Neural Networks Training with Stochastic  Gradient Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yun%2C+J">Juyoung Yun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18235" title="Abstract">arXiv:2310.18235</a> (replaced) [<a href="/pdf/2310.18235" title="Download PDF">pdf</a>, <a href="/format/2310.18235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Davidsonian Scene Graph: Improving Reliability in Fine-grained  Evaluation for Text-to-Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+J">Jaemin Cho</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yushi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+R">Roopal Garg</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+P">Peter Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+R">Ranjay Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Baldridge%2C+J">Jason Baldridge</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+M">Mohit Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Pont-Tuset%2C+J">Jordi Pont-Tuset</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Su Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024; Project website: <a href="https://google.github.io/dsg">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19064" title="Abstract">arXiv:2310.19064</a> (replaced) [<a href="/pdf/2310.19064" title="Download PDF">pdf</a>, <a href="/format/2310.19064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Apple Tasting: Combinatorial Dimensions and Minimax Rates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raman%2C+V">Vinod Raman</a>, 
<a href="/search/cs?searchtype=author&query=Subedi%2C+U">Unique Subedi</a>, 
<a href="/search/cs?searchtype=author&query=Raman%2C+A">Ananth Raman</a>, 
<a href="/search/cs?searchtype=author&query=Tewari%2C+A">Ambuj Tewari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00109" title="Abstract">arXiv:2311.00109</a> (replaced) [<a href="/pdf/2311.00109" title="Download PDF">pdf</a>, <a href="/format/2311.00109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FairWASP: Fast and Optimal Fair Wasserstein Pre-processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zikai Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Dalmasso%2C+N">Niccol&#xf2; Dalmasso</a>, 
<a href="/search/cs?searchtype=author&query=Mishler%2C+A">Alan Mishler</a>, 
<a href="/search/cs?searchtype=author&query=Potluru%2C+V+K">Vamsi K. Potluru</a>, 
<a href="/search/cs?searchtype=author&query=Balch%2C+T">Tucker Balch</a>, 
<a href="/search/cs?searchtype=author&query=Veloso%2C+M">Manuela Veloso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024, Main Track. 15 pages, 4 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05436" title="Abstract">arXiv:2311.05436</a> (replaced) [<a href="/pdf/2311.05436" title="Download PDF">pdf</a>, <a href="/format/2311.05436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Coresets via Optimal Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Xiong%2C+Z">Zikai Xiong</a>, 
<a href="/search/stat?searchtype=author&query=Dalmasso%2C+N">Niccol&#xf2; Dalmasso</a>, 
<a href="/search/stat?searchtype=author&query=Sharma%2C+S">Shubham Sharma</a>, 
<a href="/search/stat?searchtype=author&query=Lecue%2C+F">Freddy Lecue</a>, 
<a href="/search/stat?searchtype=author&query=Magazzeni%2C+D">Daniele Magazzeni</a>, 
<a href="/search/stat?searchtype=author&query=Potluru%2C+V+K">Vamsi K. Potluru</a>, 
<a href="/search/stat?searchtype=author&query=Balch%2C+T">Tucker Balch</a>, 
<a href="/search/stat?searchtype=author&query=Veloso%2C+M">Manuela Veloso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 8 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06623" title="Abstract">arXiv:2311.06623</a> (replaced) [<a href="/pdf/2311.06623" title="Download PDF">pdf</a>, <a href="/format/2311.06623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VT-Former: A Transformer-based Vehicle Trajectory Prediction Approach  For Intelligent Highway Transportation Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pazho%2C+A+D">Armin Danesh Pazho</a>, 
<a href="/search/cs?searchtype=author&query=Katariya%2C+V">Vinit Katariya</a>, 
<a href="/search/cs?searchtype=author&query=Noghre%2C+G+A">Ghazal Alinezhad Noghre</a>, 
<a href="/search/cs?searchtype=author&query=Tabkhi%2C+H">Hamed Tabkhi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08936" title="Abstract">arXiv:2311.08936</a> (replaced) [<a href="/pdf/2311.08936" title="Download PDF">pdf</a>, <a href="/format/2311.08936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Confident Naturalness Explanation (CNE): A Framework to Explain and  Assess Patterns Forming Naturalness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Emam%2C+A">Ahmed Emam</a>, 
<a href="/search/cs?searchtype=author&query=Farag%2C+M">Mohamed Farag</a>, 
<a href="/search/cs?searchtype=author&query=Roscher%2C+R">Ribana Roscher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09656" title="Abstract">arXiv:2311.09656</a> (replaced) [<a href="/pdf/2311.09656" title="Download PDF">pdf</a>, <a href="/format/2311.09656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured Chemistry Reasoning with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+S">Siru Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhuosheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Bing Yan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jiawei Han</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+L">Lianhui Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09830" title="Abstract">arXiv:2311.09830</a> (replaced) [<a href="/pdf/2311.09830" title="Download PDF">pdf</a>, <a href="/format/2311.09830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoPlanBench: Automatically generating benchmarks for LLM planners from  PDDL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stein%2C+K">Katharina Stein</a>, 
<a href="/search/cs?searchtype=author&query=Fi%C5%A1er%2C+D">Daniel Fi&#x161;er</a>, 
<a href="/search/cs?searchtype=author&query=Hoffmann%2C+J">J&#xf6;rg Hoffmann</a>, 
<a href="/search/cs?searchtype=author&query=Koller%2C+A">Alexander Koller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09922" title="Abstract">arXiv:2311.09922</a> (replaced) [<a href="/e-print/2311.09922" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast multiplication by two&#x27;s complement addition of numbers represented  as a set of polynomial radix 2 indexes, stored as an integer list for  massively parallel computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stocks%2C+M">Mark Stocks</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> withdrawn to review some details of the text for mathematical accuracy and proof. We plan to resubmit
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Software (cs.MS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10052" title="Abstract">arXiv:2311.10052</a> (replaced) [<a href="/pdf/2311.10052" title="Download PDF">pdf</a>, <a href="/format/2311.10052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entanglement buffering with two quantum memories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Davies%2C+B">Bethany Davies</a>, 
<a href="/search/quant-ph?searchtype=author&query=I%C3%B1esta%2C+%C3%81+G">&#xc1;lvaro G. I&#xf1;esta</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wehner%2C+S">Stephanie Wehner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12944" title="Abstract">arXiv:2311.12944</a> (replaced) [<a href="/pdf/2311.12944" title="Download PDF">pdf</a>, <a href="/format/2311.12944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SkyCharge: Deploying Unmanned Aerial Vehicles for Dynamic Load  Optimization in Solar Small Cell 5G Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dave%2C+D">Daksh Dave</a>, 
<a href="/search/cs?searchtype=author&query=Chamola%2C+V">Vinay Chamola</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+S">Sandeep Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Zeadally%2C+S">Sherali Zeadally</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13668" title="Abstract">arXiv:2311.13668</a> (replaced) [<a href="/pdf/2311.13668" title="Download PDF">pdf</a>, <a href="/format/2311.13668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAIRA-1: A specialised large multimodal model for radiology report  generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hyland%2C+S+L">Stephanie L. Hyland</a>, 
<a href="/search/cs?searchtype=author&query=Bannur%2C+S">Shruthi Bannur</a>, 
<a href="/search/cs?searchtype=author&query=Bouzid%2C+K">Kenza Bouzid</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+D+C">Daniel C. Castro</a>, 
<a href="/search/cs?searchtype=author&query=Ranjit%2C+M">Mercy Ranjit</a>, 
<a href="/search/cs?searchtype=author&query=Schwaighofer%2C+A">Anton Schwaighofer</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez-Garc%C3%ADa%2C+F">Fernando P&#xe9;rez-Garc&#xed;a</a>, 
<a href="/search/cs?searchtype=author&query=Salvatelli%2C+V">Valentina Salvatelli</a>, 
<a href="/search/cs?searchtype=author&query=Srivastav%2C+S">Shaury Srivastav</a>, 
<a href="/search/cs?searchtype=author&query=Thieme%2C+A">Anja Thieme</a>, 
<a href="/search/cs?searchtype=author&query=Codella%2C+N">Noel Codella</a>, 
<a href="/search/cs?searchtype=author&query=Lungren%2C+M+P">Matthew P. Lungren</a>, 
<a href="/search/cs?searchtype=author&query=Wetscherek%2C+M+T">Maria Teodora Wetscherek</a>, 
<a href="/search/cs?searchtype=author&query=Oktay%2C+O">Ozan Oktay</a>, 
<a href="/search/cs?searchtype=author&query=Alvarez-Valle%2C+J">Javier Alvarez-Valle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 9 tables, 5 figures. v2 adds test IDs and image encoder citation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14049" title="Abstract">arXiv:2311.14049</a> (replaced) [<a href="/pdf/2311.14049" title="Download PDF">pdf</a>, <a href="/format/2311.14049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessment of Deep Learning Segmentation for Real-Time Free-Breathing  Cardiac Magnetic Resonance Imaging at Rest and Under Exercise Stress
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Schilling%2C+M">Martin Schilling</a>, 
<a href="/search/eess?searchtype=author&query=Unterberg-Buchwald%2C+C">Christina Unterberg-Buchwald</a>, 
<a href="/search/eess?searchtype=author&query=Lotz%2C+J">Joachim Lotz</a>, 
<a href="/search/eess?searchtype=author&query=Uecker%2C+M">Martin Uecker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Martin Schilling and Christina Unterberg-Buchwald contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15024" title="Abstract">arXiv:2311.15024</a> (replaced) [<a href="/pdf/2311.15024" title="Download PDF">pdf</a>, <a href="/ps/2311.15024" title="Download PostScript">ps</a>, <a href="/format/2311.15024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comperative Study of Watering Hole Attack Detection Using Supervised  Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aktar%2C+M+N">Mst. Nishita Aktar</a>, 
<a href="/search/cs?searchtype=author&query=Akter%2C+S">Sornali Akter</a>, 
<a href="/search/cs?searchtype=author&query=Saad%2C+M+N+I">Md. Nusaim Islam Saad</a>, 
<a href="/search/cs?searchtype=author&query=Jisun%2C+J+H">Jakir Hosen Jisun</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+K+M">Kh. Mustafizur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Sakib%2C+M+N">Md. Nazmus Sakib</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15297" title="Abstract">arXiv:2311.15297</a> (replaced) [<a href="/pdf/2311.15297" title="Download PDF">pdf</a>, <a href="/format/2311.15297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllable Expensive Multi-objective Learning with Warm-starting  Bayesian Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q">Quang-Huy Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+L+P">Long P. Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Viet%2C+H+V">Hoang V. Viet</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+D+D">Dung D. Le</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15960" title="Abstract">arXiv:2311.15960</a> (replaced) [<a href="/pdf/2311.15960" title="Download PDF">pdf</a>, <a href="/format/2311.15960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Program Machine Policy: Addressing Long-Horizon Tasks by Integrating  Program Synthesis and State Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yu-An Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chen-Tao Lee</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guan-Ting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Pu-Jen Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shao-Hua Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Programming Languages (cs.PL); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16594" title="Abstract">arXiv:2311.16594</a> (replaced) [<a href="/pdf/2311.16594" title="Download PDF">pdf</a>, <a href="/format/2311.16594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monitor Placement for Fault Localization in Deep Neural Network  Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei-Kai Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16609" title="Abstract">arXiv:2311.16609</a> (replaced) [<a href="/pdf/2311.16609" title="Download PDF">pdf</a>, <a href="/format/2311.16609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eigenmatrix for unstructured sparse recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ying%2C+L">Lexing Ying</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17943" title="Abstract">arXiv:2311.17943</a> (replaced) [<a href="/pdf/2311.17943" title="Download PDF">pdf</a>, <a href="/format/2311.17943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LayerCollapse: Adaptive compression of neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shabgahi%2C+S+Z">Soheil Zibakhsh Shabgahi</a>, 
<a href="/search/cs?searchtype=author&query=Shariff%2C+M+S">Mohammad Sohail Shariff</a>, 
<a href="/search/cs?searchtype=author&query=Koushanfar%2C+F">Farinaz Koushanfar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04427" title="Abstract">arXiv:2312.04427</a> (replaced) [<a href="/pdf/2312.04427" title="Download PDF">pdf</a>, <a href="/format/2312.04427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spheroidal Molecular Communication via Diffusion: Signaling Between  Homogeneous Cell Aggregates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rezaei%2C+M">Mitra Rezaei</a>, 
<a href="/search/cs?searchtype=author&query=Arjmandi%2C+H">Hamidreza Arjmandi</a>, 
<a href="/search/cs?searchtype=author&query=Zoofaghari%2C+M">Mohammad Zoofaghari</a>, 
<a href="/search/cs?searchtype=author&query=Kanebratt%2C+K">Kajsa Kanebratt</a>, 
<a href="/search/cs?searchtype=author&query=Vilen%2C+L">Liisa Vilen</a>, 
<a href="/search/cs?searchtype=author&query=Janzen%2C+D">David Janzen</a>, 
<a href="/search/cs?searchtype=author&query=Gennemark%2C+P">Peter Gennemark</a>, 
<a href="/search/cs?searchtype=author&query=Noel%2C+A">Adam Noel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages; 10 figures; accepted to appear in IEEE Transactions on Molecular, Biological, and Multi-Scale Communications. This work was presented in part at the 2023 IEEE International Conference on Communication <a href="/abs/2302.09265">arXiv:2302.09265</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cell Behavior (q-bio.CB)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07577" title="Abstract">arXiv:2312.07577</a> (replaced) [<a href="/pdf/2312.07577" title="Download PDF">pdf</a>, <a href="/format/2312.07577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Distribution Shift in Tabular Data with TableShift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gardner%2C+J">Josh Gardner</a>, 
<a href="/search/cs?searchtype=author&query=Popovic%2C+Z">Zoran Popovic</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+L">Ludwig Schmidt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Dataset and Benchmarks Track accepted version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14001" title="Abstract">arXiv:2312.14001</a> (replaced) [<a href="/pdf/2312.14001" title="Download PDF">pdf</a>, <a href="/format/2312.14001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Based Face Recognition Method using Siamese Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Solomon%2C+E">Enoch Solomon</a>, 
<a href="/search/cs?searchtype=author&query=Woubie%2C+A">Abraham Woubie</a>, 
<a href="/search/cs?searchtype=author&query=Emiru%2C+E+S">Eyael Solomon Emiru</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14378" title="Abstract">arXiv:2312.14378</a> (replaced) [<a href="/pdf/2312.14378" title="Download PDF">pdf</a>, <a href="/format/2312.14378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Attention Merging for Improved Speech Recognition and Audio  Event Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sundar%2C+A+S">Anirudh S. Sundar</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C+H">Chao-Han Huck Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+D+M">David M. Chan</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Shalini Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Ravichandran%2C+V">Venkatesh Ravichandran</a>, 
<a href="/search/cs?searchtype=author&query=Nidadavolu%2C+P+S">Phani Sankar Nidadavolu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure, ICASSP 2024 Workshop on Self-supervision in Audio, Speech and Beyond
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15122" title="Abstract">arXiv:2312.15122</a> (replaced) [<a href="/pdf/2312.15122" title="Download PDF">pdf</a>, <a href="/format/2312.15122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Is All You Need: Autonomous Driving with JAX-Accelerated  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harmel%2C+M">Moritz Harmel</a>, 
<a href="/search/cs?searchtype=author&query=Paras%2C+A">Anubhav Paras</a>, 
<a href="/search/cs?searchtype=author&query=Pasternak%2C+A">Andreas Pasternak</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+N">Nicholas Roy</a>, 
<a href="/search/cs?searchtype=author&query=Linscott%2C+G">Gary Linscott</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15824" title="Abstract">arXiv:2312.15824</a> (replaced) [<a href="/pdf/2312.15824" title="Download PDF">pdf</a>, <a href="/ps/2312.15824" title="Download PostScript">ps</a>, <a href="/format/2312.15824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Learning for Few-Shot Bird Sound Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moummad%2C+I">Ilyass Moummad</a>, 
<a href="/search/cs?searchtype=author&query=Serizel%2C+R">Romain Serizel</a>, 
<a href="/search/cs?searchtype=author&query=Farrugia%2C+N">Nicolas Farrugia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15842" title="Abstract">arXiv:2312.15842</a> (replaced) [<a href="/pdf/2312.15842" title="Download PDF">pdf</a>, <a href="/format/2312.15842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Distillation of LLM for Automatic Scoring of Science Education  Assessments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Latif%2C+E">Ehsan Latif</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+L">Luyang Fang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+P">Ping Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaoming Zhai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to AIED2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16044" title="Abstract">arXiv:2312.16044</a> (replaced) [<a href="/pdf/2312.16044" title="Download PDF">pdf</a>, <a href="/format/2312.16044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMLight: Large Language Models as Traffic Signal Control Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+S">Siqi Lai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weijia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02330" title="Abstract">arXiv:2401.02330</a> (replaced) [<a href="/e-print/2401.02330" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLaVA-Phi: Efficient Multi-Modal Assistant with Small Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yichen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Minjie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ning Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ou%2C+Z">Zhicai Ou</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+X">Xiaofeng Mou</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jian Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The datasets were incomplete as they did not include all the necessary copyrights
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02494" title="Abstract">arXiv:2401.02494</a> (replaced) [<a href="/pdf/2401.02494" title="Download PDF">pdf</a>, <a href="/format/2401.02494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing GUI for Generative AI: Charting the Design Space of Human-AI  Interactions through Task Creativity and Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zijian Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03003" title="Abstract">arXiv:2401.03003</a> (replaced) [<a href="/pdf/2401.03003" title="Download PDF">pdf</a>, <a href="/format/2401.03003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AST-T5: Structure-Aware Pretraining for Code Generation and  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+L">Linyuan Gong</a>, 
<a href="/search/cs?searchtype=author&query=Elhoushi%2C+M">Mostafa Elhoushi</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+A">Alvin Cheung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03307" title="Abstract">arXiv:2401.03307</a> (replaced) [<a href="/pdf/2401.03307" title="Download PDF">pdf</a>, <a href="/format/2401.03307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Processes of Neighborhood Change
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mori%2C+J+C+M">J. Carlos Mart&#xed;nez Mori</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhanzhan Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03630" title="Abstract">arXiv:2401.03630</a> (replaced) [<a href="/pdf/2401.03630" title="Download PDF">pdf</a>, <a href="/format/2401.03630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why Solving Multi-agent Path Finding with Large Language Model has not  Succeeded Yet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weizhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Koenig%2C+S">Sven Koenig</a>, 
<a href="/search/cs?searchtype=author&query=Dilkina%2C+B">Bistra Dilkina</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04130" title="Abstract">arXiv:2401.04130</a> (replaced) [<a href="/pdf/2401.04130" title="Download PDF">pdf</a>, <a href="/format/2401.04130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Plug-and-Play Transformer Modules for Test-Time Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiangyu Chang</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S+M">Sk Miraj Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+S+V">Srikanth V. Krishnamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Guler%2C+B">Basak Guler</a>, 
<a href="/search/cs?searchtype=author&query=Swami%2C+A">Ananthram Swami</a>, 
<a href="/search/cs?searchtype=author&query=Oymak%2C+S">Samet Oymak</a>, 
<a href="/search/cs?searchtype=author&query=Roy-Chowdhury%2C+A+K">Amit K. Roy-Chowdhury</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04846" title="Abstract">arXiv:2401.04846</a> (replaced) [<a href="/pdf/2401.04846" title="Download PDF">pdf</a>, <a href="/format/2401.04846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The inherent goodness of well educated intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Glinsky%2C+M+E">Michael E. Glinsky</a>, 
<a href="/search/econ?searchtype=author&query=Sievert%2C+S">Sharon Sievert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 12 figures, 15 equations, to be submitted to Nature
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05126" title="Abstract">arXiv:2401.05126</a> (replaced) [<a href="/pdf/2401.05126" title="Download PDF">pdf</a>, <a href="/format/2401.05126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Fine-Tuning with Domain Adaptation for Privacy-Preserving  Vision Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nagamori%2C+T">Teru Nagamori</a>, 
<a href="/search/cs?searchtype=author&query=Shiota%2C+S">Sayaka Shiota</a>, 
<a href="/search/cs?searchtype=author&query=Kiya%2C+H">Hitoshi Kiya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by APSIPA Transactions on Signal and Information Processing. arXiv admin note: substantial text overlap with <a href="/abs/2309.02556">arXiv:2309.02556</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05928" title="Abstract">arXiv:2401.05928</a> (replaced) [<a href="/pdf/2401.05928" title="Download PDF">pdf</a>, <a href="/format/2401.05928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Unhelpfulness in Emotional Support Conversations with  Multifaceted AI Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiashuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chunpu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Leong%2C+C+T">Chak Tou Leong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jing Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09773" title="Abstract">arXiv:2401.09773</a> (replaced) [<a href="/pdf/2401.09773" title="Download PDF">pdf</a>, <a href="/format/2401.09773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEINE: Structure Encoding and Interaction Network for Nuclei Instance  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ye Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+L">Linghan Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongbing Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 12 figures, 6 tables, submitted to TMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10816" title="Abstract">arXiv:2401.10816</a> (replaced) [<a href="/pdf/2401.10816" title="Download PDF">pdf</a>, <a href="/format/2401.10816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Co-Pilot for Health: Personalized Algorithmic AI Nudging to Improve  Health Outcomes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chiam%2C+J">Jodi Chiam</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+A">Aloysius Lim</a>, 
<a href="/search/cs?searchtype=author&query=Nott%2C+C">Cheryl Nott</a>, 
<a href="/search/cs?searchtype=author&query=Mark%2C+N">Nicholas Mark</a>, 
<a href="/search/cs?searchtype=author&query=Teredesai%2C+A">Ankur Teredesai</a>, 
<a href="/search/cs?searchtype=author&query=Shinde%2C+S">Sunil Shinde</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11176" title="Abstract">arXiv:2401.11176</a> (replaced) [<a href="/pdf/2401.11176" title="Download PDF">pdf</a>, <a href="/format/2401.11176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Target Localization: Benchmarking Gradient Descent Using the  Cram&#xe9;r-Rao Bound
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Venkatasubramanian%2C+S">Shyam Venkatasubramanian</a>, 
<a href="/search/eess?searchtype=author&query=Gogineni%2C+S">Sandeep Gogineni</a>, 
<a href="/search/eess?searchtype=author&query=Kang%2C+B">Bosung Kang</a>, 
<a href="/search/eess?searchtype=author&query=Rangaswamy%2C+M">Muralidhar Rangaswamy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12424" title="Abstract">arXiv:2401.12424</a> (replaced) [<a href="/pdf/2401.12424" title="Download PDF">pdf</a>, <a href="/format/2401.12424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DALex: Lexicase-like Selection via Diverse Aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+A">Andrew Ni</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Li Ding</a>, 
<a href="/search/cs?searchtype=author&query=Spector%2C+L">Lee Spector</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures. Accepted at EuroGP'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14005" title="Abstract">arXiv:2401.14005</a> (replaced) [<a href="/pdf/2401.14005" title="Download PDF">pdf</a>, <a href="/format/2401.14005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cyber-Twin: Digital Twin-boosted Autonomous Attack Detection for  Vehicular Ad-Hoc Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yigit%2C+Y">Yagmur Yigit</a>, 
<a href="/search/cs?searchtype=author&query=Panitsas%2C+I">Ioannis Panitsas</a>, 
<a href="/search/cs?searchtype=author&query=Maglaras%2C+L">Leandros Maglaras</a>, 
<a href="/search/cs?searchtype=author&query=Tassiulas%2C+L">Leandros Tassiulas</a>, 
<a href="/search/cs?searchtype=author&query=Canberk%2C+B">Berk Canberk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures, IEEE International Conference on Communications (ICC) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14241" title="Abstract">arXiv:2401.14241</a> (replaced) [<a href="/pdf/2401.14241" title="Download PDF">pdf</a>, <a href="/format/2401.14241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Algorithms for Computing Sibson Capacity and Arimoto Capacity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kamatsuka%2C+A">Akira Kamatsuka</a>, 
<a href="/search/cs?searchtype=author&query=Ishikawa%2C+Y">Yuki Ishikawa</a>, 
<a href="/search/cs?searchtype=author&query=Kazama%2C+K">Koki Kazama</a>, 
<a href="/search/cs?searchtype=author&query=Yoshida%2C+T">Takahiro Yoshida</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14423" title="Abstract">arXiv:2401.14423</a> (replaced) [<a href="/pdf/2401.14423" title="Download PDF">pdf</a>, <a href="/format/2401.14423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Design and Engineering: Introduction and Advanced Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amatriain%2C+X">Xavier Amatriain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15024" title="Abstract">arXiv:2401.15024</a> (replaced) [<a href="/pdf/2401.15024" title="Download PDF">pdf</a>, <a href="/format/2401.15024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SliceGPT: Compress Large Language Models by Deleting Rows and Columns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ashkboos%2C+S">Saleh Ashkboos</a>, 
<a href="/search/cs?searchtype=author&query=Croci%2C+M+L">Maximilian L. Croci</a>, 
<a href="/search/cs?searchtype=author&query=Nascimento%2C+M+G+d">Marcelo Gennari do Nascimento</a>, 
<a href="/search/cs?searchtype=author&query=Hoefler%2C+T">Torsten Hoefler</a>, 
<a href="/search/cs?searchtype=author&query=Hensman%2C+J">James Hensman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 8 figures, accepted at ICLR24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15811" title="Abstract">arXiv:2401.15811</a> (replaced) [<a href="/pdf/2401.15811" title="Download PDF">pdf</a>, <a href="/format/2401.15811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seller-Side Experiments under Interference Induced by Feedback Loops in  Two-Sided Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhu%2C+Z">Zhihua Zhu</a>, 
<a href="/search/stat?searchtype=author&query=Cai%2C+Z">Zheng Cai</a>, 
<a href="/search/stat?searchtype=author&query=Zheng%2C+L">Liang Zheng</a>, 
<a href="/search/stat?searchtype=author&query=Si%2C+N">Nian Si</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16108" title="Abstract">arXiv:2401.16108</a> (replaced) [<a href="/pdf/2401.16108" title="Download PDF">pdf</a>, <a href="/format/2401.16108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Future Impact Decomposition in Request-level Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaobei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuchang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xueliang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Q">Qingpeng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Lantao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Han Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+P">Peng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Gai%2C+K">Kun Gai</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+G">Guangming Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.17205" title="Abstract">arXiv:2401.17205</a> (replaced) [<a href="/pdf/2401.17205" title="Download PDF">pdf</a>, <a href="/format/2401.17205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Experiment Design with Synthetic Controls
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=H%C3%BCy%C3%BCk%2C+A">Alihan H&#xfc;y&#xfc;k</a>, 
<a href="/search/stat?searchtype=author&query=Qian%2C+Z">Zhaozhi Qian</a>, 
<a href="/search/stat?searchtype=author&query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 27th International Conference on Artificial Intelligence and Statistics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.17350" title="Abstract">arXiv:2401.17350</a> (replaced) [<a href="/pdf/2401.17350" title="Download PDF">pdf</a>, <a href="/ps/2401.17350" title="Download PostScript">ps</a>, <a href="/format/2401.17350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time Series Supplier Allocation via Deep Black-Litterman Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiayuan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wentao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuchen Fang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiaowei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+D">Dingyi Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xinke Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In submission to SIGKDD 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.18030" title="Abstract">arXiv:2401.18030</a> (replaced) [<a href="/pdf/2401.18030" title="Download PDF">pdf</a>, <a href="/ps/2401.18030" title="Download PostScript">ps</a>, <a href="/format/2401.18030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed fixed-point algorithms for dynamic convex optimization over  decentralized and unbalanced wireless networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Agrawal%2C+N">Navneet Agrawal</a>, 
<a href="/search/math?searchtype=author&query=Cavalcante%2C+R+L+G">Renato L.G. Cavalcante</a>, 
<a href="/search/math?searchtype=author&query=Stanczak%2C+S">Slawomir Stanczak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 1. Accepted 27th International Workshop on Smart Antennas (WSA 2024), and will be presented during the conference on March 17 to 19, 2024, Dresden, Germany. 2. New version with corrections
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00156" title="Abstract">arXiv:2402.00156</a> (replaced) [<a href="/pdf/2402.00156" title="Download PDF">pdf</a>, <a href="/format/2402.00156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Erie: A Declarative Grammar for Data Sonification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyeok Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yea-Seul Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hullman%2C+J">Jessica Hullman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 19 tables, 4 figures. Accepted at ACH CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.01274" title="Abstract">arXiv:2402.01274</a> (replaced) [<a href="/pdf/2402.01274" title="Download PDF">pdf</a>, <a href="/format/2402.01274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Transferability of Large-Scale Self-Supervision to Few-Shot Audio  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heggan%2C+C">Calum Heggan</a>, 
<a href="/search/cs?searchtype=author&query=Budgett%2C+S">Sam Budgett</a>, 
<a href="/search/cs?searchtype=author&query=Hosepedales%2C+T">Timothy Hosepedales</a>, 
<a href="/search/cs?searchtype=author&query=Yaghoobi%2C+M">Mehrdad Yaghoobi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera Ready version as submitted to ICASSP SASB Workshop 2024. 5 pages, 2 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.01344" title="Abstract">arXiv:2402.01344</a> (replaced) [<a href="/pdf/2402.01344" title="Download PDF">pdf</a>, <a href="/format/2402.01344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monotone, Bi-Lipschitz, and Polyak-Lojasiewicz Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruigang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dvijotham%2C+K">Krishnamurthy Dvijotham</a>, 
<a href="/search/cs?searchtype=author&query=Manchester%2C+I+R">Ian R. Manchester</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.01703" title="Abstract">arXiv:2402.01703</a> (replaced) [<a href="/pdf/2402.01703" title="Download PDF">pdf</a>, <a href="/ps/2402.01703" title="Download PostScript">ps</a>, <a href="/format/2402.01703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-Perspective Machine Learning Approach to Evaluate Police-Driver  Interaction in Los Angeles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grahama%2C+B+A+T">Benjamin A.T. Grahama</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+L">Lauren Brown</a>, 
<a href="/search/cs?searchtype=author&query=Chochlakis%2C+G">Georgios Chochlakis</a>, 
<a href="/search/cs?searchtype=author&query=Dehghani%2C+M">Morteza Dehghani</a>, 
<a href="/search/cs?searchtype=author&query=Delerme%2C+R">Raquel Delerme</a>, 
<a href="/search/cs?searchtype=author&query=Friedman%2C+B">Brittany Friedman</a>, 
<a href="/search/cs?searchtype=author&query=Graeden%2C+E">Ellie Graeden</a>, 
<a href="/search/cs?searchtype=author&query=Golazizian%2C+P">Preni Golazizian</a>, 
<a href="/search/cs?searchtype=author&query=Hebbar%2C+R">Rajat Hebbar</a>, 
<a href="/search/cs?searchtype=author&query=Hejabi%2C+P">Parsa Hejabi</a>, 
<a href="/search/cs?searchtype=author&query=Kommineni%2C+A">Aditya Kommineni</a>, 
<a href="/search/cs?searchtype=author&query=Salinas%2C+M">Mayag&#xfc;ez Salinas</a>, 
<a href="/search/cs?searchtype=author&query=Sierra-Ar%C3%A9valo%2C+M">Michael Sierra-Ar&#xe9;valo</a>, 
<a href="/search/cs?searchtype=author&query=Trager%2C+J">Jackson Trager</a>, 
<a href="/search/cs?searchtype=author&query=Weller%2C+N">Nicholas Weller</a>, 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+S">Shrikanth Narayanan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02304" title="Abstract">arXiv:2402.02304</a> (replaced) [<a href="/pdf/2402.02304" title="Download PDF">pdf</a>, <a href="/format/2402.02304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Numerical Wave Propagation Enhanced By An End-to-End Deep  Learning Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kaiser%2C+L">Luis Kaiser</a>, 
<a href="/search/math?searchtype=author&query=Tsai%2C+R">Richard Tsai</a>, 
<a href="/search/math?searchtype=author&query=Klingenberg%2C+C">Christian Klingenberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02420" title="Abstract">arXiv:2402.02420</a> (replaced) [<a href="/pdf/2402.02420" title="Download PDF">pdf</a>, <a href="/format/2402.02420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Factuality of Large Language Models in the Year 2024
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Minghan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Manzoor%2C+M+A">Muhammad Arslan Manzoor</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Georgiev%2C+G">Georgi Georgiev</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+R+J">Rocktim Jyoti Das</a>, 
<a href="/search/cs?searchtype=author&query=Nakov%2C+P">Preslav Nakov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 1 figure and 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03247" title="Abstract">arXiv:2402.03247</a> (replaced) [<a href="/pdf/2402.03247" title="Download PDF">pdf</a>, <a href="/format/2402.03247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HEANA: A Hybrid Time-Amplitude Analog Optical Accelerator with Flexible  Dataflows for Energy-Efficient CNN Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vatsavai%2C+S+S">Sairam Sri Vatsavai</a>, 
<a href="/search/cs?searchtype=author&query=Karempudi%2C+V+S+P">Venkata Sai Praneeth Karempudi</a>, 
<a href="/search/cs?searchtype=author&query=Thakkar%2C+I">Ishan Thakkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper is under review at ACM TODAES
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03256" title="Abstract">arXiv:2402.03256</a> (replaced) [<a href="/pdf/2402.03256" title="Download PDF">pdf</a>, <a href="/ps/2402.03256" title="Download PostScript">ps</a>, <a href="/format/2402.03256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Best-in-Class Policies for the Predict-then-Optimize Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Michael Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+V">Vishal Gupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03646" title="Abstract">arXiv:2402.03646</a> (replaced) [<a href="/pdf/2402.03646" title="Download PDF">pdf</a>, <a href="/format/2402.03646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lens: A Foundation Model for Network Traffic in Cybersecurity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qineng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaochang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Ziyu Yao</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+H">Huajie Shao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03762" title="Abstract">arXiv:2402.03762</a> (replaced) [<a href="/pdf/2402.03762" title="Download PDF">pdf</a>, <a href="/format/2402.03762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoD-SLAM: Monocular Dense Mapping for Unbounded 3D Scene Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Heng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhetao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lechen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yuxiang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingrui Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03781" title="Abstract">arXiv:2402.03781</a> (replaced) [<a href="/pdf/2402.03781" title="Download PDF">pdf</a>, <a href="/format/2402.03781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MolTC: Towards Molecular Relational Modeling In Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Fang%2C+J">Junfeng Fang</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+S">Shuai Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Wu%2C+C">Chang Wu</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+S">Sihang Li</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+K">Kun Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Du%2C+W">Wenjie Du</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+X">Xiang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03843" title="Abstract">arXiv:2402.03843</a> (replaced) [<a href="/pdf/2402.03843" title="Download PDF">pdf</a>, <a href="/format/2402.03843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new method for optical steel rope non-destructive damage detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+Y">Yunqing Bao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Bin Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04004" title="Abstract">arXiv:2402.04004</a> (replaced) [<a href="/pdf/2402.04004" title="Download PDF">pdf</a>, <a href="/format/2402.04004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Effect of Noise in LLM Training Data with Algorithmic  Chains of Thought
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Havrilla%2C+A">Alex Havrilla</a>, 
<a href="/search/cs?searchtype=author&query=Iyer%2C+M">Maia Iyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04377" title="Abstract">arXiv:2402.04377</a> (replaced) [<a href="/pdf/2402.04377" title="Download PDF">pdf</a>, <a href="/format/2402.04377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeRCC: Nested-Regression Coded Computing for Resilient Distributed  Prediction Serving Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moradi%2C+P">Parsa Moradi</a>, 
<a href="/search/cs?searchtype=author&query=Maddah-Ali%2C+M+A">Mohammad Ali Maddah-Ali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04424" title="Abstract">arXiv:2402.04424</a> (replaced) [<a href="/pdf/2402.04424" title="Download PDF">pdf</a>, <a href="/format/2402.04424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Binary Signaling for a Two Sensor Gaussian MAC Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sardellitti%2C+L">Luca Sardellitti</a>, 
<a href="/search/cs?searchtype=author&query=Takahara%2C+G">Glen Takahara</a>, 
<a href="/search/cs?searchtype=author&query=Alajaji%2C+F">Fady Alajaji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04471" title="Abstract">arXiv:2402.04471</a> (replaced) [<a href="/pdf/2402.04471" title="Download PDF">pdf</a>, <a href="/format/2402.04471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reductive Quantum Phase Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Papadopoulos%2C+N+J+C">Nicholas J.C. Papadopoulos</a>, 
<a href="/search/quant-ph?searchtype=author&query=Reilly%2C+J+T">Jarrod T. Reilly</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wilson%2C+J+D">John Drew Wilson</a>, 
<a href="/search/quant-ph?searchtype=author&query=Holland%2C+M+J">Murray J. Holland</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04798" title="Abstract">arXiv:2402.04798</a> (replaced) [<a href="/pdf/2402.04798" title="Download PDF">pdf</a>, <a href="/format/2402.04798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spiking-PhysFormer: Camera-Based Remote Photoplethysmography with  Parallel Spike-driven Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingxuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiankai Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoxiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Jiahao Qi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Siwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kegang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuntao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Mingxuan Liu and Jiankai Tang are co-first authors of the article
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04838" title="Abstract">arXiv:2402.04838</a> (replaced) [<a href="/pdf/2402.04838" title="Download PDF">pdf</a>, <a href="/format/2402.04838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PaDeLLM-NER: Parallel Decoding in Large Language Models for Named Entity  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jinghui Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ziwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuejing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Can Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04867" title="Abstract">arXiv:2402.04867</a> (replaced) [<a href="/pdf/2402.04867" title="Download PDF">pdf</a>, <a href="/format/2402.04867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Query Suggestion with Multi-Agent Reinforcement Learning from  Human Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+B">Bingzheng Gan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wei Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by WWW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04907" title="Abstract">arXiv:2402.04907</a> (replaced) [<a href="/pdf/2402.04907" title="Download PDF">pdf</a>, <a href="/ps/2402.04907" title="Download PostScript">ps</a>, <a href="/format/2402.04907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On a Combinatorial Problem Arising in Machine Teaching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=H%C3%A5vardstun%2C+B">Brigt H&#xe5;vardstun</a>, 
<a href="/search/math?searchtype=author&query=Kratochv%C3%ADl%2C+J">Jan Kratochv&#xed;l</a>, 
<a href="/search/math?searchtype=author&query=Sunde%2C+J">Joakim Sunde</a>, 
<a href="/search/math?searchtype=author&query=Telle%2C+J+A">Jan Arne Telle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04915" title="Abstract">arXiv:2402.04915</a> (replaced) [<a href="/pdf/2402.04915" title="Download PDF">pdf</a>, <a href="/format/2402.04915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Moco: A Learnable Meta Optimizer for Combinatorial Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dernedde%2C+T">Tim Dernedde</a>, 
<a href="/search/cs?searchtype=author&query=Thyssens%2C+D">Daniela Thyssens</a>, 
<a href="/search/cs?searchtype=author&query=Dittrich%2C+S">S&#xf6;ren Dittrich</a>, 
<a href="/search/cs?searchtype=author&query=Stubbemann%2C+M">Maximilian Stubbemann</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt-Thieme%2C+L">Lars Schmidt-Thieme</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05024" title="Abstract">arXiv:2402.05024</a> (replaced) [<a href="/pdf/2402.05024" title="Download PDF">pdf</a>, <a href="/format/2402.05024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does the Use of Unusual Combinations of Datasets Contribute to Greater  Scientific Impact?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yulin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+D+M">Daniel M. Romero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Social and Information Networks (cs.SI); General Economics (econ.GN)

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05027" title="Abstract">arXiv:2402.05027</a> (replaced) [<a href="/pdf/2402.05027" title="Download PDF">pdf</a>, <a href="/format/2402.05027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Generalizability of Multi-Agent Reinforcement Learning in Graphs  with Recurrent Message Passing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weil%2C+J">Jannis Weil</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+Z">Zhenghua Bao</a>, 
<a href="/search/cs?searchtype=author&query=Abboud%2C+O">Osama Abboud</a>, 
<a href="/search/cs?searchtype=author&query=Meuser%2C+T">Tobias Meuser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAMAS 2024, version with appendix; revised sections 1 and 7, corrected table 1, final results unchanged
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05130" title="Abstract">arXiv:2402.05130</a> (replaced) [<a href="/pdf/2402.05130" title="Download PDF">pdf</a>, <a href="/format/2402.05130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LB-KBQA: Large-language-model and BERT based Knowledge-Based Question  and Answering System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhongyun Li</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yushan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaxing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yihong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05203" title="Abstract">arXiv:2402.05203</a> (replaced) [<a href="/pdf/2402.05203" title="Download PDF">pdf</a>, <a href="/format/2402.05203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bellman Conformal Inference: Calibrating Prediction Intervals For Time  Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zitong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cand%C3%A8s%2C+E">Emmanuel Cand&#xe8;s</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+L">Lihua Lei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05347" title="Abstract">arXiv:2402.05347</a> (replaced) [<a href="/pdf/2402.05347" title="Download PDF">pdf</a>, <a href="/ps/2402.05347" title="Download PostScript">ps</a>, <a href="/format/2402.05347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Implicit Adaptive Low Rank Time-Stepping Methods for Matrix  Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Appel%C3%B6%2C+D">Daniel Appel&#xf6;</a>, 
<a href="/search/math?searchtype=author&query=Cheng%2C+Y">Yingda Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05391" title="Abstract">arXiv:2402.05391</a> (replaced) [<a href="/pdf/2402.05391" title="Download PDF">pdf</a>, <a href="/format/2402.05391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Graphs Meet Multi-Modal Learning: A Comprehensive Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yichi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+Y">Yuxia Geng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Lingbing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qian Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaoyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yushan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoze Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J+Z">Jeff Z. Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ningyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huajun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Ongoing work; 55 pages, 11 Tables, 13 Figures, 619 citations; Paper list is available at <a href="https://github.com/zjukg/KG-MM-Survey">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05502" title="Abstract">arXiv:2402.05502</a> (replaced) [<a href="/pdf/2402.05502" title="Download PDF">pdf</a>, <a href="/format/2402.05502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Optimal Control Formulation of Tool Affordance Applied to Impact  Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ti%2C+B">Boyang Ti</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yongsheng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Calinon%2C+S">Sylvain Calinon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 16 figures, journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05532" title="Abstract">arXiv:2402.05532</a> (replaced) [<a href="/pdf/2402.05532" title="Download PDF">pdf</a>, <a href="/format/2402.05532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NCRF: Neural Contact Radiance Fields for Free-Viewpoint Rendering of  Hand-Object Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhongqun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jifei Song</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez-Pellitero%2C+E">Eduardo P&#xe9;rez-Pellitero</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yiren Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+H+J">Hyung Jin Chang</a>, 
<a href="/search/cs?searchtype=author&query=Leonardis%2C+A">Ale&#x161; Leonardis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 3DV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05650" title="Abstract">arXiv:2402.05650</a> (replaced) [<a href="/e-print/2402.05650" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rocks Coding, Not Development--A Human-Centric, Experimental Evaluation  of LLM-Supported SE Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+H">Huilong Ning</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gaowei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Libo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> I have decided to withdraw this article as I am in the process of making further revisions and edits to improve its content. Thank you for your understanding
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05786" title="Abstract">arXiv:2402.05786</a> (replaced) [<a href="/pdf/2402.05786" title="Download PDF">pdf</a>, <a href="/ps/2402.05786" title="Download PostScript">ps</a>, <a href="/format/2402.05786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompting Fairness: Artificial Intelligence as Game Players
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Henry%2C+J">Jazmia Henry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05790" title="Abstract">arXiv:2402.05790</a> (replaced) [<a href="/pdf/2402.05790" title="Download PDF">pdf</a>, <a href="/format/2402.05790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Underwater MEMS Gyrocompassing: A Virtual Testing Ground
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Engelsman%2C+D">Daniel Engelsman</a>, 
<a href="/search/eess?searchtype=author&query=Klein%2C+I">Itzik Klein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 Pages, 7 figures, OCEANS 2024 Singapore
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05894" title="Abstract">arXiv:2402.05894</a> (replaced) [<a href="/pdf/2402.05894" title="Download PDF">pdf</a>, <a href="/format/2402.05894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model Meets Graph Neural Network in Knowledge  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shengxiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+G">Guobing Zou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Song Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Y">Yanglan Gan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bofeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yixin Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 6 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item322">Cross-lists</a></li>
<li><a href="#item367">Replacements</a></li>
</ul>
<small>[ total of 559 entries:  <b>1-559</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2402">2402</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
