<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Thu 29 Feb 24  to  Fri  1 Mar 24, announced Mon,  4 Mar 24</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item309">Cross-lists</a></li>
<li><a href="#item350">Replacements</a></li>
</ul>
<small>[ total of 563 entries:  <b>1-563</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Mon,  4 Mar 24</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00011" title="Abstract">arXiv:2403.00011</a> [<a href="/pdf/2403.00011" title="Download PDF">pdf</a>, <a href="/format/2403.00011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introducing User Feedback-based Counterfactual Explanations (UFCE)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suffian%2C+M">Muhammad Suffian</a>, 
<a href="/search/cs?searchtype=author&query=Alonso-Moral%2C+J+M">Jose M. Alonso-Moral</a>, 
<a href="/search/cs?searchtype=author&query=Bogliolo%2C+A">Alessandro Bogliolo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint of paper submitted to IJCIS Springer
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Machine learning models are widely used in real-world applications. However,
their complexity makes it often challenging to interpret the rationale behind
their decisions. Counterfactual explanations (CEs) have emerged as a viable
solution for generating comprehensible explanations in eXplainable Artificial
Intelligence (XAI). CE provides actionable information to users on how to
achieve the desired outcome with minimal modifications to the input. However,
current CE algorithms usually operate within the entire feature space when
optimizing changes to turn over an undesired outcome, overlooking the
identification of key contributors to the outcome and disregarding the
practicality of the suggested changes. In this study, we introduce a novel
methodology, that is named as user feedback-based counterfactual explanation
(UFCE), which addresses these limitations and aims to bolster confidence in the
provided explanations. UFCE allows for the inclusion of user constraints to
determine the smallest modifications in the subset of actionable features while
considering feature dependence, and evaluates the practicality of suggested
changes using benchmark evaluation metrics. We conducted three experiments with
five datasets, demonstrating that UFCE outperforms two well-known CE methods in
terms of \textit{proximity}, \textit{sparsity}, and \textit{feasibility}.
Reported results indicate that user constraints influence the generation of
feasible CEs.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00012" title="Abstract">arXiv:2403.00012</a> [<a href="/pdf/2403.00012" title="Download PDF">pdf</a>, <a href="/format/2403.00012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PreRoutGNN for Timing Prediction with Order Preserving Partition: Global  Circuit Pre-training, Local Delay Learning and Attentional Cell Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+R">Ruizhe Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Junjie Ye</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhentao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Kai%2C+S">Shixiong Kai</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+M">Mingxuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jianye Hao</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures, The 38th Annual AAAI Conference on Artificial Intelligence (AAAI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Pre-routing timing prediction has been recently studied for evaluating the
quality of a candidate cell placement in chip design. It involves directly
estimating the timing metrics for both pin-level (slack, slew) and edge-level
(net delay, cell delay), without time-consuming routing. However, it often
suffers from signal decay and error accumulation due to the long timing paths
in large-scale industrial circuits. To address these challenges, we propose a
two-stage approach. First, we propose global circuit training to pre-train a
graph auto-encoder that learns the global graph embedding from circuit netlist.
Second, we use a novel node updating scheme for message passing on GCN,
following the topological sorting sequence of the learned graph embedding and
circuit graph. This scheme residually models the local time delay between two
adjacent pins in the updating sequence, and extracts the lookup table
information inside each cell via a new attention mechanism. To handle
large-scale circuits efficiently, we introduce an order preserving partition
scheme that reduces memory consumption while maintaining the topological
dependencies. Experiments on 21 real world circuits achieve a new SOTA R2 of
0.93 for slack prediction, which is significantly surpasses 0.59 by previous
SOTA method. Code will be available at:
https://github.com/Thinklab-SJTU/EDA-AI.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00013" title="Abstract">arXiv:2403.00013</a> [<a href="/pdf/2403.00013" title="Download PDF">pdf</a>, <a href="/format/2403.00013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prioritizing Informative Features and Examples for Deep Learning from  Noisy Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+D">Dongmin Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this dissertation, we propose a systemic framework that prioritizes
informative features and examples to enhance each stage of the development
process. Specifically, we prioritize informative features and examples and
improve the performance of feature learning, data labeling, and data selection.
We first propose an approach to extract only informative features that are
inherent to solving a target task by using auxiliary out-of-distribution data.
We deactivate the noise features in the target distribution by using that in
the out-of-distribution data. Next, we introduce an approach that prioritizes
informative examples from unlabeled noisy data in order to reduce the labeling
cost of active learning. In order to solve the purity-information dilemma,
where an attempt to select informative examples induces the selection of many
noisy examples, we propose a meta-model that finds the best balance between
purity and informativeness. Lastly, we suggest an approach that prioritizes
informative examples from labeled noisy data to preserve the performance of
data selection. For labeled image noise data, we propose a data selection
method that considers the confidence of neighboring samples to maintain the
performance of the state-of-the-art Re-labeling models. For labeled text noise
data, we present an instruction selection method that takes diversity into
account for ranking the quality of instructions with prompting, thereby
enhancing the performance of aligned large language models.
<br />Overall, our unified framework induces the deep learning development process
robust to noisy data, thereby effectively mitigating noisy features and
examples in real-world applications.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00014" title="Abstract">arXiv:2403.00014</a> [<a href="/pdf/2403.00014" title="Download PDF">pdf</a>, <a href="/format/2403.00014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GIN-SD: Source Detection in Graphs with Incomplete Nodes via Positional  Encoding and Attentive Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Le Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+P">Peican Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+K">Keke Tang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper is accepted by AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Source detection in graphs has demonstrated robust efficacy in the domain of
rumor source identification. Although recent solutions have enhanced
performance by leveraging deep neural networks, they often require complete
user data. In this paper, we address a more challenging task, rumor source
detection with incomplete user data, and propose a novel framework, i.e.,
Source Detection in Graphs with Incomplete Nodes via Positional Encoding and
Attentive Fusion (GIN-SD), to tackle this challenge. Specifically, our approach
utilizes a positional embedding module to distinguish nodes that are incomplete
and employs a self-attention mechanism to focus on nodes with greater
information transmission capacity. To mitigate the prediction bias caused by
the significant disparity between the numbers of source and non-source nodes,
we also introduce a class-balancing mechanism. Extensive experiments validate
the effectiveness of GIN-SD and its superiority to state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00016" title="Abstract">arXiv:2403.00016</a> [<a href="/pdf/2403.00016" title="Download PDF">pdf</a>, <a href="/format/2403.00016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Sensitivity Analysis for Objective-Oriented Combinatorial  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gireesan%2C+G">Ganga Gireesan</a>, 
<a href="/search/cs?searchtype=author&query=Pillai%2C+N">Nisha Pillai</a>, 
<a href="/search/cs?searchtype=author&query=Rothrock%2C+M+J">Michael J Rothrock</a>, 
<a href="/search/cs?searchtype=author&query=Nanduri%2C+B">Bindu Nanduri</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhiqian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ramkumar%2C+M">Mahalingam Ramkumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 2023 International Conference on Computational Science &amp; Computational Intelligence (CSCI'23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Pathogen control is a critical aspect of modern poultry farming, providing
important benefits for both public health and productivity. Effective poultry
management measures to reduce pathogen levels in poultry flocks promote food
safety by lowering risks of food-borne illnesses. They also support animal
health and welfare by preventing infectious diseases that can rapidly spread
and impact flock growth, egg production, and overall health. This study frames
the search for optimal management practices that minimize the presence of
multiple pathogens as a combinatorial optimization problem. Specifically, we
model the various possible combinations of management settings as a solution
space that can be efficiently explored to identify configurations that
optimally reduce pathogen levels. This design incorporates a neural network
feedback-based method that combines feature explanations with global
sensitivity analysis to ensure combinatorial optimization in multiobjective
settings. Our preliminary experiments have promising results when applied to
two real-world agricultural datasets. While further validation is still needed,
these early experimental findings demonstrate the potential of the model to
derive targeted feature interactions that adaptively optimize pathogen control
under varying real-world constraints.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00017" title="Abstract">arXiv:2403.00017</a> [<a href="/pdf/2403.00017" title="Download PDF">pdf</a>, <a href="/format/2403.00017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Interpreting Multi-Objective Feature Associations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pillai%2C+N">Nisha Pillai</a>, 
<a href="/search/cs?searchtype=author&query=Gireesan%2C+G">Ganga Gireesan</a>, 
<a href="/search/cs?searchtype=author&query=Rothrock%2C+M+J">Michael J. Rothrock Jr.</a>, 
<a href="/search/cs?searchtype=author&query=Nanduri%2C+B">Bindu Nanduri</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhiqian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ramkumar%2C+M">Mahalingam Ramkumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 18th Annual IEEE International Systems Conference 2024 (IEEE SYSCON 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Understanding how multiple features are associated and contribute to a
specific objective is as important as understanding how each feature
contributes to a particular outcome. Interpretability of a single feature in a
prediction may be handled in multiple ways; however, in a multi-objective
prediction, it is difficult to obtain interpretability of a combination of
feature values. To address this issue, we propose an objective specific feature
interaction design using multi-labels to find the optimal combination of
features in agricultural settings. One of the novel aspects of this design is
the identification of a method that integrates feature explanations with global
sensitivity analysis in order to ensure combinatorial optimization in
multi-objective settings. We have demonstrated in our preliminary experiments
that an approximate combination of feature values can be found to achieve the
desired outcome using two agricultural datasets: one with pre-harvest poultry
farm practices for multi-drug resistance presence, and one with post-harvest
poultry farm practices for food-borne pathogens. In our combinatorial
optimization approach, all three pathogens are taken into consideration
simultaneously to account for the interaction between conditions that favor
different types of pathogen growth. These results indicate that
explanation-based approaches are capable of identifying combinations of
features that reduce pathogen presence in fewer iterations than a baseline.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00018" title="Abstract">arXiv:2403.00018</a> [<a href="/pdf/2403.00018" title="Download PDF">pdf</a>, <a href="/ps/2403.00018" title="Download PostScript">ps</a>, <a href="/format/2403.00018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crypto Technology -- Impact on Global Economy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pillai%2C+A+V">Arunkumar Velayudhan Pillai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The last decade has been marked by the evolution of cryptocurrencies, which
have captured the interest of the public through the offered opportunities and
the feeling of freedom, resulting from decentralization and lack of authority
to oversee how cryptocurrency transactions are conducted. The innovation in
crypto space is often compared to the impact internet had on human life. There
is a new term called Web 3.0 for denoting all new computing innovations arising
due to the blockchain technologies. Blockchain has emerged as one of the most
important inventions of the last decade with crypto currencies or financial use
case as one of the domains which progressed most in the last 10 years. It is
very important to research about Web 3 technologies, how it is connected to
crypto economy and what to expect in this field for the next several decades.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00019" title="Abstract">arXiv:2403.00019</a> [<a href="/pdf/2403.00019" title="Download PDF">pdf</a>, <a href="/format/2403.00019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-based Parameter Estimation in Statistics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xiaoxin Yin</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D+S">David S. Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Parameter estimation is one of the most important tasks in statistics, and is
key to helping people understand the distribution behind a sample of
observations. Traditionally parameter estimation is done either by closed-form
solutions (e.g., maximum likelihood estimation for Gaussian distribution), or
by iterative numerical methods such as Newton-Raphson method when closed-form
solution does not exist (e.g., for Beta distribution).
<br />In this paper we propose a transformer-based approach to parameter
estimation. Compared with existing solutions, our approach does not require a
closed-form solution or any mathematical derivations. It does not even require
knowing the probability density function, which is needed by numerical methods.
After the transformer model is trained, only a single inference is needed to
estimate the parameters of the underlying distribution based on a sample of
observations. In the empirical study we compared our approach with maximum
likelihood estimation on commonly used distributions such as normal
distribution, exponential distribution and beta distribution. It is shown that
our approach achieves similar or better accuracy as measured by
mean-square-errors.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00023" title="Abstract">arXiv:2403.00023</a> [<a href="/pdf/2403.00023" title="Download PDF">pdf</a>, <a href="/format/2403.00023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auditable Homomorphic-based Decentralized Collaborative AI with  Attribute-based Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeh%2C+L">Lo-Yao Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Tseng%2C+S">Sheng-Po Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chia-Hsun Lu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chih-Ya Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, the notion of federated learning (FL) has led to the new
paradigm of distributed artificial intelligence (AI) with privacy preservation.
However, most current FL systems suffer from data privacy issues due to the
requirement of a trusted third party. Although some previous works introduce
differential privacy to protect the data, however, it may also significantly
deteriorate the model performance. To address these issues, we propose a novel
decentralized collaborative AI framework, named Auditable Homomorphic-based
Decentralised Collaborative AI (AerisAI), to improve security with homomorphic
encryption and fine-grained differential privacy. Our proposed AerisAI directly
aggregates the encrypted parameters with a blockchain-based smart contract to
get rid of the need of a trusted third party. We also propose a brand-new
concept for eliminating the negative impacts of differential privacy for model
performance. Moreover, the proposed AerisAI also provides the broadcast-aware
group key management based on ciphertext-policy attribute-based encryption
(CPABE) to achieve fine-grained access control based on different service-level
agreements. We provide a formal theoretical analysis of the proposed AerisAI as
well as the functionality comparison with the other baselines. We also conduct
extensive experiments on real datasets to evaluate the proposed approach. The
experimental results indicate that our proposed AerisAI significantly
outperforms the other state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00024" title="Abstract">arXiv:2403.00024</a> [<a href="/pdf/2403.00024" title="Download PDF">pdf</a>, <a href="/format/2403.00024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlowCyt: A Comparative Study of Deep Learning Approaches for Multi-Class  Classification in Flow Cytometry Benchmarking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bini%2C+L">Lorenzo Bini</a>, 
<a href="/search/cs?searchtype=author&query=Mojarrad%2C+F+N">Fatemeh Nassajian Mojarrad</a>, 
<a href="/search/cs?searchtype=author&query=Liarou%2C+M">Margarita Liarou</a>, 
<a href="/search/cs?searchtype=author&query=Matthes%2C+T">Thomas Matthes</a>, 
<a href="/search/cs?searchtype=author&query=Marchand-Maillet%2C+S">St&#xe9;phane Marchand-Maillet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2402.18611">arXiv:2402.18611</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">This paper presents FlowCyt, the first comprehensive benchmark for
multi-class single-cell classification in flow cytometry data. The dataset
comprises bone marrow samples from 30 patients, with each cell characterized by
twelve markers. Ground truth labels identify five hematological cell types: T
lymphocytes, B lymphocytes, Monocytes, Mast cells, and Hematopoietic
Stem/Progenitor Cells (HSPCs). Experiments utilize supervised inductive
learning and semi-supervised transductive learning on up to 1 million cells per
patient. Baseline methods include Gaussian Mixture Models, XGBoost, Random
Forests, Deep Neural Networks, and Graph Neural Networks (GNNs). GNNs
demonstrate superior performance by exploiting spatial relationships in
graph-encoded data. The benchmark allows standardized evaluation of clinically
relevant classification tasks, along with exploratory analyses to gain insights
into hematological cell phenotypes. This represents the first public flow
cytometry benchmark with a richly annotated, heterogeneous dataset. It will
empower the development and rigorous assessment of novel methodologies for
single-cell analysis.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00025" title="Abstract">arXiv:2403.00025</a> [<a href="/pdf/2403.00025" title="Download PDF">pdf</a>, <a href="/ps/2403.00025" title="Download PostScript">ps</a>, <a href="/format/2403.00025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Challenges and Opportunities in Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manduchi%2C+L">Laura Manduchi</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+K">Kushagra Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Bamler%2C+R">Robert Bamler</a>, 
<a href="/search/cs?searchtype=author&query=Cotterell%2C+R">Ryan Cotterell</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%A4ubener%2C+S">Sina D&#xe4;ubener</a>, 
<a href="/search/cs?searchtype=author&query=Fellenz%2C+S">Sophie Fellenz</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+A">Asja Fischer</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%A4rtner%2C+T">Thomas G&#xe4;rtner</a>, 
<a href="/search/cs?searchtype=author&query=Kirchler%2C+M">Matthias Kirchler</a>, 
<a href="/search/cs?searchtype=author&query=Kloft%2C+M">Marius Kloft</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingzhen Li</a>, 
<a href="/search/cs?searchtype=author&query=Lippert%2C+C">Christoph Lippert</a>, 
<a href="/search/cs?searchtype=author&query=de+Melo%2C+G">Gerard de Melo</a>, 
<a href="/search/cs?searchtype=author&query=Nalisnick%2C+E">Eric Nalisnick</a>, 
<a href="/search/cs?searchtype=author&query=Ommer%2C+B">Bj&#xf6;rn Ommer</a>, 
<a href="/search/cs?searchtype=author&query=Ranganath%2C+R">Rajesh Ranganath</a>, 
<a href="/search/cs?searchtype=author&query=Rudolph%2C+M">Maja Rudolph</a>, 
<a href="/search/cs?searchtype=author&query=Ullrich%2C+K">Karen Ullrich</a>, 
<a href="/search/cs?searchtype=author&query=Van+den+Broeck%2C+G">Guy Van den Broeck</a>, 
<a href="/search/cs?searchtype=author&query=Vogt%2C+J+E">Julia E Vogt</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yixin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wenzel%2C+F">Florian Wenzel</a>, 
<a href="/search/cs?searchtype=author&query=Wood%2C+F">Frank Wood</a>, 
<a href="/search/cs?searchtype=author&query=Mandt%2C+S">Stephan Mandt</a>, 
<a href="/search/cs?searchtype=author&query=Fortuin%2C+V">Vincent Fortuin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The field of deep generative modeling has grown rapidly and consistently over
the years. With the availability of massive amounts of training data coupled
with advances in scalable unsupervised learning paradigms, recent large-scale
generative models show tremendous promise in synthesizing high-resolution
images and text, as well as structured data such as videos and molecules.
However, we argue that current large-scale generative AI models do not
sufficiently address several fundamental issues that hinder their widespread
adoption across domains. In this work, we aim to identify key unresolved
challenges in modern generative AI paradigms that should be tackled to further
enhance their capabilities, versatility, and reliability. By identifying these
challenges, we aim to provide researchers with valuable insights for exploring
fruitful research directions, thereby fostering the development of more robust
and accessible generative AI solutions.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00026" title="Abstract">arXiv:2403.00026</a> [<a href="/pdf/2403.00026" title="Download PDF">pdf</a>, <a href="/format/2403.00026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Deliver: a Foundation Model for the Montreal Capacitated  Vehicle Routing Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chin%2C+S+J+K">Samuel J. K. Chin</a>, 
<a href="/search/cs?searchtype=author&query=Winkenbach%2C+M">Matthias Winkenbach</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+A">Akash Srivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper, we present the Foundation Model for the Montreal Capacitated
Vehicle Routing Problem (FM-MCVRP), a novel Deep Learning (DL) model that
approximates high-quality solutions to a variant of the Capacitated Vehicle
Routing Problem (CVRP) that characterizes many real-world applications. The
so-called Montreal Capacitated Vehicle Routing Problem (MCVRP), first formally
described by Bengio et al. (2021), is defined on a fixed and finite graph,
which is analogous to a city. Each MCVRP instance is essentially the sub-graph
connecting a randomly sampled subset of the nodes in the fixed graph, which
represent a set of potential addresses in a real-world delivery problem on a
given day. Our work exploits this problem structure to frame the MCVRP as an
analogous Natural Language Processing (NLP) task. Specifically, we leverage a
Transformer architecture embedded in a Large Language Model (LLM) framework to
train our model in a supervised manner on computationally inexpensive,
sub-optimal MCVRP solutions obtained algorithmically. Through comprehensive
computational experiments, we show that FM-MCVRP produces better MCVRP
solutions than the training data and generalizes to larger sized problem
instances not seen during training. Even when compared to near-optimal
solutions from state-of-the-art heuristics, FM-MCVRP yields competitive results
despite being trained on inferior data. For instance, for 400-customer
problems, FM-MCVRP solutions on average fall within 2% of the benchmark. Our
results further demonstrate that unlike prior works in the literature, FM-MCVRP
is a unified model, which performs consistently and reliably on a range of
problem instance sizes and parameter values such as the vehicle capacity.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00027" title="Abstract">arXiv:2403.00027</a> [<a href="/pdf/2403.00027" title="Download PDF">pdf</a>, <a href="/ps/2403.00027" title="Download PostScript">ps</a>, <a href="/format/2403.00027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Quick Framework for Evaluating Worst Robustness of Complex Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wenjun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peiyan Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+T">Tianlong Fan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Ting Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chuan-fu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zong-fu Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 8figures, 4tables,journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Robustness is pivotal for comprehending, designing, optimizing, and
rehabilitating networks, with simulation attacks being the prevailing
evaluation method. Simulation attacks are often time-consuming or even
impractical, however, a more crucial yet persistently overlooked drawback is
that any attack strategy merely provides a potential paradigm of
disintegration. The key concern is: in the worst-case scenario or facing the
most severe attacks, what is the limit of robustness, referred to as ``Worst
Robustness'', for a given system? Understanding a system's worst robustness is
imperative for grasping its reliability limits, accurately evaluating
protective capabilities, and determining associated design and security
maintenance costs. To address these challenges, we introduce the concept of
Most Destruction Attack (MDA) based on the idea of knowledge stacking. MDA is
employed to assess the worst robustness of networks, followed by the
application of an adapted CNN algorithm for rapid worst robustness prediction.
We establish the logical validity of MDA and highlight the exceptional
performance of the adapted CNN algorithm in predicting the worst robustness
across diverse network topologies, encompassing both model and empirical
networks.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00028" title="Abstract">arXiv:2403.00028</a> [<a href="/pdf/2403.00028" title="Download PDF">pdf</a>, <a href="/ps/2403.00028" title="Download PostScript">ps</a>, <a href="/format/2403.00028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lower Bounds for Differential Privacy Under Continual Observation and  Online Threshold Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cohen%2C+E">Edith Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+X">Xin Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Nelson%2C+J">Jelani Nelson</a>, 
<a href="/search/cs?searchtype=author&query=Sarl%C3%B3s%2C+T">Tam&#xe1;s Sarl&#xf3;s</a>, 
<a href="/search/cs?searchtype=author&query=Stemmer%2C+U">Uri Stemmer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">One of the most basic problems for studying the "price of privacy over time"
is the so called private counter problem, introduced by Dwork et al. (2010) and
Chan et al. (2010). In this problem, we aim to track the number of events that
occur over time, while hiding the existence of every single event. More
specifically, in every time step $t\in[T]$ we learn (in an online fashion) that
$\Delta_t\geq 0$ new events have occurred, and must respond with an estimate
$n_t\approx\sum_{j=1}^t \Delta_j$. The privacy requirement is that all of the
outputs together, across all time steps, satisfy event level differential
privacy. The main question here is how our error needs to depend on the total
number of time steps $T$ and the total number of events $n$. Dwork et al.
(2015) showed an upper bound of $O\left(\log(T)+\log^2(n)\right)$, and
Henzinger et al. (2023) showed a lower bound of $\Omega\left(\min\{\log n, \log
T\}\right)$. We show a new lower bound of $\Omega\left(\min\{n,\log
T\}\right)$, which is tight w.r.t. the dependence on $T$, and is tight in the
sparse case where $\log^2 n=O(\log T)$. Our lower bound has the following
implications:
<br />$\bullet$ We show that our lower bound extends to the "online thresholds
problem", where the goal is to privately answer many "quantile queries" when
these queries are presented one-by-one. This resolves an open question of Bun
et al. (2017).
<br />$\bullet$ Our lower bound implies, for the first time, a separation between
the number of mistakes obtainable by a private online learner and a non-private
online learner. This partially resolves a COLT'22 open question published by
Sanyal and Ramponi.
<br />$\bullet$ Our lower bound also yields the first separation between the
standard model of private online learning and a recently proposed relaxed
variant of it, called private online prediction.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00030" title="Abstract">arXiv:2403.00030</a> [<a href="/pdf/2403.00030" title="Download PDF">pdf</a>, <a href="/format/2403.00030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphPub: Generation of Differential Privacy Graph with High  Availability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wanghan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Bin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Ao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiqiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+B">Bo Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, with the rapid development of graph neural networks (GNN),
more and more graph datasets have been published for GNN tasks. However, when
an upstream data owner publishes graph data, there are often many privacy
concerns, because many real-world graph data contain sensitive information like
person's friend list. Differential privacy (DP) is a common method to protect
privacy, but due to the complex topological structure of graph data, applying
DP on graphs often affects the message passing and aggregation of GNN models,
leading to a decrease in model accuracy. In this paper, we propose a novel
graph edge protection framework, graph publisher (GraphPub), which can protect
graph topology while ensuring that the availability of data is basically
unchanged. Through reverse learning and the encoder-decoder mechanism, we
search for some false edges that do not have a large negative impact on the
aggregation of node features, and use them to replace some real edges. The
modified graph will be published, which is difficult to distinguish between
real and false data. Sufficient experiments prove that our framework achieves
model accuracy close to the original graph with an extremely low privacy
budget.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00032" title="Abstract">arXiv:2403.00032</a> [<a href="/pdf/2403.00032" title="Download PDF">pdf</a>, <a href="/format/2403.00032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time to Cite: Modeling Citation Networks using the Dynamic Impact  Single-Event Embedding Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nakis%2C+N">Nikolaos Nakis</a>, 
<a href="/search/cs?searchtype=author&query=Celikkanat%2C+A">Abdulkadir Celikkanat</a>, 
<a href="/search/cs?searchtype=author&query=Boucherie%2C+L">Louis Boucherie</a>, 
<a href="/search/cs?searchtype=author&query=Lehmann%2C+S">Sune Lehmann</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%B8rup%2C+M">Morten M&#xf8;rup</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Digital Libraries (cs.DL)

</div>
<p class="mathjax">Understanding the structure and dynamics of scientific research, i.e., the
science of science (SciSci), has become an important area of research in order
to address imminent questions including how scholars interact to advance
science, how disciplines are related and evolve, and how research impact can be
quantified and predicted. Central to the study of SciSci has been the analysis
of citation networks. Here, two prominent modeling methodologies have been
employed: one is to assess the citation impact dynamics of papers using
parametric distributions, and the other is to embed the citation networks in a
latent space optimal for characterizing the static relations between papers in
terms of their citations. Interestingly, citation networks are a prominent
example of single-event dynamic networks, i.e., networks for which each dyad
only has a single event (i.e., the point in time of citation). We presently
propose a novel likelihood function for the characterization of such
single-event networks. Using this likelihood, we propose the Dynamic Impact
Single-Event Embedding model (DISEE). The \textsc{\modelabbrev} model
characterizes the scientific interactions in terms of a latent distance model
in which random effects account for citation heterogeneity while the
time-varying impact is characterized using existing parametric representations
for assessment of dynamic impact. We highlight the proposed approach on several
real citation networks finding that the DISEE well reconciles static latent
distance network embedding approaches with classical dynamic impact
assessments.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00036" title="Abstract">arXiv:2403.00036</a> [<a href="/pdf/2403.00036" title="Download PDF">pdf</a>, <a href="/format/2403.00036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Influencing Bandits: Arm Selection for Preference Shaping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nadkarni%2C+V">Viraj Nadkarni</a>, 
<a href="/search/cs?searchtype=author&query=Manjunath%2C+D">D. Manjunath</a>, 
<a href="/search/cs?searchtype=author&query=Moharir%2C+S">Sharayu Moharir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures, 24 references, proofs in appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Systems and Control (eess.SY)

</div>
<p class="mathjax">We consider a non stationary multi-armed bandit in which the population
preferences are positively and negatively reinforced by the observed rewards.
The objective of the algorithm is to shape the population preferences to
maximize the fraction of the population favouring a predetermined arm. For the
case of binary opinions, two types of opinion dynamics are considered --
decreasing elasticity (modeled as a Polya urn with increasing number of balls)
and constant elasticity (using the voter model). For the first case, we
describe an Explore-then-commit policy and a Thompson sampling policy and
analyse the regret for each of these policies. We then show that these
algorithms and their analyses carry over to the constant elasticity case. We
also describe a Thompson sampling based algorithm for the case when more than
two types of opinions are present. Finally, we discuss the case where presence
of multiple recommendation systems gives rise to a trade-off between their
popularity and opinion shaping objectives.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00037" title="Abstract">arXiv:2403.00037</a> [<a href="/pdf/2403.00037" title="Download PDF">pdf</a>, <a href="/format/2403.00037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolving to the Future: Unseen Event Adaptive Fake News Detection on  Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiajun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhixun Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">With the rapid development of social media, the wide dissemination of fake
news on social media is increasingly threatening both individuals and society.
In the dynamic landscape of social media, fake news detection aims to develop a
model trained on news reporting past events. The objective is to predict and
identify fake news about future events, which often relate to subjects entirely
different from those in the past. However, existing fake detection methods
exhibit a lack of robustness and cannot generalize to unseen events. To address
this, we introduce Future ADaptive Event-based Fake news Detection (FADE)
framework. Specifically, we train a target predictor through an adaptive
augmentation strategy and graph contrastive learning to make more robust
overall predictions. Simultaneously, we independently train an event-only
predictor to obtain biased predictions. Then we further mitigate event bias by
obtaining the final prediction by subtracting the output of the event-only
predictor from the output of the target predictor. Encouraging results from
experiments designed to emulate real-world social media conditions validate the
effectiveness of our method in comparison to existing state-of-the-art
approaches.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00039" title="Abstract">arXiv:2403.00039</a> [<a href="/pdf/2403.00039" title="Download PDF">pdf</a>, <a href="/format/2403.00039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FhGenie: A Custom, Confidentiality-preserving Chat AI for Corporate and  Scientific Use
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weber%2C+I">Ingo Weber</a>, 
<a href="/search/cs?searchtype=author&query=Linka%2C+H">Hendrik Linka</a>, 
<a href="/search/cs?searchtype=author&query=Mertens%2C+D">Daniel Mertens</a>, 
<a href="/search/cs?searchtype=author&query=Muryshkin%2C+T">Tamara Muryshkin</a>, 
<a href="/search/cs?searchtype=author&query=Opgenoorth%2C+H">Heinrich Opgenoorth</a>, 
<a href="/search/cs?searchtype=author&query=Langer%2C+S">Stefan Langer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Since OpenAI's release of ChatGPT, generative AI has received significant
attention across various domains. These AI-based chat systems have the
potential to enhance the productivity of knowledge workers in diverse tasks.
However, the use of free public services poses a risk of data leakage, as
service providers may exploit user input for additional training and
optimization without clear boundaries. Even subscription-based alternatives
sometimes lack transparency in handling user data. To address these concerns
and enable Fraunhofer staff to leverage this technology while ensuring
confidentiality, we have designed and developed a customized chat AI called
FhGenie (genie being a reference to a helpful spirit). Within few days of its
release, thousands of Fraunhofer employees started using this service. As
pioneers in implementing such a system, many other organizations have followed
suit. Our solution builds upon commercial large language models (LLMs), which
we have carefully integrated into our system to meet our specific requirements
and compliance constraints, including confidentiality and GDPR. In this paper,
we share detailed insights into the architectural considerations, design,
implementation, and subsequent updates of FhGenie. Additionally, we discuss
challenges, observations, and the core lessons learned from its productive
usage.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00041" title="Abstract">arXiv:2403.00041</a> [<a href="/pdf/2403.00041" title="Download PDF">pdf</a>, <a href="/format/2403.00041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global and Local Prompts Cooperation via Optimal Transport for Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongxia Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingya Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Ye Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Prompt learning in pretrained visual-language models has shown remarkable
flexibility across various downstream tasks. Leveraging its inherent
lightweight nature, recent research attempted to integrate the powerful
pretrained models into federated learning frameworks to simultaneously reduce
communication costs and promote local training on insufficient data. Despite
these efforts, current federated prompt learning methods lack specialized
designs to systematically address severe data heterogeneities, e.g., data
distribution with both label and feature shifts involved. To address this
challenge, we present Federated Prompts Cooperation via Optimal Transport
(FedOTP), which introduces efficient collaborative prompt learning strategies
to capture diverse category traits on a per-client basis. Specifically, for
each client, we learn a global prompt to extract consensus knowledge among
clients, and a local prompt to capture client-specific category
characteristics. Unbalanced Optimal Transport is then employed to align local
visual features with these prompts, striking a balance between global consensus
and local personalization. Extensive experiments on datasets with various types
of heterogeneities have demonstrated that our FedOTP outperforms the
state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00044" title="Abstract">arXiv:2403.00044</a> [<a href="/pdf/2403.00044" title="Download PDF">pdf</a>, <a href="/format/2403.00044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling up Dynamic Edge Partition Models via Stochastic Gradient MCMC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sikun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Koeppl%2C+H">Heinz Koeppl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The edge partition model (EPM) is a generative model for extracting an
overlapping community structure from static graph-structured data. In the EPM,
the gamma process (GaP) prior is adopted to infer the appropriate number of
latent communities, and each vertex is endowed with a gamma distributed
positive memberships vector. Despite having many attractive properties,
inference in the EPM is typically performed using Markov chain Monte Carlo
(MCMC) methods that prevent it from being applied to massive network data. In
this paper, we generalize the EPM to account for dynamic enviroment by
representing each vertex with a positive memberships vector constructed using
Dirichlet prior specification, and capturing the time-evolving behaviour of
vertices via a Dirichlet Markov chain construction. A simple-to-implement Gibbs
sampler is proposed to perform posterior computation using Negative- Binomial
augmentation technique. For large network data, we propose a stochastic
gradient Markov chain Monte Carlo (SG-MCMC) algorithm for scalable inference in
the proposed model. The experimental results show that the novel methods
achieve competitive performance in terms of link prediction, while being much
faster.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00045" title="Abstract">arXiv:2403.00045</a> [<a href="/pdf/2403.00045" title="Download PDF">pdf</a>, <a href="/format/2403.00045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An All-Optical General-Purpose CPU and Optical Computer Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kissner%2C+M">Michael Kissner</a>, 
<a href="/search/cs?searchtype=author&query=Del+Bino%2C+L">Leonardo Del Bino</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A4sler%2C+F">Felix P&#xe4;sler</a>, 
<a href="/search/cs?searchtype=author&query=Caruana%2C+P">Peter Caruana</a>, 
<a href="/search/cs?searchtype=author&query=Ghalanos%2C+G">George Ghalanos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Optics (physics.optics)

</div>
<p class="mathjax">Energy efficiency of electronic digital processors is primarily limited by
the energy consumption of electronic communication and interconnects. The
industry is almost unanimously pushing towards replacing both long-haul, as
well as local chip interconnects, using optics to drastically increase
efficiency. In this paper, we explore what comes after the successful migration
to optical interconnects, as with this inefficiency solved, the main source of
energy consumption will be electronic digital computing, memory and
electro-optical conversion. Our approach attempts to address all these issues
by introducing efficient all-optical digital computing and memory, which in
turn eliminates the need for electro-optical conversions. Here, we demonstrate
for the first time a scheme to enable general purpose digital data processing
in an integrated form and present our photonic integrated circuit (PIC)
implementation. For this demonstration we implemented a URISC architecture
capable of running any classical piece of software all-optically and present a
comprehensive architectural framework for all-optical computing to go beyond.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00046" title="Abstract">arXiv:2403.00046</a> [<a href="/pdf/2403.00046" title="Download PDF">pdf</a>, <a href="/format/2403.00046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEED: Customize Large Language Models with Sample-Efficient Adaptation  for Code Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xue Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yihong Dong</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Ge Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Although Large Language Models (LLMs) have made significant progress in code
generation, they still struggle with code generation tasks in specific
scenarios. These scenarios usually necessitate the adaptation of LLMs to
fulfill specific needs, but the limited training data available in practice
leads to poor code generation performance. How to effectively adapt LLMs to new
scenarios with fewer training samples is a major challenge for current code
generation. In this paper, we propose a novel adaptation approach named SEED,
which stands for Sample-Efficient adaptation with Error-Driven learning for
code generation. SEED leverages the errors made by LLMs as learning
opportunities, using error revision to overcome its own shortcomings, thus
achieving efficient learning. Specifically, SEED involves identifying error
code generated by LLMs, employing Self-revise for code revision, optimizing the
model with revised code, and iteratively adapting the process for continuous
improvement. Experimental results show that, compared to traditional
fine-tuning approaches, SEED achieves superior performance with fewer training
samples, showing a relative improvement of 27.2%-325.0% in Pass@1. We also
validate the effectiveness of Self-revise, which generates revised code that
optimizes the model more efficiently compared to the code samples from
datasets. Moreover, SEED consistently demonstrates strong performance across
various LLMs, underscoring its generalizability.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00049" title="Abstract">arXiv:2403.00049</a> [<a href="/pdf/2403.00049" title="Download PDF">pdf</a>, <a href="/format/2403.00049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TEXterity -- Tactile Extrinsic deXterity: Simultaneous Tactile  Estimation and Control for Extrinsic Dexterity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sangwoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Bronars%2C+A">Antonia Bronars</a>, 
<a href="/search/cs?searchtype=author&query=Patre%2C+P">Parag Patre</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+A">Alberto Rodriguez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project website: <a href="https://sites.google.com/view/texterity.">this https URL</a> arXiv admin note: substantial text overlap with <a href="/abs/2401.10230">arXiv:2401.10230</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We introduce a novel approach that combines tactile estimation and control
for in-hand object manipulation. By integrating measurements from robot
kinematics and an image-based tactile sensor, our framework estimates and
tracks object pose while simultaneously generating motion plans in a receding
horizon fashion to control the pose of a grasped object. This approach consists
of a discrete pose estimator that tracks the most likely sequence of object
poses in a coarsely discretized grid, and a continuous pose
estimator-controller to refine the pose estimate and accurately manipulate the
pose of the grasped object. Our method is tested on diverse objects and
configurations, achieving desired manipulation objectives and outperforming
single-shot methods in estimation accuracy. The proposed approach holds
potential for tasks requiring precise manipulation and limited intrinsic
in-hand dexterity under visual occlusion, laying the foundation for closed-loop
behavior in applications such as regrasping, insertion, and tool use. Please
see https://sites.google.com/view/texterity for videos of real-world
demonstrations.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00067" title="Abstract">arXiv:2403.00067</a> [<a href="/pdf/2403.00067" title="Download PDF">pdf</a>, <a href="/format/2403.00067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Query-OPT: Optimizing Inference of Large Language Models via Multi-Query  Instructions in Meeting Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laskar%2C+M+T+R">Md Tahmid Rahman Laskar</a>, 
<a href="/search/cs?searchtype=author&query=Khasanova%2C+E">Elena Khasanova</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xue-Yong Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=TN%2C+S+B">Shashi Bhushan TN</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This work focuses on the task of query-based meeting summarization in which
the summary of a context (meeting transcript) is generated in response to a
specific query. When using Large Language Models (LLMs) for this task, a new
call to the LLM inference endpoint/API is required for each new query even if
the context stays the same. However, repeated calls to the LLM inference
endpoints would significantly increase the costs of using them in production,
making LLMs impractical for many real-world use cases. To address this problem,
in this paper, we investigate whether combining the queries for the same input
context in a single prompt to minimize repeated calls can be successfully used
in meeting summarization. In this regard, we conduct extensive experiments by
comparing the performance of various popular LLMs: GPT-4, PaLM-2, LLaMA-2,
Mistral, and FLAN-T5 in single-query and multi-query settings. We observe that
while most LLMs tend to respond to the multi-query instructions, almost all of
them (except GPT-4), even after fine-tuning, could not properly generate the
response in the required output format. We conclude that while multi-query
prompting could be useful to optimize the inference costs by reducing calls to
the inference endpoints/APIs for the task of meeting summarization, this
capability to reliably generate the response in the expected format is only
limited to certain LLMs.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00068" title="Abstract">arXiv:2403.00068</a> [<a href="/pdf/2403.00068" title="Download PDF">pdf</a>, <a href="/format/2403.00068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artwork Explanation in Large-scale Vision Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hayashi%2C+K">Kazuki Hayashi</a>, 
<a href="/search/cs?searchtype=author&query=Sakai%2C+Y">Yusuke Sakai</a>, 
<a href="/search/cs?searchtype=author&query=Kamigaito%2C+H">Hidetaka Kamigaito</a>, 
<a href="/search/cs?searchtype=author&query=Hayashi%2C+K">Katsuhiko Hayashi</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+T">Taro Watanabe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large-scale vision-language models (LVLMs) output text from images and
instructions, demonstrating advanced capabilities in text generation and
comprehension. However, it has not been clarified to what extent LVLMs
understand the knowledge necessary for explaining images, the complex
relationships between various pieces of knowledge, and how they integrate these
understandings into their explanations. To address this issue, we propose a new
task: the artwork explanation generation task, along with its evaluation
dataset and metric for quantitatively assessing the understanding and
utilization of knowledge about artworks. This task is apt for image description
based on the premise that LVLMs are expected to have pre-existing knowledge of
artworks, which are often subjects of wide recognition and documented
information. It consists of two parts: generating explanations from both images
and titles of artworks, and generating explanations using only images, thus
evaluating the LVLMs' language-based and vision-based knowledge. Alongside, we
release a training dataset for LVLMs to learn explanations that incorporate
knowledge about artworks. Our findings indicate that LVLMs not only struggle
with integrating language and visual information but also exhibit a more
pronounced limitation in acquiring knowledge from images alone. The datasets
(ExpArt=Explain Artworks) are available at
https://huggingface.co/datasets/naist-nlp/ExpArt.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00071" title="Abstract">arXiv:2403.00071</a> [<a href="/pdf/2403.00071" title="Download PDF">pdf</a>, <a href="/format/2403.00071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resonance RoPE: Improving Context Length Generalization of Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Suyuchen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kobyzev%2C+I">Ivan Kobyzev</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+P">Peng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Rezagholizadeh%2C+M">Mehdi Rezagholizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper addresses the challenge of train-short-test-long (TSTL) scenarios
in Large Language Models (LLMs) equipped with Rotary Position Embedding (RoPE),
where models pre-trained on shorter sequences face difficulty with
out-of-distribution (OOD) token positions in longer sequences. We introduce
Resonance RoPE, a novel approach designed to narrow the generalization gap in
TSTL scenarios by refining the interpolation of RoPE features for OOD
positions, significantly improving the model performance without additional
online computational costs. Furthermore, we present PosGen, a new synthetic
benchmark specifically designed for fine-grained behavior analysis in TSTL
scenarios, aiming to isolate the constantly increasing difficulty of token
generation on long contexts from the challenges of recognizing new token
positions. Our experiments on synthetic tasks show that after applying
Resonance RoPE, Transformers recognize OOD position better and more robustly.
Our extensive LLM experiments also show superior performance after applying
Resonance RoPE to the current state-of-the-art RoPE scaling method, YaRN, on
both upstream language modeling tasks and a variety of downstream long-text
applications.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00075" title="Abstract">arXiv:2403.00075</a> [<a href="/pdf/2403.00075" title="Download PDF">pdf</a>, <a href="/ps/2403.00075" title="Download PostScript">ps</a>, <a href="/format/2403.00075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Invariant Rauch-Tung-Striebel Smoother
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+der+Laan%2C+N">Niels van der Laan</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+M">Mitchell Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Arsenault%2C+J">Jonathan Arsenault</a>, 
<a href="/search/cs?searchtype=author&query=Forbes%2C+J+R">James Richard Forbes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, published in Robotics and Automation Letters
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters, vol. 5, no. 4, pp 5067-5074,
  June 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents an invariant Rauch-Tung- Striebel (IRTS) smoother
applicable to systems with states that are an element of a matrix Lie group. In
particular, the extended Rauch-Tung-Striebel (RTS) smoother is adapted to work
within a matrix Lie group framework. The main advantage of the invariant RTS
(IRTS) smoother is that the linearization of the process and measurement models
is independent of the state estimate resulting in state-estimate-independent
Jacobians when certain technical requirements are met. A sample problem is
considered that involves estimation of the three dimensional pose of a rigid
body on SE(3), along with sensor biases. The multiplicative RTS (MRTS) smoother
is also reviewed and is used as a direct comparison to the proposed IRTS
smoother using experimental data. Both smoothing methods are also compared to
invariant and multiplicative versions of the Gauss-Newton approach to solving
the batch state estimation problem.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00076" title="Abstract">arXiv:2403.00076</a> [<a href="/pdf/2403.00076" title="Download PDF">pdf</a>, <a href="/ps/2403.00076" title="Download PostScript">ps</a>, <a href="/format/2403.00076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigation and Control of Unconventional VTOL UAVs in Forward-Flight  with Explicit Wind Velocity Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cohen%2C+M">Mitchell Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Forbes%2C+J+R">James Richard Forbes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures, published in Robotics and Automation Letters
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters, vol. 5, no. 2, pp.
  1151-1158, June 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a solution for the state estimation and control problems
for a class of unconventional vertical takeoff and landing (VTOL) UAVs
operating in forward-flight conditions. A tightly-coupled state estimation
approach is used to estimate the aircraft navigation states, sensor biases, and
the wind velocity. State estimation is done within a matrix Lie group framework
using the Invariant Extended Kalman Filter (IEKF), which offers several
advantages compared to standard multiplicative EKFs traditionally used in
aerospace and robotics problems. An SO(3)- based attitude controller is
employed, leading to a single attitude control law without a separate sideslip
control loop. A control allocator is used to determine how to use multiple,
possibly redundant, actuators to produce the desired control moments. The wind
velocity estimates are used in the attitude controller and the control
allocator to improve performance. A numerical example is considered using a
sample VTOL tailsitter-type UAV with four control surfaces. Monte-Carlo
simulations demonstrate robustness of the proposed control and estimation
scheme to various initial conditions, noise levels, and flight trajectories.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00081" title="Abstract">arXiv:2403.00081</a> [<a href="/pdf/2403.00081" title="Download PDF">pdf</a>, <a href="/format/2403.00081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Constitutions of Web3
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+J+Z">Joshua Z. Tan</a>, 
<a href="/search/cs?searchtype=author&query=Langenkamp%2C+M">Max Langenkamp</a>, 
<a href="/search/cs?searchtype=author&query=Weichselbraun%2C+A">Anna Weichselbraun</a>, 
<a href="/search/cs?searchtype=author&query=Brody%2C+A">Ann Brody</a>, 
<a href="/search/cs?searchtype=author&query=Korpas%2C+L">Lucia Korpas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">The governance of online communities has been a critical issue since the
first USENET groups, and a number of serious constitutions -- declarations of
goals, values, and rights -- have emerged since the mid-1990s. More recently,
decentralized autonomous organizations (DAOs) have begun to publish their own
constitutions, manifestos, and other governance documents. There are two unique
aspects to these documents: they (1) often govern significantly more resources
than previously-observed online communities, and (2) are used in conjunction
with smart contracts that can secure certain community rights and processes
through code. In this article, we analyze 25 DAO constitutions, observe a
number of common patterns, and provide a template and a set of recommendations
to support the crafting and dissemination of future DAO constitutions. We
conclude with a report on how our template and recommendations were then used
within the actual constitutional drafting process of a major blockchain.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00087" title="Abstract">arXiv:2403.00087</a> [<a href="/pdf/2403.00087" title="Download PDF">pdf</a>, <a href="/ps/2403.00087" title="Download PostScript">ps</a>, <a href="/format/2403.00087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards the verification of a generic interlocking logic: Dafny meets  parameterized model checking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cimatti%2C+A">Alessandro Cimatti</a>, 
<a href="/search/cs?searchtype=author&query=Griggio%2C+A">Alberto Griggio</a>, 
<a href="/search/cs?searchtype=author&query=Redondi%2C+G">Gianluca Redondi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Interlocking logics are at the core of critical systems controlling the
traffic within stations. In this paper, we consider a generic interlocking
logic, which can be instantiated to control a wide class of stations. We tackle
the problem of parameterized verification, i.e. prove that the logic satisfies
the required properties for all the relevant stations. We present a simplified
case study, where the interlocking logic is directly encoded in Dafny. Then, we
show how to automate the proof of an important safety requirement, by
integrating simple, template-based invariants and more complex invariants
obtained from a model checker for parameterized systems. Based on these
positive preliminary results, we outline how we intend to integrate the
approach by extending the IDE for the design of the interlocking logic.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00088" title="Abstract">arXiv:2403.00088</a> [<a href="/pdf/2403.00088" title="Download PDF">pdf</a>, <a href="/format/2403.00088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modern Code Reviews -- Survey of Literature and Practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Badampudi%2C+D">Deepika Badampudi</a>, 
<a href="/search/cs?searchtype=author&query=Unterkalmsteiner%2C+M">Michael Unterkalmsteiner</a>, 
<a href="/search/cs?searchtype=author&query=Britto%2C+R">Ricardo Britto</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Trans. Softw. Eng. Methodol. 32(4): 107:1-107:61 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Background: Modern Code Review (MCR) is a lightweight alternative to
traditional code inspections. While secondary studies on MCR exist, it is
unknown whether the research community has targeted themes that practitioners
consider important. Objectives: The objectives are to provide an overview of
MCR research, analyze the practitioners' opinions on the importance of MCR
research, investigate the alignment between research and practice, and propose
future MCR research avenues. Method: We conducted a systematic mapping study to
survey state of the art until and including 2021, employed the Q-Methodology to
analyze the practitioners' perception of the relevance of MCR research, and
analyzed the primary studies' research impact. Results: We analyzed 244 primary
studies, resulting in five themes. As a result of the 1,300 survey data points,
we found that the respondents are positive about research investigating the
impact of MCR on product quality and MCR process properties. In contrast, they
are negative about human factor- and support systems-related research.
Conclusion: These results indicate a misalignment between the state of the art
and the themes deemed important by most survey respondents. Researchers should
focus on solutions that can improve the state of MCR practice. We provide an
MCR research agenda that can potentially increase the impact of MCR research.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00092" title="Abstract">arXiv:2403.00092</a> [<a href="/pdf/2403.00092" title="Download PDF">pdf</a>, <a href="/format/2403.00092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PROC2PDDL: Open-Domain Planning Representations from Texts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Z">Zhaoyi Hou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuling Gu</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+P">Peter Clark</a>, 
<a href="/search/cs?searchtype=author&query=Callison-Burch%2C+C">Chris Callison-Burch</a>, 
<a href="/search/cs?searchtype=author&query=Tandon%2C+N">Niket Tandon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Planning in a text-based environment continues to be a major challenge for AI
systems. Recent approaches have used language models to predict a planning
domain definition (e.g., PDDL) but have only been evaluated in closed-domain
simulated environments. To address this, we present Proc2PDDL , the first
dataset containing open-domain procedural texts paired with expert-annotated
PDDL representations. Using this dataset, we evaluate state-of-the-art models
on defining the preconditions and effects of actions. We show that Proc2PDDL is
highly challenging, with GPT-3.5's success rate close to 0% and GPT-4's around
35%. Our analysis shows both syntactic and semantic errors, indicating LMs'
deficiency in both generating domain-specific prgorams and reasoning about
events. We hope this analysis and dataset helps future progress towards
integrating the best of LMs and formal planning.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00095" title="Abstract">arXiv:2403.00095</a> [<a href="/pdf/2403.00095" title="Download PDF">pdf</a>, <a href="/ps/2403.00095" title="Download PostScript">ps</a>, <a href="/format/2403.00095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Jigsaw Puzzles using Iterative Random Sampling: Parallels with  Development of Skill Mastery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+N">Neil Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Diana Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 15 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Skill mastery is a priority for success in all fields. We present a parallel
between the development of skill mastery and the process of solving jigsaw
puzzles. We show that iterative random sampling solves jigsaw puzzles in two
phases: a lag phase that is characterized by little change and occupies the
majority of the time, and a growth phase that marks rapid and imminent puzzle
completion. Changes in the proportions of the number of single pieces and
larger pieces can be overlaid on the timeline and progression of skill mastery.
An emphasis is placed on the development of connections between pieces, which
serves as an indicator of increasing puzzle completion and increasing skill
mastery. Our manuscript provides a straightforward visual of skill mastery in
the context of a common recreational activity.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00096" title="Abstract">arXiv:2403.00096</a> [<a href="/pdf/2403.00096" title="Download PDF">pdf</a>, <a href="/ps/2403.00096" title="Download PostScript">ps</a>, <a href="/format/2403.00096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Future of Pandemic Prevention and Response CCC Workshop Report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Danks%2C+D">David Danks</a>, 
<a href="/search/cs?searchtype=author&query=Mihalcea%2C+R">Rada Mihalcea</a>, 
<a href="/search/cs?searchtype=author&query=Siek%2C+K">Katie Siek</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+M">Mona Singh</a>, 
<a href="/search/cs?searchtype=author&query=Dixon%2C+B">Brian Dixon</a>, 
<a href="/search/cs?searchtype=author&query=Griffin%2C+H">Haley Griffin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This report summarizes the discussions and conclusions of a 2-day
multidisciplinary workshop that brought together researchers and practitioners
in healthcare, computer science, and social sciences to explore what lessons
were learned and what actions, primarily in research, could be taken. One
consistent observation was that there is significant merit in thinking not only
about pandemic situations, but also about peacetime advances, as many
healthcare networks and communities are now in a perpetual state of crisis.
Attendees discussed how the COVID-19 pandemic amplified gaps in our health and
computing systems, and how current and future computing technologies could fill
these gaps and improve the trajectory of the next pandemic.
<br />Three major computing themes emerged from the workshop: models, data, and
infrastructure. Computational models are extremely important during pandemics,
from anticipating supply needs of hospitals, to determining the care capacity
of hospital and social service providers, to projecting the spread of the
disease. Accurate, reliable models can save lives, and inform community leaders
on policy decisions. Health system users require accurate, reliable data to
achieve success when applying models. This requires data and measurement
standardization across health care organizations, modernizing the data
infrastructure, and methods for ensuring data remains private while shared for
model development, validation, and application. Finally, many health care
systems lack the data, compute, and communication infrastructures required to
build models on their data, use those models in ordinary operations, or even to
reliably access their data. Robust and timely computing research has the
potential to better support healthcare works to save lives in times of crisis
(e.g., pandemics) and today during relative peacetime.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00098" title="Abstract">arXiv:2403.00098</a> [<a href="/pdf/2403.00098" title="Download PDF">pdf</a>, <a href="/format/2403.00098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Counting Complexity of the Skolem Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jindal%2C+G">Gorav Jindal</a>, 
<a href="/search/cs?searchtype=author&query=Ouaknine%2C+J">Jo&#xeb;l Ouaknine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">The Skolem Problem asks, given an integer linear recurrence sequence (LRS),
to determine whether the sequence contains a zero term or not. Its decidability
is a longstanding open problem in theoretical computer science and automata
theory. Currently, decidability is only known for LRS of order at most 4. On
the other hand, the sole known complexity result is NP-hardness, due to Blondel
and Portier.
<br />A fundamental result in this area is the celebrated Skolem-Mahler-Lech
theorem, which asserts that the zero set of any LRS is the union of a finite
set and finitely many arithmetic progressions. This paper focuses on a
computational perspective of the Skolem-Mahler-Lech theorem: we show that the
problem of counting the zeros of a given LRS is #P-hard, and in fact
#P-complete for the instances generated in our reduction.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00099" title="Abstract">arXiv:2403.00099</a> [<a href="/pdf/2403.00099" title="Download PDF">pdf</a>, <a href="/format/2403.00099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An approach for performance requirements verification and test  environments generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdeen%2C+W">Waleed Abdeen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xingru Chen</a>, 
<a href="/search/cs?searchtype=author&query=Unterkalmsteiner%2C+M">Michael Unterkalmsteiner</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Requir. Eng. 28(1): 117-144 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Model-based testing (MBT) is a method that supports the design and execution
of test cases by models that specify the intended behaviors of a system under
test. While systematic literature reviews on MBT in general exist, the state of
the art on modeling and testing performance requirements has seen much less
attention. Therefore, we conducted a systematic mapping study on model-based
performance testing. Then, we studied natural language software requirements
specifications in order to understand which and how performance requirements
are typically specified. Since none of the identified MBT techniques supported
a major benefit of modeling, namely identifying faults in requirements
specifications, we developed the Performance Requirements verificatiOn and Test
EnvironmentS generaTion approach (PRO-TEST). Finally, we evaluated PRO-TEST on
149 requirements specifications. We found and analyzed 57 primary studies from
the systematic mapping study and extracted 50 performance requirements models.
However, those models don't achieve the goals of MBT, which are validating
requirements, ensuring their testability, and generating the minimum required
test cases. We analyzed 77 Software Requirements Specification (SRS) documents,
extracted 149 performance requirements from those SRS, and illustrate that with
PRO-TEST we can model performance requirements, find issues in those
requirements and detect missing ones. We detected three not-quantifiable
requirements, 43 not-quantified requirements, and 180 underspecified parameters
in the 149 modeled performance requirements. Furthermore, we generated 96 test
environments from those models. By modeling performance requirements with
PRO-TEST, we can identify issues in the requirements related to their
ambiguity, measurability, and completeness. Additionally, it allows to generate
parameters for test environments.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00103" title="Abstract">arXiv:2403.00103</a> [<a href="/pdf/2403.00103" title="Download PDF">pdf</a>, <a href="/format/2403.00103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Robustness and Generalization of ML-Based Congestion Predictors to  Valid and Imperceptible Perturbations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Holtz%2C+C">Chester Holtz</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yucheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C">Chung-Kuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Bill Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">There is substantial interest in the use of machine learning (ML)-based
techniques throughout the electronic computer-aided design (CAD) flow,
particularly methods based on deep learning. However, while deep learning
methods have achieved state-of-the-art performance in several applications,
recent work has demonstrated that neural networks are generally vulnerable to
small, carefully chosen perturbations of their input (e.g. a single pixel
change in an image). In this work, we investigate robustness in the context of
ML-based EDA tools -- particularly for congestion prediction. As far as we are
aware, we are the first to explore this concept in the context of ML-based EDA.
<br />We first describe a novel notion of imperceptibility designed specifically
for VLSI layout problems defined on netlists and cell placements. Our
definition of imperceptibility is characterized by a guarantee that a
perturbation to a layout will not alter its global routing. We then demonstrate
that state-of-the-art CNN and GNN-based congestion models exhibit brittleness
to imperceptible perturbations. Namely, we show that when a small number of
cells (e.g. 1%-5% of cells) have their positions shifted such that a measure of
global congestion is guaranteed to remain unaffected (e.g. 1% of the design
adversarially shifted by 0.001% of the layout space results in a predicted
decrease in congestion of up to 90%, while no change in congestion is implied
by the perturbation). In other words, the quality of a predictor can be made
arbitrarily poor (i.e. can be made to predict that a design is
"congestion-free") for an arbitrary input layout. Next, we describe a simple
technique to train predictors that improves robustness to these perturbations.
Our work indicates that CAD engineers should be cautious when integrating
neural network-based mechanisms in EDA flows to ensure robust and high-quality
results.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00105" title="Abstract">arXiv:2403.00105</a> [<a href="/pdf/2403.00105" title="Download PDF">pdf</a>, <a href="/format/2403.00105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Longitudinal Counterfactuals: Constraints and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Asemota%2C+A">Alexander Asemota</a>, 
<a href="/search/cs?searchtype=author&query=Hooker%2C+G">Giles Hooker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Counterfactual explanations are a common approach to providing recourse to
data subjects. However, current methodology can produce counterfactuals that
cannot be achieved by the subject, making the use of counterfactuals for
recourse difficult to justify in practice. Though there is agreement that
plausibility is an important quality when using counterfactuals for algorithmic
recourse, ground truth plausibility continues to be difficult to quantify. In
this paper, we propose using longitudinal data to assess and improve
plausibility in counterfactuals. In particular, we develop a metric that
compares longitudinal differences to counterfactual differences, allowing us to
evaluate how similar a counterfactual is to prior observed changes.
Furthermore, we use this metric to generate plausible counterfactuals. Finally,
we discuss some of the inherent difficulties of using counterfactuals for
recourse.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00106" title="Abstract">arXiv:2403.00106</a> [<a href="/pdf/2403.00106" title="Download PDF">pdf</a>, <a href="/format/2403.00106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Umwelt: Accessible Structured Editing of Multimodal Data Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zong%2C+J">Jonathan Zong</a>, 
<a href="/search/cs?searchtype=author&query=Pineros%2C+I+P">Isabella Pedraza Pineros</a>, 
<a href="/search/cs?searchtype=author&query=Mengzhu">Mengzhu</a> (Katie)
<a href="/search/cs?searchtype=author&query=Chen">Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hajas%2C+D">Daniel Hajas</a>, 
<a href="/search/cs?searchtype=author&query=Satyanarayan%2C+A">Arvind Satyanarayan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">We present Umwelt, an authoring environment for interactive multimodal data
representations. In contrast to prior approaches, which center the visual
modality, Umwelt treats visualization, sonification, and textual description as
coequal representations: they are all derived from a shared abstract data
model, such that no modality is prioritized over the others. To simplify
specification, Umwelt evaluates a set of heuristics to generate default
multimodal representations that express a dataset's functional relationships.
To support smoothly moving between representations, Umwelt maintains a shared
query predicated that is reified across all modalities -- for instance,
navigating the textual description also highlights the visualization and
filters the sonification. In a study with 5 blind / low-vision expert users, we
found that Umwelt's multimodal representations afforded complementary overview
and detailed perspectives on a dataset, allowing participants to fluidly shift
between task- and representation-oriented ways of thinking.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00107" title="Abstract">arXiv:2403.00107</a> [<a href="/pdf/2403.00107" title="Download PDF">pdf</a>, <a href="/ps/2403.00107" title="Download PostScript">ps</a>, <a href="/format/2403.00107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Talent hat, cross-border mobility, and career development in China
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yurui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xuesen Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+C">Chaolin Tian</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xunyi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Langtian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yifang Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">This study aims to investigate the influence of cross-border recruitment
program in China, which confers scientists with a 'talent hat' including a
startup package comprising significant bonuses, pay, and funding, on their
future performance and career development. By curating a unique dataset from
China's 10-year talent recruitment program, we employed multiple matching
designs to quantify the effects of the cross-border recruitment with 'talent
hat' on early career STEM scholars. Our findings indicate that the cross-border
talents perform better than their comparable contenders who move without talent
hats and those who do not move, given equivalent scientific performance before
relocation. Moreover, we observed that scholars in experimental fields derive
greater benefits from the talent program than those in non-experimental fields.
Finally, we investigated how the changes in scientific environment of
scientists affect their future performance. We found that talents who
reassembled their collaboration network with new collaborators in new
institutions after job replacement experienced significant improvements in
their academic performance. However, shifting research directions entails
risks, which results in a subsequent decrease of future productivity and
citation impact following the relocation. This study has significant
implications for young scientists, research institutions, and governments
concerning cultivating cross-border talents.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00108" title="Abstract">arXiv:2403.00108</a> [<a href="/pdf/2403.00108" title="Download PDF">pdf</a>, <a href="/format/2403.00108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LoRA-as-an-Attack! Piercing LLM Safety Under The Share-and-Play Scenario
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zirui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruixiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jiayi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+S">Shaochen Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Chuang%2C+Y">Yu-Neng Chuang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Rui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xia Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Fine-tuning LLMs is crucial to enhancing their task-specific performance and
ensuring model behaviors are aligned with human preferences. Among various
fine-tuning methods, LoRA is popular for its efficiency and ease to use,
allowing end-users to easily post and adopt lightweight LoRA modules on
open-source platforms to tailor their model for different customization.
However, such a handy share-and-play setting opens up new attack surfaces, that
the attacker can render LoRA as an attacker, such as backdoor injection, and
widely distribute the adversarial LoRA to the community easily. This can result
in detrimental outcomes. Despite the huge potential risks of sharing LoRA
modules, this aspect however has not been fully explored. To fill the gap, in
this study we thoroughly investigate the attack opportunities enabled in the
growing share-and-play scenario. Specifically, we study how to inject backdoor
into the LoRA module and dive deeper into LoRA's infection mechanisms. We found
that training-free mechanism is possible in LoRA backdoor injection. We also
discover the impact of backdoor attacks with the presence of multiple LoRA
adaptions concurrently as well as LoRA based backdoor transferability. Our aim
is to raise awareness of the potential risks under the emerging share-and-play
scenario, so as to proactively prevent potential consequences caused by
LoRA-as-an-Attack. Warning: the paper contains potential offensive content
generated by models.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00111" title="Abstract">arXiv:2403.00111</a> [<a href="/pdf/2403.00111" title="Download PDF">pdf</a>, <a href="/format/2403.00111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A compendium and evaluation of taxonomy quality attributes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Unterkalmsteiner%2C+M">Michael Unterkalmsteiner</a>, 
<a href="/search/cs?searchtype=author&query=Adbeen%2C+W">Waleed Adbeen</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Expert Syst. J. Knowl. Eng. 40(1) (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Introduction: Taxonomies capture knowledge about a particular domain in a
succinct manner and establish a common understanding among peers. Researchers
use taxonomies to convey information about a particular knowledge area or to
support automation tasks, and practitioners use them to enable communication
beyond organizational boundaries. Aims: Despite this important role of
taxonomies in software engineering, their quality is seldom evaluated. Our aim
is to identify and define taxonomy quality attributes that provide practical
measurements, helping researchers and practitioners to compare taxonomies and
choose the one most adequate for the task at hand. Methods: We reviewed 324
publications from software engineering and information systems research and
synthesized, when provided, the definitions of quality attributes and
measurements. We evaluated the usefulness of the measurements on six taxonomies
from three domains. Results: We propose the definition of seven quality
attributes and suggest internal and external measurements that can be used to
assess a taxonomy's quality. For two measurements we provide implementations in
Python. We found the measurements useful for deciding which taxonomy is best
suited for a particular purpose. Conclusion: While there exist several
guidelines for creating taxonomies, there is a lack of actionable criteria to
compare taxonomies. In this paper, we fill this gap by synthesizing from a
wealth of literature seven, non-overlapping taxonomy quality attributes and
corresponding measurements. Future work encompasses their further evaluation of
usefulness and empirical validation.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00115" title="Abstract">arXiv:2403.00115</a> [<a href="/pdf/2403.00115" title="Download PDF">pdf</a>, <a href="/ps/2403.00115" title="Download PostScript">ps</a>, <a href="/format/2403.00115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PosSLP and Sum of Squares
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bl%C3%A4ser%2C+M">Markus Bl&#xe4;ser</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%B6rfler%2C+J">Julian D&#xf6;rfler</a>, 
<a href="/search/cs?searchtype=author&query=Jindal%2C+G">Gorav Jindal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">The problem PosSLP is the problem of determining whether a given
straight-line program (SLP) computes a positive integer. PosSLP was introduced
by Allender et al. to study the complexity of numerical analysis (Allender et
al., 2009). PosSLP can also be reformulated as the problem of deciding whether
the integer computed by a given SLP can be expressed as the sum of squares of
four integers, based on the well-known result by Lagrange in 1770, which
demonstrated that every natural number can be represented as the sum of four
non-negative integer squares.
<br />In this paper, we explore several natural extensions of this problem by
investigating whether the positive integer computed by a given SLP can be
written as the sum of squares of two or three integers. We delve into the
complexity of these variations and demonstrate relations between the complexity
of the original PosSLP problem and the complexity of these related problems.
Additionally, we introduce a new intriguing problem called Div2SLP and
illustrate how Div2SLP is connected to DegSLP and the problem of whether an SLP
computes an integer expressible as the sum of three squares.
<br />By comprehending the connections between these problems, our results offer a
deeper understanding of decision problems associated with SLPs and open avenues
for further exciting research
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00116" title="Abstract">arXiv:2403.00116</a> [<a href="/pdf/2403.00116" title="Download PDF">pdf</a>, <a href="/format/2403.00116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Linear Contextual Bandits with Heterogeneous Clients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blaser%2C+E">Ethan Blaser</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chuanhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongning Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The demand for collaborative and private bandit learning across multiple
agents is surging due to the growing quantity of data generated from
distributed systems. Federated bandit learning has emerged as a promising
framework for private, efficient, and decentralized online learning. However,
almost all previous works rely on strong assumptions of client homogeneity,
i.e., all participating clients shall share the same bandit model; otherwise,
they all would suffer linear regret. This greatly restricts the application of
federated bandit learning in practice. In this work, we introduce a new
approach for federated bandits for heterogeneous clients, which clusters
clients for collaborative bandit learning under the federated learning setting.
Our proposed algorithm achieves non-trivial sub-linear regret and communication
cost for all clients, subject to the communication protocol under federated
learning that at anytime only one model can be shared by the server.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00121" title="Abstract">arXiv:2403.00121</a> [<a href="/pdf/2403.00121" title="Download PDF">pdf</a>, <a href="/ps/2403.00121" title="Download PostScript">ps</a>, <a href="/format/2403.00121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Optimality of CVOD-based Column Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Emelianenko%2C+M">Maria Emelianenko</a>, 
<a href="/search/math?searchtype=author&query=Oldaker%2C+G+B">Guy B. Oldaker IV</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages. arXiv admin note: substantial text overlap with <a href="/abs/2402.07325">arXiv:2402.07325</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">While there exists a rich array of matrix column subset selection problem
(CSSP) algorithms for use with interpolative and CUR-type decompositions, their
use can often become prohibitive as the size of the input matrix increases. In
an effort to address these issues, the authors in
\cite{emelianenko2024adaptive} developed a general framework that pairs a
column-partitioning routine with a column-selection algorithm. Two of the four
algorithms presented in that work paired the Centroidal Voronoi Orthogonal
Decomposition (\textsf{CVOD}) and an adaptive variant (\textsf{adaptCVOD}) with
the Discrete Empirical Interpolation Method (\textsf{DEIM})
\cite{sorensen2016deim}. In this work, we extend this framework and pair the
\textsf{CVOD}-type algorithms with any CSSP algorithm that returns linearly
independent columns. Our results include detailed error bounds for the
solutions provided by these paired algorithms, as well as expressions that
explicitly characterize how the quality of the selected column partition
affects the resulting CSSP solution.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00125" title="Abstract">arXiv:2403.00125</a> [<a href="/pdf/2403.00125" title="Download PDF">pdf</a>, <a href="/format/2403.00125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Penalty-free discontinuous Galerkin method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ja%C5%9Bkowiec%2C+J">Jan Ja&#x15b;kowiec</a>, 
<a href="/search/math?searchtype=author&query=Sukumar%2C+N">N. Sukumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we present a new high-order discontinuous Galerkin (DG)
method, in which neither a penalty parameter nor a stabilization parameter is
needed. We refer to this method as penalty-free DG (\PFDG). In this method, the
trial and test functions belong to the broken Sobolev space, in which the
functions are in general discontinuous on the mesh skeleton and do not meet the
Dirichlet boundary conditions. However, a subset can be distinguished in this
space, where the functions are continuous and satisfy the Dirichlet boundary
conditions, and this subset is called admissible. The trial solution is chosen
to lie in an \emph{augmented} admissible subset, in which a small violation of
the continuity condition is permitted. This subset is constructed by applying
special augmented constraints to the linear combination of finite element basis
functions. In this approach, all the advantages of the DG method are retained
without the necessity of using stability parameters or numerical fluxes.
Several benchmark problems in two dimensions (Poisson equation, linear
elasticity, hyperelasticity, and biharmonic equation) on polygonal (triangles,
quadrilateral and weakly convex polygons) meshes as well as a three-dimensional
Poisson problem on hexahedral meshes are considered. Numerical results are
presented that affirm the sound accuracy and optimal convergence of the method
in the $L^2$ norm and the energy seminorm.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00126" title="Abstract">arXiv:2403.00126</a> [<a href="/pdf/2403.00126" title="Download PDF">pdf</a>, <a href="/format/2403.00126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAC$^2$E: Better Understanding Large Language Model Capabilities by  Dissociating Language and Cognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lingfei Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in Progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) are primarily evaluated by overall performance
on various text understanding and generation tasks. However, such a paradigm
fails to comprehensively differentiate the fine-grained language and cognitive
skills, rendering the lack of sufficient interpretation to LLMs' capabilities.
In this paper, we present FAC$^2$E, a framework for Fine-grAined and
Cognition-grounded LLMs' Capability Evaluation. Specifically, we formulate
LLMs' evaluation in a multi-dimensional and explainable manner by dissociating
the language-related capabilities and the cognition-related ones. Besides,
through extracting the intermediate reasoning from LLMs, we further break down
the process of applying a specific capability into three sub-steps: recalling
relevant knowledge, utilizing knowledge, and solving problems. Finally,
FAC$^2$E evaluates each sub-step of each fine-grained capability, providing a
two-faceted diagnosis for LLMs. Utilizing FAC$^2$E, we identify a common
shortfall in knowledge utilization among models and propose a straightforward,
knowledge-enhanced method to mitigate this issue. Our results not only showcase
promising performance enhancements but also highlight a direction for future
LLM advancements.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00127" title="Abstract">arXiv:2403.00127</a> [<a href="/pdf/2403.00127" title="Download PDF">pdf</a>, <a href="/ps/2403.00127" title="Download PostScript">ps</a>, <a href="/format/2403.00127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompting ChatGPT for Translation: A Comparative Analysis of Translation  Brief and Persona Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+S">Sui He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Prompt engineering in LLMs has shown potential for improving translation
quality. However, the potential of incorporating translation concepts in prompt
design remains largely underexplored. Against this backdrop, this paper
discusses the effectiveness of incorporating the conceptual tool of translation
brief and the personas of translator and author into prompt design for
translation tasks in ChatGPT. Findings suggest that, although certain elements
are constructive in facilitating human to human communication for translation
tasks, their effectiveness is limited for improving translation quality in
ChatGPT. This accentuates the need for more explorative research on how
translation theorists and practitioners can develop the current set of
conceptual tools rooted in the human to human communication paradigm for
translation purposes in this emerging workflow involving human machine
interaction.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00128" title="Abstract">arXiv:2403.00128</a> [<a href="/pdf/2403.00128" title="Download PDF">pdf</a>, <a href="/format/2403.00128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Flies to Robots: Inverted Landing in Small Quadcopters with Dynamic  Perching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Habas%2C+B">Bryan Habas</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+B">Bo Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 19 Figures, Journal paper currently under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Inverted landing is a routine behavior among a number of animal fliers.
However, mastering this feat poses a considerable challenge for robotic fliers,
especially to perform dynamic perching with rapid body rotations (or flips) and
landing against gravity. Inverted landing in flies have suggested that optical
flow senses are closely linked to the precise triggering and control of body
flips that lead to a variety of successful landing behaviors. Building upon
this knowledge, we aimed to replicate the flies' landing behaviors in small
quadcopters by developing a control policy general to arbitrary
ceiling-approach conditions. First, we employed reinforcement learning in
simulation to optimize discrete sensory-motor pairs across a broad spectrum of
ceiling-approach velocities and directions. Next, we converted the
sensory-motor pairs to a two-stage control policy in a continuous
augmented-optical flow space. The control policy consists of a first-stage
Flip-Trigger Policy, which employs a one-class support vector machine, and a
second-stage Flip-Action Policy, implemented as a feed-forward neural network.
To transfer the inverted-landing policy to physical systems, we utilized domain
randomization and system identification techniques for a zero-shot sim-to-real
transfer. As a result, we successfully achieved a range of robust
inverted-landing behaviors in small quadcopters, emulating those observed in
flies.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00129" title="Abstract">arXiv:2403.00129</a> [<a href="/pdf/2403.00129" title="Download PDF">pdf</a>, <a href="/ps/2403.00129" title="Download PostScript">ps</a>, <a href="/format/2403.00129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Average-Case Local Computation Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biswas%2C+A+S">Amartya Shankha Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+R">Ruidi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Pyne%2C+E">Edward Pyne</a>, 
<a href="/search/cs?searchtype=author&query=Rubinfeld%2C+R">Ronitt Rubinfeld</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We initiate the study of Local Computation Algorithms on average case inputs.
In the Local Computation Algorithm (LCA) model, we are given probe access to a
huge graph, and asked to answer membership queries about some combinatorial
structure on the graph, answering each query with sublinear work.
<br />For instance, an LCA for the $k$-spanner problem gives access to a sparse
subgraph $H\subseteq G$ that preserves distances up to a factor of $k$. We
build simple LCAs for this problem assuming the input graph is drawn from the
well-studied Erdos-Reyni and Preferential Attachment graph models. In both
cases, our spanners achieve size and stretch tradeoffs that are impossible to
achieve for general graphs, while having dramatically lower query complexity
than worst-case LCAs.
<br />Our second result investigates the intersection of LCAs with Local Access
Generators (LAGs). Local Access Generators provide efficient query access to a
random object, for instance an Erdos Reyni random graph. We explore the natural
problem of generating a random graph together with a combinatorial structure on
it. We show that this combination can be easier to solve than focusing on each
problem by itself, by building a fast, simple algorithm that provides access to
an Erdos Reyni random graph together with a maximal independent set.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00131" title="Abstract">arXiv:2403.00131</a> [<a href="/pdf/2403.00131" title="Download PDF">pdf</a>, <a href="/format/2403.00131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniTS: Building a Unified Time Series Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shanghua Gao</a>, 
<a href="/search/cs?searchtype=author&query=Koker%2C+T">Teddy Koker</a>, 
<a href="/search/cs?searchtype=author&query=Queen%2C+O">Owen Queen</a>, 
<a href="/search/cs?searchtype=author&query=Hartvigsen%2C+T">Thomas Hartvigsen</a>, 
<a href="/search/cs?searchtype=author&query=Tsiligkaridis%2C+T">Theodoros Tsiligkaridis</a>, 
<a href="/search/cs?searchtype=author&query=Zitnik%2C+M">Marinka Zitnik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Foundation models, especially LLMs, are profoundly transforming deep
learning. Instead of training many task-specific models, we can adapt a single
pretrained model to many tasks via fewshot prompting or fine-tuning. However,
current foundation models apply to sequence data but not to time series, which
present unique challenges due to the inherent diverse and multidomain time
series datasets, diverging task specifications across forecasting,
classification and other types of tasks, and the apparent need for
task-specialized models. We developed UNITS, a unified time series model that
supports a universal task specification, accommodating classification,
forecasting, imputation, and anomaly detection tasks. This is achieved through
a novel unified network backbone, which incorporates sequence and variable
attention along with a dynamic linear operator and is trained as a unified
model. Across 38 multi-domain datasets, UNITS demonstrates superior performance
compared to task-specific models and repurposed natural language-based LLMs.
UNITS exhibits remarkable zero-shot, few-shot, and prompt learning capabilities
when evaluated on new data domains and tasks. The source code and datasets are
available at https://github.com/mims-harvard/UniTS.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00133" title="Abstract">arXiv:2403.00133</a> [<a href="/pdf/2403.00133" title="Download PDF">pdf</a>, <a href="/format/2403.00133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ForTune: Running Offline Scenarios to Estimate Impact on Business  Metrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dupret%2C+G">Georges Dupret</a>, 
<a href="/search/cs?searchtype=author&query=Sozinov%2C+K">Konstantin Sozinov</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+C+B">Carmen Barcena Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Zacks%2C+Z">Ziggy Zacks</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+A">Amber Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Carterette%2C+B">Benjamin Carterette</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+M">Manuel Mai</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+S">Shubham Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+G">Gwo Liang</a> (Leo)
<a href="/search/cs?searchtype=author&query=Lien">Lien</a>, 
<a href="/search/cs?searchtype=author&query=Gatash%2C+A">Andrey Gatash</a>, 
<a href="/search/cs?searchtype=author&query=Ojeda%2C+R+S">Roberto Sanchis Ojeda</a>, 
<a href="/search/cs?searchtype=author&query=Lalmas%2C+M">Mounia Lalmas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Applications (stat.AP)

</div>
<p class="mathjax">Making ideal decisions as a product leader in a web-facing company is
extremely difficult. In addition to navigating the ambiguity of customer
satisfaction and achieving business goals, one must also pave a path forward
for ones' products and services to remain relevant, desirable, and profitable.
Data and experimentation to test product hypotheses are key to informing
product decisions. Online controlled experiments by A/B testing may provide the
best data to support such decisions with high confidence, but can be
time-consuming and expensive, especially when one wants to understand impact to
key business metrics such as retention or long-term value. Offline
experimentation allows one to rapidly iterate and test, but often cannot
provide the same level of confidence, and cannot easily shine a light on impact
on business metrics. We introduce a novel, lightweight, and flexible approach
to investigating hypotheses, called scenario analysis, that aims to support
product leaders' decisions using data about users and estimates of business
metrics. Its strengths are that it can provide guidance on trade-offs that are
incurred by growing or shifting consumption, estimate trends in long-term
outcomes like retention and other important business metrics, and can generate
hypotheses about relationships between metrics at scale.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00134" title="Abstract">arXiv:2403.00134</a> [<a href="/pdf/2403.00134" title="Download PDF">pdf</a>, <a href="/format/2403.00134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Sensing for Reciprocal MIMO Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+T">Tao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wei Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper addresses the design of transmit precoder and receive combiner
matrices to support $N_{\rm s}$ independent data streams over a time-division
duplex (TDD) point-to-point massive multiple-input multiple-output (MIMO)
channel with either a fully digital or a hybrid structure. The optimal precoder
and combiner design amounts to finding the top-$N_{\rm s}$ singular vectors of
the channel matrix, but the explicit estimation of the entire high-dimensional
channel would require significant pilot overhead. Alternatively, prior works
seek to find the precoding and combining matrices directly by exploiting
channel reciprocity and by using the power iteration method, but its
performance degrades in the low SNR regime. To tackle this challenging problem,
this paper proposes a learning-based active sensing framework, where the
transmitter and the receiver send pilots alternately using sensing beamformers
that are actively designed as functions of previously received pilots. This is
accomplished by using recurrent neural networks to summarize information from
the historical observations into hidden state vectors, then using fully
connected neural networks to learn the appropriate sensing beamformers in the
next pilot stage and finally the transmit precoding and receive combiner
matrices for data communications. Simulations demonstrate that the
learning-based method outperforms existing approaches significantly and
maintains superior performance even in low SNR regimes both in fully digital
and hybrid MIMO scenarios.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00136" title="Abstract">arXiv:2403.00136</a> [<a href="/pdf/2403.00136" title="Download PDF">pdf</a>, <a href="/format/2403.00136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developing a Taxonomy of Elements Adversarial to Autonomous Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saffary%2C+M">Mohammadali Saffary</a>, 
<a href="/search/cs?searchtype=author&query=Inampudi%2C+N">Nishan Inampudi</a>, 
<a href="/search/cs?searchtype=author&query=Siegel%2C+J+E">Joshua E. Siegel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages total, 4 pages of references, initial page left blank for IEEE submission statement. Includes 4 figures and 2 tables. Written using IEEEtran document class
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">As highly automated vehicles reach higher deployment rates, they find
themselves in increasingly dangerous situations. Knowing that the consequence
of a crash is significant for the health of occupants, bystanders, and
properties, as well as to the viability of autonomy and adjacent businesses, we
must search for more efficacious ways to comprehensively and reliably train
autonomous vehicles to better navigate the complex scenarios with which they
struggle. We therefore introduce a taxonomy of potentially adversarial elements
that may contribute to poor performance or system failures as a means of
identifying and elucidating lesser-seen risks. This taxonomy may be used to
characterize failures of automation, as well as to support simulation and
real-world training efforts by providing a more comprehensive classification
system for events resulting in disengagement, collision, or other negative
consequences. This taxonomy is created from and tested against real collision
events to ensure comprehensive coverage with minimal class overlap and few
omissions. It is intended to be used both for the identification of
harm-contributing adversarial events and in the generation thereof (to create
extreme edge- and corner-case scenarios) in training procedures.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00137" title="Abstract">arXiv:2403.00137</a> [<a href="/pdf/2403.00137" title="Download PDF">pdf</a>, <a href="/format/2403.00137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User Characteristics in Explainable AI: The Rabbit Hole of  Personalization?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nimmo%2C+R">Robert Nimmo</a>, 
<a href="/search/cs?searchtype=author&query=Constantinides%2C+M">Marios Constantinides</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Ke Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Quercia%2C+D">Daniele Quercia</a>, 
<a href="/search/cs?searchtype=author&query=Stumpf%2C+S">Simone Stumpf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 4 tables, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">As Artificial Intelligence (AI) becomes ubiquitous, the need for Explainable
AI (XAI) has become critical for transparency and trust among users. A
significant challenge in XAI is catering to diverse users, such as data
scientists, domain experts, and end-users. Recent research has started to
investigate how users' characteristics impact interactions with and user
experience of explanations, with a view to personalizing XAI. However, are we
heading down a rabbit hole by focusing on unimportant details? Our research
aimed to investigate how user characteristics are related to using,
understanding, and trusting an AI system that provides explanations. Our
empirical study with 149 participants who interacted with an XAI system that
flagged inappropriate comments showed that very few user characteristics
mattered; only age and the personality trait openness influenced actual
understanding. Our work provides evidence to reorient user-focused XAI research
and question the pursuit of personalized XAI based on fine-grained user
characteristics.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00141" title="Abstract">arXiv:2403.00141</a> [<a href="/pdf/2403.00141" title="Download PDF">pdf</a>, <a href="/format/2403.00141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EROS: Entity-Driven Controlled Policy Document Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+J">Joykirat Singh</a>, 
<a href="/search/cs?searchtype=author&query=Fazili%2C+S">Sehban Fazili</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+R">Rohan Jain</a>, 
<a href="/search/cs?searchtype=author&query=Akhtar%2C+M+S">Md Shad Akhtar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Privacy policy documents have a crucial role in educating individuals about
the collection, usage, and protection of users' personal data by organizations.
However, they are notorious for their lengthy, complex, and convoluted language
especially involving privacy-related entities. Hence, they pose a significant
challenge to users who attempt to comprehend organization's data usage policy.
In this paper, we propose to enhance the interpretability and readability of
policy documents by using controlled abstractive summarization -- we enforce
the generated summaries to include critical privacy-related entities (e.g.,
data and medium) and organization's rationale (e.g.,target and reason) in
collecting those entities. To achieve this, we develop PD-Sum, a
policy-document summarization dataset with marked privacy-related entity
labels. Our proposed model, EROS, identifies critical entities through a
span-based entity extraction model and employs them to control the information
content of the summaries using proximal policy optimization (PPO). Comparison
shows encouraging improvement over various baselines. Furthermore, we furnish
qualitative and human evaluations to establish the efficacy of EROS.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00143" title="Abstract">arXiv:2403.00143</a> [<a href="/pdf/2403.00143" title="Download PDF">pdf</a>, <a href="/format/2403.00143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble-Based Unsupervised Discontinuous Constituency Parsing by Tree  Averaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shayegh%2C+B">Behzad Shayegh</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yuqiao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+L">Lili Mou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We address unsupervised discontinuous constituency parsing, where we observe
a high variance in the performance of the only previous model. We propose to
build an ensemble of different runs of the existing discontinuous parser by
averaging the predicted trees, to stabilize and boost performance. To begin
with, we provide comprehensive computational complexity analysis (in terms of P
and NP-complete) for tree averaging under different setups of binarity and
continuity. We then develop an efficient exact algorithm to tackle the task,
which runs in a reasonable time for all samples in our experiments. Results on
three datasets show our method outperforms all baselines in all metrics; we
also provide in-depth analyses of our approach.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00144" title="Abstract">arXiv:2403.00144</a> [<a href="/pdf/2403.00144" title="Download PDF">pdf</a>, <a href="/format/2403.00144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EBBS: An Ensemble with Bi-Level Beam Search for Zero-Shot Machine  Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yuqiao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Shayegh%2C+B">Behzad Shayegh</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chenyang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yanshuai Cao</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+L">Lili Mou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The ability of zero-shot translation emerges when we train a multilingual
model with certain translation directions; the model can then directly
translate in unseen directions. Alternatively, zero-shot translation can be
accomplished by pivoting through a third language (e.g., English). In our work,
we observe that both direct and pivot translations are noisy and achieve less
satisfactory performance. We propose EBBS, an ensemble method with a novel
bi-level beam search algorithm, where each ensemble component explores its own
prediction step by step at the lower level but they are synchronized by a "soft
voting" mechanism at the upper level. Results on two popular multilingual
translation datasets show that EBBS consistently outperforms direct and pivot
translations as well as existing ensemble techniques. Further, we can distill
the ensemble's knowledge back to the multilingual model to improve inference
efficiency; profoundly, our EBBS-based distillation does not sacrifice, or even
improves, the translation quality.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00145" title="Abstract">arXiv:2403.00145</a> [<a href="/pdf/2403.00145" title="Download PDF">pdf</a>, <a href="/format/2403.00145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guidelines for Integrating Value Sensitive Design in Responsible AI  Toolkits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sadek%2C+M">Malak Sadek</a>, 
<a href="/search/cs?searchtype=author&query=Constantinides%2C+M">Marios Constantinides</a>, 
<a href="/search/cs?searchtype=author&query=Quercia%2C+D">Daniele Quercia</a>, 
<a href="/search/cs?searchtype=author&query=Mougenot%2C+C">C&#xe9;line Mougenot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 8 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Value Sensitive Design (VSD) is a framework for integrating human values
throughout the technology design process. In parallel, Responsible AI (RAI)
advocates for the development of systems aligning with ethical values, such as
fairness and transparency. In this study, we posit that a VSD approach is not
only compatible, but also advantageous to the development of RAI toolkits. To
empirically assess this hypothesis, we conducted four workshops involving 17
early-career AI researchers. Our aim was to establish links between VSD and RAI
values while examining how existing toolkits incorporate VSD principles in
their design. Our findings show that collaborative and educational design
features within these toolkits, including illustrative examples and open-ended
cues, facilitate an understanding of human and ethical values, and empower
researchers to incorporate values into AI systems. Drawing on these insights,
we formulated six design guidelines for integrating VSD values into the
development of RAI toolkits.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00148" title="Abstract">arXiv:2403.00148</a> [<a href="/pdf/2403.00148" title="Download PDF">pdf</a>, <a href="/ps/2403.00148" title="Download PostScript">ps</a>, <a href="/format/2403.00148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implications of Regulations on the Use of AI and Generative AI for  Human-Centered Responsible Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Constantinides%2C+M">Marios Constantinides</a>, 
<a href="/search/cs?searchtype=author&query=Tahaei%2C+M">Mohammad Tahaei</a>, 
<a href="/search/cs?searchtype=author&query=Quercia%2C+D">Daniele Quercia</a>, 
<a href="/search/cs?searchtype=author&query=Stumpf%2C+S">Simone Stumpf</a>, 
<a href="/search/cs?searchtype=author&query=Madaio%2C+M">Michael Madaio</a>, 
<a href="/search/cs?searchtype=author&query=Kennedy%2C+S">Sean Kennedy</a>, 
<a href="/search/cs?searchtype=author&query=Wilcox%2C+L">Lauren Wilcox</a>, 
<a href="/search/cs?searchtype=author&query=Vitak%2C+J">Jessica Vitak</a>, 
<a href="/search/cs?searchtype=author&query=Cramer%2C+H">Henriette Cramer</a>, 
<a href="/search/cs?searchtype=author&query=Bogucka%2C+E">Edyta Bogucka</a>, 
<a href="/search/cs?searchtype=author&query=Baeza-Yates%2C+R">Ricardo Baeza-Yates</a>, 
<a href="/search/cs?searchtype=author&query=Luger%2C+E">Ewa Luger</a>, 
<a href="/search/cs?searchtype=author&query=Holbrook%2C+J">Jess Holbrook</a>, 
<a href="/search/cs?searchtype=author&query=Muller%2C+M">Michael Muller</a>, 
<a href="/search/cs?searchtype=author&query=Blumenfeld%2C+I+G">Ilana Golbin Blumenfeld</a>, 
<a href="/search/cs?searchtype=author&query=Pistilli%2C+G">Giada Pistilli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">With the upcoming AI regulations (e.g., EU AI Act) and rapid advancements in
generative AI, new challenges emerge in the area of Human-Centered Responsible
Artificial Intelligence (HCR-AI). As AI becomes more ubiquitous, questions
around decision-making authority, human oversight, accountability,
sustainability, and the ethical and legal responsibilities of AI and their
creators become paramount. Addressing these questions requires a collaborative
approach. By involving stakeholders from various disciplines in the
2\textsuperscript{nd} edition of the HCR-AI Special Interest Group (SIG) at CHI
2024, we aim to discuss the implications of regulations in HCI research,
develop new theories, evaluation frameworks, and methods to navigate the
complex nature of AI ethics, steering AI development in a direction that is
beneficial and sustainable for all of humanity.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00153" title="Abstract">arXiv:2403.00153</a> [<a href="/pdf/2403.00153" title="Download PDF">pdf</a>, <a href="/format/2403.00153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical and Rich User Digitization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahuja%2C+K">Karan Ahuja</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">A long-standing vision in computer science has been to evolve computing
devices into proactive assistants that enhance our productivity, health and
wellness, and many other facets of our lives. User digitization is crucial in
achieving this vision as it allows computers to intimately understand their
users, capturing activity, pose, routine, and behavior. Today's consumer
devices - like smartphones and smartwatches provide a glimpse of this
potential, offering coarse digital representations of users with metrics such
as step count, heart rate, and a handful of human activities like running and
biking. Even these very low-dimensional representations are already bringing
value to millions of people's lives, but there is significant potential for
improvement. On the other end, professional, high-fidelity comprehensive user
digitization systems exist. For example, motion capture suits and multi-camera
rigs that digitize our full body and appearance, and scanning machines such as
MRI capture our detailed anatomy. However, these carry significant user
practicality burdens, such as financial, privacy, ergonomic, aesthetic, and
instrumentation considerations, that preclude consumer use. In general, the
higher the fidelity of capture, the lower the user's practicality. Most
conventional approaches strike a balance between user practicality and
digitization fidelity.
<br />My research aims to break this trend, developing sensing systems that
increase user digitization fidelity to create new and powerful computing
experiences while retaining or even improving user practicality and
accessibility, allowing such technologies to have a societal impact. Armed with
such knowledge, our future devices could offer longitudinal health tracking,
more productive work environments, full body avatars in extended reality, and
embodied telepresence experiences, to name just a few domains.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00154" title="Abstract">arXiv:2403.00154</a> [<a href="/pdf/2403.00154" title="Download PDF">pdf</a>, <a href="/format/2403.00154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMs in Political Science: Heralding a New Era of Visual Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+M">Mengying Xing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Interest is increasing among political scientists in leveraging the extensive
information available in images. However, the challenge of interpreting these
images lies in the need for specialized knowledge in computer vision and access
to specialized hardware. As a result, image analysis has been limited to a
relatively small group within the political science community. This landscape
could potentially change thanks to the rise of large language models (LLMs).
This paper aims to raise awareness of the feasibility of using Gemini for image
content analysis. A retrospective analysis was conducted on a corpus of 688
images. Content reports were elicited from Gemini for each image and then
manually evaluated by the authors. We find that Gemini is highly accurate in
performing object detection, which is arguably the most common and fundamental
task in image analysis for political scientists. Equally important, we show
that it is easy to implement as the entire command consists of a single prompt
in natural language; it is fast to run and should meet the time budget of most
researchers; and it is free to use and does not require any specialized
hardware. In addition, we illustrate how political scientists can leverage
Gemini for other image understanding tasks, including face identification,
sentiment analysis, and caption generation. Our findings suggest that Gemini
and other similar LLMs have the potential to drastically stimulate and
accelerate image research in political science and social sciences more
broadly.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00155" title="Abstract">arXiv:2403.00155</a> [<a href="/pdf/2403.00155" title="Download PDF">pdf</a>, <a href="/format/2403.00155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Explaining Deep Neural Network Compression Through a  Probabilistic Latent Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mozafari-Nia%2C+M">Mahsa Mozafari-Nia</a>, 
<a href="/search/cs?searchtype=author&query=Sekeh%2C+S+Y">Salimeh Yasaei Sekeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Despite the impressive performance of deep neural networks (DNNs), their
computational complexity and storage space consumption have led to the concept
of network compression. While DNN compression techniques such as pruning and
low-rank decomposition have been extensively studied, there has been
insufficient attention paid to their theoretical explanation. In this paper, we
propose a novel theoretical framework that leverages a probabilistic latent
space of DNN weights and explains the optimal network sparsity by using the
information-theoretic divergence measures. We introduce new analogous projected
patterns (AP2) and analogous-in-probability projected patterns (AP3) notions
for DNNs and prove that there exists a relationship between AP3/AP2 property of
layers in the network and its performance. Further, we provide a theoretical
analysis that explains the training process of the compressed network. The
theoretical results are empirically validated through experiments conducted on
standard pre-trained benchmarks, including AlexNet, ResNet50, and VGG16, using
CIFAR10 and CIFAR100 datasets. Through our experiments, we highlight the
relationship of AP3 and AP2 properties with fine-tuning pruned DNNs and
sparsity levels.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00157" title="Abstract">arXiv:2403.00157</a> [<a href="/pdf/2403.00157" title="Download PDF">pdf</a>, <a href="/format/2403.00157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Preserving Distributed Optimization and Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ziqin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongqiang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a chapter in the Encyclopedia of Systems and Control Engineering published by Elsevier
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Distributed optimization and learning has recently garnered great attention
due to its wide applications in sensor networks, smart grids, machine learning,
and so forth. Despite rapid development, existing distributed optimization and
learning algorithms require each agent to exchange messages with its neighbors,
which may expose sensitive information and raise significant privacy concerns.
In this survey paper, we overview privacy-preserving distributed optimization
and learning methods. We first discuss cryptography, differential privacy, and
other techniques that can be used for privacy preservation and indicate their
pros and cons for privacy protection in distributed optimization and learning.
We believe that among these approaches, differential privacy is most promising
due to its low computational and communication complexities, which are
extremely appealing for modern learning based applications with high dimensions
of optimization variables. We then introduce several differential-privacy
algorithms that can simultaneously ensure privacy and optimization accuracy.
Moreover, we provide example applications in several machine learning problems
to confirm the real-world effectiveness of these algorithms. Finally, we
highlight some challenges in this research domain and discuss future
directions.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00165" title="Abstract">arXiv:2403.00165</a> [<a href="/pdf/2403.00165" title="Download PDF">pdf</a>, <a href="/format/2403.00165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TELEClass: Taxonomy Enrichment and LLM-Enhanced Hierarchical Text  Classification with Minimal Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Ruozhen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xueqiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jinfeng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jiaming Shen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jiawei Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Hierarchical text classification aims to categorize each document into a set
of classes in a label taxonomy. Most earlier works focus on fully or
semi-supervised methods that require a large amount of human annotated data
which is costly and time-consuming to acquire. To alleviate human efforts, in
this paper, we work on hierarchical text classification with the minimal amount
of supervision: using the sole class name of each node as the only supervision.
Recently, large language models (LLM) show competitive performance on various
tasks through zero-shot prompting, but this method performs poorly in the
hierarchical setting, because it is ineffective to include the large and
structured label space in a prompt. On the other hand, previous
weakly-supervised hierarchical text classification methods only utilize the raw
taxonomy skeleton and ignore the rich information hidden in the text corpus
that can serve as additional class-indicative features. To tackle the above
challenges, we propose TELEClass, Taxonomy Enrichment and LLM-Enhanced
weakly-supervised hierarchical text classification, which (1) automatically
enriches the label taxonomy with class-indicative topical terms mined from the
corpus to facilitate classifier training and (2) utilizes LLMs for both data
annotation and creation tailored for the hierarchical label space. Experiments
show that TELEClass can outperform previous weakly-supervised hierarchical text
classification methods and LLM-based zero-shot prompting methods on two public
datasets.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00169" title="Abstract">arXiv:2403.00169</a> [<a href="/pdf/2403.00169" title="Download PDF">pdf</a>, <a href="/format/2403.00169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantitative Assurance and Synthesis of Controllers from Activity  Diagrams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+K">Kangfeng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+F">Fang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Gerasimou%2C+S">Simos Gerasimou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages, 29 figures, 5 tables, submitted to Journal of Systems and Software (JSS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL); Software Engineering (cs.SE)

</div>
<p class="mathjax">Probabilistic model checking is a widely used formal verification technique
to automatically verify qualitative and quantitative properties for
probabilistic models. However, capturing such systems, writing corresponding
properties, and verifying them require domain knowledge. This makes it not
accessible for researchers and engineers who may not have the required
knowledge. Previous studies have extended UML activity diagrams (ADs),
developed transformations, and implemented accompanying tools for automation.
The research, however, is incomprehensive and not fully open, which makes it
hard to be evaluated, extended, adapted, and accessed. In this paper, we
propose a comprehensive verification framework for ADs, including a new profile
for probability, time, and quality annotations, a semantics interpretation of
ADs in three Markov models, and a set of transformation rules from activity
diagrams to the PRISM language, supported by PRISM and Storm. Most importantly,
we developed algorithms for transformation and implemented them in a tool,
called QASCAD, using model-based techniques, for fully automated verification.
We evaluated one case study where multiple robots are used for delivery in a
hospital and further evaluated six other examples from the literature. With all
these together, this work makes noteworthy contributions to the verification of
ADs by improving evaluation, extensibility, adaptability, and accessibility.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00170" title="Abstract">arXiv:2403.00170</a> [<a href="/pdf/2403.00170" title="Download PDF">pdf</a>, <a href="/format/2403.00170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AlloyASG: Alloy Predicate Code Representation as a Compact Structurally  Balanced Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Guanxuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sullivan%2C+A">Allison Sullivan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">In the program analysis and automated bug-fixing fields, it is common to
create an abstract interpretation of a program's source code as an Abstract
Syntax Tree (AST), which enables programs written in a high-level language to
have various static and dynamic analyses applied. However, ASTs suffer from
exponential growth in their data size due to the limitation that ASTs will
often have identical nodes separately listed in the tree. To address this
issue, we introduce a novel code representation schema, Complex Structurally
Balanced Abstract Semantic Graph (CSBASG), which represents code as a
complex-weighted directed graph that lists a semantic element as a node in the
graph and ensures its structural balance for almost finitely enumerable code
segments, such as the modeling language Alloy. Our experiment ensures that
CSBASG provides a one-on-one correspondence of Alloy predicates to
complex-weighted graphs. We evaluate the effectiveness and efficiency of our
CSBASG representation for Alloy models and identify future applications of
CSBASG for Alloy code generation and automated repair.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00172" title="Abstract">arXiv:2403.00172</a> [<a href="/pdf/2403.00172" title="Download PDF">pdf</a>, <a href="/format/2403.00172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Go Beyond Black-box Policies: Rethinking the Design of Learning Agent  for Interpretable and Verifiable HVAC Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=An%2C+Z">Zhiyu An</a>, 
<a href="/search/eess?searchtype=author&query=Ding%2C+X">Xianzhong Ding</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+W">Wan Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for the 61st Design Automation Conference (DAC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent research has shown the potential of Model-based Reinforcement Learning
(MBRL) to enhance energy efficiency of Heating, Ventilation, and Air
Conditioning (HVAC) systems. However, existing methods rely on black-box
thermal dynamics models and stochastic optimizers, lacking reliability
guarantees and posing risks to occupant health. In this work, we overcome the
reliability bottleneck by redesigning HVAC controllers using decision trees
extracted from existing thermal dynamics models and historical data. Our
decision tree-based policies are deterministic, verifiable, interpretable, and
more energy-efficient than current MBRL methods. First, we introduce a novel
verification criterion for RL agents in HVAC control based on domain knowledge.
Second, we develop a policy extraction procedure that produces a verifiable
decision tree policy. We found that the high dimensionality of the thermal
dynamics model input hinders the efficiency of policy extraction. To tackle the
dimensionality challenge, we leverage importance sampling conditioned on
historical data distributions, significantly improving policy extraction
efficiency. Lastly, we present an offline verification algorithm that
guarantees the reliability of a control policy. Extensive experiments show that
our method saves 68.4% more energy and increases human comfort gain by 14.8%
compared to the state-of-the-art method, in addition to an 1127x reduction in
computation overhead. Our code and data are available at
https://github.com/ryeii/Veri_HVAC
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00174" title="Abstract">arXiv:2403.00174</a> [<a href="/pdf/2403.00174" title="Download PDF">pdf</a>, <a href="/format/2403.00174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A citizen science toolkit to collect human perceptions of urban  environments using open street view images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Danish%2C+M">Matthew Danish</a>, 
<a href="/search/cs?searchtype=author&query=Labib%2C+S">SM Labib</a>, 
<a href="/search/cs?searchtype=author&query=Ricker%2C+B">Britta Ricker</a>, 
<a href="/search/cs?searchtype=author&query=Helbich%2C+M">Marco Helbich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Street View-level Imagery (SVI) is a valuable data source for studies (e.g.,
environmental assessments, green space identification or land cover
classification). While commercial SVI is available, such providers commonly
restrict copying or reuse in ways necessary for research. Open SVI datasets are
readily available from less restrictive sources, such as Mapillary, but due to
the heterogeneity of the images, these require substantial preprocessing,
filtering, and careful quality checks. We present an efficient method for
automated downloading, processing, cropping, and filtering open SVI, to be used
in a survey of human perceptions of the streets portrayed in these images. We
demonstrate our open-source reusable SVI preparation and smartphone-friendly
perception-survey software with Amsterdam (Netherlands) as the case study.
Using a citizen science approach, we collected from 331 people 22,637 ratings
about their perceptions for various criteria. We have published our software in
a public repository for future re-use and reproducibility.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00175" title="Abstract">arXiv:2403.00175</a> [<a href="/pdf/2403.00175" title="Download PDF">pdf</a>, <a href="/format/2403.00175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FusionVision: A comprehensive approach of 3D object reconstruction and  segmentation from RGB-D cameras using YOLO and fast segment anything
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghazouali%2C+S+E">Safouane El Ghazouali</a>, 
<a href="/search/cs?searchtype=author&query=Mhirit%2C+Y">Youssef Mhirit</a>, 
<a href="/search/cs?searchtype=author&query=Oukhrid%2C+A">Ali Oukhrid</a>, 
<a href="/search/cs?searchtype=author&query=Michelucci%2C+U">Umberto Michelucci</a>, 
<a href="/search/cs?searchtype=author&query=Nouira%2C+H">Hichem Nouira</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the realm of computer vision, the integration of advanced techniques into
the processing of RGB-D camera inputs poses a significant challenge, given the
inherent complexities arising from diverse environmental conditions and varying
object appearances. Therefore, this paper introduces FusionVision, an
exhaustive pipeline adapted for the robust 3D segmentation of objects in RGB-D
imagery. Traditional computer vision systems face limitations in simultaneously
capturing precise object boundaries and achieving high-precision object
detection on depth map as they are mainly proposed for RGB cameras. To address
this challenge, FusionVision adopts an integrated approach by merging
state-of-the-art object detection techniques, with advanced instance
segmentation methods. The integration of these components enables a holistic
(unified analysis of information obtained from both color \textit{RGB} and
depth \textit{D} channels) interpretation of RGB-D data, facilitating the
extraction of comprehensive and accurate object information. The proposed
FusionVision pipeline employs YOLO for identifying objects within the RGB image
domain. Subsequently, FastSAM, an innovative semantic segmentation model, is
applied to delineate object boundaries, yielding refined segmentation masks.
The synergy between these components and their integration into 3D scene
understanding ensures a cohesive fusion of object detection and segmentation,
enhancing overall precision in 3D object segmentation. The code and pre-trained
models are publicly available at https://github.com/safouaneelg/FusionVision/.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00176" title="Abstract">arXiv:2403.00176</a> [<a href="/pdf/2403.00176" title="Download PDF">pdf</a>, <a href="/format/2403.00176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoD$^2$: Statically Optimizing Dynamic Deep Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+W">Wei Niu</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+G">Gagan Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+B">Bin Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Programming Languages (cs.PL)

</div>
<p class="mathjax">Though many compilation and runtime systems have been developed for DNNs in
recent years, the focus has largely been on static DNNs. Dynamic DNNs, where
tensor shapes and sizes and even the set of operators used are dependent upon
the input and/or execution, are becoming common. This paper presents SoD$^2$, a
comprehensive framework for optimizing Dynamic DNNs. The basis of our approach
is a classification of common operators that form DNNs, and the use of this
classification towards a Rank and Dimension Propagation (RDP) method. This
framework statically determines the shapes of operators as known constants,
symbolic constants, or operations on these. Next, using RDP we enable a series
of optimizations, like fused code generation, execution (order) planning, and
even runtime memory allocation plan generation. By evaluating the framework on
10 emerging Dynamic DNNs and comparing it against several existing systems, we
demonstrate both reductions in execution latency and memory requirements, with
RDP-enabled key optimizations responsible for much of the gains. Our evaluation
results show that SoD$^2$ runs up to $3.9\times$ faster than these systems
while saving up to $88\%$ peak memory consumption.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00177" title="Abstract">arXiv:2403.00177</a> [<a href="/pdf/2403.00177" title="Download PDF">pdf</a>, <a href="/format/2403.00177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Invasive Medical Digital Twins using Physics-Informed  Self-Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuang%2C+K">Keying Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Dean%2C+F">Frances Dean</a>, 
<a href="/search/cs?searchtype=author&query=Jedlicki%2C+J+B">Jack B. Jedlicki</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+D">David Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Philippakis%2C+A">Anthony Philippakis</a>, 
<a href="/search/cs?searchtype=author&query=Sontag%2C+D">David Sontag</a>, 
<a href="/search/cs?searchtype=author&query=Alaa%2C+A+M">Ahmed M. Alaa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">A digital twin is a virtual replica of a real-world physical phenomena that
uses mathematical modeling to characterize and simulate its defining features.
By constructing digital twins for disease processes, we can perform in-silico
simulations that mimic patients' health conditions and counterfactual outcomes
under hypothetical interventions in a virtual setting. This eliminates the need
for invasive procedures or uncertain treatment decisions. In this paper, we
propose a method to identify digital twin model parameters using only
noninvasive patient health data. We approach the digital twin modeling as a
composite inverse problem, and observe that its structure resembles pretraining
and finetuning in self-supervised learning (SSL). Leveraging this, we introduce
a physics-informed SSL algorithm that initially pretrains a neural network on
the pretext task of solving the physical model equations. Subsequently, the
model is trained to reconstruct low-dimensional health measurements from
noninvasive modalities while being constrained by the physical equations
learned in pretraining. We apply our method to identify digital twins of
cardiac hemodynamics using noninvasive echocardiogram videos, and demonstrate
its utility in unsupervised disease detection and in-silico clinical trials.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00178" title="Abstract">arXiv:2403.00178</a> [<a href="/pdf/2403.00178" title="Download PDF">pdf</a>, <a href="/format/2403.00178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Graph ODE: Continuous Treatment Effect Modeling in Multi-agent  Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zijie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jeehyun Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junkai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Baik%2C+J">Jinwoo Baik</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weitong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wodarz%2C+D">Dominik Wodarz</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yizhou Sun</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Quanquan Gu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Real-world multi-agent systems are often dynamic and continuous, where the
agents co-evolve and undergo changes in their trajectories and interactions
over time. For example, the COVID-19 transmission in the U.S. can be viewed as
a multi-agent system, where states act as agents and daily population movements
between them are interactions. Estimating the counterfactual outcomes in such
systems enables accurate future predictions and effective decision-making, such
as formulating COVID-19 policies. However, existing methods fail to model the
continuous dynamic effects of treatments on the outcome, especially when
multiple treatments (e.g., "stay-at-home" and "get-vaccine" policies) are
applied simultaneously. To tackle this challenge, we propose Causal Graph
Ordinary Differential Equations (CAG-ODE), a novel model that captures the
continuous interaction among agents using a Graph Neural Network (GNN) as the
ODE function. The key innovation of our model is to learn time-dependent
representations of treatments and incorporate them into the ODE function,
enabling precise predictions of potential outcomes. To mitigate confounding
bias, we further propose two domain adversarial learning-based objectives,
which enable our model to learn balanced continuous representations that are
not affected by treatments or interference. Experiments on two datasets (i.e.,
COVID-19 and tumor growth) demonstrate the superior performance of our proposed
model.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00179" title="Abstract">arXiv:2403.00179</a> [<a href="/pdf/2403.00179" title="Download PDF">pdf</a>, <a href="/format/2403.00179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counterspeakers&#x27; Perspectives: Unveiling Barriers and AI Needs in the  Fight against Online Hate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mun%2C+J">Jimin Mun</a>, 
<a href="/search/cs?searchtype=author&query=Buerger%2C+C">Cathy Buerger</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J+T">Jenny T. Liang</a>, 
<a href="/search/cs?searchtype=author&query=Garland%2C+J">Joshua Garland</a>, 
<a href="/search/cs?searchtype=author&query=Sap%2C+M">Maarten Sap</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in CHI 2024. 22 pages, 3 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Counterspeech, i.e., direct responses against hate speech, has become an
important tool to address the increasing amount of hate online while avoiding
censorship. Although AI has been proposed to help scale up counterspeech
efforts, this raises questions of how exactly AI could assist in this process,
since counterspeech is a deeply empathetic and agentic process for those
involved. In this work, we aim to answer this question, by conducting in-depth
interviews with 10 extensively experienced counterspeakers and a large scale
public survey with 342 everyday social media users. In participant responses,
we identified four main types of barriers and AI needs related to resources,
training, impact, and personal harms. However, our results also revealed
overarching concerns of authenticity, agency, and functionality in using AI
tools for counterspeech. To conclude, we discuss considerations for designing
AI assistants that lower counterspeaking barriers without jeopardizing its
meaning and purpose.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00180" title="Abstract">arXiv:2403.00180</a> [<a href="/pdf/2403.00180" title="Download PDF">pdf</a>, <a href="/format/2403.00180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Flex Tape Can&#x27;t Fix That&quot;: Bias and Misinformation in Edited Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Halevy%2C+K">Karina Halevy</a>, 
<a href="/search/cs?searchtype=author&query=Sotnikova%2C+A">Anna Sotnikova</a>, 
<a href="/search/cs?searchtype=author&query=AlKhamissi%2C+B">Badr AlKhamissi</a>, 
<a href="/search/cs?searchtype=author&query=Montariol%2C+S">Syrielle Montariol</a>, 
<a href="/search/cs?searchtype=author&query=Bosselut%2C+A">Antoine Bosselut</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Model editing has emerged as a cost-effective strategy to update knowledge
stored in language models. However, model editing can have unintended
consequences after edits are applied: information unrelated to the edits can
also be changed, and other general behaviors of the model can be wrongly
altered. In this work, we investigate how model editing methods unexpectedly
amplify model biases post-edit. We introduce a novel benchmark dataset,
Seesaw-CF, for measuring bias-related harms of model editing and conduct the
first in-depth investigation of how different weight-editing methods impact
model bias. Specifically, we focus on biases with respect to demographic
attributes such as race, geographic origin, and gender, as well as qualitative
flaws in long-form texts generated by edited language models. We find that
edited models exhibit, to various degrees, more biased behavior as they become
less confident in attributes for Asian, African, and South American subjects.
Furthermore, edited models amplify sexism and xenophobia in text generations
while remaining seemingly coherent and logical. Finally, editing facts about
place of birth, country of citizenship, or gender have particularly negative
effects on the model's knowledge about unrelated features like field of work.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00187" title="Abstract">arXiv:2403.00187</a> [<a href="/pdf/2403.00187" title="Download PDF">pdf</a>, <a href="/format/2403.00187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to walk in confined spaces using 3D representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miki%2C+T">Takahiro Miki</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Joonho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Wellhausen%2C+L">Lorenz Wellhausen</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+M">Marco Hutter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Legged robots have the potential to traverse complex terrain and access
confined spaces beyond the reach of traditional platforms thanks to their
ability to carefully select footholds and flexibly adapt their body posture
while walking. However, robust deployment in real-world applications is still
an open challenge. In this paper, we present a method for legged locomotion
control using reinforcement learning and 3D volumetric representations to
enable robust and versatile locomotion in confined and unstructured
environments. By employing a two-layer hierarchical policy structure, we
exploit the capabilities of a highly robust low-level policy to follow 6D
commands and a high-level policy to enable three-dimensional spatial awareness
for navigating under overhanging obstacles. Our study includes the development
of a procedural terrain generator to create diverse training environments. We
present a series of experimental evaluations in both simulation and real-world
settings, demonstrating the effectiveness of our approach in controlling a
quadruped robot in confined, rough terrain. By achieving this, our work extends
the applicability of legged robots to a broader range of scenarios.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00188" title="Abstract">arXiv:2403.00188</a> [<a href="/pdf/2403.00188" title="Download PDF">pdf</a>, <a href="/ps/2403.00188" title="Download PostScript">ps</a>, <a href="/format/2403.00188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact of Decentralized Learning on Player Utilities in Stackelberg  Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Donahue%2C+K">Kate Donahue</a>, 
<a href="/search/cs?searchtype=author&query=Immorlica%2C+N">Nicole Immorlica</a>, 
<a href="/search/cs?searchtype=author&query=Jagadeesan%2C+M">Meena Jagadeesan</a>, 
<a href="/search/cs?searchtype=author&query=Lucier%2C+B">Brendan Lucier</a>, 
<a href="/search/cs?searchtype=author&query=Slivkins%2C+A">Aleksandrs Slivkins</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">When deployed in the world, a learning agent such as a recommender system or
a chatbot often repeatedly interacts with another learning agent (such as a
user) over time. In many such two-agent systems, each agent learns separately
and the rewards of the two agents are not perfectly aligned. To better
understand such cases, we examine the learning dynamics of the two-agent system
and the implications for each agent's objective. We model these systems as
Stackelberg games with decentralized learning and show that standard regret
benchmarks (such as Stackelberg equilibrium payoffs) result in worst-case
linear regret for at least one player. To better capture these systems, we
construct a relaxed regret benchmark that is tolerant to small learning errors
by agents. We show that standard learning algorithms fail to provide sublinear
regret, and we develop algorithms to achieve near-optimal $O(T^{2/3})$ regret
for both players with respect to these benchmarks. We further design relaxed
environments under which faster learning ($O(\sqrt{T})$) is possible.
Altogether, our results take a step towards assessing how two-agent
interactions in sequential and decentralized learning environments affect the
utility of both agents.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00189" title="Abstract">arXiv:2403.00189</a> [<a href="/pdf/2403.00189" title="Download PDF">pdf</a>, <a href="/ps/2403.00189" title="Download PostScript">ps</a>, <a href="/format/2403.00189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Road to Next-Generation Multiple Access: A 50-Year Tutorial Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+C">Chongjun Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zhiguo Ding</a>, 
<a href="/search/cs?searchtype=author&query=Schober%2C+R">Robert Schober</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages, 38 figures; Submitted to Proceedings of the IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The evolution of wireless communications has been significantly influenced by
remarkable advancements in multiple access (MA) technologies over the past five
decades, shaping the landscape of modern connectivity. Within this context, a
comprehensive tutorial review is presented, focusing on representative MA
techniques developed over the past 50 years. The following areas are explored:
i) The foundational principles and information-theoretic capacity limits of
power-domain non-orthogonal multiple access (NOMA) are characterized, along
with its extension to multiple-input multiple-output (MIMO)-NOMA. ii) Several
MA transmission schemes exploiting the spatial domain are investigated,
encompassing both conventional space-division multiple access (SDMA)/MIMO-NOMA
systems and near-field MA systems utilizing spherical-wave propagation models.
iii) The application of NOMA to integrated sensing and communications (ISAC)
systems is studied. This includes an introduction to typical NOMA-based
downlink/uplink ISAC frameworks, followed by an evaluation of their performance
limits using a mutual information (MI)-based analytical framework. iv) Major
issues and research opportunities associated with the integration of MA with
other emerging technologies are identified to facilitate MA in next-generation
networks, i.e., next-generation multiple access (NGMA). Throughout the paper,
promising directions are highlighted to inspire future research endeavors in
the realm of MA and NGMA.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00190" title="Abstract">arXiv:2403.00190</a> [<a href="/pdf/2403.00190" title="Download PDF">pdf</a>, <a href="/ps/2403.00190" title="Download PostScript">ps</a>, <a href="/format/2403.00190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identification of important nodes in the information propagation network  based on the artificial intelligence method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+B">Bin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+T">Tianbo Song</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jerry Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study presents an integrated approach for identifying key nodes in
information propagation networks using advanced artificial intelligence
methods. We introduce a novel technique that combines the Decision-making Trial
and Evaluation Laboratory (DEMATEL) method with the Global Structure Model
(GSM), creating a synergistic model that effectively captures both local and
global influences within a network. This method is applied across various
complex networks, such as social, transportation, and communication systems,
utilizing the Global Network Influence Dataset (GNID). Our analysis highlights
the structural dynamics and resilience of these networks, revealing insights
into node connectivity and community formation. The findings demonstrate the
effectiveness of our AI-based approach in offering a comprehensive
understanding of network behavior, contributing significantly to strategic
network analysis and optimization.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00192" title="Abstract">arXiv:2403.00192</a> [<a href="/pdf/2403.00192" title="Download PDF">pdf</a>, <a href="/format/2403.00192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Block-MDS QC-LDPC Codes for Information Reconciliation in Key  Distribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tauz%2C+L">Lev Tauz</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+D">Debarnab Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Shreekumar%2C+J">Jayanth Shreekumar</a>, 
<a href="/search/cs?searchtype=author&query=Sarihan%2C+M+C">Murat Can Sarihan</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+C+W">Chee Wei Wong</a>, 
<a href="/search/cs?searchtype=author&query=Dolecek%2C+L">Lara Dolecek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 1 figure, submitted to the International Symposium on Information Theory (ISIT) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Quantum key distribution (QKD) is a popular protocol that provides
information theoretically secure keys to multiple parties. Two important
post-processing steps of QKD are 1) the information reconciliation (IR) step,
where parties reconcile mismatches in generated keys through classical
communication, and 2) the privacy amplification (PA) step, where parties
distill their common key into a new secure key that the adversary has little to
no information about. In general, these two steps have been abstracted as two
distinct problems. In this work, we consider a new technique of performing the
IR and PA steps jointly through sampling that relaxes the requirement on the IR
step, allowing for more success in key creation. We provide a novel LDPC code
construction known as Block-MDS QC-LDPC codes that can utilize the relaxed
requirement by creating LDPC codes with pre-defined sub-matrices of full-rank.
We demonstrate through simulations that our technique of sampling can provide
notable gains in successfully creating secret keys.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00193" title="Abstract">arXiv:2403.00193</a> [<a href="/pdf/2403.00193" title="Download PDF">pdf</a>, <a href="/ps/2403.00193" title="Download PostScript">ps</a>, <a href="/format/2403.00193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structural Resilience and Connectivity of the IPv6 Internet: An AS-level  Topology Examination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+B">Bin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+T">Tianbo Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The study utilizes a comprehensive dataset informed by IPv6 routing
information to provide statistics, degree distribution, joint degree
distribution, and clustering analysis of the IPv6 Internet's structure and
resilience.The dataset includes 17,232 unique ASes and 10,000 unique IPv6
prefixes. Analysis reveals an interconnected network with an average path
length of approximately 3 hops, suggesting a robust and efficient network with
potential redundancy and resilience, despite some isolated components. The
paper outlines the degree distribution, indicating many peripheral nodes in a
sparse network, and a clustering analysis showing a tendency for ASes to form
clusters, which is indicative of redundancy and robustness against failures.
The connectivity analysis, including path redundancy and reachability, supports
the network's resilience.The findings are crucial for network design and
strategic planning, particularly as IPv6 adoption increases. The paper
emphasizes the importance of continuous monitoring and improvement of network
connectivity in the evolving Internet landscape, highlighting the IPv6
Internet's resilience and structured connectivity.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00194" title="Abstract">arXiv:2403.00194</a> [<a href="/pdf/2403.00194" title="Download PDF">pdf</a>, <a href="/format/2403.00194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ask Your Distribution Shift if Pre-Training is Right for You
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cohen-Wang%2C+B">Benjamin Cohen-Wang</a>, 
<a href="/search/cs?searchtype=author&query=Vendrow%2C+J">Joshua Vendrow</a>, 
<a href="/search/cs?searchtype=author&query=Madry%2C+A">Aleksander Madry</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Pre-training is a widely used approach to develop models that are robust to
distribution shifts. However, in practice, its effectiveness varies:
fine-tuning a pre-trained model improves robustness significantly in some cases
but not at all in others (compared to training from scratch). In this work, we
seek to characterize the failure modes that pre-training can and cannot
address. In particular, we focus on two possible failure modes of models under
distribution shift: poor extrapolation (e.g., they cannot generalize to a
different domain) and biases in the training data (e.g., they rely on spurious
features). Our study suggests that, as a rule of thumb, pre-training can help
mitigate poor extrapolation but not dataset biases. After providing theoretical
motivation and empirical evidence for this finding, we explore two of its
implications for developing robust models: (1) pre-training and interventions
designed to prevent exploiting biases have complementary robustness benefits,
and (2) fine-tuning on a (very) small, non-diverse but de-biased dataset can
result in significantly more robust models than fine-tuning on a large and
diverse but biased dataset. Code is available at
https://github.com/MadryLab/pretraining-distribution-shift-robustness.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00196" title="Abstract">arXiv:2403.00196</a> [<a href="/pdf/2403.00196" title="Download PDF">pdf</a>, <a href="/format/2403.00196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Find Missing Video Frames with Synthetic Data Augmentation:  A General Framework and Application in Generating Thermal Images Using RGB  Cameras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Andersen%2C+M+V">Mathias Viborg Andersen</a>, 
<a href="/search/cs?searchtype=author&query=Greer%2C+R">Ross Greer</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%B8gelmose%2C+A">Andreas M&#xf8;gelmose</a>, 
<a href="/search/cs?searchtype=author&query=Trivedi%2C+M">Mohan Trivedi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Advanced Driver Assistance Systems (ADAS) in intelligent vehicles rely on
accurate driver perception within the vehicle cabin, often leveraging a
combination of sensing modalities. However, these modalities operate at varying
rates, posing challenges for real-time, comprehensive driver state monitoring.
This paper addresses the issue of missing data due to sensor frame rate
mismatches, introducing a generative model approach to create synthetic yet
realistic thermal imagery. We propose using conditional generative adversarial
networks (cGANs), specifically comparing the pix2pix and CycleGAN
architectures. Experimental results demonstrate that pix2pix outperforms
CycleGAN, and utilizing multi-view input styles, especially stacked views,
enhances the accuracy of thermal image generation. Moreover, the study
evaluates the model's generalizability across different subjects, revealing the
importance of individualized training for optimal performance. The findings
suggest the potential of generative models in addressing missing frames,
advancing driver state monitoring for intelligent vehicles, and underscoring
the need for continued research in model generalization and customization.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00198" title="Abstract">arXiv:2403.00198</a> [<a href="/pdf/2403.00198" title="Download PDF">pdf</a>, <a href="/format/2403.00198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AXOLOTL: Fairness through Assisted Self-Debiasing of Large Language  Model Outputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ebrahimi%2C+S">Sana Ebrahimi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kaiwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Asudeh%2C+A">Abolfazl Asudeh</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+G">Gautam Das</a>, 
<a href="/search/cs?searchtype=author&query=Koudas%2C+N">Nick Koudas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Pre-trained Large Language Models (LLMs) have significantly advanced natural
language processing capabilities but are susceptible to biases present in their
training data, leading to unfair outcomes in various applications. While
numerous strategies have been proposed to mitigate bias, they often require
extensive computational resources and may compromise model performance. In this
work, we introduce AXOLOTL, a novel post-processing framework, which operates
agnostically across tasks and models, leveraging public APIs to interact with
LLMs without direct access to internal parameters. Through a three-step process
resembling zero-shot learning, AXOLOTL identifies biases, proposes resolutions,
and guides the model to self-debias its outputs. This approach minimizes
computational costs and preserves model performance, making AXOLOTL a promising
tool for debiasing LLM outputs with broad applicability and ease of use.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00199" title="Abstract">arXiv:2403.00199</a> [<a href="/pdf/2403.00199" title="Download PDF">pdf</a>, <a href="/format/2403.00199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Socratic Question Generation using Data Augmentation and  Preference Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+N+A">Nischal Ashok Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+A">Andrew Lan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">The Socratic method is a way of guiding students toward solving a problem
independently without directly revealing the solution to the problem. Although
this method has been shown to significantly improve student learning outcomes,
it remains a complex labor-intensive task for instructors. Large language
models (LLMs) can be used to augment human effort by automatically generating
Socratic questions for students. However, existing methods that involve
prompting these LLMs sometimes produce invalid outputs, e.g., those that
directly reveal the solution to the problem or provide irrelevant or premature
questions. To alleviate this problem, inspired by reinforcement learning with
AI feedback (RLAIF), we first propose a data augmentation method to enrich
existing Socratic questioning datasets with questions that are invalid in
specific ways. Next, we propose a method to optimize open-source LLMs such as
LLama 2 to prefer ground-truth questions over generated invalid ones, using
direct preference optimization (DPO). Our experiments on a Socratic questions
dataset for student code debugging show that a DPO-optimized 7B LLama 2 model
can effectively avoid generating invalid questions, and as a result,
outperforms existing state-of-the-art prompting methods.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00201" title="Abstract">arXiv:2403.00201</a> [<a href="/pdf/2403.00201" title="Download PDF">pdf</a>, <a href="/ps/2403.00201" title="Download PostScript">ps</a>, <a href="/format/2403.00201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constructive S4 modal logics with the finite birelational frame property
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balbiani%2C+P">Philippe Balbiani</a>, 
<a href="/search/cs?searchtype=author&query=Di%C3%A9guez%2C+M">Mart&#xed;n Di&#xe9;guez</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Duque%2C+D">David Fern&#xe1;ndez-Duque</a>, 
<a href="/search/cs?searchtype=author&query=McLean%2C+B">Brett McLean</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2104.15053">arXiv:2104.15053</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">The logics $\mathsf{CS4}$ and $\mathsf{IS4}$ are the two leading
intuitionistic variants of the modal logic $\mathsf{S4}$. Whether the finite
model property holds for each of these logics have been long-standing open
problems. It was recently shown that $\mathsf{IS4}$ has the finite frame
property and thus the finite model property. In this paper, we prove that
$\mathsf{CS4}$ also enjoys the finite frame property.
<br />Additionally, we investigate the following three logics closely related to
$\mathsf{IS4}$. The logic $\mathsf{GS4}$ is obtained by adding the
G\"odel--Dummett axiom to $\mathsf{IS4}$; it is both a superintuitionistic and
a fuzzy logic and has previously been given a real-valued semantics. We provide
an alternative birelational semantics and prove strong completeness with
respect to this semantics. The extension $\mathsf{GS4^c}$ of $\mathsf{GS4}$
corresponds to requiring a crisp accessibility relation on the real-valued
semantics. We give a birelational semantics corresponding to an extra
confluence condition on the $\mathsf{GS4}$ birelational semantics and prove
strong completeness. Neither of these two logics have the finite model property
with respect to their real-valued semantics, but we prove that they have the
finite frame property for their birelational semantics. Establishing the finite
birelational frame property immediately establishes decidability, which was
previously open for these two logics. Our proofs yield NEXPTIME upper bounds.
The logic $\mathsf{S4I}$ is obtained from $\mathsf{IS4}$ by reversing the roles
of the modal and intuitionistic relations in the birelational semantics. We
also prove the finite frame property, and thereby decidability, for
$\mathsf{S4I}$
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00206" title="Abstract">arXiv:2403.00206</a> [<a href="/pdf/2403.00206" title="Download PDF">pdf</a>, <a href="/ps/2403.00206" title="Download PostScript">ps</a>, <a href="/format/2403.00206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MaskLRF: Self-supervised Pretraining via Masked Autoencoding of Local  Reference Frames for Rotation-invariant 3D Point Set Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Furuya%2C+T">Takahiko Furuya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Following the successes in the fields of vision and language, self-supervised
pretraining via masked autoencoding of 3D point set data, or Masked Point
Modeling (MPM), has achieved state-of-the-art accuracy in various downstream
tasks. However, current MPM methods lack a property essential for 3D point set
analysis, namely, invariance against rotation of 3D objects/scenes. Existing
MPM methods are thus not necessarily suitable for real-world applications where
3D point sets may have inconsistent orientations. This paper develops, for the
first time, a rotation-invariant self-supervised pretraining framework for
practical 3D point set analysis. The proposed algorithm, called MaskLRF, learns
rotation-invariant and highly generalizable latent features via masked
autoencoding of 3D points within Local Reference Frames (LRFs), which are not
affected by rotation of 3D point sets. MaskLRF enhances the quality of latent
features by integrating feature refinement using relative pose encoding and
feature reconstruction using low-level but rich 3D geometry. The efficacy of
MaskLRF is validated via extensive experiments on diverse downstream tasks
including classification, segmentation, registration, and domain adaptation. I
confirm that MaskLRF achieves new state-of-the-art accuracies in analyzing 3D
point sets having inconsistent orientations. Code will be available at:
https://github.com/takahikof/MaskLRF
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00207" title="Abstract">arXiv:2403.00207</a> [<a href="/pdf/2403.00207" title="Download PDF">pdf</a>, <a href="/format/2403.00207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Yodel: A Layer 3.5 Name-Based Multicast Network Architecture For The  Future Internet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moghaddassian%2C+M">Morteza Moghaddassian</a>, 
<a href="/search/cs?searchtype=author&query=Leon-Garcia%2C+A">Alberto Leon-Garcia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Contains animated figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Multicasting refers to the ability of transmitting data to multiple
recipients without data sources needing to provide more than one copy of the
data to the network. The network takes responsibility to route and deliver a
copy of each data to every intended recipient. Multicasting has the potential
to improve the network efficiency and performance (e.g., throughput and
latency) through transferring fewer bits in communicating the same data to
multiple recipients compared with unicast transmissions, reduce the amount of
networking resources needed for communication, lower the network energy
footprint, and alleviate the occurrence of congestion in the network. Over the
past few decades, providing multicast services has been a real challenge for
ISPs, especially to support home users and multi-domain network applications,
leading to the emergence of complex application-level solutions. These
solutions like Content Delivery and Peer-to-Peer networks take advantage of
complex caching, routing, transport, and topology management systems which put
heavy strains on the underlying Internet infrastructures to offer multicasting
services. In reality, the main motivation behind the design of these systems is
rather sharing content than offering efficient multicast services. In this
paper, we propound Yodel, a name-based multicast network architecture that can
provide multi-domain multicast services for current and future Internet
applications. Compared to the wider array of other name-based network
architectures with clean-slate infrastructure requirements, Yodel is designed
to provide multicast services over the current Internet infrastructure. Hence,
Yodel puts forward several design goals that distinguish it from other
name-based network architectures with inherent multicast capabilities. This
paper is prepared to discuss the Yodel architecture, its design goals, and
architectural functions.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00209" title="Abstract">arXiv:2403.00209</a> [<a href="/pdf/2403.00209" title="Download PDF">pdf</a>, <a href="/format/2403.00209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChartReformer: Natural Language-Driven Chart Image Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+P">Pengyu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Bhosale%2C+M">Mahesh Bhosale</a>, 
<a href="/search/cs?searchtype=author&query=Lal%2C+J">Jay Lal</a>, 
<a href="/search/cs?searchtype=author&query=Adhikari%2C+B">Bikhyat Adhikari</a>, 
<a href="/search/cs?searchtype=author&query=Doermann%2C+D">David Doermann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Chart visualizations are essential for data interpretation and communication;
however, most charts are only accessible in image format and lack the
corresponding data tables and supplementary information, making it difficult to
alter their appearance for different application scenarios. To eliminate the
need for original underlying data and information to perform chart editing, we
propose ChartReformer, a natural language-driven chart image editing solution
that directly edits the charts from the input images with the given instruction
prompts. The key in this method is that we allow the model to comprehend the
chart and reason over the prompt to generate the corresponding underlying data
table and visual attributes for new charts, enabling precise edits.
Additionally, to generalize ChartReformer, we define and standardize various
types of chart editing, covering style, layout, format, and data-centric edits.
The experiments show promising results for the natural language-driven chart
image editing.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00211" title="Abstract">arXiv:2403.00211</a> [<a href="/pdf/2403.00211" title="Download PDF">pdf</a>, <a href="/format/2403.00211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trustworthy Self-Attention: Enabling the Network to Focus Only on the  Most Relevant References
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jing%2C+Y">Yu Jing</a>, 
<a href="/search/cs?searchtype=author&query=Yujuan%2C+T">Tan Yujuan</a>, 
<a href="/search/cs?searchtype=author&query=Ao%2C+R">Ren Ao</a>, 
<a href="/search/cs?searchtype=author&query=Duo%2C+L">Liu Duo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The prediction of optical flow for occluded points is still a difficult
problem that has not yet been solved. Recent methods use self-attention to find
relevant non-occluded points as references for estimating the optical flow of
occluded points based on the assumption of self-similarity. However, they rely
on visual features of a single image and weak constraints, which are not
sufficient to constrain the trained network to focus on erroneous and weakly
relevant reference points. We make full use of online occlusion recognition
information to construct occlusion extended visual features and two strong
constraints, allowing the network to learn to focus only on the most relevant
references without requiring occlusion ground truth to participate in the
training of the network. Our method adds very few network parameters to the
original framework, making it very lightweight. Extensive experiments show that
our model has the greatest cross-dataset generalization. Our method achieves
much greater error reduction, 18.6%, 16.2%, and 20.1% for all points,
non-occluded points, and occluded points respectively from the state-of-the-art
GMA-base method, MATCHFlow(GMA), on Sintel Albedo pass. Furthermore, our model
achieves state-of-the-art performance on the Sintel bench-marks, ranking \#1
among all published methods on Sintel clean pass. The code will be open-source.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00212" title="Abstract">arXiv:2403.00212</a> [<a href="/pdf/2403.00212" title="Download PDF">pdf</a>, <a href="/format/2403.00212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transcription and translation of videos using fine-tuned XLSR Wav2Vec2  on custom dataset and mBART
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tathe%2C+A">Aniket Tathe</a>, 
<a href="/search/cs?searchtype=author&query=Kamble%2C+A">Anand Kamble</a>, 
<a href="/search/cs?searchtype=author&query=Kumbharkar%2C+S">Suyash Kumbharkar</a>, 
<a href="/search/cs?searchtype=author&query=Bhandare%2C+A">Atharva Bhandare</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+A+C">Anirban C. Mitra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This research addresses the challenge of training an ASR model for
personalized voices with minimal data. Utilizing just 14 minutes of custom
audio from a YouTube video, we employ Retrieval-Based Voice Conversion (RVC) to
create a custom Common Voice 16.0 corpus. Subsequently, a Cross-lingual
Self-supervised Representations (XLSR) Wav2Vec2 model is fine-tuned on this
dataset. The developed web-based GUI efficiently transcribes and translates
input Hindi videos. By integrating XLSR Wav2Vec2 and mBART, the system aligns
the translated text with the video timeline, delivering an accessible solution
for multilingual video content transcription and translation for personalized
voice.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00219" title="Abstract">arXiv:2403.00219</a> [<a href="/pdf/2403.00219" title="Download PDF">pdf</a>, <a href="/format/2403.00219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-modal Attribute Prompting for Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiamin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianzhu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large pre-trained Vision-Language Models (VLMs), like CLIP, exhibit strong
generalization ability to downstream tasks but struggle in few-shot scenarios.
Existing prompting techniques primarily focus on global text and image
representations, yet overlooking multi-modal attribute characteristics. This
limitation hinders the model's ability to perceive fine-grained visual details
and restricts its generalization ability to a broader range of unseen classes.
To address this issue, we propose a Multi-modal Attribute Prompting method
(MAP) by jointly exploring textual attribute prompting, visual attribute
prompting, and attribute-level alignment. The proposed MAP enjoys several
merits. First, we introduce learnable visual attribute prompts enhanced by
textual attribute semantics to adaptively capture visual attributes for images
from unknown categories, boosting fine-grained visual perception capabilities
for CLIP. Second, the proposed attribute-level alignment complements the global
alignment to enhance the robustness of cross-modal alignment for
open-vocabulary objects. To our knowledge, this is the first work to establish
cross-modal attribute-level alignment for CLIP-based few-shot adaptation.
Extensive experimental results on 11 datasets demonstrate that our method
performs favorably against state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00221" title="Abstract">arXiv:2403.00221</a> [<a href="/pdf/2403.00221" title="Download PDF">pdf</a>, <a href="/ps/2403.00221" title="Download PostScript">ps</a>, <a href="/format/2403.00221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mode Consensus Algorithms With Finite Convergence Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Huang%2C+C">Chao Huang</a>, 
<a href="/search/eess?searchtype=author&query=Shim%2C+H">Hyungbo Shim</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+S">Siliang Yu</a>, 
<a href="/search/eess?searchtype=author&query=Anderson%2C+B+D+O">Brian D. O. Anderson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper studies the distributed mode consensus problem in a multi-agent
system, in which the agents each possess a certain attribute and they aim to
agree upon the mode (the most frequent attribute owned by the agents) via
distributed computation. Three algorithms are proposed. The first one directly
calculates the frequency of all attributes at every agent, with protocols based
on blended dynamics, and then returns the most frequent attribute as the mode.
Assuming knowledge at each agent of a lower bound of the mode frequency as a
priori information, the second algorithm is able to reduce the number of
frequencies to be computed at every agent if the lower bound is large. The
third algorithm further eliminates the need for this information by introducing
an adaptive updating mechanism. The algorithms find the mode in finite time,
and estimates of convergence time are provided. The proposed first and second
algorithms enjoy the plug-and-play property with a dwell time.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00222" title="Abstract">arXiv:2403.00222</a> [<a href="/pdf/2403.00222" title="Download PDF">pdf</a>, <a href="/format/2403.00222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Reinforcement Learning for Global Decision Making in the  Presence of Local Agents at Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anand%2C+E">Emile Anand</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+G">Guannan Qu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">We study reinforcement learning for global decision-making in the presence of
many local agents, where the global decision-maker makes decisions affecting
all local agents, and the objective is to learn a policy that maximizes the
rewards of both the global and the local agents. Such problems find many
applications, e.g. demand response, EV charging, queueing, etc. In this
setting, scalability has been a long-standing challenge due to the size of the
state/action space which can be exponential in the number of agents. This work
proposes the SUB-SAMPLE-Q algorithm where the global agent subsamples $k\leq n$
local agents to compute an optimal policy in time that is only exponential in
$k$, providing an exponential speedup from standard methods that are
exponential in $n$. We show that the learned policy converges to the optimal
policy in the order of $\tilde{O}(1/\sqrt{k}+\epsilon_{k,m})$ as the number of
sub-sampled agents $k$ increases, where $\epsilon_{k,m}$ is the Bellman noise.
We also conduct numerical simulations in a demand-response setting and a
queueing setting.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00225" title="Abstract">arXiv:2403.00225</a> [<a href="/pdf/2403.00225" title="Download PDF">pdf</a>, <a href="/format/2403.00225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Policy Learning via Offline Skill Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+W+K">Woo Kyung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+M">Minjong Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+H">Honguk Woo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Skill-based reinforcement learning (RL) approaches have shown considerable
promise, especially in solving long-horizon tasks via hierarchical structures.
These skills, learned task-agnostically from offline datasets, can accelerate
the policy learning process for new tasks. Yet, the application of these skills
in different domains remains restricted due to their inherent dependency on the
datasets, which poses a challenge when attempting to learn a skill-based policy
via RL for a target domain different from the datasets' domains. In this paper,
we present a novel offline skill learning framework DuSkill which employs a
guided Diffusion model to generate versatile skills extended from the limited
skills in datasets, thereby enhancing the robustness of policy learning for
tasks in different domains. Specifically, we devise a guided diffusion-based
skill decoder in conjunction with the hierarchical encoding to disentangle the
skill embedding space into two distinct representations, one for encapsulating
domain-invariant behaviors and the other for delineating the factors that
induce domain variations in the behaviors. Our DuSkill framework enhances the
diversity of skills learned offline, thus enabling to accelerate the learning
procedure of high-level policies for different domains. Through experiments, we
show that DuSkill outperforms other skill-based imitation learning and RL
algorithms for several long-horizon tasks, demonstrating its benefits in
few-shot imitation and online RL.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00226" title="Abstract">arXiv:2403.00226</a> [<a href="/pdf/2403.00226" title="Download PDF">pdf</a>, <a href="/format/2403.00226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Semantic Distance Metric Learning approach for Lexical Semantic Change  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aida%2C+T">Taichi Aida</a>, 
<a href="/search/cs?searchtype=author&query=Bollegala%2C+D">Danushka Bollegala</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Detecting temporal semantic changes of words is an important task for various
NLP applications that must make time-sensitive predictions. Lexical Semantic
Change Detection (SCD) task considers the problem of predicting whether a given
target word, $w$, changes its meaning between two different text corpora, $C_1$
and $C_2$. For this purpose, we propose a supervised two-staged SCD method that
uses existing Word-in-Context (WiC) datasets. In the first stage, for a target
word $w$, we learn two sense-aware encoder that represents the meaning of $w$
in a given sentence selected from a corpus. Next, in the second stage, we learn
a sense-aware distance metric that compares the semantic representations of a
target word across all of its occurrences in $C_1$ and $C_2$. Experimental
results on multiple benchmark datasets for SCD show that our proposed method
consistently outperforms all previously proposed SCD methods for multiple
languages, establishing a novel state-of-the-art for SCD. Interestingly, our
findings imply that there are specialised dimensions that carry information
related to semantic changes of words in the sense-aware embedding space. Source
code is available at https://github.com/a1da4/svp-sdml .
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00228" title="Abstract">arXiv:2403.00228</a> [<a href="/pdf/2403.00228" title="Download PDF">pdf</a>, <a href="/format/2403.00228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DISORF: A Distributed Online NeRF Training and Rendering Framework for  Mobile Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunlin Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+R">Ruofan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Hanrui Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhengen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Durvasula%2C+S">Sankeerth Durvasula</a>, 
<a href="/search/cs?searchtype=author&query=Vijaykumar%2C+N">Nandita Vijaykumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We present a framework, DISORF, to enable online 3D reconstruction and
visualization of scenes captured by resource-constrained mobile robots and edge
devices. To address the limited compute capabilities of edge devices and
potentially limited network availability, we design a framework that
efficiently distributes computation between the edge device and remote server.
We leverage on-device SLAM systems to generate posed keyframes and transmit
them to remote servers that can perform high quality 3D reconstruction and
visualization at runtime by leveraging NeRF models. We identify a key challenge
with online NeRF training where naive image sampling strategies can lead to
significant degradation in rendering quality. We propose a novel shifted
exponential frame sampling method that addresses this challenge for online NeRF
training. We demonstrate the effectiveness of our framework in enabling
high-quality real-time reconstruction and visualization of unknown scenes as
they are captured and streamed from cameras in mobile robots and edge devices.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00231" title="Abstract">arXiv:2403.00231</a> [<a href="/pdf/2403.00231" title="Download PDF">pdf</a>, <a href="/format/2403.00231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of  Large Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Runxin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xiachong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingpeng Kong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://mm-arxiv.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large vision-language models (LVLMs), exemplified by GPT-4V, excel across
diverse tasks involving concrete images from natural scenes. However, their
ability to interpret abstract figures, such as geometry shapes and scientific
plots, remains limited due to a scarcity of training datasets in scientific
domains. To fill this gap, we introduce Multimodal ArXiv, consisting of
ArXivCap and ArXivQA, for enhancing LVLMs scientific comprehension. ArXivCap is
a figure-caption dataset comprising 6.4M images and 3.9M captions sourced from
572K ArXiv papers spanning various scientific domains. Drawing from ArXivCap,
we introduce ArXivQA, a question-answering dataset generated by prompting
GPT-4V based on scientific figures. ArXivQA greatly enhances LVLMs'
mathematical reasoning capabilities, achieving a 10.4% absolute accuracy gain
on a multimodal mathematical reasoning benchmark. Furthermore, employing
ArXivCap, we devise four vision-to-text tasks for benchmarking LVLMs.
Evaluation results with state-of-the-art LVLMs underscore their struggle with
the nuanced semantics of academic figures, with domain-specific training
yielding substantial performance gains. Our error analysis uncovers
misinterpretations of visual context, recognition errors, and the production of
overly simplified captions by current LVLMs, shedding light on future
improvements.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00232" title="Abstract">arXiv:2403.00232</a> [<a href="/pdf/2403.00232" title="Download PDF">pdf</a>, <a href="/format/2403.00232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FTTN: Feature-Targeted Testing for Numerical Properties of NVIDIA &amp; AMD  Matrix Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Ang Li</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+B">Bo Fang</a>, 
<a href="/search/cs?searchtype=author&query=Swirydowicz%2C+K">Katarzyna Swirydowicz</a>, 
<a href="/search/cs?searchtype=author&query=Laguna%2C+I">Ignacio Laguna</a>, 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+G">Ganesh Gopalakrishnan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">NVIDIA Tensor Cores and AMD Matrix Cores (together called Matrix
Accelerators) are of growing interest in high-performance computing and machine
learning owing to their high performance. Unfortunately, their numerical
behaviors are not publicly documented, including the number of extra precision
bits maintained, the accumulation order of addition, and predictable subnormal
number handling during computations. This makes it impossible to reliably port
codes across these differing accelerators. This paper contributes a collection
of {\em Feature Targeted Tests for Numerical Properties} that that help
determine these features across five floating-point formats, four rounding
modes and additional that highlight the rounding behaviors and preservation of
extra precision bits. To show the practical relevance of FTTN, we design a
simple matrix-multiplication test designed with insights gathered from our
feature-tests. We executed this very simple test on five platforms, producing
different answers: V100, A100, and MI250X produced 0, MI100 produced 255.875,
and Hopper H100 produced 191.875. Our matrix multiplication tests employ
patterns found in iterative refinement-based algorithms, highlighting the need
to check for significant result variability when porting code across GPUs.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00236" title="Abstract">arXiv:2403.00236</a> [<a href="/pdf/2403.00236" title="Download PDF">pdf</a>, <a href="/format/2403.00236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking zero-shot stance detection with FlanT5-XXL: Insights from  training data, prompting, and decoding strategies into its near-SoTA  performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aiyappa%2C+R">Rachith Aiyappa</a>, 
<a href="/search/cs?searchtype=author&query=Senthilmani%2C+S">Shruthi Senthilmani</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+J">Jisun An</a>, 
<a href="/search/cs?searchtype=author&query=Kwak%2C+H">Haewoon Kwak</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+Y">Yong-Yeol Ahn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We investigate the performance of LLM-based zero-shot stance detection on
tweets. Using FlanT5-XXL, an instruction-tuned open-source LLM, with the
SemEval 2016 Tasks 6A, 6B, and P-Stance datasets, we study the performance and
its variations under different prompts and decoding strategies, as well as the
potential biases of the model. We show that the zero-shot approach can match or
outperform state-of-the-art benchmarks, including fine-tuned models. We provide
various insights into its performance including the sensitivity to instructions
and prompts, the decoding strategies, the perplexity of the prompts, and to
negations and oppositions present in prompts. Finally, we ensure that the LLM
has not been trained on test datasets, and identify a positivity bias which may
partially explain the performance differences across decoding strategie
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00239" title="Abstract">arXiv:2403.00239</a> [<a href="/pdf/2403.00239" title="Download PDF">pdf</a>, <a href="/format/2403.00239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OPAF: Optimized Secure Two-Party Computation Protocols for Nonlinear  Activation Functions in Recurrent Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Q">Qian Feng</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Z">Zhihua Xia</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhifeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+J">Jiasi Weng</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+J">Jian Weng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Deep neural network (DNN) typically involves convolutions, pooling, and
activation function. Due to the growing concern about privacy,
privacy-preserving DNN becomes a hot research topic. Generally, the convolution
and pooling operations can be supported by additive homomorphic and secure
comparison, but the secure implementation of activation functions is not so
straightforward for the requirements of accuracy and efficiency, especially for
the non-linear ones such as exponential, sigmoid, and tanh functions. This
paper pays a special attention to the implementation of such non-linear
functions in semi-honest model with two-party settings, for which SIRNN is the
current state-of-the-art. Different from previous works, we proposed improved
implementations for these functions by using their intrinsic features as well
as worthy tiny tricks. At first, we propose a novel and efficient protocol for
exponential function by using a divide-and-conquer strategy with most of the
computations executed locally. Exponential protocol is widely used in machine
learning tasks such as Poisson regression, and is also a key component of
sigmoid and tanh functions. Next, we take advantage of the symmetry of sigmoid
and Tanh, and fine-tune the inputs to reduce the 2PC building blocks, which
helps to save overhead and improve performance. As a result, we implement these
functions with fewer fundamental building blocks. The comprehensive evaluations
show that our protocols achieve state-of-the-art precision while reducing
run-time by approximately 57%, 44%, and 42% for exponential (with only negative
inputs), sigmoid, and Tanh functions, respectively.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00241" title="Abstract">arXiv:2403.00241</a> [<a href="/pdf/2403.00241" title="Download PDF">pdf</a>, <a href="/format/2403.00241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CASIMIR: A Corpus of Scientific Articles enhanced with Multiple  Author-Integrated Revisions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jourdan%2C+L">Leane Jourdan</a>, 
<a href="/search/cs?searchtype=author&query=Boudin%2C+F">Florian Boudin</a>, 
<a href="/search/cs?searchtype=author&query=Hernandez%2C+N">Nicolas Hernandez</a>, 
<a href="/search/cs?searchtype=author&query=Dufour%2C+R">Richard Dufour</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at LREC-Coling 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Writing a scientific article is a challenging task as it is a highly codified
and specific genre, consequently proficiency in written communication is
essential for effectively conveying research findings and ideas. In this
article, we propose an original textual resource on the revision step of the
writing process of scientific articles. This new dataset, called CASIMIR,
contains the multiple revised versions of 15,646 scientific articles from
OpenReview, along with their peer reviews. Pairs of consecutive versions of an
article are aligned at sentence-level while keeping paragraph location
information as metadata for supporting future revision studies at the discourse
level. Each pair of revised sentences is enriched with automatically extracted
edits and associated revision intention. To assess the initial quality on the
dataset, we conducted a qualitative study of several state-of-the-art text
revision approaches and compared various evaluation metrics. Our experiments
led us to question the relevance of the current evaluation methods for the text
revision task.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00245" title="Abstract">arXiv:2403.00245</a> [<a href="/pdf/2403.00245" title="Download PDF">pdf</a>, <a href="/format/2403.00245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YOLO-MED : Multi-Task Interaction Network for Biomedical Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Suizhi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sirejiding%2C+S">Shalayiding Sirejiding</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yuxiang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yue Ding</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Leheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hui Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hongtao Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Object detection and semantic segmentation are pivotal components in
biomedical image analysis. Current single-task networks exhibit promising
outcomes in both detection and segmentation tasks. Multi-task networks have
gained prominence due to their capability to simultaneously tackle segmentation
and detection tasks, while also accelerating the segmentation inference.
Nevertheless, recent multi-task networks confront distinct limitations such as
the difficulty in striking a balance between accuracy and inference speed.
Additionally, they often overlook the integration of cross-scale features,
which is especially important for biomedical image analysis. In this study, we
propose an efficient end-to-end multi-task network capable of concurrently
performing object detection and semantic segmentation called YOLO-Med. Our
model employs a backbone and a neck for multi-scale feature extraction,
complemented by the inclusion of two task-specific decoders. A cross-scale
task-interaction module is employed in order to facilitate information fusion
between various tasks. Our model exhibits promising results in balancing
accuracy and speed when evaluated on the Kvasir-seg dataset and a private
biomedical image dataset.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00246" title="Abstract">arXiv:2403.00246</a> [<a href="/pdf/2403.00246" title="Download PDF">pdf</a>, <a href="/ps/2403.00246" title="Download PostScript">ps</a>, <a href="/format/2403.00246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of Phylogeny Tracking Algorithms for Serial and Multiprocess  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moreno%2C+M+A">Matthew Andres Moreno</a>, 
<a href="/search/cs?searchtype=author&query=Papa%2C+S+R">Santiago Rodriguez Papa</a>, 
<a href="/search/cs?searchtype=author&query=Dolson%2C+E">Emily Dolson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Populations and Evolution (q-bio.PE)

</div>
<p class="mathjax">Since the advent of modern bioinformatics, the challenging, multifaceted
problem of reconstructing phylogenetic history from biological sequences has
hatched perennial statistical and algorithmic innovation. Studies of the
phylogenetic dynamics of digital, agent-based evolutionary models motivate a
peculiar converse question: how to best engineer tracking to facilitate fast,
accurate, and memory-efficient lineage reconstructions? Here, we formally
describe procedures for phylogenetic analysis in both serial and distributed
computing scenarios. With respect to the former, we demonstrate
reference-counting-based pruning of extinct lineages. For the latter, we
introduce a trie-based phylogenetic reconstruction approach for "hereditary
stratigraphy" genome annotations. This process allows phylogenetic
relationships between genomes to be inferred by comparing their similarities,
akin to reconstruction of natural history from biological DNA sequences.
Phylogenetic analysis capabilities significantly advance distributed
agent-based simulations as a tool for evolutionary research, and also benefit
application-oriented evolutionary computing. Such tracing could extend also to
other digital artifacts that p
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00249" title="Abstract">arXiv:2403.00249</a> [<a href="/pdf/2403.00249" title="Download PDF">pdf</a>, <a href="/format/2403.00249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantics-enhanced Cross-modal Masked Image Modeling for Vision-Language  Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haowei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yaya Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haiyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chunfeng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qinghao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Ming Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Ji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Weiming Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In vision-language pre-training (VLP), masked image modeling (MIM) has
recently been introduced for fine-grained cross-modal alignment. However, in
most existing methods, the reconstruction targets for MIM lack high-level
semantics, and text is not sufficiently involved in masked modeling. These two
drawbacks limit the effect of MIM in facilitating cross-modal semantic
alignment. In this work, we propose a semantics-enhanced cross-modal MIM
framework (SemMIM) for vision-language representation learning. Specifically,
to provide more semantically meaningful supervision for MIM, we propose a local
semantics enhancing approach, which harvest high-level semantics from global
image features via self-supervised agreement learning and transfer them to
local patch encodings by sharing the encoding space. Moreover, to achieve deep
involvement of text during the entire MIM process, we propose a text-guided
masking strategy and devise an efficient way of injecting textual information
in both masked modeling and reconstruction target acquisition. Experimental
results validate that our method improves the effectiveness of the MIM task in
facilitating cross-modal semantic alignment. Compared to previous VLP models
with similar model size and data scale, our SemMIM model achieves
state-of-the-art or competitive performance on multiple downstream
vision-language tasks.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00250" title="Abstract">arXiv:2403.00250</a> [<a href="/pdf/2403.00250" title="Download PDF">pdf</a>, <a href="/format/2403.00250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Classifier Re-Training in Long-Tailed Recognition: A Simple  Logits Retargeting Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Han Lu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Siyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yichen Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaokang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the long-tailed recognition field, the Decoupled Training paradigm has
demonstrated remarkable capabilities among various methods. This paradigm
decouples the training process into separate representation learning and
classifier re-training. Previous works have attempted to improve both stages
simultaneously, making it difficult to isolate the effect of classifier
re-training. Furthermore, recent empirical studies have demonstrated that
simple regularization can yield strong feature representations, emphasizing the
need to reassess existing classifier re-training methods. In this study, we
revisit classifier re-training methods based on a unified feature
representation and re-evaluate their performances. We propose a new metric
called Logits Magnitude as a superior measure of model performance, replacing
the commonly used Weight Norm. However, since it is hard to directly optimize
the new metric during training, we introduce a suitable approximate invariant
called Regularized Standard Deviation. Based on the two newly proposed metrics,
we prove that reducing the absolute value of Logits Magnitude when it is nearly
balanced can effectively decrease errors and disturbances during training,
leading to better model performance. Motivated by these findings, we develop a
simple logits retargeting approach (LORT) without the requirement of prior
knowledge of the number of samples per class. LORT divides the original one-hot
label into small true label probabilities and large negative label
probabilities distributed across each class. Our method achieves
state-of-the-art performance on various imbalanced datasets, including
CIFAR100-LT, ImageNet-LT, and iNaturalist2018.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00251" title="Abstract">arXiv:2403.00251</a> [<a href="/pdf/2403.00251" title="Download PDF">pdf</a>, <a href="/format/2403.00251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are your comments outdated? Towards automatically detecting code-comment  consistency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yinan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiangping Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaocong Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">In software development and maintenance, code comments can help developers
understand source code, and improve communication among developers. However,
developers sometimes neglect to update the corresponding comment when changing
the code, resulting in outdated comments (i.e., inconsistent codes and
comments). Outdated comments are dangerous and harmful and may mislead
subsequent developers. More seriously, the outdated comments may lead to a
fatal flaw sometime in the future. To automatically identify the outdated
comments in source code, we proposed a learning-based method, called CoCC, to
detect the consistency between code and comment. To efficiently identify
outdated comments, we extract multiple features from both codes and comments
before and after they change. Besides, we also consider the relation between
code and comment in our model. Experiment results show that CoCC can
effectively detect outdated comments with precision over 90%. In addition, we
have identified the 15 most important factors that cause outdated comments, and
verified the applicability of CoCC in different programming languages. We also
used CoCC to find outdated comments in the latest commits of open source
projects, which further proves the effectiveness of the proposed method.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00252" title="Abstract">arXiv:2403.00252</a> [<a href="/pdf/2403.00252" title="Download PDF">pdf</a>, <a href="/format/2403.00252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EUROPA: A Legal Multilingual Keyphrase Generation Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sala%C3%BCn%2C+O">Olivier Sala&#xfc;n</a>, 
<a href="/search/cs?searchtype=author&query=Piedboeuf%2C+F">Fr&#xe9;d&#xe9;ric Piedboeuf</a>, 
<a href="/search/cs?searchtype=author&query=Berre%2C+G+L">Guillaume Le Berre</a>, 
<a href="/search/cs?searchtype=author&query=Hermelo%2C+D+A">David Alfonso Hermelo</a>, 
<a href="/search/cs?searchtype=author&query=Langlais%2C+P">Philippe Langlais</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Keyphrase generation has primarily been explored within the context of
academic research articles, with a particular focus on scientific domains and
the English language. In this work, we present EUROPA, a dataset for
multilingual keyphrase generation in the legal domain. It is derived from legal
judgments from the Court of Justice of the European Union (EU), and contains
instances in all 24 EU official languages. We run multilingual models on our
corpus and analyze the results, showing room for improvement on a
domain-specific multilingual corpus such as the one we present.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00254" title="Abstract">arXiv:2403.00254</a> [<a href="/pdf/2403.00254" title="Download PDF">pdf</a>, <a href="/format/2403.00254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cloud-based Federated Learning Framework for MRI Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prajapati%2C+R">Rukesh Prajapati</a>, 
<a href="/search/cs?searchtype=author&query=El-Wakeel%2C+A+S">Amr S. El-Wakeel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In contemporary rural healthcare settings, the principal challenge in
diagnosing brain images is the scarcity of available data, given that most of
the existing deep learning models demand extensive training data to optimize
their performance, necessitating centralized processing methods that
potentially compromise data privacy. This paper proposes a novel framework
tailored for brain tissue segmentation in rural healthcare facilities. The
framework employs a deep reinforcement learning (DRL) environment in tandem
with a refinement model (RM) deployed locally at rural healthcare sites. The
proposed DRL model has a reduced parameter count and practicality for
implementation across distributed rural sites. To uphold data privacy and
enhance model generalization without transgressing privacy constraints, we
employ federated learning (FL) for cooperative model training. We demonstrate
the efficacy of our approach by training the network with a limited data set
and observing a substantial performance enhancement, mitigating inaccuracies
and irregularities in segmentation across diverse sites. Remarkably, the DRL
model attains an accuracy of up to 80%, surpassing the capabilities of
conventional convolutional neural networks when confronted with data
insufficiency. Incorporating our RM results in an additional accuracy
improvement of at least 10%, while FL contributes to a further accuracy
enhancement of up to 5%. Collectively, the framework achieves an average 92%
accuracy rate within rural healthcare settings characterized by data
constraints.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00255" title="Abstract">arXiv:2403.00255</a> [<a href="/pdf/2403.00255" title="Download PDF">pdf</a>, <a href="/format/2403.00255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Team Correlation for Approximating Equilibrium in Two-Team  Zero-Sum Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Naming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mingzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Youzhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yaodong Yang</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+B">Bo An</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Ying Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Two-team zero-sum games are one of the most important paradigms in game
theory. In this paper, we focus on finding an unexploitable equilibrium in
large team games. An unexploitable equilibrium is a worst-case policy, where
members in the opponent team cannot increase their team reward by taking any
policy, e.g., cooperatively changing to other joint policies. As an optimal
unexploitable equilibrium in two-team zero-sum games, correlated-team maxmin
equilibrium remains unexploitable even in the worst case where players in the
opponent team can achieve arbitrary cooperation through a joint team policy.
However, finding such an equilibrium in large games is challenging due to the
impracticality of evaluating the exponentially large number of joint policies.
To solve this problem, we first introduce a general solution concept called
restricted correlated-team maxmin equilibrium, which solves the problem of
being impossible to evaluate all joint policy by a sample factor while avoiding
an exploitation problem under the incomplete joint policy evaluation. We then
develop an efficient sequential correlation mechanism, and based on which we
propose an algorithm for approximating the unexploitable equilibrium in large
games. We show that our approach achieves lower exploitability than the
state-of-the-art baseline when encountering opponent teams with different
exploitation ability in large team games including Google Research Football.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00257" title="Abstract">arXiv:2403.00257</a> [<a href="/pdf/2403.00257" title="Download PDF">pdf</a>, <a href="/ps/2403.00257" title="Download PostScript">ps</a>, <a href="/format/2403.00257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust deep labeling of radiological emphysema subtypes using squeeze  and excitation convolutional neural networks: The MESA Lung and SPIROMICS  Studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wysoczanski%2C+A">Artur Wysoczanski</a>, 
<a href="/search/cs?searchtype=author&query=Ettehadi%2C+N">Nabil Ettehadi</a>, 
<a href="/search/cs?searchtype=author&query=Arabshahi%2C+S">Soroush Arabshahi</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yifei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Stukovsky%2C+K+H">Karen Hinkley Stukovsky</a>, 
<a href="/search/cs?searchtype=author&query=Watson%2C+K+E">Karol E. Watson</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+M+K">MeiLan K. Han</a>, 
<a href="/search/cs?searchtype=author&query=Michos%2C+E+D">Erin D Michos</a>, 
<a href="/search/cs?searchtype=author&query=Comellas%2C+A+P">Alejandro P. Comellas</a>, 
<a href="/search/cs?searchtype=author&query=Hoffman%2C+E+A">Eric A. Hoffman</a>, 
<a href="/search/cs?searchtype=author&query=Laine%2C+A+F">Andrew F. Laine</a>, 
<a href="/search/cs?searchtype=author&query=Barr%2C+R+G">R. Graham Barr</a>, 
<a href="/search/cs?searchtype=author&query=Angelini%2C+E+D">Elsa D. Angelini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Pulmonary emphysema, the progressive, irreversible loss of lung tissue, is
conventionally categorized into three subtypes identifiable on pathology and on
lung computed tomography (CT) images. Recent work has led to the unsupervised
learning of ten spatially-informed lung texture patterns (sLTPs) on lung CT,
representing distinct patterns of emphysematous lung parenchyma based on both
textural appearance and spatial location within the lung, and which aggregate
into 6 robust and reproducible CT Emphysema Subtypes (CTES). Existing methods
for sLTP segmentation, however, are slow and highly sensitive to changes in CT
acquisition protocol. In this work, we present a robust 3-D
squeeze-and-excitation CNN for supervised classification of sLTPs and CTES on
lung CT. Our results demonstrate that this model achieves accurate and
reproducible sLTP segmentation on lung CTscans, across two independent cohorts
and independently of scanner manufacturer and model.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00260" title="Abstract">arXiv:2403.00260</a> [<a href="/pdf/2403.00260" title="Download PDF">pdf</a>, <a href="/format/2403.00260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extracting Polymer Nanocomposite Samples from Full-Length Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khalighinejad%2C+G">Ghazal Khalighinejad</a>, 
<a href="/search/cs?searchtype=author&query=Circi%2C+D">Defne Circi</a>, 
<a href="/search/cs?searchtype=author&query=Brinson%2C+L+C">L.C. Brinson</a>, 
<a href="/search/cs?searchtype=author&query=Dhingra%2C+B">Bhuwan Dhingra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper investigates the use of large language models (LLMs) for
extracting sample lists of polymer nanocomposites (PNCs) from full-length
materials science research papers. The challenge lies in the complex nature of
PNC samples, which have numerous attributes scattered throughout the text. The
complexity of annotating detailed information on PNCs limits the availability
of data, making conventional document-level relation extraction techniques
impractical due to the challenge in creating comprehensive named entity span
annotations. To address this, we introduce a new benchmark and an evaluation
technique for this task and explore different prompting strategies in a
zero-shot manner. We also incorporate self-consistency to improve the
performance. Our findings show that even advanced LLMs struggle to extract all
of the samples from an article. Finally, we analyze the errors encountered in
this process, categorizing them into three main challenges, and discuss
potential strategies for future research to overcome them.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00261" title="Abstract">arXiv:2403.00261</a> [<a href="/pdf/2403.00261" title="Download PDF">pdf</a>, <a href="/format/2403.00261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial Cascaded Clustering and Weighted Memory for Unsupervised Person  Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Jiahao Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+J">Jialong Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Chuchu Han</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Ruochen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+M">Ming Tian</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Changxin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+N">Nong Sang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent unsupervised person re-identification (re-ID) methods achieve high
performance by leveraging fine-grained local context. These methods are
referred to as part-based methods. However, most part-based methods obtain
local contexts through horizontal division, which suffer from misalignment due
to various human poses. Additionally, the misalignment of semantic information
in part features restricts the use of metric learning, thus affecting the
effectiveness of part-based methods. The two issues mentioned above result in
the under-utilization of part features in part-based methods. We introduce the
Spatial Cascaded Clustering and Weighted Memory (SCWM) method to address these
challenges. SCWM aims to parse and align more accurate local contexts for
different human body parts while allowing the memory module to balance hard
example mining and noise suppression. Specifically, we first analyze the
foreground omissions and spatial confusions issues in the previous method.
Then, we propose foreground and space corrections to enhance the completeness
and reasonableness of the human parsing results. Next, we introduce a weighted
memory and utilize two weighting strategies. These strategies address hard
sample mining for global features and enhance noise resistance for part
features, which enables better utilization of both global and part features.
Extensive experiments on Market-1501 and MSMT17 validate the proposed method's
effectiveness over many state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00265" title="Abstract">arXiv:2403.00265</a> [<a href="/pdf/2403.00265" title="Download PDF">pdf</a>, <a href="/format/2403.00265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing for Harm Reduction: Communication Repair for Multicultural  Users&#x27; Voice Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wenzel%2C+K">Kimi Wenzel</a>, 
<a href="/search/cs?searchtype=author&query=Kaufman%2C+G">Geoff Kaufman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024 CHI Conference on Human Factors in Computing Systems (CHI '24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Voice assistants' inability to serve people-of-color and non-native English
speakers has largely been documented as a quality-of-service harm. However,
little work has investigated what downstream harms propagate from this poor
service. How does poor usability materially manifest and affect users' lives?
And what interaction designs might help users recover from these effects? We
identify 6 downstream harms that propagate from quality-of-service harms in
voice assistants. Through interviews and design activities with 16
multicultural participants, we unveil these 6 harms, outline how multicultural
users uniquely personify their voice assistant, and suggest how these harms and
personifications may affect their interactions. Lastly, we employ techniques
from psychology on communication repair to contribute suggestions for
harm-reducing repair that may be implemented in voice technologies. Our
communication repair strategies include: identity affirmations (intermittent
frequency), cultural sensitivity, and blame redirection. This work shows
potential for a harm-repair framework to positively influence voice
interactions.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00266" title="Abstract">arXiv:2403.00266</a> [<a href="/pdf/2403.00266" title="Download PDF">pdf</a>, <a href="/format/2403.00266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithms for Efficient, Compact Online Data Stream Curation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moreno%2C+M+A">Matthew Andres Moreno</a>, 
<a href="/search/cs?searchtype=author&query=Papa%2C+S+R">Santiago Rodriguez Papa</a>, 
<a href="/search/cs?searchtype=author&query=Dolson%2C+E">Emily Dolson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Data stream algorithms tackle operations on high-volume sequences of
read-once data items. Data stream scenarios include inherently real-time
systems like sensor networks and financial markets. They also arise in
purely-computational scenarios like ordered traversal of big data or
long-running iterative simulations. In this work, we develop methods to
maintain running archives of stream data that are temporally representative, a
task we call "stream curation." Our approach contributes to rich existing
literature on data stream binning, which we extend by providing stateless
(i.e., non-iterative) curation schemes that enable key optimizations to trim
archive storage overhead and streamline processing of incoming observations. We
also broaden support to cover new trade-offs between curated archive size and
temporal coverage. We present a suite of five stream curation algorithms that
span $\mathcal{O}(n)$, $\mathcal{O}(\log n)$, and $\mathcal{O}(1)$ orders of
growth for retained data items. Within each order of growth, algorithms are
provided to maintain even coverage across history or bias coverage toward more
recent time points. More broadly, memory-efficient stream curation can boost
the data stream mining capabilities of low-grade hardware in roles such as
sensor nodes and data logging devices.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00268" title="Abstract">arXiv:2403.00268</a> [<a href="/pdf/2403.00268" title="Download PDF">pdf</a>, <a href="/format/2403.00268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Acne Image Grading with Label Distribution Smoothing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prokhorov%2C+K">Kirill Prokhorov</a>, 
<a href="/search/cs?searchtype=author&query=Kalinin%2C+A+A">Alexandr A. Kalinin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE ISBI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Acne, a prevalent skin condition, necessitates precise severity assessment
for effective treatment. Acne severity grading typically involves lesion
counting and global assessment. However, manual grading suffers from
variability and inefficiency, highlighting the need for automated tools.
Recently, label distribution learning (LDL) was proposed as an effective
framework for acne image grading, but its effectiveness is hindered by severity
scales that assign varying numbers of lesions to different severity grades.
Addressing these limitations, we proposed to incorporate severity scale
information into lesion counting by combining LDL with label smoothing, and to
decouple if from global assessment. A novel weighting scheme in our approach
adjusts the degree of label smoothing based on the severity grading scale. This
method helped to effectively manage label uncertainty without compromising
class distinctiveness. Applied to the benchmark ACNE04 dataset, our model
demonstrated improved performance in automated acne grading, showcasing its
potential in enhancing acne diagnostics. The source code is publicly available
at <a href="http://github.com/openface-io/acne-lds.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00269" title="Abstract">arXiv:2403.00269</a> [<a href="/pdf/2403.00269" title="Download PDF">pdf</a>, <a href="/format/2403.00269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter-Efficient Tuning of Large Convolutional Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+Z">Zichen Miao</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Q">Qiang Qiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">To address the high computational and parameter complexity associated with
fine-tuning large pre-trained models, researchers have developed
parameter-efficient methods, where only partial parameters are updated for
downstream tasks. However, these works often overlook the distinct properties
of convolutional kernels, which still remain essential elements in many large
models, such as Stable Diffusion. In this study, we first introduce filter
subspace by decomposing convolutional kernels within each network layer over a
small set of filter subspace elements, referred to as filter atoms. We then
fine-tune these models to extract task-specific representation by only adapting
the filter atoms, a few hundred parameters typically. To potentially expand the
parameter space for tuning, we further show a simple approach to generate an
overcomplete filter subspace by recursively decomposing each filter atom over
another set of filter atoms. The fine-tuning of filter atoms reshapes the
filter subspace, enabling convolutional layers to adapt to diverse downstream
tasks efficiently. Extensive experiments show that such a simple scheme
surpasses previous tuning baselines for both discriminate and generative tasks.
Our approach can potentially be complementary to many existing fine-tuning
methods.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00270" title="Abstract">arXiv:2403.00270</a> [<a href="/pdf/2403.00270" title="Download PDF">pdf</a>, <a href="/format/2403.00270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Event-Driven Learning for Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wenjie Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Malu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jilin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Belatreche%2C+A">Ammar Belatreche</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jibin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zijing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xuerui Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haizhou Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Brain-inspired spiking neural networks (SNNs) have gained prominence in the
field of neuromorphic computing owing to their low energy consumption during
feedforward inference on neuromorphic hardware. However, it remains an open
challenge how to effectively benefit from the sparse event-driven property of
SNNs to minimize backpropagation learning costs. In this paper, we conduct a
comprehensive examination of the existing event-driven learning algorithms,
reveal their limitations, and propose novel solutions to overcome them.
Specifically, we introduce two novel event-driven learning methods: the
spike-timing-dependent event-driven (STD-ED) and membrane-potential-dependent
event-driven (MPD-ED) algorithms. These proposed algorithms leverage precise
neuronal spike timing and membrane potential, respectively, for effective
learning. The two methods are extensively evaluated on static and neuromorphic
datasets to confirm their superior performance. They outperform existing
event-driven counterparts by up to 2.51% for STD-ED and 6.79% for MPD-ED on the
CIFAR-100 dataset. In addition, we theoretically and experimentally validate
the energy efficiency of our methods on neuromorphic hardware. On-chip learning
experiments achieved a remarkable 30-fold reduction in energy consumption over
time-step-based surrogate gradient methods. The demonstrated efficiency and
efficacy of the proposed event-driven learning methods emphasize their
potential to significantly advance the fields of neuromorphic computing,
offering promising avenues for energy-efficiency applications.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00272" title="Abstract">arXiv:2403.00272</a> [<a href="/pdf/2403.00272" title="Download PDF">pdf</a>, <a href="/format/2403.00272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual Pose-invariant Embeddings: Learning Category and Object-specific  Discriminative Representations for Recognition and Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+R">Rohan Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Kak%2C+A">Avinash Kak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the context of pose-invariant object recognition and retrieval, we
demonstrate that it is possible to achieve significant improvements in
performance if both the category-based and the object-identity-based embeddings
are learned simultaneously during training. In hindsight, that sounds intuitive
because learning about the categories is more fundamental than learning about
the individual objects that correspond to those categories. However, to the
best of what we know, no prior work in pose-invariant learning has demonstrated
this effect. This paper presents an attention-based dual-encoder architecture
with specially designed loss functions that optimize the inter- and intra-class
distances simultaneously in two different embedding spaces, one for the
category embeddings and the other for the object-level embeddings. The loss
functions we have proposed are pose-invariant ranking losses that are designed
to minimize the intra-class distances and maximize the inter-class distances in
the dual representation spaces. We demonstrate the power of our approach with
three challenging multi-view datasets, ModelNet-40, ObjectPI, and FG3D. With
our dual approach, for single-view object recognition, we outperform the
previous best by 20.0% on ModelNet40, 2.0% on ObjectPI, and 46.5% on FG3D. On
the other hand, for single-view object retrieval, we outperform the previous
best by 33.7% on ModelNet40, 18.8% on ObjectPI, and 56.9% on FG3D.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00273" title="Abstract">arXiv:2403.00273</a> [<a href="/pdf/2403.00273" title="Download PDF">pdf</a>, <a href="/format/2403.00273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ARED: Argentina Real Estate Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belenky%2C+I">Iv&#xe1;n Belenky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Digital Libraries (cs.DL); Statistical Finance (q-fin.ST)

</div>
<p class="mathjax">The Argentinian real estate market presents a unique case study characterized
by its unstable and rapidly shifting macroeconomic circumstances over the past
decades. Despite the existence of a few datasets for price prediction, there is
a lack of mixed modality datasets specifically focused on Argentina. In this
paper, the first edition of ARED is introduced. A comprehensive real estate
price prediction dataset series, designed for the Argentinian market. This
edition contains information solely for Jan-Feb 2024. It was found that despite
the short time range captured by this zeroth edition (44 days), time dependent
phenomena has been occurring mostly on a market level (market as a whole).
Nevertheless future editions of this dataset, will most likely contain
historical data. Each listing in ARED comprises descriptive features, and
variable-length sets of images.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00274" title="Abstract">arXiv:2403.00274</a> [<a href="/pdf/2403.00274" title="Download PDF">pdf</a>, <a href="/format/2403.00274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CustomListener: Text-guided Responsive Interaction for User-friendly  Listening Head Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Ying Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhen%2C+C">Cheng Zhen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tong Li</a>, 
<a href="/search/cs?searchtype=author&query=Ao%2C+Y">Yingying Ao</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+P">Pengfei Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Listening head generation aims to synthesize a non-verbal responsive listener
head by modeling the correlation between the speaker and the listener in
dynamic conversion.The applications of listener agent generation in virtual
interaction have promoted many works achieving the diverse and fine-grained
motion generation. However, they can only manipulate motions through simple
emotional labels, but cannot freely control the listener's motions. Since
listener agents should have human-like attributes (e.g. identity, personality)
which can be freely customized by users, this limits their realism. In this
paper, we propose a user-friendly framework called CustomListener to realize
the free-form text prior guided listener generation. To achieve
speaker-listener coordination, we design a Static to Dynamic Portrait module
(SDP), which interacts with speaker information to transform static text into
dynamic portrait token with completion rhythm and amplitude information. To
achieve coherence between segments, we design a Past Guided Generation Module
(PGG) to maintain the consistency of customized listener attributes through the
motion prior, and utilize a diffusion-based structure conditioned on the
portrait token and the motion prior to realize the controllable generation. To
train and evaluate our model, we have constructed two text-annotated listening
head datasets based on ViCo and RealTalk, which provide text-video paired
labels. Extensive experiments have verified the effectiveness of our model.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00276" title="Abstract">arXiv:2403.00276</a> [<a href="/pdf/2403.00276" title="Download PDF">pdf</a>, <a href="/format/2403.00276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Construction with Flexible Nodes for Traffic Demand Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Jinyan Hou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Haotong Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph neural networks (GNNs) have been widely applied in traffic demand
prediction, and transportation modes can be divided into station-based mode and
free-floating traffic mode. Existing research in traffic graph construction
primarily relies on map matching to construct graphs based on the road network.
However, the complexity and inhomogeneity of data distribution in free-floating
traffic demand forecasting make road network matching inflexible. To tackle
these challenges, this paper introduces a novel graph construction method
tailored to free-floating traffic mode. We propose a novel density-based
clustering algorithm (HDPC-L) to determine the flexible positioning of nodes in
the graph, overcoming the computational bottlenecks of traditional clustering
algorithms and enabling effective handling of large-scale datasets.
Furthermore, we extract valuable information from ridership data to initialize
the edge weights of GNNs. Comprehensive experiments on two real-world datasets,
the Shenzhen bike-sharing dataset and the Haikou ride-hailing dataset, show
that the method significantly improves the performance of the model. On
average, our models show an improvement in accuracy of around 25\% and 19.5\%
on the two datasets. Additionally, it significantly enhances computational
efficiency, reducing training time by approximately 12% and 32.5% on the two
datasets. We make our code available at
https://github.com/houjinyan/HDPC-L-ODInit.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00277" title="Abstract">arXiv:2403.00277</a> [<a href="/pdf/2403.00277" title="Download PDF">pdf</a>, <a href="/format/2403.00277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gender Bias in Large Language Models across Multiple Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jinman Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yitian Ding</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+C">Chen Jia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yining Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Z">Zifan Qian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 27 tables, 7 figures, submitted to ACL2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the growing deployment of large language models (LLMs) across various
applications, assessing the influence of gender biases embedded in LLMs becomes
crucial. The topic of gender bias within the realm of natural language
processing (NLP) has gained considerable focus, particularly in the context of
English. Nonetheless, the investigation of gender bias in languages other than
English is still relatively under-explored and insufficiently analyzed. In this
work, We examine gender bias in LLMs-generated outputs for different languages.
We use three measurements: 1) gender bias in selecting descriptive words given
the gender-related context. 2) gender bias in selecting gender-related pronouns
(she/he) given the descriptive words. 3) gender bias in the topics of
LLM-generated dialogues. We investigate the outputs of the GPT series of LLMs
in various languages using our three measurement methods. Our findings revealed
significant gender biases across all the languages we examined.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00278" title="Abstract">arXiv:2403.00278</a> [<a href="/pdf/2403.00278" title="Download PDF">pdf</a>, <a href="/format/2403.00278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shifted Interpolation for Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bok%2C+J">Jinho Bok</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+W">Weijie Su</a>, 
<a href="/search/cs?searchtype=author&query=Altschuler%2C+J+M">Jason M. Altschuler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Optimization and Control (math.OC); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">Noisy gradient descent and its variants are the predominant algorithms for
differentially private machine learning. It is a fundamental question to
quantify their privacy leakage, yet tight characterizations remain open even in
the foundational setting of convex losses. This paper improves over previous
analyses by establishing (and refining) the "privacy amplification by
iteration" phenomenon in the unifying framework of $f$-differential
privacy--which tightly captures all aspects of the privacy loss and immediately
implies tighter privacy accounting in other notions of differential privacy,
e.g., $(\varepsilon,\delta)$-DP and Renyi DP. Our key technical insight is the
construction of shifted interpolated processes that unravel the popular
shifted-divergences argument, enabling generalizations beyond divergence-based
relaxations of DP. Notably, this leads to the first exact privacy analysis in
the foundational setting of strongly convex optimization. Our techniques extend
to many settings: convex/strongly convex, constrained/unconstrained,
full/cyclic/stochastic batches, and all combinations thereof. As an immediate
corollary, we recover the $f$-DP characterization of the exponential mechanism
for strongly convex optimization in Gopi et al. (2022), and moreover extend
this result to more general settings.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00280" title="Abstract">arXiv:2403.00280</a> [<a href="/pdf/2403.00280" title="Download PDF">pdf</a>, <a href="/ps/2403.00280" title="Download PostScript">ps</a>, <a href="/format/2403.00280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoK: Security of Programmable Logic Controllers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez-Morales%2C+E">Efr&#xe9;n L&#xf3;pez-Morales</a> (Texas A&amp;M University-Corpus Christi), 
<a href="/search/cs?searchtype=author&query=Planta%2C+U">Ulysse Planta</a> (CISPA Helmholtz Center for Information Security), 
<a href="/search/cs?searchtype=author&query=Rubio-Medrano%2C+C">Carlos Rubio-Medrano</a> (Texas A&amp;M University-Corpus Christi), 
<a href="/search/cs?searchtype=author&query=Abbasi%2C+A">Ali Abbasi</a> (CISPA Helmholtz Center for Information Security), 
<a href="/search/cs?searchtype=author&query=Cardenas%2C+A+A">Alvaro A. Cardenas</a> (University of California, Santa Cruz)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 13 figures, Extended version February 2024, A shortened version is to be published in the 33rd USENIX Security Symposium, for more information, see <a href="https://efrenlopez.org/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Billions of people rely on essential utility and manufacturing
infrastructures such as water treatment plants, energy management, and food
production. Our dependence on reliable infrastructures makes them valuable
targets for cyberattacks. One of the prime targets for adversaries attacking
physical infrastructures are Programmable Logic Controllers (PLCs) because they
connect the cyber and physical worlds. In this study, we conduct the first
comprehensive systematization of knowledge that explores the security of PLCs:
We present an in-depth analysis of PLC attacks and defenses and discover trends
in the security of PLCs from the last 17 years of research. We introduce a
novel threat taxonomy for PLCs and Industrial Control Systems (ICS). Finally,
we identify and point out research gaps that, if left ignored, could lead to
new catastrophic attacks against critical infrastructures.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00282" title="Abstract">arXiv:2403.00282</a> [<a href="/pdf/2403.00282" title="Download PDF">pdf</a>, <a href="/format/2403.00282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scale-Invariant Gradient Aggregation for Constrained Multi-Objective  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dohyeong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+M">Mineui Hong</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jeongho Park</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+S">Songhwai Oh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Multi-objective reinforcement learning (MORL) aims to find a set of Pareto
optimal policies to cover various preferences. However, to apply MORL in
real-world applications, it is important to find policies that are not only
Pareto optimal but also satisfy pre-defined constraints for safety. To this
end, we propose a constrained MORL (CMORL) algorithm called Constrained
Multi-Objective Gradient Aggregator (CoMOGA). Recognizing the difficulty of
handling multiple objectives and constraints concurrently, CoMOGA relaxes the
original CMORL problem into a constrained optimization problem by transforming
the objectives into additional constraints. This novel transformation process
ensures that the converted constraints are invariant to the objective scales
while having the same effect as the original objectives. We show that the
proposed method converges to a local Pareto optimal policy while satisfying the
predefined constraints. Empirical evaluations across various tasks show that
the proposed method outperforms other baselines by consistently meeting
constraints and demonstrating invariance to the objective scales.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00284" title="Abstract">arXiv:2403.00284</a> [<a href="/pdf/2403.00284" title="Download PDF">pdf</a>, <a href="/format/2403.00284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Route Recommendations: Methods, Applications, and  Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhipeng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Li Yang</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+F">Fei Teng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianrui Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Nowadays, with advanced information technologies deployed citywide, large
data volumes and powerful computational resources are intelligentizing modern
city development. As an important part of intelligent transportation, route
recommendation and its applications are widely used, directly influencing
citizens` travel habits. Developing smart and efficient travel routes based on
big data (possibly multi-modal) has become a central challenge in route
recommendation research. Our survey offers a comprehensive review of route
recommendation work based on urban computing. It is organized by the following
three parts: 1) Methodology-wise. We categorize a large volume of traditional
machine learning and modern deep learning methods. Also, we discuss their
historical relations and reveal the edge-cutting progress. 2)
Application\-wise. We present numerous novel applications related to route
commendation within urban computing scenarios. 3) We discuss current problems
and challenges and envision several promising research directions. We believe
that this survey can help relevant researchers quickly familiarize themselves
with the current state of route recommendation research and then direct them to
future research trends.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00290" title="Abstract">arXiv:2403.00290</a> [<a href="/pdf/2403.00290" title="Download PDF">pdf</a>, <a href="/ps/2403.00290" title="Download PostScript">ps</a>, <a href="/format/2403.00290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Text Transmission via Prediction with Small Language Models:  Cost-Similarity Trade-off
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madhabhavi%2C+B+A">Bhavani A Madhabhavi</a>, 
<a href="/search/cs?searchtype=author&query=Karevvanavar%2C+G">Gangadhar Karevvanavar</a>, 
<a href="/search/cs?searchtype=author&query=Bhat%2C+R+V">Rajshekhar V Bhat</a>, 
<a href="/search/cs?searchtype=author&query=Pappas%2C+N">Nikolaos Pappas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We consider the communication of natural language text from a source to a
destination over noiseless and character-erasure channels. We exploit
language's inherent correlations and predictability to constrain transmission
costs by allowing the destination to predict or complete words with potential
dissimilarity with the source text. Concretely, our objective is to obtain
achievable $(\bar{c}, \bar{s})$ pairs, where $\bar{c}$ is the average
transmission cost at the source and $\bar{s}$ is the average semantic
similarity measured via cosine similarity between vector embedding of words at
the source and those predicted/completed at the destination. We obtain
$(\bar{c}, \bar{s})$ pairs for neural language and first-order Markov
chain-based small language models (SLM) for prediction, using both a threshold
policy that transmits a word if its cosine similarity with that
predicted/completed at the destination is below a threshold, and a periodic
policy, which transmits words after a specific interval and predicts/completes
the words in between, at the destination. We adopt an SLM for word completion.
We demonstrate that, when communication occurs over a noiseless channel, the
threshold policy achieves a higher $\bar{s}$ for a given $\bar{c}$ than the
periodic policy and that the $\bar{s}$ achieved with the neural SLM is greater
than or equal to that of the Markov chain-based algorithm for the same
$\bar{c}$. The improved performance comes with a higher complexity in terms of
time and computing requirements. However, when communication occurs over a
character-erasure channel, all prediction algorithms and scheduling policies
perform poorly. Furthermore, if character-level Huffman coding is used, the
required $\bar{c}$ to achieve a given $\bar{s}$ is reduced, but the above
observations still apply.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00292" title="Abstract">arXiv:2403.00292</a> [<a href="/pdf/2403.00292" title="Download PDF">pdf</a>, <a href="/format/2403.00292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DPP-Based Adversarial Prompt Searching for Lanugage Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xiaojun Wan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Language models risk generating mindless and offensive content, which hinders
their safe deployment. Therefore, it is crucial to discover and modify
potential toxic outputs of pre-trained language models before deployment. In
this work, we elicit toxic content by automatically searching for a prompt that
directs pre-trained language models towards the generation of a specific target
output. The problem is challenging due to the discrete nature of textual data
and the considerable computational resources required for a single forward pass
of the language model. To combat these challenges, we introduce Auto-regressive
Selective Replacement Ascent (ASRA), a discrete optimization algorithm that
selects prompts based on both quality and similarity with determinantal point
process (DPP). Experimental results on six different pre-trained language
models demonstrate the efficacy of ASRA for eliciting toxic content.
Furthermore, our analysis reveals a strong correlation between the success rate
of ASRA attacks and the perplexity of target outputs, while indicating limited
association with the quantity of model parameters.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00294" title="Abstract">arXiv:2403.00294</a> [<a href="/pdf/2403.00294" title="Download PDF">pdf</a>, <a href="/format/2403.00294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Gradually Reinforced Sample-Average-Approximation Differentiable  Homotopy Method for a System of Stochastic Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+P">Peixuan Li</a>, 
<a href="/search/math?searchtype=author&query=Dang%2C+C">Chuangyin Dang</a>, 
<a href="/search/math?searchtype=author&query=Zhan%2C+Y">Yang Zhan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper intends to apply the sample-average-approximation (SAA) scheme to
solve a system of stochastic equations (SSE), which has many applications in a
variety of fields. The SAA is an effective paradigm to address risks and
uncertainty in stochastic models from the perspective of Monte Carlo principle.
Nonetheless, a numerical conflict arises from the sample size of SAA when one
has to make a tradeoff between the accuracy of solutions and the computational
cost. To alleviate this issue, we incorporate a gradually reinforced SAA scheme
into a differentiable homotopy method and develop a gradually reinforced
sample-average-approximation (GRSAA) differentiable homotopy method in this
paper. By introducing a series of continuously differentiable functions of the
homotopy parameter $t$ ranging between zero and one, we establish a
differentiable homotopy system, which is able to gradually increase the sample
size of SAA as $t$ descends from one to zero. The set of solutions to the
homotopy system contains an everywhere smooth path, which starts from an
arbitrary point and ends at a solution to the SAA with any desired accuracy.
The GRSAA differentiable homotopy method serves as a bridge to link the
gradually reinforced SAA scheme and a differentiable homotopy method and
retains the nice property of global convergence the homotopy method possesses
while greatly reducing the computational cost for attaining a desired solution
to the original SSE. Several numerical experiments further confirm the
effectiveness and efficiency of the proposed method.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00299" title="Abstract">arXiv:2403.00299</a> [<a href="/pdf/2403.00299" title="Download PDF">pdf</a>, <a href="/ps/2403.00299" title="Download PostScript">ps</a>, <a href="/format/2403.00299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Auto-encoder Framework for MIMO CSI Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=So%2C+J">Jinhyun So</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+H">Hyukjoon Kwon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Existing auto-encoder (AE)-based channel state information (CSI) frameworks
have focused on a specific configuration of user equipment (UE) and base
station (BS), and thus the input and output sizes of the AE are fixed. However,
in the real-world scenario, the input and output sizes may vary depending on
the number of antennas of the BS and UE and the allocated resource block in the
frequency dimension. A naive approach to support the different input and output
sizes is to use multiple AE models, which is impractical for the UE due to the
limited HW resources. In this paper, we propose a universal AE framework that
can support different input sizes and multiple compression ratios. The proposed
AE framework significantly reduces the HW complexity while providing comparable
performance in terms of compression ratio-distortion trade-off compared to the
naive and state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00300" title="Abstract">arXiv:2403.00300</a> [<a href="/pdf/2403.00300" title="Download PDF">pdf</a>, <a href="/format/2403.00300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Base Complex: Extract and Visualize Structure of Hex-dominant  Meshes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Si%2C+L">Lei Si</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Haowei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guoning Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by IEEE Transactions on Visualization and Computer Graphics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">Hex-dominant mesh generation has received significant attention in recent
research due to its superior robustness compared to pure hex-mesh generation
techniques. In this work, we introduce the first structure for analyzing
hex-dominant meshes. This structure builds on the base complex of pure
hex-meshes but incorporates the non-hex elements for a more comprehensive and
complete representation. We provide its definition and describe its
construction steps. Based on this structure, we present an extraction and
categorization of sheets using advanced graph matching techniques to handle the
non-hex elements. This enables us to develop an enhanced visual analysis of the
structure for any hex-dominant meshes.We apply this structure-based visual
analysis to compare hex-dominant meshes generated by different methods to study
their advantages and disadvantages. This complements the standard quality
metric based on the non-hex element percentage for hex-dominant meshes.
Moreover, we propose a strategy to extract a cleaned (optimized) valence-based
singularity graph wireframe to analyze the structure for both mesh and sheets.
Our results demonstrate that the proposed hybrid base complex provides a coarse
representation for mesh element, and the proposed valence singularity graph
wireframe provides a better internal visualization of hex-dominant meshes.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00303" title="Abstract">arXiv:2403.00303</a> [<a href="/pdf/2403.00303" title="Download PDF">pdf</a>, <a href="/format/2403.00303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ODM: A Text-Image Further Alignment Pre-training Approach for Scene Text  Detection and Spotting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+C">Chen Duan</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+P">Pei Fu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Shan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Q">Qianyi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiaoming Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, text-image joint pre-training techniques have shown
promising results in various tasks. However, in Optical Character Recognition
(OCR) tasks, aligning text instances with their corresponding text regions in
images poses a challenge, as it requires effective alignment between text and
OCR-Text (referring to the text in images as OCR-Text to distinguish from the
text in natural language) rather than a holistic understanding of the overall
image content. In this paper, we propose a new pre-training method called
OCR-Text Destylization Modeling (ODM) that transfers diverse styles of text
found in images to a uniform style based on the text prompt. With ODM, we
achieve better alignment between text and OCR-Text and enable pre-trained
models to adapt to the complex and diverse styles of scene text detection and
spotting tasks. Additionally, we have designed a new labeling generation method
specifically for ODM and combined it with our proposed Text-Controller module
to address the challenge of annotation costs in OCR tasks, allowing a larger
amount of unlabeled data to participate in pre-training. Extensive experiments
on multiple public datasets demonstrate that our method significantly improves
performance and outperforms current pre-training methods in scene text
detection and spotting tasks. Code is available at
{https://github.com/PriNing/ODM}.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00306" title="Abstract">arXiv:2403.00306</a> [<a href="/pdf/2403.00306" title="Download PDF">pdf</a>, <a href="/format/2403.00306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> qPMS Sigma -- An Efficient and Exact Parallel Algorithm for the Planted  $(l, d)$ Motif Search Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhar%2C+S">Saurav Dhar</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+A">Amlan Saha</a>, 
<a href="/search/cs?searchtype=author&query=Goswami%2C+D">Dhiman Goswami</a>, 
<a href="/search/cs?searchtype=author&query=Mia%2C+M+A+K">Md. Abul Kashem Mia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Motif finding is an important step for the detection of rare events occurring
in a set of DNA or protein sequences. Extraction of information about these
rare events can lead to new biological discoveries. Motifs are some important
patterns that have numerous applications including the identification of
transcription factors and their binding sites, composite regulatory patterns,
similarity between families of proteins, etc. Although several flavors of motif
searching algorithms have been studied in the literature, we study the version
known as $ (l, d) $-motif search or Planted Motif Search (PMS). In PMS, given
two integers $ l $, $ d $ and $ n $ input sequences we try to find all the
patterns of length $ l $ that appear in each of the $ n $ input sequences with
at most $ d $ mismatches. We also discuss the quorum version of PMS in our work
that finds motifs that are not planted in all the input sequences but at least
in $ q $ of the sequences. Our algorithm is mainly based on the algorithms
qPMSPrune, qPMS7, TraverStringRef and PMS8. We introduce some techniques to
compress the input strings and make faster comparison between strings with
bitwise operations. Our algorithm performs a little better than the existing
exact algorithms to solve the qPMS problem in DNA sequence. We have also
proposed an idea for parallel implementation of our algorithm.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00307" title="Abstract">arXiv:2403.00307</a> [<a href="/pdf/2403.00307" title="Download PDF">pdf</a>, <a href="/format/2403.00307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embedded Multi-label Feature Selection via Orthogonal Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xueyuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Fulin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+T">Tianyuan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+L">Li Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+F">Feiping Nie</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xia Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the last decade, embedded multi-label feature selection methods,
incorporating the search for feature subsets into model optimization, have
attracted considerable attention in accurately evaluating the importance of
features in multi-label classification tasks. Nevertheless, the
state-of-the-art embedded multi-label feature selection algorithms based on
least square regression usually cannot preserve sufficient discriminative
information in multi-label data. To tackle the aforementioned challenge, a
novel embedded multi-label feature selection method, termed global redundancy
and relevance optimization in orthogonal regression (GRROOR), is proposed to
facilitate the multi-label feature selection. The method employs orthogonal
regression with feature weighting to retain sufficient statistical and
structural information related to local label correlations of the multi-label
data in the feature learning process. Additionally, both global feature
redundancy and global label relevancy information have been considered in the
orthogonal regression model, which could contribute to the search for
discriminative and non-redundant feature subsets in the multi-label data. The
cost function of GRROOR is an unbalanced orthogonal Procrustes problem on the
Stiefel manifold. A simple yet effective scheme is utilized to obtain an
optimal solution. Extensive experimental results on ten multi-label data sets
demonstrate the effectiveness of GRROOR.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00315" title="Abstract">arXiv:2403.00315</a> [<a href="/pdf/2403.00315" title="Download PDF">pdf</a>, <a href="/ps/2403.00315" title="Download PostScript">ps</a>, <a href="/format/2403.00315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Axe the X in XAI: A Plea for Understandable AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=P%C3%A1ez%2C+A">Andr&#xe9;s P&#xe1;ez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In a recent paper, Erasmus et al. (2021) defend the idea that the ambiguity
of the term "explanation" in explainable AI (XAI) can be solved by adopting any
of four different extant accounts of explanation in the philosophy of science:
the Deductive Nomological, Inductive Statistical, Causal Mechanical, and New
Mechanist models. In this chapter, I show that the authors' claim that these
accounts can be applied to deep neural networks as they would to any natural
phenomenon is mistaken. I also provide a more general argument as to why the
notion of explainability as it is currently used in the XAI literature bears
little resemblance to the traditional concept of scientific explanation. It
would be more fruitful to use the label "understandable AI" to avoid the
confusion that surrounds the goal and purposes of XAI. In the second half of
the chapter, I argue for a pragmatic conception of understanding that is better
suited to play the central role attributed to explanation in XAI. Following
Kuorikoski &amp; Ylikoski (2015), the conditions of satisfaction for understanding
an ML system are fleshed out in terms of an agent's success in using the
system, in drawing correct inferences from it.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00318" title="Abstract">arXiv:2403.00318</a> [<a href="/pdf/2403.00318" title="Download PDF">pdf</a>, <a href="/format/2403.00318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning for Solving Management Problems: Towards A  Large Management Mode
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jinyang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaotian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+T">Tao Ren</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qinghao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yufu Du</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yijie Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cheng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce a deep reinforcement learning (DRL) approach for solving
management problems including inventory management, dynamic pricing, and
recommendation. This DRL approach has the potential to lead to a large
management model based on certain transformer neural network structures,
resulting in an artificial general intelligence paradigm for various management
tasks. Traditional methods have limitations for solving complex real-world
problems, and we demonstrate how DRL can surpass existing heuristic approaches
for solving management tasks. We aim to solve the problems in a unified
framework, considering the interconnections between different tasks. Central to
our methodology is the development of a foundational decision model
coordinating decisions across the different domains through generative
decision-making. Our experimental results affirm the effectiveness of our
DRL-based framework in complex and dynamic business environments. This work
opens new pathways for the application of DRL in management problems,
highlighting its potential to revolutionize traditional business management.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00321" title="Abstract">arXiv:2403.00321</a> [<a href="/pdf/2403.00321" title="Download PDF">pdf</a>, <a href="/format/2403.00321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DEEP-IoT: Downlink-Enhanced Efficient-Power Internet of Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yulin Shao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
<p class="mathjax">At the heart of the Internet of Things (IoT) -- a domain witnessing explosive
growth -- the imperative for energy efficiency and the extension of device
lifespans has never been more pressing. This paper presents DEEP-IoT, a
revolutionary communication paradigm poised to redefine how IoT devices
communicate. Through a pioneering "listen more, transmit less" strategy,
DEEP-IoT challenges and transforms the traditional transmitter (IoT
devices)-centric communication model to one where the receiver (the access
point) play a pivotal role, thereby cutting down energy use and boosting device
longevity. We not only conceptualize DEEP-IoT but also actualize it by
integrating deep learning-enhanced feedback channel codes within a narrow-band
system. Simulation results show a significant enhancement in the operational
lifespan of IoT cells -- surpassing traditional systems using Turbo and Polar
codes by up to 52.71%. This leap signifies a paradigm shift in IoT
communications, setting the stage for a future where IoT devices boast
unprecedented efficiency and durability.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00322" title="Abstract">arXiv:2403.00322</a> [<a href="/pdf/2403.00322" title="Download PDF">pdf</a>, <a href="/format/2403.00322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-Based Planning and Control for Terrestrial-Aerial Bimodal Vehicles  with Passive Wheels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruibin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Junxiao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuze Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuman Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yanjun Cao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+F">Fei Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Terrestrial and aerial bimodal vehicles have gained widespread attention due
to their cross-domain maneuverability. Nevertheless, their bimodal dynamics
significantly increase the complexity of motion planning and control, thus
hindering robust and efficient autonomous navigation in unknown environments.
To resolve this issue, we develop a model-based planning and control framework
for terrestrial aerial bi-modal vehicles. This work begins by deriving a
unified dynamic model and the corresponding differential flatness. Leveraging
differential flatness, an optimization-based trajectory planner is proposed,
which takes into account both solution quality and computational efficiency.
Moreover, we design a tracking controller using nonlinear model predictive
control based on the proposed unified dynamic model to achieve accurate
trajectory tracking and smooth mode transition. We validate our framework
through extensive benchmark comparisons and experiments, demonstrating its
effectiveness in terms of planning quality and control performance.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00323" title="Abstract">arXiv:2403.00323</a> [<a href="/pdf/2403.00323" title="Download PDF">pdf</a>, <a href="/format/2403.00323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Softened Symbol Grounding for Neuro-symbolic Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zenan Li</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Taolue Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jingwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+C">Chun Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaoxing Ma</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BC%2C+J">Jian L&#xfc;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at ICLR 2023. Code is available at <a href="https://github.com/SoftWiser-group/Soften-NeSy-learning">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Neuro-symbolic learning generally consists of two separated worlds, i.e.,
neural network training and symbolic constraint solving, whose success hinges
on symbol grounding, a fundamental problem in AI. This paper presents a novel,
softened symbol grounding process, bridging the gap between the two worlds, and
resulting in an effective and efficient neuro-symbolic learning framework.
Technically, the framework features (1) modeling of symbol solution states as a
Boltzmann distribution, which avoids expensive state searching and facilitates
mutually beneficial interactions between network training and symbolic
reasoning;(2) a new MCMC technique leveraging projection and SMT solvers, which
efficiently samples from disconnected symbol solution spaces; (3) an annealing
mechanism that can escape from %being trapped into sub-optimal symbol
groundings. Experiments with three representative neuro symbolic learning tasks
demonstrate that, owining to its superior symbol grounding capability, our
framework successfully solves problems well beyond the frontier of the existing
proposals.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00325" title="Abstract">arXiv:2403.00325</a> [<a href="/pdf/2403.00325" title="Download PDF">pdf</a>, <a href="/format/2403.00325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Small, Versatile and Mighty: A Range-View Perception Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+Q">Qiang Meng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">JiaBao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Liujiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Ke Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite its compactness and information integrity, the range view
representation of LiDAR data rarely occurs as the first choice for 3D
perception tasks. In this work, we further push the envelop of the range-view
representation with a novel multi-task framework, achieving unprecedented 3D
detection performances. Our proposed Small, Versatile, and Mighty (SVM) network
utilizes a pure convolutional architecture to fully unleash the efficiency and
multi-tasking potentials of the range view representation. To boost detection
performances, we first propose a range-view specific Perspective Centric Label
Assignment (PCLA) strategy, and a novel View Adaptive Regression (VAR) module
to further refine hard-to-predict box properties. In addition, our framework
seamlessly integrates semantic segmentation and panoptic segmentation tasks for
the LiDAR point cloud, without extra modules. Among range-view-based methods,
our model achieves new state-of-the-art detection performances on the Waymo
Open Dataset. Especially, over 10 mAP improvement over convolutional
counterparts can be obtained on the vehicle class. Our presented results for
other tasks further reveal the multi-task capabilities of the proposed small
but mighty framework.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00326" title="Abstract">arXiv:2403.00326</a> [<a href="/pdf/2403.00326" title="Download PDF">pdf</a>, <a href="/format/2403.00326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAMS-DETR: Dynamic Adaptive Multispectral Detection Transformer with  Competitive Query Selection and Adaptive Feature Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Junjie%2C+G">Guo Junjie</a>, 
<a href="/search/cs?searchtype=author&query=Chenqiang%2C+G">Gao Chenqiang</a>, 
<a href="/search/cs?searchtype=author&query=Fangcen%2C+L">Liu Fangcen</a>, 
<a href="/search/cs?searchtype=author&query=Deyu%2C+M">Meng Deyu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Infrared-visible object detection aims to achieve robust even full-day object
detection by fusing the complementary information of infrared and visible
images. However, highly dynamically variable complementary characteristics and
commonly existing modality misalignment make the fusion of complementary
information difficult. In this paper, we propose a Dynamic Adaptive
Multispectral Detection Transformer (DAMS-DETR) based on DETR to simultaneously
address these two challenges. Specifically, we propose a Modality Competitive
Query Selection strategy to provide useful prior information. This strategy can
dynamically select basic salient modality feature representation for each
object. To effectively mine the complementary information and adapt to
misalignment situations, we propose a Multispectral Deformable Cross-attention
module to adaptively sample and aggregate multi-semantic level features of
infrared and visible images for each object. In addition, we further adopt the
cascade structure of DETR to better mine complementary information. Experiments
on four public datasets of different scenes demonstrate significant
improvements compared to other state-of-the-art methods. The code will be
released at https://github.com/gjj45/DAMS-DETR.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00327" title="Abstract">arXiv:2403.00327</a> [<a href="/pdf/2403.00327" title="Download PDF">pdf</a>, <a href="/format/2403.00327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task Indicating Transformer for Task-conditional Dense Predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yuxiang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Sirejiding%2C+S">Shalayiding Sirejiding</a>, 
<a href="/search/cs?searchtype=author&query=Bayramli%2C+B">Bayram Bayramli</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Suizhi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yue Ding</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hongtao Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The task-conditional model is a distinctive stream for efficient multi-task
learning. Existing works encounter a critical limitation in learning
task-agnostic and task-specific representations, primarily due to shortcomings
in global context modeling arising from CNN-based architectures, as well as a
deficiency in multi-scale feature interaction within the decoder. In this
paper, we introduce a novel task-conditional framework called Task Indicating
Transformer (TIT) to tackle this challenge. Our approach designs a Mix Task
Adapter module within the transformer block, which incorporates a Task
Indicating Matrix through matrix decomposition, thereby enhancing long-range
dependency modeling and parameter-efficient feature adaptation by capturing
intra- and inter-task features. Moreover, we propose a Task Gate Decoder module
that harnesses a Task Indicating Vector and gating mechanism to facilitate
adaptive multi-scale feature refinement guided by task embeddings. Experiments
on two public multi-task dense prediction benchmarks, NYUD-v2 and
PASCAL-Context, demonstrate that our approach surpasses state-of-the-art
task-conditional methods.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00329" title="Abstract">arXiv:2403.00329</a> [<a href="/pdf/2403.00329" title="Download PDF">pdf</a>, <a href="/format/2403.00329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning with Logical Constraints but without Shortcut Satisfaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zenan Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zehua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jingwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Taolue Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaoxing Ma</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BC%2C+J">Jian L&#xfc;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at ICLR 2023, and code is available at <a href="https://github.com/SoftWiser-group/NeSy-without-Shortcuts">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent studies in neuro-symbolic learning have explored the integration of
logical knowledge into deep learning via encoding logical constraints as an
additional loss function. However, existing approaches tend to vacuously
satisfy logical constraints through shortcuts, failing to fully exploit the
knowledge. In this paper, we present a new framework for learning with logical
constraints. Specifically, we address the shortcut satisfaction issue by
introducing dual variables for logical connectives, encoding how the constraint
is satisfied. We further propose a variational framework where the encoded
logical constraint is expressed as a distributional loss that is compatible
with the model's original training loss. The theoretical analysis shows that
the proposed approach bears salient properties, and the experimental
evaluations demonstrate its superior performance in both model generalizability
and constraint satisfaction.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00331" title="Abstract">arXiv:2403.00331</a> [<a href="/pdf/2403.00331" title="Download PDF">pdf</a>, <a href="/format/2403.00331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WindGP: Efficient Graph Partitioning on Heterogenous Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+L">Li Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haohan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Binfan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+S">Shengcheng Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jinhua Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rongqian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xin Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Graph Partitioning is widely used in many real-world applications such as
fraud detection and social network analysis, in order to enable the distributed
graph computing on large graphs. However, existing works fail to balance the
computation cost and communication cost on machines with different power
(including computing capability, network bandwidth and memory size), as they
only consider replication factor and neglect the difference of machines in
realistic data centers. In this paper, we propose a general graph partitioning
algorithm WindGP, which can support fast and high-quality edge partitioning on
heterogeneous machines. WindGP designs novel preprocessing techniques to
simplify the metric and balance the computation cost according to the
characteristics of graphs and machines. Also, best-first search is proposed
instead of BFS and DFS, in order to generate clusters with high cohesion.
Furthermore, WindGP adaptively tunes the partition results by sophisticated
local search methods. Extensive experiments show that WindGP outperforms all
state-of-the-art partition methods by 1.35 - 27 times on both dense and sparse
distributed graph algorithms, and has good scalability with graph size and
machine number.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00334" title="Abstract">arXiv:2403.00334</a> [<a href="/pdf/2403.00334" title="Download PDF">pdf</a>, <a href="/format/2403.00334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NOVA: A visual interface for assessing polarizing media coverage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dasu%2C+K">Keshav Dasu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S+Y">Sam Yu-Te Lee</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Ying-Cheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kwan-Liu Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Within the United States, the majority of the populace receives their news
online. U.S mainstream media outlets both generate and influence the news
consumed by U.S citizens. Many of these citizens have their personal beliefs
about these outlets and question the fairness of their reporting. We offer an
interactive visualization system for the public to assess their perception of
the mainstream media's coverage of a topic against the data. Our system
combines belief elicitation techniques and narrative structure designs,
emphasizing transparency and user-friendliness to facilitate users'
self-assessment on personal beliefs. We gathered $\sim${25k} articles from the
span of 2020-2022 from six mainstream media outlets as a testbed. To evaluate
our system, we present usage scenarios alongside a user study with a
qualitative analysis of user exploration strategies for personal belief
assessment. We report our observations from this study and discuss future work
and challenges of developing tools for the public to assess media outlet
coverage and belief updating on provocative topics.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00336" title="Abstract">arXiv:2403.00336</a> [<a href="/pdf/2403.00336" title="Download PDF">pdf</a>, <a href="/format/2403.00336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Never-Ending Embodied Robot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+W">Wenqi Liang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Gan Sun</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qian He</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yu Ren</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jiahua Dong</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+Y">Yang Cong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Relying on large language models (LLMs), embodied robots could perform
complex multimodal robot manipulation tasks from visual observations with
powerful generalization ability. However, most visual behavior-cloning agents
suffer from manipulation performance degradation and skill knowledge forgetting
when adapting into a series of challenging unseen tasks. We here investigate
the above challenge with NBCagent in embodied robots, a pioneering
language-conditioned Never-ending Behavior-Cloning agent, which can continually
learn observation knowledge of novel robot manipulation skills from
skill-specific and skill-shared attributes. Specifically, we establish a
skill-specific evolving planner to perform knowledge decoupling, which can
continually embed novel skill-specific knowledge in our NBCagent agent from
latent and low-rank space. Meanwhile, we propose a skill-shared semantics
rendering module and a skill-shared representation distillation module to
effectively transfer anti-forgetting skill-shared knowledge, further tackling
catastrophic forgetting on old skills from semantics and representation
aspects. Finally, we design a continual embodied robot manipulation benchmark,
and several expensive experiments demonstrate the significant performance of
our method. Visual results, code, and dataset are provided at:
https://neragent.github.io.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00337" title="Abstract">arXiv:2403.00337</a> [<a href="/pdf/2403.00337" title="Download PDF">pdf</a>, <a href="/format/2403.00337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Sheaf Diffusion in Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zaghen%2C+O">Olga Zaghen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Thesis for Master's degree in Artificial Intelligence Systems (University of Trento), 65 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This work focuses on exploring the potential benefits of introducing a
nonlinear Laplacian in Sheaf Neural Networks for graph-related tasks. The
primary aim is to understand the impact of such nonlinearity on diffusion
dynamics, signal propagation, and performance of neural network architectures
in discrete-time settings. The study primarily emphasizes experimental
analysis, using real-world and synthetic datasets to validate the practical
effectiveness of different versions of the model. This approach shifts the
focus from an initial theoretical exploration to demonstrating the practical
utility of the proposed model.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00338" title="Abstract">arXiv:2403.00338</a> [<a href="/pdf/2403.00338" title="Download PDF">pdf</a>, <a href="/format/2403.00338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Instruct: Bridging Natural-Instruct and Self-Instruct for Code  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xianzhen Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qingfu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dongliang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+W">Wanxiang Che</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Instruction tuning plays a pivotal role in Code Large Language Models (Code
LLMs) for the task of program synthesis. Presently, two dominant paradigms for
collecting tuning data are natural-instruct (human-written) and self-instruct
(automatically generated). Natural-instruct includes diverse and correct codes
but lacks instruction-code pairs, and exists improper code formats like nested
single-line codes. In contrast, self-instruct automatically generates proper
paired data. However, it suffers from low diversity due to generating
duplicates and cannot ensure the correctness of codes. To bridge the both
paradigms, we propose \textbf{Semi-Instruct}. It first converts diverse but
improper codes from natural-instruct into proper instruction-code pairs through
a method similar to self-instruct. To verify the correctness of generated
codes, we design a novel way to construct test cases by generating cases'
inputs and executing correct codes from natural-instruct to get outputs.
Finally, diverse and correct instruction-code pairs are retained for
instruction tuning. Experiments show that semi-instruct is significantly better
than natural-instruct and self-instruct. Furthermore, the performance steadily
improves as data scale increases.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00344" title="Abstract">arXiv:2403.00344</a> [<a href="/pdf/2403.00344" title="Download PDF">pdf</a>, <a href="/format/2403.00344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustifying a Policy in Multi-Agent RL with Diverse Cooperative  Behavior and Adversarial Style Sampling for Assistive Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Osa%2C+T">Tayuki Osa</a>, 
<a href="/search/cs?searchtype=author&query=Harada%2C+T">Tatsuya Harada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, accepted for ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Autonomous assistance of people with motor impairments is one of the most
promising applications of autonomous robotic systems. Recent studies have
reported encouraging results using deep reinforcement learning (RL) in the
healthcare domain. Previous studies showed that assistive tasks can be
formulated as multi-agent RL, wherein there are two agents: a caregiver and a
care-receiver. However, policies trained in multi-agent RL are often sensitive
to the policies of other agents. In such a case, a trained caregiver's policy
may not work for different care-receivers. To alleviate this issue, we propose
a framework that learns a robust caregiver's policy by training it for diverse
care-receiver responses. In our framework, diverse care-receiver responses are
autonomously learned through trials and errors. In addition, to robustify the
care-giver's policy, we propose a strategy for sampling a care-receiver's
response in an adversarial manner during the training. We evaluated the
proposed method using tasks in an Assistive Gym. We demonstrate that policies
trained with a popular deep RL method are vulnerable to changes in policies of
other agents and that the proposed framework improves the robustness against
such changes.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00349" title="Abstract">arXiv:2403.00349</a> [<a href="/pdf/2403.00349" title="Download PDF">pdf</a>, <a href="/ps/2403.00349" title="Download PostScript">ps</a>, <a href="/format/2403.00349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact of Inter-Operator Interference via Reconfigurable Intelligent  Surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miridakis%2C+N+I">Nikolaos I. Miridakis</a>, 
<a href="/search/cs?searchtype=author&query=Tsiftsis%2C+T+A">Theodoros A. Tsiftsis</a>, 
<a href="/search/cs?searchtype=author&query=Karkazis%2C+P+A">Panagiotis A. Karkazis</a>, 
<a href="/search/cs?searchtype=author&query=Leligou%2C+H+C">Helen C. Leligou</a>, 
<a href="/search/cs?searchtype=author&query=Popovski%2C+P">Petar Popovski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">A wireless communication system is studied that operates in the presence of
multiple reconfigurable intelligent surfaces (RISs). In particular, a
multi-operator environment is considered where each operator utilizes an RIS to
enhance its communication quality. Although out-of-band interference does not
exist (since each operator uses isolated spectrum resources), RISs controlled
by different operators do affect the system performance of one another due to
the inherently rapid phase shift adjustments that occur on an independent
basis. The system performance of such a communication scenario is analytically
studied for the practical case where discrete-only phase shifts occur at RIS.
The proposed framework is quite general since it is valid under arbitrary
channel fading conditions as well as the presence (or not) of the transceiver's
direct link. Finally, the derived analytical results are verified via numerical
and simulation trial as well as some novel and useful engineering outcomes are
manifested.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00352" title="Abstract">arXiv:2403.00352</a> [<a href="/pdf/2403.00352" title="Download PDF">pdf</a>, <a href="/format/2403.00352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Disentanglement in Downstream Tasks: A Study on Its Necessity  for Abstract Visual Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nai%2C+R">Ruiqian Nai</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Zixin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Ji Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In representation learning, a disentangled representation is highly desirable
as it encodes generative factors of data in a separable and compact pattern.
Researchers have advocated leveraging disentangled representations to complete
downstream tasks with encouraging empirical evidence. This paper further
investigates the necessity of disentangled representation in downstream
applications. Specifically, we show that dimension-wise disentangled
representations are unnecessary on a fundamental downstream task, abstract
visual reasoning. We provide extensive empirical evidence against the necessity
of disentanglement, covering multiple datasets, representation learning
methods, and downstream network architectures. Furthermore, our findings
suggest that the informativeness of representations is a better indicator of
downstream performance than disentanglement. Finally, the positive correlation
between informativeness and disentanglement explains the claimed usefulness of
disentangled representations in previous works. The source code is available at
https://github.com/Richard-coder-Nai/disentanglement-lib-necessity.git.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00353" title="Abstract">arXiv:2403.00353</a> [<a href="/pdf/2403.00353" title="Download PDF">pdf</a>, <a href="/format/2403.00353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MS-Net: A Multi-Path Sparse Model for Motion Prediction in Multi-Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiaqiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weigao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Siyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yiyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yafeng Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Robotics and Automation Letters (RAL)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">The multi-modality and stochastic characteristics of human behavior make
motion prediction a highly challenging task, which is critical for autonomous
driving. While deep learning approaches have demonstrated their great potential
in this area, it still remains unsolved to establish a connection between
multiple driving scenes (e.g., merging, roundabout, intersection) and the
design of deep learning models. Current learning-based methods typically use
one unified model to predict trajectories in different scenarios, which may
result in sub-optimal results for one individual scene. To address this issue,
we propose Multi-Scenes Network (aka. MS-Net), which is a multi-path sparse
model trained by an evolutionary process. MS-Net selectively activates a subset
of its parameters during the inference stage to produce prediction results for
each scene. In the training stage, the motion prediction task under
differentiated scenes is abstracted as a multi-task learning problem, an
evolutionary algorithm is designed to encourage the network search of the
optimal parameters for each scene while sharing common knowledge between
different scenes. Our experiment results show that with substantially reduced
parameters, MS-Net outperforms existing state-of-the-art methods on
well-established pedestrian motion prediction datasets, e.g., ETH and UCY, and
ranks the 2nd place on the INTERACTION challenge.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00354" title="Abstract">arXiv:2403.00354</a> [<a href="/pdf/2403.00354" title="Download PDF">pdf</a>, <a href="/format/2403.00354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Consistent Reasoning-based Aspect-Sentiment Quad Prediction with  Extract-Then-Assign Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jieyong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+R">Ryang Heo</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+Y">Yongsik Seo</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">SeongKu Kang</a>, 
<a href="/search/cs?searchtype=author&query=Yeo%2C+J">Jinyoung Yeo</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongha Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In the task of aspect sentiment quad prediction (ASQP), generative methods
for predicting sentiment quads have shown promising results. However, they
still suffer from imprecise predictions and limited interpretability, caused by
data scarcity and inadequate modeling of the quadruplet composition process. In
this paper, we propose Self-Consistent Reasoning-based Aspect-sentiment
quadruple Prediction (SCRAP), optimizing its model to generate reasonings and
the corresponding sentiment quadruplets in sequence. SCRAP adopts the
Extract-Then-Assign reasoning strategy, which closely mimics human cognition.
In the end, SCRAP significantly improves the model's ability to handle complex
reasoning tasks and correctly predict quadruplets through consistency voting,
resulting in enhanced interpretability and accuracy in ASQP.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00365" title="Abstract">arXiv:2403.00365</a> [<a href="/pdf/2403.00365" title="Download PDF">pdf</a>, <a href="/format/2403.00365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can a Funny Chatbot Make a Difference? Infusing Humor into  Conversational Agent for Behavioral Intervention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Teljeur%2C+I">Isabelle Teljeur</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuying Li</a>, 
<a href="/search/cs?searchtype=author&query=Bosch%2C+J+A">Jos A. Bosch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Regular physical activity is crucial for reducing the risk of
non-communicable disease (NCD). With NCDs on the rise globally, there is an
urgent need for effective health interventions, with chatbots emerging as a
viable and cost-effective option because of limited healthcare accessibility.
Although health professionals often utilize behavior change techniques (BCTs)
to boost physical activity levels and enhance client engagement and motivation
by affiliative humor, the efficacy of humor in chatbot-delivered interventions
is not well-understood. This study conducted a randomized controlled trial to
examine the impact of the generative humorous communication style in a 10-day
chatbot-delivered intervention for physical activity. It further investigated
if user engagement and motivation act as mediators between the communication
style and changes in physical activity levels. 66 participants engaged with the
chatbots across three groups (humorous, non-humorous, and no-intervention) and
responded to daily ecological momentary assessment questionnaires assessing
engagement, motivation, and physical activity levels. Multilevel time series
analyses revealed that an affiliative humorous communication style positively
impacted physical activity levels over time, with user engagement acting as a
mediator in this relationship, whereas motivation did not. These findings
clarify the role of humorous communication style in chatbot-delivered physical
activity interventions, offering valuable insights for future development of
intelligent conversational agents incorporating humor.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00366" title="Abstract">arXiv:2403.00366</a> [<a href="/pdf/2403.00366" title="Download PDF">pdf</a>, <a href="/ps/2403.00366" title="Download PostScript">ps</a>, <a href="/format/2403.00366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the dynamic interplay of cognitive load and emotional arousal  by using multimodal measurements: Correlation of pupil diameter and emotional  arousal in emotionally engaging tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kosel%2C+C">C. Kosel</a>, 
<a href="/search/cs?searchtype=author&query=Michel%2C+S">S. Michel</a>, 
<a href="/search/cs?searchtype=author&query=Seidel%2C+T">T. Seidel</a>, 
<a href="/search/cs?searchtype=author&query=Foerster%2C+M">M. Foerster</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contributed equally to the manuscript
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Multimodal data analysis and validation based on streams from
state-of-the-art sensor technology such as eye-tracking or emotion recognition
using the Facial Action Coding System (FACTs) with deep learning allows
educational researchers to study multifaceted learning and problem-solving
processes and to improve educational experiences. This study aims to
investigate the correlation between two continuous sensor streams, pupil
diameter as an indicator of cognitive workload and FACTs with deep learning as
an indicator of emotional arousal (RQ 1a), specifically for epochs of high,
medium, and low arousal (RQ 1b). Furthermore, the time lag between emotional
arousal and pupil diameter data will be analyzed (RQ 2). 28 participants worked
on three cognitively demanding and emotionally engaging everyday moral dilemmas
while eye-tracking and emotion recognition data were collected. The data were
pre-processed in Phyton (synchronization, blink control, downsampling) and
analyzed using correlation analysis and Granger causality tests. The results
show negative and statistically significant correlations between the data
streams for emotional arousal and pupil diameter. However, the correlation is
negative and significant only for epochs of high arousal, while positive but
non-significant relationships were found for epochs of medium or low arousal.
The average time lag for the relationship between arousal and pupil diameter
was 2.8 ms. In contrast to previous findings without a multimodal approach
suggesting a positive correlation between the constructs, the results
contribute to the state of research by highlighting the importance of
multimodal data validation and research on convergent vagility. Future research
should consider emotional regulation strategies and emotional valence.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00368" title="Abstract">arXiv:2403.00368</a> [<a href="/pdf/2403.00368" title="Download PDF">pdf</a>, <a href="/format/2403.00368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recommending Target Actions Outside Sessions in the Data-poor Insurance  Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bruun%2C+S+B">Simone Borg Bruun</a>, 
<a href="/search/cs?searchtype=author&query=Lioma%2C+C">Christina Lioma</a>, 
<a href="/search/cs?searchtype=author&query=Maistro%2C+M">Maria Maistro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2211.15360">arXiv:2211.15360</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Transactions on Recommender Systems 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Providing personalized recommendations for insurance products is particularly
challenging due to the intrinsic and distinctive features of the insurance
domain. First, unlike more traditional domains like retail, movie etc., a large
amount of user feedback is not available and the item catalog is smaller.
Second, due to the higher complexity of products, the majority of users still
prefer to complete their purchases over the phone instead of online. We present
different recommender models to address such data scarcity in the insurance
domain. We use recurrent neural networks with 3 different types of loss
functions and architectures (cross-entropy, censored Weibull, attention). Our
models cope with data scarcity by learning from multiple sessions and different
types of user actions. Moreover, differently from previous session-based
models, our models learn to predict a target action that does not happen within
the session. Our models outperform state-of-the-art baselines on a real-world
insurance dataset, with ca. 44K users, 16 items, 54K purchases and 117K
sessions. Moreover, combining our models with demographic data boosts the
performance. Analysis shows that considering multiple sessions and several
types of actions are both beneficial for the models, and that our models are
not unfair with respect to age, gender and income.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00370" title="Abstract">arXiv:2403.00370</a> [<a href="/pdf/2403.00370" title="Download PDF">pdf</a>, <a href="/format/2403.00370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Post-decoder Biasing for End-to-End Speech Recognition of Multi-turn  Medical Interview
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Heyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">End-to-end (E2E) approach is gradually replacing hybrid models for automatic
speech recognition (ASR) tasks. However, the optimization of E2E models lacks
an intuitive method for handling decoding shifts, especially in scenarios with
a large number of domain-specific rare words that hold specific important
meanings. Furthermore, the absence of knowledge-intensive speech datasets in
academia has been a significant limiting factor, and the commonly used speech
corpora exhibit significant disparities with realistic conversation. To address
these challenges, we present Medical Interview (MED-IT), a multi-turn
consultation speech dataset that contains a substantial number of
knowledge-intensive named entities. We also explore methods to enhance the
recognition performance of rare words for E2E models. We propose a novel
approach, post-decoder biasing, which constructs a transform probability matrix
based on the distribution of training transcriptions. This guides the model to
prioritize recognizing words in the biasing list. In our experiments, for
subsets of rare words appearing in the training speech between 10 and 20 times,
and between 1 and 5 times, the proposed method achieves a relative improvement
of 9.3% and 5.1%, respectively.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00372" title="Abstract">arXiv:2403.00372</a> [<a href="/pdf/2403.00372" title="Download PDF">pdf</a>, <a href="/format/2403.00372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperSDFusion: Bridging Hierarchical Structures in Language and Geometry  for Enhanced 3D Text2Shape Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leng%2C+Z">Zhiying Leng</a>, 
<a href="/search/cs?searchtype=author&query=Birdal%2C+T">Tolga Birdal</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaohui Liang</a>, 
<a href="/search/cs?searchtype=author&query=Tombari%2C+F">Federico Tombari</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE/CVF conference on computer vision and pattern recognition
  2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D shape generation from text is a fundamental task in 3D representation
learning. The text-shape pairs exhibit a hierarchical structure, where a
general text like "chair" covers all 3D shapes of the chair, while more
detailed prompts refer to more specific shapes. Furthermore, both text and 3D
shapes are inherently hierarchical structures. However, existing Text2Shape
methods, such as SDFusion, do not exploit that. In this work, we propose
HyperSDFusion, a dual-branch diffusion model that generates 3D shapes from a
given text. Since hyperbolic space is suitable for handling hierarchical data,
we propose to learn the hierarchical representations of text and 3D shapes in
hyperbolic space. First, we introduce a hyperbolic text-image encoder to learn
the sequential and multi-modal hierarchical features of text in hyperbolic
space. In addition, we design a hyperbolic text-graph convolution module to
learn the hierarchical features of text in hyperbolic space. In order to fully
utilize these text features, we introduce a dual-branch structure to embed text
features in 3D feature space. At last, to endow the generated 3D shapes with a
hierarchical structure, we devise a hyperbolic hierarchical loss. Our method is
the first to explore the hyperbolic hierarchical representation for
text-to-shape generation. Experimental results on the existing text-to-shape
paired dataset, Text2Shape, achieved state-of-the-art results.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00376" title="Abstract">arXiv:2403.00376</a> [<a href="/pdf/2403.00376" title="Download PDF">pdf</a>, <a href="/format/2403.00376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariant Test-Time Adaptation for Vision-Language Model Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Huan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Changqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Peilin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Baoyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Long-Kai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qinghua Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bingzhe Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Vision-language foundation models have exhibited remarkable success across a
multitude of downstream tasks due to their scalability on extensive image-text
paired datasets. However, these models display significant limitations when
applied to long-tail tasks, such as fine-grained image classification, as a
result of "decision shortcuts" that hinders their generalization capabilities.
In this work, we find that the CLIP model possesses a rich set of features,
encompassing both \textit{desired invariant causal features} and
\textit{undesired decision shortcuts}. Moreover, the underperformance of CLIP
on downstream tasks originates from its inability to effectively utilize
pre-trained features in accordance with specific task requirements. To address
this challenge, this paper introduces a test-time prompt tuning paradigm that
optimizes a learnable prompt, thereby compelling the model to exploit genuine
causal invariant features while disregarding decision shortcuts during the
inference phase. The proposed method effectively alleviates excessive
dependence on potentially misleading, task-irrelevant contextual information,
while concurrently emphasizing critical, task-related visual cues. We conduct
comparative analysis of the proposed method against various approaches which
validates its effectiveness.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00381" title="Abstract">arXiv:2403.00381</a> [<a href="/pdf/2403.00381" title="Download PDF">pdf</a>, <a href="/format/2403.00381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured Deep Neural Networks-Based Backstepping Trajectory Tracking  Control for Lagrangian Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+J">Jiajun Qian</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Liang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiaoqiang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaofan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Deep neural networks (DNN) are increasingly being used to learn controllers
due to their excellent approximation capabilities. However, their black-box
nature poses significant challenges to closed-loop stability guarantees and
performance analysis. In this paper, we introduce a structured DNN-based
controller for the trajectory tracking control of Lagrangian systems using
backing techniques. By properly designing neural network structures, the
proposed controller can ensure closed-loop stability for any compatible neural
network parameters. In addition, improved control performance can be achieved
by further optimizing neural network parameters. Besides, we provide explicit
upper bounds on tracking errors in terms of controller parameters, which allows
us to achieve the desired tracking performance by properly selecting the
controller parameters. Furthermore, when system models are unknown, we propose
an improved Lagrangian neural network (LNN) structure to learn the system
dynamics and design the controller. We show that in the presence of model
approximation errors and external disturbances, the closed-loop stability and
tracking control performance can still be guaranteed. The effectiveness of the
proposed approach is demonstrated through simulations.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00387" title="Abstract">arXiv:2403.00387</a> [<a href="/pdf/2403.00387" title="Download PDF">pdf</a>, <a href="/format/2403.00387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> For time-invariant delay systems, global asymptotic stability does not  imply uniform global attractivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chaillet%2C+A">Antoine Chaillet</a> (IUF, L2S), 
<a href="/search/eess?searchtype=author&query=Wirth%2C+F">Fabian Wirth</a>, 
<a href="/search/eess?searchtype=author&query=Mironchenko%2C+A">Andrii Mironchenko</a>, 
<a href="/search/eess?searchtype=author&query=Brivadis%2C+L">Lucas Brivadis</a> (L2S)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Conference on Decision and Control, Dec 2024, Milan (Italie),
  Italy
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Adapting a counterexample recently proposed by J.L. Mancilla-Aguilar and H.
Haimovich, we show here that, for time-delay systems, global asymptotic
stability does not ensure that solutions converge uniformly to zero over
bounded sets of initial states. Hence, the convergence might be arbitrarily
slow even if initial states are confined to a bounded set.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00390" title="Abstract">arXiv:2403.00390</a> [<a href="/pdf/2403.00390" title="Download PDF">pdf</a>, <a href="/ps/2403.00390" title="Download PostScript">ps</a>, <a href="/format/2403.00390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deterministic Weighted Automata under Partial Observability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Michaliszyn%2C+J">Jakub Michaliszyn</a>, 
<a href="/search/cs?searchtype=author&query=Otop%2C+J">Jan Otop</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">Weighted automata is a basic tool for specification in quantitative
verification, which allows to express quantitative features of analysed systems
such as resource consumption. Quantitative specification can be assisted by
automata learning as there are classic results on Angluin-style learning of
weighted automata. The existing work assumes perfect information about the
values returned by the target weighted automaton. In assisted synthesis of a
quantitative specification, knowledge of the exact values is a strong
assumption and may be infeasible. In our work, we address this issue by
introducing a new framework of partially-observable deterministic weighted
automata, in which weighted automata return intervals containing the computed
values of words instead of the exact values. We study the basic properties of
this framework with the particular focus on the challenges of
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00393" title="Abstract">arXiv:2403.00393</a> [<a href="/pdf/2403.00393" title="Download PDF">pdf</a>, <a href="/format/2403.00393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Private Benchmarking to Prevent Contamination and Improve Comparative  Evaluation of LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chandran%2C+N">Nishanth Chandran</a>, 
<a href="/search/cs?searchtype=author&query=Sitaram%2C+S">Sunayana Sitaram</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+D">Divya Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+R">Rahul Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+K">Kashish Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Swaminathan%2C+M">Manohar Swaminathan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Benchmarking is the de-facto standard for evaluating LLMs, due to its speed,
replicability and low cost. However, recent work has pointed out that the
majority of the open source benchmarks available today have been contaminated
or leaked into LLMs, meaning that LLMs have access to test data during
pretraining and/or fine-tuning. This raises serious concerns about the validity
of benchmarking studies conducted so far and the future of evaluation using
benchmarks. To solve this problem, we propose Private Benchmarking, a solution
where test datasets are kept private and models are evaluated without revealing
the test data to the model. We describe various scenarios (depending on the
trust placed on model owners or dataset owners), and present solutions to avoid
data contamination using private benchmarking. For scenarios where the model
weights need to be kept private, we describe solutions from confidential
computing and cryptography that can aid in private benchmarking. Finally, we
present solutions the problem of benchmark dataset auditing, to ensure that
private benchmarks are of sufficiently high quality.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00396" title="Abstract">arXiv:2403.00396</a> [<a href="/pdf/2403.00396" title="Download PDF">pdf</a>, <a href="/format/2403.00396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GLFNET: Global-Local (frequency) Filter Networks for efficient medical  image segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tragakis%2C+A">Athanasios Tragakis</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qianying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kaul%2C+C">Chaitanya Kaul</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+S+K">Swalpa Kumar Roy</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Hang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Deligianni%2C+F">Fani Deligianni</a>, 
<a href="/search/cs?searchtype=author&query=Murray-Smith%2C+R">Roderick Murray-Smith</a>, 
<a href="/search/cs?searchtype=author&query=Faccio%2C+D">Daniele Faccio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We propose a novel transformer-style architecture called Global-Local Filter
Network (GLFNet) for medical image segmentation and demonstrate its
state-of-the-art performance. We replace the self-attention mechanism with a
combination of global-local filter blocks to optimize model efficiency. The
global filters extract features from the whole feature map whereas the local
filters are being adaptively created as 4x4 patches of the same feature map and
add restricted scale information. In particular, the feature extraction takes
place in the frequency domain rather than the commonly used spatial (image)
domain to facilitate faster computations. The fusion of information from both
spatial and frequency spaces creates an efficient model with regards to
complexity, required data and performance. We test GLFNet on three benchmark
datasets achieving state-of-the-art performance on all of them while being
almost twice as efficient in terms of GFLOP operations.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00397" title="Abstract">arXiv:2403.00397</a> [<a href="/pdf/2403.00397" title="Download PDF">pdf</a>, <a href="/format/2403.00397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Price of Fairness in Bipartite Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castera%2C+R">R&#xe9;mi Castera</a>, 
<a href="/search/cs?searchtype=author&query=Garrido-Lucero%2C+F">Felipe Garrido-Lucero</a>, 
<a href="/search/cs?searchtype=author&query=Molina%2C+M">Mathieu Molina</a>, 
<a href="/search/cs?searchtype=author&query=Mauras%2C+S">Simon Mauras</a>, 
<a href="/search/cs?searchtype=author&query=Loiseau%2C+P">Patrick Loiseau</a>, 
<a href="/search/cs?searchtype=author&query=Perchet%2C+V">Vianney Perchet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We investigate notions of group fairness in bipartite matching markets
involving agents and jobs, where agents are grouped based on sensitive
attributes. Employing a geometric approach, we characterize how many agents can
be matched in each group, showing that the set of feasible matchings forms a
(discrete) polymatroid. We show how we can define weakly-fair matchings
geometrically, for which poly-matroid properties imply that they are maximal.
Next, we focus on strong fairness notions (inspired by group-fairness metrics
in machine learning), where each group gets their exact same fraction of their
entitlement, and we explore the Price of Fairness (PoF), i.e., the loss in
optimality when imposing such fairness constraints. Importantly, we advocate
for the notion of opportunity fairness, where a group entitlement is the
maximum number of agents that can be matched without the presence of other
competing groups. We show that the opportunity PoF is bounded independently of
the number of agents and jobs, but may be linear in the number of groups.
Finally, we provide improved bounds with additional structural properties, or
with stochastic graphs.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00398" title="Abstract">arXiv:2403.00398</a> [<a href="/pdf/2403.00398" title="Download PDF">pdf</a>, <a href="/format/2403.00398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Quadrupedal Locomotion with Impaired Joints Using Random Joint  Masking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Mincheol Kim</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+U">Ukcheol Shin</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jung-Yup Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appear to ICRA 2024, Project page: <a href="https://sites.google.com/view/learning-impaired-joints-loco">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Quadrupedal robots have played a crucial role in various environments, from
structured environments to complex harsh terrains, thanks to their agile
locomotion ability. However, these robots can easily lose their locomotion
functionality if damaged by external accidents or internal malfunctions. In
this paper, we propose a novel deep reinforcement learning framework to enable
a quadrupedal robot to walk with impaired joints. The proposed framework
consists of three components: 1) a random joint masking strategy for simulating
impaired joint scenarios, 2) a joint state estimator to predict an implicit
status of current joint condition based on past observation history, and 3)
progressive curriculum learning to allow a single network to conduct both
normal gait and various joint-impaired gaits. We verify that our framework
enables the Unitree's Go1 robot to walk under various impaired joint conditions
in real-world indoor and outdoor environments.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00399" title="Abstract">arXiv:2403.00399</a> [<a href="/pdf/2403.00399" title="Download PDF">pdf</a>, <a href="/format/2403.00399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> As Soon as Possible but Rationally
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bruy%C3%A8re%2C+V">V&#xe9;ronique Bruy&#xe8;re</a>, 
<a href="/search/cs?searchtype=author&query=Grandmont%2C+C">Christophe Grandmont</a>, 
<a href="/search/cs?searchtype=author&query=Raskin%2C+J">Jean-Fran&#xe7;ois Raskin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages (16 without appendix), 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">This paper addresses complexity problems in rational verification and
synthesis for multi-player games played on weighted graphs, where the objective
of each player is to minimize the cost of reaching a specific set of target
vertices. In these games, one player, referred to as the system, declares his
strategy upfront. The other players, composing the environment, then rationally
make their moves according to their objectives. The rational behavior of these
responding players is captured through two models: they opt for strategies that
either represent a Nash equilibrium or lead to a play with a Pareto-optimal
cost tuple.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00401" title="Abstract">arXiv:2403.00401</a> [<a href="/pdf/2403.00401" title="Download PDF">pdf</a>, <a href="/format/2403.00401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Biomechanical Simulations Based on A Posteriori Error  Estimates: The Potential of Dual Weighted Residual-Driven Adaptive Mesh  Refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bui%2C+H+P">Huu Phuoc Bui</a>, 
<a href="/search/math?searchtype=author&query=Duprez%2C+M">Michel Duprez</a>, 
<a href="/search/math?searchtype=author&query=Rohan%2C+P">Pierre-Yves Rohan</a>, 
<a href="/search/math?searchtype=author&query=Lejeune%2C+A">Arnaud Lejeune</a>, 
<a href="/search/math?searchtype=author&query=Bordas%2C+S+P+A">Stephane P.A. Bordas</a>, 
<a href="/search/math?searchtype=author&query=Bucki%2C+M">Marek Bucki</a>, 
<a href="/search/math?searchtype=author&query=Chouly%2C+F">Franz Chouly</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The Finite Element Method (FEM) is a well-established procedure for computing
approximate solutions to deterministic engineering problems described by
partial differential equations. FEM produces discrete approximations of the
solution with a discretisation error that can be an be quantified with \emph{a
posteriori} error estimates. The practical relevance of error estimates for
biomechanics problems, especially for soft tissue where the response is
governed by large strains, is rarely addressed. In this contribution, we
propose an implementation of \emph{a posteriori} error estimates targeting a
user-defined quantity of interest, using the Dual Weighted Residual (DWR)
technique tailored to biomechanics. The proposed method considers a general
setting that encompasses three-dimensional geometries and model
non-linearities, which appear in hyperelastic soft tissues. We take advantage
of the automatic differentiation capabilities embedded in modern finite element
software, which allows the error estimates to be computed generically for a
large class of models and constitutive laws. First we validate our methodology
using experimental measurements from silicone samples, and then illustrate its
applicability for patient-specific computations of pressure ulcers on a human
heel.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00403" title="Abstract">arXiv:2403.00403</a> [<a href="/pdf/2403.00403" title="Download PDF">pdf</a>, <a href="/format/2403.00403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fractal interpolation in the context of prediction accuracy optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baicoianu%2C+A">Alexandra Baicoianu</a>, 
<a href="/search/cs?searchtype=author&query=Gavril%C4%83%2C+C+G">Cristina Gabriela Gavril&#x103;</a>, 
<a href="/search/cs?searchtype=author&query=Pacurar%2C+C+M">Cristina Maria Pacurar</a>, 
<a href="/search/cs?searchtype=author&query=Pacurar%2C+V+D">Victor Dan Pacurar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper focuses on the hypothesis of optimizing time series predictions
using fractal interpolation techniques. In general, the accuracy of machine
learning model predictions is closely related to the quality and quantitative
aspects of the data used, following the principle of \textit{garbage-in,
garbage-out}. In order to quantitatively and qualitatively augment datasets,
one of the most prevalent concerns of data scientists is to generate synthetic
data, which should follow as closely as possible the actual pattern of the
original data.
<br />This study proposes three different data augmentation strategies based on
fractal interpolation, namely the \textit{Closest Hurst Strategy},
\textit{Closest Values Strategy} and \textit{Formula Strategy}. To validate the
strategies, we used four public datasets from the literature, as well as a
private dataset obtained from meteorological records in the city of Brasov,
Romania. The prediction results obtained with the LSTM model using the
presented interpolation strategies showed a significant accuracy improvement
compared to the raw datasets, thus providing a possible answer to practical
problems in the field of remote sensing and sensor sensitivity. Moreover, our
methodologies answer some optimization-related open questions for the fractal
interpolation step using \textit{Optuna} framework.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00404" title="Abstract">arXiv:2403.00404</a> [<a href="/pdf/2403.00404" title="Download PDF">pdf</a>, <a href="/ps/2403.00404" title="Download PostScript">ps</a>, <a href="/format/2403.00404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Routing for Mobile Ad hoc Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papadimitratos%2C+P">Panagiotis Papadimitratos</a>, 
<a href="/search/cs?searchtype=author&query=Haas%2C+Z+J">Zygmunt J. Haas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/1208.3486">arXiv:1208.3486</a>, <a href="/abs/1303.7300">arXiv:1303.7300</a> by other authors
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SCS Communication Networks and Distributed Systems Modeling and
  Simulation Conference (CNDS), San Antonio, TX, January 27-31, 2002
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The emergence of the Mobile Ad Hoc Networking (MANET) technology advocates
self-organized wireless interconnection of communication devices that would
either extend or operate in concert with the wired networking infrastructure
or, possibly, evolve to autonomous networks. In either case, the proliferation
of MANET-based applications depends on a multitude of factors, with
trustworthiness being one of the primary challenges to be met. Despite the
existence of well-known security mechanisms, additional vulnerabilities and
features pertinent to this new networking paradigm might render such
traditional solutions inapplicable. In particular, the absence of a central
authorization facility in an open and distributed communication environment is
a major challenge, especially due to the need for cooperative network
operation. In particular, in MANET, any node may compromise the routing
protocol functionality by disrupting the route discovery process. In this
paper, we present a route discovery protocol that mitigates the detrimental
effects of such malicious behavior, as to provide correct connectivity
information. Our protocol guarantees that fabricated, compromised, or replayed
route replies would either be rejected or never reach back the querying node.
Furthermore, the protocol responsiveness is safeguarded under different types
of attacks that exploit the routing protocol itself. The sole requirement of
the proposed scheme is the existence of a security association between the node
initiating the query and the sought destination. Specifically, no assumption is
made regarding the intermediate nodes, which may exhibit arbitrary and
malicious behavior. The scheme is robust in the presence of a number of
non-colluding nodes, and provides accurate routing information in a timely
manner.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00405" title="Abstract">arXiv:2403.00405</a> [<a href="/pdf/2403.00405" title="Download PDF">pdf</a>, <a href="/format/2403.00405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoK: Cross-Chain Bridging Architectural Design Flaws and Mitigations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Notland%2C+J+S">Jakob Svennevik Notland</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinguye Li</a>, 
<a href="/search/cs?searchtype=author&query=Nowostawski%2C+M">Mariusz Nowostawski</a>, 
<a href="/search/cs?searchtype=author&query=Haro%2C+P+H">Peter Halland Haro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Cross-chain bridges are solutions that enable interoperability between
heterogeneous blockchains. In contrast to the underlying blockchains, the
bridges often provide inferior security guarantees and have been targets of
hacks causing damage in the range of 1.5 to 2 billion USD in 2022. The current
state of bridge architectures is that they are ambiguous, and there is next to
no notion of how different architectures and their components are related to
different vulnerabilities. Throughout this study, we have analysed 60 different
bridges and 34 bridge exploits in the last three years (2021-2023). Our
analyses identified 13 architectural components of the bridges. We linked the
components to eight types of vulnerabilities, also called design flaws. We
identified prevention measures and proposed 11 impact reduction measures based
on the existing and possible countermeasures to address the imminent exploits
of the design flaws. The results are meant to be used as guidelines for
designing and implementing secure cross-chain bridge architectures, preventing
design flaws, and mitigating the negative impacts of exploits.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00406" title="Abstract">arXiv:2403.00406</a> [<a href="/pdf/2403.00406" title="Download PDF">pdf</a>, <a href="/ps/2403.00406" title="Download PostScript">ps</a>, <a href="/format/2403.00406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Restructuring of Merkle and Verkle Trees for Enhanced  Blockchain Scalability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuznetsov%2C+O">Oleksandr Kuznetsov</a>, 
<a href="/search/cs?searchtype=author&query=Kanonik%2C+D">Dzianis Kanonik</a>, 
<a href="/search/cs?searchtype=author&query=Rusnak%2C+A">Alex Rusnak</a>, 
<a href="/search/cs?searchtype=author&query=Yezhov%2C+A">Anton Yezhov</a>, 
<a href="/search/cs?searchtype=author&query=Domin%2C+O">Oleksandr Domin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The scalability of blockchain technology remains a pivotal challenge,
impeding its widespread adoption across various sectors. This study introduces
an innovative approach to address this challenge by proposing the adaptive
restructuring of Merkle and Verkle trees, fundamental components of blockchain
architecture responsible for ensuring data integrity and facilitating efficient
verification processes. Unlike traditional static tree structures, our adaptive
model dynamically adjusts the configuration of these trees based on usage
patterns, significantly reducing the average path length required for
verification and, consequently, the computational overhead associated with
these processes. Through a comprehensive conceptual framework, we delineate the
methodology for adaptive restructuring, encompassing both binary and non-binary
tree configurations. This framework is validated through a series of detailed
examples, demonstrating the practical feasibility and the efficiency gains
achievable with our approach. Moreover, we present a comparative analysis with
existing scalability solutions, highlighting the unique advantages of adaptive
restructuring in terms of simplicity, security, and efficiency enhancement
without introducing additional complexities or dependencies. This study's
implications extend beyond theoretical advancements, offering a scalable,
secure, and efficient method for blockchain data verification that could
facilitate broader adoption of blockchain technology in finance, supply chain
management, and beyond. As the blockchain ecosystem continues to evolve, the
principles and methodologies outlined herein are poised to contribute
significantly to its growth and maturity.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00409" title="Abstract">arXiv:2403.00409</a> [<a href="/pdf/2403.00409" title="Download PDF">pdf</a>, <a href="/format/2403.00409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably Robust DPO: Aligning Language Models with Noisy Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+S+R">Sayak Ray Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Kini%2C+A">Anush Kini</a>, 
<a href="/search/cs?searchtype=author&query=Natarajan%2C+N">Nagarajan Natarajan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Learning from preference-based feedback has recently gained traction as a
promising approach to align language models with human interests. While these
aligned generative models have demonstrated impressive capabilities across
various tasks, their dependence on high-quality human preference data poses a
bottleneck in practical applications. Specifically, noisy (incorrect and
ambiguous) preference pairs in the dataset might restrict the language models
from capturing human intent accurately. While practitioners have recently
proposed heuristics to mitigate the effect of noisy preferences, a complete
theoretical understanding of their workings remain elusive.
<br />In this work, we aim to bridge this gap by by introducing a general framework
for policy optimization in the presence of random preference flips. We focus on
the direct preference optimization (DPO) algorithm in particular since it
assumes that preferences adhere to the Bradley-Terry-Luce (BTL) model, raising
concerns about the impact of noisy data on the learned policy. We design a
novel loss function, which de-bias the effect of noise on average, making a
policy trained by minimizing that loss robust to the noise. Under log-linear
parameterization of the policy class and assuming good feature coverage of the
SFT policy, we prove that the sub-optimality gap of the proposed robust DPO
(rDPO) policy compared to the optimal policy is of the order
$O(\frac{1}{1-2\epsilon}\sqrt{\frac{d}{n}})$, where $\epsilon &lt; 1/2$ is flip
rate of labels, $d$ is policy parameter dimension and $n$ is size of dataset.
Our experiments on IMDb sentiment generation and Anthropic's helpful-harmless
dataset show that rDPO is robust to noise in preference labels compared to
vanilla DPO and other heuristics proposed by practitioners.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00411" title="Abstract">arXiv:2403.00411</a> [<a href="/pdf/2403.00411" title="Download PDF">pdf</a>, <a href="/format/2403.00411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Lingual Learning vs. Low-Resource Fine-Tuning: A Case Study with  Fact-Checking in Turkish
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cekinel%2C+R+F">Recep Firat Cekinel</a>, 
<a href="/search/cs?searchtype=author&query=Karagoz%2C+P">Pinar Karagoz</a>, 
<a href="/search/cs?searchtype=author&query=Coltekin%2C+C">Cagri Coltekin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The rapid spread of misinformation through social media platforms has raised
concerns regarding its impact on public opinion. While misinformation is
prevalent in other languages, the majority of research in this field has
concentrated on the English language. Hence, there is a scarcity of datasets
for other languages, including Turkish. To address this concern, we have
introduced the FCTR dataset, consisting of 3238 real-world claims. This dataset
spans multiple domains and incorporates evidence collected from three Turkish
fact-checking organizations. Additionally, we aim to assess the effectiveness
of cross-lingual transfer learning for low-resource languages, with a
particular focus on Turkish. We demonstrate in-context learning (zero-shot and
few-shot) performance of large language models in this context. The
experimental results indicate that the dataset has the potential to advance
research in the Turkish language.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00416" title="Abstract">arXiv:2403.00416</a> [<a href="/pdf/2403.00416" title="Download PDF">pdf</a>, <a href="/format/2403.00416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-efficient Event Camera Pre-training via Disentangled Masked  Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhenpeng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yongjian Deng</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+Y">Yifeng Geng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Limin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we present a new data-efficient voxel-based self-supervised
learning method for event cameras. Our pre-training overcomes the limitations
of previous methods, which either sacrifice temporal information by converting
event sequences into 2D images for utilizing pre-trained image models or
directly employ paired image data for knowledge distillation to enhance the
learning of event streams. In order to make our pre-training data-efficient, we
first design a semantic-uniform masking method to address the learning
imbalance caused by the varying reconstruction difficulties of different
regions in non-uniform data when using random masking. In addition, we ease the
traditional hybrid masked modeling process by explicitly decomposing it into
two branches, namely local spatio-temporal reconstruction and global semantic
reconstruction to encourage the encoder to capture local correlations and
global semantics, respectively. This decomposition allows our selfsupervised
learning method to converge faster with minimal pre-training data. Compared to
previous approaches, our self-supervised learning method does not rely on
paired RGB images, yet enables simultaneous exploration of spatial and temporal
cues in multiple scales. It exhibits excellent generalization performance and
demonstrates significant improvements across various tasks with fewer
parameters and lower computational costs.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00417" title="Abstract">arXiv:2403.00417</a> [<a href="/pdf/2403.00417" title="Download PDF">pdf</a>, <a href="/ps/2403.00417" title="Download PostScript">ps</a>, <a href="/format/2403.00417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Tokenization: Crafting Better Tokenizers for Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jinbiao Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Tokenization significantly influences language models(LMs)' performance. This
paper traces the evolution of tokenizers from word-level to subword-level,
analyzing how they balance tokens and types to enhance model adaptability while
controlling complexity. Despite subword tokenizers like Byte Pair Encoding
(BPE) overcoming many word tokenizer limitations, they encounter difficulties
in handling non-Latin languages and depend heavily on extensive training data
and computational resources to grasp the nuances of multiword expressions
(MWEs). This article argues that tokenizers, more than mere technical tools,
should drawing inspiration from the cognitive science about human language
processing. This study then introduces the "Principle of Least Effort" from
cognitive science, that humans naturally seek to reduce cognitive effort, and
discusses the benefits of this principle for tokenizer development. Based on
this principle, the paper proposes that the Less-is-Better (LiB) model could be
a new approach for LLM tokenizer. The LiB model can autonomously learn an
integrated vocabulary consisting of subwords, words, and MWEs, which
effectively reduces both the numbers of tokens and types. Comparative
evaluations show that the LiB tokenizer outperforms existing word and BPE
tokenizers, presenting an innovative method for tokenizer development, and
hinting at the possibility of future cognitive science-based tokenizers being
more efficient.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00418" title="Abstract">arXiv:2403.00418</a> [<a href="/pdf/2403.00418" title="Download PDF">pdf</a>, <a href="/format/2403.00418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMs for Targeted Sentiment in News Headlines: Exploring Different  Levels of Prompt Prescriptiveness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Juro%C5%A1%2C+J">Jana Juro&#x161;</a>, 
<a href="/search/cs?searchtype=author&query=Majer%2C+L">Laura Majer</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0najder%2C+J">Jan &#x160;najder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">News headlines often evoke sentiment by intentionally portraying entities in
particular ways, making targeted sentiment analysis (TSA) of headlines a
worthwhile but difficult task. Fine-tuned encoder models show satisfactory TSA
performance, but their background knowledge is limited, and they require a
labeled dataset. LLMs offer a potentially universal solution for TSA due to
their broad linguistic and world knowledge along with in-context learning
abilities, yet their performance is heavily influenced by prompt design.
Drawing parallels with annotation paradigms for subjective tasks, we explore
the influence of prompt design on the performance of LLMs for TSA of news
headlines. We evaluate the predictive accuracy of state-of-the-art LLMs using
prompts with different levels of prescriptiveness, ranging from plain zero-shot
to elaborate few-shot prompts matching annotation guidelines. Recognizing the
subjective nature of TSA, we evaluate the ability of LLMs to quantify
predictive uncertainty via calibration error and correlation to human
inter-annotator agreement. We find that, except for few-shot prompting,
calibration and F1-score improve with increased prescriptiveness, but the
optimal level depends on the model.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00420" title="Abstract">arXiv:2403.00420</a> [<a href="/pdf/2403.00420" title="Download PDF">pdf</a>, <a href="/format/2403.00420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Deep Reinforcement Learning Through Adversarial Attacks and  Training : A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schott%2C+L">Lucas Schott</a>, 
<a href="/search/cs?searchtype=author&query=Delas%2C+J">Josephine Delas</a>, 
<a href="/search/cs?searchtype=author&query=Hajri%2C+H">Hatem Hajri</a>, 
<a href="/search/cs?searchtype=author&query=Gherbi%2C+E">Elies Gherbi</a>, 
<a href="/search/cs?searchtype=author&query=Yaich%2C+R">Reda Yaich</a>, 
<a href="/search/cs?searchtype=author&query=Boulahia-Cuppens%2C+N">Nora Boulahia-Cuppens</a>, 
<a href="/search/cs?searchtype=author&query=Cuppens%2C+F">Frederic Cuppens</a>, 
<a href="/search/cs?searchtype=author&query=Lamprier%2C+S">Sylvain Lamprier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 57 pages, 16 figues, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep Reinforcement Learning (DRL) is an approach for training autonomous
agents across various complex environments. Despite its significant performance
in well known environments, it remains susceptible to minor conditions
variations, raising concerns about its reliability in real-world applications.
To improve usability, DRL must demonstrate trustworthiness and robustness. A
way to improve robustness of DRL to unknown changes in the conditions is
through Adversarial Training, by training the agent against well suited
adversarial attacks on the dynamics of the environment. Addressing this
critical issue, our work presents an in-depth analysis of contemporary
adversarial attack methodologies, systematically categorizing them and
comparing their objectives and operational mechanisms. This classification
offers a detailed insight into how adversarial attacks effectively act for
evaluating the resilience of DRL agents, thereby paving the way for enhancing
their robustness.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00424" title="Abstract">arXiv:2403.00424</a> [<a href="/pdf/2403.00424" title="Download PDF">pdf</a>, <a href="/format/2403.00424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Based Control of Continuous-Time Linear Systems with Performance  Specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lopez%2C+V+G">Victor G. Lopez</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%BCller%2C+M+A">Matthias A. M&#xfc;ller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The design of direct data-based controllers has become a fundamental part of
control theory research in the last few years. In this paper, we consider three
classes of data-based state feedback control problems for linear systems. These
control problems are such that, besides stabilization, some additional
performance requirements must be satisfied. First, we formulate and solve a
trajectory-reference control problem, on which desired closed-loop trajectories
are known and a controller that allows the system to closely follow those
trajectories is computed. Then, in the area of data-based optimal control, we
solve two different problems: the inverse problem of optimal control, and the
solution of the LQR problem for continuous-time systems. Finally, we consider
the case in which the precise position of the desired poles of the closed-loop
system is known, and introduce a data-based variant of a robust pole-placement
procedure. Although we focus on continuous-time systems, all of the presented
methods can also be easily formulated for the discrete-time case. The
applicability of the proposed methods is tested using numerical simulations.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00425" title="Abstract">arXiv:2403.00425</a> [<a href="/pdf/2403.00425" title="Download PDF">pdf</a>, <a href="/format/2403.00425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HALC: Object Hallucination Reduction via Adaptive Focal-Contrast  Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhaorun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhuokai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Hongyin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Huaxiu Yao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiawei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is released at <a href="https://github.com/BillChan226/HALC">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">While large vision-language models (LVLMs) have demonstrated impressive
capabilities in interpreting multi-modal contexts, they invariably suffer from
object hallucinations (OH). We introduce HALC, a novel decoding algorithm
designed to mitigate OH in LVLMs. HALC leverages distinct fine-grained optimal
visual information in vision-language tasks and operates on both local and
global contexts simultaneously. Specifically, HALC integrates a robust
auto-focal grounding mechanism (locally) to correct hallucinated tokens on the
fly, and a specialized beam search algorithm (globally) to significantly reduce
OH while preserving text generation quality. Additionally, HALC can be
integrated into any LVLMs as a plug-and-play module without extra training.
Extensive experimental studies demonstrate the effectiveness of HALC in
reducing OH, outperforming state-of-the-arts across four benchmarks.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00426" title="Abstract">arXiv:2403.00426</a> [<a href="/pdf/2403.00426" title="Download PDF">pdf</a>, <a href="/format/2403.00426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Computed Tomography based on the Defrise and Clack  Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+C">Chengze Ye</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+L">Linda-Sophie Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yipeng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Maier%2C+A">Andreas Maier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This study presents a novel approach for reconstructing cone beam computed
tomography (CBCT) for specific orbits using known operator learning. Unlike
traditional methods, this technique employs a filtered backprojection type
(FBP-type) algorithm, which integrates a unique, adaptive filtering process.
This process involves a series of operations, including weightings,
differentiations, the 2D Radon transform, and backprojection. The filter is
designed for a specific orbit geometry and is obtained using a data-driven
approach based on deep learning. The approach efficiently learns and optimizes
the orbit-related component of the filter. The method has demonstrated its
ability through experimentation by successfully learning parameters from
circular orbit projection data. Subsequently, the optimized parameters are used
to reconstruct images, resulting in outcomes that closely resemble the
analytical solution. This demonstrates the potential of the method to learn
appropriate parameters from any specific orbit projection data and achieve
reconstruction. The algorithm has demonstrated improvement, particularly in
enhancing reconstruction speed and reducing memory usage for handling specific
orbit reconstruction.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00430" title="Abstract">arXiv:2403.00430</a> [<a href="/pdf/2403.00430" title="Download PDF">pdf</a>, <a href="/ps/2403.00430" title="Download PostScript">ps</a>, <a href="/format/2403.00430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introducing locality in some generalized AG codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pacifico%2C+B">Bastien Pacifico</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Algebraic Geometry (math.AG)

</div>
<p class="mathjax">In 1999, Xing, Niederreiter and Lam introduced a generalization of AG codes
using the evaluation at non-rational places of a function field. In this paper,
we show that one can obtain a locality parameter $r$ in such codes by using
only non-rational places of degrees at most $r$. This is, up to the author's
knowledge, a new way to construct locally recoverable codes (LRCs). We give an
example of such a code reaching the Singleton-like bound for LRCs, and show the
parameters obtained for some longer codes over $\mathbb F_3$. We then
investigate similarities with certain concatenated codes. Contrary to previous
methods, our construction allows one to obtain directly codes whose dimension
is not a multiple of the locality. Finally, we give an asymptotic study using
the Garcia-Stichtenoth tower of function fields, for both our construction and
a construction of concatenated codes. We give explicit infinite families of
LRCs with locality 2 over any finite field of cardinality greater than 3
following our new approach.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00431" title="Abstract">arXiv:2403.00431</a> [<a href="/pdf/2403.00431" title="Download PDF">pdf</a>, <a href="/ps/2403.00431" title="Download PostScript">ps</a>, <a href="/format/2403.00431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robotic Process Automation as a Driver for Sustainable Innovation and  Entrepreneurship
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prucha%2C+P">Petr Prucha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> XB-CON International Conference 2023, Zelezna Ruda, Czechia
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Technological innovation plays a crucial role in driving economic growth and
development. In this study, we investigate the extent to which technological
innovation contributes to a more sustainable future and fosters
entrepreneurship. To examine this, we focus on robotic process automation (RPA)
highly relevant technology. We conducted a comprehensive analysis by examining
the usage of RPA and its impact on environmental, social, and governance (ESG)
factors. Our research involved gathering data from the 300 largest companies in
terms of market capitalization. We assessed whether these companies used RPA
and obtained their corresponding ESG ratings. To investigate the relationship
between RPA and ESG, we employed a contingency table analysis, which involved
categorizing the data based on ESG ratings. We further used Pearson's
Chi-square Test of Independence to assess the impact of RPA on ESG. Our
findings revealed a statistically significant association between RPA and ESG
ratings, indicating their interconnection. The calculated value for Pearson's
Chi-square Test of Independence was 6.54, with a corresponding p-value of
0.0381. This indicates that at a significance level of five percent, the RPA
and ESG variables depend on each other. These results suggest that RPA,
representative of modern technologies, likely influences the achievement of a
sustainable future and the promotion of entrepreneurship. In conclusion, our
study provides empirical evidence supporting the notion that technological
innovations such as RPA have the potential to positively shape sustainability
efforts and entrepreneurial endeavours.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00433" title="Abstract">arXiv:2403.00433</a> [<a href="/pdf/2403.00433" title="Download PDF">pdf</a>, <a href="/format/2403.00433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jiagu: Optimizing Serverless Computing Resource Utilization with  Harmonized Efficiency and Practicability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qingyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yanning Yang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+D">Dong Du</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yubin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Ping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jia Feng</a>, 
<a href="/search/cs?searchtype=author&query=Larus%2C+J">James Larus</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haibo Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Current serverless platforms struggle to optimize resource utilization due to
their dynamic and fine-grained nature. Conventional techniques like
overcommitment and autoscaling fall short, often sacrificing utilization for
practicability or incurring performance trade-offs. Overcommitment requires
predicting performance to prevent QoS violation, introducing trade-off between
prediction accuracy and overheads. Autoscaling requires scaling instances in
response to load fluctuations quickly to reduce resource wastage, but more
frequent scaling also leads to more cold start overheads. This paper introduces
Jiagu, which harmonizes efficiency with practicability through two novel
techniques. First, pre-decision scheduling achieves accurate prediction while
eliminating overheads by decoupling prediction and scheduling. Second,
dual-staged scaling achieves frequent adjustment of instances with minimum
overhead. We have implemented a prototype and evaluated it using real-world
applications and traces from the public cloud platform. Our evaluation shows a
54.8% improvement in deployment density over commercial clouds (with
Kubernetes) while maintaining QoS, and 81.0%--93.7% lower scheduling costs and
a 57.4%--69.3% reduction in cold start latency compared to existing QoS-aware
schedulers in research work.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00434" title="Abstract">arXiv:2403.00434</a> [<a href="/pdf/2403.00434" title="Download PDF">pdf</a>, <a href="/format/2403.00434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Semantic Communication over Wireless Networks with Rate  Splitting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhouxiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhaohui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Ye Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qianqian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoyang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, the problem of joint transmission and computation resource
allocation for probabilistic semantic communication (PSC) system with rate
splitting multiple access (RSMA) is investigated. In the considered model, the
base station (BS) needs to transmit a large amount of data to multiple users
with RSMA. Due to limited communication resources, the BS is required to
utilize semantic communication techniques to compress the large-sized data. The
semantic communication is enabled by shared probability graphs between the BS
and the users. The probability graph can be used to further compress the
transmission data at the BS, while the received compressed semantic information
can be recovered through using the same shared probability graph at each user
side. The semantic information compression progress consumes additional
computation power at the BS, which inevitably decreases the transmission power
due to limited total power budget. Considering both the effect of semantic
compression ratio and computation power, the semantic rate expression for RSMA
is first obtained. Then, based on the obtained rate expression, an optimization
problem is formulated with the aim of maximizing the sum of semantic rates of
all users under total power, semantic compression ratio, and rate allocation
constraints. To tackle this problem, an iterative algorithm is proposed, where
the rate allocation and transmit beamforming design subproblem is solved using
a successive convex approximation method, and the semantic compression ratio
subproblem is addressed using a greedy algorithm. Numerical results validate
the effectiveness of the proposed scheme.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00435" title="Abstract">arXiv:2403.00435</a> [<a href="/pdf/2403.00435" title="Download PDF">pdf</a>, <a href="/format/2403.00435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Indexing for Retrieval-Augmented Opinion Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hosking%2C+T">Tom Hosking</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Lapata%2C+M">Mirella Lapata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We propose a method for unsupervised abstractive opinion summarization, that
combines the attributability and scalability of extractive approaches with the
coherence and fluency of Large Language Models (LLMs). Our method, HIRO, learns
an index structure that maps sentences to a path through a semantically
organized discrete hierarchy. At inference time, we populate the index and use
it to identify and retrieve clusters of sentences containing popular opinions
from input reviews. Then, we use a pretrained LLM to generate a readable
summary that is grounded in these extracted evidential clusters. The modularity
of our approach allows us to evaluate its efficacy at each stage. We show that
HIRO learns an encoding space that is more semantically structured than prior
work, and generates summaries that are more representative of the opinions in
the input reviews. Human evaluation confirms that HIRO generates more coherent,
detailed and accurate summaries that are significantly preferred by annotators
compared to prior work.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00436" title="Abstract">arXiv:2403.00436</a> [<a href="/pdf/2403.00436" title="Download PDF">pdf</a>, <a href="/format/2403.00436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Abductive Ego-View Accident Video Understanding for Safe Driving  Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jianwu Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei-lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Junfei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Junbin Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hongkai Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+C">Chen Lv</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Jianru Xue</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR2024. This is not the camera-ready version. The Project page: <a href="http://www.lotvsmmau.net">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present MM-AU, a novel dataset for Multi-Modal Accident video
Understanding. MM-AU contains 11,727 in-the-wild ego-view accident videos, each
with temporally aligned text descriptions. We annotate over 2.23 million object
boxes and 58,650 pairs of video-based accident reasons, covering 58 accident
categories. MM-AU supports various accident understanding tasks, particularly
multimodal video diffusion to understand accident cause-effect chains for safe
driving. With MM-AU, we present an Abductive accident Video understanding
framework for Safe Driving perception (AdVersa-SD). AdVersa-SD performs video
diffusion via an Object-Centric Video Diffusion (OAVD) method which is driven
by an abductive CLIP model. This model involves a contrastive interaction loss
to learn the pair co-occurrence of normal, near-accident, accident frames with
the corresponding text descriptions, such as accident reasons, prevention
advice, and accident categories. OAVD enforces the causal region learning while
fixing the content of the original frame background in video generation, to
find the dominant cause-effect chain for certain accidents. Extensive
experiments verify the abductive ability of AdVersa-SD and the superiority of
OAVD against the state-of-the-art diffusion models. Additionally, we provide
careful benchmark evaluations for object detection and accident reason
answering since AdVersa-SD relies on precise object and accident reason
information.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00437" title="Abstract">arXiv:2403.00437</a> [<a href="/pdf/2403.00437" title="Download PDF">pdf</a>, <a href="/format/2403.00437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LoMOE: Localized Multi-Object Editing via Multi-Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakrabarty%2C+G">Goirik Chakrabarty</a>, 
<a href="/search/cs?searchtype=author&query=Chandrasekar%2C+A">Aditya Chandrasekar</a>, 
<a href="/search/cs?searchtype=author&query=Hebbalaguppe%2C+R">Ramya Hebbalaguppe</a>, 
<a href="/search/cs?searchtype=author&query=AP%2C+P">Prathosh AP</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent developments in the field of diffusion models have demonstrated an
exceptional capacity to generate high-quality prompt-conditioned image edits.
Nevertheless, previous approaches have primarily relied on textual prompts for
image editing, which tend to be less effective when making precise edits to
specific objects or fine-grained regions within a scene containing
single/multiple objects. We introduce a novel framework for zero-shot localized
multi-object editing through a multi-diffusion process to overcome this
challenge. This framework empowers users to perform various operations on
objects within an image, such as adding, replacing, or editing $\textbf{many}$
objects in a complex scene $\textbf{in one pass}$. Our approach leverages
foreground masks and corresponding simple text prompts that exert localized
influences on the target regions resulting in high-fidelity image editing. A
combination of cross-attention and background preservation losses within the
latent space ensures that the characteristics of the object being edited are
preserved while simultaneously achieving a high-quality, seamless
reconstruction of the background with fewer artifacts compared to the current
methods. We also curate and release a dataset dedicated to multi-object
editing, named $\texttt{LoMOE}$-Bench. Our experiments against existing
state-of-the-art methods demonstrate the improved effectiveness of our approach
in terms of both image editing quality and inference speed.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00438" title="Abstract">arXiv:2403.00438</a> [<a href="/pdf/2403.00438" title="Download PDF">pdf</a>, <a href="/format/2403.00438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Your Model Is Not Predicting Depression Well And That Is Why: A Case  Study of PRIMATE Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Milintsevich%2C+K">Kirill Milintsevich</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Sirts%2C+K">Kairit Sirts</a> (2), 
<a href="/search/cs?searchtype=author&query=Dias%2C+G">Ga&#xeb;l Dias</a> (1) ((1) University of Caen Normandy, (2) University of Tartu)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper addresses the quality of annotations in mental health datasets
used for NLP-based depression level estimation from social media texts. While
previous research relies on social media-based datasets annotated with binary
categories, i.e. depressed or non-depressed, recent datasets such as D2S and
PRIMATE aim for nuanced annotations using PHQ-9 symptoms. However, most of
these datasets rely on crowd workers without the domain knowledge for
annotation. Focusing on the PRIMATE dataset, our study reveals concerns
regarding annotation validity, particularly for the lack of interest or
pleasure symptom. Through reannotation by a mental health professional, we
introduce finer labels and textual spans as evidence, identifying a notable
number of false positives. Our refined annotations, to be released under a Data
Use Agreement, offer a higher-quality test set for anhedonia detection. This
study underscores the necessity of addressing annotation quality issues in
mental health datasets, advocating for improved methodologies to enhance NLP
model reliability in mental health assessments.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00439" title="Abstract">arXiv:2403.00439</a> [<a href="/pdf/2403.00439" title="Download PDF">pdf</a>, <a href="/format/2403.00439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Authors&#x27; Values and Attitudes Towards AI-bridged Scalable  Personalization of Creative Language Arts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taewook Kim</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+H">Hyomin Han</a>, 
<a href="/search/cs?searchtype=author&query=Adar%2C+E">Eytan Adar</a>, 
<a href="/search/cs?searchtype=author&query=Kay%2C+M">Matthew Kay</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+J+J+Y">John Joon Young Chung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures, 2 tables. Accepted to ACM CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generative AI has the potential to create a new form of interactive media:
AI-bridged creative language arts (CLA), which bridge the author and audience
by personalizing the author's vision to the audience's context and taste at
scale. However, it is unclear what the authors' values and attitudes would be
regarding AI-bridged CLA. To identify these values and attitudes, we conducted
an interview study with 18 authors across eight genres (e.g., poetry, comics)
by presenting speculative but realistic AI-bridged CLA scenarios. We identified
three benefits derived from the dynamics between author, artifact, and
audience: those that 1) authors get from the process, 2) audiences get from the
artifact, and 3) authors get from the audience. We found how AI-bridged CLA
would either promote or reduce these benefits, along with authors' concerns. We
hope our investigation hints at how AI can provide intriguing experiences to
CLA audiences while promoting authors' values.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00446" title="Abstract">arXiv:2403.00446</a> [<a href="/pdf/2403.00446" title="Download PDF">pdf</a>, <a href="/format/2403.00446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Hybrid-Action Reinforcement Learning-Based Decision and Control for  Discretionary Lane Change
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruichen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jinming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuan Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Autonomous lane-change, a key feature of advanced driver-assistance systems,
can enhance traffic efficiency and reduce the incidence of accidents. However,
safe driving of autonomous vehicles remains challenging in complex
environments. How to perform safe and appropriate lane change is a popular
topic of research in the field of autonomous driving. Currently, few papers
consider the safety of reinforcement learning in autonomous lane-change
scenarios. We introduce safe hybrid-action reinforcement learning into
discretionary lane change for the first time and propose Parameterized Soft
Actor-Critic with PID Lagrangian (PASAC-PIDLag) algorithm. Furthermore, we
conduct a comparative analysis of the Parameterized Soft Actor-Critic (PASAC),
which is an unsafe version of PASAC-PIDLag. Both algorithms are employed to
train the lane-change strategy of autonomous vehicles to output discrete
lane-change decision and longitudinal vehicle acceleration. Our simulation
results indicate that at a traffic density of 15 vehicles per kilometer (15
veh/km), the PASAC-PIDLag algorithm exhibits superior safety with a collision
rate of 0%, outperforming the PASAC algorithm, which has a collision rate of
1%. The outcomes of the generalization assessments reveal that at low traffic
density levels, both the PASAC-PIDLag and PASAC algorithms are proficient in
attaining a 0% collision rate. Under conditions of high traffic flow density,
the PASAC-PIDLag algorithm surpasses PASAC in terms of both safety and
optimality.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00448" title="Abstract">arXiv:2403.00448</a> [<a href="/pdf/2403.00448" title="Download PDF">pdf</a>, <a href="/format/2403.00448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Large Language Models Confront Repository-Level Automatic Program  Repair: How Well They Done?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxiao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jingzheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+X">Xiang Ling</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changjiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Rui%2C+Z">Zhiqing Rui</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+T">Tianyue Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yanjun Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICSE 2024 Industry Challenge Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">In recent years, large language models (LLMs) have demonstrated substantial
potential in addressing automatic program repair (APR) tasks. However, the
current evaluation of these models for APR tasks focuses solely on the limited
context of the single function or file where the bug is located, overlooking
the valuable information in the repository-level context. This paper
investigates the performance of popular LLMs in handling repository-level
repair tasks. We introduce RepoBugs, a new benchmark comprising 124 typical
repository-level bugs from open-source repositories. Preliminary experiments
using GPT3.5 based on the function where the error is located, reveal that the
repair rate on RepoBugs is only 22.58%, significantly diverging from the
performance of GPT3.5 on function-level bugs in related studies. This
underscores the importance of providing repository-level context when
addressing bugs at this level. However, the repository-level context offered by
the preliminary method often proves redundant and imprecise and easily exceeds
the prompt length limit of LLMs. To solve the problem, we propose a simple and
universal repository-level context extraction method (RLCE) designed to provide
more precise context for repository-level code repair tasks. Evaluations of
three mainstream LLMs show that RLCE significantly enhances the ability to
repair repository-level bugs. The improvement reaches a maximum of 160%
compared to the preliminary method. Additionally, we conduct a comprehensive
analysis of the effectiveness and limitations of RLCE, along with the capacity
of LLMs to address repository-level bugs, offering valuable insights for future
research.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00450" title="Abstract">arXiv:2403.00450</a> [<a href="/pdf/2403.00450" title="Download PDF">pdf</a>, <a href="/format/2403.00450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel Hyperparameter Optimization Of Spiking Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Firmin%2C+T">Thomas Firmin</a>, 
<a href="/search/cs?searchtype=author&query=Boulet%2C+P">Pierre Boulet</a>, 
<a href="/search/cs?searchtype=author&query=Talbi%2C+E">El-Ghazali Talbi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Spiking Neural Networks (SNN). SNNs are based on a more biologically inspired
approach than usual artificial neural networks. Such models are characterized
by complex dynamics between neurons and spikes. These are very sensitive to the
hyperparameters, making their optimization challenging. To tackle
hyperparameter optimization of SNNs, we initially extended the signal loss
issue of SNNs to what we call silent networks. These networks fail to emit
enough spikes at their outputs due to mistuned hyperparameters or architecture.
Generally, search spaces are heavily restrained, sometimes even discretized, to
prevent the sampling of such networks. By defining an early stopping criterion
detecting silent networks and by designing specific constraints, we were able
to instantiate larger and more flexible search spaces. We applied a constrained
Bayesian optimization technique, which was asynchronously parallelized, as the
evaluation time of a SNN is highly stochastic. Large-scale experiments were
carried-out on a multi-GPU Petascale architecture. By leveraging silent
networks, results show an acceleration of the search, while maintaining good
performances of both the optimization algorithm and the best solution obtained.
We were able to apply our methodology to two popular training algorithms, known
as spike timing dependent plasticity and surrogate gradient. Early detection
allowed us to prevent worthless and costly computation, directing the search
toward promising hyperparameter combinations. Our methodology could be applied
to multi-objective problems, where the spiking activity is often minimized to
reduce the energy consumption. In this scenario, it becomes essential to find
the delicate frontier between low-spiking and silent networks. Finally, our
approach may have implications for neural architecture search, particularly in
defining suitable spiking architectures.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00452" title="Abstract">arXiv:2403.00452</a> [<a href="/pdf/2403.00452" title="Download PDF">pdf</a>, <a href="/format/2403.00452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Ordinal Diffusion Model for Generating Medical Images with Different  Severity Levels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Takezaki%2C+S">Shumpei Takezaki</a>, 
<a href="/search/cs?searchtype=author&query=Uchida%2C+S">Seiichi Uchida</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ISBI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion models have recently been used for medical image generation because
of their high image quality. In this study, we focus on generating medical
images with ordinal classes, which have ordinal relationships, such as severity
levels. We propose an Ordinal Diffusion Model (ODM) that controls the ordinal
relationships of the estimated noise images among the classes. Our model was
evaluated experimentally by generating retinal and endoscopic images of
multiple severity classes. ODM achieved higher performance than conventional
generative models by generating realistic images, especially in high-severity
classes with fewer training samples.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00454" title="Abstract">arXiv:2403.00454</a> [<a href="/pdf/2403.00454" title="Download PDF">pdf</a>, <a href="/format/2403.00454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shorts vs. Regular Videos on YouTube: A Comparative Analysis of User  Engagement and Content Creation Trends
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Violot%2C+C">Caroline Violot</a> (University of Lausanne), 
<a href="/search/cs?searchtype=author&query=Elmas%2C+T">Tu&#x11f;rulcan Elmas</a> (Indiana University Bloomington), 
<a href="/search/cs?searchtype=author&query=Bilogrevic%2C+I">Igor Bilogrevic</a> (Google), 
<a href="/search/cs?searchtype=author&query=Humbert%2C+M">Mathias Humbert</a> (University of Lausanne)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 9 figures, to be published in the proceedings of ACM Web Science Conference 2024 (WEBSCI24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">YouTube introduced the Shorts video format in 2021, allowing users to upload
short videos that are prominently displayed on its website and app. Despite
having such a large visual footprint, there are no studies to date that have
looked at the impact Shorts introduction had on the production and consumption
of content on YouTube. This paper presents the first comparative analysis of
YouTube Shorts versus regular videos with respect to user engagement (i.e.,
views, likes, and comments), content creation frequency and video categories.
We collected a dataset containing information about 70k channels that posted at
least one Short, and we analyzed the metadata of all the videos (9.9M Shorts
and 6.9M regular videos) they uploaded between January 2021 and December 2022,
spanning a two-year period including the introduction of Shorts. Our
longitudinal analysis shows that content creators consistently increased the
frequency of Shorts production over this period, especially for newly-created
channels, which surpassed that of regular videos. We also observe that Shorts
target mostly entertainment categories, while regular videos cover a wide
variety of categories. In general, Shorts attract more views and likes per view
than regular videos, but attract less comments per view. However, Shorts do not
outperform regular videos in the education and political categories as much as
they do in other categories. Our study contributes to understanding social
media dynamics, to quantifying the spread of short-form content, and to
motivating future research on its impact on society.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00455" title="Abstract">arXiv:2403.00455</a> [<a href="/pdf/2403.00455" title="Download PDF">pdf</a>, <a href="/ps/2403.00455" title="Download PostScript">ps</a>, <a href="/format/2403.00455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Self-healing Software System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yazdanparast%2C+Z">Zahra Yazdanparast</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">With the increasing complexity of software systems, it becomes very difficult
to install, configure, adjust, and maintain them. As systems become more
interconnected and diverse, system architects are less able to predict and
design the interaction between components, deferring the handling of these
issues to runtime. One of the important problems that occur during execution is
system failures, which increase the need for self-healing systems. The main
purpose of self-healing is to have an automatic system that can heal itself
without human intervention. This system has predefined actions and procedures
that are suitable for recovering the system from different failure modes. In
this study, different self-healing methods are categorized and a summary of
them is presented.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00459" title="Abstract">arXiv:2403.00459</a> [<a href="/pdf/2403.00459" title="Download PDF">pdf</a>, <a href="/format/2403.00459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deformable One-shot Face Stylization via DINO Semantic Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zichong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hui Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024. Project page: \url{<a href="https://github.com/zichongc/DoesFS">this https URL</a>}
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper addresses the complex issue of one-shot face stylization, focusing
on the simultaneous consideration of appearance and structure, where previous
methods have fallen short. We explore deformation-aware face stylization that
diverges from traditional single-image style reference, opting for a real-style
image pair instead. The cornerstone of our method is the utilization of a
self-supervised vision transformer, specifically DINO-ViT, to establish a
robust and consistent facial structure representation across both real and
style domains. Our stylization process begins by adapting the StyleGAN
generator to be deformation-aware through the integration of spatial
transformers (STN). We then introduce two innovative constraints for generator
fine-tuning under the guidance of DINO semantics: i) a directional deformation
loss that regulates directional vectors in DINO space, and ii) a relative
structural consistency constraint based on DINO token self-similarities,
ensuring diverse generation. Additionally, style-mixing is employed to align
the color generation with the reference, minimizing inconsistent
correspondences. This framework delivers enhanced deformability for general
one-shot face stylization, achieving notable efficiency with a fine-tuning
duration of approximately 10 minutes. Extensive qualitative and quantitative
comparisons demonstrate our superiority over state-of-the-art one-shot face
stylization methods. Code is available at
\url{https://github.com/zichongc/DoesFS}.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00462" title="Abstract">arXiv:2403.00462</a> [<a href="/pdf/2403.00462" title="Download PDF">pdf</a>, <a href="/format/2403.00462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LUCID: LLM-Generated Utterances for Complex and Interesting Dialogues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stacey%2C+J">Joe Stacey</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jianpeng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Torr%2C+J">John Torr</a>, 
<a href="/search/cs?searchtype=author&query=Guigue%2C+T">Tristan Guigue</a>, 
<a href="/search/cs?searchtype=author&query=Driesen%2C+J">Joris Driesen</a>, 
<a href="/search/cs?searchtype=author&query=Coca%2C+A">Alexandru Coca</a>, 
<a href="/search/cs?searchtype=author&query=Gaynor%2C+M">Mark Gaynor</a>, 
<a href="/search/cs?searchtype=author&query=Johannsen%2C+A">Anders Johannsen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Virtual assistants are poised to take a dramatic leap forward in terms of
their dialogue capabilities, spurred by recent advances in transformer-based
Large Language Models (LLMs). Yet a major bottleneck to achieving genuinely
transformative task-oriented dialogue capabilities remains the scarcity of high
quality and linguistically sophisticated data. Existing datasets, while
impressive in scale, have limited domain coverage and contain few genuinely
challenging conversational phenomena; those which are present are typically
unlabelled, making it difficult to assess the strengths and weaknesses of
models without time-consuming and costly human evaluation. Moreover, creating
high quality dialogue data has until now required considerable human input,
limiting both the scale of these datasets and the ability to rapidly bootstrap
data for a new target domain. We aim to overcome these issues with LUCID, a
modularised and highly automated LLM-driven data generation system that
produces realistic, diverse and challenging dialogues. We use LUCID to generate
a seed dataset of 4,277 multi-domain, multi-intent conversations across 100
intents to demonstrate its capabilities. The generated conversations include a
wide range of challenging phenomena and diverse user behaviour, conveniently
identifiable via a set of turn-level tags. Finally, we provide separate test
sets for seen and unseen intents, allowing for convenient out-of-distribution
evaluation. We release both the data generation code and the dataset itself.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00464" title="Abstract">arXiv:2403.00464</a> [<a href="/pdf/2403.00464" title="Download PDF">pdf</a>, <a href="/format/2403.00464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attacking Delay-based PUFs with Minimal Adversary Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fei%2C+H">Hongming Fei</a>, 
<a href="/search/cs?searchtype=author&query=Millwood%2C+O">Owen Millwood</a>, 
<a href="/search/cs?searchtype=author&query=Gope%2C+P">Prosanta Gope</a>, 
<a href="/search/cs?searchtype=author&query=Miskelly%2C+J">Jack Miskelly</a>, 
<a href="/search/cs?searchtype=author&query=Sikdar%2C+B">Biplab Sikdar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures, journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Physically Unclonable Functions (PUFs) provide a streamlined solution for
lightweight device authentication. Delay-based Arbiter PUFs, with their ease of
implementation and vast challenge space, have received significant attention;
however, they are not immune to modelling attacks that exploit correlations
between their inputs and outputs. Research is therefore polarized between
developing modelling-resistant PUFs and devising machine learning attacks
against them. This dichotomy often results in exaggerated concerns and
overconfidence in PUF security, primarily because there lacks a universal tool
to gauge a PUF's security. In many scenarios, attacks require additional
information, such as PUF type or configuration parameters. Alarmingly, new PUFs
are often branded `secure' if they lack a specific attack model upon
introduction. To impartially assess the security of delay-based PUFs, we
present a generic framework featuring a Mixture-of-PUF-Experts (MoPE) structure
for mounting attacks on various PUFs with minimal adversarial knowledge, which
provides a way to compare their performance fairly and impartially. We
demonstrate the capability of our model to attack different PUF types,
including the first successful attack on Heterogeneous Feed-Forward PUFs using
only a reasonable amount of challenges and responses. We propose an extension
version of our model, a Multi-gate Mixture-of-PUF-Experts (MMoPE) structure,
facilitating multi-task learning across diverse PUFs to recognise commonalities
across PUF designs. This allows a streamlining of training periods for
attacking multiple PUFs simultaneously. We conclude by showcasing the potent
performance of MoPE and MMoPE across a spectrum of PUF types, employing
simulated, real-world unbiased, and biased data sets for analysis.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00465" title="Abstract">arXiv:2403.00465</a> [<a href="/pdf/2403.00465" title="Download PDF">pdf</a>, <a href="/format/2403.00465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polyamorous Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C4%85sieniec%2C+L">Leszek G&#x105;sieniec</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+B">Benjamin Smith</a>, 
<a href="/search/cs?searchtype=author&query=Wild%2C+S">Sebastian Wild</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Social and Information Networks (cs.SI); Optimization and Control (math.OC)

</div>
<p class="mathjax">Finding schedules for pairwise meetings between the members of a complex
social group without creating interpersonal conflict is challenging, especially
when different relationships have different needs. We formally define and study
the underlying optimisation problem: Polyamorous Scheduling.
<br />In Polyamorous Scheduling, we are given an edge-weighted graph and try to
find a periodic schedule of matchings in this graph such that the maximal
weighted waiting time between consecutive occurrences of the same edge is
minimised. We show that the problem is NP-hard and that there is no efficient
approximation algorithm with a better ratio than 13/12 unless P = NP. On the
positive side, we obtain an $O(\log n)$-approximation algorithm. We also define
a generalisation of density from the Pinwheel Scheduling Problem, "poly
density", and ask whether there exists a poly density threshold similar to the
5/6-density threshold for Pinwheel Scheduling [Kawamura, STOC 2024].
Polyamorous Scheduling is a natural generalisation of Pinwheel Scheduling with
respect to its optimisation variant, Bamboo Garden Trimming.
<br />Our work contributes the first nontrivial hardness-of-approximation reduction
for any periodic scheduling problem, and opens up numerous avenues for further
study of Polyamorous Scheduling.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00467" title="Abstract">arXiv:2403.00467</a> [<a href="/pdf/2403.00467" title="Download PDF">pdf</a>, <a href="/format/2403.00467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When ControlNet Meets Inexplicit Masks: A Case Study of ControlNet on  its Contour-following Ability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xuan%2C+W">Wenjie Xuan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yufei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shanshan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chaoyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Juhua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Bo Du</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">ControlNet excels at creating content that closely matches precise contours
in user-provided masks. However, when these masks contain noise, as a frequent
occurrence with non-expert users, the output would include unwanted artifacts.
This paper first highlights the crucial role of controlling the impact of these
inexplicit masks with diverse deterioration levels through in-depth analysis.
Subsequently, to enhance controllability with inexplicit masks, an advanced
Shape-aware ControlNet consisting of a deterioration estimator and a
shape-prior modulation block is devised. The deterioration estimator assesses
the deterioration factor of the provided masks. Then this factor is utilized in
the modulation block to adaptively modulate the model's contour-following
ability, which helps it dismiss the noise part in the inexplicit masks.
Extensive experiments prove its effectiveness in encouraging ControlNet to
interpret inaccurate spatial conditions robustly rather than blindly following
the given contours. We showcase application scenarios like modifying shape
priors and composable shape-controllable generation. Codes are soon available.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00473" title="Abstract">arXiv:2403.00473</a> [<a href="/pdf/2403.00473" title="Download PDF">pdf</a>, <a href="/format/2403.00473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computer-Controlled 3D Freeform Surface Weaving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiangjia Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+L+M">Lip M. Lai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zishun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+C">Chengkai Dai</a>, 
<a href="/search/cs?searchtype=author&query=Leung%2C+I+C+W">Isaac C.W. Leung</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C+C+L">Charlie C.L. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yam%2C+Y">Yeung Yam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Robotics (cs.RO); Systems and Control (eess.SY)

</div>
<p class="mathjax">In this paper, we present a new computer-controlled weaving technology that
enables the fabrication of woven structures in the shape of given 3D surfaces
by using threads in non-traditional materials with high bending-stiffness,
allowing for multiple applications with the resultant woven fabrics. A new
weaving machine and a new manufacturing process are developed to realize the
function of 3D surface weaving by the principle of short-row shaping. A
computational solution is investigated to convert input 3D freeform surfaces
into the corresponding weaving operations (indicated as W-code) to guide the
operation of this system. A variety of examples using cotton threads,
conductive threads and optical fibres are fabricated by our prototype system to
demonstrate its functionality.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00476" title="Abstract">arXiv:2403.00476</a> [<a href="/pdf/2403.00476" title="Download PDF">pdf</a>, <a href="/format/2403.00476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TempCompass: Do Video LLMs Really Understand Videos?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shicheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Shuhuai Ren</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sishuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Lu Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, there is a surge in interest surrounding video large language
models (Video LLMs). However, existing benchmarks fail to provide a
comprehensive feedback on the temporal perception ability of Video LLMs. On the
one hand, most of them are unable to distinguish between different temporal
aspects (e.g., speed, direction) and thus cannot reflect the nuanced
performance on these specific aspects. On the other hand, they are limited in
the diversity of task formats (e.g., only multi-choice QA), which hinders the
understanding of how temporal perception performance may vary across different
types of tasks. Motivated by these two problems, we propose the
\textbf{TempCompass} benchmark, which introduces a diversity of temporal
aspects and task formats. To collect high-quality test data, we devise two
novel strategies: (1) In video collection, we construct conflicting videos that
share the same static content but differ in a specific temporal aspect, which
prevents Video LLMs from leveraging single-frame bias or language priors. (2)
To collect the task instructions, we propose a paradigm where humans first
annotate meta-information for a video and then an LLM generates the
instruction. We also design an LLM-based approach to automatically and
accurately evaluate the responses from Video LLMs. Based on TempCompass, we
comprehensively evaluate 8 state-of-the-art (SOTA) Video LLMs and 3 Image LLMs,
and reveal the discerning fact that these models exhibit notably poor temporal
perception ability. Our data will be available at
\url{https://github.com/llyx97/TempCompass}.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00482" title="Abstract">arXiv:2403.00482</a> [<a href="/pdf/2403.00482" title="Download PDF">pdf</a>, <a href="/ps/2403.00482" title="Download PostScript">ps</a>, <a href="/format/2403.00482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit high-order gas-kinetic schemes for compressible flows on  three-dimensional unstructured meshes II: unsteady flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yang%2C+Y">Yaqing Yang</a>, 
<a href="/search/math?searchtype=author&query=Pan%2C+L">Liang Pan</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+K">Kun Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2304.09485">arXiv:2304.09485</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">For the simulations of unsteady flow, the global time step becomes really
small with a large variation of local cell size. In this paper, an implicit
high-order gas-kinetic scheme (HGKS) is developed to remove the restrictions on
the time step for unsteady simulations. In order to improve the efficiency and
keep the high-order accuracy, a two-stage third-order implicit time-accurate
discretization is proposed. In each stage, an artificial steady solution is
obtained for the implicit system with the pseudo-time iteration. In the
iteration, the classical implicit methods are adopted to solve the nonlinear
system, including the lower-upper symmetric Gauss-Seidel (LUSGS) and
generalized minimum residual (GMRES) methods. To achieve the spatial accuracy,
the HGKSs with both non-compact and compact reconstructions are constructed.
For the non-compact scheme, the weighted essentially non-oscillatory (WENO)
reconstruction is used. For the compact one, the Hermite WENO (HWENO)
reconstruction is adopted due to the updates of both cell-averaged flow
variables and their derivatives. The expected third-order temporal accuracy is
achieved with the two-stage temporal discretization. For the smooth flow, only
a single artificial iteration is needed. For uniform meshes, the efficiency of
the current implicit method improves significantly in comparison with the
explicit one. For the flow with discontinuities, compared with the well-known
Crank-Nicholson method, the spurious oscillations in the current schemes are
well suppressed. The increase of the artificial iteration steps introduces
extra reconstructions associating with a reduction of the computational
efficiency. Overall, the current implicit method leads to an improvement in
efficiency over the explicit one in the cases with a large variation of mesh
size.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00483" title="Abstract">arXiv:2403.00483</a> [<a href="/pdf/2403.00483" title="Download PDF">pdf</a>, <a href="/format/2403.00483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RealCustom: Narrowing Real Text Word for Real-Time Open-Domain  Text-to-Image Customization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Mengqi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Z">Zhendong Mao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingcong Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qian He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongdong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-to-image customization, which aims to synthesize text-driven images for
the given subjects, has recently revolutionized content creation. Existing
works follow the pseudo-word paradigm, i.e., represent the given subjects as
pseudo-words and then compose them with the given text. However, the inherent
entangled influence scope of pseudo-words with the given text results in a
dual-optimum paradox, i.e., the similarity of the given subjects and the
controllability of the given text could not be optimal simultaneously. We
present RealCustom that, for the first time, disentangles similarity from
controllability by precisely limiting subject influence to relevant parts only,
achieved by gradually narrowing real text word from its general connotation to
the specific subject and using its cross-attention to distinguish relevance.
Specifically, RealCustom introduces a novel "train-inference" decoupled
framework: (1) during training, RealCustom learns general alignment between
visual conditions to original textual conditions by a novel adaptive scoring
module to adaptively modulate influence quantity; (2) during inference, a novel
adaptive mask guidance strategy is proposed to iteratively update the influence
scope and influence quantity of the given subjects to gradually narrow the
generation of the real text word. Comprehensive experiments demonstrate the
superior real-time customization ability of RealCustom in the open domain,
achieving both unprecedented similarity of the given subjects and
controllability of the given text for the first time. The project page is
https://corleone-huang.github.io/realcustom/.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00485" title="Abstract">arXiv:2403.00485</a> [<a href="/pdf/2403.00485" title="Download PDF">pdf</a>, <a href="/format/2403.00485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Geometric Graph Neural Networks: Data Structures, Models and  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jiaqi Han</a>, 
<a href="/search/cs?searchtype=author&query=Cen%2C+J">Jiacheng Cen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Liming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongzhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+X">Xiangzhe Kong</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+R">Rui Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Ziyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tingyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fandi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongteng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhewei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+Y">Yu Rong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenbing Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Geometric graph is a special kind of graph with geometric features, which is
vital to model many scientific problems. Unlike generic graphs, geometric
graphs often exhibit physical symmetries of translations, rotations, and
reflections, making them ineffectively processed by current Graph Neural
Networks (GNNs). To tackle this issue, researchers proposed a variety of
Geometric Graph Neural Networks equipped with invariant/equivariant properties
to better characterize the geometry and topology of geometric graphs. Given the
current progress in this field, it is imperative to conduct a comprehensive
survey of data structures, models, and applications related to geometric GNNs.
In this paper, based on the necessary but concise mathematical preliminaries,
we provide a unified view of existing models from the geometric message passing
perspective. Additionally, we summarize the applications as well as the related
datasets to facilitate later research for methodology development and
experimental evaluation. We also discuss the challenges and future potential
directions of Geometric GNNs at the end of this survey.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00486" title="Abstract">arXiv:2403.00486</a> [<a href="/pdf/2403.00486" title="Download PDF">pdf</a>, <a href="/format/2403.00486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Selective-Stereo: Adaptive Frequency Information Selection for Stereo  Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xianqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Gangwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+H">Hao Jia</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Stereo matching methods based on iterative optimization, like RAFT-Stereo and
IGEV-Stereo, have evolved into a cornerstone in the field of stereo matching.
However, these methods struggle to simultaneously capture high-frequency
information in edges and low-frequency information in smooth regions due to the
fixed receptive field. As a result, they tend to lose details, blur edges, and
produce false matches in textureless areas. In this paper, we propose Selective
Recurrent Unit (SRU), a novel iterative update operator for stereo matching.
The SRU module can adaptively fuse hidden disparity information at multiple
frequencies for edge and smooth regions. To perform adaptive fusion, we
introduce a new Contextual Spatial Attention (CSA) module to generate attention
maps as fusion weights. The SRU empowers the network to aggregate hidden
disparity information across multiple frequencies, mitigating the risk of vital
hidden disparity information loss during iterative processes. To verify SRU's
universality, we apply it to representative iterative stereo matching methods,
collectively referred to as Selective-Stereo. Our Selective-Stereo ranks
$1^{st}$ on KITTI 2012, KITTI 2015, ETH3D, and Middlebury leaderboards among
all published methods. Code is available at
https://github.com/Windsrain/Selective-Stereo.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00489" title="Abstract">arXiv:2403.00489</a> [<a href="/pdf/2403.00489" title="Download PDF">pdf</a>, <a href="/format/2403.00489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple Ways of Working with Users to Develop Physically Assistive  Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nanavati%2C+A">Amal Nanavati</a>, 
<a href="/search/cs?searchtype=author&query=Pascher%2C+M">Max Pascher</a>, 
<a href="/search/cs?searchtype=author&query=Ranganeni%2C+V">Vinitha Ranganeni</a>, 
<a href="/search/cs?searchtype=author&query=Gordon%2C+E+K">Ethan K. Gordon</a>, 
<a href="/search/cs?searchtype=author&query=Faulkner%2C+T+K">Taylor Kessler Faulkner</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasa%2C+S+S">Siddhartha S. Srinivasa</a>, 
<a href="/search/cs?searchtype=author&query=Cakmak%2C+M">Maya Cakmak</a>, 
<a href="/search/cs?searchtype=author&query=Alves-Oliveira%2C+P">Patr&#xed;cia Alves-Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Gerken%2C+J">Jens Gerken</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A3DE '23: Workshop on Assistive Applications, Accessibility, and Disability Ethics at the ACM/IEEE International Conference on Human-Robot Interaction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Despite the growth of physically assistive robotics (PAR) research over the
last decade, nearly half of PAR user studies do not involve participants with
the target disabilities. There are several reasons for this -- recruitment
challenges, small sample sizes, and transportation logistics -- all influenced
by systemic barriers that people with disabilities face. However, it is
well-established that working with end-users results in technology that better
addresses their needs and integrates with their lived circumstances. In this
paper, we reflect on multiple approaches we have taken to working with people
with motor impairments across the design, development, and evaluation of three
PAR projects: (a) assistive feeding with a robot arm; (b) assistive
teleoperation with a mobile manipulator; and (c) shared control with a robot
arm. We discuss these approaches to working with users along three dimensions
-- individual- vs. community-level insight, logistic burden on end-users vs.
researchers, and benefit to researchers vs. community -- and share
recommendations for how other PAR researchers can incorporate users into their
work.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00491" title="Abstract">arXiv:2403.00491</a> [<a href="/pdf/2403.00491" title="Download PDF">pdf</a>, <a href="/ps/2403.00491" title="Download PostScript">ps</a>, <a href="/format/2403.00491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Divergence for Nondeterministic Probabilistic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yuxi Fu</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+H">Huan Long</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenbo Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Branching and weak probabilistic bisimilarities are two well-known notions
capturing behavioral equivalence between nondeterministic probabilistic
systems. For probabilistic systems, divergence is of major concern. Recently
several divergence-sensitive refinements of branching and weak probabilistic
bisimilarities have been proposed in the literature. Both the definitions of
these equivalences and the techniques to investigate them differ significantly.
This paper presents a comprehensive comparative study on divergence-sensitive
behavioral equivalence relations that refine the branching and weak
probabilistic bisimilarities. Additionally, these equivalence relations are
shown to have efficient checking algorithms. The techniques of this paper might
be of independent interest in a more general setting.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00497" title="Abstract">arXiv:2403.00497</a> [<a href="/pdf/2403.00497" title="Download PDF">pdf</a>, <a href="/ps/2403.00497" title="Download PostScript">ps</a>, <a href="/format/2403.00497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Homomorphism, Monotone Classes and Bounded Pathwidth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eagling-Vose%2C+T">Tala Eagling-Vose</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+B">Barnaby Martin</a>, 
<a href="/search/cs?searchtype=author&query=Paulusma%2C+D">Daniel Paulusma</a>, 
<a href="/search/cs?searchtype=author&query=Siggers%2C+M">Mark Siggers</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+S">Siani Smith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">A recent paper describes a framework for studying the computational
complexity of graph problems on monotone classes, that is those omitting a set
of graphs as a subgraph. If the problems lie in the framework, and many do,
then the computational complexity can be described for all monotone classes
defined by a finite set of omitted subgraphs. It is known that certain
homomorphism problems, e.g. $C_5$-Colouring, do not sit in the framework. By
contrast, we show that the more general problem of Graph Homomorphism does sit
in the framework.
<br />The original framework had examples where hard versus easy were NP-complete
versus P, or at least quadratic versus almost linear. We give the first example
of a problem in the framework such that hardness is in the polynomial hierarchy
above NP. Considering a variant of the colouring game as studied by Bodlaender,
we show that with the restriction of bounded alternation, the list version of
this problem is contained in the framework. The hard cases are
$\Pi_{2k}^\mathrm{P}$-complete and the easy cases are in P.
<br />The cases in P comprise those classes for which the pathwidth is bounded.
Bodlaender explains that Sequential $3$-Colouring Construction Game is in P on
classes with bounded vertex separation number, which coincides with bounded
pathwidth on unordered graphs. However, these graphs are ordered with a playing
order for the two players, which corresponds to a prefix pattern in a
quantified formula. We prove that Sequential $3$-Colouring Construction Game is
Pspace-complete on some class of bounded pathwidth, using a celebrated result
of Atserias and Oliva.
<br />We consider several locally constrained variants of the homomorphism problem.
Like $C_5$-Colouring, none of these is in the framework. However, when we
consider the bounded-degree restrictions, we prove that each of these problems
is in our framework.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00499" title="Abstract">arXiv:2403.00499</a> [<a href="/pdf/2403.00499" title="Download PDF">pdf</a>, <a href="/format/2403.00499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do Zombies Understand? A Choose-Your-Own-Adventure Exploration of  Machine Cognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goldstein%2C+A">Ariel Goldstein</a>, 
<a href="/search/cs?searchtype=author&query=Stanovsky%2C+G">Gabriel Stanovsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent advances in LLMs have sparked a debate on whether they understand
text. In this position paper, we argue that opponents in this debate hold
different definitions for understanding, and particularly differ in their view
on the role of consciousness. To substantiate this claim, we propose a thought
experiment involving an open-source chatbot $Z$ which excels on every possible
benchmark, seemingly without subjective experience. We ask whether $Z$ is
capable of understanding, and show that different schools of thought within
seminal AI research seem to answer this question differently, uncovering their
terminological disagreement. Moving forward, we propose two distinct working
definitions for understanding which explicitly acknowledge the question of
consciousness, and draw connections with a rich literature in philosophy,
psychology and neuroscience.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00504" title="Abstract">arXiv:2403.00504</a> [<a href="/pdf/2403.00504" title="Download PDF">pdf</a>, <a href="/format/2403.00504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning and Leveraging World Models in Visual Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garrido%2C+Q">Quentin Garrido</a>, 
<a href="/search/cs?searchtype=author&query=Assran%2C+M">Mahmoud Assran</a>, 
<a href="/search/cs?searchtype=author&query=Ballas%2C+N">Nicolas Ballas</a>, 
<a href="/search/cs?searchtype=author&query=Bardes%2C+A">Adrien Bardes</a>, 
<a href="/search/cs?searchtype=author&query=Najman%2C+L">Laurent Najman</a>, 
<a href="/search/cs?searchtype=author&query=LeCun%2C+Y">Yann LeCun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Joint-Embedding Predictive Architecture (JEPA) has emerged as a promising
self-supervised approach that learns by leveraging a world model. While
previously limited to predicting missing parts of an input, we explore how to
generalize the JEPA prediction task to a broader set of corruptions. We
introduce Image World Models, an approach that goes beyond masked image
modeling and learns to predict the effect of global photometric transformations
in latent space. We study the recipe of learning performant IWMs and show that
it relies on three key aspects: conditioning, prediction difficulty, and
capacity. Additionally, we show that the predictive world model learned by IWM
can be adapted through finetuning to solve diverse tasks; a fine-tuned IWM
world model matches or surpasses the performance of previous self-supervised
methods. Finally, we show that learning with an IWM allows one to control the
abstraction level of the learned representations, learning invariant
representations such as contrastive methods, or equivariant representations
such as masked image modelling.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00506" title="Abstract">arXiv:2403.00506</a> [<a href="/pdf/2403.00506" title="Download PDF">pdf</a>, <a href="/ps/2403.00506" title="Download PostScript">ps</a>, <a href="/format/2403.00506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PoTeC: A German Naturalistic Eye-tracking-while-reading Corpus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jakobi%2C+D+N">Deborah N. Jakobi</a>, 
<a href="/search/cs?searchtype=author&query=Kern%2C+T">Thomas Kern</a>, 
<a href="/search/cs?searchtype=author&query=Reich%2C+D+R">David R. Reich</a>, 
<a href="/search/cs?searchtype=author&query=Haller%2C+P">Patrick Haller</a>, 
<a href="/search/cs?searchtype=author&query=J%C3%A4ger%2C+L+A">Lena A. J&#xe4;ger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The Potsdam Textbook Corpus (PoTeC) is a naturalistic
eye-tracking-while-reading corpus containing data from 75 participants reading
12 scientific texts. PoTeC is the first naturalistic eye-tracking-while-reading
corpus that contains eye-movements from domain-experts as well as novices in a
within-participant manipulation: It is based on a 2x2x2 fully-crossed factorial
design which includes the participants' level of study and the participants'
discipline of study as between-subject factors and the text domain as a
within-subject factor. The participants' reading comprehension was assessed by
a series of text comprehension questions and their domain knowledge was tested
by text-independent background questions for each of the texts. The materials
are annotated for a variety of linguistic features at different levels. We
envision PoTeC to be used for a wide range of studies including but not limited
to analyses of expert and non-expert reading strategies. The corpus and all the
accompanying data at all stages of the preprocessing pipeline and all code used
to preprocess the data are made available via GitHub:
https://github.com/DiLi-Lab/PoTeC.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00509" title="Abstract">arXiv:2403.00509</a> [<a href="/pdf/2403.00509" title="Download PDF">pdf</a>, <a href="/format/2403.00509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Surveying the Dead Minds: Historical-Psychological Text Analysis with  Contextualized Construct Representation (CCR) for Classical Chinese
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sixuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Ying Li</a>, 
<a href="/search/cs?searchtype=author&query=Atari%2C+M">Mohammad Atari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">In this work, we develop a pipeline for historical-psychological text
analysis in classical Chinese. Humans have produced texts in various languages
for thousands of years; however, most of the computational literature is
focused on contemporary languages and corpora. The emerging field of historical
psychology relies on computational techniques to extract aspects of psychology
from historical corpora using new methods developed in natural language
processing (NLP). The present pipeline, called Contextualized Construct
Representations (CCR), combines expert knowledge in psychometrics (i.e.,
psychological surveys) with text representations generated via
transformer-based language models to measure psychological constructs such as
traditionalism, norm strength, and collectivism in classical Chinese corpora.
Considering the scarcity of available data, we propose an indirect supervised
contrastive learning approach and build the first Chinese historical psychology
corpus (C-HI-PSY) to fine-tune pre-trained models. We evaluate the pipeline to
demonstrate its superior performance compared with other approaches. The CCR
method outperforms word-embedding-based approaches across all of our tasks and
exceeds prompting with GPT-4 in most tasks. Finally, we benchmark the pipeline
against objective, external data to further verify its validity.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00510" title="Abstract">arXiv:2403.00510</a> [<a href="/pdf/2403.00510" title="Download PDF">pdf</a>, <a href="/format/2403.00510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ROME: Memorization Insights from Text, Probability and Hidden State in  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qinghua Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+L">Lijie Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Probing the memorization of large language models holds significant
importance. Previous works have established metrics for quantifying
memorization, explored various influencing factors, such as data duplication,
model size, and prompt length, and evaluated memorization by comparing model
outputs with training corpora. However, the training corpora are of enormous
scale and its pre-processing is time-consuming. To explore memorization without
accessing training data, we propose a novel approach, named ROME, wherein
memorization is explored by comparing disparities across memorized and
non-memorized. Specifically, models firstly categorize the selected samples
into memorized and non-memorized groups, and then comparing the demonstrations
in the two groups from the insights of text, probability, and hidden state.
Experimental findings show the disparities in factors including word length,
part-of-speech, word frequency, mean and variance, just to name a few.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00514" title="Abstract">arXiv:2403.00514</a> [<a href="/pdf/2403.00514" title="Download PDF">pdf</a>, <a href="/format/2403.00514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overestimation, Overfitting, and Plasticity in Actor-Critic: the Bitter  Lesson of Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nauman%2C+M">Michal Nauman</a>, 
<a href="/search/cs?searchtype=author&query=Bortkiewicz%2C+M">Micha&#x142; Bortkiewicz</a>, 
<a href="/search/cs?searchtype=author&query=Ostaszewski%2C+M">Mateusz Ostaszewski</a>, 
<a href="/search/cs?searchtype=author&query=Mi%C5%82o%C5%9B%2C+P">Piotr Mi&#x142;o&#x15b;</a>, 
<a href="/search/cs?searchtype=author&query=Trzci%C5%84ski%2C+T">Tomasz Trzci&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Cygan%2C+M">Marek Cygan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Recent advancements in off-policy Reinforcement Learning (RL) have
significantly improved sample efficiency, primarily due to the incorporation of
various forms of regularization that enable more gradient update steps than
traditional agents. However, many of these techniques have been tested in
limited settings, often on tasks from single simulation benchmarks and against
well-known algorithms rather than a range of regularization approaches. This
limits our understanding of the specific mechanisms driving RL improvements. To
address this, we implemented over 60 different off-policy agents, each
integrating established regularization techniques from recent state-of-the-art
algorithms. We tested these agents across 14 diverse tasks from 2 simulation
benchmarks. Our findings reveal that while the effectiveness of a specific
regularization setup varies with the task, certain combinations consistently
demonstrate robust and superior performance. Notably, a simple Soft
Actor-Critic agent, appropriately regularized, reliably solves dog tasks, which
were previously solved mainly through model-based approaches.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00515" title="Abstract">arXiv:2403.00515</a> [<a href="/pdf/2403.00515" title="Download PDF">pdf</a>, <a href="/format/2403.00515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Unikernels Ready for Serverless on the Edge?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moebius%2C+F">Felix Moebius</a>, 
<a href="/search/cs?searchtype=author&query=Pfandzelter%2C+T">Tobias Pfandzelter</a>, 
<a href="/search/cs?searchtype=author&query=Bermbach%2C+D">David Bermbach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Function-as-a-Service (FaaS) is a promising edge computing execution model
but requires secure sandboxing mechanisms to isolate workloads from multiple
tenants on constrained infrastructure. Although Docker containers are
lightweight and popular in open-source FaaS platforms, they are generally
considered insufficient for executing untrusted code and providing sandbox
isolation. Commercial cloud FaaS platforms thus rely on Linux microVMs or
hardened container runtimes, which are secure but come with a higher resource
footprint.
<br />Unikernels combine application code and limited operating system primitives
into a single purpose appliance, reducing the footprint of an application and
its sandbox while providing full Linux compatibility. In this paper, we study
the suitability of unikernels as an edge FaaS execution environment using the
Nanos and OSv unikernel tool chains. We compare performance along several
metrics such as cold start overhead and idle footprint against sandboxes such
as Firecracker Linux microVMs, Docker containers, and secure gVisor containers.
We find that unikernels exhibit desirable cold start performance, yet lag
behind Linux microVMs in stability. Nevertheless, we show that unikernels are a
promising candidate for further research on Linux-compatible FaaS isolation.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00517" title="Abstract">arXiv:2403.00517</a> [<a href="/pdf/2403.00517" title="Download PDF">pdf</a>, <a href="/format/2403.00517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization of the Energy-Comfort Trade-Off of HVAC Systems in Electric  City Buses Based on a Steady-State Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Widmer%2C+F">Fabio Widmer</a>, 
<a href="/search/eess?searchtype=author&query=van+Dooren%2C+S">Stijn van Dooren</a>, 
<a href="/search/eess?searchtype=author&query=Onder%2C+C+H">Christopher H. Onder</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint submitted to Control Engineering Practice
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The electrification of public transport vehicles offers the potential to
relieve city centers of pollutant and noise emissions. Furthermore, electric
buses have lower life-cycle greenhouse gas (GHG) emissions than diesel buses,
particularly when operated with sustainably produced electricity. However, the
heating, ventilation, and air-conditioning (HVAC) system can consume a
significant amount of energy, thus limiting the achievable driving range. In
this paper, we address the HVAC system in an electric city bus by analyzing the
trade-off between the energy consumption and the thermal comfort of the
passengers. We do this by developing a dynamic thermal model for the bus cabin,
which we simplify by considering it to be in steady state. We introduce a
method that is able to quickly optimize the steady-state HVAC system inputs for
a large number of samples representative of a year-round operation. A
comparison between the results from the steady-state optimization approach and
a dynamic simulation reveal small deviations in both the HVAC system power
demand and achieved thermal comfort. Thus, the approximation of the system
performance with a steady-state model is justified. We present two case studies
to demonstrate the practical relevance of the approach. First, we show how the
method can be used to compare different system designs based on a year-round
performance evaluation. Second, we show how the method can be used to generate
accurate setpoints for online controllers. In conclusion, this study shows that
a steady-state analysis of the HVAC systems of an electric city bus is a
valuable approach to evaluate and optimize its performance.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00520" title="Abstract">arXiv:2403.00520</a> [<a href="/pdf/2403.00520" title="Download PDF">pdf</a>, <a href="/format/2403.00520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IAI MovieBot 2.0: An Enhanced Research Platform with Trainable Neural  Components and Transparent User Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bernard%2C+N">Nolwenn Bernard</a>, 
<a href="/search/cs?searchtype=author&query=Kostric%2C+I">Ivica Kostric</a>, 
<a href="/search/cs?searchtype=author&query=Balog%2C+K">Krisztian Balog</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 17th ACM International Conference on Web Search and Data Mining (WSDM '24), March 4--8, 2024, Merida, Mexico
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">While interest in conversational recommender systems has been on the rise,
operational systems suitable for serving as research platforms for
comprehensive studies are currently lacking. This paper introduces an enhanced
version of the IAI MovieBot conversational movie recommender system, aiming to
evolve it into a robust and adaptable platform for conducting user-facing
experiments. The key highlights of this enhancement include the addition of
trainable neural components for natural language understanding and dialogue
policy, transparent and explainable modeling of user preferences, along with
improvements in the user interface and research infrastructure.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00522" title="Abstract">arXiv:2403.00522</a> [<a href="/pdf/2403.00522" title="Download PDF">pdf</a>, <a href="/format/2403.00522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VisionLLaMA: A Unified LLaMA Interface for Vision Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+X">Xiangxiang Chu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Jianlin Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chunhua Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large language models are built on top of a transformer-based architecture to
process textual inputs. For example, the LLaMA stands out among many
open-source implementations. Can the same transformer be used to process 2D
images? In this paper, we answer this question by unveiling a LLaMA-like vision
transformer in plain and pyramid forms, termed VisionLLaMA, which is tailored
for this purpose. VisionLLaMA is a unified and generic modelling framework for
solving most vision tasks. We extensively evaluate its effectiveness using
typical pre-training paradigms in a good portion of downstream tasks of image
perception and especially image generation. In many cases, VisionLLaMA have
exhibited substantial gains over the previous state-of-the-art vision
transformers. We believe that VisionLLaMA can serve as a strong new baseline
model for vision generation and understanding. Our code will be released at
https://github.com/Meituan-AutoML/VisionLLaMA.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00526" title="Abstract">arXiv:2403.00526</a> [<a href="/pdf/2403.00526" title="Download PDF">pdf</a>, <a href="/format/2403.00526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Quality Assessment: Challenges and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohammed%2C+S">Sedir Mohammed</a>, 
<a href="/search/cs?searchtype=author&query=Harmouch%2C+H">Hazar Harmouch</a>, 
<a href="/search/cs?searchtype=author&query=Naumann%2C+F">Felix Naumann</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+D">Divesh Srivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Data-oriented applications, their users, and even the law require data of
high quality. Research has broken down the rather vague notion of data quality
into various dimensions, such as accuracy, consistency, and reputation, to name
but a few. To achieve the goal of high data quality, many tools and techniques
exist to clean and otherwise improve data. Yet, systematic research on actually
assessing data quality in all of its dimensions is largely absent, and with it
the ability to gauge the success of any data cleaning effort. It is our vision
to establish a systematic and comprehensive framework for the (numeric)
assessment of data quality for a given dataset and its intended use. Such a
framework must cover the various facets that influence data quality, as well as
the many types of data quality dimensions. In particular, we identify five
facets that serve as a foundation of data quality assessment. For each facet,
we outline the challenges and opportunities that arise when trying to actually
assign quality scores to data and create a data quality profile for it, along
with a wide range of technologies needed for this purpose.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00527" title="Abstract">arXiv:2403.00527</a> [<a href="/pdf/2403.00527" title="Download PDF">pdf</a>, <a href="/format/2403.00527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;There is a Job Prepared for Me Here&quot;: Understanding How Short Video and  Live-streaming Platforms Empower Ageing Job Seekers in China
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">PiaoHong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Siying Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+B">Bo Wen</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhicong Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 3 figures; Accepted to ACM CHI 2024. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In recent years, the global unemployment rate has remained persistently high.
Compounding this issue, the ageing population in China often encounters
additional challenges in finding employment due to prevalent age discrimination
in daily life. However, with the advent of social media, there has been a rise
in the popularity of short videos and live-streams for recruiting ageing
workers. To better understand the motivations of ageing job seekers to engage
with these video-based recruitment methods and to explore the extent to which
such platforms can empower them, we conducted an interview-based study with
ageing job seekers who have had exposure to these short recruitment videos and
live-streaming channels. Our findings reveal that these platforms can provide a
job-seeking choice that is particularly friendly to ageing job seekers,
effectively improving their disadvantaged situation.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00528" title="Abstract">arXiv:2403.00528</a> [<a href="/pdf/2403.00528" title="Download PDF">pdf</a>, <a href="/ps/2403.00528" title="Download PostScript">ps</a>, <a href="/format/2403.00528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Simultaneous Named Entity Extraction and  Spelling Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Whittaker%2C+E">Edward Whittaker</a>, 
<a href="/search/cs?searchtype=author&query=Kitagishi%2C+I">Ikuo Kitagishi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Language Models (LMs) such as BERT, have been shown to perform well on the
task of identifying Named Entities (NE) in text. A BERT LM is typically used as
a classifier to classify individual tokens in the input text, or to classify
spans of tokens, as belonging to one of a set of possible NE categories.
<br />In this paper, we hypothesise that decoder-only Large Language Models (LLMs)
can also be used generatively to extract both the NE, as well as potentially
recover the correct surface form of the NE, where any spelling errors that were
present in the input text get automatically corrected.
<br />We fine-tune two BERT LMs as baselines, as well as eight open-source LLMs, on
the task of producing NEs from text that was obtained by applying Optical
Character Recognition (OCR) to images of Japanese shop receipts; in this work,
we do not attempt to find or evaluate the location of NEs in the text.
<br />We show that the best fine-tuned LLM performs as well as, or slightly better
than, the best fine-tuned BERT LM, although the differences are not
significant. However, the best LLM is also shown to correct OCR errors in some
cases, as initially hypothesised.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00529" title="Abstract">arXiv:2403.00529</a> [<a href="/pdf/2403.00529" title="Download PDF">pdf</a>, <a href="/format/2403.00529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VoxGenesis: Unsupervised Discovery of Latent Speaker Manifold for Speech  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weiwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Chenhang He</a>, 
<a href="/search/cs?searchtype=author&query=Mak%2C+M">Man-Wai Mak</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+J">Jiachen Lian</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K+A">Kong Aik Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Achieving nuanced and accurate emulation of human voice has been a
longstanding goal in artificial intelligence. Although significant progress has
been made in recent years, the mainstream of speech synthesis models still
relies on supervised speaker modeling and explicit reference utterances.
However, there are many aspects of human voice, such as emotion, intonation,
and speaking style, for which it is hard to obtain accurate labels. In this
paper, we propose VoxGenesis, a novel unsupervised speech synthesis framework
that can discover a latent speaker manifold and meaningful voice editing
directions without supervision. VoxGenesis is conceptually simple. Instead of
mapping speech features to waveforms deterministically, VoxGenesis transforms a
Gaussian distribution into speech distributions conditioned and aligned by
semantic tokens. This forces the model to learn a speaker distribution
disentangled from the semantic content. During the inference, sampling from the
Gaussian distribution enables the creation of novel speakers with distinct
characteristics. More importantly, the exploration of latent space uncovers
human-interpretable directions associated with specific speaker characteristics
such as gender attributes, pitch, tone, and emotion, allowing for voice editing
by manipulating the latent codes along these identified directions. We conduct
extensive experiments to evaluate the proposed VoxGenesis using both subjective
and objective metrics, finding that it produces significantly more diverse and
realistic speakers with distinct characteristics than the previous approaches.
We also show that latent space manipulation produces consistent and
human-identifiable effects that are not detrimental to the speech quality,
which was not possible with previous approaches. Audio samples of VoxGenesis
can be found at: \url{https://bit.ly/VoxGenesis}.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00536" title="Abstract">arXiv:2403.00536</a> [<a href="/pdf/2403.00536" title="Download PDF">pdf</a>, <a href="/format/2403.00536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximating the Geometric Knapsack Problem in Near-Linear Time and  Dynamically
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Buchem%2C+M">Moritz Buchem</a>, 
<a href="/search/cs?searchtype=author&query=Deuker%2C+P">Paul Deuker</a>, 
<a href="/search/cs?searchtype=author&query=Wiese%2C+A">Andreas Wiese</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">An important goal in algorithm design is determining the best running time
for solving a problem (approximately). For some problems, we know the optimal
running time, assuming certain conditional lower bounds. In this work, we study
the $d$-dimensional geometric knapsack problem where we are far from this level
of understanding. We are given a set of weighted d-dimensional geometric items
like squares, rectangles, or hypercubes and a knapsack which is a square or a
(hyper-)cube. We want to select a subset of items that fit non-overlappingly
inside the knapsack, maximizing the total profit of the packed items. We make a
significant step towards determining the best running time for solving these
problems approximately by presenting approximation algorithms with near-linear
running times for any constant dimension d and any constant parameter
$\epsilon$.
<br />For (hyper)-cubes, we present a $(1+\epsilon)$-approximation algorithm whose
running time drastically improves upon the known $(1+\epsilon)$-approximation
algorithm which has a running time where the exponent of n depends
exponentially on $1/\epsilon$ and $d$. Moreover, we present a
$(2+\epsilon)$-approximation algorithm for rectangles in the setting without
rotations and a $(17/9+\epsilon)$-approximation algorithm if we allow rotations
by 90 degrees. The best known polynomial time algorithms for these settings
have approximation ratios of $17/9+\epsilon$ and $1.5+\epsilon$, respectively,
and running times in which the exponent of n depends exponentially on
$1/\epsilon$. We also give dynamic algorithms with polylogarithmic query and
update times and the same approximation guarantees as the algorithms above. Key
to our results is a new family of structured packings which we call easily
guessable packings. They are flexible enough to guarantee profitable solutions
and structured enough so that we can compute these solutions quickly.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00539" title="Abstract">arXiv:2403.00539</a> [<a href="/pdf/2403.00539" title="Download PDF">pdf</a>, <a href="/format/2403.00539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DyPyBench: A Benchmark of Executable Python Software
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bouzenia%2C+I">Islem Bouzenia</a>, 
<a href="/search/cs?searchtype=author&query=Krishan%2C+B+P">Bajaj Piyush Krishan</a>, 
<a href="/search/cs?searchtype=author&query=Pradel%2C+M">Michael Pradel</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 16. Publication
  date: July 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Python has emerged as one of the most popular programming languages,
extensively utilized in domains such as machine learning, data analysis, and
web applications. Python's dynamic nature and extensive usage make it an
attractive candidate for dynamic program analysis. However, unlike for other
popular languages, there currently is no comprehensive benchmark suite of
executable Python projects, which hinders the development of dynamic analyses.
This work addresses this gap by presenting DyPyBench, the first benchmark of
Python projects that is large scale, diverse, ready to run (i.e., with fully
configured and prepared test suites), and ready to analyze (by integrating with
the DynaPyt dynamic analysis framework). The benchmark encompasses 50 popular
opensource projects from various application domains, with a total of 681k
lines of Python code, and 30k test cases. DyPyBench enables various
applications in testing and dynamic analysis, of which we explore three in this
work: (i) Gathering dynamic call graphs and empirically comparing them to
statically computed call graphs, which exposes and quantifies limitations of
existing call graph construction techniques for Python. (ii) Using DyPyBench to
build a training data set for LExecutor, a neural model that learns to predict
values that otherwise would be missing at runtime. (iii) Using dynamically
gathered execution traces to mine API usage specifications, which establishes a
baseline for future work on specification mining for Python. We envision
DyPyBench to provide a basis for other dynamic analyses and for studying the
runtime behavior of Python code.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00540" title="Abstract">arXiv:2403.00540</a> [<a href="/pdf/2403.00540" title="Download PDF">pdf</a>, <a href="/format/2403.00540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Epsilon-Greedy Thompson Sampling to Bayesian Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Do%2C+B">Bach Do</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruda Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Thompson sampling (TS) serves as a solution for addressing the
exploitation-exploration dilemma in Bayesian optimization (BO). While it
prioritizes exploration by randomly generating and maximizing sample paths of
Gaussian process (GP) posteriors, TS weakly manages its exploitation by
gathering information about the true objective function after each exploration
is performed. In this study, we incorporate the epsilon-greedy
($\varepsilon$-greedy) policy, a well-established selection strategy in
reinforcement learning, into TS to improve its exploitation. We first delineate
two extremes of TS applied for BO, namely the generic TS and a sample-average
TS. The former and latter promote exploration and exploitation, respectively.
We then use $\varepsilon$-greedy policy to randomly switch between the two
extremes. A small value of $\varepsilon \in (0,1)$ prioritizes exploitation,
and vice versa. We empirically show that $\varepsilon$-greedy TS with an
appropriate $\varepsilon$ is better than one of its two extremes and competes
with the other.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00542" title="Abstract">arXiv:2403.00542</a> [<a href="/pdf/2403.00542" title="Download PDF">pdf</a>, <a href="/ps/2403.00542" title="Download PostScript">ps</a>, <a href="/format/2403.00542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning Training Optimization using the Barycentric Correction  Procedure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramos-Pulido%2C+S">Sofia Ramos-Pulido</a>, 
<a href="/search/cs?searchtype=author&query=Hernandez-Gress%2C+N">Neil Hernandez-Gress</a>, 
<a href="/search/cs?searchtype=author&query=Ceballos-Cancino%2C+H+G">Hector G. Ceballos-Cancino</a> (Tecnologico de Monterrey, Mexico)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Science &amp; Information Technology (CS &amp; IT) ISSN : 2231 -
  5403 Volume 14, Number 04, February 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Machine learning (ML) algorithms are predictively competitive algorithms with
many human-impact applications. However, the issue of long execution time
remains unsolved in the literature for high-dimensional spaces. This study
proposes combining ML algorithms with an efficient methodology known as the
barycentric correction procedure (BCP) to address this issue. This study uses
synthetic data and an educational dataset from a private university to show the
benefits of the proposed method. It was found that this combination provides
significant benefits related to time in synthetic and real data without losing
accuracy when the number of instances and dimensions increases. Additionally,
for high-dimensional spaces, it was proved that BCP and linear support vector
classification (LinearSVC), after an estimated feature map for the gaussian
radial basis function (RBF) kernel, were unfeasible in terms of computational
time and accuracy.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00543" title="Abstract">arXiv:2403.00543</a> [<a href="/pdf/2403.00543" title="Download PDF">pdf</a>, <a href="/format/2403.00543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SURE: SUrvey REcipes for building reliable and robust deep networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuting Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xuanlong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dexiong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xi Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we revisit techniques for uncertainty estimation within deep
neural networks and consolidate a suite of techniques to enhance their
reliability. Our investigation reveals that an integrated application of
diverse techniques--spanning model regularization, classifier and
optimization--substantially improves the accuracy of uncertainty predictions in
image classification tasks. The synergistic effect of these techniques
culminates in our novel SURE approach. We rigorously evaluate SURE against the
benchmark of failure prediction, a critical testbed for uncertainty estimation
efficacy. Our results showcase a consistently better performance than models
that individually deploy each technique, across various datasets and model
architectures. When applied to real-world challenges, such as data corruption,
label noise, and long-tailed class distribution, SURE exhibits remarkable
robustness, delivering results that are superior or on par with current
state-of-the-art specialized methods. Particularly on Animal-10N and Food-101N
for learning with noisy labels, SURE achieves state-of-the-art performance
without any task-specific adjustments. This work not only sets a new benchmark
for robust uncertainty estimation but also paves the way for its application in
diverse, real-world scenarios where reliability is paramount. Our code is
available at \url{https://yutingli0606.github.io/SURE/}.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00546" title="Abstract">arXiv:2403.00546</a> [<a href="/pdf/2403.00546" title="Download PDF">pdf</a>, <a href="/format/2403.00546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Study of Simulators for Vehicular Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saghir%2C+R">Rida Saghir</a>, 
<a href="/search/cs?searchtype=author&query=Karunathilake%2C+T">Thenuka Karunathilake</a>, 
<a href="/search/cs?searchtype=author&query=F%C3%B6rster%2C+A">Anna F&#xf6;rster</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Vehicular Adhoc networks (VANETs) are composed of vehicles connected with
wireless links to exchange data. VANETs have become the backbone of the
Intelligent Transportation Systems (ITS) in smart cities and enable many
essential services like roadside safety, traffic management, platooning, etc
with vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I)
communications. In any form of research testing and evaluation plays a crucial
role. However, in VANETs, real-world experiments require high investment, and
heavy resources and can cause many practical difficulties. Therefore,
simulations have become critical and the primary way of evaluating VANETs'
applications. Furthermore, the upfront challenge is the realistic capture of
the networking mechanism of VANETs, which varies from situation to situation.
Several factors may contribute to the successful achievement of a random
realistic networking behavior. However, the biggest dependency is a powerful
tool for the implementation, which could probably take into account all the
configuration parameters, loss factors, mobility schemes, and other key
features of a VANET, yet give out practical performance metrics with a good
trade-off between investment of resources and the results. Hence, the aim of
this research is to evaluate some simulators in the scope of VANETs with
respect to resource utilization, packet delivery, and computational time.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00550" title="Abstract">arXiv:2403.00550</a> [<a href="/pdf/2403.00550" title="Download PDF">pdf</a>, <a href="/format/2403.00550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imitation Learning Datasets: A Toolkit For Creating Datasets, Training  Agents and Benchmarking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gavenski%2C+N">Nathan Gavenski</a>, 
<a href="/search/cs?searchtype=author&query=Luck%2C+M">Michael Luck</a>, 
<a href="/search/cs?searchtype=author&query=Rodrigues%2C+O">Odinaldo Rodrigues</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> his paper has been accepted in the demonstration track for the 23rd International Conference on Autonomous Agents and Multi-Agent Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Imitation learning field requires expert data to train agents in a task. Most
often, this learning approach suffers from the absence of available data, which
results in techniques being tested on its dataset. Creating datasets is a
cumbersome process requiring researchers to train expert agents from scratch,
record their interactions and test each benchmark method with newly created
data. Moreover, creating new datasets for each new technique results in a lack
of consistency in the evaluation process since each dataset can drastically
vary in state and action distribution. In response, this work aims to address
these issues by creating Imitation Learning Datasets, a toolkit that allows
for: (i) curated expert policies with multithreaded support for faster dataset
creation; (ii) readily available datasets and techniques with precise
measurements; and (iii) sharing implementations of common imitation learning
techniques. Demonstration link:
https://nathangavenski.github.io/#/il-datasets-video
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00553" title="Abstract">arXiv:2403.00553</a> [<a href="/pdf/2403.00553" title="Download PDF">pdf</a>, <a href="/format/2403.00553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Standardizing the Measurement of Text Diversity: A Tool and a  Comparative Analysis of Scores
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaib%2C+C">Chantal Shaib</a>, 
<a href="/search/cs?searchtype=author&query=Barrow%2C+J">Joe Barrow</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiuding Sun</a>, 
<a href="/search/cs?searchtype=author&query=Siu%2C+A+F">Alexa F. Siu</a>, 
<a href="/search/cs?searchtype=author&query=Wallace%2C+B+C">Byron C. Wallace</a>, 
<a href="/search/cs?searchtype=author&query=Nenkova%2C+A">Ani Nenkova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The diversity across outputs generated by large language models shapes the
perception of their quality and utility. Prompt leaks, templated answer
structure, and canned responses across different interactions are readily
noticed by people, but there is no standard score to measure this aspect of
model behavior. In this work we empirically investigate diversity scores on
English texts. We find that computationally efficient compression algorithms
capture information similar to what is measured by slow to compute $n$-gram
overlap homogeneity scores. Further, a combination of measures -- compression
ratios, self-repetition of long $n$-grams and Self-BLEU and BERTScore -- are
sufficient to report, as they have low mutual correlation with each other. The
applicability of scores extends beyond analysis of generative models; for
example, we highlight applications on instruction-tuning datasets and
human-produced texts. We release a diversity score package to facilitate
research and invite consistency across reports.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00554" title="Abstract">arXiv:2403.00554</a> [<a href="/pdf/2403.00554" title="Download PDF">pdf</a>, <a href="/format/2403.00554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed MPC for autonomous ships on inland waterways with  collaborative collision avoidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tran%2C+H+A">Hoang Anh Tran</a>, 
<a href="/search/eess?searchtype=author&query=Johansen%2C+T+A">Tor Arne Johansen</a>, 
<a href="/search/eess?searchtype=author&query=Negenborn%2C+R+R">Rudy R. Negenborn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents a distributed solution for the problem of collaborative
collision avoidance for autonomous inland waterway ships. A two-layer collision
avoidance framework that considers inland waterway traffic regulations is
proposed to increase navigational safety for autonomous ships. Our approach
allows for modifying traffic rules without changing the collision avoidance
algorithm, and is based on a novel formulation of model predictive control
(MPC) for collision avoidance of ships. This MPC formulation is designed for
inland waterway traffic and can handle complex scenarios. The alternating
direction method of multipliers is used as a scheme for exchanging and
negotiating intentions among ships. Simulation results show that the proposed
algorithm can comply with traffic rules. Furthermore, the proposed algorithm
can safely deviate from traffic rules when necessary to increase efficiency in
complex scenarios.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00556" title="Abstract">arXiv:2403.00556</a> [<a href="/pdf/2403.00556" title="Download PDF">pdf</a>, <a href="/format/2403.00556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nearest-Neighbours Estimators for Conditional Mutual Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Witter%2C+J">Jake Witter</a>, 
<a href="/search/cs?searchtype=author&query=Houghton%2C+C">Conor Houghton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The conditional mutual information quantifies the conditional dependence of
two random variables. It has numerous applications; it forms, for example, part
of the definition of transfer entropy, a common measure of the causal
relationship between time series. It does, however, require a lot of data to
estimate accurately and suffers the curse of dimensionality, limiting its
application in machine learning and data science. However, the
Kozachenko-Leonenko approach can address this problem: it is possible, in this
approach to define a nearest-neighbour estimator which depends only on the
distance between data points and not on the dimension of the data. Furthermore,
the bias can be calculated analytically for this estimator. Here this estimator
is described and is tested on simulated data.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00558" title="Abstract">arXiv:2403.00558</a> [<a href="/pdf/2403.00558" title="Download PDF">pdf</a>, <a href="/format/2403.00558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rational Linkages: From Poses to 3D-printed Prototypes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huczala%2C+D">Daniel Huczala</a>, 
<a href="/search/cs?searchtype=author&query=Siegele%2C+J">Johannes Siegele</a>, 
<a href="/search/cs?searchtype=author&query=Thimm%2C+D+A">Daren A. Thimm</a>, 
<a href="/search/cs?searchtype=author&query=Pfurner%2C+M">Martin Pfurner</a>, 
<a href="/search/cs?searchtype=author&query=Schr%C3%B6cker%2C+H">Hans-Peter Schr&#xf6;cker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this paper, a set of tools is introduced that simplifies the synthesis and
rapid-prototyping of single-loop rational kinematic chains. It allows the user
to perform rational motion interpolation of up to four given poses and yields
the design parameters of a linkage that can execute this motion. The package
also provides a visualization of the output and performs a self-collision
analysis with the possibility to adapt the design parameters. The results can
be imported into CAD-systems for fast 3D printing.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00561" title="Abstract">arXiv:2403.00561</a> [<a href="/pdf/2403.00561" title="Download PDF">pdf</a>, <a href="/format/2403.00561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Task Learning Using Uncertainty to Weigh Losses for Heterogeneous  Face Attribute Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Huaqing Yuan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yi He</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+P">Peng Du</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Lu Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Face images contain a wide variety of attribute information. In this paper,
we propose a generalized framework for joint estimation of ordinal and nominal
attributes based on information sharing. We tackle the correlation problem
between heterogeneous attributes using hard parameter sharing of shallow
features, and trade-off multiple loss functions by considering homoskedastic
uncertainty for each attribute estimation task. This leads to optimal
estimation of multiple attributes of the face and reduces the training cost of
multitask learning. Experimental results on benchmarks with multiple face
attributes show that the proposed approach has superior performance compared to
state of the art. Finally, we discuss the bias issues arising from the proposed
approach in face attribute estimation and validate its feasibility on edge
systems.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00563" title="Abstract">arXiv:2403.00563</a> [<a href="/pdf/2403.00563" title="Download PDF">pdf</a>, <a href="/format/2403.00563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Indirectly Parameterized Concrete Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nilsson%2C+A">Alfred Nilsson</a>, 
<a href="/search/cs?searchtype=author&query=Wijk%2C+K">Klas Wijk</a>, 
<a href="/search/cs?searchtype=author&query=Gutha%2C+S+b+c">Sai bharath chandra Gutha</a>, 
<a href="/search/cs?searchtype=author&query=Englesson%2C+E">Erik Englesson</a>, 
<a href="/search/cs?searchtype=author&query=Hotti%2C+A">Alexandra Hotti</a>, 
<a href="/search/cs?searchtype=author&query=Saccardi%2C+C">Carlo Saccardi</a>, 
<a href="/search/cs?searchtype=author&query=Kviman%2C+O">Oskar Kviman</a>, 
<a href="/search/cs?searchtype=author&query=Lagergren%2C+J">Jens Lagergren</a>, 
<a href="/search/cs?searchtype=author&query=Vinuesa%2C+R">Ricardo Vinuesa</a>, 
<a href="/search/cs?searchtype=author&query=Azizpour%2C+H">Hossein Azizpour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Feature selection is a crucial task in settings where data is
high-dimensional or acquiring the full set of features is costly. Recent
developments in neural network-based embedded feature selection show promising
results across a wide range of applications. Concrete Autoencoders (CAEs),
considered state-of-the-art in embedded feature selection, may struggle to
achieve stable joint optimization, hurting their training time and
generalization. In this work, we identify that this instability is correlated
with the CAE learning duplicate selections. To remedy this, we propose a simple
and effective improvement: Indirectly Parameterized CAEs (IP-CAEs). IP-CAEs
learn an embedding and a mapping from it to the Gumbel-Softmax distributions'
parameters. Despite being simple to implement, IP-CAE exhibits significant and
consistent improvements over CAE in both generalization and training time
across several datasets for reconstruction and classification. Unlike CAE,
IP-CAE effectively leverages non-linear relationships and does not require
retraining the jointly optimized decoder. Furthermore, our approach is, in
principle, generalizable to Gumbel-Softmax distributions beyond feature
selection.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00564" title="Abstract">arXiv:2403.00564</a> [<a href="/pdf/2403.00564" title="Download PDF">pdf</a>, <a href="/format/2403.00564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EfficientZero V2: Mastering Discrete and Continuous Control with Limited  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shaohuai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Weirui Ye</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+J">Jiacheng You</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages,10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Sample efficiency remains a crucial challenge in applying Reinforcement
Learning (RL) to real-world tasks. While recent algorithms have made
significant strides in improving sample efficiency, none have achieved
consistently superior performance across diverse domains. In this paper, we
introduce EfficientZero V2, a general framework designed for sample-efficient
RL algorithms. We have expanded the performance of EfficientZero to multiple
domains, encompassing both continuous and discrete actions, as well as visual
and low-dimensional inputs. With a series of improvements we propose,
EfficientZero V2 outperforms the current state-of-the-art (SOTA) by a
significant margin in diverse tasks under the limited data setting.
EfficientZero V2 exhibits a notable advancement over the prevailing general
algorithm, DreamerV3, achieving superior outcomes in 50 of 66 evaluated tasks
across diverse benchmarks, such as Atari 100k, Proprio Control, and Vision
Control.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00565" title="Abstract">arXiv:2403.00565</a> [<a href="/pdf/2403.00565" title="Download PDF">pdf</a>, <a href="/format/2403.00565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting UAV Type: An Exploration of Sampling and Data Augmentation  for Time Series Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Crnovrsanin%2C+T">Tarik Crnovrsanin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Calvin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Hankamer%2C+D">Dane Hankamer</a>, 
<a href="/search/cs?searchtype=author&query=Dunne%2C+C">Cody Dunne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures, 4 tables, submitted to IEEE Transactions on Cybernetics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Unmanned aerial vehicles are becoming common and have many productive uses.
However, their increased prevalence raises safety concerns -- how can we
protect restricted airspace? Knowing the type of unmanned aerial vehicle can go
a long way in determining any potential risks it carries. For instance,
fixed-wing craft can carry more weight over longer distances, thus potentially
posing a more significant threat. This paper presents a machine learning model
for classifying unmanned aerial vehicles as quadrotor, hexarotor, or
fixed-wing. Our approach effectively applies a Long-Short Term Memory (LSTM)
neural network for the purpose of time series classification. We performed
experiments to test the effects of changing the timestamp sampling method and
addressing the imbalance in the class distribution. Through these experiments,
we identified the top-performing sampling and class imbalance fixing methods.
Averaging the macro f-scores across 10 folds of data, we found that the
majority quadrotor class was predicted well (98.16%), and, despite an extreme
class imbalance, the model could also predicted a majority of fixed-wing
flights correctly (73.15%). Hexarotor instances were often misclassified as
quadrotors due to the similarity of multirotors in general (42.15%). However,
results remained relatively stable across certain methods, which prompted us to
analyze and report on their tradeoffs. The supplemental material for this
paper, including the code and data for running all the experiments and
generating the results tables, is available at https://osf.io/mnsgk/.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00566" title="Abstract">arXiv:2403.00566</a> [<a href="/pdf/2403.00566" title="Download PDF">pdf</a>, <a href="/format/2403.00566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lincoln&#x27;s Annotated Spatio-Temporal Strawberry Dataset (LAST-Straw)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=James%2C+K+M+F">Katherine Margaret Frances James</a>, 
<a href="/search/cs?searchtype=author&query=Heiwolt%2C+K">Karoline Heiwolt</a>, 
<a href="/search/cs?searchtype=author&query=Sargent%2C+D+J">Daniel James Sargent</a>, 
<a href="/search/cs?searchtype=author&query=Cielniak%2C+G">Grzegorz Cielniak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Automated phenotyping of plants for breeding and plant studies promises to
provide quantitative metrics on plant traits at a previously unattainable
observation frequency. Developers of tools for performing high-throughput
phenotyping are, however, constrained by the availability of relevant datasets
on which to perform validation. To this end, we present a spatio-temporal
dataset of 3D point clouds of strawberry plants for two varieties, totalling 84
individual point clouds. We focus on the end use of such tools - the extraction
of biologically relevant phenotypes - and demonstrate a phenotyping pipeline on
the dataset. This comprises of the steps, including; segmentation,
skeletonisation and tracking, and we detail how each stage facilitates the
extraction of different phenotypes or provision of data insights. We
particularly note that assessment is focused on the validation of phenotypes,
extracted from the representations acquired at each step of the pipeline,
rather than singularly focusing on assessing the representation itself.
Therefore, where possible, we provide \textit{in silico} ground truth baselines
for the phenotypes extracted at each step and introduce methodology for the
quantitative assessment of skeletonisation and the length trait extracted
thereof. This dataset contributes to the corpus of freely available
agricultural/horticultural spatio-temporal data for the development of
next-generation phenotyping tools, increasing the number of plant varieties
available for research in this field and providing a basis for genuine
comparison of new phenotyping methodology.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00567" title="Abstract">arXiv:2403.00567</a> [<a href="/pdf/2403.00567" title="Download PDF">pdf</a>, <a href="/format/2403.00567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flatten Long-Range Loss Landscapes for Cross-Domain Few-Shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+Y">Yixiong Zou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yicong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yiman Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuhua Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruixuan Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Cross-domain few-shot learning (CDFSL) aims to acquire knowledge from limited
training data in the target domain by leveraging prior knowledge transferred
from source domains with abundant training samples. CDFSL faces challenges in
transferring knowledge across dissimilar domains and fine-tuning models with
limited training data. To address these challenges, we initially extend the
analysis of loss landscapes from the parameter space to the representation
space, which allows us to simultaneously interpret the transferring and
fine-tuning difficulties of CDFSL models. We observe that sharp minima in the
loss landscapes of the representation space result in representations that are
hard to transfer and fine-tune. Moreover, existing flatness-based methods have
limited generalization ability due to their short-range flatness. To enhance
the transferability and facilitate fine-tuning, we introduce a simple yet
effective approach to achieve long-range flattening of the minima in the loss
landscape. This approach considers representations that are differently
normalized as minima in the loss landscape and flattens the high-loss region in
the middle by randomly sampling interpolated representations. We implement this
method as a new normalization layer that replaces the original one in both CNNs
and ViTs. This layer is simple and lightweight, introducing only a minimal
number of additional parameters. Experimental results on 8 datasets demonstrate
that our approach outperforms state-of-the-art methods in terms of average
accuracy. Moreover, our method achieves performance improvements of up to 9\%
compared to the current best approaches on individual datasets. Our code will
be released.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00570" title="Abstract">arXiv:2403.00570</a> [<a href="/pdf/2403.00570" title="Download PDF">pdf</a>, <a href="/format/2403.00570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking cluster-conditioned diffusion models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adaloglou%2C+N">Nikolas Adaloglou</a>, 
<a href="/search/cs?searchtype=author&query=Kaiser%2C+T">Tim Kaiser</a>, 
<a href="/search/cs?searchtype=author&query=Michels%2C+F">Felix Michels</a>, 
<a href="/search/cs?searchtype=author&query=Kollmann%2C+M">Markus Kollmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a comprehensive experimental study on image-level conditioning for
diffusion models using cluster assignments. We elucidate how individual
components regarding image clustering impact image synthesis across three
datasets. By combining recent advancements from image clustering and diffusion
models, we show that, given the optimal cluster granularity with respect to
image synthesis (visual groups), cluster-conditioning can achieve
state-of-the-art FID (i.e. 1.67, 2.17 on CIFAR10 and CIFAR100 respectively),
while attaining a strong training sample efficiency. Finally, we propose a
novel method to derive an upper cluster bound that reduces the search space of
the visual groups using solely feature-based clustering. Unlike existing
approaches, we find no significant connection between clustering and
cluster-conditional image generation. The code and cluster assignments will be
released.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00571" title="Abstract">arXiv:2403.00571</a> [<a href="/pdf/2403.00571" title="Download PDF">pdf</a>, <a href="/format/2403.00571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational homogenization for aerogel-like polydisperse open-porous  materials using neural network--based surrogate models on the microscale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Klawonn%2C+A">Axel Klawonn</a>, 
<a href="/search/math?searchtype=author&query=Lanser%2C+M">Martin Lanser</a>, 
<a href="/search/math?searchtype=author&query=Mager%2C+L">Lucas Mager</a>, 
<a href="/search/math?searchtype=author&query=Rege%2C+A">Ameya Rege</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The morphology of nanostructured materials exhibiting a polydisperse porous
space, such as aerogels, is very open porous and fine grained. Therefore, a
simulation of the deformation of a large aerogel structure resolving the
nanostructure would be extremely expensive. Thus, multi-scale or homogenization
approaches have to be considered. Here, a computational scale bridging approach
based on the FE$^2$ method is suggested, where the macroscopic scale is
discretized using finite elements while the microstructure of the open-porous
material is resolved as a network of Euler-Bernoulli beams. Here, the beam
frame based RVEs (representative volume elements) have pores whose size
distribution follows the measured values for a specific material. This is a
well-known approach to model aerogel structures. For the computational
homogenization, an approach to average the first Piola-Kirchhoff stresses in a
beam frame by neglecting rotational moments is suggested. To further overcome
the computationally most expensive part in the homogenization method, that is,
solving the RVEs and averaging their stress fields, a surrogate model is
introduced based on neural networks. The networks input is the localized
deformation gradient on the macroscopic scale and its output is the averaged
stress for the specific material. It is trained on data generated by the beam
frame based approach. The effiency and robustness of both homogenization
approaches is shown numerically, the approximation properties of the surrogate
model is verified for different macroscopic problems and discretizations.
Different (Quasi-)Newton solvers are considered on the macroscopic scale and
compared with respect to their convergence properties.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00573" title="Abstract">arXiv:2403.00573</a> [<a href="/pdf/2403.00573" title="Download PDF">pdf</a>, <a href="/format/2403.00573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IDTrust: Deep Identity Document Quality Detection with Bandpass  Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Al-Ghadi%2C+M">Musab Al-Ghadi</a>, 
<a href="/search/cs?searchtype=author&query=Voerman%2C+J">Joris Voerman</a>, 
<a href="/search/cs?searchtype=author&query=Bakkali%2C+S">Souhail Bakkali</a>, 
<a href="/search/cs?searchtype=author&query=Coustaty%2C+M">Micka&#xeb;l Coustaty</a>, 
<a href="/search/cs?searchtype=author&query=Sidere%2C+N">Nicolas Sidere</a>, 
<a href="/search/cs?searchtype=author&query=St-Georges%2C+X">Xavier St-Georges</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submit to ICIP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The increasing use of digital technologies and mobile-based registration
procedures highlights the vital role of personal identity documents (IDs) in
verifying users and safeguarding sensitive information. However, the rise in
counterfeit ID production poses a significant challenge, necessitating the
development of reliable and efficient automated verification methods. This
paper introduces IDTrust, a deep-learning framework for assessing the quality
of IDs. IDTrust is a system that enhances the quality of identification
documents by using a deep learning-based approach. This method eliminates the
need for relying on original document patterns for quality checks and
pre-processing steps for alignment. As a result, it offers significant
improvements in terms of dataset applicability. By utilizing a bandpass
filtering-based method, the system aims to effectively detect and differentiate
ID quality. Comprehensive experiments on the MIDV-2020 and L3i-ID datasets
identify optimal parameters, significantly improving discrimination performance
and effectively distinguishing between original and scanned ID documents.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00574" title="Abstract">arXiv:2403.00574</a> [<a href="/pdf/2403.00574" title="Download PDF">pdf</a>, <a href="/format/2403.00574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Single-Model Views for Deep Learning: Optimization versus  Generalizability of Stochastic Optimization Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Inan%2C+T+T">Toki Tahmid Inan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingrui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shehu%2C+A">Amarda Shehu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Despite an extensive body of literature on deep learning optimization, our
current understanding of what makes an optimization algorithm effective is
fragmented. In particular, we do not understand well whether enhanced
optimization translates to improved generalizability. Current research
overlooks the inherent stochastic nature of stochastic gradient descent (SGD)
and its variants, resulting in a lack of comprehensive benchmarking and insight
into their statistical performance. This paper aims to address this gap by
adopting a novel approach. Rather than solely evaluating the endpoint of
individual optimization trajectories, we draw from an ensemble of trajectories
to estimate the stationary distribution of stochastic optimizers. Our
investigation encompasses a wide array of techniques, including SGD and its
variants, flat-minima optimizers, and new algorithms we propose under the Basin
Hopping framework. Through our evaluation, which encompasses synthetic
functions with known minima and real-world problems in computer vision and
natural language processing, we emphasize fair benchmarking under a statistical
framework, comparing stationary distributions and establishing statistical
significance. Our study uncovers several key findings regarding the
relationship between training loss and hold-out accuracy, as well as the
comparable performance of SGD, noise-enabled variants, and novel optimizers
utilizing the BH framework. Notably, these algorithms demonstrate performance
on par with flat-minima optimizers like SAM, albeit with half the gradient
evaluations. We anticipate that our work will catalyze further exploration in
deep learning optimization, encouraging a shift away from single-model
approaches towards methodologies that acknowledge and leverage the stochastic
nature of optimizers.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00578" title="Abstract">arXiv:2403.00578</a> [<a href="/pdf/2403.00578" title="Download PDF">pdf</a>, <a href="/format/2403.00578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SINDy vs Hard Nonlinearities and Hidden Dynamics: a Benchmarking Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ugolini%2C+A+R">Aurelio Raffa Ugolini</a>, 
<a href="/search/eess?searchtype=author&query=Breschi%2C+V">Valentina Breschi</a>, 
<a href="/search/eess?searchtype=author&query=Manzoni%2C+A">Andrea Manzoni</a>, 
<a href="/search/eess?searchtype=author&query=Tanelli%2C+M">Mara Tanelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IFAC SYSID 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work we analyze the effectiveness of the Sparse Identification of
Nonlinear Dynamics (SINDy) technique on three benchmark datasets for nonlinear
identification, to provide a better understanding of its suitability when
tackling real dynamical systems. While SINDy can be an appealing strategy for
pursuing physics-based learning, our analysis highlights difficulties in
dealing with unobserved states and non-smooth dynamics. Due to the ubiquity of
these features in real systems in general, and control applications in
particular, we complement our analysis with hands-on approaches to tackle these
issues in order to exploit SINDy also in these challenging contexts.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00579" title="Abstract">arXiv:2403.00579</a> [<a href="/pdf/2403.00579" title="Download PDF">pdf</a>, <a href="/format/2403.00579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuPIMs: A NPU-PIM Heterogeneous Acceleration for Batched Inference of  Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heo%2C+G">Guseul Heo</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sangyeop Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+J">Jaehong Cho</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+H">Hyunmin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sanghyeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ham%2C+H">Hyungkyu Ham</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+G">Gwangsun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Mahajan%2C+D">Divya Mahajan</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jongse Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Modern transformer-based Large Language Models (LLMs) are constructed with a
series of decoder blocks. Each block comprises three key components: (1) QKV
generation, (2) multi-head attention, and (3) feed-forward networks. In batched
processing, QKV generation and feed-forward networks involve compute-intensive
matrix-matrix multiplications (GEMM), while multi-head attention requires
bandwidth-heavy matrix-vector multiplications (GEMV). Machine learning
accelerators like TPUs or NPUs are proficient in handling GEMM but are less
efficient for GEMV computations. Conversely, Processing-in-Memory (PIM)
technology is tailored for efficient GEMV computation, while it lacks the
computational power to effectively handle GEMM. Inspired by this insight, we
propose NeuPIMs, a heterogeneous accelerator-based system that jointly exploits
a conventional GEMM-focused NPU and GEMV-optimized PIM devices. The main
challenge in efficiently integrating NPU and PIM lies in enabling concurrent
operations on both platforms, each addressing a specific kernel type. First,
existing PIMs typically operate in a "blocked" mode, allowing only either NPU
or PIM to be active at any given time. Second, the inherent dependencies
between GEMM and GEMV in LLMs restrict their parallel processing. To tackle
these challenges, NeuPIMs is equipped with dual row buffers in each bank,
facilitating the simultaneous management of memory read/write operations and
PIM commands. Further, NeuPIMs employs a runtime sub-batch interleaving
technique to maximize concurrent execution, leveraging batch parallelism to
allow two independent sub-batches to be pipelined within a single NeuPIMs node.
Our evaluation demonstrates that compared to an NPU-only approach and a na\"ive
NPU-PIM integrated system, NeuPIMs achieves 2.3$\times$ and 1.6$\times$
throughput improvement, respectively.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00582" title="Abstract">arXiv:2403.00582</a> [<a href="/pdf/2403.00582" title="Download PDF">pdf</a>, <a href="/format/2403.00582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To Trust or Distrust Trust Measures: Validating Questionnaires for Trust  in AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scharowski%2C+N">Nicolas Scharowski</a>, 
<a href="/search/cs?searchtype=author&query=Perrig%2C+S+A+C">Sebastian A. C. Perrig</a>, 
<a href="/search/cs?searchtype=author&query=Aeschbach%2C+L+F">Lena Fanya Aeschbach</a>, 
<a href="/search/cs?searchtype=author&query=von+Felten%2C+N">Nick von Felten</a>, 
<a href="/search/cs?searchtype=author&query=Opwis%2C+K">Klaus Opwis</a>, 
<a href="/search/cs?searchtype=author&query=Wintersberger%2C+P">Philipp Wintersberger</a>, 
<a href="/search/cs?searchtype=author&query=Br%C3%BChlmann%2C+F">Florian Br&#xfc;hlmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Despite the importance of trust in human-AI interactions, researchers must
adopt questionnaires from other disciplines that lack validation in the AI
context. Motivated by the need for reliable and valid measures, we investigated
the psychometric quality of two trust questionnaires, the Trust between People
and Automation scale (TPA) by Jian et al. (2000) and the Trust Scale for the AI
Context (TAI) by Hoffman et al. (2023). In a pre-registered online experiment
(N = 1485), participants observed interactions with trustworthy and
untrustworthy AI (autonomous vehicle and chatbot). Results support the
psychometric quality of the TAI while revealing opportunities to improve the
TPA, which we outline in our recommendations for using the two questionnaires.
Furthermore, our findings provide additional empirical evidence of trust and
distrust as two distinct constructs that may coexist independently. Building on
our findings, we highlight the opportunities and added value of measuring both
trust and distrust in human-AI research and advocate for further work on both
constructs.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00584" title="Abstract">arXiv:2403.00584</a> [<a href="/pdf/2403.00584" title="Download PDF">pdf</a>, <a href="/format/2403.00584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized User Representations for Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fazelnia%2C+G">Ghazal Fazelnia</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Sanket Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Keum%2C+C">Claire Keum</a>, 
<a href="/search/cs?searchtype=author&query=Koh%2C+M">Mark Koh</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+I">Ian Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Lalmas%2C+M">Mounia Lalmas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a novel framework for user representation in large-scale
recommender systems, aiming at effectively representing diverse user taste in a
generalized manner. Our approach employs a two-stage methodology combining
representation learning and transfer learning. The representation learning
model uses an autoencoder that compresses various user features into a
representation space. In the second stage, downstream task-specific models
leverage user representations via transfer learning instead of curating user
features individually. We further augment this methodology on the
representation's input features to increase flexibility and enable reaction to
user events, including new user experiences, in Near-Real Time. Additionally,
we propose a novel solution to manage deployment of this framework in
production models, allowing downstream models to work independently. We
validate the performance of our framework through rigorous offline and online
experiments within a large-scale system, showcasing its remarkable efficacy
across multiple evaluation tasks. Finally, we show how the proposed framework
can significantly reduce infrastructure costs compared to alternative
approaches.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00585" title="Abstract">arXiv:2403.00585</a> [<a href="/pdf/2403.00585" title="Download PDF">pdf</a>, <a href="/format/2403.00585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Uncoded Storage Elastic Computing with Heterogeneous  Computation Speeds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenbo Huang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+X">Xudong You</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+K">Kai Wan</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+R+C">Robert Caiming Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+M">Mingyue Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures, submitted to ISIT2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Elasticity plays an important role in modern cloud computing systems. Elastic
computing allows virtual machines (i.e., computing nodes) to be preempted when
high-priority jobs arise, and also allows new virtual machines to participate
in the computation. In 2018, Yang et al. introduced Coded Storage Elastic
Computing (CSEC) to address the elasticity using coding technology, with lower
storage and computation load requirements. However, CSEC is limited to certain
types of computations (e.g., linear) due to the coded data storage based on
linear coding. Then Centralized Uncoded Storage Elastic Computing (CUSEC) with
heterogeneous computation speeds was proposed, which directly copies parts of
data into the virtual machines. In all existing works in elastic computing, the
storage assignment is centralized, meaning that the number and identity of all
virtual machines possible used in the whole computation process are known
during the storage assignment. In this paper, we consider Decentralized Uncoded
Storage Elastic Computing (DUSEC) with heterogeneous computation speeds, where
any available virtual machine can join the computation which is not predicted
and thus coordination among different virtual machines' storage assignments is
not allowed. Under a decentralized storage assignment originally proposed in
coded caching by Maddah-Ali and Niesen, we propose a computing scheme with
closed-form optimal computation time. We also run experiments over MNIST
dataset with Softmax regression model through the Tencent cloud platform, and
the experiment results demonstrate that the proposed DUSEC system approaches
the state-of-art best storage assignment in the CUSEC system in computation
time.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00586" title="Abstract">arXiv:2403.00586</a> [<a href="/pdf/2403.00586" title="Download PDF">pdf</a>, <a href="/format/2403.00586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open Assistant Toolkit -- version 2
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fischer%2C+S">Sophie Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Rossetto%2C+F">Federico Rossetto</a>, 
<a href="/search/cs?searchtype=author&query=Gemmell%2C+C">Carlos Gemmell</a>, 
<a href="/search/cs?searchtype=author&query=Ramsay%2C+A">Andrew Ramsay</a>, 
<a href="/search/cs?searchtype=author&query=Mackie%2C+I">Iain Mackie</a>, 
<a href="/search/cs?searchtype=author&query=Zubel%2C+P">Philip Zubel</a>, 
<a href="/search/cs?searchtype=author&query=Tecklenburg%2C+N">Niklas Tecklenburg</a>, 
<a href="/search/cs?searchtype=author&query=Dalton%2C+J">Jeffrey Dalton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">We present the second version of the Open Assistant Toolkit (OAT-v2), an
open-source task-oriented conversational system for composing generative neural
models. OAT-v2 is a scalable and flexible assistant platform supporting
multiple domains and modalities of user interaction. It splits processing a
user utterance into modular system components, including submodules such as
action code generation, multimodal content retrieval, and knowledge-augmented
response generation. Developed over multiple years of the Alexa TaskBot
challenge, OAT-v2 is a proven system that enables scalable and robust
experimentation in experimental and real-world deployment. OAT-v2 provides open
models and software for research and commercial applications to enable the
future of multimodal virtual assistants across diverse applications and types
of rich interaction.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00587" title="Abstract">arXiv:2403.00587</a> [<a href="/pdf/2403.00587" title="Download PDF">pdf</a>, <a href="/format/2403.00587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Explicit Spatial Relationships in Text-to-Image Generation  through an Automatically Derived Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salaberria%2C+A">Ander Salaberria</a>, 
<a href="/search/cs?searchtype=author&query=Azkune%2C+G">Gorka Azkune</a>, 
<a href="/search/cs?searchtype=author&query=de+Lacalle%2C+O+L">Oier Lopez de Lacalle</a>, 
<a href="/search/cs?searchtype=author&query=Soroa%2C+A">Aitor Soroa</a>, 
<a href="/search/cs?searchtype=author&query=Agirre%2C+E">Eneko Agirre</a>, 
<a href="/search/cs?searchtype=author&query=Keller%2C+F">Frank Keller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages and 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Existing work has observed that current text-to-image systems do not
accurately reflect explicit spatial relations between objects such as 'left of'
or 'below'. We hypothesize that this is because explicit spatial relations
rarely appear in the image captions used to train these models. We propose an
automatic method that, given existing images, generates synthetic captions that
contain 14 explicit spatial relations. We introduce the Spatial Relation for
Generation (SR4G) dataset, which contains 9.9 millions image-caption pairs for
training, and more than 60 thousand captions for evaluation. In order to test
generalization we also provide an 'unseen' split, where the set of objects in
the train and test captions are disjoint. SR4G is the first dataset that can be
used to spatially fine-tune text-to-image systems. We show that fine-tuning two
different Stable Diffusion models (denoted as SD$_{SR4G}$) yields up to 9
points improvements in the VISOR metric. The improvement holds in the 'unseen'
split, showing that SD$_{SR4G}$ is able to generalize to unseen objects.
SD$_{SR4G}$ improves the state-of-the-art with fewer parameters, and avoids
complex architectures. Our analysis shows that improvement is consistent for
all relations. The dataset and the code will be publicly available.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00590" title="Abstract">arXiv:2403.00590</a> [<a href="/pdf/2403.00590" title="Download PDF">pdf</a>, <a href="/format/2403.00590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hercules: Heterogeneous Requirements Congestion Control Protocol
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rozen-Schiff%2C+N">Neta Rozen-Schiff</a>, 
<a href="/search/cs?searchtype=author&query=Pechtalt%2C+I">Itzcak Pechtalt</a>, 
<a href="/search/cs?searchtype=author&query=Navon%2C+A">Amit Navon</a>, 
<a href="/search/cs?searchtype=author&query=Bruckman%2C+L">Leon Bruckman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Today's networks are struggling to scale and satisfy the high number and high
variety of co-existing network requirements. While existing congestion control
(CC) protocols are designed to handle strict classification of network flows
into one or few priorities, a more granular and dynamic congestion control is
needed.
<br />In this paper we present Hercules, a novel CC protocol based on an online
learning approach, which supports unbounded and continues requirements space.
We implemented Hercules as a QUIC module and we show, through analytical
analysis and real-world experiments, that it provides between $50\%-250\%$
higher QoS for co-existing diverse network flows and outperforms
state-of-the-art CC protocols, even under high network congestion.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00591" title="Abstract">arXiv:2403.00591</a> [<a href="/pdf/2403.00591" title="Download PDF">pdf</a>, <a href="/format/2403.00591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Causal Features for Incremental Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhenwei He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Object detection limits its recognizable categories during the training
phase, in which it can not cover all objects of interest for users. To satisfy
the practical necessity, the incremental learning ability of the detector
becomes a critical factor for real-world applications. Unfortunately, neural
networks unavoidably meet catastrophic forgetting problem when it is
implemented on a new task. To this end, many incremental object detection
models preserve the knowledge of previous tasks by replaying samples or
distillation from previous models. However, they ignore an important factor
that the performance of the model mostly depends on its feature. These models
try to rouse the memory of the neural network with previous samples but not to
prevent forgetting. To this end, in this paper, we propose an incremental
causal object detection (ICOD) model by learning causal features, which can
adapt to more tasks. Traditional object detection models, unavoidably depend on
the data-bias or data-specific features to get the detection results, which can
not adapt to the new task. When the model meets the requirements of incremental
learning, the data-bias information is not beneficial to the new task, and the
incremental learning may eliminate these features and lead to forgetting. To
this end, our ICOD is introduced to learn the causal features, rather than the
data-bias features when training the detector. Thus, when the model is
implemented to a new task, the causal features of the old task can aid the
incremental learning process to alleviate the catastrophic forgetting problem.
We conduct our model on several experiments, which shows a causal feature
without data-bias can make the model adapt to new tasks better.
\keywords{Object detection, incremental learning, causal feature.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00592" title="Abstract">arXiv:2403.00592</a> [<a href="/pdf/2403.00592" title="Download PDF">pdf</a>, <a href="/format/2403.00592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Few-shot 3D Point Cloud Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+Z">Zhaochong An</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Guolei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fayao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zongwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>, 
<a href="/search/cs?searchtype=author&query=Belongie%2C+S">Serge Belongie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper revisits few-shot 3D point cloud semantic segmentation (FS-PCS),
with a focus on two significant issues in the state-of-the-art: foreground
leakage and sparse point distribution. The former arises from non-uniform point
sampling, allowing models to distinguish the density disparities between
foreground and background for easier segmentation. The latter results from
sampling only 2,048 points, limiting semantic information and deviating from
the real-world practice. To address these issues, we introduce a standardized
FS-PCS setting, upon which a new benchmark is built. Moreover, we propose a
novel FS-PCS model. While previous methods are based on feature optimization by
mainly refining support features to enhance prototypes, our method is based on
correlation optimization, referred to as Correlation Optimization Segmentation
(COSeg). Specifically, we compute Class-specific Multi-prototypical Correlation
(CMC) for each query point, representing its correlations to category
prototypes. Then, we propose the Hyper Correlation Augmentation (HCA) module to
enhance CMC. Furthermore, tackling the inherent property of few-shot training
to incur base susceptibility for models, we propose to learn non-parametric
prototypes for the base classes during training. The learned base prototypes
are used to calibrate correlations for the background class through a Base
Prototypes Calibration (BPC) module. Experiments on popular datasets
demonstrate the superiority of COSeg over existing methods. The code is
available at: https://github.com/ZhaochongAn/COSeg
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00594" title="Abstract">arXiv:2403.00594</a> [<a href="/pdf/2403.00594" title="Download PDF">pdf</a>, <a href="/format/2403.00594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discrete minimizers of the interaction energy in collective behavior: a  brief numerical and analytic review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ca%C3%B1izo%2C+J+A">Jos&#xe9; A. Ca&#xf1;izo</a>, 
<a href="/search/math?searchtype=author&query=Ramos-Lora%2C+A">Alejandro Ramos-Lora</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)

</div>
<p class="mathjax">We consider minimizers of the N-particle interaction potential energy and
briefly review numerical methods used to calculate them. We consider simple
pair potentials which are attractive at short distances and repulsive at long
distances, focusing on examples which are sums of two powers. The range of
powers we look at includes the well-known case of the Lennard-Jones potential,
but we are also interested in less singular potentials which are relevant in
collective behavior models. We report on results using the software GMIN
developed by Wales and collaborators for problems in chemistry. For all cases,
this algorithm gives good candidates for the minimizers for relatively low
values of the particle number N. This is well-known for potentials similar to
Lennard-Jones, but not for the range which is of interest in collective
behavior. Standard minimization procedures have been used in the literature in
this range, but they are likely to yield stationary states which are not
minimizers. We illustrate numerically some properties of the minimizers in 2D,
such as lattice structure, Wulff shapes, and the continuous large-N limit for
locally integrable (that is, less singular) potentials.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00598" title="Abstract">arXiv:2403.00598</a> [<a href="/pdf/2403.00598" title="Download PDF">pdf</a>, <a href="/ps/2403.00598" title="Download PostScript">ps</a>, <a href="/format/2403.00598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Popularity and Perfectness in One-sided Matching Markets with Capacities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cs%C3%A1ji%2C+G">Gergely Cs&#xe1;ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We consider many-to-one matching problems, where one side corresponds to
applicants who have preferences and the other side to houses who do not have
preferences. We consider two different types of this market: one, where the
applicants have capacities, and one where the houses do. First, we answer an
open question by Manlove and Sng (2006) (partly solved Paluch (2014) for
preferences with ties), that is, we show that deciding if a popular matching
exists in the house allocation problem, where agents have capacities is NP-hard
for previously studied versions of popularity. Then, we consider the other
version, where the houses have capacities. We study how to optimally increase
the capacities of the houses to obtain a matching satisfying multiple
optimality criteria, like popularity, Pareto-optimality and perfectness. We
consider two common optimality criteria, one aiming to minimize the sum of
capacity increases of all houses and the other aiming to minimize the maximum
capacity increase of any school. We obtain a complete picture in terms of
computational complexity and some algorithms.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00606" title="Abstract">arXiv:2403.00606</a> [<a href="/pdf/2403.00606" title="Download PDF">pdf</a>, <a href="/format/2403.00606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flattening Singular Values of Factorized Convolution for Medical Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zexin Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+N">Na Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jiansheng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiaoxi Lu</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+H">Heng Meng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Convolutional neural networks (CNNs) have long been the paradigm of choice
for robust medical image processing (MIP). Therefore, it is crucial to
effectively and efficiently deploy CNNs on devices with different computing
capabilities to support computer-aided diagnosis. Many methods employ
factorized convolutional layers to alleviate the burden of limited
computational resources at the expense of expressiveness. To this end, given
weak medical image-driven CNN model optimization, a Singular value equalization
generalizer-induced Factorized Convolution (SFConv) is proposed to improve the
expressive power of factorized convolutions in MIP models. We first decompose
the weight matrix of convolutional filters into two low-rank matrices to
achieve model reduction. Then minimize the KL divergence between the two
low-rank weight matrices and the uniform distribution, thereby reducing the
number of singular value directions with significant variance. Extensive
experiments on fundus and OCTA datasets demonstrate that our SFConv yields
competitive expressiveness over vanilla convolutions while reducing complexity.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00607" title="Abstract">arXiv:2403.00607</a> [<a href="/pdf/2403.00607" title="Download PDF">pdf</a>, <a href="/format/2403.00607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Operational Planning in Warfare: A Stochastic Game Approach to  Military Campaigns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McCarthy%2C+J+E">Joseph E. McCarthy</a>, 
<a href="/search/cs?searchtype=author&query=Dahan%2C+M">Mathieu Dahan</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+C+C">Chelsea C. White III</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We study a two-player discounted zero-sum stochastic game model for dynamic
operational planning in military campaigns. At each stage, the players manage
multiple commanders who order military actions on objectives that have an open
line of control. When a battle over the control of an objective occurs, its
stochastic outcome depends on the actions and the enabling support provided by
the control of other objectives. Each player aims to maximize the cumulative
number of objectives they control, weighted by their criticality. To solve this
large-scale stochastic game, we derive properties of its Markov perfect
equilibria by leveraging the logistics and military operational command and
control structure. We show the consequential isotonicity of the optimal value
function with respect to the partially ordered state space, which in turn leads
to a significant reduction of the state and action spaces. We also accelerate
Shapley's value iteration algorithm by eliminating dominated actions and
investigating pure equilibria of the matrix game solved at each iteration. We
demonstrate the computational value of our equilibrium results on a case study
that reflects representative operational-level military campaigns with
geopolitical implications. Our analysis reveals a complex interplay between the
game's parameters and dynamics in equilibrium, resulting in new military
insights for campaign analysts.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00611" title="Abstract">arXiv:2403.00611</a> [<a href="/pdf/2403.00611" title="Download PDF">pdf</a>, <a href="/format/2403.00611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic positioning via ray tracing with noisy angle of arrival  measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Corlay%2C+V">Vincent Corlay</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Viet-Hoa Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Gresset%2C+N">Nicolas Gresset</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Communications Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper investigates the problems of interference prediction and sensing
for efficient spectrum access and link adaptation. The considered approach for
interference prediction relies on a parametric model. However, we assume that
the number of observations available to learn theses parameters is limited.
This implies that they should be treated as random variables rather than fixed
values. We show how this can impact the spectrum access and link adaptation
strategies. We also introduce the notion of "interferer-coherence time" to
establish the number of independent interferer state realizations experienced
by a codeword. We explain how it can be computed taking into account the model
uncertainty and how this impacts the link adaptation.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00613" title="Abstract">arXiv:2403.00613</a> [<a href="/pdf/2403.00613" title="Download PDF">pdf</a>, <a href="/format/2403.00613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complete and Near-Optimal Robotic Crack Coverage and Filling in Civil  Infrastructure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Veeraraghavan%2C+V">Vishnu Veeraraghavan</a>, 
<a href="/search/cs?searchtype=author&query=Hunte%2C+K">Kyle Hunte</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jingang Yi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kaiyan Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We present a simultaneous sensor-based inspection and footprint coverage
(SIFC) planning and control design with applications to autonomous robotic
crack mapping and filling. The main challenge of the SIFC problem lies in the
coupling of complete sensing (for mapping) and robotic footprint (for filling)
coverage tasks. Initially, we assume known target information (e.g., crack) and
employ classic cell decomposition methods to achieve complete sensing coverage
of the workspace and complete robotic footprint coverage using the least-cost
route. Subsequently, we generalize the algorithm to handle unknown target
information, allowing the robot to scan and incrementally construct the target
graph online while conducting robotic footprint coverage. The online
polynomial-time SIFC planning algorithm minimizes the total robot traveling
distance, guarantees complete sensing coverage of the entire workspace, and
achieves near-optimal robotic footprint coverage, as demonstrated through
empirical experiments. For the demonstrated application, we design coordinated
nozzle motion control with the planned robot trajectory to efficiently fill all
cracks within the robot's footprint. Experimental results are presented to
illustrate the algorithm's design, performance, and comparisons. The SIFC
algorithm offers a high-efficiency motion planning solution for various robotic
applications requiring simultaneous sensing and actuation coverage.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00621" title="Abstract">arXiv:2403.00621</a> [<a href="/pdf/2403.00621" title="Download PDF">pdf</a>, <a href="/ps/2403.00621" title="Download PostScript">ps</a>, <a href="/format/2403.00621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaBoost-Based Efficient Channel Estimation and Data Detection in  One-Bit Massive MIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esfandiari%2C+M">Majdoddin Esfandiari</a>, 
<a href="/search/cs?searchtype=author&query=Vorobyov%2C+S+A">Sergiy A. Vorobyov</a>, 
<a href="/search/cs?searchtype=author&query=Heath%2C+R+W">Robert W. Heath Jr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The use of one-bit analog-to-digital converter (ADC) has been considered as a
viable alternative to high resolution counterparts in realizing and
commercializing massive multiple-input multiple-output (MIMO) systems. However,
the issue of discarding the amplitude information by one-bit quantizers has to
be compensated. Thus, carefully tailored methods need to be developed for
one-bit channel estimation and data detection as the conventional ones cannot
be used. To address these issues, the problems of one-bit channel estimation
and data detection for MIMO orthogonal frequency division multiplexing (OFDM)
system that operates over uncorrelated frequency selective channels are
investigated here. We first develop channel estimators that exploit Gaussian
discriminant analysis (GDA) classifier and approximated versions of it as the
so-called weak classifiers in an adaptive boosting (AdaBoost) approach.
Particularly, the combination of the approximated GDA classifiers with AdaBoost
offers the benefit of scalability with the linear order of computations, which
is critical in massive MIMO-OFDM systems. We then take advantage of the same
idea for proposing the data detectors. Numerical results validate the
efficiency of the proposed channel estimators and data detectors compared to
other methods. They show comparable/better performance to that of the
state-of-the-art methods, but require dramatically lower computational
complexities and run times.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00622" title="Abstract">arXiv:2403.00622</a> [<a href="/pdf/2403.00622" title="Download PDF">pdf</a>, <a href="/ps/2403.00622" title="Download PostScript">ps</a>, <a href="/format/2403.00622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shortened Polar Codes under Automorphism Ensemble Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pillet%2C+C">Charles Pillet</a>, 
<a href="/search/cs?searchtype=author&query=Sagitov%2C+I">Ilshat Sagitov</a>, 
<a href="/search/cs?searchtype=author&query=Bioglio%2C+V">Valerio Bioglio</a>, 
<a href="/search/cs?searchtype=author&query=Giard%2C+P">Pascal Giard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, accepted in IEEE Communications Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we propose a low-latency decoding solution of shortened polar
codes based on their automorphism groups. The automorphism group of shortened
polar codes, designed according to two existing shortening patterns, are shown
to be limited but non-empty, making the Automorphism Ensemble (AE) decoding of
shortened polar codes possible. Extensive simulation results for shortened
polar codes under AE are provided and are compared to the SC-List (SCL)
algorithm. The block-error rate of shortened polar codes under AE matches or
beats SCL while lowering the decoding latency.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00623" title="Abstract">arXiv:2403.00623</a> [<a href="/pdf/2403.00623" title="Download PDF">pdf</a>, <a href="/format/2403.00623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of the particle relaxation method for generating uniform  particle distributions in smoothed particle hydrodynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fan%2C+Y">Yu Fan</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+X">Xiaoliang Li</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+S">Shuoguo Zhang</a>, 
<a href="/search/math?searchtype=author&query=Hu%2C+X">Xiangyu Hu</a>, 
<a href="/search/math?searchtype=author&query=Adams%2C+N+A">Nikolaus A. Adams</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">We establish a theoretical framework of the particle relaxation method for
uniform particle generation of Smoothed Particle Hydrodynamics. We achieve this
by reformulating the particle relaxation as an optimization problem. The
objective function is an integral difference between discrete particle-based
and smoothed-analytical volume fractions. The analysis demonstrates that the
particle relaxation method in the domain interior is essentially equivalent to
employing a gradient descent approach to solve this optimization problem, and
we can extend such an equivalence to the bounded domain by introducing a proper
boundary term. Additionally, each periodic particle distribution has a
spatially uniform particle volume, denoted as characteristic volume. The
relaxed particle distribution has the largest characteristic volume, and the
kernel cut-off radius determines this volume. This insight enables us to
control the relaxed particle distribution by selecting the target kernel
cut-off radius for a given kernel function.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00625" title="Abstract">arXiv:2403.00625</a> [<a href="/pdf/2403.00625" title="Download PDF">pdf</a>, <a href="/format/2403.00625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bias Mitigation in Fine-tuning Pre-trained Models for Enhanced Fairness  and Efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yixuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Feng Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Fine-tuning pre-trained models is a widely employed technique in numerous
real-world applications. However, fine-tuning these models on new tasks can
lead to unfair outcomes. This is due to the absence of generalization
guarantees for fairness properties, regardless of whether the original
pre-trained model was developed with fairness considerations. To tackle this
issue, we introduce an efficient and robust fine-tuning framework specifically
designed to mitigate biases in new tasks. Our empirical analysis shows that the
parameters in the pre-trained model that affect predictions for different
demographic groups are different, so based on this observation, we employ a
transfer learning strategy that neutralizes the importance of these influential
weights, determined using Fisher information across demographic groups.
Additionally, we integrate this weight importance neutralization strategy with
a matrix factorization technique, which provides a low-rank approximation of
the weight matrix using fewer parameters, reducing the computational demands.
Experiments on multiple pre-trained models and new tasks demonstrate the
effectiveness of our method.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00628" title="Abstract">arXiv:2403.00628</a> [<a href="/pdf/2403.00628" title="Download PDF">pdf</a>, <a href="/format/2403.00628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Region-Adaptive Transform with Segmentation Prior for Image Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuxi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenhan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+H">Huihui Bai</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yunchao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Learned Image Compression (LIC) has shown remarkable progress in recent
years. Existing works commonly employ CNN-based or self-attention-based modules
as transform methods for compression. However, there is no prior research on
neural transform that focuses on specific regions. In response, we introduce
the class-agnostic segmentation masks (i.e. semantic masks without category
labels) for extracting region-adaptive contextual information. Our proposed
module, Region-Adaptive Transform, applies adaptive convolutions on different
regions guided by the masks. Additionally, we introduce a plug-and-play module
named Scale Affine Layer to incorporate rich contexts from various regions.
While there have been prior image compression efforts that involve segmentation
masks as additional intermediate inputs, our approach differs significantly
from them. Our advantages lie in that, to avoid extra bitrate overhead, we
treat these masks as privilege information, which is accessible during the
model training stage but not required during the inference phase. To the best
of our knowledge, we are the first to employ class-agnostic masks as privilege
information and achieve superior performance in pixel-fidelity metrics, such as
Peak Signal to Noise Ratio (PSNR). The experimental results demonstrate our
improvement compared to previously well-performing methods, with about 8.2%
bitrate saving compared to VTM-17.0. The code will be released at
https://github.com/GityuxiLiu/Region-Adaptive-Transform-with-Segmentation-Prior-for-Image-Compression.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00631" title="Abstract">arXiv:2403.00631</a> [<a href="/pdf/2403.00631" title="Download PDF">pdf</a>, <a href="/format/2403.00631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transforming Design Spaces Using Pareto-Laplace Filters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aliahmadi%2C+H">Hazhir Aliahmadi</a>, 
<a href="/search/cs?searchtype=author&query=Perez%2C+R">Ruben Perez</a>, 
<a href="/search/cs?searchtype=author&query=van+Anders%2C+G">Greg van Anders</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28+19 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Statistical Mechanics (cond-mat.stat-mech); Optimization and Control (math.OC)

</div>
<p class="mathjax">Optimization is a critical tool for addressing a broad range of human and
technical problems. However, the paradox of advanced optimization techniques is
that they have maximum utility for problems in which the relationship between
the structure of the problem and the ultimate solution is the most obscure. The
existence of solution with limited insight contrasts with techniques that have
been developed for a broad range of engineering problems where integral
transform techniques yield solutions and insight in tandem. Here, we present a
``Pareto-Laplace'' integral transform framework that can be applied to problems
typically studied via optimization. We show that the framework admits related
geometric, statistical, and physical representations that provide new forms of
insight into relationships between objectives and outcomes. We argue that some
known approaches are special cases of this framework, and point to a broad
range of problems for further application.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00632" title="Abstract">arXiv:2403.00632</a> [<a href="/pdf/2403.00632" title="Download PDF">pdf</a>, <a href="/format/2403.00632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metamorpheus: Interactive, Affective, and Creative Dream Narration  Through Metaphorical Visual Storytelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Q">Qian Wan</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xin Feng</a>, 
<a href="/search/cs?searchtype=author&query=Bei%2C+Y">Yining Bei</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhiqi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhicong Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Human emotions are essentially molded by lived experiences, from which we
construct personalised meaning. The engagement in such meaning-making process
has been practiced as an intervention in various psychotherapies to promote
wellness. Nevertheless, to support recollecting and recounting lived
experiences in everyday life remains under explored in HCI. It also remains
unknown how technologies such as generative AI models can facilitate the
meaning making process, and ultimately support affective mindfulness. In this
paper we present Metamorpheus, an affective interface that engages users in a
creative visual storytelling of emotional experiences during dreams.
Metamorpheus arranges the storyline based on a dream's emotional arc, and
provokes self-reflection through the creation of metaphorical images and text
depictions. The system provides metaphor suggestions, and generates visual
metaphors and text depictions using generative AI models, while users can apply
generations to recolour and re-arrange the interface to be visually affective.
Our experience-centred evaluation manifests that, by interacting with
Metamorpheus, users can recall their dreams in vivid detail, through which they
relive and reflect upon their experiences in a meaningful way.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00633" title="Abstract">arXiv:2403.00633</a> [<a href="/pdf/2403.00633" title="Download PDF">pdf</a>, <a href="/format/2403.00633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Informed and Assessable Observability Design Decisions in Cloud-native  Microservice Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borges%2C+M+C">Maria C. Borges</a>, 
<a href="/search/cs?searchtype=author&query=Bauer%2C+J">Joshua Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Werner%2C+S">Sebastian Werner</a>, 
<a href="/search/cs?searchtype=author&query=Gebauer%2C+M">Michael Gebauer</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+S">Stefan Tai</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on Software Architecture 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Observability is important to ensure the reliability of microservice
applications. These applications are often prone to failures, since they have
many independent services deployed on heterogeneous environments. When employed
"correctly", observability can help developers identify and troubleshoot faults
quickly. However, instrumenting and configuring the observability of a
microservice application is not trivial but tool-dependent and tied to costs.
Architects need to understand observability-related trade-offs in order to
weigh between different observability design alternatives. Still, these
architectural design decisions are not supported by systematic methods and
typically just rely on "professional intuition". In this paper, we argue for a
systematic method to arrive at informed and continuously assessable
observability design decisions. Specifically, we focus on fault observability
of cloud-native microservice applications, and turn this into a testable and
quantifiable property. Towards our goal, we first model the scale and scope of
observability design decisions across the cloud-native stack. Then, we propose
observability metrics which can be determined for any microservice application
through so-called observability experiments. We present a proof-of-concept
implementation of our experiment tool OXN. OXN is able to inject arbitrary
faults into an application, similar to Chaos Engineering, but also possesses
the unique capability to modify the observability configuration, allowing for
the assessment of design decisions that were previously left unexplored. We
demonstrate our approach using a popular open source microservice application
and show the trade-offs involved in different observability design decisions.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00641" title="Abstract">arXiv:2403.00641</a> [<a href="/pdf/2403.00641" title="Download PDF">pdf</a>, <a href="/format/2403.00641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Online Epistemic Replanning of Multi-Robot Missions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bramblett%2C+L">Lauren Bramblett</a>, 
<a href="/search/cs?searchtype=author&query=Miloradovic%2C+B">Branko Miloradovic</a>, 
<a href="/search/cs?searchtype=author&query=Sherman%2C+P">Patrick Sherman</a>, 
<a href="/search/cs?searchtype=author&query=Papadopoulos%2C+A+V">Alessandro V. Papadopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Bezzo%2C+N">Nicola Bezzo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">As Multi-Robot Systems (MRS) become more affordable and computing
capabilities grow, they provide significant advantages for complex applications
such as environmental monitoring, underwater inspections, or space exploration.
However, accounting for potential communication loss or the unavailability of
communication infrastructures in these application domains remains an open
problem. Much of the applicable MRS research assumes that the system can
sustain communication through proximity regulations and formation control or by
devising a framework for separating and adhering to a predetermined plan for
extended periods of disconnection. The latter technique enables an MRS to be
more efficient, but breakdowns and environmental uncertainties can have a
domino effect throughout the system, particularly when the mission goal is
intricate or time-sensitive. To deal with this problem, our proposed framework
has two main phases: i) a centralized planner to allocate mission tasks by
rewarding intermittent rendezvous between robots to mitigate the effects of the
unforeseen events during mission execution, and ii) a decentralized replanning
scheme leveraging epistemic planning to formalize belief propagation and a
Monte Carlo tree search for policy optimization given distributed rational
belief updates. The proposed framework outperforms a baseline heuristic and is
validated using simulations and experiments with aerial vehicles.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00642" title="Abstract">arXiv:2403.00642</a> [<a href="/pdf/2403.00642" title="Download PDF">pdf</a>, <a href="/format/2403.00642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking The Uniformity Metric in Self-Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+X">Xianghong Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jian Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Benyou Wang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Uniformity plays a crucial role in the assessment of learned representations,
contributing to a deeper comprehension of self-supervised learning. The seminal
work by \citet{Wang2020UnderstandingCR} introduced a uniformity metric that
quantitatively measures the collapse degree of learned representations.
Directly optimizing this metric together with alignment proves to be effective
in preventing constant collapse. However, we present both theoretical and
empirical evidence revealing that this metric lacks sensitivity to dimensional
collapse, highlighting its limitations. To address this limitation and design a
more effective uniformity metric, this paper identifies five fundamental
properties, some of which the existing uniformity metric fails to meet. We
subsequently introduce a novel uniformity metric that satisfies all of these
desiderata and exhibits sensitivity to dimensional collapse. When applied as an
auxiliary loss in various established self-supervised methods, our proposed
uniformity metric consistently enhances their performance in downstream
tasks.Our code was released at
https://github.com/sunset-clouds/WassersteinUniformityMetric.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00643" title="Abstract">arXiv:2403.00643</a> [<a href="/pdf/2403.00643" title="Download PDF">pdf</a>, <a href="/ps/2403.00643" title="Download PostScript">ps</a>, <a href="/format/2403.00643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Undercomplete Decomposition of Symmetric Tensors in Linear Time, and  Smoothed Analysis of the Condition Number
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koiran%2C+P">Pascal Koiran</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Subhayan Saha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 55 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Numerical Analysis (math.NA)

</div>
<p class="mathjax">We study symmetric tensor decompositions, i.e., decompositions of the form $T
= \sum_{i=1}^r u_i^{\otimes 3}$ where $T$ is a symmetric tensor of order 3 and
$u_i \in \mathbb{C}^n$.In order to obtain efficient decomposition algorithms,
it is necessary to require additional properties from $u_i$. In this paper we
assume that the $u_i$ are linearly independent. This implies $r \leq n$,that
is, the decomposition of T is undercomplete.
<br />We give a randomized algorithm for the following problem in the exact
arithmetic model of computation: Let $T$ be an order-3 symmetric tensor that
has an undercomplete decomposition.Then given some $T'$ close to $T$, an
accuracy parameter $\varepsilon$, and an upper bound B on the condition number
of the tensor, output vectors $u'_i$ such that $||u_i - u'_i|| \leq
\varepsilon$ (up to permutation and multiplication by cube roots of unity) with
high probability. The main novel features of our algorithm are:
<br />1) We provide the first algorithm for this problem that runs in linear time
in the size of the input tensor. More specifically, it requires $O(n^3)$
arithmetic operations for all accuracy parameters $\varepsilon =$ 1/poly(n) and
B = poly(n).
<br />2) Our algorithm is robust, that is, it can handle inverse-quasi-polynomial
noise (in $n$,B,$\frac{1}{\varepsilon}$) in the input tensor.
<br />3) We present a smoothed analysis of the condition number of the tensor
decomposition problem. This guarantees that the condition number is low with
high probability and further shows that our algorithm runs in linear time,
except for some rare badly conditioned inputs.
<br />Our main algorithm is a reduction to the complete case ($r=n$) treated in our
previous work [Koiran,Saha,CIAC 2023]. For efficiency reasons we cannot use
this algorithm as a blackbox. Instead, we show that it can be run on an
implicitly represented tensor obtained from the input tensor by a change of
basis.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00644" title="Abstract">arXiv:2403.00644</a> [<a href="/pdf/2403.00644" title="Download PDF">pdf</a>, <a href="/format/2403.00644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diff-Plugin: Revitalizing Details for Diffusion-based Low-level Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+Z">Zhanghan Ke</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+N">Nanxuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+R+W+H">Rynson W.H. Lau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion models trained on large-scale datasets have achieved remarkable
progress in image synthesis. However, due to the randomness in the diffusion
process, they often struggle with handling diverse low-level tasks that require
details preservation. To overcome this limitation, we present a new Diff-Plugin
framework to enable a single pre-trained diffusion model to generate
high-fidelity results across a variety of low-level tasks. Specifically, we
first propose a lightweight Task-Plugin module with a dual branch design to
provide task-specific priors, guiding the diffusion process in preserving image
content. We then propose a Plugin-Selector that can automatically select
different Task-Plugins based on the text instruction, allowing users to edit
images by indicating multiple low-level tasks with natural language. We conduct
extensive experiments on 8 low-level vision tasks. The results demonstrate the
superiority of Diff-Plugin over existing methods, particularly in real-world
scenarios. Our ablations further validate that Diff-Plugin is stable,
schedulable, and supports robust training across different dataset sizes.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00645" title="Abstract">arXiv:2403.00645</a> [<a href="/pdf/2403.00645" title="Download PDF">pdf</a>, <a href="/ps/2403.00645" title="Download PostScript">ps</a>, <a href="/format/2403.00645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Event-Triggered Robust Cooperative Output Regulation for a Class of  Linear Multi-Agent Systems with an Unknown Exosystem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Qian%2C+Y">Yangyang Qian</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+L">Lu Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper investigates the robust cooperative output regulation problem for
a class of heterogeneous uncertain linear multi-agent systems with an unknown
exosystem via event-triggered control (ETC). By utilizing the internal model
approach and the adaptive control technique, a distributed adaptive internal
model is constructed for each agent. Then, based on this internal model, a
fully distributed ETC strategy composed of a distributed event-triggered
adaptive output feedback control law and a distributed dynamic event-triggering
mechanism is proposed, in which each agent updates its control input at its own
triggering time instants. It is shown that under the proposed ETC strategy, the
robust cooperative output regulation problem can be solved without requiring
either the global information associated with the communication topology or the
bounds of the uncertain or unknown parameters in each agent and the exosystem.
A numerical example is provided to illustrate the effectiveness of the proposed
control strategy.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00646" title="Abstract">arXiv:2403.00646</a> [<a href="/pdf/2403.00646" title="Download PDF">pdf</a>, <a href="/format/2403.00646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability-Certified Learning of Control Systems with Quadratic  Nonlinearities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duff%2C+I+P">Igor Pontes Duff</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+P">Pawan Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Benner%2C+P">Peter Benner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS); Optimization and Control (math.OC)

</div>
<p class="mathjax">This work primarily focuses on an operator inference methodology aimed at
constructing low-dimensional dynamical models based on a priori hypotheses
about their structure, often informed by established physics or expert
insights. Stability is a fundamental attribute of dynamical systems, yet it is
not always assured in models derived through inference. Our main objective is
to develop a method that facilitates the inference of quadratic control
dynamical systems with inherent stability guarantees. To this aim, we
investigate the stability characteristics of control systems with
energy-preserving nonlinearities, thereby identifying conditions under which
such systems are bounded-input bounded-state stable. These insights are
subsequently applied to the learning process, yielding inferred models that are
inherently stable by design. The efficacy of our proposed framework is
demonstrated through a couple of numerical examples.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00662" title="Abstract">arXiv:2403.00662</a> [<a href="/pdf/2403.00662" title="Download PDF">pdf</a>, <a href="/format/2403.00662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling the Quality of Dialogical Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alshomary%2C+M">Milad Alshomary</a>, 
<a href="/search/cs?searchtype=author&query=Lange%2C+F">Felix Lange</a>, 
<a href="/search/cs?searchtype=author&query=Booshehri%2C+M">Meisam Booshehri</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+M">Meghdut Sengupta</a>, 
<a href="/search/cs?searchtype=author&query=Cimiano%2C+P">Philipp Cimiano</a>, 
<a href="/search/cs?searchtype=author&query=Wachsmuth%2C+H">Henning Wachsmuth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures, LREC-COLING 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Explanations are pervasive in our lives. Mostly, they occur in dialogical
form where an {\em explainer} discusses a concept or phenomenon of interest
with an {\em explainee}. Leaving the explainee with a clear understanding is
not straightforward due to the knowledge gap between the two participants.
Previous research looked at the interaction of explanation moves, dialogue
acts, and topics in successful dialogues with expert explainers. However,
daily-life explanations often fail, raising the question of what makes a
dialogue successful. In this work, we study explanation dialogues in terms of
the interactions between the explainer and explainee and how they correlate
with the quality of explanations in terms of a successful understanding on the
explainee's side. In particular, we first construct a corpus of 399 dialogues
from the Reddit forum {\em Explain Like I am Five} and annotate it for
interaction flows and explanation quality. We then analyze the interaction
flows, comparing them to those appearing in expert dialogues. Finally, we
encode the interaction flows using two language models that can handle long
inputs, and we provide empirical evidence for the effectiveness boost gained
through the encoding in predicting the success of explanation dialogues.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00663" title="Abstract">arXiv:2403.00663</a> [<a href="/pdf/2403.00663" title="Download PDF">pdf</a>, <a href="/format/2403.00663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COLON: The largest COlonoscopy LONg sequence public database
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruiz%2C+L">Lina Ruiz</a>, 
<a href="/search/cs?searchtype=author&query=Sierra-Jerez%2C+F">Franklin Sierra-Jerez</a>, 
<a href="/search/cs?searchtype=author&query=Ruiz%2C+J">Jair Ruiz</a>, 
<a href="/search/cs?searchtype=author&query=Martinez%2C+F">Fabio Martinez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Colorectal cancer is the third most aggressive cancer worldwide. Polyps, as
the main biomarker of the disease, are detected, localized, and characterized
through colonoscopy procedures. Nonetheless, during the examination, up to 25%
of polyps are missed, because of challenging conditions (camera movements,
lighting changes), and the close similarity of polyps and intestinal folds.
Besides, there is a remarked subjectivity and expert dependency to observe and
detect abnormal regions along the intestinal tract. Currently, publicly
available polyp datasets have allowed significant advances in computational
strategies dedicated to characterizing non-parametric polyp shapes. These
computational strategies have achieved remarkable scores of up to 90% in
segmentation tasks. Nonetheless, these strategies operate on cropped and
expert-selected frames that always observe polyps. In consequence, these
computational approximations are far from clinical scenarios and real
applications, where colonoscopies are redundant on intestinal background with
high textural variability. In fact, the polyps typically represent less than 1%
of total observations in a complete colonoscopy record. This work introduces
COLON: the largest COlonoscopy LONg sequence dataset with around of 30 thousand
polyp labeled frames and 400 thousand background frames. The dataset was
collected from a total of 30 complete colonoscopies with polyps at different
stages, variations in preparation procedures, and some cases the observation of
surgical instrumentation. Additionally, 10 full intestinal background video
control colonoscopies were integrated in order to achieve a robust
polyp-background frame differentiation. The COLON dataset is open to the
scientific community to bring new scenarios to propose computational tools
dedicated to polyp detection and segmentation over long sequences, being closer
to real colonoscopy scenarios.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00665" title="Abstract">arXiv:2403.00665</a> [<a href="/pdf/2403.00665" title="Download PDF">pdf</a>, <a href="/format/2403.00665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complex-Valued Neural Network based Federated Learning for Multi-user  Indoor Positioning Performance Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hanzhi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingzhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuchen Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this article, the use of channel state information (CSI) for indoor
positioning is studied. In the considered model, a server equipped with several
antennas sends pilot signals to users, while each user uses the received pilot
signals to estimate channel states for user positioning. To this end, we
formulate the positioning problem as an optimization problem aiming to minimize
the gap between the estimated positions and the ground truth positions of
users. To solve this problem, we design a complex-valued neural network (CVNN)
model based federated learning (FL) algorithm. Compared to standard real-valued
centralized machine learning (ML) methods, our proposed algorithm has two main
advantages. First, our proposed algorithm can directly process complex-valued
CSI data without data transformation. Second, our proposed algorithm is a
distributed ML method that does not require users to send their CSI data to the
server. Since the output of our proposed algorithm is complex-valued which
consists of the real and imaginary parts, we study the use of the CVNN to
implement two learning tasks. First, the proposed algorithm directly outputs
the estimated positions of a user. Here, the real and imaginary parts of an
output neuron represent the 2D coordinates of the user. Second, the proposed
method can output two CSI features (i.e., line-of-sight/non-line-of-sight
transmission link classification and time of arrival (TOA) prediction) which
can be used in traditional positioning algorithms. Simulation results
demonstrate that our designed CVNN based FL can reduce the mean positioning
error between the estimated position and the actual position by up to 36\%,
compared to a RVNN based FL which requires to transform CSI data into
real-valued data.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00668" title="Abstract">arXiv:2403.00668</a> [<a href="/pdf/2403.00668" title="Download PDF">pdf</a>, <a href="/format/2403.00668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Upper-6GHz and mmWave in Real-World 5G Networks: A Direct  on-Field Comparison
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morini%2C+M">Marcello Morini</a>, 
<a href="/search/cs?searchtype=author&query=Moro%2C+E">Eugenio Moro</a>, 
<a href="/search/cs?searchtype=author&query=Filippini%2C+I">Ilario Filippini</a>, 
<a href="/search/cs?searchtype=author&query=Capone%2C+A">Antonio Capone</a>, 
<a href="/search/cs?searchtype=author&query=De+Donno%2C+D">Danilo De Donno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The spectrum crunch challenge poses a vital threat to the progress of
cellular networks and recently prompted the inclusion of millimeter wave
(mmWave) and Upper 6GHz (U6G) in the 3GPP standards. These two bands promise to
unlock a large portion of untapped spectrum, but the harsh propagation due to
the increased carrier frequency might negatively impact the performance of
urban Radio Access Network (RAN) deployments. Within the span of a year, two
co-located 5G networks operating in these frequency bands were deployed at
Politecnico di Milano, Milan, Italy, entirely dedicated to the dense urban
performance assessment of the two systems. This paper presents an in-depth
analysis of the measurement campaigns conducted on them, with the U6G campaign
representing the first of its kind. A benchmark is provided by ray-tracing
simulations. The results suggest that networks operating in these frequency
bands provide good indoor and outdoor coverage and throughput in urban
scenarios, even when deployed in the macro base station setup common to lower
frequencies. In addition, a comparative performance analysis of these two key
technologies is provided, offering insights on their relative strengths,
weaknesses and improvement margins and informing on which bands is better
suited for urban macro coverage.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00669" title="Abstract">arXiv:2403.00669</a> [<a href="/pdf/2403.00669" title="Download PDF">pdf</a>, <a href="/format/2403.00669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Additive Manufacturing through Deep Learning: A Comprehensive  Review of Current Progress and Future Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saimon%2C+A+I">Amirul Islam Saimon</a>, 
<a href="/search/cs?searchtype=author&query=Yangue%2C+E">Emmanuel Yangue</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+X">Xiaowei Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhenyu">Zhenyu</a> (James)
<a href="/search/cs?searchtype=author&query=Kong">Kong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chenang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Additive manufacturing (AM) has already proved itself to be the potential
alternative to widely-used subtractive manufacturing due to its extraordinary
capacity of manufacturing highly customized products with minimum material
wastage. Nevertheless, it is still not being considered as the primary choice
for the industry due to some of its major inherent challenges, including
complex and dynamic process interactions, which are sometimes difficult to
fully understand even with traditional machine learning because of the
involvement of high-dimensional data such as images, point clouds, and voxels.
However, the recent emergence of deep learning (DL) is showing great promise in
overcoming many of these challenges as DL can automatically capture complex
relationships from high-dimensional data without hand-crafted feature
extraction. Therefore, the volume of research in the intersection of AM and DL
is exponentially growing each year which makes it difficult for the researchers
to keep track of the trend and future potential directions. Furthermore, to the
best of our knowledge, there is no comprehensive review paper in this research
track summarizing the recent studies. Therefore, this paper reviews the recent
studies that apply DL for making the AM process better with a high-level
summary of their contributions and limitations. Finally, it summarizes the
current challenges and recommends some of the promising opportunities in this
domain for further investigation with a special focus on generalizing DL models
for wide-range of geometry types, managing uncertainties both in AM data and DL
models, overcoming limited and noisy AM data issues by incorporating generative
models, and unveiling the potential of interpretable DL for AM.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00673" title="Abstract">arXiv:2403.00673</a> [<a href="/pdf/2403.00673" title="Download PDF">pdf</a>, <a href="/format/2403.00673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Snapshot Reinforcement Learning: Leveraging Prior Trajectories for  Efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yanxiao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yangge Qian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+J">Jingyang Shan</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+X">Xiaolin Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep reinforcement learning (DRL) algorithms require substantial samples and
computational resources to achieve higher performance, which restricts their
practical application and poses challenges for further development. Given the
constraint of limited resources, it is essential to leverage existing
computational work (e.g., learned policies, samples) to enhance sample
efficiency and reduce the computational resource consumption of DRL algorithms.
Previous works to leverage existing computational work require intrusive
modifications to existing algorithms and models, designed specifically for
specific algorithms, lacking flexibility and universality. In this paper, we
present the Snapshot Reinforcement Learning (SnapshotRL) framework, which
enhances sample efficiency by simply altering environments, without making any
modifications to algorithms and models. By allowing student agents to choose
states in teacher trajectories as the initial state to sample, SnapshotRL can
effectively utilize teacher trajectories to assist student agents in training,
allowing student agents to explore a larger state space at the early training
phase. We propose a simple and effective SnapshotRL baseline algorithm, S3RL,
which integrates well with existing DRL algorithms. Our experiments demonstrate
that integrating S3RL with TD3, SAC, and PPO algorithms on the MuJoCo benchmark
significantly improves sample efficiency and average return, without extra
samples and additional computational resources.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00674" title="Abstract">arXiv:2403.00674</a> [<a href="/pdf/2403.00674" title="Download PDF">pdf</a>, <a href="/format/2403.00674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cell-Free Massive MIMO with Multi-Antenna Users and Phase Misalignments:  A Novel Partially Coherent Transmission Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ganesan%2C+U+K">Unnikrishnan Kunnath Ganesan</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+T+T">Tung Thanh Vu</a>, 
<a href="/search/cs?searchtype=author&query=Larsson%2C+E+G">Erik G. Larsson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 10 figures. Accepted for publication in IEEE Open Journal of the Communications Society
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Cell-free massive multiple-input multiple-output (MIMO) is a promising
technology for next-generation communication systems. This work proposes a
novel partially coherent (PC) transmission framework to cope with the challenge
of phase misalignment among the access points (APs), which is important for
unlocking the full potential of cell-free massive MIMO technology. With the PC
operation, the APs are only required to be phase-aligned within clusters. Each
cluster transmits the same data stream towards each user equipment (UE), while
different clusters send different data streams. We first propose a novel
algorithm to group APs into clusters such that the distance between two APs is
always smaller than a reference distance ensuring the phase alignment of these
APs. Then, we propose new algorithms that optimize the combining at UEs and
precoding at APs to maximize the downlink sum data rates. We also propose a
novel algorithm for data stream allocation to further improve the sum data rate
of the PC operation. Numerical results show that the PC operation using the
proposed framework with a sufficiently small reference distance can offer a sum
rate close to the sum rate of the ideal fully coherent (FC) operation that
requires network-wide phase alignment. This demonstrates the potential of PC
operation in practical deployments of cell-free massive MIMO networks.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00675" title="Abstract">arXiv:2403.00675</a> [<a href="/pdf/2403.00675" title="Download PDF">pdf</a>, <a href="/format/2403.00675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reusing Historical Trajectories in Natural Policy Gradient via  Importance Sampling: Convergence and Convergence Rate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yifan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+E">Enlu Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Reinforcement learning provides a mathematical framework for learning-based
control, whose success largely depends on the amount of data it can utilize.
The efficient utilization of historical trajectories obtained from previous
policies is essential for expediting policy optimization. Empirical evidence
has shown that policy gradient methods based on importance sampling work well.
However, existing literature often neglect the interdependence between
trajectories from different iterations, and the good empirical performance
lacks a rigorous theoretical justification. In this paper, we study a variant
of the natural policy gradient method with reusing historical trajectories via
importance sampling. We show that the bias of the proposed estimator of the
gradient is asymptotically negligible, the resultant algorithm is convergent,
and reusing past trajectories helps improve the convergence rate. We further
apply the proposed estimator to popular policy optimization algorithms such as
trust region policy optimization. Our theoretical results are verified on
classical benchmarks.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00680" title="Abstract">arXiv:2403.00680</a> [<a href="/pdf/2403.00680" title="Download PDF">pdf</a>, <a href="/format/2403.00680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Learning of Item Response Theory Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frick%2C+S">Susanne Frick</a>, 
<a href="/search/cs?searchtype=author&query=Krivo%C5%A1ija%2C+A">Amer Krivo&#x161;ija</a>, 
<a href="/search/cs?searchtype=author&query=Munteanu%2C+A">Alexander Munteanu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML)

</div>
<p class="mathjax">Item Response Theory (IRT) models aim to assess latent abilities of $n$
examinees along with latent difficulty characteristics of $m$ test items from
categorical data that indicates the quality of their corresponding answers.
Classical psychometric assessments are based on a relatively small number of
examinees and items, say a class of $200$ students solving an exam comprising
$10$ problems. More recent global large scale assessments such as PISA, or
internet studies, may lead to significantly increased numbers of participants.
Additionally, in the context of Machine Learning where algorithms take the role
of examinees and data analysis problems take the role of items, both $n$ and
$m$ may become very large, challenging the efficiency and scalability of
computations. To learn the latent variables in IRT models from large data, we
leverage the similarity of these models to logistic regression, which can be
approximated accurately using small weighted subsets called coresets. We
develop coresets for their use in alternating IRT training algorithms,
facilitating scalable learning from large data.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00682" title="Abstract">arXiv:2403.00682</a> [<a href="/pdf/2403.00682" title="Download PDF">pdf</a>, <a href="/format/2403.00682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An iterative method for the solution of Laplace-like equations in high  and very high space dimensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yserentant%2C+H">Harry Yserentant</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper deals with the equation $-\Delta u+\mu u=f$ on high-dimensional
spaces $\mathbb{R}^m$, where the right-hand side $f(x)=F(Tx)$ is composed of a
separable function $F$ with an integrable Fourier transform on a space of a
dimension $n&gt;m$ and a linear mapping given by a matrix $T$ of full rank and
$\mu\geq 0$ is a constant. For example, the right-hand side can explicitly
depend on differences $x_i-x_j$ of components of $x$. Following our publication
[Numer. Math. (2020) 146:219--238], we show that the solution of this equation
can be expanded into sums of functions of the same structure and develop in
this framework an equally simple and fast iterative method for its computation.
The method is based on the observation that in almost all cases and for large
problem classes the expression $\|T^ty\|^2$ deviates on the unit sphere
$\|y\|=1$ the less from its mean value the higher the dimension $m$ is, a
concentration of measure effect. The higher the dimension $m$, the faster the
iteration converges.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00685" title="Abstract">arXiv:2403.00685</a> [<a href="/pdf/2403.00685" title="Download PDF">pdf</a>, <a href="/ps/2403.00685" title="Download PostScript">ps</a>, <a href="/format/2403.00685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Know your exceptions: Towards an Ontology of Exceptions in Knowledge  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sacco%2C+G">Gabriele Sacco</a>, 
<a href="/search/cs?searchtype=author&query=Bozzato%2C+L">Loris Bozzato</a>, 
<a href="/search/cs?searchtype=author&query=Kutz%2C+O">Oliver Kutz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 4 pages are appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Defeasible reasoning is a kind of reasoning where some generalisations may
not be valid in all circumstances, that is general conclusions may fail in some
cases. Various formalisms have been developed to model this kind of reasoning,
which is characteristic of common-sense contexts. However, it is not easy for a
modeller to choose among these systems the one that better fits its domain from
an ontological point of view. In this paper we first propose a framework based
on the notions of exceptionality and defeasibility in order to be able to
compare formalisms and reveal their ontological commitments. Then, we apply
this framework to compare four systems, showing the differences that may occur
from an ontological perspective.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00686" title="Abstract">arXiv:2403.00686</a> [<a href="/pdf/2403.00686" title="Download PDF">pdf</a>, <a href="/format/2403.00686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Bit of a Problem: Measurement Disparities in Dataset Sizes Across  Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arnett%2C+C">Catherine Arnett</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+T+A">Tyler A. Chang</a>, 
<a href="/search/cs?searchtype=author&query=Bergen%2C+B+K">Benjamin K. Bergen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">How should text dataset sizes be compared across languages? Even for
content-matched (parallel) corpora, UTF-8 encoded text can require a
dramatically different number of bytes for different languages. In our work, we
define the byte premium between two languages as the ratio of bytes used to
encode content-matched text in those languages. We compute byte premiums for
1155 languages, and we use linear regressions to estimate byte premiums for
other languages. We release a tool to obtain byte premiums for any two
languages, enabling comparisons of dataset sizes across languages for more
equitable multilingual model development and data practices.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00689" title="Abstract">arXiv:2403.00689</a> [<a href="/pdf/2403.00689" title="Download PDF">pdf</a>, <a href="/format/2403.00689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hydra: Computer Vision for Data Quality Monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Britton%2C+T">Thomas Britton</a>, 
<a href="/search/cs?searchtype=author&query=Jeske%2C+T">Torri Jeske</a>, 
<a href="/search/cs?searchtype=author&query=Lawrence%2C+D">David Lawrence</a>, 
<a href="/search/cs?searchtype=author&query=Rajput%2C+K">Kishansingh Rajput</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Nuclear Experiment (nucl-ex); Instrumentation and Detectors (physics.ins-det)

</div>
<p class="mathjax">Hydra is a system which utilizes computer vision to perform near real time
data quality management, initially developed for Hall-D in 2019. Since then, it
has been deployed across all experimental halls at Jefferson Lab, with the
CLAS12 collaboration in Hall-B being the first outside of GlueX to fully
utilize Hydra. The system comprises back end processes that manage the models,
their inferences, and the data flow. The front-end components, accessible via
web pages, allow detector experts and shift crews to view and interact with the
system. This talk will give an overview of the Hydra system as well as
highlight significant developments in Hydra's feature set, acute challenges
with operating Hydra in all halls, and lessons learned along the way.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00690" title="Abstract">arXiv:2403.00690</a> [<a href="/pdf/2403.00690" title="Download PDF">pdf</a>, <a href="/format/2403.00690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Playing NetHack with LLMs: Potential &amp; Limitations as Zero-Shot Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeurissen%2C+D">Dominik Jeurissen</a>, 
<a href="/search/cs?searchtype=author&query=Perez-Liebana%2C+D">Diego Perez-Liebana</a>, 
<a href="/search/cs?searchtype=author&query=Gow%2C+J">Jeremy Gow</a>, 
<a href="/search/cs?searchtype=author&query=Cakmak%2C+D">Duygu Cakmak</a>, 
<a href="/search/cs?searchtype=author&query=Kwan%2C+J">James Kwan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have shown great success as high-level planners
for zero-shot game-playing agents. However, these agents are primarily
evaluated on Minecraft, where long-term planning is relatively straightforward.
In contrast, agents tested in dynamic robot environments face limitations due
to simplistic environments with only a few objects and interactions. To fill
this gap in the literature, we present NetPlay, the first LLM-powered zero-shot
agent for the challenging roguelike NetHack. NetHack is a particularly
challenging environment due to its diverse set of items and monsters, complex
interactions, and many ways to die.
<br />NetPlay uses an architecture designed for dynamic robot environments,
modified for NetHack. Like previous approaches, it prompts the LLM to choose
from predefined skills and tracks past interactions to enhance decision-making.
Given NetHack's unpredictable nature, NetPlay detects important game events to
interrupt running skills, enabling it to react to unforeseen circumstances.
While NetPlay demonstrates considerable flexibility and proficiency in
interacting with NetHack's mechanics, it struggles with ambiguous task
descriptions and a lack of explicit feedback. Our findings demonstrate that
NetPlay performs best with detailed context information, indicating the
necessity for dynamic methods in supplying context information for complex
games such as NetHack.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00691" title="Abstract">arXiv:2403.00691</a> [<a href="/pdf/2403.00691" title="Download PDF">pdf</a>, <a href="/format/2403.00691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tri-Modal Motion Retrieval by Learning a Joint Embedding Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+K">Kangning Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+S">Shihao Zou</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yuxuan Ge</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zheng Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Information retrieval is an ever-evolving and crucial research domain. The
substantial demand for high-quality human motion data especially in online
acquirement has led to a surge in human motion research works. Prior works have
mainly concentrated on dual-modality learning, such as text and motion tasks,
but three-modality learning has been rarely explored. Intuitively, an extra
introduced modality can enrich a model's application scenario, and more
importantly, an adequate choice of the extra modality can also act as an
intermediary and enhance the alignment between the other two disparate
modalities. In this work, we introduce LAVIMO (LAnguage-VIdeo-MOtion
alignment), a novel framework for three-modality learning integrating
human-centric videos as an additional modality, thereby effectively bridging
the gap between text and motion. Moreover, our approach leverages a specially
designed attention mechanism to foster enhanced alignment and synergistic
effects among text, video, and motion modalities. Empirically, our results on
the HumanML3D and KIT-ML datasets show that LAVIMO achieves state-of-the-art
performance in various motion-related cross-modal retrieval tasks, including
text-to-motion, motion-to-text, video-to-motion and motion-to-video.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00696" title="Abstract">arXiv:2403.00696</a> [<a href="/pdf/2403.00696" title="Download PDF">pdf</a>, <a href="/format/2403.00696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Consistent Decoding for More Factual Open Responses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malon%2C+C">Christopher Malon</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaodan Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Self-consistency has emerged as a powerful method for improving the accuracy
of short answers generated by large language models. As previously defined, it
only concerns the accuracy of a final answer parsed from generated text. In
this work, we extend the idea to open response generation, by integrating
voting into the decoding method. Each output sentence is selected from among
multiple samples, conditioning on the previous selections, based on a simple
token overlap score. We compare this "Sample &amp; Select" method to greedy
decoding, beam search, nucleus sampling, and the recently introduced
hallucination avoiding decoders of DoLA, P-CRR, and S-CRR. We show that Sample
&amp; Select improves factuality by a 30% relative margin against these decoders in
NLI-based evaluation on the subsets of CNN/DM and XSum used in the FRANK
benchmark, while maintaining comparable ROUGE-1 F1 scores against reference
summaries. We collect human verifications of the generated summaries,
confirming the factual superiority of our method.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00704" title="Abstract">arXiv:2403.00704</a> [<a href="/pdf/2403.00704" title="Download PDF">pdf</a>, <a href="/format/2403.00704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representing Guardedness in Call-by-Value and Guarded Parametrized  Monads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goncharov%2C+S">Sergey Goncharov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of <a href="https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FSCD.2023.34">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Like the notion of computation via (strong) monads serves to classify various
flavours of impurity, including exceptions, non-determinism, probability, local
and global store, the notion of guardedness classifies well-behavedness of
cycles in various settings. In its most general form, the guardedness
discipline applies to general symmetric monoidal categories and further
specializes to Cartesian and co-Cartesian categories, where it governs guarded
recursion and guarded iteration respectively. Here, even more specifically, we
deal with the semantics of call-by-value guarded iteration. It was shown by
Levy, Power and Thielecke that call-by-value languages can be generally
interpreted in Freyd categories, but in order to represent effectful function
spaces, such a category must canonically arise from a strong monad. We
generalize this fact by showing that representing guarded effectful function
spaces calls for certain parametrized monads (in the sense of Uustalu). This
provides a description of guardedness as an intrinsic categorical property of
programs, complementing the existing description of guardedness as a predicate
on a category.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00712" title="Abstract">arXiv:2403.00712</a> [<a href="/pdf/2403.00712" title="Download PDF">pdf</a>, <a href="/format/2403.00712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Inductive Biases for Surface Normal Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bae%2C+G">Gwangbin Bae</a>, 
<a href="/search/cs?searchtype=author&query=Davison%2C+A+J">Andrew J. Davison</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024 (camera-ready version will be uploaded in March 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite the growing demand for accurate surface normal estimation models,
existing methods use general-purpose dense prediction models, adopting the same
inductive biases as other tasks. In this paper, we discuss the inductive biases
needed for surface normal estimation and propose to (1) utilize the per-pixel
ray direction and (2) encode the relationship between neighboring surface
normals by learning their relative rotation. The proposed method can generate
crisp - yet, piecewise smooth - predictions for challenging in-the-wild images
of arbitrary resolution and aspect ratio. Compared to a recent ViT-based
state-of-the-art model, our method shows a stronger generalization ability,
despite being trained on an orders of magnitude smaller dataset. The code is
available at https://github.com/baegwangbin/DSINE.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00715" title="Abstract">arXiv:2403.00715</a> [<a href="/pdf/2403.00715" title="Download PDF">pdf</a>, <a href="/ps/2403.00715" title="Download PostScript">ps</a>, <a href="/format/2403.00715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Learning Rate for Follow-the-Regularized-Leader: Competitive  Ratio Analysis and Best-of-Both-Worlds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ito%2C+S">Shinji Ito</a>, 
<a href="/search/cs?searchtype=author&query=Tsuchiya%2C+T">Taira Tsuchiya</a>, 
<a href="/search/cs?searchtype=author&query=Honda%2C+J">Junya Honda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Follow-The-Regularized-Leader (FTRL) is known as an effective and versatile
approach in online learning, where appropriate choice of the learning rate is
crucial for smaller regret. To this end, we formulate the problem of adjusting
FTRL's learning rate as a sequential decision-making problem and introduce the
framework of competitive analysis. We establish a lower bound for the
competitive ratio and propose update rules for learning rate that achieves an
upper bound within a constant factor of this lower bound. Specifically, we
illustrate that the optimal competitive ratio is characterized by the
(approximate) monotonicity of components of the penalty term, showing that a
constant competitive ratio is achievable if the components of the penalty term
form a monotonically non-increasing sequence, and derive a tight competitive
ratio when penalty terms are $\xi$-approximately monotone non-increasing. Our
proposed update rule, referred to as \textit{stability-penalty matching}, also
facilitates constructing the Best-Of-Both-Worlds (BOBW) algorithms for
stochastic and adversarial environments. In these environments our result
contributes to achieve tighter regret bound and broaden the applicability of
algorithms for various settings such as multi-armed bandits, graph bandits,
linear bandits, and contextual bandits.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00717" title="Abstract">arXiv:2403.00717</a> [<a href="/pdf/2403.00717" title="Download PDF">pdf</a>, <a href="/format/2403.00717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAIDR: Making Statistical Visualizations Accessible with Multimodal Data  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">JooYoung Seo</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yilin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Bongshin Lee</a>, 
<a href="/search/cs?searchtype=author&query=McCurry%2C+S">Sean McCurry</a>, 
<a href="/search/cs?searchtype=author&query=Yam%2C+Y+J">Yu Jun Yam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CHI 2024. Source code is available at <a href="https://github.com/xability/maidr">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">This paper investigates new data exploration experiences that enable blind
users to interact with statistical data visualizations$-$bar plots, heat maps,
box plots, and scatter plots$-$leveraging multimodal data representations. In
addition to sonification and textual descriptions that are commonly employed by
existing accessible visualizations, our MAIDR (multimodal access and
interactive data representation) system incorporates two additional modalities
(braille and review) that offer complementary benefits. It also provides blind
users with the autonomy and control to interactively access and understand data
visualizations. In a user study involving 11 blind participants, we found the
MAIDR system facilitated the accurate interpretation of statistical
visualizations. Participants exhibited a range of strategies in combining
multiple modalities, influenced by their past interactions and experiences with
data visualizations. This work accentuates the overlooked potential of
combining refreshable tactile representation with other modalities and elevates
the discussion on the importance of user autonomy when designing accessible
data visualizations.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00720" title="Abstract">arXiv:2403.00720</a> [<a href="/pdf/2403.00720" title="Download PDF">pdf</a>, <a href="/format/2403.00720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subhomogeneous Deep Equilibrium Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sittoni%2C+P">Pietro Sittoni</a>, 
<a href="/search/cs?searchtype=author&query=Tudisco%2C+F">Francesco Tudisco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Optimization and Control (math.OC)

</div>
<p class="mathjax">Implicit-depth neural networks have grown as powerful alternatives to
traditional networks in various applications in recent years. However, these
models often lack guarantees of existence and uniqueness, raising stability,
performance, and reproducibility issues. In this paper, we present a new
analysis of the existence and uniqueness of fixed points for implicit-depth
neural networks based on the concept of subhomogeneous operators and the
nonlinear Perron-Frobenius theory. Compared to previous similar analyses, our
theory allows for weaker assumptions on the parameter matrices, thus yielding a
more flexible framework for well-defined implicit networks. We illustrate the
performance of the resulting subhomogeneous networks on feed-forward,
convolutional, and graph neural network examples.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00724" title="Abstract">arXiv:2403.00724</a> [<a href="/pdf/2403.00724" title="Download PDF">pdf</a>, <a href="/format/2403.00724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-Shot Relation Extraction with Hybrid Visual Evidence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+J">Jiaying Gong</a>, 
<a href="/search/cs?searchtype=author&query=Eldardiry%2C+H">Hoda Eldardiry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 5 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The goal of few-shot relation extraction is to predict relations between name
entities in a sentence when only a few labeled instances are available for
training. Existing few-shot relation extraction methods focus on uni-modal
information such as text only. This reduces performance when there are no clear
contexts between the name entities described in text. We propose a multi-modal
few-shot relation extraction model (MFS-HVE) that leverages both textual and
visual semantic information to learn a multi-modal representation jointly. The
MFS-HVE includes semantic feature extractors and multi-modal fusion components.
The MFS-HVE semantic feature extractors are developed to extract both textual
and visual features. The visual features include global image features and
local object features within the image. The MFS-HVE multi-modal fusion unit
integrates information from various modalities using image-guided attention,
object-guided attention, and hybrid feature attention to fully capture the
semantic interaction between visual regions of images and relevant texts.
Extensive experiments conducted on two public datasets demonstrate that
semantic visual information significantly improves the performance of few-shot
relation prediction.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00725" title="Abstract">arXiv:2403.00725</a> [<a href="/pdf/2403.00725" title="Download PDF">pdf</a>, <a href="/ps/2403.00725" title="Download PostScript">ps</a>, <a href="/format/2403.00725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cost-Effective Activity Control of Asymptomatic Carriers in Layered  Temporal Social Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moradian%2C+M">Masoumeh Moradian</a>, 
<a href="/search/cs?searchtype=author&query=Dadlani%2C+A">Aresh Dadlani</a>, 
<a href="/search/cs?searchtype=author&query=Kairgeldin%2C+R">Rasul Kairgeldin</a>, 
<a href="/search/cs?searchtype=author&query=Khonsari%2C+A">Ahmad Khonsari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">The robustness of human social networks against epidemic propagation relies
on the propensity for physical contact adaptation. During the early phase of
infection, asymptomatic carriers exhibit the same activity level as susceptible
individuals, which presents challenges for incorporating control measures in
epidemic projection models. This paper focuses on modeling and cost-efficient
activity control of susceptible and carrier individuals in the context of the
susceptible-carrier-infected-removed (SCIR) epidemic model over a two-layer
contact network. In this model, individuals switch from a static contact layer
to create new links in a temporal layer based on state-dependent activation
rates. We derive conditions for the infection to die out or persist in a
homogeneous network. Considering the significant costs associated with reducing
the activity of susceptible and carrier individuals, we formulate an
optimization problem to minimize the disease decay rate while constrained by a
limited budget. We propose the use of successive geometric programming (SGP)
approximation for this optimization task. Through simulation experiments on
Poisson random graphs, we assess the impact of different parameters on disease
prevalence. The results demonstrate that our SGP framework achieves a cost
reduction of nearly 33% compared to conventional methods based on degree and
closeness centrality.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00729" title="Abstract">arXiv:2403.00729</a> [<a href="/pdf/2403.00729" title="Download PDF">pdf</a>, <a href="/format/2403.00729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Transformers Capture Spatial Relations between Objects?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+C">Chuan Wen</a>, 
<a href="/search/cs?searchtype=author&query=Jayaraman%2C+D">Dinesh Jayaraman</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 8 figures, ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Spatial relationships between objects represent key scene information for
humans to understand and interact with the world. To study the capability of
current computer vision systems to recognize physically grounded spatial
relations, we start by proposing precise relation definitions that permit
consistently annotating a benchmark dataset. Despite the apparent simplicity of
this task relative to others in the recognition literature, we observe that
existing approaches perform poorly on this benchmark. We propose new approaches
exploiting the long-range attention capabilities of transformers for this task,
and evaluating key design principles. We identify a simple "RelatiViT"
architecture and demonstrate that it outperforms all current approaches. To our
knowledge, this is the first method to convincingly outperform naive baselines
on spatial relation prediction in in-the-wild settings. The code and datasets
are available in \url{https://sites.google.com/view/spatial-relation}.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00737" title="Abstract">arXiv:2403.00737</a> [<a href="/pdf/2403.00737" title="Download PDF">pdf</a>, <a href="/format/2403.00737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Happy Ending: An Empty Hexagon in Every Set of 30 Points
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heule%2C+M+J+H">Marijn J.H. Heule</a>, 
<a href="/search/cs?searchtype=author&query=Scheucher%2C+M">Manfred Scheucher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Logic in Computer Science (cs.LO); Combinatorics (math.CO)

</div>
<p class="mathjax">Satisfiability solving has been used to tackle a range of long-standing open
math problems in recent years. We add another success by solving a geometry
problem that originated a century ago. In the 1930s, Esther Klein's exploration
of unavoidable shapes in planar point sets in general position showed that
every set of five points includes four points in convex position. For a long
time, it was open if an empty hexagon, i.e., six points in convex position
without a point inside, can be avoided. In 2006, Gerken and Nicol\'as
independently proved that the answer is no. We establish the exact bound: Every
30-point set in the plane in general position contains an empty hexagon. Our
key contributions include an effective, compact encoding and a search-space
partitioning strategy enabling linear-time speedups even when using thousands
of cores.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00742" title="Abstract">arXiv:2403.00742</a> [<a href="/pdf/2403.00742" title="Download PDF">pdf</a>, <a href="/format/2403.00742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dialect prejudice predicts AI decisions about people&#x27;s character,  employability, and criminality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hofmann%2C+V">Valentin Hofmann</a>, 
<a href="/search/cs?searchtype=author&query=Kalluri%2C+P+R">Pratyusha Ria Kalluri</a>, 
<a href="/search/cs?searchtype=author&query=Jurafsky%2C+D">Dan Jurafsky</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+S">Sharese King</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Hundreds of millions of people now interact with language models, with uses
ranging from serving as a writing aid to informing hiring decisions. Yet these
language models are known to perpetuate systematic racial prejudices, making
their judgments biased in problematic ways about groups like African Americans.
While prior research has focused on overt racism in language models, social
scientists have argued that racism with a more subtle character has developed
over time. It is unknown whether this covert racism manifests in language
models. Here, we demonstrate that language models embody covert racism in the
form of dialect prejudice: we extend research showing that Americans hold
raciolinguistic stereotypes about speakers of African American English and find
that language models have the same prejudice, exhibiting covert stereotypes
that are more negative than any human stereotypes about African Americans ever
experimentally recorded, although closest to the ones from before the civil
rights movement. By contrast, the language models' overt stereotypes about
African Americans are much more positive. We demonstrate that dialect prejudice
has the potential for harmful consequences by asking language models to make
hypothetical decisions about people, based only on how they speak. Language
models are more likely to suggest that speakers of African American English be
assigned less prestigious jobs, be convicted of crimes, and be sentenced to
death. Finally, we show that existing methods for alleviating racial bias in
language models such as human feedback training do not mitigate the dialect
prejudice, but can exacerbate the discrepancy between covert and overt
stereotypes, by teaching language models to superficially conceal the racism
that they maintain on a deeper level. Our findings have far-reaching
implications for the fair and safe employment of language technology.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00743" title="Abstract">arXiv:2403.00743</a> [<a href="/pdf/2403.00743" title="Download PDF">pdf</a>, <a href="/format/2403.00743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Acceleration of Incomplete Cholesky Preconditioners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Booth%2C+J+D">Joshua Dennis Booth</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hongyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Garnett%2C+T">Trevor Garnett</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">The solution of a sparse system of linear equations is ubiquitous in
scientific applications. Iterative methods, such as the Preconditioned
Conjugate Gradient method (PCG), are normally chosen over direct methods due to
memory and computational complexity constraints. However, the efficiency of
these methods depends on the preconditioner utilized. The development of the
preconditioner normally requires some insight into the sparse linear system and
the desired trade-off of generating the preconditioner and the reduction in the
number of iterations. Incomplete factorization methods tend to be black box
methods to generate these preconditioners but may fail for a number of reasons.
These reasons include numerical issues that require searching for adequate
scaling, shifting, and fill-in while utilizing a difficult to parallelize
algorithm. With a move towards heterogeneous computing, many sparse
applications find GPUs that are optimized for dense tensor applications like
training neural networks being underutilized. In this work, we demonstrate that
a simple artificial neural network trained either at compile time or in
parallel to the running application on a GPU can provide an incomplete sparse
Cholesky factorization that can be used as a preconditioner. This generated
preconditioner is as good or better in terms of reduction of iterations than
the one found using multiple preconditioning techniques such as scaling and
shifting. Moreover, the generated method also works and never fails to produce
a preconditioner that does not reduce the iteration count.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00745" title="Abstract">arXiv:2403.00745</a> [<a href="/pdf/2403.00745" title="Download PDF">pdf</a>, <a href="/format/2403.00745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AtP*: An efficient and scalable method for localizing LLM behaviour to  components
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kram%C3%A1r%2C+J">J&#xe1;nos Kram&#xe1;r</a>, 
<a href="/search/cs?searchtype=author&query=Lieberum%2C+T">Tom Lieberum</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+R">Rohin Shah</a>, 
<a href="/search/cs?searchtype=author&query=Nanda%2C+N">Neel Nanda</a> (Google DeepMind)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Activation Patching is a method of directly computing causal attributions of
behavior to model components. However, applying it exhaustively requires a
sweep with cost scaling linearly in the number of model components, which can
be prohibitively expensive for SoTA Large Language Models (LLMs). We
investigate Attribution Patching (AtP), a fast gradient-based approximation to
Activation Patching and find two classes of failure modes of AtP which lead to
significant false negatives. We propose a variant of AtP called AtP*, with two
changes to address these failure modes while retaining scalability. We present
the first systematic study of AtP and alternative methods for faster activation
patching and show that AtP significantly outperforms all other investigated
methods, with AtP* providing further significant improvement. Finally, we
provide a method to bound the probability of remaining false negatives of AtP*
estimates.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00752" title="Abstract">arXiv:2403.00752</a> [<a href="/pdf/2403.00752" title="Download PDF">pdf</a>, <a href="/format/2403.00752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Experimental Study of Low-Latency Video Streaming over 5G
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+I">Imran Khan</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+T+X">Tuyen X. Tran</a>, 
<a href="/search/cs?searchtype=author&query=Hiltunen%2C+M">Matti Hiltunen</a>, 
<a href="/search/cs?searchtype=author&query=Karagioules%2C+T">Theodore Karagioules</a>, 
<a href="/search/cs?searchtype=author&query=Koutsonikolas%2C+D">Dimitrios Koutsonikolas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Performance (cs.PF)

</div>
<p class="mathjax">Low-latency video streaming over 5G has become rapidly popular over the last
few years due to its increased usage in hosting virtual events, online
education, webinars, and all-hands meetings. Our work aims to address the
absence of studies that reveal the real-world behavior of low-latency video
streaming. To that end, we provide an experimental methodology and
measurements, collected in a US metropolitan area over a commercial 5G network,
that correlates application-level QoE and lower-layer metrics on the devices,
such as RSRP, RSRQ, handover records, etc., under both static and mobility
scenarios. We find that RAN-side information, which is readily available on
every cellular device, has the potential to enhance throughput estimation
modules of video streaming clients, ultimately making low-latency streaming
more resilient against network perturbations and handover events.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00758" title="Abstract">arXiv:2403.00758</a> [<a href="/pdf/2403.00758" title="Download PDF">pdf</a>, <a href="/format/2403.00758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Reversal Curse via Semantic-aware Permutation Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qingyan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Junliang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">While large language models (LLMs) have achieved impressive performance
across diverse tasks, recent studies showcase that causal LLMs suffer from the
"reversal curse". It is a typical example that the model knows "A's father is
B", but is unable to reason "B's child is A". This limitation poses a challenge
to the advancement of artificial general intelligence (AGI), as it suggests a
gap in the models' ability to comprehend and apply bidirectional reasoning. In
this paper, we first conduct substantial evaluation and identify that the root
cause of the reversal curse lies in the different word order between the
training and inference stage, namely, the poor ability of causal language
models to predict antecedent words within the training data. Accordingly,
permutation on the training data is considered as a potential solution, since
this can make the model predict antecedent words or tokens. However, previous
permutation methods may disrupt complete phrases or entities, thereby posing
challenges for the model to comprehend and learn from training data. To address
this issue, we propose Semantic-aware Permutation Training (SPT), which
addresses this issue by segmenting the training sentences into semantic units
(i.e., entities or phrases) with an assistant language model and permuting
these units before feeding into the model. Extensive experiments demonstrate
that SPT effectively mitigates the reversal curse since the performance on
reversed questions approximates that on the forward ones, and significantly
advances the performance of existing works.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00762" title="Abstract">arXiv:2403.00762</a> [<a href="/pdf/2403.00762" title="Download PDF">pdf</a>, <a href="/format/2403.00762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point Could Mamba: Point Cloud Learning via State Space Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangtai Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Haobo Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shunping Ji</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shuicheng Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work, for the first time, we demonstrate that Mamba-based point cloud
methods can outperform point-based methods. Mamba exhibits strong global
modeling capabilities and linear computational complexity, making it highly
attractive for point cloud analysis. To enable more effective processing of 3-D
point cloud data by Mamba, we propose a novel Consistent Traverse Serialization
to convert point clouds into 1-D point sequences while ensuring that
neighboring points in the sequence are also spatially adjacent. Consistent
Traverse Serialization yields six variants by permuting the order of x, y, and
z coordinates, and the synergistic use of these variants aids Mamba in
comprehensively observing point cloud data. Furthermore, to assist Mamba in
handling point sequences with different orders more effectively, we introduce
point prompts to inform Mamba of the sequence's arrangement rules. Finally, we
propose positional encoding based on spatial coordinate mapping to inject
positional information into point cloud sequences better. Based on these
improvements, we construct a point cloud network named Point Cloud Mamba, which
combines local and global modeling. Point Cloud Mamba surpasses the SOTA
point-based method PointNeXt and achieves new SOTA performance on the
ScanObjectNN, ModelNet40, and ShapeNetPart datasets.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Mon,  4 Mar 24</h3>
<dl>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18354" title="Abstract">arXiv:2402.18354</a> (cross-list from physics.ao-ph) [<a href="/pdf/2402.18354" title="Download PDF">pdf</a>, <a href="/format/2402.18354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SuperdropNet: a Stable and Accurate Machine Learning Proxy for  Droplet-based Cloud Microphysics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Sharma%2C+S">Shivani Sharma</a>, 
<a href="/search/physics?searchtype=author&query=Greenberg%2C+D">David Greenberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Cloud microphysics has important consequences for climate and weather
phenomena, and inaccurate representations can limit forecast accuracy. While
atmospheric models increasingly resolve storms and clouds, the accuracy of the
underlying microphysics remains limited by computationally expedient bulk
moment schemes based on simplifying assumptions. Droplet-based Lagrangian
schemes are more accurate but are underutilized due to their large
computational overhead. Machine learning (ML) based schemes can bridge this gap
by learning from vast droplet-based simulation datasets, but have so far
struggled to match the accuracy and stability of bulk moment schemes. To
address this challenge, we developed SuperdropNet, an ML-based emulator of the
Lagrangian superdroplet simulations. To improve accuracy and stability, we
employ multi-step autoregressive prediction during training, impose physical
constraints, and carefully control stochasticity in the training data.
Superdropnet predicted hydrometeor states and cloud-to-rain transition times
more accurately than previous ML emulators, and matched or outperformed bulk
moment schemes in many cases. We further carried out detailed analyses to
reveal how multistep autoregressive training improves performance, and how the
performance of SuperdropNet and other microphysical schemes hydrometeors' mass,
number and size distribution. Together our results suggest that ML models can
effectively emulate cloud microphysics, in a manner consistent with
droplet-based simulations.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18594" title="Abstract">arXiv:2402.18594</a> (cross-list from physics.soc-ph) [<a href="/pdf/2402.18594" title="Download PDF">pdf</a>, <a href="/ps/2402.18594" title="Download PostScript">ps</a>, <a href="/format/2402.18594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing the Dynamics of COVID-19 Lockdown Success: Insights from  Regional Data and Public Health Measures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Manik%2C+M+M+H">Md. Motaleb Hossen Manik</a>, 
<a href="/search/physics?searchtype=author&query=Habib%2C+M+A">Md. Ahsan Habib</a>, 
<a href="/search/physics?searchtype=author&query=Islam%2C+M+Z">Md. Zabirul Islam</a>, 
<a href="/search/physics?searchtype=author&query=Ahmed%2C+T">Tanim Ahmed</a>, 
<a href="/search/physics?searchtype=author&query=Haque%2C+F">Fabliha Haque</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Digital Libraries (cs.DL)

</div>
<p class="mathjax">The COVID-19 pandemic caused by the coronavirus had a significant effect on
social, economic, and health systems globally. The virus emerged in Wuhan,
China, and spread worldwide resulting in severe disease, death, and social
interference. Countries implemented lockdowns in various regions to limit the
spread of the virus. Some of them were successful and some failed. Here,
several factors played a vital role in their success. But mostly these factors
and their correlations remained unidentified. In this paper, we unlocked those
factors that contributed to the success of lockdown during the COVID-19
pandemic and explored the correlations among them. Moreover, this paper
proposes several strategies to control any pandemic situation in the future.
Here, it explores the relationships among variables, such as population
density, number of infected, death, recovered patients, and the success or
failure of the lockdown in different regions of the world. The findings suggest
a strong correlation among these factors and indicate that the spread of
similar kinds of viruses can be reduced in the future by implementing several
safety measures.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00008" title="Abstract">arXiv:2403.00008</a> (cross-list from physics.bio-ph) [<a href="/pdf/2403.00008" title="Download PDF">pdf</a>, <a href="/format/2403.00008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mathematical models of drug delivery via a contact lens during wear
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Anderson%2C+D+M">Daniel M. Anderson</a>, 
<a href="/search/physics?searchtype=author&query=Luke%2C+R+A">Rayanne A. Luke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 20 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biological Physics (physics.bio-ph)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this work we develop and investigate mathematical and computational models
that describe drug delivery from a contact lens during wear. Our models are
designed to predict the dynamics of drug release from the contact lens and
subsequent transport into the adjacent pre-lens tear film and post-lens tear
film as well as into the ocular tissue (e.g. cornea), into the eyelid, and out
of these regions. These processes are modeled by one dimensional diffusion out
of the lens coupled to compartment-type models for drug concentrations in the
various accompanying regions. In addition to numerical solutions that are
compared with experimental data on drug release in an in vitro eye model, we
also identify a large diffusion limit model for which analytical solutions can
be written down for all quantities of interest, such as cumulative release of
the drug from the contact lens. We use our models to make assessments about
possible mechanisms and drug transport pathways through the pre-lens and
post-lens tear films and provide interpretation of experimental observations.
We discuss successes and limitations of our models as well as their potential
to guide further research to help understand the dynamics of ophthalmic drug
delivery via drug-eluting contact lenses.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00009" title="Abstract">arXiv:2403.00009</a> (cross-list from q-fin.PM) [<a href="/pdf/2403.00009" title="Download PDF">pdf</a>, <a href="/format/2403.00009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Randomized Control in Performance Analysis and Empirical Asset Pricing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Bachelard%2C+C">Cyril Bachelard</a>, 
<a href="/search/q-fin?searchtype=author&query=Chalkis%2C+A">Apostolos Chalkis</a>, 
<a href="/search/q-fin?searchtype=author&query=Fisikopoulos%2C+V">Vissarion Fisikopoulos</a>, 
<a href="/search/q-fin?searchtype=author&query=Tsigaridas%2C+E">Elias Tsigaridas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 57 pages, 7 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Portfolio Management (q-fin.PM)</span>; Computational Geometry (cs.CG); Computational Finance (q-fin.CP)

</div>
<p class="mathjax">The present article explores the application of randomized control techniques
in empirical asset pricing and performance evaluation. It introduces geometric
random walks, a class of Markov chain Monte Carlo methods, to construct
flexible control groups in the form of random portfolios adhering to investor
constraints. The sampling-based methods enable an exploration of the
relationship between academically studied factor premia and performance in a
practical setting. In an empirical application, the study assesses the
potential to capture premias associated with size, value, quality, and momentum
within a strongly constrained setup, exemplified by the investor guidelines of
the MSCI Diversified Multifactor index. Additionally, the article highlights
issues with the more traditional use case of random portfolios for drawing
inferences in performance evaluation, showcasing challenges related to the
intricacies of high-dimensional geometry.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00033" title="Abstract">arXiv:2403.00033</a> (cross-list from q-bio.NC) [<a href="/pdf/2403.00033" title="Download PDF">pdf</a>, <a href="/format/2403.00033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Resting-State fMRI Data in Marijuana Users via High-Order  Attention Brain Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Ding%2C+J">Jun-En Ding</a>, 
<a href="/search/q-bio?searchtype=author&query=Yang%2C+S">Shihao Yang</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+F">Feng Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">The sustained use of marijuana significantly impacts the lives and health of
people. In this study, we propose an interpretable novel framework called the
HOGAB (High-Order Attention Graph Attention Neural Networks) model to analyze
local abnormal brain activity in chronic marijuana users in two datasets. The
HOGAB integrates dynamic intrinsic functional networks with LSTM technology to
capture temporal patterns in fMRI time series of marijuana users. Moreover, we
use the high-order attention module in neighborhood nodes for information
fusion and message passing, enhancing community clustering analysis for
long-term marijuana users. Furthermore, we improve the overall learning ability
of the model by incorporating attention mechanisms, achieving an AUC of 85.1%
and an accuracy of 80.7% in multigraph classification. In addition, we compare
linear machine learning methods and evaluate the effectiveness of our proposed
HODAB model. Specifically, we identified the most relevant subnetworks and
cognitive regions that are negatively influenced by persistent marijuana use,
revealing that chronic marijuana use adversely affects cognitive control,
particularly within the Dorsal Attention and Frontoparietal networks, which are
essential for attentional, cognitive, and higher cognitive functions. The
results show that our proposed model is capable of accurately predicting
craving maps and identifying brain maps associated with long-term cravings, and
also pinpointing active areas that are important for analysis.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00043" title="Abstract">arXiv:2403.00043</a> (cross-list from q-bio.BM) [<a href="/pdf/2403.00043" title="Download PDF">pdf</a>, <a href="/format/2403.00043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RiNALMo: General-Purpose RNA Language Models Can Generalize Well on  Structure Prediction Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Peni%C4%87%2C+R+J">Rafael Josip Peni&#x107;</a>, 
<a href="/search/q-bio?searchtype=author&query=Vla%C5%A1i%C4%87%2C+T">Tin Vla&#x161;i&#x107;</a>, 
<a href="/search/q-bio?searchtype=author&query=Huber%2C+R+G">Roland G. Huber</a>, 
<a href="/search/q-bio?searchtype=author&query=Wan%2C+Y">Yue Wan</a>, 
<a href="/search/q-bio?searchtype=author&query=%C5%A0iki%C4%87%2C+M">Mile &#x160;iki&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Ribonucleic acid (RNA) plays a variety of crucial roles in fundamental
biological processes. Recently, RNA has become an interesting drug target,
emphasizing the need to improve our understanding of its structures and
functions. Over the years, sequencing technologies have produced an enormous
amount of unlabeled RNA data, which hides important knowledge and potential.
Motivated by the successes of protein language models, we introduce RiboNucleic
Acid Language Model (RiNALMo) to help unveil the hidden code of RNA. RiNALMo is
the largest RNA language model to date with $650$ million parameters
pre-trained on $36$ million non-coding RNA sequences from several available
databases. RiNALMo is able to extract hidden knowledge and capture the
underlying structure information implicitly embedded within the RNA sequences.
RiNALMo achieves state-of-the-art results on several downstream tasks. Notably,
we show that its generalization capabilities can overcome the inability of
other deep learning methods for secondary structure prediction to generalize on
unseen RNA families. The code has been made publicly available on
https://github.com/lbcb-sci/RiNALMo.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00122" title="Abstract">arXiv:2403.00122</a> (cross-list from physics.soc-ph) [<a href="/pdf/2403.00122" title="Download PDF">pdf</a>, <a href="/ps/2403.00122" title="Download PostScript">ps</a>, <a href="/format/2403.00122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Readiness in Healthcare and Public Health: Building a Quantum  Literate Workforce
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=VanGeest%2C+J+B">Jonathan B VanGeest</a>, 
<a href="/search/physics?searchtype=author&query=Fogarty%2C+K+J">Kieran J Fogarty</a>, 
<a href="/search/physics?searchtype=author&query=Hervey%2C+W+G">William G Hervey</a>, 
<a href="/search/physics?searchtype=author&query=Hanson%2C+R+A">Robert A Hanson</a>, 
<a href="/search/physics?searchtype=author&query=Nair%2C+S">Suresh Nair</a>, 
<a href="/search/physics?searchtype=author&query=Akers%2C+T+A">Timothy A Akers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Computers and Society (cs.CY); Emerging Technologies (cs.ET); Quantum Physics (quant-ph)

</div>
<p class="mathjax">Quantum technologies, including quantum computing, cryptography, and sensing,
among others, are set to revolutionize sectors ranging from materials science
to drug discovery. Despite their significant potential, the implications for
public health have been largely overlooked, highlighting a critical gap in
recognition and preparation. This oversight necessitates immediate action, as
public health remains largely unaware of quantum technologies as a tool for
advancement. The application of quantum principles to epidemiology and health
informatics, termed quantum health epidemiology and quantum health informatics,
has the potential to radically transform disease surveillance, prediction,
modeling, and analysis of health data. However, there is a notable lack of
quantum expertise within the public health workforce and educational pipelines.
This gap underscores the urgent need for the development of quantum literacy
among public health practitioners, leaders, and students to leverage emerging
opportunities while addressing risks and ethical considerations. Innovative
teaching methods, such as interactive simulations, games, visual models, and
other tailored platforms, offer viable solutions for bridging knowledge gaps
without the need for advanced physics or mathematics. However, the opportunity
to adapt is fleeting as the quantum era in healthcare looms near. It is
imperative that public health urgently focuses on updating its educational
approaches, workforce strategies, data governance, and organizational culture
to proactively meet the challenges of quantum disruption thereby becoming
quantum ready.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00132" title="Abstract">arXiv:2403.00132</a> (cross-list from quant-ph) [<a href="/pdf/2403.00132" title="Download PDF">pdf</a>, <a href="/format/2403.00132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Hardware Roofline: Evaluating the Impact of Gate Expressivity on  Quantum Processor Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Kalloor%2C+J">Justin Kalloor</a>, 
<a href="/search/quant-ph?searchtype=author&query=Weiden%2C+M">Mathias Weiden</a>, 
<a href="/search/quant-ph?searchtype=author&query=Younis%2C+E">Ed Younis</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kubiatowicz%2C+J">John Kubiatowicz</a>, 
<a href="/search/quant-ph?searchtype=author&query=De+Jong%2C+B">Bert De Jong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Iancu%2C+C">Costin Iancu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Hardware Architecture (cs.AR); Performance (cs.PF)

</div>
<p class="mathjax">The design space of current quantum computers is expansive with no obvious
winning solution. This leaves practitioners with a clear question: "What is the
optimal system configuration to run an algorithm?". This paper explores
hardware design trade-offs across NISQ systems to guide algorithm and hardware
design choices. The evaluation is driven by algorithmic workloads and algorithm
fidelity models which capture architectural features such as gate expressivity,
fidelity, and crosstalk. We also argue that the criteria for gate design and
selection should be extended from maximizing average fidelity to a more
comprehensive approach that takes into account the gate expressivity with
respect to algorithmic structures. We consider native entangling gates (CNOT,
ECR, CZ, ZZ, XX, Sycamore, $\sqrt{\text{iSWAP}}$), proposed gates (B Gate,
$\sqrt[4]{\text{CNOT}}$, $\sqrt[8]{\text{CNOT}}$), as well as parameterized
gates (FSim, XY). Our methodology is driven by a custom synthesis driven
circuit compilation workflow, which is able to produce minimal circuit
representations for a given system configuration. By providing a method to
evaluate the suitability of algorithms for hardware platforms, this work
emphasizes the importance of hardware-software co-design for quantum computing.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00147" title="Abstract">arXiv:2403.00147</a> (cross-list from math.OC) [<a href="/pdf/2403.00147" title="Download PDF">pdf</a>, <a href="/ps/2403.00147" title="Download PostScript">ps</a>, <a href="/format/2403.00147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of Kernel Mirror Prox for Measure Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dvurechensky%2C+P">Pavel Dvurechensky</a>, 
<a href="/search/math?searchtype=author&query=Zhu%2C+J">Jia-Jie Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">By choosing a suitable function space as the dual to the non-negative measure
cone, we study in a unified framework a class of functional saddle-point
optimization problems, which we term the Mixed Functional Nash Equilibrium
(MFNE), that underlies several existing machine learning algorithms, such as
implicit generative models, distributionally robust optimization (DRO), and
Wasserstein barycenters. We model the saddle-point optimization dynamics as an
interacting Fisher-Rao-RKHS gradient flow when the function space is chosen as
a reproducing kernel Hilbert space (RKHS). As a discrete time counterpart, we
propose a primal-dual kernel mirror prox (KMP) algorithm, which uses a dual
step in the RKHS, and a primal entropic mirror prox step. We then provide a
unified convergence analysis of KMP in an infinite-dimensional setting for this
class of MFNE problems, which establishes a convergence rate of $O(1/N)$ in the
deterministic case and $O(1/\sqrt{N})$ in the stochastic case, where $N$ is the
iteration counter. As a case study, we apply our analysis to DRO, providing
algorithmic guarantees for DRO robustness and convergence.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00158" title="Abstract">arXiv:2403.00158</a> (cross-list from stat.CO) [<a href="/pdf/2403.00158" title="Download PDF">pdf</a>, <a href="/format/2403.00158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Efficient Estimation using Monte Carlo Efficient Influence  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Agrawal%2C+R">Raj Agrawal</a>, 
<a href="/search/stat?searchtype=author&query=Witty%2C+S">Sam Witty</a>, 
<a href="/search/stat?searchtype=author&query=Zane%2C+A">Andy Zane</a>, 
<a href="/search/stat?searchtype=author&query=Bingham%2C+E">Eli Bingham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation (stat.CO)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Many practical problems involve estimating low dimensional statistical
quantities with high-dimensional models and datasets. Several approaches
address these estimation tasks based on the theory of influence functions, such
as debiased/double ML or targeted minimum loss estimation. This paper
introduces \textit{Monte Carlo Efficient Influence Functions} (MC-EIF), a fully
automated technique for approximating efficient influence functions that
integrates seamlessly with existing differentiable probabilistic programming
systems. MC-EIF automates efficient statistical estimation for a broad class of
models and target functionals that would previously require rigorous custom
analysis. We prove that MC-EIF is consistent, and that estimators using MC-EIF
achieve optimal $\sqrt{N}$ convergence rates. We show empirically that
estimators using MC-EIF are at parity with estimators using analytic EIFs.
Finally, we demonstrate a novel capstone example using MC-EIF for optimal
portfolio selection.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00182" title="Abstract">arXiv:2403.00182</a> (cross-list from quant-ph) [<a href="/pdf/2403.00182" title="Download PDF">pdf</a>, <a href="/ps/2403.00182" title="Download PostScript">ps</a>, <a href="/format/2403.00182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAT, Gadgets, Max2XOR, and Quantum Annealers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ans%C3%B3tegui%2C+C">Carlos Ans&#xf3;tegui</a>, 
<a href="/search/quant-ph?searchtype=author&query=Levy%2C+J">Jordi Levy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2204.01774">arXiv:2204.01774</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Quantum Annealers are basically quantum computers that with high probability
can optimize certain quadratic functions on Boolean variables in constant time.
These functions are basically the Hamiltonian of Ising models that reach the
ground energy state, with a high probability, after an annealing process. They
have been proposed as a way to solve SAT.
<br />These Hamiltonians can be seen as Max2XOR problems, i.e. as the problem of
finding an assignment that maximizes the number of XOR clauses of at most 2
variables that are satisfied. In this paper, we present several gadgets to
reduce SAT to Max2XOR. We show how they can be used to translate SAT instances
to initial configurations of a quantum annealer.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00184" title="Abstract">arXiv:2403.00184</a> (cross-list from stat.ML) [<a href="/pdf/2403.00184" title="Download PDF">pdf</a>, <a href="/format/2403.00184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entry-Specific Bounds for Low-Rank Matrix Completion under Highly  Non-Uniform Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Xi%2C+X">Xumei Xi</a>, 
<a href="/search/stat?searchtype=author&query=Yu%2C+C+L">Christina Lee Yu</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+Y">Yudong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Low-rank matrix completion concerns the problem of estimating unobserved
entries in a matrix using a sparse set of observed entries. We consider the
non-uniform setting where the observed entries are sampled with highly varying
probabilities, potentially with different asymptotic scalings. We show that
under structured sampling probabilities, it is often better and sometimes
optimal to run estimation algorithms on a smaller submatrix rather than the
entire matrix. In particular, we prove error upper bounds customized to each
entry, which match the minimax lower bounds under certain conditions. Our
bounds characterize the hardness of estimating each entry as a function of the
localized sampling probabilities. We provide numerical experiments that confirm
our theoretical findings.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00229" title="Abstract">arXiv:2403.00229</a> (cross-list from eess.SP) [<a href="/pdf/2403.00229" title="Download PDF">pdf</a>, <a href="/ps/2403.00229" title="Download PostScript">ps</a>, <a href="/format/2403.00229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffraction and Scattering Aware Radio Map and Environment  Reconstruction using Geometry Model-Assisted Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+W">Wangqian Chen</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Junting Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine learning (ML) facilitates rapid channel modeling for 5G and beyond
wireless communication systems. Many existing ML techniques utilize a city map
to construct the radio map; however, an updated city map may not always be
available. This paper proposes to employ the received signal strength (RSS)
data to jointly construct the radio map and the virtual environment by
exploiting the geometry structure of the environment. In contrast to many
existing ML approaches that lack of an environment model, we develop a virtual
obstacle model and characterize the geometry relation between the propagation
paths and the virtual obstacles. A multi-screen knife-edge model is adopted to
extract the key diffraction features, and these features are fed into a neural
network (NN) for diffraction representation. To describe the scattering, as
oppose to most existing methods that directly input an entire city map, our
model focuses on the geometry structure from the local area surrounding the
TX-RX pair and the spatial invariance of such local geometry structure is
exploited. Numerical experiments demonstrate that, in addition to
reconstructing a 3D virtual environment, the proposed model outperforms the
state-of-the-art methods in radio map construction with 10%-18% accuracy
improvements. It can also reduce 20% data and 50% training epochs when
transferred to a new environment.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00233" title="Abstract">arXiv:2403.00233</a> (cross-list from stat.ML) [<a href="/pdf/2403.00233" title="Download PDF">pdf</a>, <a href="/format/2403.00233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Bandits with General Causal Models and Interventions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Yan%2C+Z">Zirui Yan</a>, 
<a href="/search/stat?searchtype=author&query=Wei%2C+D">Dennis Wei</a>, 
<a href="/search/stat?searchtype=author&query=Katz-Rogozhnikov%2C+D">Dmitriy Katz-Rogozhnikov</a>, 
<a href="/search/stat?searchtype=author&query=Sattigeri%2C+P">Prasanna Sattigeri</a>, 
<a href="/search/stat?searchtype=author&query=Tajer%2C+A">Ali Tajer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 13 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper considers causal bandits (CBs) for the sequential design of
interventions in a causal system. The objective is to optimize a reward
function via minimizing a measure of cumulative regret with respect to the best
sequence of interventions in hindsight. The paper advances the results on CBs
in three directions. First, the structural causal models (SCMs) are assumed to
be unknown and drawn arbitrarily from a general class $\mathcal{F}$ of
Lipschitz-continuous functions. Existing results are often focused on
(generalized) linear SCMs. Second, the interventions are assumed to be
generalized soft with any desired level of granularity, resulting in an
infinite number of possible interventions. The existing literature, in
contrast, generally adopts atomic and hard interventions. Third, we provide
general upper and lower bounds on regret. The upper bounds subsume (and
improve) known bounds for special cases. The lower bounds are generally
hitherto unknown. These bounds are characterized as functions of the (i) graph
parameters, (ii) eluder dimension of the space of SCMs, denoted by
$\operatorname{dim}(\mathcal{F})$, and (iii) the covering number of the
function space, denoted by ${\rm cn}(\mathcal{F})$. Specifically, the
cumulative achievable regret over horizon $T$ is $\mathcal{O}(K
d^{L-1}\sqrt{T\operatorname{dim}(\mathcal{F}) \log({\rm cn}(\mathcal{F}))})$,
where $K$ is related to the Lipschitz constants, $d$ is the graph's maximum
in-degree, and $L$ is the length of the longest causal path. The upper bound is
further refined for special classes of SCMs (neural network, polynomial, and
linear), and their corresponding lower bounds are provided.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00237" title="Abstract">arXiv:2403.00237</a> (cross-list from stat.ME) [<a href="/pdf/2403.00237" title="Download PDF">pdf</a>, <a href="/ps/2403.00237" title="Download PostScript">ps</a>, <a href="/format/2403.00237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable Reduced-Rank VAR Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Rong%2C+X">Xinhui Rong</a>, 
<a href="/search/stat?searchtype=author&query=Solo%2C+V">Victor Solo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The vector autoregression (VAR) has been widely used in system
identification, econometrics, natural science, and many other areas. However,
when the state dimension becomes large the parameter dimension explodes. So
rank reduced modelling is attractive and is well developed. But a fundamental
requirement in almost all applications is stability of the fitted model. And
this has not been addressed in the rank reduced case. Here, we develop, for the
first time, a closed-form formula for an estimator of a rank reduced transition
matrix which is guaranteed to be stable. We show that our estimator is
consistent and asymptotically statistically efficient and illustrate it in
comparative simulations.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00258" title="Abstract">arXiv:2403.00258</a> (cross-list from stat.ML) [<a href="/pdf/2403.00258" title="Download PDF">pdf</a>, <a href="/ps/2403.00258" title="Download PostScript">ps</a>, <a href="/format/2403.00258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Lossless&quot; Compression of Deep Neural Networks: A High-dimensional  Neural Tangent Kernel Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Gu%2C+L">Lingyu Gu</a>, 
<a href="/search/stat?searchtype=author&query=Du%2C+Y">Yongqi Du</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+Y">Yuan Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Xie%2C+D">Di Xie</a>, 
<a href="/search/stat?searchtype=author&query=Pu%2C+S">Shiliang Pu</a>, 
<a href="/search/stat?searchtype=author&query=Qiu%2C+R+C">Robert C. Qiu</a>, 
<a href="/search/stat?searchtype=author&query=Liao%2C+Z">Zhenyu Liao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 4 figures, and 2 tables. Fixing typos in Theorems 1 and 2 from NeurIPS 2022 proceeding (<a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/185087ea328b4f03ea8fd0c8aa96f747-Abstract-Conference.html">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Modern deep neural networks (DNNs) are extremely powerful; however, this
comes at the price of increased depth and having more parameters per layer,
making their training and inference more computationally challenging. In an
attempt to address this key limitation, efforts have been devoted to the
compression (e.g., sparsification and/or quantization) of these large-scale
machine learning models, so that they can be deployed on low-power IoT devices.
In this paper, building upon recent advances in neural tangent kernel (NTK) and
random matrix theory (RMT), we provide a novel compression approach to wide and
fully-connected \emph{deep} neural nets. Specifically, we demonstrate that in
the high-dimensional regime where the number of data points $n$ and their
dimension $p$ are both large, and under a Gaussian mixture model for the data,
there exists \emph{asymptotic spectral equivalence} between the NTK matrices
for a large family of DNN models. This theoretical result enables "lossless"
compression of a given DNN to be performed, in the sense that the compressed
network yields asymptotically the same NTK as the original (dense and
unquantized) network, with its weights and activations taking values
\emph{only} in $\{ 0, \pm 1 \}$ up to a scaling. Experiments on both synthetic
and real-world data are conducted to support the advantages of the proposed
compression scheme, with code available at
\url{https://github.com/Model-Compression/Lossless_Compression}.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00259" title="Abstract">arXiv:2403.00259</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2403.00259" title="Download PDF">pdf</a>, <a href="/ps/2403.00259" title="Download PostScript">ps</a>, <a href="/format/2403.00259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deciphering diffuse scattering with machine learning and the equivariant  foundation model: The case of molten FeO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Sivaraman%2C+G">Ganesh Sivaraman</a>, 
<a href="/search/cond-mat?searchtype=author&query=Benmore%2C+C+J">Chris J. Benmore</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Bridging the gap between diffuse x-ray or neutron scattering measurements and
predicted structures derived from atom-atom pair potentials in disordered
materials, has been a longstanding challenge in condensed matter physics. This
perspective gives a brief overview of the traditional approaches employed over
the past several decades. Namely, the use of approximate interatomic pair
potentials that relate 3-dimensional structural models to the measured
structure factor and its associated pair distribution function. The use of
machine learned interatomic potentials has grown in the past few years, and has
been particularly successful in the cases of ionic and oxide systems. Recent
advances in large scale sampling, along with a direct integration of scattering
measurements into the model development, has provided improved agreement
between experiments and large-scale models calculated with quantum mechanical
accuracy. However, details of local polyhedral bonding and connectivity in
meta-stable disordered systems still require improvement. Here we leverage
MACE-MP-0; a newly introduced equivariant foundation model and validate the
results against high-quality experimental scattering data for the case of
molten iron(II) oxide (FeO). These preliminary results suggest that the
emerging foundation model has the potential to surpass the traditional
limitations of classical interatomic potentials.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00289" title="Abstract">arXiv:2403.00289</a> (cross-list from physics.med-ph) [<a href="/pdf/2403.00289" title="Download PDF">pdf</a>, <a href="/format/2403.00289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization of Array Encoding for Ultrasound Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Spainhour%2C+J">Jacob Spainhour</a>, 
<a href="/search/physics?searchtype=author&query=Smart%2C+K">Korben Smart</a>, 
<a href="/search/physics?searchtype=author&query=Becker%2C+S">Stephen Becker</a>, 
<a href="/search/physics?searchtype=author&query=Bottenus%2C+N">Nick Bottenus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">Objective: The transmit encoding model for synthetic aperture imaging is a
robust and flexible framework for understanding the effect of acoustic
transmission on ultrasound image reconstruction. Our objective is to use
machine learning (ML) to construct scanning sequences, parameterized by time
delays and apodization weights, that produce high quality B-mode images.
Approach: We use an ML model in PyTorch and simulated RF data from Field II to
probe the space of possible encoding sequences for those that minimize a loss
function that describes image quality. This approach is made computationally
feasible by a novel formulation of the derivative for delay-and-sum
beamforming. We demonstrate these results experimentally on wire targets and a
tissue-mimicking phantom. Main Results: When trained according to a given set
of imaging parameters (imaging domain, hardware restrictions), our ML imaging
model produces optimized encoding sequences that improve a number of standard
quality metrics including resolution, field of view, and contrast, over
conventional sequences. Significance: This work demonstrates that the set of
encoding schemes that are commonly used represent only a narrow subset of those
available. Additionally, it demonstrates the value for ML tasks in synthetic
transmit aperture imaging to consider the beamformer within the model, instead
of as purely post-processing.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00293" title="Abstract">arXiv:2403.00293</a> (cross-list from eess.AS) [<a href="/pdf/2403.00293" title="Download PDF">pdf</a>, <a href="/format/2403.00293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Adapter Tuning of Pre-trained Speech Models for Automatic  Speaker Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sang%2C+M">Mufan Sang</a>, 
<a href="/search/eess?searchtype=author&query=Hansen%2C+J+H+L">John H.L. Hansen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">With excellent generalization ability, self-supervised speech models have
shown impressive performance on various downstream speech tasks in the
pre-training and fine-tuning paradigm. However, as the growing size of
pre-trained models, fine-tuning becomes practically unfeasible due to heavy
computation and storage overhead, as well as the risk of overfitting. Adapters
are lightweight modules inserted into pre-trained models to facilitate
parameter-efficient adaptation. In this paper, we propose an effective adapter
framework designed for adapting self-supervised speech models to the speaker
verification task. With a parallel adapter design, our proposed framework
inserts two types of adapters into the pre-trained model, allowing the
adaptation of latent features within intermediate Transformer layers and output
embeddings from all Transformer layers. We conduct comprehensive experiments to
validate the efficiency and effectiveness of the proposed framework.
Experimental results on the VoxCeleb1 dataset demonstrate that the proposed
adapters surpass fine-tuning and other parameter-efficient transfer learning
methods, achieving superior performance while updating only 5% of the
parameters.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00363" title="Abstract">arXiv:2403.00363</a> (cross-list from quant-ph) [<a href="/pdf/2403.00363" title="Download PDF">pdf</a>, <a href="/format/2403.00363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SFQ counter-based precomputation for large-scale cryogenic VQE machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ueno%2C+Y">Yosuke Ueno</a>, 
<a href="/search/quant-ph?searchtype=author&query=Imamura%2C+S">Satoshi Imamura</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tomida%2C+Y">Yuna Tomida</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tanimoto%2C+T">Teruo Tanimoto</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tanaka%2C+M">Masamitsu Tanaka</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tabuchi%2C+Y">Yutaka Tabuchi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Inoue%2C+K">Koji Inoue</a>, 
<a href="/search/quant-ph?searchtype=author&query=Nakamura%2C+H">Hiroshi Nakamura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, 3 tables. Accepted by DAC'24 WIP poster session
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">The variational quantum eigensolver (VQE) is a promising candidate that
brings practical benefits from quantum computing. However, the required
bandwidth in/out of a cryostat is a limiting factor to scale cryogenic quantum
computers. We propose a tailored counter-based module with single flux quantum
circuits in 4-K stage which precomputes a part of VQE calculation and reduces
the amount of inter-temperature communication. The evaluation shows that our
system reduces the required bandwidth by 97%, and with this drastic reduction,
total power consumption is reduced by 93% in the case where 277 VQE programs
are executed in parallel on a 10000-qubit machine.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00379" title="Abstract">arXiv:2403.00379</a> (cross-list from eess.AS) [<a href="/pdf/2403.00379" title="Download PDF">pdf</a>, <a href="/format/2403.00379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Frequency Bands on Acoustic Anomaly Detection of Machines  using Deep Learning Based Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+T">Tin Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Pham%2C+L">Lam Pham</a>, 
<a href="/search/eess?searchtype=author&query=Lam%2C+P">Phat Lam</a>, 
<a href="/search/eess?searchtype=author&query=Ngo%2C+D">Dat Ngo</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+H">Hieu Tang</a>, 
<a href="/search/eess?searchtype=author&query=Schindler%2C+A">Alexander Schindler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">In this paper, we propose a deep learning based model for Acoustic Anomaly
Detection of Machines, the task for detecting abnormal machines by analysing
the machine sound. By conducting extensive experiments, we indicate that
multiple techniques of pseudo audios, audio segment, data augmentation,
Mahalanobis distance, and narrow frequency bands, which mainly focus on feature
engineering, are effective to enhance the system performance. Among the
evaluating techniques, the narrow frequency bands presents a significant
impact. Indeed, our proposed model, which focuses on the narrow frequency
bands, outperforms the DCASE baseline on the benchmark dataset of DCASE 2022
Task 2 Development set. The important role of the narrow frequency bands
indicated in this paper inspires the research community on the task of Acoustic
Anomaly Detection of Machines to further investigate and propose novel network
architectures focusing on the frequency bands.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00394" title="Abstract">arXiv:2403.00394</a> (cross-list from physics.med-ph) [<a href="/pdf/2403.00394" title="Download PDF">pdf</a>, <a href="/ps/2403.00394" title="Download PostScript">ps</a>, <a href="/format/2403.00394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> List-Mode PET Image Reconstruction Using Dykstra-Like Splitting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Ote%2C+K">Kibo Ote</a>, 
<a href="/search/physics?searchtype=author&query=Hashimoto%2C+F">Fumio Hashimoto</a>, 
<a href="/search/physics?searchtype=author&query=Onishi%2C+Y">Yuya Onishi</a>, 
<a href="/search/physics?searchtype=author&query=Ouchi%2C+Y">Yasuomi Ouchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">To converge the block iterative method in image reconstruction for positron
emission tomography (PET), careful control of relaxation parameters is
required, which is a challenging task. The automatic determination of
relaxation parameters for list-mode reconstructions also remains challenging.
Therefore, a different approach than controlling relaxation parameters would be
desired by list-mode PET reconstruction. In this study, we propose a list-mode
maximum likelihood Dykstra-like splitting PET reconstruction (LM-MLDS). LM-MLDS
converges the list-mode block iterative method by adding the distance from an
initial image as a penalty term into an objective function. LM-MLDS takes a
two-step approach because its performance depends on the quality of the initial
image. The first step uses a uniform image as the initial image, and then the
second step uses a reconstructed image after one main iteration as the initial
image. We evaluated LM-MLDS using simulation and clinical data. LM-MLDS
provided a higher peak signal-to-noise ratio and suppressed an oscillation of
tradeoff curves between noise and contrast than the other block iterative
methods. In a clinical study, LM-MLDS removed the false hotspots at the edge of
the axial field of view and improved the image quality of slices covering the
top of the head to the cerebellum. LM-MLDS showed different noise properties
than the other methods due to Gaussian denoising induced by the proximity
operator. The list-mode proximal splitting PET reconstruction is useful not
only for optimizing nondifferentiable functions such as total variation but
also for converging block iterative methods without controlling relaxation
parameters.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00402" title="Abstract">arXiv:2403.00402</a> (cross-list from eess.SP) [<a href="/pdf/2403.00402" title="Download PDF">pdf</a>, <a href="/ps/2403.00402" title="Download PostScript">ps</a>, <a href="/format/2403.00402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatio-temporal reconstruction of substance dynamics using compressed  sensing in multi-spectral magnetic resonance spectroscopic imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yamamoto%2C+U">Utako Yamamoto</a>, 
<a href="/search/eess?searchtype=author&query=Imai%2C+H">Hirohiko Imai</a>, 
<a href="/search/eess?searchtype=author&query=Sano%2C+K">Kei Sano</a>, 
<a href="/search/eess?searchtype=author&query=Ohzeki%2C+M">Masayuki Ohzeki</a>, 
<a href="/search/eess?searchtype=author&query=Matsuda%2C+T">Tetsuya Matsuda</a>, 
<a href="/search/eess?searchtype=author&query=Tanaka%2C+T">Toshiyuki Tanaka</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Expert Systems with Applications, Vol. 232 (2023) p. 120744
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The objective of our study is to observe dynamics of multiple substances in
vivo with high temporal resolution from multi-spectral magnetic resonance
spectroscopic imaging (MRSI) data. The multi-spectral MRSI can effectively
separate spectral peaks of multiple substances and is useful to measure spatial
distributions of substances. However it is difficult to measure time-varying
substance distributions directly by ordinary full sampling because the
measurement requires a significantly long time. In this study, we propose a
novel method to reconstruct the spatio-temporal distributions of substances
from randomly undersampled multi-spectral MRSI data on the basis of compressed
sensing (CS) and the partially separable function model with base spectra of
substances. In our method, we have employed spatio-temporal sparsity and
temporal smoothness of the substance distributions as prior knowledge to
perform CS. The effectiveness of our method has been evaluated using phantom
data sets of glass tubes filled with glucose or lactate solution in increasing
amounts over time and animal data sets of a tumor-bearing mouse to observe the
metabolic dynamics involved in the Warburg effect in vivo. The reconstructed
results are consistent with the expected behaviors, showing that our method can
reconstruct the spatio-temporal distribution of substances with a temporal
resolution of four seconds which is extremely short time scale compared with
that of full sampling. Since this method utilizes only prior knowledge
naturally assumed for the spatio-temporal distributions of substances and is
independent of the number of the spectral and spatial dimensions or the
acquisition sequence of MRSI, it is expected to contribute to revealing the
underlying substance dynamics in MRSI data already acquired or to be acquired
in the future.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00412" title="Abstract">arXiv:2403.00412</a> (cross-list from math.CO) [<a href="/pdf/2403.00412" title="Download PDF">pdf</a>, <a href="/format/2403.00412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Bounds for Point Selections and Halving Hyperplanes in Higher  Dimensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Rubin%2C+N">Natan Rubin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preliminary version has appeared in the Proceedings of the 2024 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">Let $(P,E)$ be a $(d+1)$-uniform geometric hypergraph, where $P$ is an
$n$-point set in general position in $\mathbb{R}^d$ and $E\subseteq {P\choose
d+1}$ is a collection of $\epsilon{n\choose d+1}$ $d$-dimensional simplices
with vertices in $P$, for $0&lt;\epsilon\leq 1$. We show that there is a point
$x\in {\mathbb R}^d$ that pierces $\displaystyle
\Omega\left(\epsilon^{(d^4+d)(d+1)+\delta}{n\choose d+1}\right)$ simplices in
$E$, for any fixed $\delta&gt;0$. This is a dramatic improvement in all dimensions
$d\geq 3$, over the previous lower bounds of the general form $\displaystyle
\epsilon^{(cd)^{d+1}}n^{d+1}$, which date back to the seminal 1991 work of
Alon, B\'{a}r\'{a}ny, F\"{u}redi and Kleitman.
<br />As a result, any $n$-point set in general position in $\mathbb{R}^d$ admits
only $\displaystyle O\left(n^{d-\frac{1}{d(d-1)^4+d(d-1)}+\delta}\right)$
halving hyperplanes, for any $\delta&gt;0$, which is a significant improvement
over the previously best known bound $\displaystyle
O\left(n^{d-\frac{1}{(2d)^{d}}}\right)$ in all dimensions $d\geq 5$.
<br />An essential ingredient of our proof is the following semi-algebraic
Tur\'an-type result of independent interest: Let $(V_1,\ldots,V_k,E)$ be a
hypergraph of bounded semi-algebraic description complexity in ${\mathbb R}^d$
that satisfies $|E|\geq \varepsilon |V_1|\cdot\ldots \cdot |V_k|$ for some
$\varepsilon&gt;0$. Then there exist subsets $W_i\subseteq V_i$ that satisfy
$W_1\times W_2\times\ldots\times W_k\subseteq E$, and
$|W_1|\cdot\ldots\cdots|W_k|=\Omega\left(\varepsilon^{d(k-1)+1}|V_1|\cdot
|V_2|\cdot\ldots\cdot|V_k|\right)$.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00423" title="Abstract">arXiv:2403.00423</a> (cross-list from stat.ML) [<a href="/pdf/2403.00423" title="Download PDF">pdf</a>, <a href="/format/2403.00423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Validation of ML-UQ calibration statistics using simulated reference  values: a sensitivity analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Pernot%2C+P">Pascal Pernot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Chemical Physics (physics.chem-ph)

</div>
<p class="mathjax">Some popular Machine Learning Uncertainty Quantification (ML-UQ) calibration
statistics do not have predefined reference values and are mostly used in
comparative studies. In consequence, calibration is almost never validated and
the diagnostic is left to the appreciation of the reader. Simulated reference
values, based on synthetic calibrated datasets derived from actual
uncertainties, have been proposed to palliate this problem. As the generative
probability distribution for the simulation of synthetic errors is often not
constrained, the sensitivity of simulated reference values to the choice of
generative distribution might be problematic, shedding a doubt on the
calibration diagnostic. This study explores various facets of this problem, and
shows that some statistics are excessively sensitive to the choice of
generative distribution to be used for validation when the generative
distribution is unknown. This is the case, for instance, of the correlation
coefficient between absolute errors and uncertainties (CC) and of the expected
normalized calibration error (ENCE). A robust validation workflow to deal with
simulated reference values is proposed.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00447" title="Abstract">arXiv:2403.00447</a> (cross-list from math.OC) [<a href="/pdf/2403.00447" title="Download PDF">pdf</a>, <a href="/format/2403.00447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous Approximations of Projected Dynamical Systems via Control  Barrier Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Delimpaltadakis%2C+G">Giannis Delimpaltadakis</a>, 
<a href="/search/math?searchtype=author&query=Cort%C3%A9s%2C+J">Jorge Cort&#xe9;s</a>, 
<a href="/search/math?searchtype=author&query=H.%2C+W+P+M">W.P.M.H.</a> (Maurice)
<a href="/search/math?searchtype=author&query=Heemels">Heemels</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Projected Dynamical Systems (PDSs) form a class of discontinuous constrained
dynamical systems, and have been used widely to solve optimization problems and
variational inequalities. Recently, they have also gained significant attention
for control purposes, such as high-performance integrators, saturated control
and feedback optimization. In this work, we establish that locally Lipschitz
continuous dynamics, involving Control Barrier Functions (CBFs), namely
CBF-based dynamics, approximate PDSs. Specifically, we prove that trajectories
of CBF-based dynamics uniformly converge to trajectories of PDSs, as a
CBF-parameter is taken to infinity. Towards this, we also prove that CBF-based
dynamics are perturbations of PDSs, with quantitative bounds on the
perturbation. Our results pave the way to implement discontinuous PDS-based
controllers in a continuous fashion, employing CBFs. Moreover, they can be
employed to numerically simulate PDSs, overcoming disadvantages of existing
discretization schemes, such as computing projections to possibly non-convex
sets. Finally, this bridge between CBFs and PDSs may yield other potential
benefits, including novel insights on stability.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00470" title="Abstract">arXiv:2403.00470</a> (cross-list from astro-ph.IM) [<a href="/pdf/2403.00470" title="Download PDF">pdf</a>, <a href="/format/2403.00470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Robotic Arm Manipulation for Planetary Missions using Causal  Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=McDonnell%2C+C">C. McDonnell</a>, 
<a href="/search/astro-ph?searchtype=author&query=Arana-Catania%2C+M">M. Arana-Catania</a>, 
<a href="/search/astro-ph?searchtype=author&query=Upadhyay%2C+S">S. Upadhyay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, ASTRA 2023: 17th Symposium on Advanced Space Technologies in Robotics and Automation, 18-20 October 2023, Leiden, The Netherlands
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Earth and Planetary Astrophysics (astro-ph.EP); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Autonomous robotic arm manipulators have the potential to make planetary
exploration and in-situ resource utilization missions more time efficient and
productive, as the manipulator can handle the objects itself and perform
goal-specific actions. We train a manipulator to autonomously study objects of
which it has no prior knowledge, such as planetary rocks. This is achieved
using causal machine learning in a simulated planetary environment. Here, the
manipulator interacts with objects, and classifies them based on differing
causal factors. These are parameters, such as mass or friction coefficient,
that causally determine the outcomes of its interactions. Through reinforcement
learning, the manipulator learns to interact in ways that reveal the underlying
causal factors. We show that this method works even without any prior knowledge
of the objects, or any previously-collected training data. We carry out the
training in planetary exploration conditions, with realistic manipulator
models.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00488" title="Abstract">arXiv:2403.00488</a> (cross-list from astro-ph.SR) [<a href="/pdf/2403.00488" title="Download PDF">pdf</a>, <a href="/format/2403.00488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring solar differential rotation and viscosity via passive imaging  with inertial waves
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Nguyen%2C+T+T+N">Tram Thi Ngoc Nguyen</a>, 
<a href="/search/astro-ph?searchtype=author&query=Hohage%2C+T">Thorsten Hohage</a>, 
<a href="/search/astro-ph?searchtype=author&query=Fournier%2C+D">Damien Fournier</a>, 
<a href="/search/astro-ph?searchtype=author&query=Gizon%2C+L">Laurent Gizon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> proceedings paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Solar and Stellar Astrophysics (astro-ph.SR)</span>; Numerical Analysis (math.NA); Optimization and Control (math.OC)

</div>
<p class="mathjax">The recent discovery of inertial waves on the surface of the Sun offers new
possibilities to learn about the solar interior. These waves are long-lived
with a period on the order of the Sun rotation period ($\sim$27 days) and are
sensitive to parameters deep inside the Sun. They are excited by turbulent
convection, leading to a passive imaging problem. In this work, we present the
forward and inverse problem of reconstructing viscosity and differential
rotation on the Sun from cross-covariance observations of these inertial waves.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00507" title="Abstract">arXiv:2403.00507</a> (cross-list from quant-ph) [<a href="/pdf/2403.00507" title="Download PDF">pdf</a>, <a href="/format/2403.00507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Molecular unfolding formulation with enhanced quantum annealing approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Bishwas%2C+A+K">Arit Kumar Bishwas</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pitchai%2C+A">Arish Pitchai</a>, 
<a href="/search/quant-ph?searchtype=author&query=Som%2C+A">Anuraj Som</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Molecular docking is a crucial phase in drug discovery, involving the precise
determination of the optimal spatial arrangement between two molecules when
they bind. The such analysis, the 3D structure of molecules is a fundamental
consideration, involving the manipulation of molecular representations based on
their degrees of freedom, including rigid roto-translation and fragment
rotations along rotatable bonds, to determine the preferred spatial arrangement
when molecules bind to each other. In this paper, quantum annealing based
solution to solve Molecular unfolding (MU) problem, a specific phase within
molecular docking, is explored and compared with a state-of-the-art classical
algorithm named "GeoDock". Molecular unfolding focuses on expanding a molecule
to an unfolded state to simplify manipulation within the target cavity and
optimize its configuration, typically by maximizing molecular area or internal
atom distances. Molecular unfolding problem aims to find the torsional
configuration that increases the inter-atomic distance within a molecule, which
also increases the molecular area. Quantum annealing approach first encodes the
problem into a Higher-order Unconstrained Binary Optimization (HUBO) equation
which is pruned to an arbitrary percentage to improve the time efficiency and
to be able to solve the equation using any quantum annealer. The resultant HUBO
is then converted to a Quadratic Unconstrained Binary Optimization equation
(QUBO), which is easily embedded on a D-wave annealing Quantum processor.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00523" title="Abstract">arXiv:2403.00523</a> (cross-list from q-fin.GN) [<a href="/pdf/2403.00523" title="Download PDF">pdf</a>, <a href="/ps/2403.00523" title="Download PostScript">ps</a>, <a href="/format/2403.00523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the Efficacy of Heuristic-Based Address Clustering for Bitcoin
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Schnoering%2C+H">Hugo Schnoering</a>, 
<a href="/search/q-fin?searchtype=author&query=Porthaux%2C+P">Pierre Porthaux</a>, 
<a href="/search/q-fin?searchtype=author&query=Vazirgiannis%2C+M">Michalis Vazirgiannis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Finance (q-fin.GN)</span>; Cryptography and Security (cs.CR); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Exploring transactions within the Bitcoin blockchain entails examining the
transfer of bitcoins among several hundred million entities. However, it is
often impractical and resource-consuming to study such a vast number of
entities. Consequently, entity clustering serves as an initial step in most
analytical studies. This process often employs heuristics grounded in the
practices and behaviors of these entities. In this research, we delve into the
examination of two widely used heuristics, alongside the introduction of four
novel ones. Our contribution includes the introduction of the
\textit{clustering ratio}, a metric designed to quantify the reduction in the
number of entities achieved by a given heuristic. The assessment of this
reduction ratio plays an important role in justifying the selection of a
specific heuristic for analytical purposes. Given the dynamic nature of the
Bitcoin system, characterized by a continuous increase in the number of
entities on the blockchain, and the evolving behaviors of these entities, we
extend our study to explore the temporal evolution of the clustering ratio for
each heuristic. This temporal analysis enhances our understanding of the
effectiveness of these heuristics over time.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00549" title="Abstract">arXiv:2403.00549</a> (cross-list from eess.IV) [<a href="/pdf/2403.00549" title="Download PDF">pdf</a>, <a href="/format/2403.00549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relaxometry Guided Quantitative Cardiac Magnetic Resonance Image  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Y">Yidong Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Tao%2C+Q">Qian Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Deep learning-based methods have achieved prestigious performance for
magnetic resonance imaging (MRI) reconstruction, enabling fast imaging for many
clinical applications. Previous methods employ convolutional networks to learn
the image prior as the regularization term. In quantitative MRI, the physical
model of nuclear magnetic resonance relaxometry is known, providing additional
prior knowledge for image reconstruction. However, traditional reconstruction
networks are limited to learning the spatial domain prior knowledge, ignoring
the relaxometry prior. Therefore, we propose a relaxometry-guided quantitative
MRI reconstruction framework to learn the spatial prior from data and the
relaxometry prior from MRI physics. Additionally, we also evaluated the
performance of two popular reconstruction backbones, namely, recurrent
variational networks (RVN) and variational networks (VN) with U- Net.
Experiments demonstrate that the proposed method achieves highly promising
results in quantitative MRI reconstruction.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00612" title="Abstract">arXiv:2403.00612</a> (cross-list from eess.IV) [<a href="/pdf/2403.00612" title="Download PDF">pdf</a>, <a href="/format/2403.00612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing dermatological diagnosis: Development of a hyperspectral  dermatoscope for enhanced skin imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hetz%2C+M+J">Martin J. Hetz</a>, 
<a href="/search/eess?searchtype=author&query=Garcia%2C+C+N">Carina Nogueira Garcia</a>, 
<a href="/search/eess?searchtype=author&query=Haggenm%C3%BCller%2C+S">Sarah Haggenm&#xfc;ller</a>, 
<a href="/search/eess?searchtype=author&query=Brinker%2C+T+J">Titus J. Brinker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Clinical dermatology necessitates precision and innovation for efficient
diagnosis and treatment of various skin conditions. This paper introduces the
development of a cutting-edge hyperspectral dermatoscope (the Hyperscope)
tailored for human skin analysis. We detail the requirements to such a device
and the design considerations, from optical configurations to sensor selection,
necessary to capture a wide spectral range with high fidelity. Preliminary
results from 15 individuals and 160 recorded skin images demonstrate the
potential of the Hyperscope in identifying and characterizing various skin
conditions, offering a promising avenue for non-invasive skin evaluation and a
platform for future research in dermatology-related hyperspectral imaging.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00636" title="Abstract">arXiv:2403.00636</a> (cross-list from eess.IV) [<a href="/pdf/2403.00636" title="Download PDF">pdf</a>, <a href="/format/2403.00636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Theory and GNNs to Unravel the Topographical Organization of Brain  Lesions in Variants of Alzheimer&#x27;s Disease Progression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hebert-Stevens%2C+L">Leopold Hebert-Stevens</a>, 
<a href="/search/eess?searchtype=author&query=Jimenez%2C+G">Gabriel Jimenez</a>, 
<a href="/search/eess?searchtype=author&query=Delatour%2C+B">Benoit Delatour</a>, 
<a href="/search/eess?searchtype=author&query=Stimmer%2C+L">Lev Stimmer</a>, 
<a href="/search/eess?searchtype=author&query=Racoceanu%2C+D">Daniel Racoceanu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This study utilizes graph theory and deep learning to assess variations in
Alzheimer's disease (AD) neuropathologies, focusing on classic (cAD) and rapid
(rpAD) progression forms. It analyses the distribution of amyloid plaques and
tau tangles in postmortem brain tissues. Histopathological images are converted
into tau-pathology-based graphs, and derived metrics are used for statistical
analysis and in machine learning classifiers. These classifiers incorporate
SHAP value explainability to differentiate between cAD and rpAD. Graph neural
networks (GNNs) demonstrate greater efficiency than traditional CNN methods in
analyzing this data, preserving spatial pathology context. Additionally, GNNs
provide significant insights through explainable AI techniques. The analysis
shows denser networks in rpAD and a distinctive impact on brain cortical
layers: rpAD predominantly affects middle layers, whereas cAD influences both
superficial and deep layers of the same cortical regions. These results suggest
a unique neuropathological network organization for each AD variant.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00637" title="Abstract">arXiv:2403.00637</a> (cross-list from math.PR) [<a href="/pdf/2403.00637" title="Download PDF">pdf</a>, <a href="/ps/2403.00637" title="Download PostScript">ps</a>, <a href="/format/2403.00637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the complexity of strong approximation of stochastic differential  equations with a non-Lipschitz drift coefficient
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=M%C3%BCller-Gronbach%2C+T">T. M&#xfc;ller-Gronbach</a>, 
<a href="/search/math?searchtype=author&query=Yaroslavtseva%2C+L">L. Yaroslavtseva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We survey recent developments in the field of complexity of pathwise
approximation in $p$-th mean of the solution of a stochastic differential
equation at the final time based on finitely many evaluations of the driving
Brownian motion. First, we briefly review the case of equations with globally
Lipschitz continuous coefficients, for which an error rate of at least $1/2$ in
terms of the number of evaluations of the driving Brownian motion is always
guaranteed by using the equidistant Euler-Maruyama scheme. Then we illustrate
that giving up the global Lipschitz continuity of the coefficients may lead to
a non-polynomial decay of the error for the Euler-Maruyama scheme or even to an
arbitrary slow decay of the smallest possible error that can be achieved on the
basis of finitely many evaluations of the driving Brownian motion. Finally, we
turn to recent positive results for equations with a drift coefficient that is
not globally Lipschitz continuous. Here we focus on scalar equations with a
Lipschitz continuous diffusion coefficient and a drift coefficient that
satisfies piecewise smoothness assumptions or has fractional Sobolev regularity
and we present corresponding complexity results.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00692" title="Abstract">arXiv:2403.00692</a> (cross-list from eess.SP) [<a href="/pdf/2403.00692" title="Download PDF">pdf</a>, <a href="/format/2403.00692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Autonomous Cooperation in Heterogeneous Nanosatellite  Constellations Using Dynamic Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Casadesus-Vila%2C+G">Guillem Casadesus-Vila</a>, 
<a href="/search/eess?searchtype=author&query=Ruiz-de-Azua%2C+J">Joan-Adria Ruiz-de-Azua</a>, 
<a href="/search/eess?searchtype=author&query=Alarcon%2C+E">Eduard Alarcon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">The upcoming landscape of Earth Observation missions will defined by
networked heterogeneous nanosatellite constellations required to meet strict
mission requirements, such as revisit times and spatial resolution. However,
scheduling satellite communications in these satellite networks through
efficiently creating a global satellite Contact Plan (CP) is a complex task,
with current solutions requiring ground-based coordination or being limited by
onboard computational resources. The paper proposes a novel approach to
overcome these challenges by modeling the constellations and CP as dynamic
networks and employing graph-based techniques. The proposed method utilizes a
state-of-the-art dynamic graph neural network to evaluate the performance of a
given CP and update it using a heuristic algorithm based on simulated
annealing. The trained neural network can predict the network delay with a mean
absolute error of 3.6 minutes. Simulation results show that the proposed method
can successfully design a contact plan for large satellite networks, improving
the delay by 29.1%, similar to a traditional approach, while performing the
objective evaluations 20x faster.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00694" title="Abstract">arXiv:2403.00694</a> (cross-list from stat.ML) [<a href="/pdf/2403.00694" title="Download PDF">pdf</a>, <a href="/format/2403.00694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defining Expertise: Applications to Treatment Effect Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=H%C3%BCy%C3%BCk%2C+A">Alihan H&#xfc;y&#xfc;k</a>, 
<a href="/search/stat?searchtype=author&query=Wei%2C+Q">Qiyao Wei</a>, 
<a href="/search/stat?searchtype=author&query=Curth%2C+A">Alicia Curth</a>, 
<a href="/search/stat?searchtype=author&query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 12th International Conference on Learning Representations (ICLR 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Decision-makers are often experts of their domain and take actions based on
their domain knowledge. Doctors, for instance, may prescribe treatments by
predicting the likely outcome of each available treatment. Actions of an expert
thus naturally encode part of their domain knowledge, and can help make
inferences within the same domain: Knowing doctors try to prescribe the best
treatment for their patients, we can tell treatments prescribed more frequently
are likely to be more effective. Yet in machine learning, the fact that most
decision-makers are experts is often overlooked, and "expertise" is seldom
leveraged as an inductive bias. This is especially true for the literature on
treatment effect estimation, where often the only assumption made about actions
is that of overlap. In this paper, we argue that expertise - particularly the
type of expertise the decision-makers of a domain are likely to have - can be
informative in designing and selecting methods for treatment effect estimation.
We formally define two types of expertise, predictive and prognostic, and
demonstrate empirically that: (i) the prominent type of expertise in a domain
significantly influences the performance of different methods in treatment
effect estimation, and (ii) it is possible to predict the type of expertise
present in a dataset, which can provide a quantitative basis for model
selection.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00698" title="Abstract">arXiv:2403.00698</a> (cross-list from math.MG) [<a href="/pdf/2403.00698" title="Download PDF">pdf</a>, <a href="/ps/2403.00698" title="Download PostScript">ps</a>, <a href="/format/2403.00698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Path Tracking using Echoes in an Unknown Environment: the Issue of  Symmetries and How to Break Them
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Boutin%2C+M">Mireille Boutin</a>, 
<a href="/search/math?searchtype=author&query=Kemper%2C+G">Gregor Kemper</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Metric Geometry (math.MG)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This paper deals with the problem of reconstructing the path of a vehicle in
an unknown environment consisting of planar structures using sound. Many
systems in the literature do this by using a loudspeaker and microphones
mounted on a vehicle. Symmetries in the environment lead to solution
ambiguities for such systems. We propose to resolve this issue by placing the
loudspeaker at a fixed location in the environment rather than on the vehicle.
The question of whether this will remove ambiguities regardless of the
environment geometry leads to a question about breaking symmetries that can be
phrased in purely mathematical terms. We solve this question in the affirmative
if the geometry is in dimension three or bigger, and give counterexamples in
dimension two. Excluding the rare situations where the counterexamples arise,
we also give an affirmative answer in dimension two. Our results lead to a
simple path reconstruction algorithm for a vehicle carrying four microphones
navigating within an environment in which a loudspeaker at a fixed position
emits short bursts of sounds. This algorithm could be combined with other
methods from the literature to construct a path tracking system for vehicles
navigating within a potentially symmetric environment.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00736" title="Abstract">arXiv:2403.00736</a> (cross-list from math.PR) [<a href="/pdf/2403.00736" title="Download PDF">pdf</a>, <a href="/format/2403.00736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Probability to Hit Every Bin with a Linear Number of Balls
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Walzer%2C+S">Stefan Walzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Assume that $2n$ balls are thrown independently and uniformly at random into
$n$ bins. We consider the unlikely event $E$ that every bin receives at least
one ball, showing that $\Pr[E] = \Theta(b^n)$ where $b \approx 0.836$. Note
that, due to correlations, $b$ is not simply the probability that any single
bin receives at least one ball. More generally, we consider the event that
throwing $\alpha n$ balls into $n$ bins results in at least $d$ balls in each
bin.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00746" title="Abstract">arXiv:2403.00746</a> (cross-list from q-fin.CP) [<a href="/pdf/2403.00746" title="Download PDF">pdf</a>, <a href="/format/2403.00746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A time-stepping deep gradient flow method for option pricing in (rough)  diffusion models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Papapantoleon%2C+A">Antonis Papapantoleon</a>, 
<a href="/search/q-fin?searchtype=author&query=Rou%2C+J">Jasper Rou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance (q-fin.CP)</span>; Machine Learning (cs.LG); Probability (math.PR); Mathematical Finance (q-fin.MF)

</div>
<p class="mathjax">We develop a novel deep learning approach for pricing European options in
diffusion models, that can efficiently handle high-dimensional problems
resulting from Markovian approximations of rough volatility models. The option
pricing partial differential equation is reformulated as an energy minimization
problem, which is approximated in a time-stepping fashion by deep artificial
neural networks. The proposed scheme respects the asymptotic behavior of option
prices for large levels of moneyness, and adheres to a priori known bounds for
option prices. The accuracy and efficiency of the proposed method is assessed
in a series of numerical examples, with particular focus in the lifted Heston
model.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00748" title="Abstract">arXiv:2403.00748</a> (cross-list from math.OC) [<a href="/pdf/2403.00748" title="Download PDF">pdf</a>, <a href="/ps/2403.00748" title="Download PostScript">ps</a>, <a href="/format/2403.00748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Primal-Dual iLQR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sousa-Pinto%2C+J">Jo&#xe3;o Sousa-Pinto</a>, 
<a href="/search/math?searchtype=author&query=Orban%2C+D">Dominique Orban</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">We introduce a new algorithm for solving unconstrained discrete-time optimal
control problems. Our method follows a direct multiple shooting approach, and
consists of applying the SQP method together with an $\ell_2$ augmented
Lagrangian primal-dual merit function. We use the LQR algorithm to efficiently
solve the primal-dual SQP problem. As our algorithm is a specialization of
NPSQP (Gill et al. 1992), it inherits its generic properties, including global
convergence, fast local convergence, and the lack of need for second order
corrections, improving on existing direct multiple shooting approaches such as
GNMS (Giftthaler et al. 2018) and FDDP (Mastalli et al. 2020).
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00750" title="Abstract">arXiv:2403.00750</a> (cross-list from math.CO) [<a href="/pdf/2403.00750" title="Download PDF">pdf</a>, <a href="/ps/2403.00750" title="Download PostScript">ps</a>, <a href="/format/2403.00750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge open packing: complexity, algorithmic aspects, and bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bre%C5%A1ar%2C+B">Bo&#x161;tjan Bre&#x161;ar</a>, 
<a href="/search/math?searchtype=author&query=Samadi%2C+B">Babak Samadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Given a graph $G$, two edges $e_{1},e_{2}\in E(G)$ are said to have a common
edge $e$ if $e$ joins an endvertex of $e_{1}$ to an endvertex of $e_{2}$. A
subset $B\subseteq E(G)$ is an edge open packing set in $G$ if no two edges of
$B$ have a common edge in $G$, and the maximum cardinality of such a set in $G$
is called the edge open packing number, $\rho_{e}^{o}(G)$, of $G$. In this
paper, we prove that the decision version of the edge open packing number is
NP-complete even when restricted to graphs with universal vertices, Eulerian
bipartite graphs, and planar graphs with maximum degree $4$, respectively. In
contrast, we present a linear-time algorithm that computes the edge open
packing number of a tree. We also resolve two problems posed in the seminal
paper [Edge open packing sets in graphs, RAIRO-Oper.\ Res.\ 56 (2022)
3765--3776]. Notably, we characterize the graphs $G$ that attain the upper
bound $\rho_e^o(G)\le |E(G)|/\delta(G)$, and provide lower and upper bounds for
the edge-deleted subgraph of a graph and establish the corresponding
realization result.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Mon,  4 Mar 24</h3>
<dl>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/0710.3901" title="Abstract">arXiv:0710.3901</a> (replaced) [<a href="/pdf/0710.3901" title="Download PDF">pdf</a>, <a href="/ps/0710.3901" title="Download PostScript">ps</a>, <a href="/format/0710.3901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A recursive linear time modular decomposition algorithm via LexBFS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Corneil%2C+D">Derek Corneil</a>, 
<a href="/search/cs?searchtype=author&query=Habib%2C+M">Michel Habib</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+C">Christophe Paul</a>, 
<a href="/search/cs?searchtype=author&query=Tedder%2C+M">Marc Tedder</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An EA of this work appeared in ICALP'08. The arXiv v2 contains an appendix with some sketches of proofs. To date, complete proofs can only be found in the PhD of M. Tedder and spread over several chapters. This is the first self-contained version. To ease the understanding, the noveI presentation enlights the combinatorial objects involved in the algorithm, which still relies on the same ideas
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1607.06444" title="Abstract">arXiv:1607.06444</a> (replaced) [<a href="/pdf/1607.06444" title="Download PDF">pdf</a>, <a href="/format/1607.06444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Complexity of Drawing Graphs on Few Lines and Few Planes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaplick%2C+S">Steven Chaplick</a>, 
<a href="/search/cs?searchtype=author&query=Fleszar%2C+K">Krzysztof Fleszar</a>, 
<a href="/search/cs?searchtype=author&query=Lipp%2C+F">Fabian Lipp</a>, 
<a href="/search/cs?searchtype=author&query=Ravsky%2C+A">Alexander Ravsky</a>, 
<a href="/search/cs?searchtype=author&query=Verbitsky%2C+O">Oleg Verbitsky</a>, 
<a href="/search/cs?searchtype=author&query=Wolff%2C+A">Alexander Wolff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preliminary version appeared in Proc. WADS 2017
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Graph Algorithms and Applications, 27(6):459-488, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1710.01837" title="Abstract">arXiv:1710.01837</a> (replaced) [<a href="/pdf/1710.01837" title="Download PDF">pdf</a>, <a href="/ps/1710.01837" title="Download PostScript">ps</a>, <a href="/format/1710.01837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Postquantum Br&#xe8;gman relative entropies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math-ph?searchtype=author&query=Kostecki%2C+R+P">Ryszard Pawe&#x142; Kostecki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v3: paper rewritten from scratch; parts of v2 about categories and resource monoids are moved to <a href="/abs/2103.07810">arXiv:2103.07810</a>, while models based on Orlicz spaces are moved to an upcoming paper; v4: further improvements; a proof of H\"{o}lder continuity of nonassociative Mazur map, and a discussion of $L_p$ spaces over order unit spaces have been added; v5: a new section with noncommutative Orlicz spaces
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Physics (math-ph)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1907.02677" title="Abstract">arXiv:1907.02677</a> (replaced) [<a href="/pdf/1907.02677" title="Download PDF">pdf</a>, <a href="/format/1907.02677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable Feature Learning in Multivariate Big Data Analysis for  Network Monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Camacho%2C+J">Jos&#xe9; Camacho</a>, 
<a href="/search/cs?searchtype=author&query=Wasielewska%2C+K">Katarzyna Wasielewska</a>, 
<a href="/search/cs?searchtype=author&query=Bro%2C+R">Rasmus Bro</a>, 
<a href="/search/cs?searchtype=author&query=Kotz%2C+D">David Kotz</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Network and Service Management, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1909.12077" title="Abstract">arXiv:1909.12077</a> (replaced) [<a href="/pdf/1909.12077" title="Download PDF">pdf</a>, <a href="/format/1909.12077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symplectic ODE-Net: Learning Hamiltonian Dynamics with Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y+D">Yaofeng Desmond Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+B">Biswadip Dey</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+A">Amit Chakraborty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a Conference Paper at ICLR 2020
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on Learning Representations (ICLR 2020);
  https://openreview.net/forum?id=ryxmb1rKDS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Computational Physics (physics.comp-ph); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2007.12315" title="Abstract">arXiv:2007.12315</a> (replaced) [<a href="/pdf/2007.12315" title="Download PDF">pdf</a>, <a href="/format/2007.12315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Robust Optimization for Imitation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brown%2C+D+S">Daniel S. Brown</a>, 
<a href="/search/cs?searchtype=author&query=Niekum%2C+S">Scott Niekum</a>, 
<a href="/search/cs?searchtype=author&query=Petrik%2C+M">Marek Petrik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In proceedings NeurIPS 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.15738" title="Abstract">arXiv:2010.15738</a> (replaced) [<a href="/pdf/2010.15738" title="Download PDF">pdf</a>, <a href="/ps/2010.15738" title="Download PostScript">ps</a>, <a href="/format/2010.15738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Agile Coach Role: Coaching for Agile Performance Impact
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stray%2C+V">Viktoria Stray</a>, 
<a href="/search/cs?searchtype=author&query=Tkalich%2C+A">Anastasiia Tkalich</a>, 
<a href="/search/cs?searchtype=author&query=Moe%2C+N+B">Nils Brede Moe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the 54th Hawaii International Conference on
  System Sciences, 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2011.10577" title="Abstract">arXiv:2011.10577</a> (replaced) [<a href="/pdf/2011.10577" title="Download PDF">pdf</a>, <a href="/format/2011.10577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep learning insights into cosmological structure formation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Lucie-Smith%2C+L">Luisa Lucie-Smith</a>, 
<a href="/search/astro-ph?searchtype=author&query=Peiris%2C+H+V">Hiranya V. Peiris</a>, 
<a href="/search/astro-ph?searchtype=author&query=Pontzen%2C+A">Andrew Pontzen</a>, 
<a href="/search/astro-ph?searchtype=author&query=Nord%2C+B">Brian Nord</a>, 
<a href="/search/astro-ph?searchtype=author&query=Thiyagalingam%2C+J">Jeyan Thiyagalingam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 10 figures. Accepted in PRD
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cosmology and Nongalactic Astrophysics (astro-ph.CO)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.01768" title="Abstract">arXiv:2106.01768</a> (replaced) [<a href="/pdf/2106.01768" title="Download PDF">pdf</a>, <a href="/ps/2106.01768" title="Download PostScript">ps</a>, <a href="/format/2106.01768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Homeostasis: Design and Implementation of a Self-Stabilizing Compiler
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nougrahiya%2C+A">Aman Nougrahiya</a>, 
<a href="/search/cs?searchtype=author&query=Nandivada%2C+V+K">V. Krishna Nandivada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in ACM TOPLAS. 58 pages, 36 figures. Patent granted in India. US Patent published. For associated code, see <a href="https://github.com/anonymousoopsla21/homeostasis">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.07319" title="Abstract">arXiv:2109.07319</a> (replaced) [<a href="/pdf/2109.07319" title="Download PDF">pdf</a>, <a href="/format/2109.07319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InceptionXML: A Lightweight Framework with Synchronized Negative  Sampling for Short Text Extreme Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kharbanda%2C+S">Siddhant Kharbanda</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+A">Atmadeep Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Palrecha%2C+A">Akash Palrecha</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+D">Devaansh Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Babbar%2C+R">Rohit Babbar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.13384" title="Abstract">arXiv:2111.13384</a> (replaced) [<a href="/pdf/2111.13384" title="Download PDF">pdf</a>, <a href="/format/2111.13384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EOLANG and $\varphi$-calculus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bugayenko%2C+Y">Yegor Bugayenko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.04539" title="Abstract">arXiv:2112.04539</a> (replaced) [<a href="/pdf/2112.04539" title="Download PDF">pdf</a>, <a href="/format/2112.04539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt-based Zero-shot Relation Extraction with Semantic Knowledge  Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+J">Jiaying Gong</a>, 
<a href="/search/cs?searchtype=author&query=Eldardiry%2C+H">Hoda Eldardiry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.06834" title="Abstract">arXiv:2202.06834</a> (replaced) [<a href="/pdf/2202.06834" title="Download PDF">pdf</a>, <a href="/format/2202.06834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory-Efficient Sequential Pattern Mining with Hybrid Tries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hosseininasab%2C+A">Amin Hosseininasab</a>, 
<a href="/search/cs?searchtype=author&query=van+Hoeve%2C+W">Willem-Jan van Hoeve</a>, 
<a href="/search/cs?searchtype=author&query=Cire%2C+A+A">Andre A. Cire</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.09393" title="Abstract">arXiv:2202.09393</a> (replaced) [<a href="/pdf/2202.09393" title="Download PDF">pdf</a>, <a href="/format/2202.09393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Decomposition Diagrams Applied beyond Shannon Entropy: A  Generalization of Hu&#x27;s Theorem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lang%2C+L">Leon Lang</a>, 
<a href="/search/cs?searchtype=author&query=Baudot%2C+P">Pierre Baudot</a>, 
<a href="/search/cs?searchtype=author&query=Quax%2C+R">Rick Quax</a>, 
<a href="/search/cs?searchtype=author&query=Forr%C3%A9%2C+P">Patrick Forr&#xe9;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 58 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.16464" title="Abstract">arXiv:2203.16464</a> (replaced) [<a href="/pdf/2203.16464" title="Download PDF">pdf</a>, <a href="/format/2203.16464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Interpretable Deep Reinforcement Learning Models via Inverse  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Sean Xie</a>, 
<a href="/search/cs?searchtype=author&query=Vosoughi%2C+S">Soroush Vosoughi</a>, 
<a href="/search/cs?searchtype=author&query=Hassanpour%2C+S">Saeed Hassanpour</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted to ICPR 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.02160" title="Abstract">arXiv:2205.02160</a> (replaced) [<a href="/pdf/2205.02160" title="Download PDF">pdf</a>, <a href="/format/2205.02160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making SGD Parameter-Free
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Carmon%2C+Y">Yair Carmon</a>, 
<a href="/search/math?searchtype=author&query=Hinder%2C+O">Oliver Hinder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.00288" title="Abstract">arXiv:2207.00288</a> (replaced) [<a href="/pdf/2207.00288" title="Download PDF">pdf</a>, <a href="/format/2207.00288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Influence-Augmented Local Simulators for Parallel MARL in  Large Networked Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suau%2C+M">Miguel Suau</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jinke He</a>, 
<a href="/search/cs?searchtype=author&query=%C3%87elikok%2C+M+M">Mustafa Mert &#xc7;elikok</a>, 
<a href="/search/cs?searchtype=author&query=Spaan%2C+M+T+J">Matthijs T. J. Spaan</a>, 
<a href="/search/cs?searchtype=author&query=Oliehoek%2C+F+A">Frans A. Oliehoek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.03378" title="Abstract">arXiv:2208.03378</a> (replaced) [<a href="/pdf/2208.03378" title="Download PDF">pdf</a>, <a href="/format/2208.03378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Rapid Exploration in Close-Proximity of an Asteroid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Negri%2C+R+B">Rodolfo Batista Negri</a>, 
<a href="/search/astro-ph?searchtype=author&query=de+Almeida+Prado%2C+A+F+B">Ant&#xf4;nio Fernando Bertachini de Almeida Prado</a>, 
<a href="/search/astro-ph?searchtype=author&query=Chagas%2C+R+A+J">Ronan Arraes Jardim Chagas</a>, 
<a href="/search/astro-ph?searchtype=author&query=de+Moraes%2C+R+V">Rodolpho Vilhena de Moraes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the AIAA's Journal of Guidance, Control, and Dynamics. DOI: soon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.04244" title="Abstract">arXiv:2209.04244</a> (replaced) [<a href="/pdf/2209.04244" title="Download PDF">pdf</a>, <a href="/ps/2209.04244" title="Download PostScript">ps</a>, <a href="/format/2209.04244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Window Expressions for Stream Data Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Praveen%2C+M">M. Praveen</a>, 
<a href="/search/cs?searchtype=author&query=Hitarth%2C+S">S. Hitarth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.00108" title="Abstract">arXiv:2210.00108</a> (replaced) [<a href="/pdf/2210.00108" title="Download PDF">pdf</a>, <a href="/format/2210.00108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ImpNet: Imperceptible and blackbox-undetectable backdoors in compiled  neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Clifford%2C+T">Tim Clifford</a>, 
<a href="/search/cs?searchtype=author&query=Shumailov%2C+I">Ilia Shumailov</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yiren Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+R">Ross Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Mullins%2C+R">Robert Mullins</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures, to be published in IEEE Secure and Trustworthy Machine Learning 2024. For website see <a href="https://ml.backdoors.uk">this https URL</a> . For source code, see <a href="https://git.sr.ht/~tim-clifford/impnet_source">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.01282" title="Abstract">arXiv:2210.01282</a> (replaced) [<a href="/pdf/2210.01282" title="Download PDF">pdf</a>, <a href="/format/2210.01282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structural Estimation of Markov Decision Processes in High-Dimensional  State Space with Finite-Time Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+S">Siliang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+M">Mingyi Hong</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+A">Alfredo Garcia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This conference version of this paper refers to "Maximum-Likelihood Inverse Reinforcement Learning with Finite-Time Guarantees" in NeurIPS 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Econometrics (econ.EM); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.07161" title="Abstract">arXiv:2210.07161</a> (replaced) [<a href="/pdf/2210.07161" title="Download PDF">pdf</a>, <a href="/ps/2210.07161" title="Download PostScript">ps</a>, <a href="/format/2210.07161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Logic of &quot;Black Box&quot; Classifier Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinghan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lorini%2C+E">Emiliano Lorini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08229" title="Abstract">arXiv:2211.08229</a> (replaced) [<a href="/pdf/2211.08229" title="Download PDF">pdf</a>, <a href="/format/2211.08229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CorruptEncoder: Data Poisoning based Backdoor Attacks to Contrastive  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinghuai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongbin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jinyuan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+N+Z">Neil Zhenqiang Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.04466" title="Abstract">arXiv:2212.04466</a> (replaced) [<a href="/pdf/2212.04466" title="Download PDF">pdf</a>, <a href="/format/2212.04466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On inclusion of time-varying source in the acoustic wave equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Javaherian%2C+A">Ashkan Javaherian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.06776" title="Abstract">arXiv:2212.06776</a> (replaced) [<a href="/pdf/2212.06776" title="Download PDF">pdf</a>, <a href="/format/2212.06776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unfolding Local Growth Rate Estimates for (Almost) Perfect Adversarial  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lorenz%2C+P">Peter Lorenz</a>, 
<a href="/search/cs?searchtype=author&query=Keuper%2C+M">Margret Keuper</a>, 
<a href="/search/cs?searchtype=author&query=Keuper%2C+J">Janis Keuper</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at VISAPP23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06662" title="Abstract">arXiv:2301.06662</a> (replaced) [<a href="/pdf/2301.06662" title="Download PDF">pdf</a>, <a href="/format/2301.06662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Learning Across Data Silos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11862" title="Abstract">arXiv:2301.11862</a> (replaced) [<a href="/pdf/2301.11862" title="Download PDF">pdf</a>, <a href="/format/2301.11862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Additive Models for Location Scale and Shape: A Framework for  Interpretable Neural Regression Beyond the Mean
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Thielmann%2C+A">Anton Thielmann</a>, 
<a href="/search/stat?searchtype=author&query=Kruse%2C+R">Ren&#xe9;-Marcel Kruse</a>, 
<a href="/search/stat?searchtype=author&query=Kneib%2C+T">Thomas Kneib</a>, 
<a href="/search/stat?searchtype=author&query=S%C3%A4fken%2C+B">Benjamin S&#xe4;fken</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 27th International Conference on Artificial Intelligence and Statistics (AISTATS) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12357" title="Abstract">arXiv:2301.12357</a> (replaced) [<a href="/pdf/2301.12357" title="Download PDF">pdf</a>, <a href="/format/2301.12357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPEED: Experimental Design for Policy Evaluation in Linear  Heteroscedastic Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Mukherjee%2C+S">Subhojyoti Mukherjee</a>, 
<a href="/search/stat?searchtype=author&query=Xie%2C+Q">Qiaomin Xie</a>, 
<a href="/search/stat?searchtype=author&query=Hanna%2C+J">Josiah Hanna</a>, 
<a href="/search/stat?searchtype=author&query=Nowak%2C+R">Robert Nowak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00389" title="Abstract">arXiv:2302.00389</a> (replaced) [<a href="/pdf/2302.00389" title="Download PDF">pdf</a>, <a href="/format/2302.00389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodality Representation Learning: A Survey on Evolution,  Pretraining and Its Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manzoor%2C+M+A">Muhammad Arslan Manzoor</a>, 
<a href="/search/cs?searchtype=author&query=Albarri%2C+S">Sarah Albarri</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+Z">Ziting Xian</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Z">Zaiqiao Meng</a>, 
<a href="/search/cs?searchtype=author&query=Nakov%2C+P">Preslav Nakov</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Shangsong Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00556" title="Abstract">arXiv:2302.00556</a> (replaced) [<a href="/pdf/2302.00556" title="Download PDF">pdf</a>, <a href="/format/2302.00556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correspondence-free online human motion retargeting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rekik%2C+R">Rim Rekik</a>, 
<a href="/search/cs?searchtype=author&query=Marsot%2C+M">Mathieu Marsot</a>, 
<a href="/search/cs?searchtype=author&query=Wuhrer%2C+S">Stefanie Wuhrer</a>, 
<a href="/search/cs?searchtype=author&query=Franco%2C+J">Jean-S&#xe9;bastien Franco</a>, 
<a href="/search/cs?searchtype=author&query=Olivier%2C+A">Anne-H&#xe9;l&#xe8;ne Olivier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in International Conference on 3D Vision (3DV), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05797" title="Abstract">arXiv:2302.05797</a> (replaced) [<a href="/pdf/2302.05797" title="Download PDF">pdf</a>, <a href="/ps/2302.05797" title="Download PostScript">ps</a>, <a href="/format/2302.05797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global Convergence Rate of Deep Equilibrium Models with General  Activations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Truong%2C+L+V">Lan V. Truong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11351" title="Abstract">arXiv:2302.11351</a> (replaced) [<a href="/pdf/2302.11351" title="Download PDF">pdf</a>, <a href="/format/2302.11351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Abrupt and spontaneous strategy switches emerge in simple regularised  neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%B6we%2C+A+T">Anika T. L&#xf6;we</a>, 
<a href="/search/cs?searchtype=author&query=Touzo%2C+L">L&#xe9;o Touzo</a>, 
<a href="/search/cs?searchtype=author&query=Muhle-Karbe%2C+P+S">Paul S. Muhle-Karbe</a>, 
<a href="/search/cs?searchtype=author&query=Saxe%2C+A+M">Andrew M. Saxe</a>, 
<a href="/search/cs?searchtype=author&query=Summerfield%2C+C">Christopher Summerfield</a>, 
<a href="/search/cs?searchtype=author&query=Schuck%2C+N+W">Nicolas W. Schuck</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14334" title="Abstract">arXiv:2302.14334</a> (replaced) [<a href="/pdf/2302.14334" title="Download PDF">pdf</a>, <a href="/format/2302.14334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design of an Adaptive Lightweight LiDAR to Decouple Robot-Camera  Geometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dingkang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+L">Lenworth Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Dantu%2C+K">Karthik Dantu</a>, 
<a href="/search/cs?searchtype=author&query=Koppal%2C+S+J">Sanjeev J. Koppal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is published in IEEE Transactions on Robotics
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Robotics, 2024.
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04878" title="Abstract">arXiv:2303.04878</a> (replaced) [<a href="/pdf/2303.04878" title="Download PDF">pdf</a>, <a href="/format/2303.04878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepGD: A Multi-Objective Black-Box Test Selection Approach for Deep  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aghababaeyan%2C+Z">Zohreh Aghababaeyan</a>, 
<a href="/search/cs?searchtype=author&query=Abdellatif%2C+M">Manel Abdellatif</a>, 
<a href="/search/cs?searchtype=author&query=Dadkhah%2C+M">Mahboubeh Dadkhah</a>, 
<a href="/search/cs?searchtype=author&query=Briand%2C+L">Lionel Briand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Performance (cs.PF); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05707" title="Abstract">arXiv:2303.05707</a> (replaced) [<a href="/pdf/2303.05707" title="Download PDF">pdf</a>, <a href="/format/2303.05707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MuLTI: Efficient Video-and-Language Understanding with Text-Guided  MultiWay-Sampler and Multiple Choice Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiaqi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yunkuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Mengli Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xing Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07257" title="Abstract">arXiv:2303.07257</a> (replaced) [<a href="/pdf/2303.07257" title="Download PDF">pdf</a>, <a href="/format/2303.07257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Audio-Visual BatVision Dataset for Research on Sight and Sound
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brunetto%2C+A">Amandine Brunetto</a>, 
<a href="/search/cs?searchtype=author&query=Hornauer%2C+S">Sascha Hornauer</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S+X">Stella X. Yu</a>, 
<a href="/search/cs?searchtype=author&query=Moutarde%2C+F">Fabien Moutarde</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page <a href="https://amandinebtto.github.io/Batvision-Dataset/">this https URL</a> This version contains camera ready paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07539" title="Abstract">arXiv:2303.07539</a> (replaced) [<a href="/pdf/2303.07539" title="Download PDF">pdf</a>, <a href="/ps/2303.07539" title="Download PostScript">ps</a>, <a href="/format/2303.07539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HCI Papers Cite HCI Papers, Increasingly So
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X+%27">Xiang &#x27;Anthony&#x27; Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08774" title="Abstract">arXiv:2303.08774</a> (replaced) [<a href="/pdf/2303.08774" title="Download PDF">pdf</a>, <a href="/format/2303.08774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT-4 Technical Report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=OpenAI">OpenAI</a>: 
<a href="/search/cs?searchtype=author&query=Achiam%2C+J">Josh Achiam</a>, 
<a href="/search/cs?searchtype=author&query=Adler%2C+S">Steven Adler</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+S">Sandhini Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+L">Lama Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Akkaya%2C+I">Ilge Akkaya</a>, 
<a href="/search/cs?searchtype=author&query=Aleman%2C+F+L">Florencia Leoni Aleman</a>, 
<a href="/search/cs?searchtype=author&query=Almeida%2C+D">Diogo Almeida</a>, 
<a href="/search/cs?searchtype=author&query=Altenschmidt%2C+J">Janko Altenschmidt</a>, 
<a href="/search/cs?searchtype=author&query=Altman%2C+S">Sam Altman</a>, 
<a href="/search/cs?searchtype=author&query=Anadkat%2C+S">Shyamal Anadkat</a>, 
<a href="/search/cs?searchtype=author&query=Avila%2C+R">Red Avila</a>, 
<a href="/search/cs?searchtype=author&query=Babuschkin%2C+I">Igor Babuschkin</a>, 
<a href="/search/cs?searchtype=author&query=Balaji%2C+S">Suchir Balaji</a>, 
<a href="/search/cs?searchtype=author&query=Balcom%2C+V">Valerie Balcom</a>, 
<a href="/search/cs?searchtype=author&query=Baltescu%2C+P">Paul Baltescu</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+H">Haiming Bao</a>, 
<a href="/search/cs?searchtype=author&query=Bavarian%2C+M">Mohammad Bavarian</a>, 
<a href="/search/cs?searchtype=author&query=Belgum%2C+J">Jeff Belgum</a>, 
<a href="/search/cs?searchtype=author&query=Bello%2C+I">Irwan Bello</a>, 
<a href="/search/cs?searchtype=author&query=Berdine%2C+J">Jake Berdine</a>, 
<a href="/search/cs?searchtype=author&query=Bernadett-Shapiro%2C+G">Gabriel Bernadett-Shapiro</a>, 
<a href="/search/cs?searchtype=author&query=Berner%2C+C">Christopher Berner</a>, 
<a href="/search/cs?searchtype=author&query=Bogdonoff%2C+L">Lenny Bogdonoff</a>, 
<a href="/search/cs?searchtype=author&query=Boiko%2C+O">Oleg Boiko</a>, 
<a href="/search/cs?searchtype=author&query=Boyd%2C+M">Madelaine Boyd</a>, 
<a href="/search/cs?searchtype=author&query=Brakman%2C+A">Anna-Luisa Brakman</a>, 
<a href="/search/cs?searchtype=author&query=Brockman%2C+G">Greg Brockman</a>, 
<a href="/search/cs?searchtype=author&query=Brooks%2C+T">Tim Brooks</a>, 
<a href="/search/cs?searchtype=author&query=Brundage%2C+M">Miles Brundage</a>, 
<a href="/search/cs?searchtype=author&query=Button%2C+K">Kevin Button</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+T">Trevor Cai</a>, 
<a href="/search/cs?searchtype=author&query=Campbell%2C+R">Rosie Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Cann%2C+A">Andrew Cann</a>, 
<a href="/search/cs?searchtype=author&query=Carey%2C+B">Brittany Carey</a>, 
<a href="/search/cs?searchtype=author&query=Carlson%2C+C">Chelsea Carlson</a>, 
<a href="/search/cs?searchtype=author&query=Carmichael%2C+R">Rory Carmichael</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+B">Brooke Chan</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Che Chang</a>, 
<a href="/search/cs?searchtype=author&query=Chantzis%2C+F">Fotis Chantzis</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Derek Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sully Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruby Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jason Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mark Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chess%2C+B">Ben Chess</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+C">Chester Cho</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+C">Casey Chu</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+H+W">Hyung Won Chung</a>, 
<a href="/search/cs?searchtype=author&query=Cummings%2C+D">Dave Cummings</a>, 
<a href="/search/cs?searchtype=author&query=Currier%2C+J">Jeremiah Currier</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yunxing Dai</a>, 
<a href="/search/cs?searchtype=author&query=Decareaux%2C+C">Cory Decareaux</a>, 
<a href="/search/cs?searchtype=author&query=Degry%2C+T">Thomas Degry</a>, 
<a href="/search/cs?searchtype=author&query=Deutsch%2C+N">Noah Deutsch</a>,  et al. (226 additional authors not shown)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 100 pages; updated authors list; fixed author names and added citation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10087" title="Abstract">arXiv:2303.10087</a> (replaced) [<a href="/pdf/2303.10087" title="Download PDF">pdf</a>, <a href="/format/2303.10087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Refinement for Absolute Pose Regression with Feature Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bhalgat%2C+Y">Yash Bhalgat</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiawang Bian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kejie Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zirui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Prisacariu%2C+V+A">Victor Adrian Prisacariu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper Accepted by CVPR 2024. Project Page: <a href="http://nefes.active.vision.">this http URL</a> Code will be released at <a href="https://github.com/ActiveVisionLab/NeFeS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16521" title="Abstract">arXiv:2303.16521</a> (replaced) [<a href="/pdf/2303.16521" title="Download PDF">pdf</a>, <a href="/format/2303.16521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hard Regularization to Prevent Deep Online Clustering Collapse without  Data Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahon%2C+L">Louis Mahon</a>, 
<a href="/search/cs?searchtype=author&query=Lukasiewicz%2C+T">Thomas Lukasiewicz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16548" title="Abstract">arXiv:2303.16548</a> (replaced) [<a href="/pdf/2303.16548" title="Download PDF">pdf</a>, <a href="/ps/2303.16548" title="Download PostScript">ps</a>, <a href="/format/2303.16548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Policy Gradient Methods for Discrete Time Linear Quadratic Regulator  With Random Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+D">Deyue Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 57 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17550" title="Abstract">arXiv:2303.17550</a> (replaced) [<a href="/pdf/2303.17550" title="Download PDF">pdf</a>, <a href="/format/2303.17550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAE-Talker: High Fidelity Speech-Driven Talking Face Generation with  Diffusion Autoencoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+C">Chenpeng Du</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACM Multimedia 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.18242" title="Abstract">arXiv:2303.18242</a> (replaced) [<a href="/pdf/2303.18242" title="Download PDF">pdf</a>, <a href="/format/2303.18242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $\infty$-Diff: Infinite Resolution Diffusion with Subsampled Mollified  States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bond-Taylor%2C+S">Sam Bond-Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Willcocks%2C+C+G">Chris G. Willcocks</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01099" title="Abstract">arXiv:2304.01099</a> (replaced) [<a href="/pdf/2304.01099" title="Download PDF">pdf</a>, <a href="/format/2304.01099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dichotomies for Maximum Matching Cut: $H$-Freeness, Bounded Diameter,  Bounded Radius
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lucke%2C+F">Felicia Lucke</a>, 
<a href="/search/math?searchtype=author&query=Paulusma%2C+D">Dani&#xeb;l Paulusma</a>, 
<a href="/search/math?searchtype=author&query=Ries%2C+B">Bernard Ries</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2207.07095">arXiv:2207.07095</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC); Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02780" title="Abstract">arXiv:2304.02780</a> (replaced) [<a href="/pdf/2304.02780" title="Download PDF">pdf</a>, <a href="/ps/2304.02780" title="Download PostScript">ps</a>, <a href="/format/2304.02780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Transformer-Based Deep Learning Approach for Fairly Predicting  Post-Liver Transplant Risk Factors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Can Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiaoqian Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Journal of Biomedical Informatics
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J Biomed Inform. 2024 Jan;149:104545
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03870" title="Abstract">arXiv:2304.03870</a> (replaced) [<a href="/pdf/2304.03870" title="Download PDF">pdf</a>, <a href="/format/2304.03870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASPEST: Bridging the Gap Between Active Learning and Selective  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiefeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J">Jinsung Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Ebrahimi%2C+S">Sayna Ebrahimi</a>, 
<a href="/search/cs?searchtype=author&query=Arik%2C+S">Sercan Arik</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+S">Somesh Jha</a>, 
<a href="/search/cs?searchtype=author&query=Pfister%2C+T">Tomas Pfister</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09914" title="Abstract">arXiv:2304.09914</a> (replaced) [<a href="/pdf/2304.09914" title="Download PDF">pdf</a>, <a href="/format/2304.09914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Face of Populism: Examining Differences in Facial Emotional  Expressions of Political Leaders Using Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Major%2C+S">Sara Major</a>, 
<a href="/search/cs?searchtype=author&query=Toma%C5%A1evi%C4%87%2C+A">Aleksandar Toma&#x161;evi&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Version 3.0: Improved discussion related to the limitations of the study
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Social and Information Networks (cs.SI); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00188" title="Abstract">arXiv:2305.00188</a> (replaced) [<a href="/pdf/2305.00188" title="Download PDF">pdf</a>, <a href="/format/2305.00188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Characterizations and Efficient Local Search for General Integer  Linear Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lin%2C+P">Peng Lin</a>, 
<a href="/search/math?searchtype=author&query=Cai%2C+S">Shaowei Cai</a>, 
<a href="/search/math?searchtype=author&query=Zou%2C+M">Mengchuan Zou</a>, 
<a href="/search/math?searchtype=author&query=Lin%2C+J">Jinkun Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02337" title="Abstract">arXiv:2305.02337</a> (replaced) [<a href="/pdf/2305.02337" title="Download PDF">pdf</a>, <a href="/format/2305.02337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Hamiltonian Simulation with Decision Diagrams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Sander%2C+A">Aaron Sander</a>, 
<a href="/search/quant-ph?searchtype=author&query=Burgholzer%2C+L">Lukas Burgholzer</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wille%2C+R">Robert Wille</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Conference on Quantum Computing and
  Engineering (QCE)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Other Condensed Matter (cond-mat.other); Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04447" title="Abstract">arXiv:2305.04447</a> (replaced) [<a href="/pdf/2305.04447" title="Download PDF">pdf</a>, <a href="/format/2305.04447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Steerer: Novel Steering Vector Synthesis with a Causal Neural  Field over Frequency and Source Positions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Di+Carlo%2C+D">Diego Di Carlo</a>, 
<a href="/search/eess?searchtype=author&query=Nugraha%2C+A+A">Aditya Arie Nugraha</a>, 
<a href="/search/eess?searchtype=author&query=Fontaine%2C+M">Mathieu Fontaine</a>, 
<a href="/search/eess?searchtype=author&query=Fontaine%2C+M">Mathieu Fontaine</a>, 
<a href="/search/eess?searchtype=author&query=Yoshii%2C+K">Kazuyoshi Yoshii</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera ready version for HSCMA 24 at ICASSP 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11897" title="Abstract">arXiv:2305.11897</a> (replaced) [<a href="/pdf/2305.11897" title="Download PDF">pdf</a>, <a href="/ps/2305.11897" title="Download PostScript">ps</a>, <a href="/format/2305.11897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Critical Appraisal of Artificial Intelligence-Mediated Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tafazoli%2C+D">Dara Tafazoli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14779" title="Abstract">arXiv:2305.14779</a> (replaced) [<a href="/pdf/2305.14779" title="Download PDF">pdf</a>, <a href="/format/2305.14779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alt-Text with Context: Improving Accessibility for Images on Twitter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srivatsan%2C+N">Nikita Srivatsan</a>, 
<a href="/search/cs?searchtype=author&query=Samaniego%2C+S">Sofia Samaniego</a>, 
<a href="/search/cs?searchtype=author&query=Florez%2C+O">Omar Florez</a>, 
<a href="/search/cs?searchtype=author&query=Berg-Kirkpatrick%2C+T">Taylor Berg-Kirkpatrick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14916" title="Abstract">arXiv:2305.14916</a> (replaced) [<a href="/pdf/2305.14916" title="Download PDF">pdf</a>, <a href="/format/2305.14916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tuning-Free Maximum Likelihood Training of Latent Variable Models via  Coin Betting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sharrock%2C+L">Louis Sharrock</a>, 
<a href="/search/stat?searchtype=author&query=Dodd%2C+D">Daniel Dodd</a>, 
<a href="/search/stat?searchtype=author&query=Nemeth%2C+C">Christopher Nemeth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15022" title="Abstract">arXiv:2305.15022</a> (replaced) [<a href="/pdf/2305.15022" title="Download PDF">pdf</a>, <a href="/format/2305.15022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical clustering with dot products recovers hidden tree structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Gray%2C+A">Annie Gray</a>, 
<a href="/search/stat?searchtype=author&query=Modell%2C+A">Alexander Modell</a>, 
<a href="/search/stat?searchtype=author&query=Rubin-Delanchy%2C+P">Patrick Rubin-Delanchy</a>, 
<a href="/search/stat?searchtype=author&query=Whiteley%2C+N">Nick Whiteley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18502" title="Abstract">arXiv:2305.18502</a> (replaced) [<a href="/pdf/2305.18502" title="Download PDF">pdf</a>, <a href="/format/2305.18502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Escaping mediocrity: how two-layer networks learn hard generalized  linear models with SGD
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Arnaboldi%2C+L">Luca Arnaboldi</a>, 
<a href="/search/stat?searchtype=author&query=Krzakala%2C+F">Florent Krzakala</a>, 
<a href="/search/stat?searchtype=author&query=Loureiro%2C+B">Bruno Loureiro</a>, 
<a href="/search/stat?searchtype=author&query=Stephan%2C+L">Ludovic Stephan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19738" title="Abstract">arXiv:2305.19738</a> (replaced) [<a href="/pdf/2305.19738" title="Download PDF">pdf</a>, <a href="/format/2305.19738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bures-Wasserstein Means of Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Haasler%2C+I">Isabel Haasler</a>, 
<a href="/search/stat?searchtype=author&query=Frossard%2C+P">Pascal Frossard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00497" title="Abstract">arXiv:2306.00497</a> (replaced) [<a href="/pdf/2306.00497" title="Download PDF">pdf</a>, <a href="/format/2306.00497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Risks of Recourse in Binary Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fokkema%2C+H">Hidde Fokkema</a>, 
<a href="/search/cs?searchtype=author&query=Garreau%2C+D">Damien Garreau</a>, 
<a href="/search/cs?searchtype=author&query=van+Erven%2C+T">Tim van Erven</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 8 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00919" title="Abstract">arXiv:2306.00919</a> (replaced) [<a href="/pdf/2306.00919" title="Download PDF">pdf</a>, <a href="/format/2306.00919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning About Social Context from Smartphone Data: Generalization  Across Countries and Daily Life Moments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mader%2C+A+R">Aurel Ruben Mader</a>, 
<a href="/search/cs?searchtype=author&query=Meegahapola%2C+L">Lakmal Meegahapola</a>, 
<a href="/search/cs?searchtype=author&query=Gatica-Perez%2C+D">Daniel Gatica-Perez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ACM CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01334" title="Abstract">arXiv:2306.01334</a> (replaced) [<a href="/pdf/2306.01334" title="Download PDF">pdf</a>, <a href="/format/2306.01334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Domain Generalization: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Ying Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+R">Rongfei Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Donta%2C+P+K">Praveen Kumar Donta</a>, 
<a href="/search/cs?searchtype=author&query=Murturi%2C+I">Ilir Murturi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Min Huang</a>, 
<a href="/search/cs?searchtype=author&query=Dustdar%2C+S">Schahram Dustdar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02412" title="Abstract">arXiv:2306.02412</a> (replaced) [<a href="/pdf/2306.02412" title="Download PDF">pdf</a>, <a href="/ps/2306.02412" title="Download PostScript">ps</a>, <a href="/format/2306.02412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalised Br&#xe8;gman relative entropies: a brief introduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math-ph?searchtype=author&query=Kostecki%2C+R+P">Ryszard Pawe&#x142; Kostecki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/1710.01837">arXiv:1710.01837</a> (author's note: this overlap will be removed in the upcoming v5 of <a href="/abs/1710.01837">arXiv:1710.01837</a> and the upcoming v4 of this paper); v3: minor change (grant numbers)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Physics (math-ph)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03303" title="Abstract">arXiv:2306.03303</a> (replaced) [<a href="/pdf/2306.03303" title="Download PDF">pdf</a>, <a href="/format/2306.03303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global universal approximation of functional input maps on weighted  spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cuchiero%2C+C">Christa Cuchiero</a>, 
<a href="/search/stat?searchtype=author&query=Schmocker%2C+P">Philipp Schmocker</a>, 
<a href="/search/stat?searchtype=author&query=Teichmann%2C+J">Josef Teichmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 60 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Functional Analysis (math.FA); Probability (math.PR); Mathematical Finance (q-fin.MF)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06027" title="Abstract">arXiv:2306.06027</a> (replaced) [<a href="/pdf/2306.06027" title="Download PDF">pdf</a>, <a href="/format/2306.06027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VarSaw: Application-tailored Measurement Error Mitigation for  Variational Quantum Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Dangwal%2C+S">Siddharth Dangwal</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ravi%2C+G+S">Gokul Subramanian Ravi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Das%2C+P">Poulami Das</a>, 
<a href="/search/quant-ph?searchtype=author&query=Smith%2C+K+N">Kaitlin N. Smith</a>, 
<a href="/search/quant-ph?searchtype=author&query=Baker%2C+J+M">Jonathan M. Baker</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chong%2C+F+T">Frederic T. Chong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears at the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS) 2024. First two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Hardware Architecture (cs.AR); Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06112" title="Abstract">arXiv:2306.06112</a> (replaced) [<a href="/pdf/2306.06112" title="Download PDF">pdf</a>, <a href="/format/2306.06112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ModelObfuscator: Obfuscating Model Information to Protect Deployed  ML-based Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mingyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Grundy%2C+J">John Grundy</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chunyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published In Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA23)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the 32nd ACM SIGSOFT International Symposium on
  Software Testing and Analysis (ISSTA 2023), 2023, 1005-1017
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07669" title="Abstract">arXiv:2306.07669</a> (replaced) [<a href="/pdf/2306.07669" title="Download PDF">pdf</a>, <a href="/format/2306.07669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rate-Splitting with Hybrid Messages: DoF Analysis of the Two-User MIMO  Broadcast Channel with Imperfect CSIT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yufan Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Gaojie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+B">Bojie Lv</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+P">Pei Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, double column
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08158" title="Abstract">arXiv:2306.08158</a> (replaced) [<a href="/pdf/2306.08158" title="Download PDF">pdf</a>, <a href="/format/2306.08158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sociodemographic Bias in Language Models: A Survey and Forward Path
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+V">Vipul Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Venkit%2C+P+N">Pranav Narayanan Venkit</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+S">Shomir Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Passonneau%2C+R+J">Rebecca J. Passonneau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 3 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08173" title="Abstract">arXiv:2306.08173</a> (replaced) [<a href="/pdf/2306.08173" title="Download PDF">pdf</a>, <a href="/format/2306.08173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safeguarding Data in Multimodal AI: A Differentially Private Approach to  CLIP Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+A">Alyssa Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peihan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Nakada%2C+R">Ryumei Nakada</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Linjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wanrong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Information Theory (cs.IT); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09547" title="Abstract">arXiv:2306.09547</a> (replaced) [<a href="/pdf/2306.09547" title="Download PDF">pdf</a>, <a href="/format/2306.09547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training generative models from privatized data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reshetova%2C+D">Daria Reshetova</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei-Ning Chen</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96zg%C3%BCr%2C+A">Ayfer &#xd6;zg&#xfc;r</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09731" title="Abstract">arXiv:2306.09731</a> (replaced) [<a href="/pdf/2306.09731" title="Download PDF">pdf</a>, <a href="/format/2306.09731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical study of the Serre-Green-Naghdi equations in 2D
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gavrilyuk%2C+S">S. Gavrilyuk</a>, 
<a href="/search/math?searchtype=author&query=Klein%2C+C">C. Klein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Minor changes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10125" title="Abstract">arXiv:2306.10125</a> (replaced) [<a href="/pdf/2306.10125" title="Download PDF">pdf</a>, <a href="/format/2306.10125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress,  and Prospects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kexin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Q">Qingsong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoli Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+R">Rongyao Cai</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Ming Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">James Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuxuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+G">Guansong Pang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dongjin Song</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 200+ references. The first work to comprehensively and systematically summarize self-supervised learning for time series analysis (SSL4TS). The GitHub repository is <a href="https://github.com/qingsongedu/Awesome-SSL4TS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11172" title="Abstract">arXiv:2306.11172</a> (replaced) [<a href="/pdf/2306.11172" title="Download PDF">pdf</a>, <a href="/format/2306.11172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-based Auto-encoder for Time-offset Faster-than-Nyquist  Downlink NOMA with Timing Errors and Imperfect CSI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Aboutaleb%2C+A">Ahmed Aboutaleb</a>, 
<a href="/search/eess?searchtype=author&query=Torabi%2C+M">Mohammad Torabi</a>, 
<a href="/search/eess?searchtype=author&query=Belzer%2C+B">Benjamin Belzer</a>, 
<a href="/search/eess?searchtype=author&query=Sivakumar%2C+K">Krishnamoorthy Sivakumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16314" title="Abstract">arXiv:2306.16314</a> (replaced) [<a href="/pdf/2306.16314" title="Download PDF">pdf</a>, <a href="/ps/2306.16314" title="Download PostScript">ps</a>, <a href="/format/2306.16314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Summation-by-parts operators for general function spaces: The second  derivative
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Glaubitz%2C+J">Jan Glaubitz</a>, 
<a href="/search/math?searchtype=author&query=Klein%2C+S">Simon-Christian Klein</a>, 
<a href="/search/math?searchtype=author&query=Nordstr%C3%B6m%2C+J">Jan Nordstr&#xf6;m</a>, 
<a href="/search/math?searchtype=author&query=%C3%96ffner%2C+P">Philipp &#xd6;ffner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17366" title="Abstract">arXiv:2306.17366</a> (replaced) [<a href="/pdf/2306.17366" title="Download PDF">pdf</a>, <a href="/format/2306.17366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $&#x3bb;$-models: Effective Decision-Aware Reinforcement Learning with  Latent Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Voelcker%2C+C+A">Claas A Voelcker</a>, 
<a href="/search/cs?searchtype=author&query=Ahmadian%2C+A">Arash Ahmadian</a>, 
<a href="/search/cs?searchtype=author&query=Abachi%2C+R">Romina Abachi</a>, 
<a href="/search/cs?searchtype=author&query=Gilitschenski%2C+I">Igor Gilitschenski</a>, 
<a href="/search/cs?searchtype=author&query=Farahmand%2C+A">Amir-massoud Farahmand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03742" title="Abstract">arXiv:2307.03742</a> (replaced) [<a href="/pdf/2307.03742" title="Download PDF">pdf</a>, <a href="/ps/2307.03742" title="Download PostScript">ps</a>, <a href="/format/2307.03742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine error bounds for approximate asymmetric saddle point problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ruas%2C+V">Vitoriano Ruas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Version V2 of the article incorporates several modifications, including its title, mostly aimed at clarifying its contributions. Relevant complementary material on the topic is supplied in new Section 5. A conclusion section and 7 new references are provided. Keywords: Asymmetric saddle-point problem; Error bounds; Inf-sup conditions; Mixed finite elements; Stability constants
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04652" title="Abstract">arXiv:2307.04652</a> (replaced) [<a href="/pdf/2307.04652" title="Download PDF">pdf</a>, <a href="/ps/2307.04652" title="Download PostScript">ps</a>, <a href="/format/2307.04652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Winding number and circular 4-coloring of signed graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gujgiczer%2C+A">Anna Gujgiczer</a>, 
<a href="/search/math?searchtype=author&query=Naserasr%2C+R">Reza Naserasr</a>, 
<a href="/search/math?searchtype=author&query=S%2C+R">Rohini S</a>, 
<a href="/search/math?searchtype=author&query=Taruni%2C+S">S Taruni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07884" title="Abstract">arXiv:2307.07884</a> (replaced) [<a href="/pdf/2307.07884" title="Download PDF">pdf</a>, <a href="/format/2307.07884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preconditioning techniques for generalized Sylvester matrix equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Voet%2C+Y">Yannis Voet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 3 figures, 2 tables. Submitted manuscript
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01839" title="Abstract">arXiv:2308.01839</a> (replaced) [<a href="/pdf/2308.01839" title="Download PDF">pdf</a>, <a href="/format/2308.01839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is your data alignable? Principled and interpretable alignability  testing and integration of single-cell data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Ma%2C+R">Rong Ma</a>, 
<a href="/search/q-bio?searchtype=author&query=Sun%2C+E+D">Eric D. Sun</a>, 
<a href="/search/q-bio?searchtype=author&query=Donoho%2C+D">David Donoho</a>, 
<a href="/search/q-bio?searchtype=author&query=Zou%2C+J">James Zou</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the National Academy of Sciences, 2024, 121(10)
  e2313719121
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Computer Vision and Pattern Recognition (cs.CV); Genomics (q-bio.GN); Applications (stat.AP); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02747" title="Abstract">arXiv:2308.02747</a> (replaced) [<a href="/pdf/2308.02747" title="Download PDF">pdf</a>, <a href="/format/2308.02747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SureFED: Robust Federated Learning via Uncertainty-Aware Inward and  Outward Inspection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heydaribeni%2C+N">Nasimeh Heydaribeni</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruisi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Javidi%2C+T">Tara Javidi</a>, 
<a href="/search/cs?searchtype=author&query=Nita-Rotaru%2C+C">Cristina Nita-Rotaru</a>, 
<a href="/search/cs?searchtype=author&query=Koushanfar%2C+F">Farinaz Koushanfar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02918" title="Abstract">arXiv:2308.02918</a> (replaced) [<a href="/pdf/2308.02918" title="Download PDF">pdf</a>, <a href="/format/2308.02918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral Ranking Inferences based on General Multiway Comparisons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Fan%2C+J">Jianqing Fan</a>, 
<a href="/search/stat?searchtype=author&query=Lou%2C+Z">Zhipeng Lou</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+W">Weichen Wang</a>, 
<a href="/search/stat?searchtype=author&query=Yu%2C+M">Mengxin Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 62 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04455" title="Abstract">arXiv:2308.04455</a> (replaced) [<a href="/pdf/2308.04455" title="Download PDF">pdf</a>, <a href="/format/2308.04455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anonymizing Speech: Evaluating and Designing Speaker Anonymization  Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Champion%2C+P">Pierre Champion</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD Thesis Pierre Champion | Universit\'e de Lorraine - INRIA Nancy | for associated source code, see <a href="https://github.com/deep-privacy/SA-toolkit">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04466" title="Abstract">arXiv:2308.04466</a> (replaced) [<a href="/pdf/2308.04466" title="Download PDF">pdf</a>, <a href="/format/2308.04466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backdoor Federated Learning by Poisoning Backdoor-Critical Layers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+H">Haomin Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+M">Mingxian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+Y">Yang Hua</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jian Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xu Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICLR'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05576" title="Abstract">arXiv:2308.05576</a> (replaced) [<a href="/pdf/2308.05576" title="Download PDF">pdf</a>, <a href="/format/2308.05576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do Language Models&#x27; Words Refer?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mandelkern%2C+M">Matthew Mandelkern</a>, 
<a href="/search/cs?searchtype=author&query=Linzen%2C+T">Tal Linzen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06250" title="Abstract">arXiv:2308.06250</a> (replaced) [<a href="/pdf/2308.06250" title="Download PDF">pdf</a>, <a href="/format/2308.06250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Big AI Models for 6G Wireless Networks: Opportunities, Challenges, and  Research Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zirui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhaohui Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06960" title="Abstract">arXiv:2308.06960</a> (replaced) [<a href="/pdf/2308.06960" title="Download PDF">pdf</a>, <a href="/format/2308.06960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Search to Fine-tune Pre-trained Graph Neural Networks for Graph-level  Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhili Wang</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+S">Shimin Di</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaofang Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10261" title="Abstract">arXiv:2308.10261</a> (replaced) [<a href="/pdf/2308.10261" title="Download PDF">pdf</a>, <a href="/format/2308.10261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Good Are Large Language Models at Out-of-Distribution Detection?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+L">Liming Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zexin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yujie Feng</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+L">Lei Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiao-Ming Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11971" title="Abstract">arXiv:2308.11971</a> (replaced) [<a href="/pdf/2308.11971" title="Download PDF">pdf</a>, <a href="/format/2308.11971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EVE: Efficient Vision-Language Pre-training with Masked Prediction and  Modality-Aware MoE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Longteng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jia Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+S">Shuai Shao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zehuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongyu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01213" title="Abstract">arXiv:2309.01213</a> (replaced) [<a href="/pdf/2309.01213" title="Download PDF">pdf</a>, <a href="/format/2309.01213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit regularization of deep residual networks towards neural ODEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Marion%2C+P">Pierre Marion</a>, 
<a href="/search/stat?searchtype=author&query=Wu%2C+Y">Yu-Han Wu</a>, 
<a href="/search/stat?searchtype=author&query=Sander%2C+M+E">Michael E. Sander</a>, 
<a href="/search/stat?searchtype=author&query=Biau%2C+G">G&#xe9;rard Biau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024 (spotlight). 40 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08464" title="Abstract">arXiv:2309.08464</a> (replaced) [<a href="/pdf/2309.08464" title="Download PDF">pdf</a>, <a href="/ps/2309.08464" title="Download PostScript">ps</a>, <a href="/format/2309.08464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Average Consensus with Improved Accuracy-Privacy  Trade-off
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+W">Weijia Liu</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+F">Fanghong Guo</a>, 
<a href="/search/eess?searchtype=author&query=Qiao%2C+Z">Zixin Qiao</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Z">Zhengguang Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09902" title="Abstract">arXiv:2309.09902</a> (replaced) [<a href="/pdf/2309.09902" title="Download PDF">pdf</a>, <a href="/format/2309.09902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speaker attribution in German parliamentary debates with QLoRA-adapted  large language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bornheim%2C+T">Tobias Bornheim</a>, 
<a href="/search/cs?searchtype=author&query=Grieger%2C+N">Niklas Grieger</a>, 
<a href="/search/cs?searchtype=author&query=Blaneck%2C+P+G">Patrick Gustav Blaneck</a>, 
<a href="/search/cs?searchtype=author&query=Bialonski%2C+S">Stephan Bialonski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures; peer-reviewed and published in the Journal for Language Technology and Computational Linguistics, available at <a href="https://jlcl.org/article/view/244">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal for Language Technology and Computational Linguistics, 37,
  1-13 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10225" title="Abstract">arXiv:2309.10225</a> (replaced) [<a href="/pdf/2309.10225" title="Download PDF">pdf</a>, <a href="/format/2309.10225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VPRTempo: A Fast Temporally Encoded Spiking Neural Network for Visual  Place Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hines%2C+A+D">Adam D. Hines</a>, 
<a href="/search/cs?searchtype=author&query=Stratton%2C+P+G">Peter G. Stratton</a>, 
<a href="/search/cs?searchtype=author&query=Milford%2C+M">Michael Milford</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+T">Tobias Fischer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, accepted to the IEEE International Conference on Robotics and Automation (ICRA) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10726" title="Abstract">arXiv:2309.10726</a> (replaced) [<a href="/pdf/2309.10726" title="Download PDF">pdf</a>, <a href="/format/2309.10726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-Shot Panoptic Segmentation With Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=K%C3%A4ppeler%2C+M">Markus K&#xe4;ppeler</a>, 
<a href="/search/cs?searchtype=author&query=Petek%2C+K">K&#xfc;rsat Petek</a>, 
<a href="/search/cs?searchtype=author&query=V%C3%B6disch%2C+N">Niclas V&#xf6;disch</a>, 
<a href="/search/cs?searchtype=author&query=Burgard%2C+W">Wolfram Burgard</a>, 
<a href="/search/cs?searchtype=author&query=Valada%2C+A">Abhinav Valada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for "IEEE International Conference on Robotics and Automation (ICRA) 2024"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11038" title="Abstract">arXiv:2309.11038</a> (replaced) [<a href="/pdf/2309.11038" title="Download PDF">pdf</a>, <a href="/format/2309.11038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CaveSeg: Deep Semantic Segmentation and Scene Parsing for Autonomous  Underwater Cave Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdullah%2C+A">A. Abdullah</a>, 
<a href="/search/cs?searchtype=author&query=Barua%2C+T">T. Barua</a>, 
<a href="/search/cs?searchtype=author&query=Tibbetts%2C+R">R. Tibbetts</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Z. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+J">M. J. Islam</a>, 
<a href="/search/cs?searchtype=author&query=Rekleitis%2C+I">I. Rekleitis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICRA 2024. 10 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11040" title="Abstract">arXiv:2309.11040</a> (replaced) [<a href="/pdf/2309.11040" title="Download PDF">pdf</a>, <a href="/format/2309.11040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stein Variational Guided Model Predictive Path Integral Control:  Proposal and Experiments with Fast Maneuvering Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Honda%2C+K">Kohei Honda</a>, 
<a href="/search/cs?searchtype=author&query=Akai%2C+N">Naoki Akai</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+K">Kosuke Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Aoki%2C+M">Mizuho Aoki</a>, 
<a href="/search/cs?searchtype=author&query=Hosogaya%2C+H">Hirotaka Hosogaya</a>, 
<a href="/search/cs?searchtype=author&query=Okuda%2C+H">Hiroyuki Okuda</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+T">Tatsuya Suzuki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14150" title="Abstract">arXiv:2309.14150</a> (replaced) [<a href="/pdf/2309.14150" title="Download PDF">pdf</a>, <a href="/format/2309.14150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learned Contextual LiDAR Informed Visual Search in Unseen Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+R">Ryan Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Morgenstein%2C+K">Kyle Morgenstein</a>, 
<a href="/search/cs?searchtype=author&query=Ortega%2C+S">Steven Ortega</a>, 
<a href="/search/cs?searchtype=author&query=Sentis%2C+L">Luis Sentis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages + references. 6 figures. 1 algorithm. 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16264" title="Abstract">arXiv:2309.16264</a> (replaced) [<a href="/pdf/2309.16264" title="Download PDF">pdf</a>, <a href="/format/2309.16264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAMMA: Generalizable Articulation Modeling and Manipulation for  Articulated Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qiaojun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junbo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenhai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+C">Ce Hao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Liu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+L">Lin Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16739" title="Abstract">arXiv:2309.16739</a> (replaced) [<a href="/pdf/2309.16739" title="Download PDF">pdf</a>, <a href="/format/2309.16739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pushing Large Language Models to the 6G Edge: Vision, Challenges, and  Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+G">Guanqiao Qu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qiyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xianhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaibin Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17388" title="Abstract">arXiv:2309.17388</a> (replaced) [<a href="/pdf/2309.17388" title="Download PDF">pdf</a>, <a href="/format/2309.17388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tree Cross Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+L">Leo Feng</a>, 
<a href="/search/cs?searchtype=author&query=Tung%2C+F">Frederick Tung</a>, 
<a href="/search/cs?searchtype=author&query=Hajimirsadeghi%2C+H">Hossein Hajimirsadeghi</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+M+O">Mohamed Osama Ahmed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00290" title="Abstract">arXiv:2310.00290</a> (replaced) [<a href="/pdf/2310.00290" title="Download PDF">pdf</a>, <a href="/ps/2310.00290" title="Download PostScript">ps</a>, <a href="/format/2310.00290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universality of almost periodicity in bounded discrete time series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoneda%2C+T">Tsuyoshi Yoneda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Analysis of PDEs (math.AP); Dynamical Systems (math.DS); Functional Analysis (math.FA)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02304" title="Abstract">arXiv:2310.02304</a> (replaced) [<a href="/pdf/2310.02304" title="Download PDF">pdf</a>, <a href="/format/2310.02304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Taught Optimizer (STOP): Recursively Self-Improving Code Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zelikman%2C+E">Eric Zelikman</a>, 
<a href="/search/cs?searchtype=author&query=Lorch%2C+E">Eliana Lorch</a>, 
<a href="/search/cs?searchtype=author&query=Mackey%2C+L">Lester Mackey</a>, 
<a href="/search/cs?searchtype=author&query=Kalai%2C+A+T">Adam Tauman Kalai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03309" title="Abstract">arXiv:2310.03309</a> (replaced) [<a href="/pdf/2310.03309" title="Download PDF">pdf</a>, <a href="/format/2310.03309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concise and Organized Perception Facilitates Large Language Models for  Deductive Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shaotian Yan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chen Shen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jieping Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05922" title="Abstract">arXiv:2310.05922</a> (replaced) [<a href="/pdf/2310.05922" title="Download PDF">pdf</a>, <a href="/format/2310.05922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FLATTEN: optical FLow-guided ATTENtion for consistent text-to-video  editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cong%2C+Y">Yuren Cong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mengmeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Simon%2C+C">Christian Simon</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shoufa Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jiawei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yanping Xie</a>, 
<a href="/search/cs?searchtype=author&query=Perez-Rua%2C+J">Juan-Manuel Perez-Rua</a>, 
<a href="/search/cs?searchtype=author&query=Rosenhahn%2C+B">Bodo Rosenhahn</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+T">Tao Xiang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Sen He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICLR2024. Project page: <a href="https://flatten-video-editing.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09235" title="Abstract">arXiv:2310.09235</a> (replaced) [<a href="/pdf/2310.09235" title="Download PDF">pdf</a>, <a href="/format/2310.09235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoPrompt: Supporting Prompt Sharing and Referring in Collaborative  Natural Language Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+L">Li Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yen%2C+R">Ryan Yen</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yuzhe You</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+M">Mingming Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhicong Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '24), May 11--16, 2024, Honolulu, HI, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09985" title="Abstract">arXiv:2310.09985</a> (replaced) [<a href="/pdf/2310.09985" title="Download PDF">pdf</a>, <a href="/format/2310.09985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompting for Discovery: Flexible Sense-Making for AI Art-Making with  Dreamsheets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almeda%2C+S+G">Shm Garanganao Almeda</a>, 
<a href="/search/cs?searchtype=author&query=Zamfirescu-Pereira%2C+J+D">J.D. Zamfirescu-Pereira</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K+W">Kyu Won Kim</a>, 
<a href="/search/cs?searchtype=author&query=Rathnam%2C+P+M">Pradeep Mani Rathnam</a>, 
<a href="/search/cs?searchtype=author&query=Hartmann%2C+B">Bjoern Hartmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 14 figures, currently under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10817" title="Abstract">arXiv:2310.10817</a> (replaced) [<a href="/pdf/2310.10817" title="Download PDF">pdf</a>, <a href="/format/2310.10817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Documentation Use Through Log Analysis: An Exploratory  Case Study of Four Cloud Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nam%2C+D">Daye Nam</a>, 
<a href="/search/cs?searchtype=author&query=Macvean%2C+A">Andrew Macvean</a>, 
<a href="/search/cs?searchtype=author&query=Myers%2C+B">Brad Myers</a>, 
<a href="/search/cs?searchtype=author&query=Vasilescu%2C+B">Bogdan Vasilescu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11046" title="Abstract">arXiv:2310.11046</a> (replaced) [<a href="/pdf/2310.11046" title="Download PDF">pdf</a>, <a href="/format/2310.11046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Graph Condensation with Structure-based Neural Tangent Kernel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+W">Wenqi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiatong Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11143" title="Abstract">arXiv:2310.11143</a> (replaced) [<a href="/pdf/2310.11143" title="Download PDF">pdf</a>, <a href="/ps/2310.11143" title="Download PostScript">ps</a>, <a href="/format/2310.11143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring a new machine learning based probabilistic model for  high-resolution indoor radon mapping, using the German indoor radon survey  data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Petermann%2C+E">Eric Petermann</a>, 
<a href="/search/stat?searchtype=author&query=Bossew%2C+P">Peter Bossew</a>, 
<a href="/search/stat?searchtype=author&query=Kemski%2C+J">Joachim Kemski</a>, 
<a href="/search/stat?searchtype=author&query=Gruber%2C+V">Valeria Gruber</a>, 
<a href="/search/stat?searchtype=author&query=Suhr%2C+N">Nils Suhr</a>, 
<a href="/search/stat?searchtype=author&query=Hoffmann%2C+B">Bernd Hoffmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11401" title="Abstract">arXiv:2310.11401</a> (replaced) [<a href="/pdf/2310.11401" title="Download PDF">pdf</a>, <a href="/format/2310.11401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Group Fairness in Online Settings Using Oblique Decision  Forests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+S+B+R">Somnath Basu Roy Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Monath%2C+N">Nicholas Monath</a>, 
<a href="/search/cs?searchtype=author&query=Beirami%2C+A">Ahmad Beirami</a>, 
<a href="/search/cs?searchtype=author&query=Kidambi%2C+R">Rahul Kidambi</a>, 
<a href="/search/cs?searchtype=author&query=Dubey%2C+A">Avinava Dubey</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+A">Amr Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Chaturvedi%2C+S">Snigdha Chaturvedi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024 (Spotlight)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11475" title="Abstract">arXiv:2310.11475</a> (replaced) [<a href="/pdf/2310.11475" title="Download PDF">pdf</a>, <a href="/format/2310.11475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tracking and Mapping in Medical Computer Vision: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+A">Adam Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Mohareri%2C+O">Omid Mohareri</a>, 
<a href="/search/cs?searchtype=author&query=DiMaio%2C+S">Simon DiMaio</a>, 
<a href="/search/cs?searchtype=author&query=Yip%2C+M+C">Michael C. Yip</a>, 
<a href="/search/cs?searchtype=author&query=Salcudean%2C+S+E">Septimiu E. Salcudean</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 17 figures. To appear in Medical Image Analysis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12508" title="Abstract">arXiv:2310.12508</a> (replaced) [<a href="/pdf/2310.12508" title="Download PDF">pdf</a>, <a href="/format/2310.12508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency  in Both Image Classification and Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chongyu Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiancheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yihua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+E">Eric Wong</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+D">Dennis Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sijia Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICLR 2024 as a Spotlight paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13653" title="Abstract">arXiv:2310.13653</a> (replaced) [<a href="/pdf/2310.13653" title="Download PDF">pdf</a>, <a href="/format/2310.13653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Transport for Measures with Noisy Tree Metric
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Le%2C+T">Tam Le</a>, 
<a href="/search/stat?searchtype=author&query=Nguyen%2C+T">Truyen Nguyen</a>, 
<a href="/search/stat?searchtype=author&query=Fukumizu%2C+K">Kenji Fukumizu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16298" title="Abstract">arXiv:2310.16298</a> (replaced) [<a href="/pdf/2310.16298" title="Download PDF">pdf</a>, <a href="/format/2310.16298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stencil Matrixization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenxuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Liang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Baicheng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+P">Penghao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunquan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Long Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhe Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16605" title="Abstract">arXiv:2310.16605</a> (replaced) [<a href="/pdf/2310.16605" title="Download PDF">pdf</a>, <a href="/format/2310.16605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WebDRO: A Web-based Group-level Clustering and Reweighting Method for  Unsupervised Dense Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+P">Peixuan Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Chenyan Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17009" title="Abstract">arXiv:2310.17009</a> (replaced) [<a href="/pdf/2310.17009" title="Download PDF">pdf</a>, <a href="/format/2310.17009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulation-based stacking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Yao%2C+Y">Yuling Yao</a>, 
<a href="/search/stat?searchtype=author&query=Blancard%2C+B+R">Bruno R&#xe9;galdo-Saint Blancard</a>, 
<a href="/search/stat?searchtype=author&query=Domke%2C+J">Justin Domke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at International Conference on Artificial Intelligence and Statistics (AISTATS) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19103" title="Abstract">arXiv:2310.19103</a> (replaced) [<a href="/pdf/2310.19103" title="Download PDF">pdf</a>, <a href="/format/2310.19103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proving Linear Mode Connectivity of Neural Networks via Optimal  Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferbach%2C+D">Damien Ferbach</a>, 
<a href="/search/cs?searchtype=author&query=Goujaud%2C+B">Baptiste Goujaud</a>, 
<a href="/search/cs?searchtype=author&query=Gidel%2C+G">Gauthier Gidel</a>, 
<a href="/search/cs?searchtype=author&query=Dieuleveut%2C+A">Aymeric Dieuleveut</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a conference paper at AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00460" title="Abstract">arXiv:2311.00460</a> (replaced) [<a href="/pdf/2311.00460" title="Download PDF">pdf</a>, <a href="/format/2311.00460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Budgeted Rejection Sampling for Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verine%2C+A">Alexandre Verine</a>, 
<a href="/search/cs?searchtype=author&query=Pydi%2C+M+S">Muni Sreenivas Pydi</a>, 
<a href="/search/cs?searchtype=author&query=Negrevergne%2C+B">Benjamin Negrevergne</a>, 
<a href="/search/cs?searchtype=author&query=Chevaleyre%2C+Y">Yann Chevaleyre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02198" title="Abstract">arXiv:2311.02198</a> (replaced) [<a href="/pdf/2311.02198" title="Download PDF">pdf</a>, <a href="/format/2311.02198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imitation Bootstrapped Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hengyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Mirchandani%2C+S">Suvir Mirchandani</a>, 
<a href="/search/cs?searchtype=author&query=Sadigh%2C+D">Dorsa Sadigh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02206" title="Abstract">arXiv:2311.02206</a> (replaced) [<a href="/pdf/2311.02206" title="Download PDF">pdf</a>, <a href="/format/2311.02206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modern Datalog on the GPU
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yihao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shovon%2C+A+R">Ahmedur Rahman Shovon</a>, 
<a href="/search/cs?searchtype=author&query=Gilray%2C+T">Thomas Gilray</a>, 
<a href="/search/cs?searchtype=author&query=Micinski%2C+K">Kristopher Micinski</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sidharth Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05919" title="Abstract">arXiv:2311.05919</a> (replaced) [<a href="/pdf/2311.05919" title="Download PDF">pdf</a>, <a href="/format/2311.05919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inter-object Discriminative Graph Modeling for Indoor Scene Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Chuanxin Song</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hanbo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xin Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06956" title="Abstract">arXiv:2311.06956</a> (replaced) [<a href="/pdf/2311.06956" title="Download PDF">pdf</a>, <a href="/format/2311.06956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SegReg: Segmenting OARs by Registering MR Images and CT Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xuyin Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bowen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Biao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+H">Hien Le</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+B">Bora Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Z">Zhibin Liao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunxiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Verjans%2C+J">Johan Verjans</a>, 
<a href="/search/cs?searchtype=author&query=To%2C+M">Minh-Son To</a>, 
<a href="/search/cs?searchtype=author&query=Hartley%2C+R">Richard Hartley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ISBI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07499" title="Abstract">arXiv:2311.07499</a> (replaced) [<a href="/pdf/2311.07499" title="Download PDF">pdf</a>, <a href="/format/2311.07499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging the Sim-to-Real Gap with Dynamic Compliance Tuning for  Industrial Insertion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tomizuka%2C+M">Masayoshi Tomizuka</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hui Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICRA 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08107" title="Abstract">arXiv:2311.08107</a> (replaced) [<a href="/pdf/2311.08107" title="Download PDF">pdf</a>, <a href="/format/2311.08107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAIE Framework: Support Alone Isn&#x27;t Enough -- Advancing LLM Training  with Adversarial Remarks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Loem%2C+M">Mengsay Loem</a>, 
<a href="/search/cs?searchtype=author&query=Kaneko%2C+M">Masahiro Kaneko</a>, 
<a href="/search/cs?searchtype=author&query=Okazaki%2C+N">Naoaki Okazaki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09010" title="Abstract">arXiv:2311.09010</a> (replaced) [<a href="/pdf/2311.09010" title="Download PDF">pdf</a>, <a href="/ps/2311.09010" title="Download PostScript">ps</a>, <a href="/format/2311.09010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of sum-of-squares relaxations for the quantum rotor model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Rao%2C+S">Sujit Rao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, appeared at QIP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09510" title="Abstract">arXiv:2311.09510</a> (replaced) [<a href="/pdf/2311.09510" title="Download PDF">pdf</a>, <a href="/format/2311.09510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One Size Does Not Fit All: Customizing Open-Domain Procedures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lal%2C+Y+K">Yash Kumar Lal</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Brahman%2C+F">Faeze Brahman</a>, 
<a href="/search/cs?searchtype=author&query=Majumder%2C+B+P">Bodhisattwa Prasad Majumder</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+P">Peter Clark</a>, 
<a href="/search/cs?searchtype=author&query=Tandon%2C+N">Niket Tandon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13162" title="Abstract">arXiv:2311.13162</a> (replaced) [<a href="/pdf/2311.13162" title="Download PDF">pdf</a>, <a href="/format/2311.13162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Top-L Most Influential Community Detection Over Social Networks  (Technical Report)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Nan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yutong Ye</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+X">Xiang Lian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingsong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13385" title="Abstract">arXiv:2311.13385</a> (replaced) [<a href="/pdf/2311.13385" title="Download PDF">pdf</a>, <a href="/format/2311.13385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SegVol: Universal and Interactive Volumetric Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yuxin Du</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+F">Fan Bai</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tiejun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bo Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14625" title="Abstract">arXiv:2311.14625</a> (replaced) [<a href="/pdf/2311.14625" title="Download PDF">pdf</a>, <a href="/format/2311.14625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ARIA: On the Interaction Between Architectures, Initialization and  Aggregation Methods for Federated Visual Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Siomos%2C+V">Vasilis Siomos</a>, 
<a href="/search/cs?searchtype=author&query=Naval-Marimont%2C+S">Sergio Naval-Marimont</a>, 
<a href="/search/cs?searchtype=author&query=Passerat-Palmbach%2C+J">Jonathan Passerat-Palmbach</a>, 
<a href="/search/cs?searchtype=author&query=Tarroni%2C+G">Giacomo Tarroni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ISBI 2024, camera-ready version with updated information on hyper-parameter tuning and clearer phrasing for practical take-aways
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00398" title="Abstract">arXiv:2312.00398</a> (replaced) [<a href="/pdf/2312.00398" title="Download PDF">pdf</a>, <a href="/format/2312.00398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Estimate Critical Gait Parameters from Single-View RGB  Videos with Transformer-Based Attention Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+Q+H+T">Quoc Hung T. Le</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+H+H">Hieu H. Pham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ISBI 2024 (21st IEEE International Symposium on Biomedical Imaging)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02277" title="Abstract">arXiv:2312.02277</a> (replaced) [<a href="/pdf/2312.02277" title="Download PDF">pdf</a>, <a href="/format/2312.02277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ALEXR: An Optimal Single-Loop Algorithm for Convex Finite-Sum Coupled  Compositional Stochastic Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+B">Bokun Wang</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+T">Tianbao Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added some closed-form expressions of the dual update
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04455" title="Abstract">arXiv:2312.04455</a> (replaced) [<a href="/pdf/2312.04455" title="Download PDF">pdf</a>, <a href="/format/2312.04455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fortify the Shortest Stave in Attention: Enhancing Context Awareness of  Large Language Models for Effective Tool Use
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+A">Ang Lv</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Ting-En Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Changyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuchuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rui Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06024" title="Abstract">arXiv:2312.06024</a> (replaced) [<a href="/pdf/2312.06024" title="Download PDF">pdf</a>, <a href="/format/2312.06024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Thinking Assistants: LLM-Based Conversational Assistants that Help Users  Think By Asking rather than Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Soya Park</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+C">Chinmay Kulkarni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06152" title="Abstract">arXiv:2312.06152</a> (replaced) [<a href="/pdf/2312.06152" title="Download PDF">pdf</a>, <a href="/format/2312.06152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the performance of weak supervision searches using transfer  and meta-learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ph?searchtype=author&query=Beauchesne%2C+H">Hugues Beauchesne</a>, 
<a href="/search/hep-ph?searchtype=author&query=Chen%2C+Z">Zong-En Chen</a>, 
<a href="/search/hep-ph?searchtype=author&query=Chiang%2C+C">Cheng-Wei Chiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 7 figures, matches the published version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Phenomenology (hep-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07358" title="Abstract">arXiv:2312.07358</a> (replaced) [<a href="/pdf/2312.07358" title="Download PDF">pdf</a>, <a href="/format/2312.07358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributional Bellman Operators over Mean Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wenliang%2C+L+K">Li Kevin Wenliang</a>, 
<a href="/search/stat?searchtype=author&query=D%C3%A9letang%2C+G">Gr&#xe9;goire D&#xe9;letang</a>, 
<a href="/search/stat?searchtype=author&query=Aitchison%2C+M">Matthew Aitchison</a>, 
<a href="/search/stat?searchtype=author&query=Hutter%2C+M">Marcus Hutter</a>, 
<a href="/search/stat?searchtype=author&query=Ruoss%2C+A">Anian Ruoss</a>, 
<a href="/search/stat?searchtype=author&query=Gretton%2C+A">Arthur Gretton</a>, 
<a href="/search/stat?searchtype=author&query=Rowland%2C+M">Mark Rowland</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12343" title="Abstract">arXiv:2312.12343</a> (replaced) [<a href="/pdf/2312.12343" title="Download PDF">pdf</a>, <a href="/format/2312.12343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LatestEval: Addressing Data Contamination in Language Model Evaluation  through Dynamic and Time-Sensitive Test Construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yucheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Guerin%2C+F">Frank Guerin</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenghua Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12462" title="Abstract">arXiv:2312.12462</a> (replaced) [<a href="/pdf/2312.12462" title="Download PDF">pdf</a>, <a href="/format/2312.12462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards an end-to-end artificial intelligence driven global weather  forecasting system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Chen%2C+K">Kun Chen</a>, 
<a href="/search/physics?searchtype=author&query=Bai%2C+L">Lei Bai</a>, 
<a href="/search/physics?searchtype=author&query=Ling%2C+F">Fenghua Ling</a>, 
<a href="/search/physics?searchtype=author&query=Ye%2C+P">Peng Ye</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/physics?searchtype=author&query=Luo%2C+J">Jing-Jia Luo</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+K">Kang Chen</a>, 
<a href="/search/physics?searchtype=author&query=Han%2C+T">Tao Han</a>, 
<a href="/search/physics?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14388" title="Abstract">arXiv:2312.14388</a> (replaced) [<a href="/pdf/2312.14388" title="Download PDF">pdf</a>, <a href="/format/2312.14388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generalized Shuffle Framework for Privacy Amplification: Strengthening  Privacy Guarantees and Enhancing Utility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">E Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yifei Ge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Correct some typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14889" title="Abstract">arXiv:2312.14889</a> (replaced) [<a href="/pdf/2312.14889" title="Download PDF">pdf</a>, <a href="/ps/2312.14889" title="Download PostScript">ps</a>, <a href="/format/2312.14889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Rate-Optimal Partitioning Classification from Observable and from  Privatised Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cs%C3%A1ji%2C+B+C">Bal&#xe1;zs Csan&#xe1;d Cs&#xe1;ji</a>, 
<a href="/search/stat?searchtype=author&query=Gy%C3%B6rfi%2C+L">L&#xe1;szl&#xf3; Gy&#xf6;rfi</a>, 
<a href="/search/stat?searchtype=author&query=Tam%C3%A1s%2C+A">Ambrus Tam&#xe1;s</a>, 
<a href="/search/stat?searchtype=author&query=Walk%2C+H">Harro Walk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15308" title="Abstract">arXiv:2312.15308</a> (replaced) [<a href="/pdf/2312.15308" title="Download PDF">pdf</a>, <a href="/ps/2312.15308" title="Download PostScript">ps</a>, <a href="/format/2312.15308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The hull variation problem for projective Reed-Muller codes and quantum  error-correcting codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruano%2C+D">Diego Ruano</a>, 
<a href="/search/cs?searchtype=author&query=San-Jos%C3%A9%2C+R">Rodrigo San-Jos&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00037" title="Abstract">arXiv:2401.00037</a> (replaced) [<a href="/pdf/2401.00037" title="Download PDF">pdf</a>, <a href="/format/2401.00037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Messenger RNA Design via Expected Partition Function and Continuous  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Dai%2C+N">Ning Dai</a>, 
<a href="/search/q-bio?searchtype=author&query=Tang%2C+W+Y">Wei Yu Tang</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhou%2C+T">Tianshuo Zhou</a>, 
<a href="/search/q-bio?searchtype=author&query=Mathews%2C+D+H">David H. Mathews</a>, 
<a href="/search/q-bio?searchtype=author&query=Huang%2C+L">Liang Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00594" title="Abstract">arXiv:2401.00594</a> (replaced) [<a href="/pdf/2401.00594" title="Download PDF">pdf</a>, <a href="/ps/2401.00594" title="Download PostScript">ps</a>, <a href="/format/2401.00594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Design for Multi-user Downlink Beamforming with Reconfigurable  Intelligent Surface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ebrahimi%2C+M">Mohammad Ebrahimi</a>, 
<a href="/search/eess?searchtype=author&query=Dong%2C+M">Min Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01387" title="Abstract">arXiv:2401.01387</a> (replaced) [<a href="/pdf/2401.01387" title="Download PDF">pdf</a>, <a href="/format/2401.01387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffAugment: Diffusion based Long-Tailed Visual Relationship Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+P">Parul Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Tuan Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Dhall%2C+A">Abhinav Dhall</a>, 
<a href="/search/cs?searchtype=author&query=Hayat%2C+M">Munawar Hayat</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Trung Le</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+T">Thanh-Toan Do</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01523" title="Abstract">arXiv:2401.01523</a> (replaced) [<a href="/pdf/2401.01523" title="Download PDF">pdf</a>, <a href="/format/2401.01523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GOAT-Bench: Safety Insights to Large Multimodal Models through  Meme-Based Social Abuse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hongzhan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Ziyang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Ruichao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jing Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first work to benchmark Large Multimodal Models in safety insight on social media
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04190" title="Abstract">arXiv:2401.04190</a> (replaced) [<a href="/pdf/2401.04190" title="Download PDF">pdf</a>, <a href="/format/2401.04190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is it possible to know cosmological fine-tuning?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=D%C3%ADaz-Pach%C3%B3n%2C+D+A">Daniel Andr&#xe9;s D&#xed;az-Pach&#xf3;n</a>, 
<a href="/search/astro-ph?searchtype=author&query=H%C3%B6ssjer%2C+O">Ola H&#xf6;ssjer</a>, 
<a href="/search/astro-ph?searchtype=author&query=Mathew%2C+C">Calvin Mathew</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted version. Minor changes: a sentence removed at the end of Section 5.2, and more comprehensive keywords
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cosmology and Nongalactic Astrophysics (astro-ph.CO)</span>; Information Theory (cs.IT); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06040" title="Abstract">arXiv:2401.06040</a> (replaced) [<a href="/pdf/2401.06040" title="Download PDF">pdf</a>, <a href="/format/2401.06040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wavelet-Inspired Multiscale Graph Convolutional Recurrent Network for  Traffic Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+Q">Qipeng Qian</a>, 
<a href="/search/cs?searchtype=author&query=Mallick%2C+T">Tanwi Mallick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06637" title="Abstract">arXiv:2401.06637</a> (replaced) [<a href="/pdf/2401.06637" title="Download PDF">pdf</a>, <a href="/format/2401.06637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Examples are Misaligned in Diffusion Model Manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lorenz%2C+P">Peter Lorenz</a>, 
<a href="/search/cs?searchtype=author&query=Durall%2C+R">Ricard Durall</a>, 
<a href="/search/cs?searchtype=author&query=Keuper%2C+J">Janis Keuper</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08909" title="Abstract">arXiv:2401.08909</a> (replaced) [<a href="/pdf/2401.08909" title="Download PDF">pdf</a>, <a href="/format/2401.08909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Gradients for Unsupervised Accuracy Estimation under  Distribution Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+R">Renchunzi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Odonnat%2C+A">Ambroise Odonnat</a>, 
<a href="/search/cs?searchtype=author&query=Feofanov%2C+V">Vasilii Feofanov</a>, 
<a href="/search/cs?searchtype=author&query=Redko%2C+I">Ievgen Redko</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+B">Bo An</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10726" title="Abstract">arXiv:2401.10726</a> (replaced) [<a href="/e-print/2401.10726" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empowering Aggregators with Practical Data-Driven Tools: Harnessing  Aggregated and Disaggregated Flexibility for Demand Response
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mylonas%2C+C">Costas Mylonas</a>, 
<a href="/search/eess?searchtype=author&query=Boric%2C+D">Donata Boric</a>, 
<a href="/search/eess?searchtype=author&query=Maric%2C+L+L">Leila Luttenberger Maric</a>, 
<a href="/search/eess?searchtype=author&query=Tsitsanis%2C+A">Alexandros Tsitsanis</a>, 
<a href="/search/eess?searchtype=author&query=Petrianou%2C+E">Eleftheria Petrianou</a>, 
<a href="/search/eess?searchtype=author&query=Foti%2C+M">Magda Foti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We will perform a major update and change in the order of the name of the authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10910" title="Abstract">arXiv:2401.10910</a> (replaced) [<a href="/pdf/2401.10910" title="Download PDF">pdf</a>, <a href="/format/2401.10910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metacognition is all you need? Using Introspection in Generative Agents  to Improve Goal-directed Behavior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Toy%2C+J">Jason Toy</a>, 
<a href="/search/q-bio?searchtype=author&query=MacAdam%2C+J">Josh MacAdam</a>, 
<a href="/search/q-bio?searchtype=author&query=Tabor%2C+P">Phil Tabor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11148" title="Abstract">arXiv:2401.11148</a> (replaced) [<a href="/pdf/2401.11148" title="Download PDF">pdf</a>, <a href="/format/2401.11148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing System-Level Safety in Mixed-Autonomy Platoon via Safe  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+J">Jingyuan Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+L">Longhao Yan</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+K">Kaidi Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13170" title="Abstract">arXiv:2401.13170</a> (replaced) [<a href="/pdf/2401.13170" title="Download PDF">pdf</a>, <a href="/format/2401.13170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CFMatch: Aligning Automated Answer Equivalence Evaluation with Expert  Judgments For Open-Domain Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongxia Li</a>, 
<a href="/search/cs?searchtype=author&query=Mondal%2C+I">Ishani Mondal</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yijun Liang</a>, 
<a href="/search/cs?searchtype=author&query=Nghiem%2C+H">Huy Nghiem</a>, 
<a href="/search/cs?searchtype=author&query=Boyd-Graber%2C+J">Jordan Boyd-Graber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> See <a href="/abs/2402.11161">arXiv:2402.11161</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13371" title="Abstract">arXiv:2401.13371</a> (replaced) [<a href="/pdf/2401.13371" title="Download PDF">pdf</a>, <a href="/format/2401.13371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SVARM-IQ: Efficient Approximation of Any-order Shapley Interactions  through Stratification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kolpaczki%2C+P">Patrick Kolpaczki</a>, 
<a href="/search/cs?searchtype=author&query=Muschalik%2C+M">Maximilian Muschalik</a>, 
<a href="/search/cs?searchtype=author&query=Fumagalli%2C+F">Fabian Fumagalli</a>, 
<a href="/search/cs?searchtype=author&query=Hammer%2C+B">Barbara Hammer</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%BCllermeier%2C+E">Eyke H&#xfc;llermeier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13662" title="Abstract">arXiv:2401.13662</a> (replaced) [<a href="/pdf/2401.13662" title="Download PDF">pdf</a>, <a href="/format/2401.13662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Definitive Guide to Policy Gradients in Deep Reinforcement Learning:  Theory, Algorithms and Implementations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lehmann%2C+M">Matthias Lehmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16439" title="Abstract">arXiv:2401.16439</a> (replaced) [<a href="/pdf/2401.16439" title="Download PDF">pdf</a>, <a href="/ps/2401.16439" title="Download PostScript">ps</a>, <a href="/format/2401.16439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distribution-Specific Auditing For Subgroup Fairness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hsu%2C+D">Daniel Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jizhou Huang</a>, 
<a href="/search/cs?searchtype=author&query=Juba%2C+B">Brendan Juba</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Complexity (cs.CC); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.17010" title="Abstract">arXiv:2401.17010</a> (replaced) [<a href="/pdf/2401.17010" title="Download PDF">pdf</a>, <a href="/ps/2401.17010" title="Download PostScript">ps</a>, <a href="/format/2401.17010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finetuning Large Language Models for Vulnerability Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shestov%2C+A">Alexey Shestov</a>, 
<a href="/search/cs?searchtype=author&query=Levichev%2C+R">Rodion Levichev</a>, 
<a href="/search/cs?searchtype=author&query=Mussabayev%2C+R">Ravil Mussabayev</a>, 
<a href="/search/cs?searchtype=author&query=Maslov%2C+E">Evgeny Maslov</a>, 
<a href="/search/cs?searchtype=author&query=Cheshkov%2C+A">Anton Cheshkov</a>, 
<a href="/search/cs?searchtype=author&query=Zadorozhny%2C+P">Pavel Zadorozhny</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00957" title="Abstract">arXiv:2402.00957</a> (replaced) [<a href="/pdf/2402.00957" title="Download PDF">pdf</a>, <a href="/format/2402.00957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Credal Learning Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caprio%2C+M">Michele Caprio</a>, 
<a href="/search/cs?searchtype=author&query=Sultana%2C+M">Maryam Sultana</a>, 
<a href="/search/cs?searchtype=author&query=Elia%2C+E">Eleni Elia</a>, 
<a href="/search/cs?searchtype=author&query=Cuzzolin%2C+F">Fabio Cuzzolin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.01663" title="Abstract">arXiv:2402.01663</a> (replaced) [<a href="/pdf/2402.01663" title="Download PDF">pdf</a>, <a href="/format/2402.01663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Killer Apps: Low-Speed, Large-Scale AI Weapons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feldman%2C+P">Philip Feldman</a>, 
<a href="/search/cs?searchtype=author&query=Dant%2C+A">Aaron Dant</a>, 
<a href="/search/cs?searchtype=author&query=Foulds%2C+J+R">James R. Foulds</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages with 10 pages of appendices. 3 Figures, 2 code listings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.01719" title="Abstract">arXiv:2402.01719</a> (replaced) [<a href="/pdf/2402.01719" title="Download PDF">pdf</a>, <a href="/format/2402.01719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring Moral Inconsistencies in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bonagiri%2C+V+K">Vamshi Krishna Bonagiri</a>, 
<a href="/search/cs?searchtype=author&query=Vennam%2C+S">Sreeram Vennam</a>, 
<a href="/search/cs?searchtype=author&query=Gaur%2C+M">Manas Gaur</a>, 
<a href="/search/cs?searchtype=author&query=Kumaraguru%2C+P">Ponnurangam Kumaraguru</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at BlackBoxNLP 2023, Co-located with EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02648" title="Abstract">arXiv:2402.02648</a> (replaced) [<a href="/pdf/2402.02648" title="Download PDF">pdf</a>, <a href="/format/2402.02648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursive Chain-of-Feedback Prevents Performance Degradation from  Redundant Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahn%2C+J">Jinwoo Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+K">Kyuseung Shin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Still Ongoing Work; 8 Pages; 2 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03268" title="Abstract">arXiv:2402.03268</a> (replaced) [<a href="/pdf/2402.03268" title="Download PDF">pdf</a>, <a href="/format/2402.03268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Reasoning Ability of Language Models From the  Perspective of Reasoning Paths Aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Amayuelas%2C+A">Alfonso Amayuelas</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kexun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liangming Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenhu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W+Y">William Yang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03408" title="Abstract">arXiv:2402.03408</a> (replaced) [<a href="/pdf/2402.03408" title="Download PDF">pdf</a>, <a href="/format/2402.03408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Effective Invocation Methods of Massive LLM Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Can Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bolin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sui%2C+D">Dianbo Sui</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhiying Tu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiabao Kang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03776" title="Abstract">arXiv:2402.03776</a> (replaced) [<a href="/pdf/2402.03776" title="Download PDF">pdf</a>, <a href="/ps/2402.03776" title="Download PostScript">ps</a>, <a href="/format/2402.03776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models As MOOCs Graders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Golchin%2C+S">Shahriar Golchin</a>, 
<a href="/search/cs?searchtype=author&query=Garuda%2C+N">Nikhil Garuda</a>, 
<a href="/search/cs?searchtype=author&query=Impey%2C+C">Christopher Impey</a>, 
<a href="/search/cs?searchtype=author&query=Wenger%2C+M">Matthew Wenger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v1.3 preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04792" title="Abstract">arXiv:2402.04792</a> (replaced) [<a href="/pdf/2402.04792" title="Download PDF">pdf</a>, <a href="/format/2402.04792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Direct Language Model Alignment from Online AI Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Shangmin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Biao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianlin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Khalman%2C+M">Misha Khalman</a>, 
<a href="/search/cs?searchtype=author&query=Llinares%2C+F">Felipe Llinares</a>, 
<a href="/search/cs?searchtype=author&query=Rame%2C+A">Alexandre Rame</a>, 
<a href="/search/cs?searchtype=author&query=Mesnard%2C+T">Thomas Mesnard</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Piot%2C+B">Bilal Piot</a>, 
<a href="/search/cs?searchtype=author&query=Ferret%2C+J">Johan Ferret</a>, 
<a href="/search/cs?searchtype=author&query=Blondel%2C+M">Mathieu Blondel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 9 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05493" title="Abstract">arXiv:2402.05493</a> (replaced) [<a href="/pdf/2402.05493" title="Download PDF">pdf</a>, <a href="/format/2402.05493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating White-Box Attacks for On-Device Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mingyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hailong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in The International Conference on Software Engineering 2024 (ICSE'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05956" title="Abstract">arXiv:2402.05956</a> (replaced) [<a href="/pdf/2402.05956" title="Download PDF">pdf</a>, <a href="/format/2402.05956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-scale Transformers with Adaptive Pathways for Time Series  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yunyao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+Y">Yang Shu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yihang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Q">Qingsong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Chenjuan Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 12th International Conference on Learning Representations (ICLR 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07939" title="Abstract">arXiv:2402.07939</a> (replaced) [<a href="/pdf/2402.07939" title="Download PDF">pdf</a>, <a href="/format/2402.07939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UFO: A UI-Focused Agent for Windows OS Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoyun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liqun Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shilin He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+B">Bo Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+S">Si Qin</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+M">Minghua Ma</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yu Kang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qingwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Rajmohan%2C+S">Saravan Rajmohan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08223" title="Abstract">arXiv:2402.08223</a> (replaced) [<a href="/pdf/2402.08223" title="Download PDF">pdf</a>, <a href="/ps/2402.08223" title="Download PostScript">ps</a>, <a href="/format/2402.08223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Limits of Price Discrimination Under Privacy Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Fallah%2C+A">Alireza Fallah</a>, 
<a href="/search/econ?searchtype=author&query=Jordan%2C+M+I">Michael I. Jordan</a>, 
<a href="/search/econ?searchtype=author&query=Makhdoumi%2C+A">Ali Makhdoumi</a>, 
<a href="/search/econ?searchtype=author&query=Malekian%2C+A">Azarakhsh Malekian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.09353" title="Abstract">arXiv:2402.09353</a> (replaced) [<a href="/pdf/2402.09353" title="Download PDF">pdf</a>, <a href="/format/2402.09353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DoRA: Weight-Decomposed Low-Rank Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shih-Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chien-Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongxu Yin</a>, 
<a href="/search/cs?searchtype=author&query=Molchanov%2C+P">Pavlo Molchanov</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y+F">Yu-Chiang Frank Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+K">Kwang-Ting Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Min-Hung Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.09367" title="Abstract">arXiv:2402.09367</a> (replaced) [<a href="/pdf/2402.09367" title="Download PDF">pdf</a>, <a href="/ps/2402.09367" title="Download PostScript">ps</a>, <a href="/format/2402.09367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prediction of Activated Sludge Settling Characteristics from Microscopy  Images with Deep Convolutional Neural Networks and Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borzooei%2C+S">Sina Borzooei</a>, 
<a href="/search/cs?searchtype=author&query=Scabini%2C+L">Leonardo Scabini</a>, 
<a href="/search/cs?searchtype=author&query=Miranda%2C+G">Gisele Miranda</a>, 
<a href="/search/cs?searchtype=author&query=Daneshgar%2C+S">Saba Daneshgar</a>, 
<a href="/search/cs?searchtype=author&query=Deblieck%2C+L">Lukas Deblieck</a>, 
<a href="/search/cs?searchtype=author&query=De+Langhe%2C+P">Piet De Langhe</a>, 
<a href="/search/cs?searchtype=author&query=Bruno%2C+O">Odemir Bruno</a>, 
<a href="/search/cs?searchtype=author&query=De+Baets%2C+B">Bernard De Baets</a>, 
<a href="/search/cs?searchtype=author&query=Nopens%2C+I">Ingmar Nopens</a>, 
<a href="/search/cs?searchtype=author&query=Torfs%2C+E">Elena Torfs</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 Pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.09595" title="Abstract">arXiv:2402.09595</a> (replaced) [<a href="/pdf/2402.09595" title="Download PDF">pdf</a>, <a href="/format/2402.09595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correctly Communicating Software: Distributed, Asynchronous, and Beyond  (extended version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+den+Heuvel%2C+B">Bas van den Heuvel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.10043" title="Abstract">arXiv:2402.10043</a> (replaced) [<a href="/pdf/2402.10043" title="Download PDF">pdf</a>, <a href="/format/2402.10043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to validate average calibration for machine learning regression  tasks ?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Pernot%2C+P">Pascal Pernot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.12810" title="Abstract">arXiv:2402.12810</a> (replaced) [<a href="/pdf/2402.12810" title="Download PDF">pdf</a>, <a href="/format/2402.12810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PIP-Net: Pedestrian Intention Prediction in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azarmi%2C+M">Mohsen Azarmi</a>, 
<a href="/search/cs?searchtype=author&query=Rezaei%2C+M">Mahdi Rezaei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">He Wang</a>, 
<a href="/search/cs?searchtype=author&query=Glaser%2C+S">Sebastien Glaser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Image and Video Processing (eess.IV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.12907" title="Abstract">arXiv:2402.12907</a> (replaced) [<a href="/pdf/2402.12907" title="Download PDF">pdf</a>, <a href="/format/2402.12907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incentive Compatibility for AI Alignment in Sociotechnical Systems:  Positions and Prospects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaowei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+F">Fengshuo Bai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mingzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Haoyang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chengdong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yaodong Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Computer Science and Game Theory (cs.GT); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13693" title="Abstract">arXiv:2402.13693</a> (replaced) [<a href="/pdf/2402.13693" title="Download PDF">pdf</a>, <a href="/format/2402.13693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CMNER: A Chinese Multimodal NER Dataset based on Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yuanze Ji</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bobo Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fei Li</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+C">Chong Teng</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+D">Donghong Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13717" title="Abstract">arXiv:2402.13717</a> (replaced) [<a href="/pdf/2402.13717" title="Download PDF">pdf</a>, <a href="/format/2402.13717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neeko: Leveraging Dynamic LoRA for Efficient Multi-Character  Role-Playing Agent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiaoyan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+T">Tongxu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yifan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+F">Fangyu Lei</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liehuang Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13918" title="Abstract">arXiv:2402.13918</a> (replaced) [<a href="/pdf/2402.13918" title="Download PDF">pdf</a>, <a href="/format/2402.13918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BenchCloudVision: A Benchmark Analysis of Deep Learning Approaches for  Cloud Detection and Segmentation in Remote Sensing Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fabio%2C+L">Loddo Fabio</a>, 
<a href="/search/cs?searchtype=author&query=Piga%2C+D">Dario Piga</a>, 
<a href="/search/cs?searchtype=author&query=Umberto%2C+M">Michelucci Umberto</a>, 
<a href="/search/cs?searchtype=author&query=Safouane%2C+E+G">El Ghazouali Safouane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Expert Systems and Applications. Under license CC-BY-NC-ND
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13956" title="Abstract">arXiv:2402.13956</a> (replaced) [<a href="/pdf/2402.13956" title="Download PDF">pdf</a>, <a href="/format/2402.13956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can You Learn Semantics Through Next-Word Prediction? The Case of  Entailment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Merrill%2C+W">William Merrill</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhaofeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Naka%2C+N">Norihito Naka</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Linzen%2C+T">Tal Linzen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14041" title="Abstract">arXiv:2402.14041</a> (replaced) [<a href="/pdf/2402.14041" title="Download PDF">pdf</a>, <a href="/ps/2402.14041" title="Download PostScript">ps</a>, <a href="/format/2402.14041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E2USD: Efficient-yet-effective Unsupervised State Detection for  Multivariate Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+Z">Zhichen Lai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dalin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+W">Weizhu Qian</a>, 
<a href="/search/cs?searchtype=author&query=Jensen%2C+C+S">Christian S. Jensen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by The Web Conference 2024 (WWW 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14042" title="Abstract">arXiv:2402.14042</a> (replaced) [<a href="/pdf/2402.14042" title="Download PDF">pdf</a>, <a href="/format/2402.14042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Protect and Extend -- Using GANs for Synthetic Data Generation of  Time-Series Medical Records
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ashrafi%2C+N">Navid Ashrafi</a>, 
<a href="/search/cs?searchtype=author&query=Schmitt%2C+V">Vera Schmitt</a>, 
<a href="/search/cs?searchtype=author&query=Spang%2C+R+P">Robert P. Spang</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%B6ller%2C+S">Sebastian M&#xf6;ller</a>, 
<a href="/search/cs?searchtype=author&query=Voigt-Antons%2C+J">Jan-Niklas Voigt-Antons</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14270" title="Abstract">arXiv:2402.14270</a> (replaced) [<a href="/pdf/2402.14270" title="Download PDF">pdf</a>, <a href="/format/2402.14270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Take the Bull by the Horns: Hard Sample-Reweighted Continual Training  Improves LLM Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuxi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhendong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sow%2C+D">Daouda Sow</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Junjie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianlong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yingbin Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mingyuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint; updated reference and related works
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14576" title="Abstract">arXiv:2402.14576</a> (replaced) [<a href="/pdf/2402.14576" title="Download PDF">pdf</a>, <a href="/format/2402.14576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge Caching Based on Deep Reinforcement Learning and Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niknia%2C+F">Farnaz Niknia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Ping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zixu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+A">Aakash Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Rezaei%2C+A+S">Adib S. Rezaei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14591" title="Abstract">arXiv:2402.14591</a> (replaced) [<a href="/pdf/2402.14591" title="Download PDF">pdf</a>, <a href="/format/2402.14591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Speed Detector For Low-Powered Devices In Aerial Grasping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Ashish Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Behera%2C+L">Laxmidhar Behera</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 Pages, 9 Figures, 8 Tables, IEEE Robotics and Automation Letters (IEEE RA-L)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14875" title="Abstract">arXiv:2402.14875</a> (replaced) [<a href="/pdf/2402.14875" title="Download PDF">pdf</a>, <a href="/format/2402.14875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What&#x27;s in a Name? Auditing Large Language Models for Race and Gender  Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haim%2C+A">Amit Haim</a>, 
<a href="/search/cs?searchtype=author&query=Salinas%2C+A">Alejandro Salinas</a>, 
<a href="/search/cs?searchtype=author&query=Nyarko%2C+J">Julian Nyarko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 9 tables, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14978" title="Abstract">arXiv:2402.14978</a> (replaced) [<a href="/pdf/2402.14978" title="Download PDF">pdf</a>, <a href="/format/2402.14978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-Augmented Brainwriting: Investigating the use of LLMs in group  ideation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaer%2C+O">Orit Shaer</a>, 
<a href="/search/cs?searchtype=author&query=Cooper%2C+A">Angelora Cooper</a>, 
<a href="/search/cs?searchtype=author&query=Mokryn%2C+O">Osnat Mokryn</a>, 
<a href="/search/cs?searchtype=author&query=Kun%2C+A+L">Andrew L. Kun</a>, 
<a href="/search/cs?searchtype=author&query=Shoshan%2C+H+B">Hagit Ben Shoshan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conditionally Accepted to CHI24. 27 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15021" title="Abstract">arXiv:2402.15021</a> (replaced) [<a href="/pdf/2402.15021" title="Download PDF">pdf</a>, <a href="/format/2402.15021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLoVe: Encoding Compositional Language in Contrastive Vision-Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castro%2C+S">Santiago Castro</a>, 
<a href="/search/cs?searchtype=author&query=Ziai%2C+A">Amir Ziai</a>, 
<a href="/search/cs?searchtype=author&query=Saluja%2C+A">Avneesh Saluja</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhuoning Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Mihalcea%2C+R">Rada Mihalcea</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15160" title="Abstract">arXiv:2402.15160</a> (replaced) [<a href="/pdf/2402.15160" title="Download PDF">pdf</a>, <a href="/format/2402.15160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatially-Aware Transformer for Embodied Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+J">Junmo Cho</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J">Jaesik Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+S">Sungjin Ahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024 Spotlight. First two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15302" title="Abstract">arXiv:2402.15302</a> (replaced) [<a href="/pdf/2402.15302" title="Download PDF">pdf</a>, <a href="/format/2402.15302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How (un)ethical are instruction-centric responses of LLMs? Unveiling the  vulnerabilities of safety guardrails to harmful queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Somnath Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Layek%2C+S">Sayan Layek</a>, 
<a href="/search/cs?searchtype=author&query=Hazra%2C+R">Rima Hazra</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+A">Animesh Mukherjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review. {<a href="https://huggingface.co/datasets/SoftMINER-Group/TechHazardQA">this https URL</a>}
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15481" title="Abstract">arXiv:2402.15481</a> (replaced) [<a href="/pdf/2402.15481" title="Download PDF">pdf</a>, <a href="/format/2402.15481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prejudice and Caprice: A Statistical Framework for Measuring Social  Discrimination in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiran Liu</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Ke Yang</a> (1 and 3), 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zehan Qi</a> (2), 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a> (2), 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yang Yu</a> (2), 
<a href="/search/cs?searchtype=author&query=Zhai%2C+C">Chengxiang Zhai</a> (3) ((1) Equal contributions, (2) Tsinghua University, (3) University of Illinois Urbana-Champaign)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15830" title="Abstract">arXiv:2402.15830</a> (replaced) [<a href="/pdf/2402.15830" title="Download PDF">pdf</a>, <a href="/format/2402.15830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Swarm Body: Embodied Swarm Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ichihashi%2C+S">Sosuke Ichihashi</a>, 
<a href="/search/cs?searchtype=author&query=Kuroki%2C+S">So Kuroki</a>, 
<a href="/search/cs?searchtype=author&query=Nishimura%2C+M">Mai Nishimura</a>, 
<a href="/search/cs?searchtype=author&query=Kasaura%2C+K">Kazumi Kasaura</a>, 
<a href="/search/cs?searchtype=author&query=Hiraki%2C+T">Takefumi Hiraki</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+K">Kazutoshi Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Yoshida%2C+S">Shigeo Yoshida</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Emerging Technologies (cs.ET); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15852" title="Abstract">arXiv:2402.15852</a> (replaced) [<a href="/pdf/2402.15852" title="Download PDF">pdf</a>, <a href="/format/2402.15852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NaVid: Video-based VLM Plans the Next Step for Vision-and-Language  Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiazhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kunyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Rongtao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Gengze Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yicong Hong</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+X">Xiaomeng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhizheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wang He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15861" title="Abstract">arXiv:2402.15861</a> (replaced) [<a href="/pdf/2402.15861" title="Download PDF">pdf</a>, <a href="/format/2402.15861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MATHWELL: Generating Educational Math Word Problems at Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Christ%2C+B+R">Bryan R Christ</a>, 
<a href="/search/cs?searchtype=author&query=Kropko%2C+J">Jonathan Kropko</a>, 
<a href="/search/cs?searchtype=author&query=Hartvigsen%2C+T">Thomas Hartvigsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15987" title="Abstract">arXiv:2402.15987</a> (replaced) [<a href="/pdf/2402.15987" title="Download PDF">pdf</a>, <a href="/format/2402.15987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Likelihood-based Mitigation of Evaluation Bias in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ohi%2C+M">Masanari Ohi</a>, 
<a href="/search/cs?searchtype=author&query=Kaneko%2C+M">Masahiro Kaneko</a>, 
<a href="/search/cs?searchtype=author&query=Koike%2C+R">Ryuto Koike</a>, 
<a href="/search/cs?searchtype=author&query=Loem%2C+M">Mengsay Loem</a>, 
<a href="/search/cs?searchtype=author&query=Okazaki%2C+N">Naoaki Okazaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 main pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15997" title="Abstract">arXiv:2402.15997</a> (replaced) [<a href="/pdf/2402.15997" title="Download PDF">pdf</a>, <a href="/format/2402.15997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cieran: Designing Sequential Colormaps via In-Situ Active Preference  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+M">Matt-Heun Hong</a>, 
<a href="/search/cs?searchtype=author&query=Sunberg%2C+Z+N">Zachary N. Sunberg</a>, 
<a href="/search/cs?searchtype=author&query=Szafir%2C+D+A">Danielle Albers Szafir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CHI 2024. 12 pages/9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16914" title="Abstract">arXiv:2402.16914</a> (replaced) [<a href="/pdf/2402.16914" title="Download PDF">pdf</a>, <a href="/format/2402.16914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLM  Jailbreakers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xirui Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruochen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Minhao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+C">Cho-Jui Hsieh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17322" title="Abstract">arXiv:2402.17322</a> (replaced) [<a href="/pdf/2402.17322" title="Download PDF">pdf</a>, <a href="/format/2402.17322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enclosing Points with Geometric Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chan%2C+T+M">Timothy M. Chan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qizheng He</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Jie Xue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In SoCG'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17944" title="Abstract">arXiv:2402.17944</a> (replaced) [<a href="/pdf/2402.17944" title="Download PDF">pdf</a>, <a href="/format/2402.17944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models(LLMs) on Tabular Data: Prediction, Generation, and  Understanding -- A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+X">Xi Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weijie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+F+A">Fiona Anting Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiani Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Ziqing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yanjun Qi</a>, 
<a href="/search/cs?searchtype=author&query=Nickleach%2C+S">Scott Nickleach</a>, 
<a href="/search/cs?searchtype=author&query=Socolinsky%2C+D">Diego Socolinsky</a>, 
<a href="/search/cs?searchtype=author&query=Sengamedu%2C+S">Srinivasan Sengamedu</a>, 
<a href="/search/cs?searchtype=author&query=Faloutsos%2C+C">Christos Faloutsos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 4 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17978" title="Abstract">arXiv:2402.17978</a> (replaced) [<a href="/pdf/2402.17978" title="Download PDF">pdf</a>, <a href="/format/2402.17978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imagine, Initialize, and Explore: An Effective Exploration Method in  Multi-Agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zeyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+L">Lipeng Wan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinrui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuoran Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xingyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+X">Xuguang Lan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 38th Annual AAAI Conference on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17992" title="Abstract">arXiv:2402.17992</a> (replaced) [<a href="/pdf/2402.17992" title="Download PDF">pdf</a>, <a href="/ps/2402.17992" title="Download PostScript">ps</a>, <a href="/format/2402.17992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Informed Machine Learning for Seismic Response Prediction OF  Nonlinear Steel Moment Resisting Frame Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Bond%2C+R+B">R. Bailey Bond</a>, 
<a href="/search/physics?searchtype=author&query=Ren%2C+P">Pu Ren</a>, 
<a href="/search/physics?searchtype=author&query=Hajjar%2C+J+F">Jerome F. Hajjar</a>, 
<a href="/search/physics?searchtype=author&query=Sun%2C+H">Hao Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applied Physics (physics.app-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18045" title="Abstract">arXiv:2402.18045</a> (replaced) [<a href="/pdf/2402.18045" title="Download PDF">pdf</a>, <a href="/format/2402.18045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-FAct: Assessing Multilingual LLMs&#x27; Multi-Regional Knowledge using  FActScore
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shafayat%2C+S">Sheikh Shafayat</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+E">Eunsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+J">Juhyun Oh</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+A">Alice Oh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18146" title="Abstract">arXiv:2402.18146</a> (replaced) [<a href="/pdf/2402.18146" title="Download PDF">pdf</a>, <a href="/ps/2402.18146" title="Download PostScript">ps</a>, <a href="/format/2402.18146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3DSFLabelling: Boosting 3D Scene Flow Estimation by Pseudo  Auto-labelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chaokang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guangming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiuming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hesheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhuang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenqiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zhujin Liang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Yi Shan</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+D">Dalong Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR2024! 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18162" title="Abstract">arXiv:2402.18162</a> (replaced) [<a href="/pdf/2402.18162" title="Download PDF">pdf</a>, <a href="/format/2402.18162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Out-of-Distribution Detection using Neural Activation Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+W">Weilin Wan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weizhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Cheng Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18233" title="Abstract">arXiv:2402.18233</a> (replaced) [<a href="/pdf/2402.18233" title="Download PDF">pdf</a>, <a href="/format/2402.18233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Aerial Object Detection with Visual Description Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zang%2C+Z">Zhengqing Zang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chenwei Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+J">Jiancheng Lv</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18294" title="Abstract">arXiv:2402.18294</a> (replaced) [<a href="/pdf/2402.18294" title="Download PDF">pdf</a>, <a href="/format/2402.18294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Whole-body Humanoid Robot Locomotion with Human Reference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+P">Peter Cui</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+D">David Yan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jingkai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yiqun Duan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Arthur Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Renjing Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18469" title="Abstract">arXiv:2402.18469</a> (replaced) [<a href="/pdf/2402.18469" title="Download PDF">pdf</a>, <a href="/ps/2402.18469" title="Download PostScript">ps</a>, <a href="/format/2402.18469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interval-Constrained Bipartite Matching over Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abels%2C+A">Andreas Abels</a>, 
<a href="/search/cs?searchtype=author&query=Anapolska%2C+M">Mariia Anapolska</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18609" title="Abstract">arXiv:2402.18609</a> (replaced) [<a href="/pdf/2402.18609" title="Download PDF">pdf</a>, <a href="/format/2402.18609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ICE-SEARCH: A Language Model-Driven Feature Selection Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tianze Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tianyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shaoshan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lvu%2C+F">Fuyuan Lvu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xue Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18678" title="Abstract">arXiv:2402.18678</a> (replaced) [<a href="/pdf/2402.18678" title="Download PDF">pdf</a>, <a href="/format/2402.18678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RORA: Robust Free-Text Rationale Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhengping Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yining Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hanjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Khashabi%2C+D">Daniel Khashabi</a>, 
<a href="/search/cs?searchtype=author&query=Van+Durme%2C+B">Benjamin Van Durme</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Anqi Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18826" title="Abstract">arXiv:2402.18826</a> (replaced) [<a href="/pdf/2402.18826" title="Download PDF">pdf</a>, <a href="/ps/2402.18826" title="Download PostScript">ps</a>, <a href="/format/2402.18826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Machine Can&#x27;t Replace the Human Heart
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Baihan Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18838" title="Abstract">arXiv:2402.18838</a> (replaced) [<a href="/pdf/2402.18838" title="Download PDF">pdf</a>, <a href="/format/2402.18838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When does word order matter and when doesn&#x27;t it?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuanda Chen</a>, 
<a href="/search/cs?searchtype=author&query=O%27Donnell%2C+T">Timothy O&#x27;Donnell</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+S">Siva Reddy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18888" title="Abstract">arXiv:2402.18888</a> (replaced) [<a href="/pdf/2402.18888" title="Download PDF">pdf</a>, <a href="/format/2402.18888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-Based Extensible Codebook for Discrete Federated Learning in  Heterogeneous Data Silos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dianbo Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18929" title="Abstract">arXiv:2402.18929</a> (replaced) [<a href="/pdf/2402.18929" title="Download PDF">pdf</a>, <a href="/format/2402.18929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating Beyond Dropout: An Intriguing Solution Towards Generalizable  Image Super Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongjun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yinqiang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+T">Tieyong Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19062" title="Abstract">arXiv:2402.19062</a> (replaced) [<a href="/pdf/2402.19062" title="Download PDF">pdf</a>, <a href="/format/2402.19062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Convolutional Neural Networks for Automated Echocardiography View  Recognition: A Holistic Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Thomas%2C+S">Sarina Thomas</a>, 
<a href="/search/eess?searchtype=author&query=Tiago%2C+C">Cristiana Tiago</a>, 
<a href="/search/eess?searchtype=author&query=Andreassen%2C+B+S">B&#xf8;rge Solli Andreassen</a>, 
<a href="/search/eess?searchtype=author&query=Aase%2C+S+A">Svein Arne Aase</a>, 
<a href="/search/eess?searchtype=author&query=%C5%A0prem%2C+J">Jurica &#x160;prem</a>, 
<a href="/search/eess?searchtype=author&query=Steen%2C+E">Erik Steen</a>, 
<a href="/search/eess?searchtype=author&query=Solberg%2C+A">Anne Solberg</a>, 
<a href="/search/eess?searchtype=author&query=Ben-Yosef%2C+G">Guy Ben-Yosef</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at ASMUS - MICCAI conference 2023, Vancouver
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19282" title="Abstract">arXiv:2402.19282</a> (replaced) [<a href="/pdf/2402.19282" title="Download PDF">pdf</a>, <a href="/format/2402.19282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WanJuan-CC: A Safe and High-Quality Open-sourced English Webtext Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jiantao Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+H">Haijun Lv</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhenjiang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+W">Wenchang Ning</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jia Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">ChaoBin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+P">Pei Chu</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yuan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+R">Runyu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhiyuan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Huanze Tang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Z">Zhikai Lei</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Jiawei Hong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Keyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+Z">Zhaoye Fei</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruiliang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hang Yan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19350" title="Abstract">arXiv:2402.19350</a> (replaced) [<a href="/pdf/2402.19350" title="Download PDF">pdf</a>, <a href="/format/2402.19350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompting Explicit and Implicit Knowledge for Multi-hop Question  Answering Based on Human Reading Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Guangming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+Y">Yunfei Long</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Cunjin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jiaxing Shen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xia Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted at LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19422" title="Abstract">arXiv:2402.19422</a> (replaced) [<a href="/pdf/2402.19422" title="Download PDF">pdf</a>, <a href="/format/2402.19422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PEM: Prototype-based Efficient MaskFormer for Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cavagnero%2C+N">Niccol&#xf2; Cavagnero</a>, 
<a href="/search/cs?searchtype=author&query=Rosi%2C+G">Gabriele Rosi</a>, 
<a href="/search/cs?searchtype=author&query=Cuttano%2C+C">Claudia Cuttano</a>, 
<a href="/search/cs?searchtype=author&query=Pistilli%2C+F">Francesca Pistilli</a>, 
<a href="/search/cs?searchtype=author&query=Ciccone%2C+M">Marco Ciccone</a>, 
<a href="/search/cs?searchtype=author&query=Averta%2C+G">Giuseppe Averta</a>, 
<a href="/search/cs?searchtype=author&query=Cermelli%2C+F">Fabio Cermelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19434" title="Abstract">arXiv:2402.19434</a> (replaced) [<a href="/pdf/2402.19434" title="Download PDF">pdf</a>, <a href="/format/2402.19434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital Twin Aided Massive MIMO: CSI Compression and Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shuaifeng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Alkhateeb%2C+A">Ahmed Alkhateeb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICC 2024. Dataset and code files will be available soon on the DeepMIMO website <a href="https://www.deepmimo.net/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19457" title="Abstract">arXiv:2402.19457</a> (replaced) [<a href="/pdf/2402.19457" title="Download PDF">pdf</a>, <a href="/format/2402.19457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $\texttt{COSMIC}$: Mutual Information for Task-Agnostic Summarization  Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Darrin%2C+M">Maxime Darrin</a>, 
<a href="/search/cs?searchtype=author&query=Formont%2C+P">Philippe Formont</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+J+C+K">Jackie Chi Kit Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Piantanida%2C+P">Pablo Piantanida</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19467" title="Abstract">arXiv:2402.19467</a> (replaced) [<a href="/pdf/2402.19467" title="Download PDF">pdf</a>, <a href="/format/2402.19467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanders%2C+K">Kate Sanders</a>, 
<a href="/search/cs?searchtype=author&query=Weir%2C+N">Nathaniel Weir</a>, 
<a href="/search/cs?searchtype=author&query=Van+Durme%2C+B">Benjamin Van Durme</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item309">Cross-lists</a></li>
<li><a href="#item350">Replacements</a></li>
</ul>
<small>[ total of 563 entries:  <b>1-563</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2403">2403</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
