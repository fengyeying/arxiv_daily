<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Mon  4 Mar 24  to  Tue  5 Mar 24, announced Wed,  6 Mar 24</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item364">Cross-lists</a></li>
<li><a href="#item415">Replacements</a></li>
</ul>
<small>[ total of 684 entries:  <b>1-684</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Wed,  6 Mar 24</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02347" title="Abstract">arXiv:2403.02347</a> [<a href="/pdf/2403.02347" title="Download PDF">pdf</a>, <a href="/format/2403.02347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Convergence of Federated Learning Algorithms without Data  Similarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beikmohammadi%2C+A">Ali Beikmohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Khirirat%2C+S">Sarit Khirirat</a>, 
<a href="/search/cs?searchtype=author&query=Magn%C3%BAsson%2C+S">Sindri Magn&#xfa;sson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Data similarity assumptions have traditionally been relied upon to understand
the convergence behaviors of federated learning methods. Unfortunately, this
approach often demands fine-tuning step sizes based on the level of data
similarity. When data similarity is low, these small step sizes result in an
unacceptably slow convergence speed for federated methods. In this paper, we
present a novel and unified framework for analyzing the convergence of
federated learning algorithms without the need for data similarity conditions.
Our analysis centers on an inequality that captures the influence of step sizes
on algorithmic convergence performance. By applying our theorems to well-known
federated algorithms, we derive precise expressions for three widely used step
size schedules: fixed, diminishing, and step-decay step sizes, which are
independent of data similarity conditions. Finally, we conduct comprehensive
evaluations of the performance of these federated learning algorithms,
employing the proposed step size strategies to train deep neural network models
on benchmark datasets under varying data similarity conditions. Our findings
demonstrate significant improvements in convergence speed and overall
performance, marking a substantial advancement in federated learning research.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02352" title="Abstract">arXiv:2403.02352</a> [<a href="/pdf/2403.02352" title="Download PDF">pdf</a>, <a href="/format/2403.02352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ATP: Enabling Fast LLM Serving via Attention on Top Principal Keys
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yue Niu</a>, 
<a href="/search/cs?searchtype=author&query=Prakash%2C+S">Saurav Prakash</a>, 
<a href="/search/cs?searchtype=author&query=Avestimehr%2C+S">Salman Avestimehr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We propose a new attention mechanism with linear complexity, ATP, that
fixates \textbf{A}ttention on \textbf{T}op \textbf{P}rincipal keys, rather than
on each individual token. Particularly, ATP is driven by an important
observation that input sequences are typically low-rank, i.e., input sequences
can be represented by a few principal bases. Therefore, instead of directly
iterating over all the input tokens, ATP transforms inputs into an orthogonal
space and computes attention only on the top principal bases (keys). Owing to
the observed low-rank structure in input sequences, ATP is able to capture
semantic relationships in input sequences with a few principal keys.
Furthermore, the attention complexity is reduced from \emph{quadratic} to
\emph{linear} without incurring a noticeable performance drop. ATP further
reduces complexity for other linear layers with low-rank inputs, leading to
more speedup compared to prior works that solely target the attention module.
Our evaluations on various models (e.g., BERT and Llama) demonstrate that ATP
achieves comparable accuracy with much lower computation and memory complexity
than the standard attention mechanism. In particular, ATP barely loses accuracy
with only $1/2$ principal keys, and only incurs around $2\%$ accuracy drops
with $1/4$ principal keys.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02354" title="Abstract">arXiv:2403.02354</a> [<a href="/pdf/2403.02354" title="Download PDF">pdf</a>, <a href="/format/2403.02354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatio-Temporal Field Neural Networks for Air Quality Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yutong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiongyan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yutong Xia</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Junlin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+S">Siru Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Shifen Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuxuan Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The air quality inference problem aims to utilize historical data from a
limited number of observation sites to infer the air quality index at an
unknown location. Considering the sparsity of data due to the high maintenance
cost of the stations, good inference algorithms can effectively save the cost
and refine the data granularity. While spatio-temporal graph neural networks
have made excellent progress on this problem, their non-Euclidean and discrete
data structure modeling of reality limits its potential. In this work, we make
the first attempt to combine two different spatio-temporal perspectives, fields
and graphs, by proposing a new model, Spatio-Temporal Field Neural Network, and
its corresponding new framework, Pyramidal Inference. Extensive experiments
validate that our model achieves state-of-the-art performance in nationwide air
quality inference in the Chinese Mainland, demonstrating the superiority of our
proposed model and framework.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02355" title="Abstract">arXiv:2403.02355</a> [<a href="/pdf/2403.02355" title="Download PDF">pdf</a>, <a href="/format/2403.02355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Knowledge Graph Completion with Time-sensitive Relations in  Hypercomplex Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+L">Li Cai</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+X">Xin Mao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhihong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shangqing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuhao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Changxu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+M">Man Lan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Temporal knowledge graph completion (TKGC) aims to fill in missing facts
within a given temporal knowledge graph at a specific time. Existing methods,
operating in real or complex spaces, have demonstrated promising performance in
this task. This paper advances beyond conventional approaches by introducing
more expressive quaternion representations for TKGC within hypercomplex space.
Unlike existing quaternion-based methods, our study focuses on capturing
time-sensitive relations rather than time-aware entities. Specifically, we
model time-sensitive relations through time-aware rotation and periodic time
translation, effectively capturing complex temporal variability. Furthermore,
we theoretically demonstrate our method's capability to model symmetric,
asymmetric, inverse, compositional, and evolutionary relation patterns.
Comprehensive experiments on public datasets validate that our proposed
approach achieves state-of-the-art performance in the field of TKGC.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02360" title="Abstract">arXiv:2403.02360</a> [<a href="/pdf/2403.02360" title="Download PDF">pdf</a>, <a href="/format/2403.02360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Optimal Customized Architecture for Heterogeneous Federated  Learning with Contrastive Cloud-Edge Model Decoupling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xingyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+T">Tian Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+T">Tiancheng Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Kou%2C+G">Gang Kou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Changqiao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D+O">Dapeng Oliver Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated learning, as a promising distributed learning paradigm, enables
collaborative training of a global model across multiple network edge clients
without the need for central data collecting. However, the heterogeneity of
edge data distribution drags the model towards the local minima, which can be
distant from the global optimum. Such heterogeneity often leads to slow
convergence and substantial communication overhead. To address these issues, we
propose a novel federated learning framework called FedCMD, a model decoupling
tailored to the Cloud-edge supported federated learning that separates deep
neural networks into a body for capturing shared representations in Cloud and a
personalized head for migrating data heterogeneity. Our motivation is that, by
the deep investigation of the performance of selecting different neural network
layers as the personalized head, we found rigidly assigning the last layer as
the personalized head in current studies is not always optimal. Instead, it is
necessary to dynamically select the personalized layer that maximizes the
training performance by taking the representation difference between neighbor
layers into account. To find the optimal personalized layer, we utilize the
low-dimensional representation of each layer to contrast feature distribution
transfer and introduce a Wasserstein-based layer selection method, aimed at
identifying the best-match layer for personalization. Additionally, a weighted
global aggregation algorithm is proposed based on the selected personalized
layer for the practical application of FedCMD. Extensive experiments on ten
benchmarks demonstrate the efficiency and superior performance of our solution
compared with nine state-of-the-art solutions. All code and results are
available at https://github.com/elegy112138/FedCMD.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02363" title="Abstract">arXiv:2403.02363</a> [<a href="/pdf/2403.02363" title="Download PDF">pdf</a>, <a href="/format/2403.02363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Addressing Long-Tail Noisy Label Learning Problems: a Two-Stage Solution  with Label Refurbishment Considering Label Rarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Ying-Hsuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+J">Jun-Wei Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+L">Li Xin</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+S">Shin-You Teng</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+Y">Yi-Kuan Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+M">Ming-Ching Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Real-world datasets commonly exhibit noisy labels and class imbalance, such
as long-tailed distributions. While previous research addresses this issue by
differentiating noisy and clean samples, reliance on information from
predictions based on noisy long-tailed data introduces potential errors. To
overcome the limitations of prior works, we introduce an effective two-stage
approach by combining soft-label refurbishing with multi-expert ensemble
learning. In the first stage of robust soft label refurbishing, we acquire
unbiased features through contrastive learning, making preliminary predictions
using a classifier trained with a carefully designed BAlanced Noise-tolerant
Cross-entropy (BANC) loss. In the second stage, our label refurbishment method
is applied to obtain soft labels for multi-expert ensemble learning, providing
a principled solution to the long-tail noisy label problem. Experiments
conducted across multiple benchmarks validate the superiority of our approach,
Label Refurbishment considering Label Rarity (LR^2), achieving remarkable
accuracies of 94.19% and 77.05% on simulated noisy CIFAR-10 and CIFAR-100
long-tail datasets, as well as 77.74% and 81.40% on real-noise long-tail
datasets, Food-101N and Animal-10N, surpassing existing state-of-the-art
methods.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02366" title="Abstract">arXiv:2403.02366</a> [<a href="/pdf/2403.02366" title="Download PDF">pdf</a>, <a href="/format/2403.02366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Evaluation of English--Irish Transformer-Based NMT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lankford%2C+S">S&#xe9;amus Lankford</a>, 
<a href="/search/cs?searchtype=author&query=Afli%2C+H">Haithem Afli</a>, 
<a href="/search/cs?searchtype=author&query=Way%2C+A">Andy Way</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2403.01985">arXiv:2403.01985</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Information 2022, 13(7), 309
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this study, a human evaluation is carried out on how hyperparameter
settings impact the quality of Transformer-based Neural Machine Translation
(NMT) for the low-resourced English--Irish pair. SentencePiece models using
both Byte Pair Encoding (BPE) and unigram approaches were appraised. Variations
in model architectures included modifying the number of layers, evaluating the
optimal number of heads for attention and testing various regularisation
techniques. The greatest performance improvement was recorded for a
Transformer-optimized model with a 16k BPE subword model. Compared with a
baseline Recurrent Neural Network (RNN) model, a Transformer-optimized model
demonstrated a BLEU score improvement of 7.8 points. When benchmarked against
Google Translate, our translation engines demonstrated significant
improvements. Furthermore, a quantitative fine-grained manual evaluation was
conducted which compared the performance of machine translation systems. Using
the Multidimensional Quality Metrics (MQM) error taxonomy, a human evaluation
of the error types generated by an RNN-based system and a Transformer-based
system was explored. Our findings show the best-performing Transformer system
significantly reduces both accuracy and fluency errors when compared with an
RNN-based model.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02367" title="Abstract">arXiv:2403.02367</a> [<a href="/pdf/2403.02367" title="Download PDF">pdf</a>, <a href="/format/2403.02367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> adaptNMT: an open-source, language-agnostic development environment for  Neural Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lankford%2C+S">S&#xe9;amus Lankford</a>, 
<a href="/search/cs?searchtype=author&query=Afli%2C+H">Haithem Afli</a>, 
<a href="/search/cs?searchtype=author&query=Way%2C+A">Andy Way</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Language Resources and Evaluation 57, 1671-1696, (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">adaptNMT streamlines all processes involved in the development and deployment
of RNN and Transformer neural translation models. As an open-source
application, it is designed for both technical and non-technical users who work
in the field of machine translation. Built upon the widely-adopted OpenNMT
ecosystem, the application is particularly useful for new entrants to the field
since the setup of the development environment and creation of train,
validation and test splits is greatly simplified. Graphing, embedded within the
application, illustrates the progress of model training, and SentencePiece is
used for creating subword segmentation models. Hyperparameter customization is
facilitated through an intuitive user interface, and a single-click model
development approach has been implemented. Models developed by adaptNMT can be
evaluated using a range of metrics, and deployed as a translation service
within the application. To support eco-friendly research in the NLP space, a
green report also flags the power consumption and kgCO$_{2}$ emissions
generated during model development. The application is freely available.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02368" title="Abstract">arXiv:2403.02368</a> [<a href="/pdf/2403.02368" title="Download PDF">pdf</a>, <a href="/ps/2403.02368" title="Download PostScript">ps</a>, <a href="/format/2403.02368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Hybrid Feature Importance and Feature Interaction Detection  Framework for Predictive Optimization in Industry 4.0 Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhipeng Ma</a>, 
<a href="/search/cs?searchtype=author&query=J%C3%B8rgensen%2C+B+N">Bo N&#xf8;rregaard J&#xf8;rgensen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z+G">Zheng Grace Ma</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IECON 2023- 49th Annual Conference of the IEEE Industrial
  Electronics Society
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Advanced machine learning algorithms are increasingly utilized to provide
data-based prediction and decision-making support in Industry 4.0. However, the
prediction accuracy achieved by the existing models is insufficient to warrant
practical implementation in real-world applications. This is because not all
features present in real-world datasets possess a direct relevance to the
predictive analysis being conducted. Consequently, the careful incorporation of
select features has the potential to yield a substantial positive impact on the
outcome. To address the research gap, this paper proposes a novel hybrid
framework that combines the feature importance detector - local interpretable
model-agnostic explanations (LIME) and the feature interaction detector -
neural interaction detection (NID), to improve prediction accuracy. By applying
the proposed framework, unnecessary features can be eliminated, and
interactions are encoded to generate a more conducive dataset for predictive
purposes. Subsequently, the proposed model is deployed to refine the prediction
of electricity consumption in foundry processing. The experimental outcomes
reveal an augmentation of up to 9.56% in the R2 score, and a diminution of up
to 24.05% in the root mean square error.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02369" title="Abstract">arXiv:2403.02369</a> [<a href="/pdf/2403.02369" title="Download PDF">pdf</a>, <a href="/format/2403.02369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-agent Reinforcement Learning Study of Evolution of Communication  and Teaching under Libertarian and Utilitarian Governing Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dizaji%2C+A+S">Aslan S. Dizaji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">Laboratory experiments have shown that communication plays an important role
in solving social dilemmas. Here, by extending the AI-Economist, a mixed motive
multi-agent reinforcement learning environment, I intend to find an answer to
the following descriptive question: which governing system does facilitate the
emergence and evolution of communication and teaching among agents? To answer
this question, the AI-Economist is extended by a voting mechanism to simulate
three different governing systems across individualistic-collectivistic axis,
from full-libertarian to Full-Utilitarian governing systems. Moreover, the
AI-Economist is further extended to include communication with possible
misalignment, a variant of signalling game, by letting agents to build houses
together if they are able to name mutually complement material resources by the
same letter. Moreover, another extension is made to the AI-Economist to include
teaching with possible misalignment, again a variant of signalling game, by
letting half the agents as teachers who know how to use mutually complement
material resources to build houses but are not capable of building actual
houses, and the other half as students who do not have this information but are
able to actually build those houses if teachers teach them. I found a strong
evidence that collectivistic environment such as Full-Utilitarian system is
more favourable for the emergence of communication and teaching, or more
precisely, evolution of language alignment. Moreover, I found some evidence
that evolution of language alignment through communication and teaching under
collectivistic governing systems makes individuals more advantageously inequity
averse. As a result, there is a positive correlation between evolution of
language alignment and equality in the society.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02370" title="Abstract">arXiv:2403.02370</a> [<a href="/pdf/2403.02370" title="Download PDF">pdf</a>, <a href="/format/2403.02370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> adaptMLLM: Fine-Tuning Multilingual Language Models on Low-Resource  Languages with Integrated LLM Playgrounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lankford%2C+S">S&#xe9;amus Lankford</a>, 
<a href="/search/cs?searchtype=author&query=Afli%2C+H">Haithem Afli</a>, 
<a href="/search/cs?searchtype=author&query=Way%2C+A">Andy Way</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Information 2023, 14(12), 638
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The advent of Multilingual Language Models (MLLMs) and Large Language Models
has spawned innovation in many areas of natural language processing. Despite
the exciting potential of this technology, its impact on developing
high-quality Machine Translation (MT) outputs for low-resource languages
remains relatively under-explored. Furthermore, an open-source application,
dedicated to both fine-tuning MLLMs and managing the complete MT workflow for
low-resources languages, remains unavailable. We aim to address these
imbalances through the development of adaptMLLM, which streamlines all
processes involved in the fine-tuning of MLLMs for MT. This open-source
application is tailored for developers, translators, and users who are engaged
in MT. An intuitive interface allows for easy customisation of hyperparameters,
and the application offers a range of metrics for model evaluation and the
capability to deploy models as a translation service directly within the
application. As a multilingual tool, we used adaptMLLM to fine-tune models for
two low-resource language pairs: English to Irish (EN$\leftrightarrow$GA) and
English to Marathi (EN$\leftrightarrow$MR). Compared with baselines from the
LoResMT2021 Shared Task, the adaptMLLM system demonstrated significant
improvements. In the EN$\rightarrow$GA direction, an improvement of 5.2 BLEU
points was observed and an increase of 40.5 BLEU points was recorded in the
GA$\rightarrow$EN direction. Significant improvements in the translation
performance of the EN$\leftrightarrow$MR pair were also observed notably in the
MR$\rightarrow$EN direction with an increase of 21.3 BLEU points. Finally, a
fine-grained human evaluation of the MLLM output on the EN$\rightarrow$GA pair
was conducted using the Multidimensional Quality Metrics and Scalar Quality
Metrics error taxonomies. The application and models are freely available.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02372" title="Abstract">arXiv:2403.02372</a> [<a href="/pdf/2403.02372" title="Download PDF">pdf</a>, <a href="/format/2403.02372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OTClean: Data Cleaning for Conditional Independence Violations using  Optimal Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pirhadi%2C+A">Alireza Pirhadi</a>, 
<a href="/search/cs?searchtype=author&query=Moslemi%2C+M+H">Mohammad Hossein Moslemi</a>, 
<a href="/search/cs?searchtype=author&query=Cloninger%2C+A">Alexander Cloninger</a>, 
<a href="/search/cs?searchtype=author&query=Milani%2C+M">Mostafa Milani</a>, 
<a href="/search/cs?searchtype=author&query=Salimi%2C+B">Babak Salimi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB)

</div>
<p class="mathjax">Ensuring Conditional Independence (CI) constraints is pivotal for the
development of fair and trustworthy machine learning models. In this paper, we
introduce \sys, a framework that harnesses optimal transport theory for data
repair under CI constraints. Optimal transport theory provides a rigorous
framework for measuring the discrepancy between probability distributions,
thereby ensuring control over data utility. We formulate the data repair
problem concerning CIs as a Quadratically Constrained Linear Program (QCLP) and
propose an alternating method for its solution. However, this approach faces
scalability issues due to the computational cost associated with computing
optimal transport distances, such as the Wasserstein distance. To overcome
these scalability challenges, we reframe our problem as a regularized
optimization problem, enabling us to develop an iterative algorithm inspired by
Sinkhorn's matrix scaling algorithm, which efficiently addresses
high-dimensional and large-scale data. Through extensive experiments, we
demonstrate the efficacy and efficiency of our proposed methods, showcasing
their practical utility in real-world data cleaning and preprocessing tasks.
Furthermore, we provide comparisons with traditional approaches, highlighting
the superiority of our techniques in terms of preserving data utility while
ensuring adherence to the desired CI constraints.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02409" title="Abstract">arXiv:2403.02409</a> [<a href="/pdf/2403.02409" title="Download PDF">pdf</a>, <a href="/ps/2403.02409" title="Download PostScript">ps</a>, <a href="/format/2403.02409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Respecting Type Error Telemetry at Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Greenman%2C+B">Ben Greenman</a> (Brown University, USA / University of Utah, USA), 
<a href="/search/cs?searchtype=author&query=Jeffrey%2C+A">Alan Jeffrey</a> (Roblox, USA), 
<a href="/search/cs?searchtype=author&query=Krishnamurthi%2C+S">Shriram Krishnamurthi</a> (Brown University, USA), 
<a href="/search/cs?searchtype=author&query=Shah%2C+M">Mitesh Shah</a> (Roblox, USA)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The Art, Science, and Engineering of Programming, 2024, Vol. 8,
  Issue 3, Article 12
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Context: Roblox Studio lets millions of creators build interactive
experiences by programming in a variant of Lua called Luau. The creators form a
broad group, ranging from novices writing their first script to professional
developers; thus, Luau must support a wide audience. As part of its efforts to
support all kinds of programmers, Luau includes an optional, gradual type
system and goes to great lengths to minimize false positive errors.
<br />Inquiry: Since Luau is currently being used by many creators, we want to
collect data to improve the language and, in particular, the type system. The
standard way to collect data is to deploy client-side telemetry; however, we
cannot scrape personal data or proprietary information, which means we cannot
collect source code fragments, error messages, or even filepaths. The research
questions are thus about how to conduct telemetry that is not invasive and
obtain insights from it about type errors.
<br />Approach: We designed and implemented a pseudonymized, randomly-sampling
telemetry system for Luau. Telemetry records include a timestamp, a session id,
a reason for sending, and a numeric summary of the most recent type analyses.
This information lets us study type errors over time without revealing private
data. We deployed the system in Roblox Studio during Spring 2023 and collected
over 1.5 million telemetry records from over 340,000 sessions.
<br />Knowledge: We present several findings about Luau, all of which suggest that
telemetry is an effective way to study type error pragmatics. One of the
less-surprising findings is that opt-in gradual types are unpopular: there is
an 100x gap between the number of untyped Luau sessions and the number of typed
ones. One surprise is that the strict mode for type analysis is overly
conservative about interactions with data assets. A reassuring finding is that
type analysis rarely hits its internal limits on problem size.
<br />Grounding: Our findings are supported by a dataset of over 1.5 million
telemetry records. The data and scripts for analyzing it are available in an
artifact.
<br />Importance: Beyond the immediate benefits to Luau, our findings about types
and type errors have implications for adoption and ergonomics in other gradual
languages such as TypeScript, Elixir, and Typed Racket. Our telemetry design is
of broad interest, as it reports on type errors without revealing sensitive
information.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02411" title="Abstract">arXiv:2403.02411</a> [<a href="/pdf/2403.02411" title="Download PDF">pdf</a>, <a href="/format/2403.02411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NiNformer: A Network in Network Transformer with Token Mixing Generated  Gating Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdullah%2C+A+N">Abdullah Nazhat Abdullah</a>, 
<a href="/search/cs?searchtype=author&query=Aydin%2C+T">Tarkan Aydin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The Attention mechanism is the main component of the Transformer
architecture, and since its introduction, it has led to significant
advancements in Deep Learning that span many domains and multiple tasks. The
Attention Mechanism was utilized in Computer Vision as the Vision Transformer
ViT, and its usage has expanded into many tasks in the vision domain, such as
classification, segmentation, object detection, and image generation. While
this mechanism is very expressive and capable, it comes with the drawback of
being computationally expensive and requiring datasets of considerable size for
effective optimization. To address these shortcomings, many designs have been
proposed in the literature to reduce the computational burden and alleviate the
data size requirements. Examples of such attempts in the vision domain are the
MLP-Mixer, the Conv-Mixer, the Perciver-IO, and many more. This paper
introduces a new computational block as an alternative to the standard ViT
block that reduces the compute burdens by replacing the normal Attention layers
with a Network in Network structure that enhances the static approach of the
MLP Mixer with a dynamic system of learning an element-wise gating function by
a token mixing process. Extensive experimentation shows that the proposed
design provides better performance than the baseline architectures on multiple
datasets applied in the image classification task of the vision domain.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02416" title="Abstract">arXiv:2403.02416</a> [<a href="/pdf/2403.02416" title="Download PDF">pdf</a>, <a href="/ps/2403.02416" title="Download PostScript">ps</a>, <a href="/format/2403.02416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arrays in Practice: An Empirical Study of Array Access Patterns on the  JVM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%85kerblom%2C+B">Beatrice &#xc5;kerblom</a> (Stockholm University, Sweden), 
<a href="/search/cs?searchtype=author&query=Castegren%2C+E">Elias Castegren</a> (Uppsala University, Sweden)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The Art, Science, and Engineering of Programming, 2024, Vol. 8,
  Issue 3, Article 14
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">The array is a data structure used in a wide range of programs. Its compact
storage and constant time random access makes it highly efficient, but
arbitrary indexing complicates the analysis of code containing array accesses.
Such analyses are important for compiler optimisations such as bounds check
elimination. The aim of this work is to gain a better understanding of how
arrays are used in real-world programs. While previous work has applied static
analyses to understand how arrays are accessed and used, we take a dynamic
approach. We empirically examine various characteristics of array usage by
instrumenting programs to log all array accesses, allowing for analysis of
array sizes, element types, from where arrays are accessed and to which extent
sequences of array accesses form recognizable patterns. The programs in the
study were collected from the Renaissance benchmark suite, all running on the
Java Virtual Machine.
<br />We account for characteristics displayed by the arrays investigated, finding
that most arrays have a small size, are accessed by only one or two classes and
by a single thread. On average over the benchmarks, 69.8% of the access
patterns consist of uncomplicated traversals. Most of the instrumented classes
(over 95%) do not use arrays directly at all. These results come from tracing
data covering 3,803,043,390 array accesses made across 168,686 classes. While
our analysis has only been applied to the Renaissance benchmark suite, the
methodology can be applied to any program running on the Java Virtual Machine.
This study, and the methodology in general, can inform future runtime
implementations and compiler optimisations.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02418" title="Abstract">arXiv:2403.02418</a> [<a href="/pdf/2403.02418" title="Download PDF">pdf</a>, <a href="/format/2403.02418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Zero to Hero: How local curvature at artless initial conditions  leads away from bad minima
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bonnaire%2C+T">Tony Bonnaire</a>, 
<a href="/search/cs?searchtype=author&query=Biroli%2C+G">Giulio Biroli</a>, 
<a href="/search/cs?searchtype=author&query=Cammarota%2C+C">Chiara Cammarota</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Statistical Mechanics (cond-mat.stat-mech)

</div>
<p class="mathjax">We investigate the optimization dynamics of gradient descent in a non-convex
and high-dimensional setting, with a focus on the phase retrieval problem as a
case study for complex loss landscapes. We first study the high-dimensional
limit where both the number $M$ and the dimension $N$ of the data are going to
infinity at fixed signal-to-noise ratio $\alpha = M/N$. By analyzing how the
local curvature changes during optimization, we uncover that for intermediate
$\alpha$, the Hessian displays a downward direction pointing towards good
minima in the first regime of the descent, before being trapped in bad minima
at the end. Hence, the local landscape is benign and informative at first,
before gradient descent brings the system into a uninformative maze. The
transition between the two regimes is associated to a BBP-type threshold in the
time-dependent Hessian. Through both theoretical analysis and numerical
experiments, we show that in practical cases, i.e. for finite but even very
large $N$, successful optimization via gradient descent in phase retrieval is
achieved by falling towards the good minima before reaching the bad ones. This
mechanism explains why successful recovery is obtained well before the
algorithmic transition corresponding to the high-dimensional limit.
Technically, this is associated to strong logarithmic corrections of the
algorithmic transition at large $N$ with respect to the one expected in the
$N\to\infty$ limit. Our analysis sheds light on such a new mechanism that
facilitate gradient descent dynamics in finite large dimensions, also
highlighting the importance of good initialization of spectral properties for
optimization in complex high-dimensional landscapes.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02419" title="Abstract">arXiv:2403.02419</a> [<a href="/pdf/2403.02419" title="Download PDF">pdf</a>, <a href="/format/2403.02419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are More LLM Calls All You Need? Towards Scaling Laws of Compound  Inference Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lingjiao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Davis%2C+J+Q">Jared Quincy Davis</a>, 
<a href="/search/cs?searchtype=author&query=Hanin%2C+B">Boris Hanin</a>, 
<a href="/search/cs?searchtype=author&query=Bailis%2C+P">Peter Bailis</a>, 
<a href="/search/cs?searchtype=author&query=Stoica%2C+I">Ion Stoica</a>, 
<a href="/search/cs?searchtype=author&query=Zaharia%2C+M">Matei Zaharia</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">James Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Systems and Control (eess.SY)

</div>
<p class="mathjax">Many recent state-of-the-art results in language tasks were achieved using
compound systems that perform multiple Large Language Model (LLM) calls and
aggregate their responses. However, there is little understanding of how the
number of LLM calls -- e.g., when asking the LLM to answer each question
multiple times and taking a consensus -- affects such a compound system's
performance. In this paper, we initiate the study of scaling laws of compound
inference systems. We analyze, theoretically and empirically, how the number of
LLM calls affects the performance of one-layer Voting Inference Systems -- one
of the simplest compound systems, which aggregates LLM responses via majority
voting. We find empirically that across multiple language tasks, surprisingly,
Voting Inference Systems' performance first increases but then decreases as a
function of the number of LLM calls. Our theoretical results suggest that this
non-monotonicity is due to the diversity of query difficulties within a task:
more LLM calls lead to higher performance on "easy" queries, but lower
performance on "hard" queries, and non-monotone behavior emerges when a task
contains both types of queries. This insight then allows us to compute, from a
small number of samples, the number of LLM calls that maximizes system
performance, and define a scaling law of Voting Inference Systems. Experiments
show that our scaling law can predict the performance of Voting Inference
Systems and find the optimal number of LLM calls to make.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02420" title="Abstract">arXiv:2403.02420</a> [<a href="/pdf/2403.02420" title="Download PDF">pdf</a>, <a href="/format/2403.02420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dr Wenowdis: Specializing dynamic language C extensions using type  information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bernstein%2C+M">Maxwell Bernstein</a>, 
<a href="/search/cs?searchtype=author&query=Bolz-Tereick%2C+C">CF Bolz-Tereick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">C-based interpreters such as CPython make extensive use of C "extension"
code, which is opaque to static analysis tools and faster runtimes with JIT
compilers, such as PyPy. Not only are the extensions opaque, but the interface
between the dynamic language types and the C types can introduce impedance. We
hypothesise that frequent calls to C extension code introduce significant
overhead that is often unnecessary. We validate this hypothesis by introducing
a simple technique, "typed methods", which allow selected C extension functions
to have additional metadata attached to them in a backward-compatible way. This
additional metadata makes it much easier for a JIT compiler (and as we show,
even an interpreter!) to significantly reduce the call and return overhead.
Although we have prototyped typed methods in PyPy, we suspect that the same
technique is applicable to a wider variety of language runtimes and that the
information can also be consumed by static analysis tooling.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02421" title="Abstract">arXiv:2403.02421</a> [<a href="/pdf/2403.02421" title="Download PDF">pdf</a>, <a href="/format/2403.02421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Situated Understanding of Older Adults&#x27; Interactions with Voice  Assistants: A Month-long In-home Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahmood%2C+A">Amama Mahmood</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chien-Ming Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Our work addresses the challenges older adults face with commercial Voice
Assistants (VAs), notably in conversation breakdowns and error handling.
Traditional methods of collecting user experiences-usage logs and post-hoc
interviews-do not fully capture the intricacies of older adults' interactions
with VAs, particularly regarding their reactions to errors. To bridge this gap,
we equipped 15 older adults' homes with Amazon smart speakers integrated with
custom audio recorders to collect ``in-the-wild'' audio interaction data for
detailed error analysis. Recognizing the conversational limitations of current
VAs, our study also explored the capabilities of Large Language Models (LLMs)
to handle natural and imperfect text for improving VAs. Midway through our
study, we deployed ChatGPT-powered Alexa skill to investigate its efficacy for
older adults. Our research suggests leveraging vocal and verbal responses
combined with LLMs' contextual capabilities for enhanced error prevention and
management in VAs, while proposing design considerations to align VA
capabilities with older adults' expectations.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02426" title="Abstract">arXiv:2403.02426</a> [<a href="/pdf/2403.02426" title="Download PDF">pdf</a>, <a href="/format/2403.02426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital Twins and Civil Engineering Phases: Reorienting Adoption  Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adebiyi%2C+T+A">Taiwo A. Adebiyi</a>, 
<a href="/search/cs?searchtype=author&query=Ajenifuja%2C+N+A">Nafeezat A. Ajenifuja</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruda Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">Digital twin (DT) technology has received immense attention over the years
due to the promises it presents to various stakeholders in science and
engineering. As a result, different thematic areas of DT have been explored.
This is no different in specific fields such as manufacturing, automation, oil
and gas, and civil engineering, leading to fragmented approaches for
field-specific applications. The civil engineering industry is further
disadvantaged in this regard as it relies on external techniques by other
engineering fields for its DT adoption. A rising consequence of these
extensions is a concentrated application of DT to the operations and
maintenance phase. On another spectrum, Building Information Modeling (BIM) are
pervasively utilized in the planning/design phase, and the transient nature of
the construction phase remains a challenge for its DT adoption. In this paper,
we present a phase-based development of DT in the Architecture, Engineering,
and Construction industry. We commence by presenting succinct expositions on DT
as a concept and as a service and establish a five-level scale system.
Furthermore, we present separately a systematic literature review of the
conventional techniques employed at each civil engineering phase. In this
regard, we identified enabling technologies such as computer vision for
extended sensing and the Internet of Things for reliable integration.
Ultimately, we attempt to reveal DT as an important tool across the entire life
cycle of civil engineering projects and nudge researchers to think more
holistically in their quest for the integration of DT for civil engineering
applications.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02428" title="Abstract">arXiv:2403.02428</a> [<a href="/pdf/2403.02428" title="Download PDF">pdf</a>, <a href="/ps/2403.02428" title="Download PostScript">ps</a>, <a href="/format/2403.02428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Broadening the View of Live Programmers: Integrating a Cross-Cutting  Perspective on Run-Time Behavior into a Live Programming Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rein%2C+P">Patrick Rein</a> (Hasso Plattner Institute - University of Potsdam, Germany), 
<a href="/search/cs?searchtype=author&query=Flach%2C+C">Christian Flach</a> (Hasso Plattner Institute - University of Potsdam, Germany), 
<a href="/search/cs?searchtype=author&query=Ramson%2C+S">Stefan Ramson</a> (Hasso Plattner Institute - University of Potsdam, Germany), 
<a href="/search/cs?searchtype=author&query=Krebs%2C+E">Eva Krebs</a> (Hasso Plattner Institute - University of Potsdam, Germany), 
<a href="/search/cs?searchtype=author&query=Hirschfeld%2C+R">Robert Hirschfeld</a> (Hasso Plattner Institute - University of Potsdam, Germany)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The Art, Science, and Engineering of Programming, 2024, Vol. 8,
  Issue 3, Article 13
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Live programming provides feedback on run-time behavior by visualizing
concrete values of expressions close to the source code. When using such a
local perspective on run-time behavior, programmers have to mentally
reconstruct the control flow if they want to understand the relation between
observed values. As this requires complete and correct knowledge of all
relevant code, this reconstruction is impractical for larger programs as well
as in the case of unexpected program behavior. In turn, cross-cutting
perspectives on run-time behavior can visualize the actual control flow
directly. At the same time, cross-cutting perspectives are often difficult to
navigate due to the large number of run-time events.
<br />We propose to integrate cross-cutting perspectives into live programming
environments based on local perspectives so that the two complement each other:
the cross-cutting perspective provides an overview of the run-time behavior;
the local perspective provides detailed feedback as well as points of interest
to navigate the cross-cutting perspective. We present a cross-cutting
perspective prototype in the form of a call tree browser integrated into the
Babylonian/S live programming environment. In an exploratory user study, we
observed that programmers found the tool useful for debugging, code
comprehension, and navigation. Finally, we discuss how our prototype
illustrates how the features of live programming environments may serve as the
basis for other powerful dynamic development tools.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02429" title="Abstract">arXiv:2403.02429</a> [<a href="/pdf/2403.02429" title="Download PDF">pdf</a>, <a href="/format/2403.02429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards efficient deep autoencoders for multivariate time series anomaly  detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pietro%C5%84%2C+M">Marcin Pietro&#x144;</a>, 
<a href="/search/cs?searchtype=author&query=%C5%BBurek%2C+D">Dominik &#x17b;urek</a>, 
<a href="/search/cs?searchtype=author&query=Faber%2C+K">Kamil Faber</a>, 
<a href="/search/cs?searchtype=author&query=Corizzo%2C+R">Roberto Corizzo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multivariate time series anomaly detection is a crucial problem in many
industrial and research applications. Timely detection of anomalies allows, for
instance, to prevent defects in manufacturing processes and failures in
cyberphysical systems. Deep learning methods are preferred among others for
their accuracy and robustness for the analysis of complex multivariate data.
However, a key aspect is being able to extract predictions in a timely manner,
to accommodate real-time requirements in different applications. In the case of
deep learning models, model reduction is extremely important to achieve optimal
results in real-time systems with limited time and memory constraints. In this
paper, we address this issue by proposing a novel compression method for deep
autoencoders that involves three key factors. First, pruning reduces the number
of weights, while preventing catastrophic drops in accuracy by means of a fast
search process that identifies high sparsity levels. Second, linear and
non-linear quantization reduces model complexity by reducing the number of bits
for every single weight. The combined contribution of these three aspects allow
the model size to be reduced, by removing a subset of the weights (pruning),
and decreasing their bit-width (quantization). As a result, the compressed
model is faster and easier to adopt in highly constrained hardware
environments. Experiments performed on popular multivariate anomaly detection
benchmarks, show that our method is capable of achieving significant model
compression ratio (between 80% and 95%) without a significant reduction in the
anomaly detection performance.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02430" title="Abstract">arXiv:2403.02430</a> [<a href="/pdf/2403.02430" title="Download PDF">pdf</a>, <a href="/format/2403.02430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed MIMO Measurements for Integrated Communication and Sensing  in an Industrial Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nelson%2C+C">Christian Nelson</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Fedorov%2C+A">Aleksei Fedorov</a>, 
<a href="/search/cs?searchtype=author&query=Deutschmann%2C+B+J+B">Benjamin J. B. Deutschmann</a>, 
<a href="/search/cs?searchtype=author&query=Tufvesson%2C+F">Fredrik Tufvesson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 20 figure, Published in MDPI Sensors
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sensors 2024, 24(5), 1385
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Many concepts for future generations of wireless communication systems use
coherent processing of signals from many distributed antennas. The aim is to
improve communication reliability, capacity, and energy efficiency and provide
possibilities for new applications through integrated communication and
sensing. The large bandwidths available in the higher bands have inspired much
work regarding sensing in the mmWave and sub-THz bands; however, the sub-6 GHz
cellular bands will still be the main provider of wide cellular coverage due to
the more favorable propagation conditions. In this paper, we present a
measurement system and results of sub-6 GHz distributed MIMO measurements
performed in an industrial environment. From the measurements, we evaluated the
diversity for both large-scale and small-scale fading and characterized the
link reliability. We also analyzed the possibility of multistatic sensing and
positioning of users in the environment, with the initial results showing a
mean-square error below 20 cm on the estimated position. Further, the results
clearly showed that new channel models are needed that are spatially consistent
and deal with the nonstationary channel properties among the antennas.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02431" title="Abstract">arXiv:2403.02431</a> [<a href="/pdf/2403.02431" title="Download PDF">pdf</a>, <a href="/format/2403.02431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Constraint Inference from User Demonstrations Based on  Margin-Respecting Preference Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papadimitriou%2C+D">Dimitris Papadimitriou</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+D+S">Daniel S. Brown</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">It is crucial for robots to be aware of the presence of constraints in order
to acquire safe policies. However, explicitly specifying all constraints in an
environment can be a challenging task. State-of-the-art constraint inference
algorithms learn constraints from demonstrations, but tend to be
computationally expensive and prone to instability issues. In this paper, we
propose a novel Bayesian method that infers constraints based on preferences
over demonstrations. The main advantages of our proposed approach are that it
1) infers constraints without calculating a new policy at each iteration, 2)
uses a simple and more realistic ranking of groups of demonstrations, without
requiring pairwise comparisons over all demonstrations, and 3) adapts to cases
where there are varying levels of constraint violation. Our empirical results
demonstrate that our proposed Bayesian approach infers constraints of varying
severity, more accurately than state-of-the-art constraint inference methods.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02436" title="Abstract">arXiv:2403.02436</a> [<a href="/pdf/2403.02436" title="Download PDF">pdf</a>, <a href="/format/2403.02436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How does Architecture Influence the Base Capabilities of Pre-trained  Language Models? A Case Study Based on FFN-Wider Transformer Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yanyan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Bing Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Pre-trained language models have been proven to possess strong base
capabilities, which not only excel in in-distribution language modeling but
also show powerful abilities in out-of-distribution language modeling, transfer
learning and few-shot learning. Unlike existing work focusing on the influence
of scale on base capabilities, our work examines the influence of architecture
on those. Specifically, our concern is: How does architecture influence the
base capabilities of pre-trained language models? In this work, we attempt to
explain and reverse the decline in base capabilities caused by the architecture
of FFN-Wider Transformers, seeking to provide some insights. Through analysis,
we found the contribution ratio of Multi-Head Attention (a combination
function) to pre-trained language modeling is a key factor affecting base
capabilities. FFN-Wider Transformers reduce the contribution ratio of this
combination function, leading to a decline in base capabilities. We confirmed
this by experiments and proposed Combination Enhancement Architecture (CEA) to
address the decline in base capabilities of such models. Significantly, we
extended our explanation and CEA to Mixture of Experts (MoE) architecture
Transformers, which also alleviated their decline in base capabilities to some
extent, proving our work can offer useful guidance for architecture analysis,
architecture improvement and architecture design.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02437" title="Abstract">arXiv:2403.02437</a> [<a href="/pdf/2403.02437" title="Download PDF">pdf</a>, <a href="/format/2403.02437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoK: Challenges and Opportunities in Federated Unlearning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+H">Hyejun Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shiqing Ma</a>, 
<a href="/search/cs?searchtype=author&query=Houmansadr%2C+A">Amir Houmansadr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated learning (FL), introduced in 2017, facilitates collaborative
learning between non-trusting parties with no need for the parties to
explicitly share their data among themselves. This allows training models on
user data while respecting privacy regulations such as GDPR and CPRA. However,
emerging privacy requirements may mandate model owners to be able to
\emph{forget} some learned data, e.g., when requested by data owners or law
enforcement. This has given birth to an active field of research called
\emph{machine unlearning}. In the context of FL, many techniques developed for
unlearning in centralized settings are not trivially applicable! This is due to
the unique differences between centralized and distributed learning, in
particular, interactivity, stochasticity, heterogeneity, and limited
accessibility in FL. In response, a recent line of work has focused on
developing unlearning mechanisms tailored to FL.
<br />This SoK paper aims to take a deep look at the \emph{federated unlearning}
literature, with the goal of identifying research trends and challenges in this
emerging field. By carefully categorizing papers published on FL unlearning
(since 2020), we aim to pinpoint the unique complexities of federated
unlearning, highlighting limitations on directly applying centralized
unlearning methods. We compare existing federated unlearning methods regarding
influence removal and performance recovery, compare their threat models and
assumptions, and discuss their implications and limitations. For instance, we
analyze the experimental setup of FL unlearning studies from various
perspectives, including data heterogeneity and its simulation, the datasets
used for demonstration, and evaluation metrics. Our work aims to offer insights
and suggestions for future research on federated unlearning.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02439" title="Abstract">arXiv:2403.02439</a> [<a href="/pdf/2403.02439" title="Download PDF">pdf</a>, <a href="/format/2403.02439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Root Causing Prediction Anomalies Using Explainable AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vishnampet%2C+R">Ramanathan Vishnampet</a>, 
<a href="/search/cs?searchtype=author&query=Shenoy%2C+R">Rajesh Shenoy</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianhui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Anuj Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to The 2nd World Conference on eXplainable Artificial Intelligence, 17-19 July, 2024, Malta, Valletta
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents a novel application of explainable AI (XAI) for
root-causing performance degradation in machine learning models that learn
continuously from user engagement data. In such systems a single feature
corruption can cause cascading feature, label and concept drifts. We have
successfully applied this technique to improve the reliability of models used
in personalized advertising. Performance degradation in such systems manifest
as prediction anomalies in the models. These models are typically trained
continuously using features that are produced by hundreds of real time data
processing pipelines or derived from other upstream models. A failure in any of
these pipelines or an instability in any of the upstream models can cause
feature corruption, causing the model's predicted output to deviate from the
actual output and the training data to become corrupted. The causal
relationship between the features and the predicted output is complex, and
root-causing is challenging due to the scale and dynamism of the system. We
demonstrate how temporal shifts in the global feature importance distribution
can effectively isolate the cause of a prediction anomaly, with better recall
than model-to-feature correlation methods. The technique appears to be
effective even when approximating the local feature importance using a simple
perturbation-based method, and aggregating over a few thousand examples. We
have found this technique to be a model-agnostic, cheap and effective way to
monitor complex data pipelines in production and have deployed a system for
continuously analyzing the global feature importance distribution of
continuously trained models.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02444" title="Abstract">arXiv:2403.02444</a> [<a href="/pdf/2403.02444" title="Download PDF">pdf</a>, <a href="/format/2403.02444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anatomically Constrained Tractography of the Fetal Brain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Calixto%2C+C">Camilo Calixto</a>, 
<a href="/search/cs?searchtype=author&query=Jaimes%2C+C">Camilo Jaimes</a>, 
<a href="/search/cs?searchtype=author&query=Soldatelli%2C+M+D">Matheus D. Soldatelli</a>, 
<a href="/search/cs?searchtype=author&query=Warfield%2C+S+K">Simon K. Warfield</a>, 
<a href="/search/cs?searchtype=author&query=Gholipour%2C+A">Ali Gholipour</a>, 
<a href="/search/cs?searchtype=author&query=Karimi%2C+D">Davood Karimi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion-weighted Magnetic Resonance Imaging (dMRI) is increasingly used to
study the fetal brain in utero. An important computation enabled by dMRI is
streamline tractography, which has unique applications such as tract-specific
analysis of the brain white matter and structural connectivity assessment.
However, due to the low fetal dMRI data quality and the challenging nature of
tractography, existing methods tend to produce highly inaccurate results. They
generate many false streamlines while failing to reconstruct streamlines that
constitute the major white matter tracts. In this paper, we advocate for
anatomically constrained tractography based on an accurate segmentation of the
fetal brain tissue directly in the dMRI space. We develop a deep learning
method to compute the segmentation automatically. Experiments on independent
test data show that this method can accurately segment the fetal brain tissue
and drastically improve tractography results. It enables the reconstruction of
highly curved tracts such as optic radiations. Importantly, our method infers
the tissue segmentation and streamline propagation direction from a diffusion
tensor fit to the dMRI data, making it applicable to routine fetal dMRI scans.
The proposed method can lead to significant improvements in the accuracy and
reproducibility of quantitative assessment of the fetal brain with dMRI.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02445" title="Abstract">arXiv:2403.02445</a> [<a href="/pdf/2403.02445" title="Download PDF">pdf</a>, <a href="/format/2403.02445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Free Proxies Unmasked: A Vulnerability and Longitudinal Analysis of Free  Proxy Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehanna%2C+N">Naif Mehanna</a> (1, 2 and 3), 
<a href="/search/cs?searchtype=author&query=Rudametkin%2C+W">Walter Rudametkin</a> (4, 5 and 6), 
<a href="/search/cs?searchtype=author&query=Laperdrix%2C+P">Pierre Laperdrix</a> (2, 1 and 3), 
<a href="/search/cs?searchtype=author&query=Vastel%2C+A">Antoine Vastel</a> (7) ((1) University of Lille, (2) CNRS, (3) Inria Lille, (4) University of Rennes, (5) IRISA, (6) IUF, (7) Datadome)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Workshop on Measurements, Attacks, and Defenses for the Web (MADWeb'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Free-proxies have been widespread since the early days of the Web, helping
users bypass geo-blocked content and conceal their IP addresses. Various proxy
providers promise faster Internet or increased privacy while advertising their
lists comprised of hundreds of readily available free proxies. However, while
paid proxy services advertise the support of encrypted connections and high
stability, free proxies often lack such guarantees, making them prone to
malicious activities such as eavesdropping or modifying content. Furthermore,
there is a market that encourages exploiting devices to install proxies.
<br />In this paper, we present a 30-month longitudinal study analyzing the
stability, security, and potential manipulation of free web proxies that we
collected from 11 providers. Our collection resulted in over 640,600 proxies,
that we cumulatively tested daily. We find that only 34.5% of proxies were
active at least once during our tests, showcasing the general instability of
free proxies. Geographically, a majority of proxies originate from the US and
China. Leveraging the Shodan search engine, we identified 4,452 distinct
vulnerabilities on the proxies' IP addresses, including 1,755 vulnerabilities
that allow unauthorized remote code execution and 2,036 that enable privilege
escalation on the host device. Through the software analysis on the proxies' IP
addresses, we find that 42,206 of them appear to run on MikroTik routers.
Worryingly, we also discovered 16,923 proxies that manipulate content,
indicating potential malicious intent by proxy owners. Ultimately, our research
reveals that the use of free web proxies poses significant risks to users'
privacy and security. The instability, vulnerabilities, and potential for
malicious actions uncovered in our analysis lead us to strongly caution users
against relying on free proxies.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02446" title="Abstract">arXiv:2403.02446</a> [<a href="/pdf/2403.02446" title="Download PDF">pdf</a>, <a href="/format/2403.02446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Latency Predictors for Neural Architecture Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akhauri%2C+Y">Yash Akhauri</a>, 
<a href="/search/cs?searchtype=author&query=Abdelfattah%2C+M+S">Mohamed S. Abdelfattah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at MLSys'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR); Computer Vision and Pattern Recognition (cs.CV); Performance (cs.PF)

</div>
<p class="mathjax">Efficient deployment of neural networks (NN) requires the co-optimization of
accuracy and latency. For example, hardware-aware neural architecture search
has been used to automatically find NN architectures that satisfy a latency
constraint on a specific hardware device. Central to these search algorithms is
a prediction model that is designed to provide a hardware latency estimate for
a candidate NN architecture. Recent research has shown that the sample
efficiency of these predictive models can be greatly improved through
pre-training on some \textit{training} devices with many samples, and then
transferring the predictor on the \textit{test} (target) device. Transfer
learning and meta-learning methods have been used for this, but often exhibit
significant performance variability. Additionally, the evaluation of existing
latency predictors has been largely done on hand-crafted training/test device
sets, making it difficult to ascertain design features that compose a robust
and general latency predictor. To address these issues, we introduce a
comprehensive suite of latency prediction tasks obtained in a principled way
through automated partitioning of hardware device sets. We then design a
general latency predictor to comprehensively study (1) the predictor
architecture, (2) NN sample selection methods, (3) hardware device
representations, and (4) NN operation encoding schemes. Building on conclusions
from our study, we present an end-to-end latency predictor training strategy
that outperforms existing methods on 11 out of 12 difficult latency prediction
tasks, improving latency prediction by 22.5\% on average, and up to to 87.6\%
on the hardest tasks. Focusing on latency prediction, our HW-Aware NAS reports
a $5.8\times$ speedup in wall-clock time. Our code is available on
\href{https://github.com/abdelfattah-lab/nasflat_latency}{https://github.com/abdelfattah-lab/nasflat\_latency}.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02449" title="Abstract">arXiv:2403.02449</a> [<a href="/pdf/2403.02449" title="Download PDF">pdf</a>, <a href="/format/2403.02449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Illuminant Estimation in Dual-Exposure HDR Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Afifi%2C+M">Mahmoud Afifi</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhenhua Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+L">Liang Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">High dynamic range (HDR) imaging involves capturing a series of frames of the
same scene, each with different exposure settings, to broaden the dynamic range
of light. This can be achieved through burst capturing or using staggered HDR
sensors that capture long and short exposures simultaneously in the camera
image signal processor (ISP). Within camera ISP pipeline, illuminant estimation
is a crucial step aiming to estimate the color of the global illuminant in the
scene. This estimation is used in camera ISP white-balance module to remove
undesirable color cast in the final image. Despite the multiple frames captured
in the HDR pipeline, conventional illuminant estimation methods often rely only
on a single frame of the scene. In this paper, we explore leveraging
information from frames captured with different exposure times. Specifically,
we introduce a simple feature extracted from dual-exposure images to guide
illuminant estimators, referred to as the dual-exposure feature (DEF). To
validate the efficiency of DEF, we employed two illuminant estimators using the
proposed DEF: 1) a multilayer perceptron network (MLP), referred to as
exposure-based MLP (EMLP), and 2) a modified version of the convolutional color
constancy (CCC) to integrate our DEF, that we call ECCC. Both EMLP and ECCC
achieve promising results, in some cases surpassing prior methods that require
hundreds of thousands or millions of parameters, with only a few hundred
parameters for EMLP and a few thousand parameters for ECCC.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02450" title="Abstract">arXiv:2403.02450</a> [<a href="/pdf/2403.02450" title="Download PDF">pdf</a>, <a href="/format/2403.02450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exposure-Conscious Path Planning for Equal-Exposure Corridors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamzezadeh%2C+E+T">Eugene T. Hamzezadeh</a>, 
<a href="/search/cs?searchtype=author&query=Rogers%2C+J+G">John G. Rogers</a>, 
<a href="/search/cs?searchtype=author&query=Dantam%2C+N+T">Neil T. Dantam</a>, 
<a href="/search/cs?searchtype=author&query=Petruska%2C+A+J">Andrew J. Petruska</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures. Submitted to 2024 IEEE 20th International Conference on Automation Science and Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">While maximizing line-of-sight coverage of specific regions or agents in the
environment is a well explored path planning objective, the converse problem of
minimizing exposure to the entire environment during navigation is especially
interesting in the context of minimizing detection risk. This work demonstrates
that minimizing line-of-sight exposure to the environment is non-Markovian,
which cannot be efficiently solved optimally with traditional path planning.
The optimality gap of the graph-search algorithm A* and the trade-offs in
optimality vs. computation time of several approximating heuristics is
explored. Finally, the concept of equal-exposure corridors, which afford
polynomial time determination of all paths that do not increase exposure, is
presented.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02451" title="Abstract">arXiv:2403.02451</a> [<a href="/pdf/2403.02451" title="Download PDF">pdf</a>, <a href="/format/2403.02451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Views Are My Own, But Also Yours: Benchmarking Theory of Mind using  Common Ground
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soubki%2C+A">Adil Soubki</a>, 
<a href="/search/cs?searchtype=author&query=Murzaku%2C+J">John Murzaku</a>, 
<a href="/search/cs?searchtype=author&query=Jordehi%2C+A+Y">Arash Yousefi Jordehi</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+P">Peter Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Markowska%2C+M">Magdalena Markowska</a>, 
<a href="/search/cs?searchtype=author&query=Mirroshandel%2C+S+A">Seyed Abolghasem Mirroshandel</a>, 
<a href="/search/cs?searchtype=author&query=Rambow%2C+O">Owen Rambow</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Evaluating the theory of mind (ToM) capabilities of language models (LMs) has
recently received much attention. However, many existing benchmarks rely on
synthetic data which risks misaligning the resulting experiments with human
behavior. We introduce the first ToM dataset based on naturally occurring
spoken dialogs, Common-ToM, and show that LMs struggle to demonstrate ToM. We
then show that integrating a simple, explicit representation of beliefs
improves LM performance on Common-ToM.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02454" title="Abstract">arXiv:2403.02454</a> [<a href="/pdf/2403.02454" title="Download PDF">pdf</a>, <a href="/format/2403.02454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Ink Splotch Effect: A Case Study on ChatGPT as a Co-Creative Game  Designer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anjum%2C+A">Asad Anjum</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuting Li</a>, 
<a href="/search/cs?searchtype=author&query=Law%2C+N">Noelle Law</a>, 
<a href="/search/cs?searchtype=author&query=Charity%2C+M">M Charity</a>, 
<a href="/search/cs?searchtype=author&query=Togelius%2C+J">Julian Togelius</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This paper studies how large language models (LLMs) can act as effective,
high-level creative collaborators and ``muses'' for game design. We model the
design of this study after the exercises artists use by looking at amorphous
ink splotches for creative inspiration. Our goal is to determine whether
AI-assistance can improve, hinder, or provide an alternative quality to games
when compared to the creative intents implemented by human designers. The
capabilities of LLMs as game designers are stress tested by placing it at the
forefront of the decision making process. Three prototype games are designed
across 3 different genres: (1) a minimalist base game, (2) a game with features
and game feel elements added by a human game designer, and (3) a game with
features and feel elements directly implemented from prompted outputs of the
LLM, ChatGPT. A user study was conducted and participants were asked to blindly
evaluate the quality and their preference of these games. We discuss both the
development process of communicating creative intent to an AI chatbot and the
synthesized open feedback of the participants. We use this data to determine
both the benefits and shortcomings of AI in a more design-centric role.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02459" title="Abstract">arXiv:2403.02459</a> [<a href="/pdf/2403.02459" title="Download PDF">pdf</a>, <a href="/ps/2403.02459" title="Download PostScript">ps</a>, <a href="/format/2403.02459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cybersecurity competence of older adult users of mobile devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vrhovec%2C+S">Simon Vrhovec</a>, 
<a href="/search/cs?searchtype=author&query=Bernik%2C+I">Igor Bernik</a>, 
<a href="/search/cs?searchtype=author&query=Fujs%2C+D">Damjan Fujs</a>, 
<a href="/search/cs?searchtype=author&query=Vavpoti%C4%8D%2C+D">Damjan Vavpoti&#x10d;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">This work reports on a cross-sectional study on device proficiency, support
availability and cybersecurity competence of older adult users of smartphones
and/or tablets. Results indicate that cybersecurity competence is associated
with both device proficiency and support availability although the variance
explained is relatively low. There were no differences in cybersecurity
competence between users and non-users of either mobile devices. Users of both
smartphones and tablets had significantly higher device proficiency than
non-users. Users of tablets had significantly higher support availability than
non-users while there were no significant differences between users and
non-users of smartphones.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02460" title="Abstract">arXiv:2403.02460</a> [<a href="/pdf/2403.02460" title="Download PDF">pdf</a>, <a href="/format/2403.02460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MagicClay: Sculpting Meshes With Generative Neural Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barda%2C+A">Amir Barda</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+V+G">Vladimir G. Kim</a>, 
<a href="/search/cs?searchtype=author&query=Aigerman%2C+N">Noam Aigerman</a>, 
<a href="/search/cs?searchtype=author&query=Bermano%2C+A+H">Amit H. Bermano</a>, 
<a href="/search/cs?searchtype=author&query=Groueix%2C+T">Thibault Groueix</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page: <a href="https://amir90.github.io/MagicClay.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">The recent developments in neural fields have brought phenomenal capabilities
to the field of shape generation, but they lack crucial properties, such as
incremental control - a fundamental requirement for artistic work. Triangular
meshes, on the other hand, are the representation of choice for most geometry
related tasks, offering efficiency and intuitive control, but do not lend
themselves to neural optimization. To support downstream tasks, previous art
typically proposes a two-step approach, where first a shape is generated using
neural fields, and then a mesh is extracted for further processing. Instead, in
this paper we introduce a hybrid approach that maintains both a mesh and a
Signed Distance Field (SDF) representations consistently. Using this
representation, we introduce MagicClay - an artist friendly tool for sculpting
regions of a mesh according to textual prompts while keeping other regions
untouched. Our framework carefully and efficiently balances consistency between
the representations and regularizations in every step of the shape
optimization; Relying on the mesh representation, we show how to render the SDF
at higher resolutions and faster. In addition, we employ recent work in
differentiable mesh reconstruction to adaptively allocate triangles in the mesh
where required, as indicated by the SDF. Using an implemented prototype, we
demonstrate superior generated geometry compared to the state-of-the-art, and
novel consistent control, allowing sequential prompt-based edits to the same
mesh for the first time.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02469" title="Abstract">arXiv:2403.02469</a> [<a href="/pdf/2403.02469" title="Download PDF">pdf</a>, <a href="/format/2403.02469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision-Language Models for Medical Report Generation and Visual Question  Answering: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hartsock%2C+I">Iryna Hartsock</a>, 
<a href="/search/cs?searchtype=author&query=Rasool%2C+G">Ghulam Rasool</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Medical vision-language models (VLMs) combine computer vision and natural
language processing to analyze visual and textual medical data. Our paper
reviews recent advancements in developing VLMs specialized for healthcare,
focusing on models designed for medical report generation and visual question
answering. We provide background on natural language processing and computer
vision, explaining how techniques from both fields are integrated into VLMs to
enable learning from multimodal data. Key areas we address include the
exploration of medical vision-language datasets, in-depth analyses of
architectures and pre-training strategies employed in recent noteworthy medical
VLMs, and comprehensive discussion on evaluation metrics for assessing VLMs'
performance in medical report generation and visual question answering. We also
highlight current challenges and propose future directions, including enhancing
clinical validity and addressing patient privacy concerns. Overall, our review
summarizes recent progress in developing VLMs to harness multimodal medical
data for improved healthcare applications.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02472" title="Abstract">arXiv:2403.02472</a> [<a href="/pdf/2403.02472" title="Download PDF">pdf</a>, <a href="/format/2403.02472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OffLanDat: A Community Based Implicit Offensive Language Dataset  Generated by Large Language Model Through Prompt Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Amit Das</a>, 
<a href="/search/cs?searchtype=author&query=Rahgouy%2C+M">Mostafa Rahgouy</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+D">Dongji Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+T">Tathagata Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Raychawdhary%2C+N">Nilanjana Raychawdhary</a>, 
<a href="/search/cs?searchtype=author&query=Sandage%2C+M">Mary Sandage</a>, 
<a href="/search/cs?searchtype=author&query=Pope%2C+L">Lauramarie Pope</a>, 
<a href="/search/cs?searchtype=author&query=Dozier%2C+G">Gerry Dozier</a>, 
<a href="/search/cs?searchtype=author&query=Seals%2C+C">Cheryl Seals</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The widespread presence of offensive languages on social media has resulted
in adverse effects on societal well-being. As a result, it has become very
important to address this issue with high priority. Offensive languages exist
in both explicit and implicit forms, with the latter being more challenging to
detect. Current research in this domain encounters several challenges. Firstly,
the existing datasets primarily rely on the collection of texts containing
explicit offensive keywords, making it challenging to capture implicitly
offensive contents that are devoid of these keywords. Secondly, usual
methodologies tend to focus solely on textual analysis, neglecting the valuable
insights that community information can provide. In this research paper, we
introduce a novel dataset OffLanDat, a community based implicit offensive
language dataset generated by ChatGPT containing data for 38 different target
groups. Despite limitations in generating offensive texts using ChatGPT due to
ethical constraints, we present a prompt-based approach that effectively
generates implicit offensive languages. To ensure data quality, we evaluate our
data with human. Additionally, we employ a prompt-based Zero-Shot method with
ChatGPT and compare the detection results between human annotation and ChatGPT
annotation. We utilize existing state-of-the-art models to see how effective
they are in detecting such languages. We will make our code and dataset public
for other researchers.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02473" title="Abstract">arXiv:2403.02473</a> [<a href="/pdf/2403.02473" title="Download PDF">pdf</a>, <a href="/format/2403.02473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When do Convolutional Neural Networks Stop Learning?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+S">Sahan Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Trahan%2C+G">Gabriel Trahan</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+A">Aminul Islam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Convolutional Neural Networks (CNNs) have demonstrated outstanding
performance in computer vision tasks such as image classification, detection,
segmentation, and medical image analysis. In general, an arbitrary number of
epochs is used to train such neural networks. In a single epoch, the entire
training data -- divided by batch size -- are fed to the network. In practice,
validation error with training loss is used to estimate the neural network's
generalization, which indicates the optimal learning capacity of the network.
Current practice is to stop training when the training loss decreases and the
gap between training and validation error increases (i.e., the generalization
gap) to avoid overfitting. However, this is a trial-and-error-based approach
which raises a critical question: Is it possible to estimate when neural
networks stop learning based on training data? This research work introduces a
hypothesis that analyzes the data variation across all the layers of a CNN
variant to anticipate its near-optimal learning capacity. In the training
phase, we use our hypothesis to anticipate the near-optimal learning capacity
of a CNN variant without using any validation data. Our hypothesis can be
deployed as a plug-and-play to any existing CNN variant without introducing
additional trainable parameters to the network. We test our hypothesis on six
different CNN variants and three different general image datasets (CIFAR10,
CIFAR100, and SVHN). The result based on these CNN variants and datasets shows
that our hypothesis saves 58.49\% of computational time (on average) in
training. We further conduct our hypothesis on ten medical image datasets and
compared with the MedMNIST-V2 benchmark. Based on our experimental result, we
save $\approx$ 44.1\% of computational time without losing accuracy against the
MedMNIST-V2 benchmark.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02474" title="Abstract">arXiv:2403.02474</a> [<a href="/pdf/2403.02474" title="Download PDF">pdf</a>, <a href="/format/2403.02474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Emotion Dynamics of Literary Novels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vishnubhotla%2C+K">Krishnapriya Vishnubhotla</a>, 
<a href="/search/cs?searchtype=author&query=Hammond%2C+A">Adam Hammond</a>, 
<a href="/search/cs?searchtype=author&query=Hirst%2C+G">Graeme Hirst</a>, 
<a href="/search/cs?searchtype=author&query=Mohammad%2C+S+M">Saif M. Mohammad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages plus appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Stories are rich in the emotions they exhibit in their narratives and evoke
in the readers. The emotional journeys of the various characters within a story
are central to their appeal. Computational analysis of the emotions of novels,
however, has rarely examined the variation in the emotional trajectories of the
different characters within them, instead considering the entire novel to
represent a single story arc. In this work, we use character dialogue to
distinguish between the emotion arcs of the narration and the various
characters. We analyze the emotion arcs of the various characters in a dataset
of English literary novels using the framework of Utterance Emotion Dynamics.
Our findings show that the narration and the dialogue largely express disparate
emotions through the course of a novel, and that the commonalities or
differences in the emotional arcs of stories are more accurately captured by
those associated with individual characters.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02475" title="Abstract">arXiv:2403.02475</a> [<a href="/pdf/2403.02475" title="Download PDF">pdf</a>, <a href="/format/2403.02475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing LLM Safety via Constrained Direct Preference Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zixuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaolin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zizhan Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The rapidly increasing capabilities of large language models (LLMs) raise an
urgent need to align AI systems with diverse human preferences to
simultaneously enhance their usefulness and safety, despite the often
conflicting nature of these goals. To address this important problem, a
promising approach is to enforce a safety constraint at the fine-tuning stage
through a constrained Reinforcement Learning from Human Feedback (RLHF)
framework. This approach, however, is computationally expensive and often
unstable. In this work, we introduce Constrained DPO (C-DPO), a novel extension
of the recently proposed Direct Preference Optimization (DPO) approach for
fine-tuning LLMs that is both efficient and lightweight. By integrating dual
gradient descent and DPO, our method identifies a nearly optimal trade-off
between helpfulness and harmlessness without using reinforcement learning.
Empirically, our approach provides a safety guarantee to LLMs that is missing
in DPO while achieving significantly higher rewards under the same safety
constraint compared to a recently proposed safe RLHF approach.
<br />Warning: This paper contains example data that may be offensive or harmful.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02476" title="Abstract">arXiv:2403.02476</a> [<a href="/pdf/2403.02476" title="Download PDF">pdf</a>, <a href="/ps/2403.02476" title="Download PostScript">ps</a>, <a href="/format/2403.02476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple Finite-Time Analysis of TD Learning with Linear Function  Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mitra%2C+A">Aritra Mitra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">We study the finite-time convergence of TD learning with linear function
approximation under Markovian sampling. Existing proofs for this setting either
assume a projection step in the algorithm to simplify the analysis, or require
a fairly intricate argument to ensure stability of the iterates. We ask:
\textit{Is it possible to retain the simplicity of a projection-based analysis
without actually performing a projection step in the algorithm?} Our main
contribution is to show this is possible via a novel two-step argument. In the
first step, we use induction to prove that under a standard choice of a
constant step-size $\alpha$, the iterates generated by TD learning remain
uniformly bounded in expectation. In the second step, we establish a recursion
that mimics the steady-state dynamics of TD learning up to a bounded
perturbation on the order of $O(\alpha^2)$ that captures the effect of
Markovian sampling. Combining these pieces leads to an overall approach that
considerably simplifies existing proofs. We conjecture that our inductive proof
technique will find applications in the analyses of more complex stochastic
approximation algorithms, and conclude by providing some examples of such
applications.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02482" title="Abstract">arXiv:2403.02482</a> [<a href="/pdf/2403.02482" title="Download PDF">pdf</a>, <a href="/format/2403.02482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MORBDD: Multiobjective Restricted Binary Decision Diagrams by Learning  to Sparsify
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+R">Rahul Patel</a>, 
<a href="/search/cs?searchtype=author&query=Khalil%2C+E+B">Elias B. Khalil</a>, 
<a href="/search/cs?searchtype=author&query=Bergman%2C+D">David Bergman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In multicriteria decision-making, a user seeks a set of non-dominated
solutions to a (constrained) multiobjective optimization problem, the so-called
Pareto frontier. In this work, we seek to bring a state-of-the-art method for
exact multiobjective integer linear programming into the heuristic realm. We
focus on binary decision diagrams (BDDs) which first construct a graph that
represents all feasible solutions to the problem and then traverse the graph to
extract the Pareto frontier. Because the Pareto frontier may be exponentially
large, enumerating it over the BDD can be time-consuming. We explore how
restricted BDDs, which have already been shown to be effective as heuristics
for single-objective problems, can be adapted to multiobjective optimization
through the use of machine learning (ML). MORBDD, our ML-based BDD sparsifier,
first trains a binary classifier to eliminate BDD nodes that are unlikely to
contribute to Pareto solutions, then post-processes the sparse BDD to ensure
its connectivity via optimization. Experimental results on multiobjective
knapsack problems show that MORBDD is highly effective at producing very small
restricted BDDs with excellent approximation quality, outperforming
width-limited restricted BDDs and the well-known evolutionary algorithm
NSGA-II.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02484" title="Abstract">arXiv:2403.02484</a> [<a href="/pdf/2403.02484" title="Download PDF">pdf</a>, <a href="/format/2403.02484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Encodings for Prediction-based Neural Architecture Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akhauri%2C+Y">Yash Akhauri</a>, 
<a href="/search/cs?searchtype=author&query=Abdelfattah%2C+M+S">Mohamed S. Abdelfattah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Predictor-based methods have substantially enhanced Neural Architecture
Search (NAS) optimization. The efficacy of these predictors is largely
influenced by the method of encoding neural network architectures. While
traditional encodings used an adjacency matrix describing the graph structure
of a neural network, novel encodings embrace a variety of approaches from
unsupervised pretraining of latent representations to vectors of zero-cost
proxies. In this paper, we categorize and investigate neural encodings from
three main types: structural, learned, and score-based. Furthermore, we extend
these encodings and introduce \textit{unified encodings}, that extend NAS
predictors to multiple search spaces. Our analysis draws from experiments
conducted on over 1.5 million neural network architectures on NAS spaces such
as NASBench-101 (NB101), NB201, NB301, Network Design Spaces (NDS), and
TransNASBench-101. Building on our study, we present our predictor
\textbf{FLAN}: \textbf{Fl}ow \textbf{A}ttention for \textbf{N}AS. FLAN
integrates critical insights on predictor design, transfer learning, and
\textit{unified encodings} to enable more than an order of magnitude cost
reduction for training NAS accuracy predictors. Our implementation and
encodings for all neural networks are open-sourced at
\href{https://github.com/abdelfattah-lab/flan_nas}{https://github.com/abdelfattah-lab/flan\_nas}.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02486" title="Abstract">arXiv:2403.02486</a> [<a href="/pdf/2403.02486" title="Download PDF">pdf</a>, <a href="/format/2403.02486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demonstrating a Robust Walking Algorithm for Underactuated Bipedal  Robots in Non-flat, Non-stationary Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dosunmu-Ogunbi%2C+O">Oluwami Dosunmu-Ogunbi</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+A">Aayushi Shrivastava</a>, 
<a href="/search/cs?searchtype=author&query=Grizzle%2C+J+W">Jessy W Grizzle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This work explores an innovative algorithm designed to enhance the mobility
of underactuated bipedal robots across challenging terrains, especially when
navigating through spaces with constrained opportunities for foot support, like
steps or stairs. By combining ankle torque with a refined angular
momentum-based linear inverted pendulum model (ALIP), our method allows
variability in the robot's center of mass height. We employ a dual-strategy
controller that merges virtual constraints for precise motion regulation across
essential degrees of freedom with an ALIP-centric model predictive control
(MPC) framework, aimed at enforcing gait stability. The effectiveness of our
feedback design is demonstrated through its application on the Cassie bipedal
robot, which features 20 degrees of freedom. Key to our implementation is the
development of tailored nominal trajectories and an optimized MPC that reduces
the execution time to under 500 microseconds--and, hence, is compatible with
Cassie's controller update frequency. This paper not only showcases the
successful hardware deployment but also demonstrates a new capability, a
bipedal robot using a moving walkway.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02491" title="Abstract">arXiv:2403.02491</a> [<a href="/pdf/2403.02491" title="Download PDF">pdf</a>, <a href="/format/2403.02491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ivie: Lightweight Anchored Explanations of Just-Generated Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Litao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+A">Alyssa Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Head%2C+A">Andrew Head</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 10 figures, to be published in the CHI Conference on Human Factors in Computing Systems (CHI 24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Programming assistants have reshaped the experience of programming into one
where programmers spend less time writing and more time critically examining
code. In this paper, we explore how programming assistants can be extended to
accelerate the inspection of generated code. We introduce an extension to the
programming assistant called Ivie, or instantly visible in-situ explanations.
When using Ivie, a programmer's generated code is instantly accompanied by
explanations positioned just adjacent to the code. Our design was optimized for
extremely low-cost invocation and dismissal. Explanations are compact and
informative. They describe meaningful expressions, from individual variables to
entire blocks of code. We present an implementation of Ivie that forks VS Code,
applying a modern LLM for timely segmentation and explanation of generated
code. In a lab study, we compared Ivie to a contemporary baseline tool for code
understanding. Ivie improved understanding of generated code, and was received
by programmers as a highly useful, low distraction, desirable complement to the
programming assistant.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02495" title="Abstract">arXiv:2403.02495</a> [<a href="/pdf/2403.02495" title="Download PDF">pdf</a>, <a href="/format/2403.02495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseudo-Labeling and Contextual Curriculum Learning for Online Grasp  Learning in Robotic Bin Picking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+H">Huy Le</a>, 
<a href="/search/cs?searchtype=author&query=Schillinger%2C+P">Philipp Schillinger</a>, 
<a href="/search/cs?searchtype=author&query=Gabriel%2C+M">Miroslav Gabriel</a>, 
<a href="/search/cs?searchtype=author&query=Qualmann%2C+A">Alexander Qualmann</a>, 
<a href="/search/cs?searchtype=author&query=Vien%2C+N+A">Ngo Anh Vien</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The prevailing grasp prediction methods predominantly rely on offline
learning, overlooking the dynamic grasp learning that occurs during real-time
adaptation to novel picking scenarios. These scenarios may involve previously
unseen objects, variations in camera perspectives, and bin configurations,
among other factors. In this paper, we introduce a novel approach, SSL-ConvSAC,
that combines semi-supervised learning and reinforcement learning for online
grasp learning. By treating pixels with reward feedback as labeled data and
others as unlabeled, it efficiently exploits unlabeled data to enhance
learning. In addition, we address the imbalance between labeled and unlabeled
data by proposing a contextual curriculum-based method. We ablate the proposed
approach on real-world evaluation data and demonstrate promise for improving
online grasp learning on bin picking tasks using a physical 7-DoF Franka Emika
robot arm with a suction gripper. Video: https://youtu.be/OAro5pg8I9U
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02496" title="Abstract">arXiv:2403.02496</a> [<a href="/pdf/2403.02496" title="Download PDF">pdf</a>, <a href="/ps/2403.02496" title="Download PostScript">ps</a>, <a href="/format/2403.02496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Choose Your Own Adventure: Interactive E-Books to Improve Word Knowledge  and Comprehension Skills
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Day%2C+S">Stephanie Day</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J+K">Jin K. Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Arner%2C+T">Tracy Arner</a>, 
<a href="/search/cs?searchtype=author&query=McNamara%2C+D">Danielle McNamara</a>, 
<a href="/search/cs?searchtype=author&query=Connor%2C+C">Carol Connor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The purpose of this feasibility study was to examine the potential impact of
reading digital interactive e-books on essential skills that support reading
comprehension with third-fifth grade students. Students read two e-Books that
taught word learning and comprehension monitoring strategies in the service of
learning difficult vocabulary and targeted science concepts about hurricanes.
We investigated whether specific comprehension strategies including word
learning and strategies that supported general reading comprehension,
summarization, and question generation, show promise of effectiveness in
building vocabulary knowledge and comprehension skills in the e-Books. Students
were assigned to read one of three versions of each of the e-Books, each
version implemented one strategy. The books employed a choose-your-adventure
format with embedded comprehension questions that provided students with
immediate feedback on their responses. Paired samples t-tests were run to
examine pre-to-post differences in learning the targeted vocabulary and science
concepts taught in both e-Books. For both e-Books, students demonstrated
significant gains in word learning and on the targeted hurricane concepts.
Additionally, Hierarchical Linear Modeling (HLM) revealed that no one strategy
was more associated with larger gains than the other. Performance on the
embedded questions in the books was also associated with greater posttest
outcomes for both e-Books. This work discusses important considerations for
implementation and future development of e-books that can enhance student
engagement and improve reading comprehension.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02497" title="Abstract">arXiv:2403.02497</a> [<a href="/pdf/2403.02497" title="Download PDF">pdf</a>, <a href="/format/2403.02497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Magnetic Localization for In-body Nano-communication Medical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Skos%2C+K">Krzysztof Skos</a>, 
<a href="/search/cs?searchtype=author&query=Jornet%2C+J+M">Josep Miquel Jornet</a>, 
<a href="/search/cs?searchtype=author&query=Kulakowski%2C+P">Pawel Kulakowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Nano-machines circulating inside the human body, collecting data on tissue
conditions, represent a vital part of next-generation medical diagnostic
systems. However, for these devices to operate effectively, they need to relay
not only their medical measurements but also their positions. This paper
introduces a novel localization method for in-body nano-machines based on the
magnetic field, leveraging the advantageous magnetic permeability of all human
tissues. The entire proposed localization system is described, starting from
10x10 ${\mu}m^2$ magnetometers to be integrated into the nano-machines, to a
set of external wires generating the magnetic field. Mathematical equations for
the localization algorithm are also provided, assuming the nano-machines do not
execute the computations themselves, but transmit their magnetic field
measurements together with medical data outside of the body. The whole system
is validated with computer simulations that capture the measurement error of
the magnetometers, the error induced by the Earth magnetic field, and a human
body model assuming different possible positions of nano-machines. The results
show a very high system accuracy with localization errors even below 1 cm.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02499" title="Abstract">arXiv:2403.02499</a> [<a href="/pdf/2403.02499" title="Download PDF">pdf</a>, <a href="/format/2403.02499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The complexity of computing in continuous time: space complexity is  precision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blanc%2C+M">Manon Blanc</a>, 
<a href="/search/cs?searchtype=author&query=Bournez%2C+O">Olivier Bournez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">Models of computations over the integers are equivalent from a computability
and complexity theory point of view by the Church-Turing thesis. It is not
possible to unify discrete-time models over the reals. The situation is unclear
but simpler for continuous-time models, as there is a unifying mathematical
model provided by ordinary differential equations (ODEs). For example, the GPAC
model of Shannon is known to correspond to polynomial ODEs. However, the
question of a robust complexity theory for such models and its relations to
classical (discrete) computation theory is an old problem. There was some
recent significant progress: it has been proved that (classical) time
complexity corresponds to the length of the involved curves. The question of
whether there is a simple and robust way to measure space complexity remains.
We argue that space complexity corresponds to precision and conversely. We
propose and prove an algebraic characterisation of FPSPACE, using continuous
ODEs. Recent papers proposed algebraic characterisations of polynomial-time and
-space complexity classes over the reals, but with a discrete-time: those
algebras rely on discrete ODE schemes. Here, we use classical (continuous)
ODEs, with the classic definition of derivation and hence with the more natural
context of continuous-time associated with ODEs. We characterise both the case
of polynomial space functions over the integers and the reals. We prove that
Turing machines, with a proper representation of real numbers, can be simulated
by continuous ODEs and not just discrete ODEs. A major consequence is that the
associated space complexity is provably related to the numerical stability of
involved schemas and the associated required precision. We obtain that a
problem can be solved in polynomial space if and only if it can be simulated by
some numerically stable ODE, using a polynomial precision.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02502" title="Abstract">arXiv:2403.02502</a> [<a href="/pdf/2403.02502" title="Download PDF">pdf</a>, <a href="/format/2403.02502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trial and Error: Exploration-Based Trajectory Optimization for LLM  Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yifan Song</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Da Yin</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+X">Xiang Yue</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sujian Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B+Y">Bill Yuchen Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) have become integral components in various
autonomous agent systems. In this study, we present an exploration-based
trajectory optimization approach, referred to as ETO. This learning method is
designed to enhance the performance of open LLM agents. Contrary to previous
studies that exclusively train on successful expert trajectories, our method
allows agents to learn from their exploration failures. This leads to improved
performance through an iterative optimization framework. During the exploration
phase, the agent interacts with the environment while completing given tasks,
gathering failure trajectories to create contrastive trajectory pairs. In the
subsequent training phase, the agent utilizes these trajectory preference pairs
to update its policy using contrastive learning methods like DPO. This
iterative cycle of exploration and training fosters continued improvement in
the agents. Our experiments on three complex tasks demonstrate that ETO
consistently surpasses baseline performance by a large margin. Furthermore, an
examination of task-solving efficiency and potential in scenarios lacking
expert trajectory underscores the effectiveness of our approach.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02504" title="Abstract">arXiv:2403.02504</a> [<a href="/pdf/2403.02504" title="Download PDF">pdf</a>, <a href="/format/2403.02504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Tutorial on the Pretrain-Finetune Paradigm for Natural Language  Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The pretrain-finetune paradigm represents a transformative approach in
natural language processing (NLP). This paradigm distinguishes itself through
the use of large pretrained language models, demonstrating remarkable
efficiency in finetuning tasks, even with limited training data. This
efficiency is especially beneficial for research in social sciences, where the
number of annotated samples is often quite limited. Our tutorial offers a
comprehensive introduction to the pretrain-finetune paradigm. We first delve
into the fundamental concepts of pretraining and finetuning, followed by
practical exercises using real-world applications. We demonstrate the
application of the paradigm across various tasks, including multi-class
classification and regression. Emphasizing its efficacy and user-friendliness,
the tutorial aims to encourage broader adoption of this paradigm. To this end,
we have provided open access to all our code and datasets. The tutorial is
particularly valuable for quantitative researchers in psychology, offering them
an insightful guide into this innovative approach.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02506" title="Abstract">arXiv:2403.02506</a> [<a href="/pdf/2403.02506" title="Download PDF">pdf</a>, <a href="/format/2403.02506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Representation Learning via Image Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sander%2C+T">Tom Sander</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yaodong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sanjabi%2C+M">Maziar Sanjabi</a>, 
<a href="/search/cs?searchtype=author&query=Durmus%2C+A">Alain Durmus</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhuri%2C+K">Kamalika Chaudhuri</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Chuan Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Differentially private (DP) machine learning is considered the gold-standard
solution for training a model from sensitive data while still preserving
privacy. However, a major barrier to achieving this ideal is its sub-optimal
privacy-accuracy trade-off, which is particularly visible in DP representation
learning. Specifically, it has been shown that under modest privacy budgets,
most models learn representations that are not significantly better than
hand-crafted features. In this work, we show that effective DP representation
learning can be done via image captioning and scaling up to internet-scale
multimodal datasets. Through a series of engineering tricks, we successfully
train a DP image captioner (DP-Cap) on a 233M subset of LAION-2B from scratch
using a reasonable amount of computation, and obtaining unprecedented
high-quality image features that can be used in a variety of downstream vision
and vision-language tasks. For example, under a privacy budget of
$\varepsilon=8$, a linear classifier trained on top of learned DP-Cap features
attains 65.8% accuracy on ImageNet-1K, considerably improving the previous SOTA
of 56.5%. Our work challenges the prevailing sentiment that high-utility DP
representation learning cannot be achieved by training from scratch.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02507" title="Abstract">arXiv:2403.02507</a> [<a href="/pdf/2403.02507" title="Download PDF">pdf</a>, <a href="/ps/2403.02507" title="Download PostScript">ps</a>, <a href="/format/2403.02507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LQ Control of Traffic Flow Models via Variable Speed Limits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Block%2C+B">Brian Block</a>, 
<a href="/search/eess?searchtype=author&query=Stockar%2C+S">Stephanie Stockar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to 2024 American Control Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, an extension of a linear control design for hyperbolic linear
partial differential equations is presented for a first-order traffic flow
model. Starting from the Lighthill-Whitham-Richards (LWR) model, variable speed
limit control (VSL) is applied through a modification of Greenshield's
equilibrium flow model. Then, an optimal linear quadratic (LQ) controller is
designed on the linear LWR model. The LQ state feedback function is found via
the solution of a Riccati differential equation. Unlike previous studies, the
control input is the rate of change of the input, not the input itself. The
proposed controller is then verified on both the linear and nonlinear models.
In both cases, the controller is able to drive the system to a desired density
profile. In the nonlinear application, a higher control gain is needed to
achieve similar results as in the linear case.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02508" title="Abstract">arXiv:2403.02508</a> [<a href="/pdf/2403.02508" title="Download PDF">pdf</a>, <a href="/format/2403.02508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collision Avoidance and Geofencing for Fixed-wing Aircraft with Control  Barrier Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Molnar%2C+T+G">Tamas G. Molnar</a>, 
<a href="/search/cs?searchtype=author&query=Kannan%2C+S+K">Suresh K. Kannan</a>, 
<a href="/search/cs?searchtype=author&query=Cunningham%2C+J">James Cunningham</a>, 
<a href="/search/cs?searchtype=author&query=Dunlap%2C+K">Kyle Dunlap</a>, 
<a href="/search/cs?searchtype=author&query=Hobbs%2C+K+L">Kerianne L. Hobbs</a>, 
<a href="/search/cs?searchtype=author&query=Ames%2C+A+D">Aaron D. Ames</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO); Dynamical Systems (math.DS)

</div>
<p class="mathjax">Safety-critical failures often have fatal consequences in aerospace control.
Control systems on aircraft, therefore, must ensure the strict satisfaction of
safety constraints, preferably with formal guarantees of safe behavior. This
paper establishes the safety-critical control of fixed-wing aircraft in
collision avoidance and geofencing tasks. A control framework is developed
wherein a run-time assurance (RTA) system modulates the nominal flight
controller of the aircraft whenever necessary to prevent it from colliding with
other aircraft or crossing a boundary (geofence) in space. The RTA is
formulated as a safety filter using control barrier functions (CBFs) with
formal guarantees of safe behavior. CBFs are constructed and compared for a
nonlinear kinematic fixed-wing aircraft model. The proposed CBF-based
controllers showcase the capability of safely executing simultaneous collision
avoidance and geofencing, as demonstrated by simulations on the kinematic model
and a high-fidelity dynamical model.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02509" title="Abstract">arXiv:2403.02509</a> [<a href="/pdf/2403.02509" title="Download PDF">pdf</a>, <a href="/format/2403.02509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPUQ: Perturbation-Based Uncertainty Quantification for Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mouatadid%2C+L">Lalla Mouatadid</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+K">Kamalika Das</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to appear at EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In recent years, large language models (LLMs) have become increasingly
prevalent, offering remarkable text generation capabilities. However, a
pressing challenge is their tendency to make confidently wrong predictions,
highlighting the critical need for uncertainty quantification (UQ) in LLMs.
While previous works have mainly focused on addressing aleatoric uncertainty,
the full spectrum of uncertainties, including epistemic, remains inadequately
explored. Motivated by this gap, we introduce a novel UQ method, sampling with
perturbation for UQ (SPUQ), designed to tackle both aleatoric and epistemic
uncertainties. The method entails generating a set of perturbations for LLM
inputs, sampling outputs for each perturbation, and incorporating an
aggregation module that generalizes the sampling uncertainty approach for text
generation tasks. Through extensive experiments on various datasets, we
investigated different perturbation and aggregation techniques. Our findings
show a substantial improvement in model uncertainty calibration, with a
reduction in Expected Calibration Error (ECE) by 50\% on average. Our findings
suggest that our proposed UQ method offers promising steps toward enhancing the
reliability and trustworthiness of LLMs.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02513" title="Abstract">arXiv:2403.02513</a> [<a href="/pdf/2403.02513" title="Download PDF">pdf</a>, <a href="/format/2403.02513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balancing Enhancement, Harmlessness, and General Capabilities: Enhancing  Conversational LLMs with Direct RLHF
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+K">Ke Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+C">Chenguang Xi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xun Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In recent advancements in Conversational Large Language Models (LLMs), a
concerning trend has emerged, showing that many new base LLMs experience a
knowledge reduction in their foundational capabilities following Supervised
Fine-Tuning (SFT). This process often leads to issues such as forgetting or a
decrease in the base model's abilities. Moreover, fine-tuned models struggle to
align with user preferences, inadvertently increasing the generation of toxic
outputs when specifically prompted. To overcome these challenges, we adopted an
innovative approach by completely bypassing SFT and directly implementing
Harmless Reinforcement Learning from Human Feedback (RLHF). Our method not only
preserves the base model's general capabilities but also significantly enhances
its conversational abilities, while notably reducing the generation of toxic
outputs. Our approach holds significant implications for fields that demand a
nuanced understanding and generation of responses, such as customer service. We
applied this methodology to Mistral, the most popular base model, thereby
creating Mistral-Plus. Our validation across 11 general tasks demonstrates that
Mistral-Plus outperforms similarly sized open-source base models and their
corresponding instruct versions. Importantly, the conversational abilities of
Mistral-Plus were significantly improved, indicating a substantial advancement
over traditional SFT models in both safety and user preference alignment.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02514" title="Abstract">arXiv:2403.02514</a> [<a href="/pdf/2403.02514" title="Download PDF">pdf</a>, <a href="/format/2403.02514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Purpose for Open-Ended Learning Robots: A Computational Taxonomy,  Definition, and Operationalisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baldassarre%2C+G">Gianluca Baldassarre</a>, 
<a href="/search/cs?searchtype=author&query=Duro%2C+R+J">Richard J. Duro</a>, 
<a href="/search/cs?searchtype=author&query=Cartoni%2C+E">Emilio Cartoni</a>, 
<a href="/search/cs?searchtype=author&query=Khamassi%2C+M">Mehdi Khamassi</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+A">Alejandro Romero</a>, 
<a href="/search/cs?searchtype=author&query=Santucci%2C+V+G">Vieri Giuliano Santucci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Autonomous open-ended learning (OEL) robots are able to cumulatively acquire
new skills and knowledge through direct interaction with the environment, for
example relying on the guidance of intrinsic motivations and self-generated
goals. OEL robots have a high relevance for applications as they can use the
autonomously acquired knowledge to accomplish tasks relevant for their human
users. OEL robots, however, encounter an important limitation: this may lead to
the acquisition of knowledge that is not so much relevant to accomplish the
users' tasks. This work analyses a possible solution to this problem that
pivots on the novel concept of `purpose'. Purposes indicate what the designers
and/or users want from the robot. The robot should use internal representations
of purposes, called here `desires', to focus its open-ended exploration towards
the acquisition of knowledge relevant to accomplish them. This work contributes
to develop a computational framework on purpose in two ways. First, it
formalises a framework on purpose based on a three-level motivational hierarchy
involving: (a) the purposes; (b) the desires, which are domain independent; (c)
specific domain dependent state-goals. Second, the work highlights key
challenges highlighted by the framework such as: the `purpose-desire alignment
problem', the `purpose-goal grounding problem', and the `arbitration between
desires'. Overall, the approach enables OEL robots to learn in an autonomous
way but also to focus on acquiring goals and skills that meet the purposes of
the designers and users.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02518" title="Abstract">arXiv:2403.02518</a> [<a href="/pdf/2403.02518" title="Download PDF">pdf</a>, <a href="/format/2403.02518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MPI Errors Detection using GNN Embedding and Vector Embedding over LLVM  IR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karchi%2C+J+E">Jad El Karchi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hanze Chen</a>, 
<a href="/search/cs?searchtype=author&query=TehraniJamsaz%2C+A">Ali TehraniJamsaz</a>, 
<a href="/search/cs?searchtype=author&query=Jannesari%2C+A">Ali Jannesari</a>, 
<a href="/search/cs?searchtype=author&query=Popov%2C+M">Mihail Popov</a>, 
<a href="/search/cs?searchtype=author&query=Saillard%2C+E">Emmanuelle Saillard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Identifying errors in parallel MPI programs is a challenging task. Despite
the growing number of verification tools, debugging parallel programs remains a
significant challenge. This paper is the first to utilize embedding and deep
learning graph neural networks (GNNs) to tackle the issue of identifying bugs
in MPI programs. Specifically, we have designed and developed two models that
can determine, from a code's LLVM Intermediate Representation (IR), whether the
code is correct or contains a known MPI error. We tested our models using two
dedicated MPI benchmark suites for verification: MBI and MPI-CorrBench. By
training and validating our models on the same benchmark suite, we achieved a
prediction accuracy of 92% in detecting error types. Additionally, we trained
and evaluated our models on distinct benchmark suites (e.g., transitioning from
MBI to MPI-CorrBench) and achieved a promising accuracy of over 80%. Finally,
we investigated the interaction between different MPI errors and quantified our
models' generalization capabilities over new unseen errors. This involved
removing error types during training and assessing whether our models could
still predict them. The detection accuracy of removed errors varies
significantly between 20% to 80%, indicating connected error patterns.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02522" title="Abstract">arXiv:2403.02522</a> [<a href="/pdf/2403.02522" title="Download PDF">pdf</a>, <a href="/format/2403.02522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HeAR -- Health Acoustic Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baur%2C+S">Sebastien Baur</a>, 
<a href="/search/cs?searchtype=author&query=Nabulsi%2C+Z">Zaid Nabulsi</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+W">Wei-Hung Weng</a>, 
<a href="/search/cs?searchtype=author&query=Garrison%2C+J">Jake Garrison</a>, 
<a href="/search/cs?searchtype=author&query=Blankemeier%2C+L">Louis Blankemeier</a>, 
<a href="/search/cs?searchtype=author&query=Fishman%2C+S">Sam Fishman</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Christina Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kakarmath%2C+S">Sujay Kakarmath</a>, 
<a href="/search/cs?searchtype=author&query=Maimbolwa%2C+M">Minyoi Maimbolwa</a>, 
<a href="/search/cs?searchtype=author&query=Sanjase%2C+N">Nsala Sanjase</a>, 
<a href="/search/cs?searchtype=author&query=Shuma%2C+B">Brian Shuma</a>, 
<a href="/search/cs?searchtype=author&query=Matias%2C+Y">Yossi Matias</a>, 
<a href="/search/cs?searchtype=author&query=Corrado%2C+G+S">Greg S. Corrado</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+S">Shwetak Patel</a>, 
<a href="/search/cs?searchtype=author&query=Shetty%2C+S">Shravya Shetty</a>, 
<a href="/search/cs?searchtype=author&query=Prabhakara%2C+S">Shruthi Prabhakara</a>, 
<a href="/search/cs?searchtype=author&query=Muyoyeta%2C+M">Monde Muyoyeta</a>, 
<a href="/search/cs?searchtype=author&query=Ardila%2C+D">Diego Ardila</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 tables, 4 figures, 6 supplementary tables, 3 supplementary figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Health acoustic sounds such as coughs and breaths are known to contain useful
health signals with significant potential for monitoring health and disease,
yet are underexplored in the medical machine learning community. The existing
deep learning systems for health acoustics are often narrowly trained and
evaluated on a single task, which is limited by data and may hinder
generalization to other tasks. To mitigate these gaps, we develop HeAR, a
scalable self-supervised learning-based deep learning system using masked
autoencoders trained on a large dataset of 313 million two-second long audio
clips. Through linear probes, we establish HeAR as a state-of-the-art health
audio embedding model on a benchmark of 33 health acoustic tasks across 6
datasets. By introducing this work, we hope to enable and accelerate further
health acoustics research.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02523" title="Abstract">arXiv:2403.02523</a> [<a href="/pdf/2403.02523" title="Download PDF">pdf</a>, <a href="/format/2403.02523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer for Times Series: an Application to the S&amp;P500
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brugiere%2C+P">Pierre Brugiere</a>, 
<a href="/search/cs?searchtype=author&query=Turinici%2C+G">Gabriel Turinici</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Portfolio Management (q-fin.PM); Statistical Finance (q-fin.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">The transformer models have been extensively used with good results in a wide
area of machine learning applications including Large Language Models and image
generation. Here, we inquire on the applicability of this approach to financial
time series. We first describe the dataset construction for two prototypical
situations: a mean reverting synthetic Ornstein-Uhlenbeck process on one hand
and real S&amp;P500 data on the other hand. Then, we present in detail the proposed
Transformer architecture and finally we discuss some encouraging results. For
the synthetic data we predict rather accurately the next move, and for the
S&amp;P500 we get some interesting results related to quadratic variation and
volatility prediction.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02525" title="Abstract">arXiv:2403.02525</a> [<a href="/pdf/2403.02525" title="Download PDF">pdf</a>, <a href="/format/2403.02525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Analysis of Intent-Based Markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chitra%2C+T">Tarun Chitra</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+K">Kshitij Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Pai%2C+M">Mallesh Pai</a>, 
<a href="/search/cs?searchtype=author&query=Diamandis%2C+T">Theo Diamandis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Mechanisms for decentralized finance on blockchains suffer from various
problems, including suboptimal price execution for users, latency, and a worse
user experience compared to their centralized counterparts. Recently, off-chain
marketplaces, colloquially called `intent markets,' have been proposed as a
solution to these problems. In these markets, agents called \emph{solvers}
compete to satisfy user orders, which may include complicated user-specified
conditions. We provide two formal models of solvers' strategic behavior: one
probabilistic and another deterministic. In our first model, solvers initially
pay upfront costs to enter a Dutch auction to fill the user's order and then
exert congestive, costly effort to search for prices for the user. Our results
show that the costs incurred by solvers result in restricted entry in the
market. Further, in the presence of costly effort and congestion, our results
counter-intuitively show that a planner who aims to maximize user welfare may
actually prefer to restrict entry, resulting in limited oligopoly. We then
introduce an alternative, optimization-based deterministic model which
corroborates these results. We conclude with extensions of our model to other
auctions within blockchains and non-cryptocurrency applications, such as the US
SEC's Proposal 615.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02527" title="Abstract">arXiv:2403.02527</a> [<a href="/pdf/2403.02527" title="Download PDF">pdf</a>, <a href="/ps/2403.02527" title="Download PostScript">ps</a>, <a href="/format/2403.02527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A dataset of over one thousand computed tomography scans of battery  cells
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Condon%2C+A">Amariah Condon</a>, 
<a href="/search/cs?searchtype=author&query=Buscarino%2C+B">Bailey Buscarino</a>, 
<a href="/search/cs?searchtype=author&query=Moch%2C+E">Eric Moch</a>, 
<a href="/search/cs?searchtype=author&query=Sehnert%2C+W+J">William J. Sehnert</a>, 
<a href="/search/cs?searchtype=author&query=Miles%2C+O">Owen Miles</a>, 
<a href="/search/cs?searchtype=author&query=Herring%2C+P+K">Patrick K. Herring</a>, 
<a href="/search/cs?searchtype=author&query=Attia%2C+P+M">Peter M. Attia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Battery technology is increasingly important for global electrification
efforts. However, batteries are highly sensitive to small manufacturing
variations that can induce reliability or safety issues. An important
technology for battery quality control is computed tomography (CT) scanning,
which is widely used for non-destructive 3D inspection across a variety of
clinical and industrial applications. Historically, however, the utility of CT
scanning for high-volume manufacturing has been limited by its low throughput
as well as the difficulty of handling its large file sizes. In this work, we
present a dataset of over one thousand CT scans of as-produced commercially
available batteries. The dataset spans various chemistries (lithium-ion and
sodium-ion) as well as various battery form factors (cylindrical, pouch, and
prismatic). We evaluate seven different battery types in total. The
manufacturing variability and the presence of battery defects can be observed
via this dataset. This dataset may be of interest to scientists and engineers
working on battery technology, computer vision, or both.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02528" title="Abstract">arXiv:2403.02528</a> [<a href="/pdf/2403.02528" title="Download PDF">pdf</a>, <a href="/format/2403.02528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DACO: Towards Application-Driven and Comprehensive Data Analysis via  Code Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xueqing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Rui Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Sha%2C+J">Jingzhen Sha</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Te-Lin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hanyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+M">Mohan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+N">Nanyun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haoran Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Data analysis is a crucial analytical process to generate in-depth studies
and conclusive insights to comprehensively answer a given user query for
tabular data. In this work, we aim to propose new resources and benchmarks to
inspire future research on this crucial yet challenging and under-explored
task. However, collecting data analysis annotations curated by experts can be
prohibitively expensive. We propose to automatically generate high-quality
answer annotations leveraging the code-generation capabilities of LLMs with a
multi-turn prompting technique. We construct the DACO dataset, containing (1)
440 databases (of tabular data) collected from real-world scenarios, (2) ~2k
query-answer pairs that can serve as weak supervision for model training, and
(3) a concentrated but high-quality test set with human refined annotations
that serves as our main evaluation benchmark. We train a 6B supervised
fine-tuning (SFT) model on DACO dataset, and find that the SFT model learns
reasonable data analysis capabilities. To further align the models with human
preference, we use reinforcement learning to encourage generating analysis
perceived by human as helpful, and design a set of dense rewards to propagate
the sparse human preference reward to intermediate code generation steps. Our
DACO-RL algorithm is evaluated by human annotators to produce more helpful
answers than SFT model in 57.72% cases, validating the effectiveness of our
proposed algorithm. Data and code are released at
https://github.com/shirley-wu/daco
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02529" title="Abstract">arXiv:2403.02529</a> [<a href="/pdf/2403.02529" title="Download PDF">pdf</a>, <a href="/format/2403.02529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secret-Key Capacity from MIMO Channel Probing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hua%2C+Y">Yingbo Hua</a>, 
<a href="/search/cs?searchtype=author&query=Maksud%2C+A">Ahmed Maksud</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in IEEE Wireless Communications Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Revealing expressions of secret-key capacity (SKC) based on data sets from
Gaussian MIMO channel probing are presented. It is shown that Maurer's upper
and lower bounds on SKC coincide when the used data sets are produced from
one-way channel probing. As channel coherence time increases, SKC in bits per
probing channel use is always lower bounded by a positive value unless
eavesdropper's observations are noiseless, which is unlike SKC solely based on
reciprocal channels.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02531" title="Abstract">arXiv:2403.02531</a> [<a href="/pdf/2403.02531" title="Download PDF">pdf</a>, <a href="/format/2403.02531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Density-based Isometric Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yousefi%2C+B">Bardia Yousefi</a>, 
<a href="/search/cs?searchtype=author&query=Khansari%2C+M">M&#xe9;lina Khansari</a>, 
<a href="/search/cs?searchtype=author&query=Trask%2C+R">Ryan Trask</a>, 
<a href="/search/cs?searchtype=author&query=Tallon%2C+P">Patrick Tallon</a>, 
<a href="/search/cs?searchtype=author&query=Carino%2C+C">Carina Carino</a>, 
<a href="/search/cs?searchtype=author&query=Afrasiyabi%2C+A">Arman Afrasiyabi</a>, 
<a href="/search/cs?searchtype=author&query=Kundra%2C+V">Vikas Kundra</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+L">Lei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Farahani%2C+K">Keyvan Farahani</a>, 
<a href="/search/cs?searchtype=author&query=Hershman%2C+M">Michelle Hershman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the author's version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The isometric mapping method employs the shortest path algorithm to estimate
the Euclidean distance between points on High dimensional (HD) manifolds. This
may not be sufficient for weakly uniformed HD data as it could lead to
overestimating distances between far neighboring points, resulting in
inconsistencies between the intrinsic (local) and extrinsic (global) distances
during the projection. To address this issue, we modify the shortest path
algorithm by adding a novel constraint inspired by the Parzen-Rosenblatt (PR)
window, which helps to maintain the uniformity of the constructed shortest-path
graph in Isomap. Multiple imaging datasets overall of 72,236 cases, 70,000
MINST data, 1596 from multiple Chest-XRay pneumonia datasets, and three NSCLC
CT/PET datasets with a total of 640 lung cancer patients, were used to
benchmark and validate PR-Isomap. 431 imaging biomarkers were extracted from
each modality. Our results indicate that PR-Isomap projects HD attributes into
a lower-dimensional (LD) space while preserving information, visualized by the
MNIST dataset indicating the maintaining local and global distances. PR-Isomap
achieved the highest comparative accuracies of 80.9% (STD:5.8) for pneumonia
and 78.5% (STD:4.4), 88.4% (STD:1.4), and 61.4% (STD:11.4) for three NSCLC
datasets, with a confidence interval of 95% for outcome prediction. Similarly,
the multivariate Cox model showed higher overall survival, measured with
c-statistics and log-likelihood test, of PR-Isomap compared to other
dimensionality reduction methods. Kaplan Meier survival curve also signifies
the notable ability of PR-Isomap to distinguish between high-risk and low-risk
patients using multimodal imaging biomarkers preserving HD imaging
characteristics for precision medicine.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02534" title="Abstract">arXiv:2403.02534</a> [<a href="/pdf/2403.02534" title="Download PDF">pdf</a>, <a href="/format/2403.02534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Foundation Time Series Model: To Synthesize Or Not To  Synthesize?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuvshinova%2C+K">Kseniia Kuvshinova</a>, 
<a href="/search/cs?searchtype=author&query=Tsymboi%2C+O">Olga Tsymboi</a>, 
<a href="/search/cs?searchtype=author&query=Kostromina%2C+A">Alina Kostromina</a>, 
<a href="/search/cs?searchtype=author&query=Simakov%2C+D">Dmitry Simakov</a>, 
<a href="/search/cs?searchtype=author&query=Kovtun%2C+E">Elizaveta Kovtun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The industry is rich in cases when we are required to make forecasting for
large amounts of time series at once. However, we might be in a situation where
we can not afford to train a separate model for each of them. Such issue in
time series modeling remains without due attention. The remedy for this setting
is the establishment of a foundation model. Such a model is expected to work in
zero-shot and few-shot regimes. However, what should we take as a training
dataset for such kind of model?
<br />Witnessing the benefits from the enrichment of NLP datasets with
artificially-generated data, we might want to adopt their experience for time
series. In contrast to natural language, the process of generation of synthetic
time series data is even more favorable because it provides full control of
series patterns, time horizons, and number of samples. In this work, we
consider the essential question if it is advantageous to train a foundation
model on synthetic data or it is better to utilize only a limited number of
real-life examples. Our experiments are conducted only for regular time series
and speak in favor of leveraging solely the real time series. Moreover, the
choice of the proper source dataset strongly influences the performance during
inference. When provided access even to a limited quantity of short time series
data, employing it within a supervised framework yields more favorable results
than training on a larger volume of synthetic data. The code for our
experiments is publicly available on Github
\url{https://github.com/sb-ai-lab/synthesize_or_not}.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02545" title="Abstract">arXiv:2403.02545</a> [<a href="/pdf/2403.02545" title="Download PDF">pdf</a>, <a href="/format/2403.02545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wukong: Towards a Scaling Law for Large-Scale Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Buyun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Liang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+J">Jade Nie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Daifeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yanli Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shen Li</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yuchen Hao</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yantao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Lakshminarayanan%2C+G">Guna Lakshminarayanan</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+E+D">Ellie Dingqiao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jongsoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Naumov%2C+M">Maxim Naumov</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenlin Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Scaling laws play an instrumental role in the sustainable improvement in
model quality. Unfortunately, recommendation models to date do not exhibit such
laws similar to those observed in the domain of large language models, due to
the inefficiencies of their upscaling mechanisms. This limitation poses
significant challenges in adapting these models to increasingly more complex
real-world datasets. In this paper, we propose an effective network
architecture based purely on stacked factorization machines, and a synergistic
upscaling strategy, collectively dubbed Wukong, to establish a scaling law in
the domain of recommendation. Wukong's unique design makes it possible to
capture diverse, any-order of interactions simply through taller and wider
layers. We conducted extensive evaluations on six public datasets, and our
results demonstrate that Wukong consistently outperforms state-of-the-art
models quality-wise. Further, we assessed Wukong's scalability on an internal,
large-scale dataset. The results show that Wukong retains its superiority in
quality over state-of-the-art models, while holding the scaling law across two
orders of magnitude in model complexity, extending beyond 100 Gflop or
equivalently up to GPT-3/LLaMa-2 scale of total training compute, where prior
arts fall short.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02546" title="Abstract">arXiv:2403.02546</a> [<a href="/pdf/2403.02546" title="Download PDF">pdf</a>, <a href="/format/2403.02546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Catch&#x27;em all: Classification of Rare, Prominent, and Novel Malware  Families
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eren%2C+M+E">Maksim E. Eren</a>, 
<a href="/search/cs?searchtype=author&query=Barron%2C+R">Ryan Barron</a>, 
<a href="/search/cs?searchtype=author&query=Bhattarai%2C+M">Manish Bhattarai</a>, 
<a href="/search/cs?searchtype=author&query=Wanna%2C+S">Selma Wanna</a>, 
<a href="/search/cs?searchtype=author&query=Solovyev%2C+N">Nicholas Solovyev</a>, 
<a href="/search/cs?searchtype=author&query=Rasmussen%2C+K">Kim Rasmussen</a>, 
<a href="/search/cs?searchtype=author&query=Alexandrov%2C+B+S">Boian S. Alexandrov</a>, 
<a href="/search/cs?searchtype=author&query=Nicholas%2C+C">Charles Nicholas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE 12th International Symposium on Digital Forensics and Security (ISDFS), 2024. arXiv admin note: text overlap with <a href="/abs/2309.01350">arXiv:2309.01350</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">National security is threatened by malware, which remains one of the most
dangerous and costly cyber threats. As of last year, researchers reported 1.3
billion known malware specimens, motivating the use of data-driven machine
learning (ML) methods for analysis. However, shortcomings in existing ML
approaches hinder their mass adoption. These challenges include detection of
novel malware and the ability to perform malware classification in the face of
class imbalance: a situation where malware families are not equally represented
in the data. Our work addresses these shortcomings with MalwareDNA: an advanced
dimensionality reduction and feature extraction framework. We demonstrate
stable task performance under class imbalance for the following tasks: malware
family classification and novel malware detection with a trade-off in increased
abstention or reject-option rate.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02547" title="Abstract">arXiv:2403.02547</a> [<a href="/pdf/2403.02547" title="Download PDF">pdf</a>, <a href="/format/2403.02547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Projection Mapping under Environmental Lighting by Replacing Room Lights  with Heterogeneous Projectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Takeuchi%2C+M">Masaki Takeuchi</a>, 
<a href="/search/cs?searchtype=author&query=Kusuyama%2C+H">Hiroki Kusuyama</a>, 
<a href="/search/cs?searchtype=author&query=Iwai%2C+D">Daisuke Iwai</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+K">Kosuke Sato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Projection mapping (PM) is a technique that enhances the appearance of
real-world surfaces using projected images, enabling multiple people to view
augmentations simultaneously, thereby facilitating communication and
collaboration. However, PM typically requires a dark environment to achieve
high-quality projections, limiting its practicality. In this paper, we overcome
this limitation by replacing conventional room lighting with heterogeneous
projectors. These projectors replicate environmental lighting by selectively
illuminating the scene, excluding the projection target. Our contributions
include a distributed projector optimization framework designed to effectively
replicate environmental lighting and the incorporation of a large-aperture
projector, in addition to standard projectors, to reduce high-luminance emitted
rays and hard shadows -- undesirable factors for collaborative tasks in PM. We
conducted a series of quantitative and qualitative experiments, including user
studies, to validate our approach. Our findings demonstrate that our
projector-based lighting system significantly enhances the contrast and realism
of PM results even under environmental lighting compared to typical lights.
Furthermore, our method facilitates a substantial shift in the perceived color
mode from the undesirable aperture-color mode, where observers perceive the
projected object as self-luminous, to the surface-color mode in PM.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02558" title="Abstract">arXiv:2403.02558</a> [<a href="/pdf/2403.02558" title="Download PDF">pdf</a>, <a href="/ps/2403.02558" title="Download PostScript">ps</a>, <a href="/format/2403.02558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Updating the Minimum Information about CLinical Artificial Intelligence  (MI-CLAIM) checklist for generative modeling research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miao%2C+B+Y">Brenda Y. Miao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+I+Y">Irene Y. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+C+Y">Christopher YK Williams</a>, 
<a href="/search/cs?searchtype=author&query=Davidson%2C+J">Jays&#xf3;n Davidson</a>, 
<a href="/search/cs?searchtype=author&query=Garcia-Agundez%2C+A">Augusto Garcia-Agundez</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Harry Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zack%2C+T">Travis Zack</a>, 
<a href="/search/cs?searchtype=author&query=Butte%2C+A+J">Atul J. Butte</a>, 
<a href="/search/cs?searchtype=author&query=Sushil%2C+M">Madhumita Sushil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recent advances in generative models, including large language models (LLMs),
vision language models (VLMs), and diffusion models, have accelerated the field
of natural language and image processing in medicine and marked a significant
paradigm shift in how biomedical models can be developed and deployed. While
these models are highly adaptable to new tasks, scaling and evaluating their
usage presents new challenges not addressed in previous frameworks. In
particular, the ability of these models to produce useful outputs with little
to no specialized training data ("zero-" or "few-shot" approaches), as well as
the open-ended nature of their outputs, necessitate the development of updated
guidelines in using and evaluating these models. In response to gaps in
standards and best practices for the development of clinical AI tools
identified by US Executive Order 141103 and several emerging national networks
for clinical AI evaluation, we begin to formalize some of these guidelines by
building on the "Minimum information about clinical artificial intelligence
modeling" (MI-CLAIM) checklist. The MI-CLAIM checklist, originally developed in
2020, provided a set of six steps with guidelines on the minimum information
necessary to encourage transparent, reproducible research for artificial
intelligence (AI) in medicine. Here, we propose modifications to the original
checklist that highlight differences in training, evaluation, interpretability,
and reproducibility of generative models compared to traditional AI models for
clinical research. This updated checklist also seeks to clarify cohort
selection reporting and adds additional items on alignment with ethical
standards.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02561" title="Abstract">arXiv:2403.02561</a> [<a href="/pdf/2403.02561" title="Download PDF">pdf</a>, <a href="/format/2403.02561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Human Mesh Reconstruction with Textures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xiaoyu Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianxin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jie Guo</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yanwen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The field of 3D detailed human mesh reconstruction has made significant
progress in recent years. However, current methods still face challenges when
used in industrial applications due to unstable results, low-quality meshes,
and a lack of UV unwrapping and skinning weights. In this paper, we present
SHERT, a novel pipeline that can reconstruct semantic human meshes with
textures and high-precision details. SHERT applies semantic- and normal-based
sampling between the detailed surface (eg mesh and SDF) and the corresponding
SMPL-X model to obtain a partially sampled semantic mesh and then generates the
complete semantic mesh by our specifically designed self-supervised completion
and refinement networks. Using the complete semantic mesh as a basis, we employ
a texture diffusion model to create human textures that are driven by both
images and texts. Our reconstructed meshes have stable UV unwrapping,
high-quality triangle meshes, and consistent semantic information. The given
SMPL-X model provides semantic information and shape priors, allowing SHERT to
perform well even with incorrect and incomplete inputs. The semantic
information also makes it easy to substitute and animate different body parts
such as the face, body, and hands. Quantitative and qualitative experiments
demonstrate that SHERT is capable of producing high-fidelity and robust
semantic meshes that outperform state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02563" title="Abstract">arXiv:2403.02563</a> [<a href="/pdf/2403.02563" title="Download PDF">pdf</a>, <a href="/ps/2403.02563" title="Download PostScript">ps</a>, <a href="/format/2403.02563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Systemic Biases in Sign Language AI Research: A Deaf-Led Call to  Reevaluate Research Agendas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Desai%2C+A">Aashaka Desai</a>, 
<a href="/search/cs?searchtype=author&query=De+Meulder%2C+M">Maartje De Meulder</a>, 
<a href="/search/cs?searchtype=author&query=Hochgesang%2C+J+A">Julie A. Hochgesang</a>, 
<a href="/search/cs?searchtype=author&query=Kocab%2C+A">Annemarie Kocab</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+A+X">Alex X. Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Growing research in sign language recognition, generation, and translation AI
has been accompanied by calls for ethical development of such technologies.
While these works are crucial to helping individual researchers do better,
there is a notable lack of discussion of systemic biases or analysis of
rhetoric that shape the research questions and methods in the field, especially
as it remains dominated by hearing non-signing researchers. Therefore, we
conduct a systematic review of 101 recent papers in sign language AI. Our
analysis identifies significant biases in the current state of sign language AI
research, including an overfocus on addressing perceived communication
barriers, a lack of use of representative datasets, use of annotations lacking
linguistic foundations, and development of methods that build on flawed models.
We take the position that the field lacks meaningful input from Deaf
stakeholders, and is instead driven by what decisions are the most convenient
or perceived as important to hearing researchers. We end with a call to action:
the field must make space for Deaf researchers to lead the conversation in sign
language AI.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02567" title="Abstract">arXiv:2403.02567</a> [<a href="/pdf/2403.02567" title="Download PDF">pdf</a>, <a href="/format/2403.02567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eliciting Better Multilingual Structured Reasoning from LLMs through  Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bryan Li</a>, 
<a href="/search/cs?searchtype=author&query=Alkhouli%2C+T">Tamer Alkhouli</a>, 
<a href="/search/cs?searchtype=author&query=Bonadiman%2C+D">Daniele Bonadiman</a>, 
<a href="/search/cs?searchtype=author&query=Pappas%2C+N">Nikolaos Pappas</a>, 
<a href="/search/cs?searchtype=author&query=Mansour%2C+S">Saab Mansour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Development of large language models (LLM) have shown progress on reasoning,
though studies have been limited to English or simple reasoning tasks. We thus
introduce a multilingual structured reasoning and explanation dataset, termed
xSTREET, that covers four tasks across six languages. xSTREET exposes a gap in
base LLM performance between English and non-English reasoning tasks. We then
propose two methods to remedy this gap, building on the insight that LLMs
trained on code are better reasoners. First, at training time, we augment a
code dataset with multi-lingual comments using machine translation while
keeping program code as-is. Second, at inference time, we bridge the gap
between training and inference by employing a prompt structure that
incorporates step-by-step code primitives to derive new facts and find a
solution. Our methods show improved multilingual performance on xSTREET, most
notably on the scientific commonsense reasoning subtask. Furthermore, the
models show no regression on non-reasoning tasks, thus showing our techniques
maintain general-purpose abilities.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02568" title="Abstract">arXiv:2403.02568</a> [<a href="/pdf/2403.02568" title="Download PDF">pdf</a>, <a href="/format/2403.02568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Born Accessible Data Science and Visualization Courses: Challenges of  Developing Curriculum to be Taught by Blind Instructors to Blind Students
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">JooYoung Seo</a>, 
<a href="/search/cs?searchtype=author&query=O%27Modhrain%2C+S">Sile O&#x27;Modhrain</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yilin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Kamath%2C+S">Sanchita Kamath</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Bongshin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Coughlan%2C+J+M">James M. Coughlan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">While recent years have seen a growing interest in accessible visualization
tools and techniques for blind people, little attention is paid to the learning
opportunities and teaching strategies of data science and visualization
tailored for blind individuals. Whereas the former focuses on the accessibility
issues of data visualization tools, the latter is concerned with the
learnability of concepts and skills for data science and visualization. In this
paper, we present novel approaches to teaching data science and visualization
to blind students in an online setting. Taught by blind instructors, nine blind
learners having a wide range of professional backgrounds participated in a
two-week summer course. We describe the course design, teaching strategies, and
learning outcomes. We also discuss the challenges and opportunities of teaching
data science and visualization to blind students. Our work contributes to the
growing body of knowledge on accessible data science and visualization
education, and provides insights into the design of online courses for blind
students.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02571" title="Abstract">arXiv:2403.02571</a> [<a href="/pdf/2403.02571" title="Download PDF">pdf</a>, <a href="/format/2403.02571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DPAdapter: Improving Differentially Private Deep Learning through Noise  Tolerance Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+R">Rui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Dongruo Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhikun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+J">John Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Haixu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">XiaoFeng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the 33rd USENIX Security Symposium, August 2024, Philadelphia Marriott Downtown, PA, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recent developments have underscored the critical role of
\textit{differential privacy} (DP) in safeguarding individual data for training
machine learning models. However, integrating DP oftentimes incurs significant
model performance degradation due to the perturbation introduced into the
training process, presenting a formidable challenge in the {differentially
private machine learning} (DPML) field. To this end, several mitigative efforts
have been proposed, typically revolving around formulating new DPML algorithms
or relaxing DP definitions to harmonize with distinct contexts. In spite of
these initiatives, the diminishment induced by DP on models, particularly
large-scale models, remains substantial and thus, necessitates an innovative
solution that adeptly circumnavigates the consequential impairment of model
utility.
<br />In response, we introduce DPAdapter, a pioneering technique designed to
amplify the model performance of DPML algorithms by enhancing parameter
robustness. The fundamental intuition behind this strategy is that models with
robust parameters are inherently more resistant to the noise introduced by DP,
thereby retaining better performance despite the perturbations. DPAdapter
modifies and enhances the sharpness-aware minimization (SAM) technique,
utilizing a two-batch strategy to provide a more accurate perturbation estimate
and an efficient gradient descent, thereby improving parameter robustness
against noise. Notably, DPAdapter can act as a plug-and-play component and be
combined with existing DPML algorithms to further improve their performance.
Our experiments show that DPAdapter vastly enhances state-of-the-art DPML
algorithms, increasing average accuracy from 72.92\% to 77.09\% with a privacy
budget of $\epsilon=4$.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02573" title="Abstract">arXiv:2403.02573</a> [<a href="/pdf/2403.02573" title="Download PDF">pdf</a>, <a href="/format/2403.02573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning-augmented Online Minimization of Age of Information and  Transmission Costs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhongdong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Keyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bin Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y+T">Y. Thomas Hou</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+B">Bo Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preliminary version of this work is to be presented at IEEE INFOCOM 2024 Age and Semantics of Information Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We consider a discrete-time system where a resource-constrained source (e.g.,
a small sensor) transmits its time-sensitive data to a destination over a
time-varying wireless channel. Each transmission incurs a fixed transmission
cost (e.g., energy cost), and no transmission results in a staleness cost
represented by the Age-of-Information. The source must balance the tradeoff
between transmission and staleness costs. To address this challenge, we develop
a robust online algorithm to minimize the sum of transmission and staleness
costs, ensuring a worst-case performance guarantee. While online algorithms are
robust, they are usually overly conservative and may have a poor average
performance in typical scenarios. In contrast, by leveraging historical data
and prediction models, machine learning (ML) algorithms perform well in average
cases. However, they typically lack worst-case performance guarantees. To
achieve the best of both worlds, we design a learning-augmented online
algorithm that exhibits two desired properties: (i) consistency: closely
approximating the optimal offline algorithm when the ML prediction is accurate
and trusted; (ii) robustness: ensuring worst-case performance guarantee even ML
predictions are inaccurate. Finally, we perform extensive simulations to show
that our online algorithm performs well empirically and that our
learning-augmented algorithm achieves both consistency and robustness.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02574" title="Abstract">arXiv:2403.02574</a> [<a href="/pdf/2403.02574" title="Download PDF">pdf</a>, <a href="/format/2403.02574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatCite: LLM Agent with Human Workflow Guidance for Comparative  Literature Summary
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yutong Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Aiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kai Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+L">Lijie Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">The literature review is an indispensable step in the research process. It
provides the benefit of comprehending the research problem and understanding
the current research situation while conducting a comparative analysis of prior
works. However, literature summary is challenging and time consuming. The
previous LLM-based studies on literature review mainly focused on the complete
process, including literature retrieval, screening, and summarization. However,
for the summarization step, simple CoT method often lacks the ability to
provide extensive comparative summary. In this work, we firstly focus on the
independent literature summarization step and introduce ChatCite, an LLM agent
with human workflow guidance for comparative literature summary. This agent, by
mimicking the human workflow, first extracts key elements from relevant
literature and then generates summaries using a Reflective Incremental
Mechanism. In order to better evaluate the quality of the generated summaries,
we devised a LLM-based automatic evaluation metric, G-Score, in refer to the
human evaluation criteria. The ChatCite agent outperformed other models in
various dimensions in the experiments. The literature summaries generated by
ChatCite can also be directly used for drafting literature reviews.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02576" title="Abstract">arXiv:2403.02576</a> [<a href="/pdf/2403.02576" title="Download PDF">pdf</a>, <a href="/format/2403.02576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AceMap: Knowledge Discovery through Academic Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinbing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+L">Luoyi Fu</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+X">Xiaoying Gan</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Ying Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+G">Guanjie Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jiaxin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+L">Liyao Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+N">Nanyang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Meng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Shiyu Liang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+B">Bin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haiwen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Cheng Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+H">Huquan Kang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingli Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qi Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhixin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Jiexing Qi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Pan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yuyang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lyuwen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jungang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jianping Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chenghu Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report for AceMap (<a href="https://www.acemap.info">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The exponential growth of scientific literature requires effective management
and extraction of valuable insights. While existing scientific search engines
excel at delivering search results based on relational databases, they often
neglect the analysis of collaborations between scientific entities and the
evolution of ideas, as well as the in-depth analysis of content within
scientific publications. The representation of heterogeneous graphs and the
effective measurement, analysis, and mining of such graphs pose significant
challenges. To address these challenges, we present AceMap, an academic system
designed for knowledge discovery through academic graph. We present advanced
database construction techniques to build the comprehensive AceMap database
with large-scale academic publications that contain rich visual, textual, and
numerical information. AceMap also employs innovative visualization,
quantification, and analysis methods to explore associations and logical
relationships among academic entities. AceMap introduces large-scale academic
network visualization techniques centered on nebular graphs, providing a
comprehensive view of academic networks from multiple perspectives. In
addition, AceMap proposes a unified metric based on structural entropy to
quantitatively measure the knowledge content of different academic entities.
Moreover, AceMap provides advanced analysis capabilities, including tracing the
evolution of academic ideas through citation relationships and concept
co-occurrence, and generating concise summaries informed by this evolutionary
process. In addition, AceMap uses machine reading methods to generate potential
new ideas at the intersection of different fields. Exploring the integration of
large language models and knowledge graphs is a promising direction for future
research in idea evolution. Please visit \url{https://www.acemap.info} for
further exploration.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02580" title="Abstract">arXiv:2403.02580</a> [<a href="/pdf/2403.02580" title="Download PDF">pdf</a>, <a href="/format/2403.02580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What do we learn from inverting CLIP models?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kazemi%2C+H">Hamid Kazemi</a>, 
<a href="/search/cs?searchtype=author&query=Chegini%2C+A">Atoosa Chegini</a>, 
<a href="/search/cs?searchtype=author&query=Geiping%2C+J">Jonas Geiping</a>, 
<a href="/search/cs?searchtype=author&query=Feizi%2C+S">Soheil Feizi</a>, 
<a href="/search/cs?searchtype=author&query=Goldstein%2C+T">Tom Goldstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Warning: This paper contains sexually explicit images and language, offensive visuals and terminology, discussions on pornography, gender bias, and other potentially unsettling, distressing, and/or offensive content for certain readers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We employ an inversion-based approach to examine CLIP models. Our examination
reveals that inverting CLIP models results in the generation of images that
exhibit semantic alignment with the specified target prompts. We leverage these
inverted images to gain insights into various aspects of CLIP models, such as
their ability to blend concepts and inclusion of gender biases. We notably
observe instances of NSFW (Not Safe For Work) images during model inversion.
This phenomenon occurs even for semantically innocuous prompts, like "a
beautiful landscape," as well as for prompts involving the names of
celebrities.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02581" title="Abstract">arXiv:2403.02581</a> [<a href="/pdf/2403.02581" title="Download PDF">pdf</a>, <a href="/format/2403.02581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VEglue: Testing Visual Entailment Systems via Object-Aligned Joint  Erasing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+Z">Zhiyuan Chang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Cheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qing Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Visual entailment (VE) is a multimodal reasoning task consisting of
image-sentence pairs whereby a promise is defined by an image, and a hypothesis
is described by a sentence. The goal is to predict whether the image
semantically entails the sentence. VE systems have been widely adopted in many
downstream tasks. Metamorphic testing is the commonest technique for AI
algorithms, but it poses a significant challenge for VE testing. They either
only consider perturbations on single modality which would result in
ineffective tests due to the destruction of the relationship of image-text
pair, or just conduct shallow perturbations on the inputs which can hardly
detect the decision error made by VE systems. Motivated by the fact that
objects in the image are the fundamental element for reasoning, we propose
VEglue, an object-aligned joint erasing approach for VE systems testing. It
first aligns the object regions in the premise and object descriptions in the
hypothesis to identify linked and un-linked objects. Then, based on the
alignment information, three Metamorphic Relations are designed to jointly
erase the objects of the two modalities. We evaluate VEglue on four widely-used
VE systems involving two public datasets. Results show that VEglue could detect
11,609 issues on average, which is 194%-2,846% more than the baselines. In
addition, VEglue could reach 52.5% Issue Finding Rate (IFR) on average, and
significantly outperform the baselines by 17.1%-38.2%. Furthermore, we leverage
the tests generated by VEglue to retrain the VE systems, which largely improves
model performance (50.8% increase in accuracy) on newly generated tests without
sacrificing the accuracy on the original test set.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02582" title="Abstract">arXiv:2403.02582</a> [<a href="/pdf/2403.02582" title="Download PDF">pdf</a>, <a href="/ps/2403.02582" title="Download PostScript">ps</a>, <a href="/format/2403.02582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Approximate Fully-Dynamic Matching and Online Matrix-Vector  Multiplication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y+P">Yang P. Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study connections between the problem of fully dynamic
$(1-\epsilon)$-approximate maximum bipartite matching, and the dual
$(1+\epsilon)$-approximate vertex cover problem, with the online matrix-vector
($\mathsf{OMv}$) conjecture which has recently been used in several
fine-grained hardness reductions. We prove that there is an online algorithm
that maintains a $(1+\epsilon)$-approximate vertex cover in amortized
$n^{1-c}\epsilon^{-C}$ time for constants $c, C &gt; 0$ for fully dynamic updates
if and only if the $\mathsf{OMv}$ conjecture is false. Similarly, we prove that
there is an online algorithm that maintains a $(1-\epsilon)$-approximate
maximum matching in amortized $n^{1-c}\epsilon^{-C}$ time if and only if there
is a nontrivial algorithm for another dynamic problem, which we call dynamic
approximate $\mathsf{OMv}$, that has seemingly no matching structure. This
provides some evidence against achieving amortized sublinear update times for
approximate fully dynamic matching and vertex cover.
<br />Leveraging these connections, we obtain faster algorithms for approximate
fully dynamic matching in both the online and offline settings.
<br />1. We give a randomized algorithm that with high probability maintains a
$(1-\epsilon)$-approximate bipartite matching and $(1+\epsilon)$-approximate
vertex cover in fully dynamic graphs, in amortized $O(\epsilon^{-O(1)}
\frac{n}{2^{\Omega(\sqrt{\log n})}})$ update time. Our algorithm leverages fast
algorithms for $\mathsf{OMv}$ due to Larsen-Williams [SODA 2017].
<br />2. We give a randomized offline algorithm for $(1-\epsilon)$-approximate
maximum matching with amortized runtime $O(n^{.58}\epsilon^{-O(1)})$ by using
fast matrix multiplication, significantly improving over the runtimes achieved
via online algorithms. We also give an offline algorithm that maintains a
$(1+\epsilon)$-approximate vertex cover in amortized
$O(n^{.723}\epsilon^{-O(1)})$ time.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02583" title="Abstract">arXiv:2403.02583</a> [<a href="/pdf/2403.02583" title="Download PDF">pdf</a>, <a href="/format/2403.02583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Software Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yinan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiangping Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+R">Rui Peng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhicao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jinbo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Furen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zibin Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The rapid development of deep learning techniques, improved computational
power, and the availability of vast training data have led to significant
advancements in pre-trained models and large language models (LLMs).
Pre-trained models based on architectures such as BERT and Transformer, as well
as LLMs like ChatGPT, have demonstrated remarkable language capabilities and
found applications in Software engineering. Software engineering tasks can be
divided into many categories, among which generative tasks are the most concern
by researchers, where pre-trained models and LLMs possess powerful language
representation and contextual awareness capabilities, enabling them to leverage
diverse training data and adapt to generative tasks through fine-tuning,
transfer learning, and prompt engineering. These advantages make them effective
tools in generative tasks and have demonstrated excellent performance. In this
paper, we present a comprehensive literature review of generative tasks in SE
using pre-trained models and LLMs. We accurately categorize SE generative tasks
based on software engineering methodologies and summarize the advanced
pre-trained models and LLMs involved, as well as the datasets and evaluation
metrics used. Additionally, we identify key strengths, weaknesses, and gaps in
existing approaches, and propose potential research directions. This review
aims to provide researchers and practitioners with an in-depth analysis and
guidance on the application of pre-trained models and LLMs in generative tasks
within SE.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02584" title="Abstract">arXiv:2403.02584</a> [<a href="/pdf/2403.02584" title="Download PDF">pdf</a>, <a href="/format/2403.02584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Direct Sampling Method and Its Integration with Deep Learning for  Inverse Scattering Problems with Phaseless Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ning%2C+J">Jianfeng Ning</a>, 
<a href="/search/math?searchtype=author&query=Han%2C+F">Fuqun Han</a>, 
<a href="/search/math?searchtype=author&query=Zou%2C+J">Jun Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider in this work an inverse acoustic scattering problem when only
phaseless data is available. The inverse problem is highly nonlinear and
ill-posed due to the lack of the phase information. Solving inverse scattering
problems with phaseless data is important in applications as the collection of
physically acceptable phased data is usually difficult and expensive. A novel
direct sampling method (DSM) will be developed to effectively estimate the
locations and geometric shapes of the unknown scatterers from phaseless data
generated by a very limited number of incident waves. With a careful
theoretical analysis of the behavior of the index function and some
representative numerical examples, the new DSM is shown to be computationally
efficient, easy to implement, robust to large noise, and does not require any
prior knowledge of the unknown scatterers. Furthermore, to fully exploit the
index functions obtained from the DSM, we also propose to integrate the DSM
with a deep learning technique (DSM-DL) to achieve high-quality
reconstructions. Several challenging and representative numerical experiments
are carried out to demonstrate the accuracy and robustness of reconstructions
by DSM-DL. The DSM-DL networks trained by phased data are further theoretically
and numerically shown to be able to solve problems with phaseless data.
Additionally, our numerical experiments also show the DSM-DL can solve inverse
scattering problems with mixed types of scatterers, which renders its
applications in many important practical scenarios.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02586" title="Abstract">arXiv:2403.02586</a> [<a href="/pdf/2403.02586" title="Download PDF">pdf</a>, <a href="/format/2403.02586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Event Definition Following For Zero-Shot Event Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zefan Cai</a>, 
<a href="/search/cs?searchtype=author&query=Kung%2C+P">Po-Nien Kung</a>, 
<a href="/search/cs?searchtype=author&query=Suvarna%2C+A">Ashima Suvarna</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+M+D">Mingyu Derek Ma</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+H">Hritik Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+B">Baobao Chang</a>, 
<a href="/search/cs?searchtype=author&query=Brantingham%2C+P+J">P. Jeffrey Brantingham</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+N">Nanyun Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Existing approaches on zero-shot event detection usually train models on
datasets annotated with known event types, and prompt them with unseen event
definitions. These approaches yield sporadic successes, yet generally fall
short of expectations. In this work, we aim to improve zero-shot event
detection by training models to better follow event definitions. We hypothesize
that a diverse set of event types and definitions are the key for models to
learn to follow event definitions while existing event extraction datasets
focus on annotating many high-quality examples for a few event types. To verify
our hypothesis, we construct an automatically generated Diverse Event
Definition (DivED) dataset and conduct comparative studies. Our experiments
reveal that a large number of event types (200) and diverse event definitions
can significantly boost event extraction performance; on the other hand, the
performance does not scale with over ten examples per event type. Beyond
scaling, we incorporate event ontology information and hard-negative samples
during training, further boosting the performance. Based on these findings, we
fine-tuned a LLaMA-2-7B model on our DivED dataset, yielding performance that
surpasses SOTA large language models like GPT-3.5 across three open benchmarks
on zero-shot event detection.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02595" title="Abstract">arXiv:2403.02595</a> [<a href="/pdf/2403.02595" title="Download PDF">pdf</a>, <a href="/format/2403.02595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Stochastic Dynamics from Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guo%2C+Z">Ziheng Guo</a>, 
<a href="/search/math?searchtype=author&query=Cialenco%2C+I">Igor Cialenco</a>, 
<a href="/search/math?searchtype=author&query=Zhong%2C+M">Ming Zhong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present a noise guided trajectory based system identification method for
inferring the dynamical structure from observation generated by stochastic
differential equations. Our method can handle various kinds of noise, including
the case when the the components of the noise is correlated. Our method can
also learn both the noise level and drift term together from trajectory. We
present various numerical tests for showcasing the superior performance of our
learning algorithm.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02598" title="Abstract">arXiv:2403.02598</a> [<a href="/pdf/2403.02598" title="Download PDF">pdf</a>, <a href="/ps/2403.02598" title="Download PostScript">ps</a>, <a href="/format/2403.02598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pooling Image Datasets With Multiple Covariate Shift and Imbalance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chytas%2C+S+P">Sotirios Panagiotis Chytas</a>, 
<a href="/search/cs?searchtype=author&query=Lokhande%2C+V+S">Vishnu Suresh Lokhande</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peiran Li</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+V">Vikas Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The International Conference on Learning Representations (ICLR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Small sample sizes are common in many disciplines, which necessitates pooling
roughly similar datasets across multiple institutions to study weak but
relevant associations between images and disease outcomes. Such data often
manifest shift/imbalance in covariates (i.e., secondary non-imaging data).
Controlling for such nuisance variables is common within standard statistical
analysis, but the ideas do not directly apply to overparameterized models.
Consequently, recent work has shown how strategies from invariant
representation learning provides a meaningful starting point, but the current
repertoire of methods is limited to accounting for shifts/imbalances in just a
couple of covariates at a time. In this paper, we show how viewing this problem
from the perspective of Category theory provides a simple and effective
solution that completely avoids elaborate multi-stage training pipelines that
would otherwise be needed. We show the effectiveness of this approach via
extensive experiments on real datasets. Further, we discuss how this style of
formulation offers a unified perspective on at least 5+ distinct problem
settings, from self-supervised learning to matching problems in 3D
reconstruction.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02600" title="Abstract">arXiv:2403.02600</a> [<a href="/pdf/2403.02600" title="Download PDF">pdf</a>, <a href="/format/2403.02600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TESTAM: A Time-Enhanced Spatio-Temporal Attention Model with Mixture of  Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyunwook Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+S">Sungahn Ko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 7 figures, Accepted as poster to ICLR 2024. Code: <a href="https://github.com/HyunWookL/TESTAM">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on Learning Representations (ICLR 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Accurate traffic forecasting is challenging due to the complex dependency on
road networks, various types of roads, and the abrupt speed change due to the
events. Recent works mainly focus on dynamic spatial modeling with adaptive
graph embedding or graph attention having less consideration for temporal
characteristics and in-situ modeling. In this paper, we propose a novel deep
learning model named TESTAM, which individually models recurring and
non-recurring traffic patterns by a mixture-of-experts model with three experts
on temporal modeling, spatio-temporal modeling with static graph, and dynamic
spatio-temporal dependency modeling with dynamic graph. By introducing
different experts and properly routing them, TESTAM could better model various
circumstances, including spatially isolated nodes, highly related nodes, and
recurring and non-recurring events. For the proper routing, we reformulate a
gating problem into a classification problem with pseudo labels. Experimental
results on three public traffic network datasets, METR-LA, PEMS-BAY, and
EXPY-TKY, demonstrate that TESTAM achieves a better indication and modeling of
recurring and non-recurring traffic. We published the official code at
https://github.com/HyunWookL/TESTAM
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02604" title="Abstract">arXiv:2403.02604</a> [<a href="/pdf/2403.02604" title="Download PDF">pdf</a>, <a href="/format/2403.02604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniDoorManip: Learning Universal Door Manipulation Policy Over  Large-scale and Diverse Door Manipulation Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaojie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Ruihai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zilong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+Y">Yiran Geng</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhaofeng He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Learning a universal manipulation policy encompassing doors with diverse
categories, geometries and mechanisms, is crucial for future embodied agents to
effectively work in complex and broad real-world scenarios. Due to the limited
datasets and unrealistic simulation environments, previous works fail to
achieve good performance across various doors. In this work, we build a novel
door manipulation environment reflecting different realistic door manipulation
mechanisms, and further equip this environment with a large-scale door dataset
covering 6 door categories with hundreds of door bodies and handles, making up
thousands of different door instances. Additionally, to better emulate
real-world scenarios, we introduce a mobile robot as the agent and use the
partial and occluded point cloud as the observation, which are not considered
in previous works while possessing significance for real-world implementations.
To learn a universal policy over diverse doors, we propose a novel framework
disentangling the whole manipulation process into three stages, and integrating
them by training in the reversed order of inference. Extensive experiments
validate the effectiveness of our designs and demonstrate our framework's
strong performance.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02607" title="Abstract">arXiv:2403.02607</a> [<a href="/pdf/2403.02607" title="Download PDF">pdf</a>, <a href="/ps/2403.02607" title="Download PostScript">ps</a>, <a href="/format/2403.02607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MEBS: Multi-task End-to-end Bid Shading for Multi-slot Display  Advertising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+Z">Zhen Gong</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+L">Lvyin Niu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Miao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhenzhe Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhilin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+R">Rongquan Bai</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chuan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Bo Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Online bidding and auction are crucial aspects of the online advertising
industry. Conventionally, there is only one slot for ad display and most
current studies focus on it. Nowadays, multi-slot display advertising is
gradually becoming popular where many ads could be displayed in a list and
shown as a whole to users. However, multi-slot display advertising leads to
different cost-effectiveness. Advertisers have the incentive to adjust bid
prices so as to win the most economical ad positions. In this study, we
introduce bid shading into multi-slot display advertising for bid price
adjustment with a Multi-task End-to-end Bid Shading(MEBS) method. We prove the
optimality of our method theoretically and examine its performance
experimentally. Through extensive offline and online experiments, we
demonstrate the effectiveness and efficiency of our method, and we obtain a
7.01% lift in Gross Merchandise Volume, a 7.42% lift in Return on Investment,
and a 3.26% lift in ad buy count.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02608" title="Abstract">arXiv:2403.02608</a> [<a href="/pdf/2403.02608" title="Download PDF">pdf</a>, <a href="/format/2403.02608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DNNLasso: Scalable Graph Learning for Matrix-Variate Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Meixia Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yangjing Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 27th International Conference on Artificial Intelligence and Statistics (AISTATS) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We consider the problem of jointly learning row-wise and column-wise
dependencies of matrix-variate observations, which are modelled separately by
two precision matrices. Due to the complicated structure of Kronecker-product
precision matrices in the commonly used matrix-variate Gaussian graphical
models, a sparser Kronecker-sum structure was proposed recently based on the
Cartesian product of graphs. However, existing methods for estimating
Kronecker-sum structured precision matrices do not scale well to large scale
datasets. In this paper, we introduce DNNLasso, a diagonally non-negative
graphical lasso model for estimating the Kronecker-sum structured precision
matrix, which outperforms the state-of-the-art methods by a large margin in
both accuracy and computational time. Our code is available at
https://github.com/YangjingZhang/DNNLasso.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02609" title="Abstract">arXiv:2403.02609</a> [<a href="/pdf/2403.02609" title="Download PDF">pdf</a>, <a href="/format/2403.02609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Search Intenion Network for Personalized Query Auto-Completion in  E-Commerce
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+W">Wei Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+C">Chengfu Huo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Query Auto-Completion(QAC), as an important part of the modern search engine,
plays a key role in complementing user queries and helping them refine their
search intentions.Today's QAC systems in real-world scenarios face two major
challenges:1)intention equivocality(IE): during the user's typing process,the
prefix often contains a combination of characters and subwords, which makes the
current intention ambiguous and difficult to model.2)intention transfer
(IT):previous works make personalized recommendations based on users'
historical sequences, but ignore the search intention transfer.However, the
current intention extracted from prefix may be contrary to the historical
preferences.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02610" title="Abstract">arXiv:2403.02610</a> [<a href="/pdf/2403.02610" title="Download PDF">pdf</a>, <a href="/ps/2403.02610" title="Download PostScript">ps</a>, <a href="/format/2403.02610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT4PCG 2 Competition: Prompt Engineering for Science Birds Level  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taveekitworachai%2C+P">Pittawat Taveekitworachai</a>, 
<a href="/search/cs?searchtype=author&query=Abdullah%2C+F">Febri Abdullah</a>, 
<a href="/search/cs?searchtype=author&query=Dewantoro%2C+M+F">Mury F. Dewantoro</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yi Xia</a>, 
<a href="/search/cs?searchtype=author&query=Suntichaikul%2C+P">Pratch Suntichaikul</a>, 
<a href="/search/cs?searchtype=author&query=Thawonmas%2C+R">Ruck Thawonmas</a>, 
<a href="/search/cs?searchtype=author&query=Togelius%2C+J">Julian Togelius</a>, 
<a href="/search/cs?searchtype=author&query=Renz%2C+J">Jochen Renz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This paper presents the second ChatGPT4PCG competition at the 2024 IEEE
Conference on Games. In this edition of the competition, we follow the first
edition, but make several improvements and changes. We introduce a new
evaluation metric along with allowing a more flexible format for participants'
submissions and making several improvements to the evaluation pipeline.
Continuing from the first edition, we aim to foster and explore the realm of
prompt engineering (PE) for procedural content generation (PCG). While the
first competition saw success, it was hindered by various limitations; we aim
to mitigate these limitations in this edition. We introduce diversity as a new
metric to discourage submissions aimed at producing repetitive structures.
Furthermore, we allow submission of a Python program instead of a prompt text
file for greater flexibility in implementing advanced PE approaches, which may
require control flow, including conditions and iterations. We also make several
improvements to the evaluation pipeline with a better classifier for similarity
evaluation and better-performing function signatures. We thoroughly evaluate
the effectiveness of the new metric and the improved classifier. Additionally,
we perform an ablation study to select a function signature to instruct ChatGPT
for level generation. Finally, we provide implementation examples of various PE
techniques in Python and evaluate their preliminary performance. We hope this
competition serves as a resource and platform for learning about PE and PCG in
general.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02611" title="Abstract">arXiv:2403.02611</a> [<a href="/pdf/2403.02611" title="Download PDF">pdf</a>, <a href="/format/2403.02611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Framework for Microscopy Defocus Deblur with Multi-Pyramid  Transformer and Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuelin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+P">Pengyu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+W">Wanquan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chengyu Fang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S+S">Shing Shin Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Defocus blur is a persistent problem in microscope imaging that poses harm to
pathology interpretation and medical intervention in cell microscopy and
microscope surgery. To address this problem, a unified framework including
multi-pyramid transformer (MPT) and extended frequency contrastive
regularization (EFCR) is proposed to tackle two outstanding challenges in
microscopy deblur: longer attention span and feature deficiency. The MPT
employs an explicit pyramid structure at each network stage that integrates the
cross-scale window attention (CSWA), the intra-scale channel attention (ISCA),
and the feature-enhancing feed-forward network (FEFN) to capture long-range
cross-scale spatial interaction and global channel context. The EFCR addresses
the feature deficiency problem by exploring latent deblur signals from
different frequency bands. It also enables deblur knowledge transfer to learn
cross-domain information from extra data, improving deblur performance for
labeled and unlabeled data. Extensive experiments and downstream task
validation show the framework achieves state-of-the-art performance across
multiple datasets. Project page: https://github.com/PieceZhang/MPT-CataBlur.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02613" title="Abstract">arXiv:2403.02613</a> [<a href="/pdf/2403.02613" title="Download PDF">pdf</a>, <a href="/format/2403.02613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models and Video Games: A Preliminary Scoping Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sweetser%2C+P">Penny Sweetser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) hold interesting potential for the design,
development, and research of video games. Building on the decades of prior
research on generative AI in games, many researchers have sped to investigate
the power and potential of LLMs for games. Given the recent spike in
LLM-related research in games, there is already a wealth of relevant research
to survey. In order to capture a snapshot of the state of LLM research in
games, and to help lay the foundation for future work, we carried out an
initial scoping review of relevant papers published so far. In this paper, we
review 76 papers published between 2022 to early 2024 on LLMs and video games,
with key focus areas in game AI, game development, narrative, and game research
and reviews. Our paper provides an early state of the field and lays the
groundwork for future research and reviews on this topic.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02615" title="Abstract">arXiv:2403.02615</a> [<a href="/pdf/2403.02615" title="Download PDF">pdf</a>, <a href="/format/2403.02615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Limitations of Large Language Models in Compositional  Relation Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jinman Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xueyan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 7 figures, 7 tables, submitted to ICML 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present a comprehensive evaluation of large language models(LLMs)' ability
to reason about composition relations through a benchmark encompassing 1,500
test cases in English, designed to cover six distinct types of composition
relations: Positional, Comparative, Personal, Mathematical, Identity, and
Other. Acknowledging the significance of multilingual capabilities, we expanded
our assessment to include translations of these cases into Chinese, Japanese,
French, and Korean. Our Multilingual Composition Relation (MCR) benchmark aims
at investigating the robustness and adaptability of LLMs in handling
composition relation reasoning across diverse linguistic contexts.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02616" title="Abstract">arXiv:2403.02616</a> [<a href="/pdf/2403.02616" title="Download PDF">pdf</a>, <a href="/ps/2403.02616" title="Download PostScript">ps</a>, <a href="/format/2403.02616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Spatio-Temporal State Estimation for Fine-grained Adaptive  Anomaly Diagnosis of Industrial Cyber-physical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haili Sun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Lansheng Han</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Cai Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chunjie Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Networking and Internet Architecture (cs.NI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Accurate detection and diagnosis of abnormal behaviors such as network
attacks from multivariate time series (MTS) are crucial for ensuring the stable
and effective operation of industrial cyber-physical systems (CPS). However,
existing researches pay little attention to the logical dependencies among
system working states, and have difficulties in explaining the evolution
mechanisms of abnormal signals. To reveal the spatio-temporal association
relationships and evolution mechanisms of the working states of industrial CPS,
this paper proposes a fine-grained adaptive anomaly diagnosis method (i.e.
MAD-Transformer) to identify and diagnose anomalies in MTS. MAD-Transformer
first constructs a temporal state matrix to characterize and estimate the
change patterns of the system states in the temporal dimension. Then, to better
locate the anomalies, a spatial state matrix is also constructed to capture the
inter-sensor state correlation relationships within the system. Subsequently,
based on these two types of state matrices, a three-branch structure of
series-temporal-spatial attention module is designed to simultaneously capture
the series, temporal, and space dependencies among MTS. Afterwards, three
associated alignment loss functions and a reconstruction loss are constructed
to jointly optimize the model. Finally, anomalies are determined and diagnosed
by comparing the residual matrices with the original matrices. We conducted
comparative experiments on five publicly datasets spanning three application
domains (service monitoring, spatial and earth exploration, and water
treatment), along with a petroleum refining simulation dataset collected by
ourselves. The results demonstrate that MAD-Transformer can adaptively detect
fine-grained anomalies with short duration, and outperforms the
state-of-the-art baselines in terms of noise robustness and localization
performance.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02617" title="Abstract">arXiv:2403.02617</a> [<a href="/pdf/2403.02617" title="Download PDF">pdf</a>, <a href="/ps/2403.02617" title="Download PostScript">ps</a>, <a href="/format/2403.02617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Reduced-Order Resistive Force Model for Robotic Foot-Mud Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xunjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jingang Yi</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+J">Jerry Shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AIM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Legged robots are well-suited for broad exploration tasks in complex
environments with yielding terrain. Understanding robotic foot-terrain
interactions is critical for safe locomotion and walking efficiency for legged
robots. This paper presents a reduced-order resistive-force model for
robotic-foot/mud interactions. We focus on vertical robot locomotion on mud and
propose a visco-elasto-plastic analog to model the foot/mud interaction forces.
Dynamic behaviors such as mud visco-elasticity, withdrawing cohesive suction,
and yielding are explicitly discussed with the proposed model. Besides
comparing with dry/wet granular materials, mud intrusion experiments are
conducted to validate the force model. The dependency of the model parameter on
water content and foot velocity is also studied to reveal in-depth model
properties under various conditions. The proposed force model potentially
provides an enabling tool for legged robot locomotion and control on muddy
terrain.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02618" title="Abstract">arXiv:2403.02618</a> [<a href="/pdf/2403.02618" title="Download PDF">pdf</a>, <a href="/format/2403.02618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TinyGC-Net: An Extremely Tiny Network for Calibrating MEMS Gyroscopes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chao%2C+C">Cui Chao</a>, 
<a href="/search/cs?searchtype=author&query=Jiankang%2C+Z">Zhao Jiankang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">As the errors of microelectromechanical system (MEMS) gyroscopes are complex
and nonlinear, the current calibration methods, which rely on linear models or
networks with numerous parameters, are inadequate for low-cost embedded
computing platforms to achieve both precision and real-time performance. In
this paper, we introduce a extremely tiny network (TGC-Net) that characterizes
the measurement model of MEMS gyroscopes. The network has a small number of
parameters and can be trained on a central processing unit (CPU) before being
deployed on a microcontroller unit (MCU). The TGC-Net leverage the robust data
processing capabilities of deep learning to derive a nonlinear measurement
model from fragmented gyroscope data. Subsequently, this model is used to
regress errors on the gyroscope data. Moreover, we analyze the relationship
between the compact network and the traditional linear model for MEMS
gyroscopes, and emphasize the significance of the adequate angular motion
stimulation for train the network. The experimental results, based on public
datasets and real-world scenarios, demonstrate the practicality and
effectiveness of the proposed method. These findings suggest that this
technique is a viable candidate for applications that require MEMS gyroscopes.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02619" title="Abstract">arXiv:2403.02619</a> [<a href="/pdf/2403.02619" title="Download PDF">pdf</a>, <a href="/format/2403.02619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Machine Learning models at the Edge: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khouas%2C+A+R">Aymen Rayane Khouas</a>, 
<a href="/search/cs?searchtype=author&query=Bouadjenek%2C+M+R">Mohamed Reda Bouadjenek</a>, 
<a href="/search/cs?searchtype=author&query=Hacid%2C+H">Hakim Hacid</a>, 
<a href="/search/cs?searchtype=author&query=Aryal%2C+S">Sunil Aryal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Edge Computing (EC) has gained significant traction in recent years,
promising enhanced efficiency by integrating Artificial Intelligence (AI)
capabilities at the edge. While the focus has primarily been on the deployment
and inference of Machine Learning (ML) models at the edge, the training aspect
remains less explored. This survey delves into Edge Learning (EL), specifically
the optimization of ML model training at the edge. The objective is to
comprehensively explore diverse approaches and methodologies in EL, synthesize
existing knowledge, identify challenges, and highlight future trends. Utilizing
Scopus' advanced search, relevant literature on EL was identified, revealing a
concentration of research efforts in distributed learning methods, particularly
Federated Learning (FL). This survey further provides a guideline for comparing
techniques used to optimize ML for edge learning, along with an exploration of
different frameworks, libraries, and simulation tools available for EL. In
doing so, the paper contributes to a holistic understanding of the current
landscape and future directions in the intersection of edge computing and
machine learning, paving the way for informed comparisons between optimization
methods and techniques designed for edge learning.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02622" title="Abstract">arXiv:2403.02622</a> [<a href="/pdf/2403.02622" title="Download PDF">pdf</a>, <a href="/format/2403.02622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> World Models for Autonomous Driving: An Initial Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+Y">Yanchen Guan</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+H">Haicheng Liao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenning Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guohui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chengzhong Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">In the rapidly evolving landscape of autonomous driving, the capability to
accurately predict future events and assess their implications is paramount for
both safety and efficiency, critically aiding the decision-making process.
World models have emerged as a transformative approach, enabling autonomous
driving systems to synthesize and interpret vast amounts of sensor data,
thereby predicting potential future scenarios and compensating for information
gaps. This paper provides an initial review of the current state and
prospective advancements of world models in autonomous driving, spanning their
theoretical underpinnings, practical applications, and the ongoing research
efforts aimed at overcoming existing limitations. Highlighting the significant
role of world models in advancing autonomous driving technologies, this survey
aspires to serve as a foundational reference for the research community,
facilitating swift access to and comprehension of this burgeoning field, and
inspiring continued innovation and exploration.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02624" title="Abstract">arXiv:2403.02624</a> [<a href="/pdf/2403.02624" title="Download PDF">pdf</a>, <a href="/format/2403.02624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pareto-Optimal Estimation and Policy Learning on Short-term and  Long-term Treatment Effects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yingrong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+A">Anpeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+Q">Qiaowei Miao</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+R">Ruoxuan Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+K">Kun Kuang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper focuses on developing Pareto-optimal estimation and policy
learning to identify the most effective treatment that maximizes the total
reward from both short-term and long-term effects, which might conflict with
each other. For example, a higher dosage of medication might increase the speed
of a patient's recovery (short-term) but could also result in severe long-term
side effects. Although recent works have investigated the problems about
short-term or long-term effects or the both, how to trade-off between them to
achieve optimal treatment remains an open challenge. Moreover, when multiple
objectives are directly estimated using conventional causal representation
learning, the optimization directions among various tasks can conflict as well.
In this paper, we systematically investigate these issues and introduce a
Pareto-Efficient algorithm, comprising Pareto-Optimal Estimation (POE) and
Pareto-Optimal Policy Learning (POPL), to tackle them. POE incorporates a
continuous Pareto module with representation balancing, enhancing estimation
efficiency across multiple tasks. As for POPL, it involves deriving short-term
and long-term outcomes linked with various treatment levels, facilitating an
exploration of the Pareto frontier emanating from these outcomes. Results on
both the synthetic and real-world datasets demonstrate the superiority of our
method.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02626" title="Abstract">arXiv:2403.02626</a> [<a href="/pdf/2403.02626" title="Download PDF">pdf</a>, <a href="/format/2403.02626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Collaborator: Enabling Subjective Vision Classification With  Minimal Human Effort via LLM Tool-Use
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Toubal%2C+I+E">Imad Eddine Toubal</a>, 
<a href="/search/cs?searchtype=author&query=Avinash%2C+A">Aditya Avinash</a>, 
<a href="/search/cs?searchtype=author&query=Alldrin%2C+N+G">Neil Gordon Alldrin</a>, 
<a href="/search/cs?searchtype=author&query=Dlabal%2C+J">Jan Dlabal</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wenlei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+E">Enming Luo</a>, 
<a href="/search/cs?searchtype=author&query=Stretcu%2C+O">Otilia Stretcu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hao Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chun-Ta Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Howard Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+R">Ranjay Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Fuxman%2C+A">Ariel Fuxman</a>, 
<a href="/search/cs?searchtype=author&query=Duerig%2C+T">Tom Duerig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">From content moderation to wildlife conservation, the number of applications
that require models to recognize nuanced or subjective visual concepts is
growing. Traditionally, developing classifiers for such concepts requires
substantial manual effort measured in hours, days, or even months to identify
and annotate data needed for training. Even with recently proposed Agile
Modeling techniques, which enable rapid bootstrapping of image classifiers,
users are still required to spend 30 minutes or more of monotonous, repetitive
data labeling just to train a single classifier. Drawing on Fiske's Cognitive
Miser theory, we propose a new framework that alleviates manual effort by
replacing human labeling with natural language interactions, reducing the total
effort required to define a concept by an order of magnitude: from labeling
2,000 images to only 100 plus some natural language interactions. Our framework
leverages recent advances in foundation models, both large language models and
vision-language models, to carve out the concept space through conversation and
by automatically labeling training data points. Most importantly, our framework
eliminates the need for crowd-sourced annotations. Moreover, our framework
ultimately produces lightweight classification models that are deployable in
cost-sensitive scenarios. Across 15 subjective concepts and across 2 public
image classification datasets, our trained models outperform traditional Agile
Modeling as well as state-of-the-art zero-shot classification models like
ALIGN, CLIP, CuPL, and large visual question-answering models like PaLI-X.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02627" title="Abstract">arXiv:2403.02627</a> [<a href="/pdf/2403.02627" title="Download PDF">pdf</a>, <a href="/format/2403.02627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eight-Partitioning Points in 3D, and Efficiently Too
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aronov%2C+B">Boris Aronov</a>, 
<a href="/search/cs?searchtype=author&query=Basit%2C+A">Abdul Basit</a>, 
<a href="/search/cs?searchtype=author&query=Tasinato%2C+G">Gianluca Tasinato</a>, 
<a href="/search/cs?searchtype=author&query=Ramesh%2C+I">Indu Ramesh</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+U">Uli Wagner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 3 figures, preliminary version to appear in SoCG'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">An \emph{eight-partition} of a finite set of points (respectively, of a
continuous mass distribution) in $\mathbb{R}^3$ consists of three planes that
divide the space into $8$ octants, such that each open octant contains at most
$1/8$ of the points (respectively, of the mass). In 1966, Hadwiger showed that
any mass distribution in $\mathbb{R}^3$ admits an eight-partition; moreover,
one can prescribe the normal direction of one of the three planes. The
analogous result for finite point sets follows by a standard limit argument.
<br />We prove the following variant of this result: Any mass distribution (or
point set) in $\mathbb{R}^3$ admits an eight-partition for which the
intersection of two of the planes is a line with a prescribed direction.
<br />Moreover, we present an efficient algorithm for calculating an
eight-partition of a set of $n$ points in~$\mathbb{R}^3$ (with prescribed
normal direction of one of the planes) in time $O^{*}(n^{5/2})$.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02628" title="Abstract">arXiv:2403.02628</a> [<a href="/pdf/2403.02628" title="Download PDF">pdf</a>, <a href="/format/2403.02628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Continual Learning: Fast and Slow Thinking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+B">Biqing Qi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xingquan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Junqi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianxing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Ligang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bowen Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Advanced life forms, sustained by the synergistic interaction of neural
cognitive mechanisms, continually acquire and transfer knowledge throughout
their lifespan. In contrast, contemporary machine learning paradigms exhibit
limitations in emulating the facets of continual learning (CL). Nonetheless,
the emergence of large language models (LLMs) presents promising avenues for
realizing CL via interactions with these models. Drawing on Complementary
Learning System theory, this paper presents a novel Interactive Continual
Learning (ICL) framework, enabled by collaborative interactions among models of
various sizes. Specifically, we assign the ViT model as System1 and multimodal
LLM as System2. To enable the memory module to deduce tasks from class
information and enhance Set2Set retrieval, we propose the Class-Knowledge-Task
Multi-Head Attention (CKT-MHA). Additionally, to improve memory retrieval in
System1 through enhanced geometric representation, we introduce the CL-vMF
mechanism, based on the von Mises-Fisher (vMF) distribution. Meanwhile, we
introduce the von Mises-Fisher Outlier Detection and Interaction (vMF-ODI)
strategy to identify hard examples, thus enhancing collaboration between
System1 and System2 for complex reasoning realization. Comprehensive evaluation
of our proposed ICL demonstrates significant resistance to forgetting and
superior performance relative to existing methods.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02629" title="Abstract">arXiv:2403.02629</a> [<a href="/pdf/2403.02629" title="Download PDF">pdf</a>, <a href="/format/2403.02629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Geometric-Photometric Joint Alignment for Facial Mesh  Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xizhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaxiong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengjian Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper presents a Geometric-Photometric Joint Alignment(GPJA) method, for
accurately aligning human expressions by combining geometry and photometric
information. Common practices for registering human heads typically involve
aligning landmarks with facial template meshes using geometry processing
approaches, but often overlook photometric consistency. GPJA overcomes this
limitation by leveraging differentiable rendering to align vertices with target
expressions, achieving joint alignment in geometry and photometric appearances
automatically, without the need for semantic annotation or aligned meshes for
training. It features a holistic rendering alignment strategy and a multiscale
regularized optimization for robust and fast convergence. The method utilizes
derivatives at vertex positions for supervision and employs a gradient-based
algorithm which guarantees smoothness and avoids topological defects during the
geometry evolution. Experimental results demonstrate faithful alignment under
various expressions, surpassing the conventional ICP-based methods and the
state-of-the-art deep learning based method. In practical, our method enhances
the efficiency of obtaining topology-consistent face models from multi-view
stereo facial scanning.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02630" title="Abstract">arXiv:2403.02630</a> [<a href="/pdf/2403.02630" title="Download PDF">pdf</a>, <a href="/format/2403.02630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedHCDR: Federated Cross-Domain Recommendation with Hypergraph Signal  Decoupling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Dongyi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+L">Lin Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiyuan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yunqing Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Q">Qing Liao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In recent years, Cross-Domain Recommendation (CDR) has drawn significant
attention, which utilizes user data from multiple domains to enhance the
recommendation performance. However, current CDR methods require sharing user
data across domains, thereby violating the General Data Protection Regulation
(GDPR). Consequently, numerous approaches have been proposed for Federated
Cross-Domain Recommendation (FedCDR). Nevertheless, the data heterogeneity
across different domains inevitably influences the overall performance of
federated learning. In this study, we propose FedHCDR, a novel Federated
Cross-Domain Recommendation framework with Hypergraph signal decoupling.
Specifically, to address the data heterogeneity across domains, we introduce an
approach called hypergraph signal decoupling (HSD) to decouple the user
features into domain-exclusive and domain-shared features. The approach employs
high-pass and low-pass hypergraph filters to decouple domain-exclusive and
domain-shared user representations, which are trained by the local-global
bi-directional transfer algorithm. In addition, a hypergraph contrastive
learning (HCL) module is devised to enhance the learning of domain-shared user
relationship information by perturbing the user hypergraph. Extensive
experiments conducted on three real-world scenarios demonstrate that FedHCDR
outperforms existing baselines significantly.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02631" title="Abstract">arXiv:2403.02631</a> [<a href="/pdf/2403.02631" title="Download PDF">pdf</a>, <a href="/ps/2403.02631" title="Download PostScript">ps</a>, <a href="/format/2403.02631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy in Multi-agent Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yongqiang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to "Encyclopedia of Systems and Control Engineering" published by Elsevier
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">With the increasing awareness of privacy and the deployment of legislations
in various multi-agent system application domains such as power systems and
intelligent transportation, the privacy protection problem for multi-agent
systems is gaining increased traction in recent years. This article discusses
some of the representative advancements in the filed.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02633" title="Abstract">arXiv:2403.02633</a> [<a href="/pdf/2403.02633" title="Download PDF">pdf</a>, <a href="/format/2403.02633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatially Non-Stationary XL-MIMO Channel Estimation: A Three-Layer  Generalized Approximate Message Passing Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+A">Anzheng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun-Bo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yijin Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wence Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaodan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yijian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hongkang Yu</a>, 
<a href="/search/cs?searchtype=author&query=de+Lamare%2C+R+C">Rodrigo C. de Lamare</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This manuscript has been submitted to the IEEE journal for possible pubilcation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, channel estimation problem for extremely large-scale
multi-input multi-output (XL-MIMO) systems is investigated with the
considerations of the spherical wavefront effect and the spatially
non-stationary (SnS) property. Due to the diversities of SnS characteristics
among different propagation paths, the concurrent channel estimation of
multiple paths becomes intractable. To address this challenge, we propose a
two-phase channel estimation scheme. In the first phase, the angles of
departure (AoDs) on the user side are estimated, and a carefully designed pilot
transmission scheme enables the decomposition of the received signal from
different paths. In the second phase, the subchannel estimation corresponding
to different paths is formulated as a three-layer Bayesian inference problem.
Specifically, the first layer captures block sparsity in the angular domain,
the second layer promotes SnS property in the antenna domain, and the third
layer decouples the subchannels from the observed signals. To efficiently
facilitate Bayesian inference, we propose a novel three-layer generalized
approximate message passing (TL-GAMP) algorithm based on structured variational
massage passing and belief propagation rules. Simulation results validate the
convergence and effectiveness of the proposed algorithm, showcasing its
robustness to different channel scenarios.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02635" title="Abstract">arXiv:2403.02635</a> [<a href="/pdf/2403.02635" title="Download PDF">pdf</a>, <a href="/format/2403.02635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PPS-QMIX: Periodically Parameter Sharing for Accelerating Convergence of  Multi-Agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Ke Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">DanDan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qiuhan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Ce Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Training for multi-agent reinforcement learning(MARL) is a time-consuming
process caused by distribution shift of each agent. One drawback is that
strategy of each agent in MARL is independent but actually in cooperation.
Thus, a vertical issue in multi-agent reinforcement learning is how to
efficiently accelerate training process. To address this problem, current
research has leveraged a centralized function(CF) across multiple agents to
learn contribution of the team reward for each agent. However, CF based methods
introduce joint error from other agents in estimation of value network. In so
doing, inspired by federated learning, we propose three simple novel approaches
called Average Periodically Parameter Sharing(A-PPS), Reward-Scalability
Periodically Parameter Sharing(RS-PPS) and Partial Personalized Periodically
Parameter Sharing(PP-PPS) mechanism to accelerate training of MARL. Agents
share Q-value network periodically during the training process. Agents which
has same identity adapt collected reward as scalability and update partial
neural network during period to share different parameters. We apply our
approaches in classical MARL method QMIX and evaluate our approaches on various
tasks in StarCraft Multi-Agent Challenge(SMAC) environment. Performance of
numerical experiments yield enormous enhancement, with an average improvement
of 10\%-30\%, and enable to win tasks that QMIX cannot. Our code can be
downloaded from https://github.com/ColaZhang22/PPS-QMIX
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02636" title="Abstract">arXiv:2403.02636</a> [<a href="/pdf/2403.02636" title="Download PDF">pdf</a>, <a href="/format/2403.02636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithms for Galois Words: Detection, Factorization, and Rotation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hendrian%2C+D">Diptarama Hendrian</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6ppl%2C+D">Dominik K&#xf6;ppl</a>, 
<a href="/search/cs?searchtype=author&query=Yoshinaka%2C+R">Ryo Yoshinaka</a>, 
<a href="/search/cs?searchtype=author&query=Shinohara%2C+A">Ayumi Shinohara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Lyndon words are extensively studied in combinatorics on words -- they play a
crucial role on upper bounding the number of runs a word can have [Bannai+,
SIAM J. Comput.'17]. We can determine Lyndon words, factorize a word into
Lyndon words in lexicographically decreasing order, and find the Lyndon
rotation of a word, all in linear time within constant additional working
space. A recent research interest emerged from the question of what happens
when we change the lexicographic order, which is at the heart of the definition
of Lyndon words. In particular, the alternating order, where the order of all
odd positions becomes reversed, has been recently proposed. While a Lyndon word
is, among all its cyclic rotations, the smallest one with respect to the
lexicographic order, a Galois word exhibits the same property by exchanging the
lexicographic order with the alternating order. Unfortunately, this exchange
has a large impact on the properties Galois words exhibit, which makes it a
nontrivial task to translate results from Lyndon words to Galois words. Up
until now, it has only been conjectured that linear-time algorithms with
constant additional working space in the spirit of Duval's algorithm are
possible for computing the Galois factorization or the Galois rotation.
<br />Here, we affirm this conjecture as follows. Given a word $T$ of length $n$,
we can determine whether $T$ is a Galois word, in $O(n)$ time with constant
additional working space. Within the same complexities, we can also determine
the Galois rotation of $T$, and compute the Galois factorization of $T$ online.
The last result settles Open Problem~1 in [Dolce et al., TCS'2019] for Galois
words.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02637" title="Abstract">arXiv:2403.02637</a> [<a href="/pdf/2403.02637" title="Download PDF">pdf</a>, <a href="/format/2403.02637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BSDP: Brain-inspired Streaming Dual-level Perturbations for Online Open  World Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Liyan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+L">Liping Jing</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jian Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Humans can easily distinguish the known and unknown categories and can
recognize the unknown object by learning it once instead of repeating it many
times without forgetting the learned object. Hence, we aim to make deep
learning models simulate the way people learn. We refer to such a learning
manner as OnLine Open World Object Detection(OLOWOD). Existing OWOD approaches
pay more attention to the identification of unknown categories, while the
incremental learning part is also very important. Besides, some neuroscience
research shows that specific noises allow the brain to form new connections and
neural pathways which may improve learning speed and efficiency. In this paper,
we take the dual-level information of old samples as perturbations on new
samples to make the model good at learning new knowledge without forgetting the
old knowledge. Therefore, we propose a simple plug-and-play method, called
Brain-inspired Streaming Dual-level Perturbations(BSDP), to solve the OLOWOD
problem. Specifically, (1) we first calculate the prototypes of previous
categories and use the distance between samples and the prototypes as the
sample selecting strategy to choose old samples for replay; (2) then take the
prototypes as the streaming feature-level perturbations of new samples, so as
to improve the plasticity of the model through revisiting the old knowledge;
(3) and also use the distribution of the features of the old category samples
to generate adversarial data in the form of streams as the data-level
perturbations to enhance the robustness of the model to new categories. We
empirically evaluate BSDP on PASCAL VOC and MS-COCO, and the excellent results
demonstrate the promising performance of our proposed method and learning
manner.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02639" title="Abstract">arXiv:2403.02639</a> [<a href="/pdf/2403.02639" title="Download PDF">pdf</a>, <a href="/format/2403.02639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> False Positive Sampling-based Data Augmentation for Enhanced 3D Object  Detection Accuracy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+J">Jiyong Oh</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Junhaeng Lee</a>, 
<a href="/search/cs?searchtype=author&query=Byun%2C+W">Woongchan Byun</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+M">Minsang Kong</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S+H">Sang Hun Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent studies have focused on enhancing the performance of 3D object
detection models. Among various approaches, ground-truth sampling has been
proposed as an augmentation technique to address the challenges posed by
limited ground-truth data. However, an inherent issue with ground-truth
sampling is its tendency to increase false positives. Therefore, this study
aims to overcome the limitations of ground-truth sampling and improve the
performance of 3D object detection models by developing a new augmentation
technique called false-positive sampling. False-positive sampling involves
retraining the model using point clouds that are identified as false positives
in the model's predictions. We propose an algorithm that utilizes both
ground-truth and false-positive sampling and an algorithm for building the
false-positive sample database. Additionally, we analyze the principles behind
the performance enhancement due to false-positive sampling and propose a
technique that applies the concept of curriculum learning to the sampling
strategy that encompasses both false-positive and ground-truth sampling
techniques. Our experiments demonstrate that models utilizing false-positive
sampling show a reduction in false positives and exhibit improved object
detection performance. On the KITTI and Waymo Open datasets, models with
false-positive sampling surpass the baseline models by a large margin.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02640" title="Abstract">arXiv:2403.02640</a> [<a href="/pdf/2403.02640" title="Download PDF">pdf</a>, <a href="/format/2403.02640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HoloVIC: Large-scale Dataset and Benchmark for Multi-Sensor Holographic  Intersection and Vehicle-Infrastructure Cooperative
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Cong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+L">Lei Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chengkai Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Z">Zelong Kong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xueqi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Kan%2C+Y">Yuheng Kan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wei Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024 accepted, (Not Camera-ready Version), Benchmark Website(Coming Soon): <a href="https://holovic.net">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vehicle-to-everything (V2X) is a popular topic in the field of Autonomous
Driving in recent years. Vehicle-infrastructure cooperation (VIC) becomes one
of the important research area. Due to the complexity of traffic conditions
such as blind spots and occlusion, it greatly limits the perception
capabilities of single-view roadside sensing systems. To further enhance the
accuracy of roadside perception and provide better information to the vehicle
side, in this paper, we constructed holographic intersections with various
layouts to build a large-scale multi-sensor holographic vehicle-infrastructure
cooperation dataset, called HoloVIC. Our dataset includes 3 different types of
sensors (Camera, Lidar, Fisheye) and employs 4 sensor-layouts based on the
different intersections. Each intersection is equipped with 6-18 sensors to
capture synchronous data. While autonomous vehicles pass through these
intersections for collecting VIC data. HoloVIC contains in total on 100k+
synchronous frames from different sensors. Additionally, we annotated 3D
bounding boxes based on Camera, Fisheye, and Lidar. We also associate the IDs
of the same objects across different devices and consecutive frames in
sequence. Based on HoloVIC, we formulated four tasks to facilitate the
development of related research. We also provide benchmarks for these tasks.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02642" title="Abstract">arXiv:2403.02642</a> [<a href="/pdf/2403.02642" title="Download PDF">pdf</a>, <a href="/format/2403.02642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UFO: Uncertainty-aware LiDAR-image Fusion for Off-road Semantic Terrain  Map Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+O">Ohn Kim</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">Junwon Seo</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+S">Seongyong Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C+H">Chong Hui Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Autonomous off-road navigation requires an accurate semantic understanding of
the environment, often converted into a bird's-eye view (BEV) representation
for various downstream tasks. While learning-based methods have shown success
in generating local semantic terrain maps directly from sensor data, their
efficacy in off-road environments is hindered by challenges in accurately
representing uncertain terrain features. This paper presents a learning-based
fusion method for generating dense terrain classification maps in BEV. By
performing LiDAR-image fusion at multiple scales, our approach enhances the
accuracy of semantic maps generated from an RGB image and a single-sweep LiDAR
scan. Utilizing uncertainty-aware pseudo-labels further enhances the network's
ability to learn reliably in off-road environments without requiring precise 3D
annotations. By conducting thorough experiments using off-road driving
datasets, we demonstrate that our method can improve accuracy in off-road
terrains, validating its efficacy in facilitating reliable and safe autonomous
navigation in challenging off-road settings.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02647" title="Abstract">arXiv:2403.02647</a> [<a href="/pdf/2403.02647" title="Download PDF">pdf</a>, <a href="/format/2403.02647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FinReport: Explainable Stock Earnings Forecasting via News Factor  Analyzing Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xinjie Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yawen Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+X">Xiaofen Xing</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jin Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WWW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The task of stock earnings forecasting has received considerable attention
due to the demand investors in real-world scenarios. However, compared with
financial institutions, it is not easy for ordinary investors to mine factors
and analyze news. On the other hand, although large language models in the
financial field can serve users in the form of dialogue robots, it still
requires users to have financial knowledge to ask reasonable questions. To
serve the user experience, we aim to build an automatic system, FinReport, for
ordinary investors to collect information, analyze it, and generate reports
after summarizing.
<br />Specifically, our FinReport is based on financial news announcements and a
multi-factor model to ensure the professionalism of the report. The FinReport
consists of three modules: news factorization module, return forecasting
module, risk assessment module. The news factorization module involves
understanding news information and combining it with stock factors, the return
forecasting module aim to analysis the impact of news on market sentiment, and
the risk assessment module is adopted to control investment risk. Extensive
experiments on real-world datasets have well verified the effectiveness and
explainability of our proposed FinReport. Our codes and datasets are available
at https://github.com/frinkleko/FinReport.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02648" title="Abstract">arXiv:2403.02648</a> [<a href="/pdf/2403.02648" title="Download PDF">pdf</a>, <a href="/format/2403.02648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Remove that Square Root: A New Efficient Scale-Invariant Version of  AdaGrad
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choudhury%2C+S">Sayantan Choudhury</a>, 
<a href="/search/cs?searchtype=author&query=Tupitsa%2C+N">Nazarii Tupitsa</a>, 
<a href="/search/cs?searchtype=author&query=Loizou%2C+N">Nicolas Loizou</a>, 
<a href="/search/cs?searchtype=author&query=Horvath%2C+S">Samuel Horvath</a>, 
<a href="/search/cs?searchtype=author&query=Takac%2C+M">Martin Takac</a>, 
<a href="/search/cs?searchtype=author&query=Gorbunov%2C+E">Eduard Gorbunov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
<p class="mathjax">Adaptive methods are extremely popular in machine learning as they make
learning rate tuning less expensive. This paper introduces a novel optimization
algorithm named KATE, which presents a scale-invariant adaptation of the
well-known AdaGrad algorithm. We prove the scale-invariance of KATE for the
case of Generalized Linear Models. Moreover, for general smooth non-convex
problems, we establish a convergence rate of $O \left(\frac{\log T}{\sqrt{T}}
\right)$ for KATE, matching the best-known ones for AdaGrad and Adam. We also
compare KATE to other state-of-the-art adaptive algorithms Adam and AdaGrad in
numerical experiments with different problems, including complex machine
learning tasks like image classification and text classification on real data.
The results indicate that KATE consistently outperforms AdaGrad and
matches/surpasses the performance of Adam in all considered scenarios.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02649" title="Abstract">arXiv:2403.02649</a> [<a href="/pdf/2403.02649" title="Download PDF">pdf</a>, <a href="/format/2403.02649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-shot Learner Parameterization by Diffusion Time-steps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+Z">Zhongqi Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+R">Richang Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanwang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qianru Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Even when using large multi-modal foundation models, few-shot learning is
still challenging -- if there is no proper inductive bias, it is nearly
impossible to keep the nuanced class attributes while removing the visually
prominent attributes that spuriously correlate with class labels. To this end,
we find an inductive bias that the time-steps of a Diffusion Model (DM) can
isolate the nuanced class attributes, i.e., as the forward diffusion adds noise
to an image at each time-step, nuanced attributes are usually lost at an
earlier time-step than the spurious attributes that are visually prominent.
Building on this, we propose Time-step Few-shot (TiF) learner. We train
class-specific low-rank adapters for a text-conditioned DM to make up for the
lost attributes, such that images can be accurately reconstructed from their
noisy ones given a prompt. Hence, at a small time-step, the adapter and prompt
are essentially a parameterization of only the nuanced class attributes. For a
test image, we can use the parameterization to only extract the nuanced class
attributes for classification. TiF learner significantly outperforms OpenCLIP
and its adapters on a variety of fine-grained and customized few-shot learning
tasks. Codes are in https://github.com/yue-zhongqi/tif.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02652" title="Abstract">arXiv:2403.02652</a> [<a href="/pdf/2403.02652" title="Download PDF">pdf</a>, <a href="/format/2403.02652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AlloyInEcore: Embedding of First-Order Relational Logic into Meta-Object  Facility for Automated Model Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Erata%2C+F">Ferhat Erata</a>, 
<a href="/search/cs?searchtype=author&query=Goknil%2C+A">Arda Goknil</a>, 
<a href="/search/cs?searchtype=author&query=Kurtev%2C+I">Ivan Kurtev</a>, 
<a href="/search/cs?searchtype=author&query=Tekinerdogan%2C+B">Bedir Tekinerdogan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in ESEC/FSE 2018: Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">We present AlloyInEcore, a tool for specifying metamodels with their static
semantics to facilitate automated, formal reasoning on models. Software
development projects require that software systems be specified in various
models (e.g., requirements models, architecture models, test models, and source
code). It is crucial to reason about those models to ensure the correct and
complete system specifications. AlloyInEcore allows the user to specify
metamodels with their static semantics, while, using the semantics, it
automatically detects inconsistent models, and completes partial models. It has
been evaluated on three industrial case studies in the automotive domain
(https://modelwriter.github.io/AlloyInEcore/).
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02654" title="Abstract">arXiv:2403.02654</a> [<a href="/pdf/2403.02654" title="Download PDF">pdf</a>, <a href="/ps/2403.02654" title="Download PostScript">ps</a>, <a href="/format/2403.02654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Restricted Isometry Property of Rank-One Measurements with Random  Unit-Modulus Vectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhenni Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The restricted isometry property (RIP) is essential for the linear map to
guarantee the successful recovery of low-rank matrices. The existing works show
that the linear map generated by the measurement matrices with independent and
identically distributed (i.i.d.) entries satisfies RIP with high probability.
However, when dealing with non-i.i.d. measurement matrices, such as the
rank-one measurements, the RIP compliance may not be guaranteed. In this paper,
we show that the RIP can still be achieved with high probability, when the
rank-one measurement matrix is constructed by the random unit-modulus vectors.
Compared to the existing works, we first address the challenge of establishing
RIP for the linear map in non-i.i.d. scenarios. As validated in the
experiments, this linear map is memory-efficient, and not only satisfies the
RIP but also exhibits similar recovery performance of the low-rank matrices to
that of conventional i.i.d. measurement matrices.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02660" title="Abstract">arXiv:2403.02660</a> [<a href="/pdf/2403.02660" title="Download PDF">pdf</a>, <a href="/format/2403.02660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A randomized lattice rule without component-by-component construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Goda%2C+T">Takashi Goda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We study the multivariate integration problem for periodic functions from the
weighted Korobov space in the randomized setting. We introduce a new randomized
rank-1 lattice rule with a randomly chosen number of points, which avoids the
need for component-by-component construction in the search for good generating
vectors while still achieving nearly the optimal rate of the randomized error.
Our idea is to exploit the fact that at least half of the possible generating
vectors yield nearly the optimal rate of the worst-case error in the
deterministic setting. By randomly choosing generating vectors $r$ times and
comparing their corresponding worst-case errors, one can find one generating
vector with a desired worst-case error bound with a very high probability, and
the (small) failure probability can be controlled by increasing $r$
logarithmically as a function of the number of points. Numerical experiments
are conducted to support our theoretical findings.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02661" title="Abstract">arXiv:2403.02661</a> [<a href="/pdf/2403.02661" title="Download PDF">pdf</a>, <a href="/format/2403.02661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Save My Gas Fees: Understanding and Detecting Real-world Gas  Issues in Solidity Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+M">Mengting He</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shihao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Boqin Qin</a>, 
<a href="/search/cs?searchtype=author&query=Yoshida%2C+N">Nobuko Yoshida</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tingting Yu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Linhai Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiying Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The execution of smart contracts on Ethereum, a public blockchain system,
incurs a fee called gas fee for its computation and data-store consumption.
When programmers develop smart contracts (e.g., in the Solidity programming
language), they could unknowingly write code snippets that unnecessarily cause
more gas fees. These issues, or what we call gas wastes, could lead to
significant monetary waste for users. Yet, there have been no systematic
examination of them or effective tools for detecting them. This paper takes the
initiative in helping Ethereum users reduce their gas fees in two important
steps: we conduct the first empirical study on gas wastes in popular smart
contracts written in Solidity by understanding their root causes and fixing
strategies; we then develop a static tool, PeCatch, to effectively detect gas
wastes with simple fixes in Solidity programs based on our study findings.
Overall, we make seven insights and four suggestions from our gas-waste study,
which could foster future tool development, language improvement, and
programmer awareness, and develop eight gas-waste checkers, which pinpoint 383
previously unknown gas wastes from famous Solidity libraries.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02665" title="Abstract">arXiv:2403.02665</a> [<a href="/pdf/2403.02665" title="Download PDF">pdf</a>, <a href="/format/2403.02665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DGAP: Efficient Dynamic Graph Analysis on Persistent Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+A+A+R">Abdullah Al Raqibul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+D">Dong Dai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Performance (cs.PF)

</div>
<p class="mathjax">Dynamic graphs, featuring continuously updated vertices and edges, have grown
in importance for numerous real-world applications. To accommodate this, graph
frameworks, particularly their internal data structures, must support both
persistent graph updates and rapid graph analysis simultaneously, leading to
complex designs to orchestrate `fast but volatile' and `persistent but slow'
storage devices. Emerging persistent memory technologies, such as Optane DCPMM,
offer a promising alternative to simplify the designs by providing data
persistence, low latency, and high IOPS together. In light of this, we propose
DGAP, a framework for efficient dynamic graph analysis on persistent memory.
Unlike traditional dynamic graph frameworks, which combine multiple graph data
structures (e.g., edge list or adjacency list) to achieve the required
performance, DGAP utilizes a single mutable Compressed Sparse Row (CSR) graph
structure with new designs for persistent memory to construct the framework.
Specifically, DGAP introduces a \textit{per-section edge log} to reduce write
amplification on persistent memory; a \textit{per-thread undo log} to enable
high-performance, crash-consistent rebalancing operations; and a data placement
schema to minimize in-place updates on persistent memory. Our extensive
evaluation results demonstrate that DGAP can achieve up to $3.2\times$ better
graph update performance and up to $3.77\times$ better graph analysis
performance compared to state-of-the-art dynamic graph frameworks for
persistent memory, such as XPGraph, LLAMA, and GraphOne.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02667" title="Abstract">arXiv:2403.02667</a> [<a href="/pdf/2403.02667" title="Download PDF">pdf</a>, <a href="/format/2403.02667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> G-EvoNAS: Evolutionary Neural Architecture Search Based on Network  Growth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">Juan Zou</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Weiwei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yizhang Xia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Z">Zhanglu Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">The evolutionary paradigm has been successfully applied to neural network
search(NAS) in recent years. Due to the vast search complexity of the global
space, current research mainly seeks to repeatedly stack partial architectures
to build the entire model or to seek the entire model based on manually
designed benchmark modules. The above two methods are attempts to reduce the
search difficulty by narrowing the search space. To efficiently search network
architecture in the global space, this paper proposes another solution, namely
a computationally efficient neural architecture evolutionary search framework
based on network growth (G-EvoNAS). The complete network is obtained by
gradually deepening different Blocks. The process begins from a shallow
network, grows and evolves, and gradually deepens into a complete network,
reducing the search complexity in the global space. Then, to improve the
ranking accuracy of the network, we reduce the weight coupling of each network
in the SuperNet by pruning the SuperNet according to elite groups at different
growth stages. The G-EvoNAS is tested on three commonly used image
classification datasets, CIFAR10, CIFAR100, and ImageNet, and compared with
various state-of-the-art algorithms, including hand-designed networks and NAS
networks. Experimental results demonstrate that G-EvoNAS can find a neural
network architecture comparable to state-of-the-art designs in 0.2 GPU days.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02674" title="Abstract">arXiv:2403.02674</a> [<a href="/pdf/2403.02674" title="Download PDF">pdf</a>, <a href="/format/2403.02674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Meta-evaluation for Grammatical Error Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kobayashi%2C+M">Masamune Kobayashi</a>, 
<a href="/search/cs?searchtype=author&query=Mita%2C+M">Masato Mita</a>, 
<a href="/search/cs?searchtype=author&query=Komachi%2C+M">Mamoru Komachi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to TACL. This arXiv version is a pre-MIT Press publication version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Metrics are the foundation for automatic evaluation in grammatical error
correction (GEC), with their evaluation of the metrics (meta-evaluation)
relying on their correlation with human judgments. However, conventional
meta-evaluations in English GEC encounter several challenges including biases
caused by inconsistencies in evaluation granularity, and an outdated setup
using classical systems. These problems can lead to misinterpretation of
metrics and potentially hinder the applicability of GEC techniques. To address
these issues, this paper proposes SEEDA, a new dataset for GEC meta-evaluation.
SEEDA consists of corrections with human ratings along two different
granularities: edit-based and sentence-based, covering 12 state-of-the-art
systems including large language models (LLMs), and two human corrections with
different focuses. The results of improved correlations by aligning the
granularity in the sentence-level meta-evaluation, suggest that edit-based
metrics may have been underestimated in existing studies. Furthermore,
correlations of most metrics decrease when changing from classical to neural
systems, indicating that traditional metrics are relatively poor at evaluating
fluently corrected sentences with many edits.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02677" title="Abstract">arXiv:2403.02677</a> [<a href="/pdf/2403.02677" title="Download PDF">pdf</a>, <a href="/format/2403.02677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finetuned Multimodal Language Models Are High-Quality Image-Text Data  Filters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weizhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mrini%2C+K">Khalil Mrini</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Linjie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sateesh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yu Tian</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xifeng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Heng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Website: <a href="https://mlm-filter.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">We propose a novel framework for filtering image-text data by leveraging
fine-tuned Multimodal Language Models (MLMs). Our approach outperforms
predominant filtering methods (e.g., CLIPScore) via integrating the recent
advances in MLMs. We design four distinct yet complementary metrics to
holistically measure the quality of image-text data. A new pipeline is
established to construct high-quality instruction data for fine-tuning MLMs as
data filters. Comparing with CLIPScore, our MLM filters produce more precise
and comprehensive scores that directly improve the quality of filtered data and
boost the performance of pre-trained models. We achieve significant
improvements over CLIPScore on popular foundation models (i.e., CLIP and BLIP2)
and various downstream tasks. Our MLM filter can generalize to different models
and tasks, and be used as a drop-in replacement for CLIPScore. An additional
ablation study is provided to verify our design choices for the MLM filter.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02680" title="Abstract">arXiv:2403.02680</a> [<a href="/pdf/2403.02680" title="Download PDF">pdf</a>, <a href="/format/2403.02680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Dual-Level Cancelable Framework for Palmprint Verification and  Hack-Proof Data Storage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ziyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Ming Kang</a>, 
<a href="/search/cs?searchtype=author&query=Teoh%2C+A+B+J">Andrew Beng Jin Teoh</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chengrui Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bob Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In recent years, palmprints have been widely used for individual
verification. The rich privacy information in palmprint data necessitates its
protection to ensure security and privacy without sacrificing system
performance. Existing systems often use cancelable technologies to protect
templates, but these technologies ignore the potential risk of data leakage.
Upon breaching the system and gaining access to the stored database, a hacker
could easily manipulate the stored templates, compromising the security of the
verification system. To address this issue, we propose a dual-level cancelable
palmprint verification framework in this paper. Specifically, the raw template
is initially encrypted using a competition hashing network with a first-level
token, facilitating the end-to-end generation of cancelable templates.
Different from previous works, the protected template undergoes further
encryption to differentiate the second-level protected template from the
first-level one. The system specifically creates a negative database (NDB) with
the second-level token for dual-level protection during the enrollment stage.
Reversing the NDB is NP-hard and a fine-grained algorithm for NDB generation is
introduced to manage the noise and specified bits. During the verification
stage, we propose an NDB matching algorithm based on matrix operation to
accelerate the matching process of previous NDB methods caused by
dictionary-based matching rules. This approach circumvents the need to store
templates identical to those utilized for verification, reducing the risk of
potential data leakage. Extensive experiments conducted on public palmprint
datasets have confirmed the effectiveness and generality of the proposed
framework. Upon acceptance of the paper, the code will be accessible at
https://github.com/Deep-Imaging-Group/NPR.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02681" title="Abstract">arXiv:2403.02681</a> [<a href="/pdf/2403.02681" title="Download PDF">pdf</a>, <a href="/format/2403.02681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SGD with Partial Hessian for Deep Neural Networks Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Ying Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yong%2C+H">Hongwei Yong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Due to the effectiveness of second-order algorithms in solving classical
optimization problems, designing second-order optimizers to train deep neural
networks (DNNs) has attracted much research interest in recent years. However,
because of the very high dimension of intermediate features in DNNs, it is
difficult to directly compute and store the Hessian matrix for network
optimization. Most of the previous second-order methods approximate the Hessian
information imprecisely, resulting in unstable performance. In this work, we
propose a compound optimizer, which is a combination of a second-order
optimizer with a precise partial Hessian matrix for updating channel-wise
parameters and the first-order stochastic gradient descent (SGD) optimizer for
updating the other parameters. We show that the associated Hessian matrices of
channel-wise parameters are diagonal and can be extracted directly and
precisely from Hessian-free methods. The proposed method, namely SGD with
Partial Hessian (SGD-PH), inherits the advantages of both first-order and
second-order optimizers. Compared with first-order optimizers, it adopts a
certain amount of information from the Hessian matrix to assist optimization,
while compared with the existing second-order optimizers, it keeps the good
generalization performance of first-order optimizers. Experiments on image
classification tasks demonstrate the effectiveness of our proposed optimizer
SGD-PH. The code is publicly available at
\url{https://github.com/myingysun/SGDPH}.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02682" title="Abstract">arXiv:2403.02682</a> [<a href="/pdf/2403.02682" title="Download PDF">pdf</a>, <a href="/format/2403.02682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time Weaver: A Conditional Time Series Generation Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Narasimhan%2C+S+S">Sai Shankar Narasimhan</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+S">Shubhankar Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Akcin%2C+O">Oguzhan Akcin</a>, 
<a href="/search/cs?searchtype=author&query=Sanghavi%2C+S">Sujay Sanghavi</a>, 
<a href="/search/cs?searchtype=author&query=Chinchali%2C+S">Sandeep Chinchali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Imagine generating a city's electricity demand pattern based on weather, the
presence of an electric vehicle, and location, which could be used for capacity
planning during a winter freeze. Such real-world time series are often enriched
with paired heterogeneous contextual metadata (weather, location, etc.).
Current approaches to time series generation often ignore this paired metadata,
and its heterogeneity poses several practical challenges in adapting existing
conditional generation approaches from the image, audio, and video domains to
the time series domain. To address this gap, we introduce Time Weaver, a novel
diffusion-based model that leverages the heterogeneous metadata in the form of
categorical, continuous, and even time-variant variables to significantly
improve time series generation. Additionally, we show that naive extensions of
standard evaluation metrics from the image to the time series domain are
insufficient. These metrics do not penalize conditional generation approaches
for their poor specificity in reproducing the metadata-specific features in the
generated time series. Thus, we innovate a novel evaluation metric that
accurately captures the specificity of conditional generation and the realism
of the generated time series. We show that Time Weaver outperforms
state-of-the-art benchmarks, such as Generative Adversarial Networks (GANs), by
up to 27% in downstream classification tasks on real-world energy, medical, air
quality, and traffic data sets.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02683" title="Abstract">arXiv:2403.02683</a> [<a href="/pdf/2403.02683" title="Download PDF">pdf</a>, <a href="/format/2403.02683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Defer to a Population: A Meta-Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tailor%2C+D">Dharmesh Tailor</a>, 
<a href="/search/cs?searchtype=author&query=Patra%2C+A">Aditya Patra</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+R">Rajeev Verma</a>, 
<a href="/search/cs?searchtype=author&query=Manggala%2C+P">Putra Manggala</a>, 
<a href="/search/cs?searchtype=author&query=Nalisnick%2C+E">Eric Nalisnick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 27th International Conference on Artificial Intelligence and Statistics (AISTATS 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The learning to defer (L2D) framework allows autonomous systems to be safe
and robust by allocating difficult decisions to a human expert. All existing
work on L2D assumes that each expert is well-identified, and if any expert were
to change, the system should be re-trained. In this work, we alleviate this
constraint, formulating an L2D system that can cope with never-before-seen
experts at test-time. We accomplish this by using meta-learning, considering
both optimization- and model-based variants. Given a small context set to
characterize the currently available expert, our framework can quickly adapt
its deferral policy. For the model-based approach, we employ an attention
mechanism that is able to look for points in the context set that are similar
to a given test point, leading to an even more precise assessment of the
expert's abilities. In the experiments, we validate our methods on image
recognition, traffic sign detection, and skin lesion diagnosis benchmarks.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02687" title="Abstract">arXiv:2403.02687</a> [<a href="/pdf/2403.02687" title="Download PDF">pdf</a>, <a href="/format/2403.02687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced DareFightingICE Competitions: Sound Design and AI Competitions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+I">Ibrahim Khan</a>, 
<a href="/search/cs?searchtype=author&query=Nimpattanavong%2C+C">Chollakorn Nimpattanavong</a>, 
<a href="/search/cs?searchtype=author&query=Van+Nguyen%2C+T">Thai Van Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Plupattanakit%2C+K">Kantinan Plupattanakit</a>, 
<a href="/search/cs?searchtype=author&query=Thawonmas%2C+R">Ruck Thawonmas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This paper presents a new and improved DareFightingICE platform, a fighting
game platform with a focus on visually impaired players (VIPs), in the Unity
game engine. It also introduces the separation of the DareFightingICE
Competition into two standalone competitions called DareFightingICE Sound
Design Competition and DareFightingICE AI Competition--at the 2024 IEEE
Conference on Games (CoG)--in which a new platform will be used. This new
platform is an enhanced version of the old DareFightingICE platform, having a
better audio system to convey 3D sound and a better way to send audio data to
AI agents. With this enhancement and by utilizing Unity, the new
DareFightingICE platform is more accessible in terms of adding new features for
VIPs and future audio research. This paper also improves the evaluation method
for evaluating sound designs in the Sound Design Competition which will ensure
a better sound design for VIPs as this competition continues to run at future
CoG. To the best of our knowledge, both of our competitions are first of their
kind, and the connection between the competitions to mutually improve the
entries' quality with time makes these competitions an important part of
representing an often overlooked segment within the broader gaming community,
VIPs.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02688" title="Abstract">arXiv:2403.02688</a> [<a href="/pdf/2403.02688" title="Download PDF">pdf</a>, <a href="/format/2403.02688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DOCTOR: Dynamic On-Chip Remediation Against Temporally-Drifting Thermal  Variations Toward Self-Corrected Photonic Tensor Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Haotian Lu</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Sanmitra Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiaqi Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Photonic computing has emerged as a promising solution for accelerating
computation-intensive artificial intelligence (AI) workloads, offering
unparalleled speed and energy efficiency, especially in resource-limited,
latency-sensitive edge computing environments. However, the deployment of
analog photonic tensor accelerators encounters reliability challenges due to
hardware noises and environmental variations. While off-chip noise-aware
training and on-chip training have been proposed to enhance the variation
tolerance of optical neural accelerators with moderate, static noises, we
observe a notable performance degradation over time due to temporally drifting
variations, which requires a real-time, in-situ calibration mechanism. To
tackle this challenging reliability issues, for the first time, we propose a
lightweight dynamic on-chip remediation framework, dubbed DOCTOR, providing
adaptive, in-situ accuracy recovery against temporally drifting noises. The
DOCTOR framework intelligently monitors the chip status using adaptive probing
and performs fast in-situ training-free calibration to restore accuracy when
necessary. Recognizing nonuniform spatial variation distributions across
devices and tensor cores, we also propose a variation-aware architectural
remapping strategy to avoid executing critical tasks on noisy devices.
Extensive experiments show that our proposed framework can guarantee sustained
performance under drifting variations with 34% higher accuracy and 2-3
orders-of-magnitude lower overhead compared to state-of-the-art on-chip
training methods.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02689" title="Abstract">arXiv:2403.02689</a> [<a href="/pdf/2403.02689" title="Download PDF">pdf</a>, <a href="/format/2403.02689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Common Feature Mining for Efficient Video Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yaoyan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Di Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advancements in video semantic segmentation have made substantial
progress by exploiting temporal correlations. Nevertheless, persistent
challenges, including redundant computation and the reliability of the feature
propagation process, underscore the need for further innovation. In response,
we present Deep Common Feature Mining (DCFM), a novel approach strategically
designed to address these challenges by leveraging the concept of feature
sharing. DCFM explicitly decomposes features into two complementary components.
The common representation extracted from a key-frame furnishes essential
high-level information to neighboring non-key frames, allowing for direct
re-utilization without feature propagation. Simultaneously, the independent
feature, derived from each video frame, captures rapidly changing information,
providing frame-specific clues crucial for segmentation. To achieve such
decomposition, we employ a symmetric training strategy tailored for sparsely
annotated data, empowering the backbone to learn a robust high-level
representation enriched with common information. Additionally, we incorporate a
self-supervised loss function to reinforce intra-class feature similarity and
enhance temporal consistency. Experimental evaluations on the VSPW and
Cityscapes datasets demonstrate the effectiveness of our method, showing a
superior balance between accuracy and efficiency.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02690" title="Abstract">arXiv:2403.02690</a> [<a href="/pdf/2403.02690" title="Download PDF">pdf</a>, <a href="/format/2403.02690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dirichlet-based Per-Sample Weighting by Transition Matrix for Noisy  Label Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bae%2C+H">HeeSun Bae</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+S">Seungjae Shin</a>, 
<a href="/search/cs?searchtype=author&query=Na%2C+B">Byeonghu Na</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+I">Il-Chul Moon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 20 figures, Accepted to the twelfth International Conference on Learninig Representations (ICLR 24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">For learning with noisy labels, the transition matrix, which explicitly
models the relation between noisy label distribution and clean label
distribution, has been utilized to achieve the statistical consistency of
either the classifier or the risk. Previous researches have focused more on how
to estimate this transition matrix well, rather than how to utilize it. We
propose good utilization of the transition matrix is crucial and suggest a new
utilization method based on resampling, coined RENT. Specifically, we first
demonstrate current utilizations can have potential limitations for
implementation. As an extension to Reweighting, we suggest the Dirichlet
distribution-based per-sample Weight Sampling (DWS) framework, and compare
reweighting and resampling under DWS framework. With the analyses from DWS, we
propose RENT, a REsampling method with Noise Transition matrix. Empirically,
RENT consistently outperforms existing transition matrix utilization methods,
which includes reweighting, on various benchmark datasets. Our code is
available at \url{https://github.com/BaeHeeSun/RENT}.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02691" title="Abstract">arXiv:2403.02691</a> [<a href="/pdf/2403.02691" title="Download PDF">pdf</a>, <a href="/format/2403.02691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InjecAgent: Benchmarking Indirect Prompt Injections in Tool-Integrated  Large Language Model Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Q">Qiusi Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zhixiang Liang</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+Z">Zifan Ying</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+D">Daniel Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 5 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Recent work has embodied LLMs as agents, allowing them to access tools,
perform actions, and interact with external content (e.g., emails or websites).
However, external content introduces the risk of indirect prompt injection
(IPI) attacks, where malicious instructions are embedded within the content
processed by LLMs, aiming to manipulate these agents into executing detrimental
actions against users. Given the potentially severe consequences of such
attacks, establishing benchmarks to assess and mitigate these risks is
imperative.
<br />In this work, we introduce InjecAgent, a benchmark designed to assess the
vulnerability of tool-integrated LLM agents to IPI attacks. InjecAgent
comprises 1,054 test cases covering 17 different user tools and 62 attacker
tools. We categorize attack intentions into two primary types: direct harm to
users and exfiltration of private data. We evaluate 30 different LLM agents and
show that agents are vulnerable to IPI attacks, with ReAct-prompted GPT-4
vulnerable to attacks 24% of the time. Further investigation into an enhanced
setting, where the attacker instructions are reinforced with a hacking prompt,
shows additional increases in success rates, nearly doubling the attack success
rate on the ReAct-prompted GPT-4. Our findings raise questions about the
widespread deployment of LLM Agents. Our benchmark is available at
https://github.com/uiuc-kang-lab/InjecAgent.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02692" title="Abstract">arXiv:2403.02692</a> [<a href="/pdf/2403.02692" title="Download PDF">pdf</a>, <a href="/format/2403.02692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uplift Modeling for Target User Attacks on Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Changsheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fuli Feng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wentao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+D">Daizong Ding</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WWW'24 as an oral paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Recommender systems are vulnerable to injective attacks, which inject limited
fake users into the platforms to manipulate the exposure of target items to all
users. In this work, we identify that conventional injective attackers overlook
the fact that each item has its unique potential audience, and meanwhile, the
attack difficulty across different users varies. Blindly attacking all users
will result in a waste of fake user budgets and inferior attack performance. To
address these issues, we focus on an under-explored attack task called target
user attacks, aiming at promoting target items to a particular user group. In
addition, we formulate the varying attack difficulty as heterogeneous treatment
effects through a causal lens and propose an Uplift-guided Budget Allocation
(UBA) framework. UBA estimates the treatment effect on each target user and
optimizes the allocation of fake user budgets to maximize the attack
performance. Theoretical and empirical analysis demonstrates the rationality of
treatment effect estimation methods of UBA. By instantiating UBA on multiple
attackers, we conduct extensive experiments on three datasets under various
settings with different target items, target users, fake user budgets, victim
models, and defense models, validating the effectiveness and robustness of UBA.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02693" title="Abstract">arXiv:2403.02693</a> [<a href="/pdf/2403.02693" title="Download PDF">pdf</a>, <a href="/format/2403.02693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Mobile-Friendly Viewport Prediction for Live 360-Degree Video  Streaming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+T">Tao Long</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weizhen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+L">Laizhong Cui</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiangchuan Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Viewport prediction is the crucial task for adaptive 360-degree video
streaming, as the bitrate control algorithms usually require the knowledge of
the user's viewing portions of the frames. Various methods are studied and
adopted for viewport prediction from less accurate statistic tools to highly
calibrated deep neural networks. Conventionally, it is difficult to implement
sophisticated deep learning methods on mobile devices, which have limited
computation capability. In this work, we propose an advanced learning-based
viewport prediction approach and carefully design it to introduce minimal
transmission and computation overhead for mobile terminals. We also propose a
model-agnostic meta-learning (MAML) based saliency prediction network trainer,
which provides a few-sample fast training solution to obtain the prediction
model by utilizing the information from the past models. We further discuss how
to integrate this mobile-friendly viewport prediction (MFVP) approach into a
typical 360-degree video live streaming system by formulating and solving the
bitrate adaptation problem. Extensive experiment results show that our
prediction approach can work in real-time for live video streaming and can
achieve higher accuracies compared to other existing prediction methods on
mobile end, which, together with our bitrate adaptation algorithm,
significantly improves the streaming QoE from various aspects. We observe the
accuracy of MFVP is 8.1$\%$ to 28.7$\%$ higher than other algorithms and
achieves 3.73$\%$ to 14.96$\%$ higher average quality level and 49.6$\%$ to
74.97$\%$ less quality level change than other algorithms.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02694" title="Abstract">arXiv:2403.02694</a> [<a href="/pdf/2403.02694" title="Download PDF">pdf</a>, <a href="/format/2403.02694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Aware Semantic Cache for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gill%2C+W">Waris Gill</a> (1), 
<a href="/search/cs?searchtype=author&query=Elidrisi%2C+M">Mohamed Elidrisi</a> (2), 
<a href="/search/cs?searchtype=author&query=Kalapatapu%2C+P">Pallavi Kalapatapu</a> (2), 
<a href="/search/cs?searchtype=author&query=Anwar%2C+A">Ali Anwar</a> (3), 
<a href="/search/cs?searchtype=author&query=Gulzar%2C+M+A">Muhammad Ali Gulzar</a> (1) ((1) Virginia Tech, USA, (2) Cisco, USA (3) University of Minnesota, Minneapolis, USA)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This study presents the first privacy aware semantic cache for LLMs based on Federated Learning. Total pages 12
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Large Language Models (LLMs) like ChatGPT, Google Bard, Claude, and Llama 2
have revolutionized natural language processing and search engine dynamics.
However, these models incur exceptionally high computational costs. For
instance, GPT-3 consists of 175 billion parameters and inference on these
models also demands billions of floating-point operations. Caching is a natural
solution to reduce LLM inference costs on repeated queries. However, existing
caching methods are incapable of finding semantic similarities among LLM
queries, leading to unacceptable false hit-and-miss rates.
<br />This paper introduces MeanCache, a semantic cache for LLMs that identifies
semantically similar queries to determine cache hit or miss. Using MeanCache,
the response to a user's semantically similar query can be retrieved from a
local cache rather than re-querying the LLM, thus reducing costs, service
provider load, and environmental impact. MeanCache leverages Federated Learning
(FL) to collaboratively train a query similarity model in a distributed manner
across numerous users without violating privacy. By placing a local cache in
each user's device and using FL, MeanCache reduces the latency and costs and
enhances model performance, resulting in lower cache false hit rates. Our
experiments, benchmarked against the GPTCache, reveal that MeanCache attains an
approximately 17% higher F-score and a 20% increase in precision during
semantic cache hit-and-miss decisions. Furthermore, MeanCache reduces the
storage requirement by 83% and accelerates semantic cache hit-and-miss
decisions by 11%, while still surpassing GPTCache.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02695" title="Abstract">arXiv:2403.02695</a> [<a href="/pdf/2403.02695" title="Download PDF">pdf</a>, <a href="/format/2403.02695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllable Prompt Tuning For Balancing Group Distributional Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phan%2C+H">Hoang Phan</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+A+G">Andrew Gordon Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Q">Qi Lei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 11 figures, 13 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Models trained on data composed of different groups or domains can suffer
from severe performance degradation under distribution shifts. While recent
methods have largely focused on optimizing the worst-group objective, this
often comes at the expense of good performance on other groups. To address this
problem, we introduce an optimization scheme to achieve good performance across
groups and find a good solution for all without severely sacrificing
performance on any of them. However, directly applying such optimization
involves updating the parameters of the entire network, making it both
computationally expensive and challenging. Thus, we introduce Controllable
Prompt Tuning (CPT), which couples our approach with prompt-tuning techniques.
On spurious correlation benchmarks, our procedures achieve state-of-the-art
results across both transformer and non-transformer architectures, as well as
unimodal and multimodal data, while requiring only 0.4% tunable parameters.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02698" title="Abstract">arXiv:2403.02698</a> [<a href="/pdf/2403.02698" title="Download PDF">pdf</a>, <a href="/format/2403.02698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Walk: Debiasing Multi-Hop Fact Verification with Front-Door  Adjustment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Congzhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Linhai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Deyu Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Conventional multi-hop fact verification models are prone to rely on spurious
correlations from the annotation artifacts, leading to an obvious performance
decline on unbiased datasets. Among the various debiasing works, the causal
inference-based methods become popular by performing theoretically guaranteed
debiasing such as casual intervention or counterfactual reasoning. However,
existing causal inference-based debiasing methods, which mainly formulate fact
verification as a single-hop reasoning task to tackle shallow bias patterns,
cannot deal with the complicated bias patterns hidden in multiple hops of
evidence. To address the challenge, we propose Causal Walk, a novel method for
debiasing multi-hop fact verification from a causal perspective with front-door
adjustment. Specifically, in the structural causal model, the reasoning path
between the treatment (the input claim-evidence graph) and the outcome (the
veracity label) is introduced as the mediator to block the confounder. With the
front-door adjustment, the causal effect between the treatment and the outcome
is decomposed into the causal effect between the treatment and the mediator,
which is estimated by applying the idea of random walk, and the causal effect
between the mediator and the outcome, which is estimated with normalized
weighted geometric mean approximation. To investigate the effectiveness of the
proposed method, an adversarial multi-hop fact verification dataset and a
symmetric multi-hop fact verification dataset are proposed with the help of the
large language model. Experimental results show that Causal Walk outperforms
some previous debiasing methods on both existing datasets and the newly
constructed datasets. Code and data will be released at
https://github.com/zcccccz/CausalWalk.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02701" title="Abstract">arXiv:2403.02701</a> [<a href="/pdf/2403.02701" title="Download PDF">pdf</a>, <a href="/format/2403.02701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fighting Game Adaptive Background Music for Improved Gameplay
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+I">Ibrahim Khan</a>, 
<a href="/search/cs?searchtype=author&query=Van+Nguyen%2C+T">Thai Van Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nimpattanavong%2C+C">Chollakorn Nimpattanavong</a>, 
<a href="/search/cs?searchtype=author&query=Thawonmas%2C+R">Ruck Thawonmas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an updated version of our IEEE CoG 2023 paper (<a href="https://ieeexplore.ieee.org/document/10333245">this https URL</a>). This version has revised the description of the association between the distance between the two players (PD) and the instrument's volume on page 2. arXiv admin note: substantial text overlap with <a href="/abs/2303.15734">arXiv:2303.15734</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This paper presents our work to enhance the background music (BGM) in
DareFightingICE by adding adaptive features. The adaptive BGM consists of three
different categories of instruments playing the BGM of the winner sound design
from the 2022 DareFightingICE Competition. The BGM adapts by changing the
volume of each category of instruments. Each category is connected to a
different element of the game. We then run experiments to evaluate the adaptive
BGM by using a deep reinforcement learning AI agent that only uses audio as
input (Blind DL AI). The results show that the performance of the Blind DL AI
improves while playing with the adaptive BGM as compared to playing without the
adaptive BGM.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02707" title="Abstract">arXiv:2403.02707</a> [<a href="/pdf/2403.02707" title="Download PDF">pdf</a>, <a href="/format/2403.02707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Generalization in Medical Visual Question Answering Tasks via  Gradient-Guided Model Perturbation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Gang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyang Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zerui He</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+S">Shenjun Zhong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Leveraging pre-trained visual language models has become a widely adopted
approach for improving performance in downstream visual question answering
(VQA) applications. However, in the specialized field of medical VQA, the
scarcity of available data poses a significant barrier to achieving reliable
model generalization. Numerous methods have been proposed to enhance model
generalization, addressing the issue from data-centric and model-centric
perspectives. Data augmentation techniques are commonly employed to enrich the
dataset, while various regularization approaches aim to prevent model
overfitting, especially when training on limited data samples. In this paper,
we introduce a method that incorporates gradient-guided parameter perturbations
to the visual encoder of the multimodality model during both pre-training and
fine-tuning phases, to improve model generalization for downstream medical VQA
tasks. The small perturbation is adaptively generated by aligning with the
direction of the moving average gradient in the optimization landscape, which
is opposite to the directions of the optimizer's historical updates. It is
subsequently injected into the model's visual encoder. The results show that,
even with a significantly smaller pre-training image caption dataset, our
approach achieves competitive outcomes on both VQA-RAD and SLAKE datasets.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02708" title="Abstract">arXiv:2403.02708</a> [<a href="/pdf/2403.02708" title="Download PDF">pdf</a>, <a href="/format/2403.02708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backfire Effect Reveals Early Controversy in Online Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Songtao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Fua%2C+C">Chenbo Fua</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+H">Han Han</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Ye Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Kailun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xuan%2C+Q">Qi Xuan</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+Y">Yong Min</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">The rapid development of online media has significantly facilitated the
public's information consumption, knowledge acquisition, and opinion exchange.
However, it has also led to more violent conflicts in online discussions.
Therefore, controversy detection becomes important for computational and social
sciences. Previous research on detection methods has primarily focused on
larger datasets and more complex computational models but has rarely examined
the underlying mechanisms of conflict, particularly the psychological
motivations behind them. In this paper, we present evidence that conflicting
posts tend to have a high proportion of "ascending gradient of likes", i.e.,
replies get more likes than comments. Additionally, there is a gradient in the
number of replies between the neighboring tiers as well. We develop two new
gradient features and demonstrate the common enhancement effect of our features
in terms of controversy detection models. Further, multiple evaluation
algorithms are used to compare structural, interactive, and textual features
with the new features across multiple Chinese and English media. The results
show that it is a general case that gradient features are significantly
different in terms of controversy and are more important than other features.
More thoroughly, we discuss the mechanism by which the ascending gradient
emerges, suggesting that the case is related to the "backfire effect" in
ideological conflicts that have received recent attention. The features formed
by the psychological mechanism also show excellent detection performance in
application scenarios where only a few hot information or early information are
considered. Our findings can provide a new perspective for online conflict
behavior analysis and early detection.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02709" title="Abstract">arXiv:2403.02709</a> [<a href="/pdf/2403.02709" title="Download PDF">pdf</a>, <a href="/format/2403.02709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RT-Sketch: Goal-Conditioned Imitation Learning from Hand-Drawn Sketches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sundaresan%2C+P">Priya Sundaresan</a>, 
<a href="/search/cs?searchtype=author&query=Vuong%2C+Q">Quan Vuong</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiayuan Gu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Peng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Ted Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Kirmani%2C+S">Sean Kirmani</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tianhe Yu</a>, 
<a href="/search/cs?searchtype=author&query=Stark%2C+M">Michael Stark</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Ajinkya Jain</a>, 
<a href="/search/cs?searchtype=author&query=Hausman%2C+K">Karol Hausman</a>, 
<a href="/search/cs?searchtype=author&query=Sadigh%2C+D">Dorsa Sadigh</a>, 
<a href="/search/cs?searchtype=author&query=Bohg%2C+J">Jeannette Bohg</a>, 
<a href="/search/cs?searchtype=author&query=Schaal%2C+S">Stefan Schaal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Natural language and images are commonly used as goal representations in
goal-conditioned imitation learning (IL). However, natural language can be
ambiguous and images can be over-specified. In this work, we propose hand-drawn
sketches as a modality for goal specification in visual imitation learning.
Sketches are easy for users to provide on the fly like language, but similar to
images they can also help a downstream policy to be spatially-aware and even go
beyond images to disambiguate task-relevant from task-irrelevant objects. We
present RT-Sketch, a goal-conditioned policy for manipulation that takes a
hand-drawn sketch of the desired scene as input, and outputs actions. We train
RT-Sketch on a dataset of paired trajectories and corresponding synthetically
generated goal sketches. We evaluate this approach on six manipulation skills
involving tabletop object rearrangements on an articulated countertop.
Experimentally we find that RT-Sketch is able to perform on a similar level to
image or language-conditioned agents in straightforward settings, while
achieving greater robustness when language goals are ambiguous or visual
distractors are present. Additionally, we show that RT-Sketch has the capacity
to interpret and act upon sketches with varied levels of specificity, ranging
from minimal line drawings to detailed, colored drawings. For supplementary
material and videos, please refer to our website: <a href="http://rt-sketch.github.io.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02710" title="Abstract">arXiv:2403.02710</a> [<a href="/pdf/2403.02710" title="Download PDF">pdf</a>, <a href="/format/2403.02710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FastOcc: Accelerating 3D Occupancy Prediction by Fusing the 2D  Bird&#x27;s-Eye View and Perspective View
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Jiawei Hou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoyan Li</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+W">Wenhao Guan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+D">Di Feng</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yuheng Du</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+X">Xiangyang Xue</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+J">Jian Pu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">In autonomous driving, 3D occupancy prediction outputs voxel-wise status and
semantic labels for more comprehensive understandings of 3D scenes compared
with traditional perception tasks, such as 3D object detection and bird's-eye
view (BEV) semantic segmentation. Recent researchers have extensively explored
various aspects of this task, including view transformation techniques,
ground-truth label generation, and elaborate network design, aiming to achieve
superior performance. However, the inference speed, crucial for running on an
autonomous vehicle, is neglected. To this end, a new method, dubbed FastOcc, is
proposed. By carefully analyzing the network effect and latency from four
parts, including the input image resolution, image backbone, view
transformation, and occupancy prediction head, it is found that the occupancy
prediction head holds considerable potential for accelerating the model while
keeping its accuracy. Targeted at improving this component, the time-consuming
3D convolution network is replaced with a novel residual-like architecture,
where features are mainly digested by a lightweight 2D BEV convolution network
and compensated by integrating the 3D voxel features interpolated from the
original image features. Experiments on the Occ3D-nuScenes benchmark
demonstrate that our FastOcc achieves state-of-the-art results with a fast
inference speed.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02711" title="Abstract">arXiv:2403.02711</a> [<a href="/pdf/2403.02711" title="Download PDF">pdf</a>, <a href="/format/2403.02711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing computational effort in topology optimization considering the  deformation in additive manufacturing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miki%2C+T">Takao Miki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Integrating topology optimization and additive manufacturing (AM) technology
can facilitate innovative product development. However, laser powder bed
fusion, which is the predominant method in metal AM, can lead to issues such as
residual stress and deformation. Recently, topology optimization methods
considering these stresses and deformations have been proposed; however, they
suffer from challenges caused by an increased computational cost. In this
study, we propose a method for reducing computational cost in topology
optimization considering the deformation in AM. An inherent strain method-based
analytical model is presented for simulating the residual stress and
deformation in the AM process. Subsequently, a constraint condition to suppress
the deformation is formulated, and a method to reduce the computational cost of
the adjoint analysis in deriving sensitivity is proposed. The minimum mean
compliance problem considering AM deformation and self-support constraints can
then be incorporated into the level set-based topology optimization framework.
Finally, numerical examples are presented for validating the effectiveness of
the proposed topology optimization method.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02712" title="Abstract">arXiv:2403.02712</a> [<a href="/pdf/2403.02712" title="Download PDF">pdf</a>, <a href="/format/2403.02712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breeze-7B Technical Report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hsu%2C+C">Chan-Jan Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang-Le Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+F">Feng-Ting Liao</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+P">Po-Chun Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yi-Chang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shiu%2C+D">Da-Shan Shiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Breeze-7B is an open-source language model based on Mistral-7B, designed to
address the need for improved language comprehension and chatbot-oriented
capabilities in Traditional Chinese. This technical report provides an overview
of the additional pretraining, finetuning, and evaluation stages for the
Breeze-7B model. The Breeze-7B family of base and chat models exhibits good
performance on language comprehension and chatbot-oriented tasks, reaching the
top in several benchmarks among models comparable in its complexity class.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02713" title="Abstract">arXiv:2403.02713</a> [<a href="/pdf/2403.02713" title="Download PDF">pdf</a>, <a href="/format/2403.02713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Android in the Zoo: Chain-of-Action-Thought for GUI Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jihao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+Y">Yihua Teng</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+M">Minghui Liao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+N">Nuo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xiao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhongyu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+D">Duyu Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Dataset could be found in <a href="https://github.com/IMNearth/CoAT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language model (LLM) leads to a surge of autonomous GUI agents for
smartphone, which completes a task triggered by natural language through
predicting a sequence of actions of API. Even though the task highly relies on
past actions and visual observations, existing studies typical consider little
semantic information carried out by intermediate screenshots and screen
operations. To address this, this work presents Chain-of-Action-Thought (dubbed
CoAT), which takes the description of the previous actions, the current screen,
and more importantly the action thinking of what actions should be performed
and the outcomes led by the chosen action. We demonstrate that, in a zero-shot
setting upon an off-the-shell LLM, CoAT significantly improves the goal
progress compared to standard context modeling. To further facilitate the
research in this line, we construct a benchmark Android-In-The-Zoo (AitZ),
which contains 18,643 screen-action pairs together with chain-of-action-thought
annotations. Experiments show that fine-tuning a 200M model on our AitZ dataset
achieves on par performance with CogAgent-Chat-18B.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02714" title="Abstract">arXiv:2403.02714</a> [<a href="/pdf/2403.02714" title="Download PDF">pdf</a>, <a href="/format/2403.02714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DomainVerse: A Benchmark Towards Real-World Distribution Shifts For  Tuning-Free Adaptive Domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+F">Feng Hou</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Ying Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+C">Cheng Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhongchao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jianping Fan</a>, 
<a href="/search/cs?searchtype=author&query=Rui%2C+Y">Yong Rui</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhiqiang He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Currently in review for ICML 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Traditional cross-domain tasks, including domain adaptation and domain
generalization, rely heavily on training model by source domain data. With the
recent advance of vision-language models (VLMs), viewed as natural source
models, the cross-domain task changes to directly adapt the pre-trained source
model to arbitrary target domains equipped with prior domain knowledge, and we
name this task Adaptive Domain Generalization (ADG). However, current
cross-domain datasets have many limitations, such as unrealistic domains,
unclear domain definitions, and the inability to fine-grained domain
decomposition, which drives us to establish a novel dataset DomainVerse for
ADG. Benefiting from the introduced hierarchical definition of domain shifts,
DomainVerse consists of about 0.5 million images from 390 fine-grained
realistic domains. With the help of the constructed DomainVerse and VLMs, we
propose two methods called Domain CLIP and Domain++ CLIP for tuning-free
adaptive domain generalization. Extensive and comprehensive experiments
demonstrate the significance of the dataset and the effectiveness of the
proposed methods.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02715" title="Abstract">arXiv:2403.02715</a> [<a href="/pdf/2403.02715" title="Download PDF">pdf</a>, <a href="/format/2403.02715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crossing Linguistic Horizons: Finetuning and Comprehensive Evaluation of  Vietnamese Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Truong%2C+S+T">Sang T. Truong</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+Q">Duc Q. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Toan Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+D+D">Dong D. Le</a>, 
<a href="/search/cs?searchtype=author&query=Truong%2C+N+N">Nhi N. Truong</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+T">Tho Quan</a>, 
<a href="/search/cs?searchtype=author&query=Koyejo%2C+S">Sanmi Koyejo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent advancements in large language models (LLMs) have underscored their
importance in the evolution of artificial intelligence. However, despite
extensive pretraining on multilingual datasets, available open-sourced LLMs
exhibit limited effectiveness in processing Vietnamese. The challenge is
exacerbated by the absence of systematic benchmark datasets and metrics
tailored for Vietnamese LLM evaluation. To mitigate these issues, we have
finetuned LLMs specifically for Vietnamese and developed a comprehensive
evaluation framework encompassing 10 common tasks and 31 metrics. Our
evaluation results reveal that the fine-tuned LLMs exhibit enhanced
comprehension and generative capabilities in Vietnamese. Moreover, our analysis
indicates that models with more parameters can introduce more biases and
uncalibrated outputs and the key factor influencing LLM performance is the
quality of the training or fine-tuning datasets. These insights underscore the
significance of meticulous fine-tuning with high-quality datasets in enhancing
LLM performance.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02716" title="Abstract">arXiv:2403.02716</a> [<a href="/pdf/2403.02716" title="Download PDF">pdf</a>, <a href="/format/2403.02716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-trained Model-based Actionable Warning Identification: A Feasibility  Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+X">Xiuting Ge</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chunrong Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Quanjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Daoyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bowen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Q">Qirui Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+A">An Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shangwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhihong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenyu Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Actionable Warning Identification (AWI) plays a pivotal role in improving the
usability of static code analyzers. Currently, Machine Learning (ML)-based AWI
approaches, which mainly learn an AWI classifier from labeled warnings, are
notably common. However, these approaches still face the problem of restricted
performance due to the direct reliance on a limited number of labeled warnings
to develop a classifier. Very recently, Pre-Trained Models (PTMs), which have
been trained through billions of text/code tokens and demonstrated substantial
success applications on various code-related tasks, could potentially
circumvent the above problem. Nevertheless, the performance of PTMs on AWI has
not been systematically investigated, leaving a gap in understanding their pros
and cons. In this paper, we are the first to explore the feasibility of
applying various PTMs for AWI. By conducting the extensive evaluation on 10K+
SpotBugs warnings from 10 large-scale and open-source projects, we observe that
all studied PTMs are consistently 9.85%~21.12% better than the state-of-the-art
ML-based AWI approaches. Besides, we investigate the impact of three primary
aspects (i.e., data preprocessing, model training, and model prediction) in the
typical PTM-based AWI workflow. Further, we identify the reasons for current
PTMs' underperformance on AWI. Based on our findings, we provide several
practical guidelines to enhance PTM-based AWI in future work.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02718" title="Abstract">arXiv:2403.02718</a> [<a href="/pdf/2403.02718" title="Download PDF">pdf</a>, <a href="/format/2403.02718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DP-CRE: Continual Relation Extraction via Decoupled Contrastive Learning  and Memory Structure Preservation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Mengyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Meng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Ludi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yi Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted By LREC-Coling-2024, 10 pages with 2 pages of appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Continuous Relation Extraction (CRE) aims to incrementally learn relation
knowledge from a non-stationary stream of data. Since the introduction of new
relational tasks can overshadow previously learned information, catastrophic
forgetting becomes a significant challenge in this domain. Current replay-based
training paradigms prioritize all data uniformly and train memory samples
through multiple rounds, which would result in overfitting old tasks and
pronounced bias towards new tasks because of the imbalances of the replay set.
To handle the problem, we introduce the DecouPled CRE (DP-CRE) framework that
decouples the process of prior information preservation and new knowledge
acquisition. This framework examines alterations in the embedding space as new
relation classes emerge, distinctly managing the preservation and acquisition
of knowledge. Extensive experiments show that DP-CRE significantly outperforms
other CRE baselines across two datasets.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02719" title="Abstract">arXiv:2403.02719</a> [<a href="/pdf/2403.02719" title="Download PDF">pdf</a>, <a href="/ps/2403.02719" title="Download PostScript">ps</a>, <a href="/format/2403.02719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Scale Subgraph Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanbei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+L">Lei Geng</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zhitao Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Graph-level contrastive learning, aiming to learn the representations for
each graph by contrasting two augmented graphs, has attracted considerable
attention. Previous studies usually simply assume that a graph and its
augmented graph as a positive pair, otherwise as a negative pair. However, it
is well known that graph structure is always complex and multi-scale, which
gives rise to a fundamental question: after graph augmentation, will the
previous assumption still hold in reality? By an experimental analysis, we
discover the semantic information of an augmented graph structure may be not
consistent as original graph structure, and whether two augmented graphs are
positive or negative pairs is highly related with the multi-scale structures.
Based on this finding, we propose a multi-scale subgraph contrastive learning
method which is able to characterize the fine-grained semantic information.
Specifically, we generate global and local views at different scales based on
subgraph sampling, and construct multiple contrastive relationships according
to their semantic associations to provide richer self-supervised signals.
Extensive experiments and parametric analysis on eight graph classification
real-world datasets well demonstrate the effectiveness of the proposed method.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02723" title="Abstract">arXiv:2403.02723</a> [<a href="/pdf/2403.02723" title="Download PDF">pdf</a>, <a href="/format/2403.02723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimum Topology Attacks for Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengmei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+L">Lingjuan Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tianchi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Junping Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published on WWW 2023. Proceedings of the ACM Web Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">With the great popularity of Graph Neural Networks (GNNs), their robustness
to adversarial topology attacks has received significant attention. Although
many attack methods have been proposed, they mainly focus on fixed-budget
attacks, aiming at finding the most adversarial perturbations within a fixed
budget for target node. However, considering the varied robustness of each
node, there is an inevitable dilemma caused by the fixed budget, i.e., no
successful perturbation is found when the budget is relatively small, while if
it is too large, the yielding redundant perturbations will hurt the
invisibility. To break this dilemma, we propose a new type of topology attack,
named minimum-budget topology attack, aiming to adaptively find the minimum
perturbation sufficient for a successful attack on each node. To this end, we
propose an attack model, named MiBTack, based on a dynamic projected gradient
descent algorithm, which can effectively solve the involving non-convex
constraint optimization on discrete topology. Extensive results on three GNNs
and four real-world datasets show that MiBTack can successfully lead all target
nodes misclassified with the minimum perturbation edges. Moreover, the obtained
minimum budget can be used to measure node robustness, so we can explore the
relationships of robustness, topology, and uncertainty for nodes, which is
beyond what the current fixed-budget topology attacks can offer.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02727" title="Abstract">arXiv:2403.02727</a> [<a href="/pdf/2403.02727" title="Download PDF">pdf</a>, <a href="/format/2403.02727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HARGPT: Are LLMs Zero-Shot Human Activity Recognizers?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Sijie Ji</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xinzhe Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenshu Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">There is an ongoing debate regarding the potential of Large Language Models
(LLMs) as foundational models seamlessly integrated with Cyber-Physical Systems
(CPS) for interpreting the physical world. In this paper, we carry out a case
study to answer the following question: Are LLMs capable of zero-shot human
activity recognition (HAR). Our study, HARGPT, presents an affirmative answer
by demonstrating that LLMs can comprehend raw IMU data and perform HAR tasks in
a zero-shot manner, with only appropriate prompts. HARGPT inputs raw IMU data
into LLMs and utilizes the role-play and think step-by-step strategies for
prompting. We benchmark HARGPT on GPT4 using two public datasets of different
inter-class similarities and compare various baselines both based on
traditional machine learning and state-of-the-art deep classification models.
Remarkably, LLMs successfully recognize human activities from raw IMU data and
consistently outperform all the baselines on both datasets. Our findings
indicate that by effective prompting, LLMs can interpret raw IMU data based on
their knowledge base, possessing a promising potential to analyze raw sensor
data of the physical world effectively.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02730" title="Abstract">arXiv:2403.02730</a> [<a href="/pdf/2403.02730" title="Download PDF">pdf</a>, <a href="/format/2403.02730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Two-Stage Training Method for Modeling Constrained Systems With Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coelho%2C+C">C. Coelho</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+M+F+P">M. Fernanda P. Costa</a>, 
<a href="/search/cs?searchtype=author&query=Ferr%C3%A1s%2C+L+L">L.L. Ferr&#xe1;s</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Optimization and Control (math.OC)

</div>
<p class="mathjax">Real-world systems are often formulated as constrained optimization problems.
Techniques to incorporate constraints into Neural Networks (NN), such as Neural
Ordinary Differential Equations (Neural ODEs), have been used. However, these
introduce hyperparameters that require manual tuning through trial and error,
raising doubts about the successful incorporation of constraints into the
generated model. This paper describes in detail the two-stage training method
for Neural ODEs, a simple, effective, and penalty parameter-free approach to
model constrained systems. In this approach the constrained optimization
problem is rewritten as two unconstrained sub-problems that are solved in two
stages. The first stage aims at finding feasible NN parameters by minimizing a
measure of constraints violation. The second stage aims to find the optimal NN
parameters by minimizing the loss function while keeping inside the feasible
region. We experimentally demonstrate that our method produces models that
satisfy the constraints and also improves their predictive performance. Thus,
ensuring compliance with critical system properties and also contributing to
reducing data quantity requirements. Furthermore, we show that the proposed
method improves the convergence to an optimal solution and improves the
explainability of Neural ODE models. Our proposed two-stage training method can
be used with any NN architectures.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02735" title="Abstract">arXiv:2403.02735</a> [<a href="/pdf/2403.02735" title="Download PDF">pdf</a>, <a href="/format/2403.02735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed OpenMP Offloading of OpenMC on Intel GPU MAX Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fridman%2C+Y">Yehonatan Fridman</a>, 
<a href="/search/cs?searchtype=author&query=Tamir%2C+G">Guy Tamir</a>, 
<a href="/search/cs?searchtype=author&query=Steinitz%2C+U">Uri Steinitz</a>, 
<a href="/search/cs?searchtype=author&query=Oren%2C+G">Gal Oren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Monte Carlo (MC) simulations play a pivotal role in diverse scientific and
engineering domains, with applications ranging from nuclear physics to
materials science. Harnessing the computational power of high-performance
computing (HPC) systems, especially Graphics Processing Units (GPUs), has
become essential for accelerating MC simulations. This paper focuses on the
adaptation and optimization of the OpenMC neutron and photon transport Monte
Carlo code for Intel GPUs, specifically the Intel Data Center Max 1100 GPU
(codename Ponte Vecchio, PVC), through distributed OpenMP offloading. Building
upon prior work by Tramm J.R., et al. (2022), which laid the groundwork for GPU
adaptation, our study meticulously extends the OpenMC code's capabilities to
Intel GPUs. We present a comprehensive benchmarking and scaling analysis,
comparing performance on Intel MAX GPUs to state-of-the-art CPU execution
(Intel Xeon Platinum 8480+ Processor, codename 4th generation Sapphire Rapids).
The results demonstrate a remarkable acceleration factor compared to CPU
execution, showcasing the GPU-adapted code's superiority over its CPU
counterpart as computational load increases.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02736" title="Abstract">arXiv:2403.02736</a> [<a href="/pdf/2403.02736" title="Download PDF">pdf</a>, <a href="/format/2403.02736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bootstrapping Rare Object Detection in High-Resolution Satellite Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zaytar%2C+A">Akram Zaytar</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+C">Caleb Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Hacheme%2C+G+Q">Gilles Q. Hacheme</a>, 
<a href="/search/cs?searchtype=author&query=Tadesse%2C+G+A">Girmaw A. Tadesse</a>, 
<a href="/search/cs?searchtype=author&query=Dodhia%2C+R">Rahul Dodhia</a>, 
<a href="/search/cs?searchtype=author&query=Ferres%2C+J+M+L">Juan M. Lavista Ferres</a>, 
<a href="/search/cs?searchtype=author&query=Hughey%2C+L+F">Lacey F. Hughey</a>, 
<a href="/search/cs?searchtype=author&query=Stabach%2C+J+A">Jared A. Stabach</a>, 
<a href="/search/cs?searchtype=author&query=Amoke%2C+I">Irene Amoke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Rare object detection is a fundamental task in applied geospatial machine
learning, however is often challenging due to large amounts of high-resolution
satellite or aerial imagery and few or no labeled positive samples to start
with. This paper addresses the problem of bootstrapping such a rare object
detection task assuming there is no labeled data and no spatial prior over the
area of interest. We propose novel offline and online cluster-based approaches
for sampling patches that are significantly more efficient, in terms of
exposing positive samples to a human annotator, than random sampling. We apply
our methods for identifying bomas, or small enclosures for herd animals, in the
Serengeti Mara region of Kenya and Tanzania. We demonstrate a significant
enhancement in detection efficiency, achieving a positive sampling rate
increase from 2% (random) to 30%. This advancement enables effective machine
learning mapping even with minimal labeling budgets, exemplified by an F1 score
on the boma detection task of 0.51 with a budget of 300 total patches.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02737" title="Abstract">arXiv:2403.02737</a> [<a href="/pdf/2403.02737" title="Download PDF">pdf</a>, <a href="/format/2403.02737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Fractional Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coelho%2C+C">C. Coelho</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+M+F+P">M. Fernanda P. Costa</a>, 
<a href="/search/cs?searchtype=author&query=Ferr%C3%A1s%2C+L+L">L.L. Ferr&#xe1;s</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Fractional Differential Equations (FDEs) are essential tools for modelling
complex systems in science and engineering. They extend the traditional
concepts of differentiation and integration to non-integer orders, enabling a
more precise representation of processes characterised by non-local and
memory-dependent behaviours.
<br />This property is useful in systems where variables do not respond to changes
instantaneously, but instead exhibit a strong memory of past interactions.
<br />Having this in mind, and drawing inspiration from Neural Ordinary
Differential Equations (Neural ODEs), we propose the Neural FDE, a novel deep
neural network architecture that adjusts a FDE to the dynamics of data.
<br />This work provides a comprehensive overview of the numerical method employed
in Neural FDEs and the Neural FDE architecture. The numerical outcomes suggest
that, despite being more computationally demanding, the Neural FDE may
outperform the Neural ODE in modelling systems with memory or dependencies on
past states, and it can effectively be applied to learn more intricate
dynamical systems.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02738" title="Abstract">arXiv:2403.02738</a> [<a href="/pdf/2403.02738" title="Download PDF">pdf</a>, <a href="/format/2403.02738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Prompting: Debiasing Large Language Model Prompting based on  Front-Door Adjustment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Congzhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Linhai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Deyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guoqiang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Despite the significant achievements of existing prompting methods such as
in-context learning and chain-of-thought for large language models (LLMs), they
still face challenges of various biases. Traditional debiasing methods
primarily focus on the model training stage, including data augmentation-based
and reweight-based approaches, with the limitations of addressing the complex
biases of LLMs. To address such limitations, the causal relationship behind the
prompting methods is uncovered using a structural causal model, and a novel
causal prompting method based on front-door adjustment is proposed to
effectively mitigate the bias of LLMs. In specific, causal intervention is
implemented by designing the prompts without accessing the parameters and
logits of LLMs.The chain-of-thoughts generated by LLMs are employed as the
mediator variable and the causal effect between the input prompt and the output
answers is calculated through front-door adjustment to mitigate model biases.
Moreover, to obtain the representation of the samples precisely and estimate
the causal effect more accurately, contrastive learning is used to fine-tune
the encoder of the samples by aligning the space of the encoder with the LLM.
Experimental results show that the proposed causal prompting approach achieves
excellent performance on 3 natural language processing datasets on both
open-source and closed-source LLMs.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02741" title="Abstract">arXiv:2403.02741</a> [<a href="/pdf/2403.02741" title="Download PDF">pdf</a>, <a href="/format/2403.02741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> State-Constrained Zero-Sum Differential Games with One-Sided Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghimire%2C+M">Mukesh Ghimire</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yi Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We study zero-sum differential games with state constraints and one-sided
information, where the informed player (Player 1) has a categorical payoff type
unknown to the uninformed player (Player 2). The goal of Player 1 is to
minimize his payoff without violating the constraints, while that of Player 2
is to either violate the state constraints, or otherwise, to maximize the
payoff. One example of the game is a man-to-man matchup in football. Without
state constraints, Cardaliaguet (2007) showed that the value of such a game
exists and is convex to the common belief of players. Our theoretical
contribution is an extension of this result to differential games with state
constraints and the derivation of the primal and dual subdynamic principles
necessary for computing the behavioral strategies. Compared with existing works
on imperfect-information dynamic games that focus on scalability and
generalization, our focus is instead on revealing the mechanism of belief
manipulation behaviors resulted from information asymmetry and state
constraints. We use a simplified football game to demonstrate the utility of
this work, where we reveal player positions and belief states in which the
attacker should (or should not) play specific random fake moves to take
advantage of information asymmetry, and compute how the defender should
respond.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02742" title="Abstract">arXiv:2403.02742</a> [<a href="/pdf/2403.02742" title="Download PDF">pdf</a>, <a href="/format/2403.02742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Training A Chinese Large Language Model for Anesthesiology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhonghai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jie Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Y">Yibing Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bohao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Liang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hua Jin</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Jun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weifeng Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Medical large language models (LLMs) have gained popularity recently due to
their significant practical utility. However, most existing research focuses on
general medicine, and there is a need for in-depth study of LLMs in specific
fields like anesthesiology. To fill the gap, we introduce Hypnos, a Chinese
Anesthesia model built upon existing LLMs, e.g., Llama. Hypnos' contributions
have three aspects: 1) The data, such as utilizing Self-Instruct, acquired from
current LLMs likely includes inaccuracies. Hypnos implements a cross-filtering
strategy to improve the data quality. This strategy involves using one LLM to
assess the quality of the generated data from another LLM and filtering out the
data with low quality. 2) Hypnos employs a general-to-specific training
strategy that starts by fine-tuning LLMs using the general medicine data and
subsequently improving the fine-tuned LLMs using data specifically from
Anesthesiology. The general medical data supplement the medical expertise in
Anesthesiology and enhance the effectiveness of Hypnos' generation. 3) We
introduce a standardized benchmark for evaluating medical LLM in
Anesthesiology. Our benchmark includes both publicly available instances from
the Internet and privately obtained cases from the Hospital. Hypnos outperforms
other medical LLMs in anesthesiology in metrics, GPT-4, and human evaluation on
the benchmark dataset.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02744" title="Abstract">arXiv:2403.02744</a> [<a href="/pdf/2403.02744" title="Download PDF">pdf</a>, <a href="/format/2403.02744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-adaptive Traffic Anomaly Detection System for IoT Smart Home  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+N">Naoto Watanabe</a> (1), 
<a href="/search/cs?searchtype=author&query=Yamazaki%2C+T">Taku Yamazaki</a> (1), 
<a href="/search/cs?searchtype=author&query=Miyoshi%2C+T">Takumi Miyoshi</a> (1), 
<a href="/search/cs?searchtype=author&query=Yamamoto%2C+R">Ryo Yamamoto</a> (2), 
<a href="/search/cs?searchtype=author&query=Nakahara%2C+M">Masataka Nakahara</a> (3), 
<a href="/search/cs?searchtype=author&query=Okui%2C+N">Norihiro Okui</a> (3), 
<a href="/search/cs?searchtype=author&query=Kubota%2C+A">Ayumu Kubota</a> (3) ((1) Shibaura Institute of Technology, (2) The University of Electro-Communications, (3) KDDI Research, Inc.)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 43 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">With the growth of internet of things (IoT) devices, cyberattacks, such as
distributed denial of service, that exploit vulnerable devices infected with
malware have increased. Therefore, vendors and users must keep their device
firmware updated to eliminate vulnerabilities and quickly handle unknown
cyberattacks. However, it is difficult for both vendors and users to
continually keep the devices safe because vendors must provide updates quickly
and the users must continuously manage the conditions of all deployed devices.
Therefore, to ensure security, it is necessary for a system to adapt
autonomously to changes in cyberattacks. In addition, it is important to
consider network-side security that detects and filters anomalous traffic at
the gateway to comprehensively protect those devices. This paper proposes a
self-adaptive anomaly detection system for IoT traffic, including unknown
attacks. The proposed system comprises a honeypot server and a gateway. The
honeypot server continuously captures traffic and adaptively generates an
anomaly detection model using real-time captured traffic. Thereafter, the
gateway uses the generated model to detect anomalous traffic. Thus, the
proposed system can adapt to unknown attacks to reflect pattern changes in
anomalous traffic based on real-time captured traffic. Three experiments were
conducted to evaluate the proposed system: a virtual experiment using
pre-captured traffic from various regions across the world, a demonstration
experiment using real-time captured traffic, and a virtual experiment using a
public dataset containing the traffic generated by malware. The experimental
results indicate that a system adaptable in real time to evolving cyberattacks
is a novel approach for ensuring the comprehensive security of IoT devices
against both known and unknown attacks.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02745" title="Abstract">arXiv:2403.02745</a> [<a href="/pdf/2403.02745" title="Download PDF">pdf</a>, <a href="/format/2403.02745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CURATRON: Complete Robust Preference Data for Robust Alignment of Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+S+T">Son The Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Naresh%2C+N+U">Niranjan Uma Naresh</a>, 
<a href="/search/cs?searchtype=author&query=Tulabandhula%2C+T">Theja Tulabandhula</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">This paper addresses the challenges of aligning large language models (LLMs)
with human values via preference learning (PL), with a focus on the issues of
incomplete and corrupted data in preference datasets. We propose a novel method
for robustly and completely recalibrating values within these datasets to
enhance LLMs resilience against the issues. In particular, we devise a
guaranteed polynomial time ranking algorithm that robustifies several existing
models, such as the classic Bradley--Terry--Luce (BTL) (Bradley and Terry,
1952) model and certain generalizations of it. To the best of our knowledge,
our present work is the first to propose an algorithm that provably recovers an
{\epsilon}-optimal ranking with high probability while allowing as large as
O(n) perturbed pairwise comparison results per model response. Furthermore, we
show robust recovery results in the partially observed setting. Our experiments
confirm that our algorithms handle adversarial noise and unobserved comparisons
well in both general and LLM preference dataset settings. This work contributes
to the development and scaling of more reliable and ethically aligned AI models
by equipping the dataset curation pipeline with the ability to handle missing
and maliciously manipulated inputs.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02746" title="Abstract">arXiv:2403.02746</a> [<a href="/pdf/2403.02746" title="Download PDF">pdf</a>, <a href="/format/2403.02746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning without Exact Guidance: Updating Large-scale High-resolution  Land Cover Maps from Low-resolution Historical Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuohong Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wei He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiepan Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+F">Fangxiao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 9 figures, conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large-scale high-resolution (HR) land-cover mapping is a vital task to survey
the Earth's surface and resolve many challenges facing humanity. However, it is
still a non-trivial task hindered by complex ground details, various landforms,
and the scarcity of accurate training labels over a wide-span geographic area.
In this paper, we propose an efficient, weakly supervised framework
(Paraformer), a.k.a. Low-to-High Network (L2HNet) V2, to guide large-scale HR
land-cover mapping with easy-access historical land-cover data of low
resolution (LR). Specifically, existing land-cover mapping approaches reveal
the dominance of CNNs in preserving local ground details but still suffer from
insufficient global modeling in various landforms. Therefore, we design a
parallel CNN-Transformer feature extractor in Paraformer, consisting of a
downsampling-free CNN branch and a Transformer branch, to jointly capture local
and global contextual information. Besides, facing the spatial mismatch of
training data, a pseudo-label-assisted training (PLAT) module is adopted to
reasonably refine LR labels for weakly supervised semantic segmentation of HR
images. Experiments on two large-scale datasets demonstrate the superiority of
Paraformer over other state-of-the-art methods for automatically updating HR
land-cover maps from LR historical labels.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02751" title="Abstract">arXiv:2403.02751</a> [<a href="/pdf/2403.02751" title="Download PDF">pdf</a>, <a href="/format/2403.02751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Splat-Nav: Safe Real-Time Robot Navigation in Gaussian Splatting Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Timothy Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shorinwa%2C+O">Ola Shorinwa</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Weijia Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Bruno%2C+J">Joseph Bruno</a>, 
<a href="/search/cs?searchtype=author&query=Dames%2C+P">Philip Dames</a>, 
<a href="/search/cs?searchtype=author&query=Schwager%2C+M">Mac Schwager</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present Splat-Nav, a navigation pipeline that consists of a real-time safe
planning module and a robust state estimation module designed to operate in the
Gaussian Splatting (GSplat) environment representation, a popular emerging 3D
scene representation from computer vision. We formulate rigorous collision
constraints that can be computed quickly to build a guaranteed-safe polytope
corridor through the map. We then optimize a B-spline trajectory through this
corridor. We also develop a real-time, robust state estimation module by
interpreting the GSplat representation as a point cloud. The module enables the
robot to localize its global pose with zero prior knowledge from RGB-D images
using point cloud alignment, and then track its own pose as it moves through
the scene from RGB images using image-to-point cloud localization. We also
incorporate semantics into the GSplat in order to obtain better images for
localization. All of these modules operate mainly on CPU, freeing up GPU
resources for tasks like real-time scene reconstruction. We demonstrate the
safety and robustness of our pipeline in both simulation and hardware, where we
show re-planning at 5 Hz and pose estimation at 20 Hz, an order of magnitude
faster than Neural Radiance Field (NeRF)-based navigation methods, thereby
enabling real-time navigation.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02752" title="Abstract">arXiv:2403.02752</a> [<a href="/pdf/2403.02752" title="Download PDF">pdf</a>, <a href="/format/2403.02752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HINTs: Sensemaking on large collections of documents with Hypergraph  visualization and INTelligent agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S+Y">Sam Yu-Te Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kwan-Liu Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Sensemaking on a large collection of documents (corpus) is a challenging task
often found in fields such as market research, legal studies, intelligence
analysis, political science, computational linguistics, etc. Previous works
approach this problem either from a topic- or entity-based perspective, but
they lack interpretability and trust due to poor model alignment. In this
paper, we present HINTs, a visual analytics approach that combines topic- and
entity-based techniques seamlessly and integrates Large Language Models (LLMs)
as both a general NLP task solver and an intelligent agent. By leveraging the
extraction capability of LLMs in the data preparation stage, we model the
corpus as a hypergraph that matches the user's mental model when making sense
of the corpus. The constructed hypergraph is hierarchically organized with an
agglomerative clustering algorithm by combining semantic and connectivity
similarity. The system further integrates an LLM-based intelligent chatbot
agent in the interface to facilitate sensemaking. To demonstrate the
generalizability and effectiveness of the HINTs system, we present two case
studies on different domains and a comparative user study. We report our
insights on the behavior patterns and challenges when intelligent agents are
used to facilitate sensemaking. We find that while intelligent agents can
address many challenges in sensemaking, the visual hints that visualizations
provide are necessary to address the new problems brought by intelligent
agents. We discuss limitations and future work for combining interactive
visualization and LLMs more profoundly to better support corpus analysis.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02753" title="Abstract">arXiv:2403.02753</a> [<a href="/pdf/2403.02753" title="Download PDF">pdf</a>, <a href="/format/2403.02753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Group Activity Features Through Person Attribute Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nakatani%2C+C">Chihiro Nakatani</a>, 
<a href="/search/cs?searchtype=author&query=Kawashima%2C+H">Hiroaki Kawashima</a>, 
<a href="/search/cs?searchtype=author&query=Ukita%2C+N">Norimichi Ukita</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper proposes Group Activity Feature (GAF) learning in which features
of multi-person activity are learned as a compact latent vector. Unlike prior
work in which the manual annotation of group activities is required for
supervised learning, our method learns the GAF through person attribute
prediction without group activity annotations. By learning the whole network in
an end-to-end manner so that the GAF is required for predicting the person
attributes of people in a group, the GAF is trained as the features of
multi-person activity. As a person attribute, we propose to use a person's
action class and appearance features because the former is easy to annotate due
to its simpleness, and the latter requires no manual annotation. In addition,
we introduce a location-guided attribute prediction to disentangle the complex
GAF for extracting the features of each target person properly. Various
experimental results validate that our method outperforms SOTA methods
quantitatively and qualitatively on two public datasets. Visualization of our
GAF also demonstrates that our method learns the GAF representing fined-grained
group activity classes. Code: https://github.com/chihina/GAFL-CVPR2024.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02754" title="Abstract">arXiv:2403.02754</a> [<a href="/pdf/2403.02754" title="Download PDF">pdf</a>, <a href="/format/2403.02754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Ask Critical Questions for Assisting Product Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zixuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+L">Lizi Liao</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGIR eCom'22
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Product search plays an essential role in eCommerce. It was treated as a
special type of information retrieval problem. Most existing works make use of
historical data to improve the search performance, which do not take the
opportunity to ask for user's current interest directly. Some session-aware
methods take the user's clicks within the session as implicit feedback, but it
is still just a guess on user's preference. To address this problem, recent
conversational or question-based search models interact with users directly for
understanding the user's interest explicitly. However, most users do not have a
clear picture on what to buy at the initial stage. Asking critical attributes
that the user is looking for after they explored for a while should be a more
efficient way to help them searching for the target items. In this paper, we
propose a dual-learning model that hybrids the best from both implicit session
feedback and proactively clarifying with users on the most critical questions.
We first establish a novel utility score to measure whether a clicked item
provides useful information for finding the target. Then we develop the dual
Selection Net and Ranking Net for choosing the critical questions and ranking
the items. It innovatively links traditional click-stream data and text-based
questions together. To verify our proposal, we did extensive experiments on a
public dataset, and our model largely outperformed other state-of-the-art
methods.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02756" title="Abstract">arXiv:2403.02756</a> [<a href="/pdf/2403.02756" title="Download PDF">pdf</a>, <a href="/format/2403.02756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Role Prompting Guided Domain Adaptation with General Capability Preserve  for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+F">Fei Mi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+B">Boyang Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongru Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kam-Fai Wong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruifeng Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The growing interest in Large Language Models (LLMs) for specialized
applications has revealed a significant challenge: when tailored to specific
domains, LLMs tend to experience catastrophic forgetting, compromising their
general capabilities and leading to a suboptimal user experience. Additionally,
crafting a versatile model for multiple domains simultaneously often results in
a decline in overall performance due to confusion between domains. In response
to these issues, we present the RolE Prompting Guided Multi-Domain Adaptation
(REGA) strategy. This novel approach effectively manages multi-domain LLM
adaptation through three key components: 1) Self-Distillation constructs and
replays general-domain exemplars to alleviate catastrophic forgetting. 2) Role
Prompting assigns a central prompt to the general domain and a unique role
prompt to each specific domain to minimize inter-domain confusion during
training. 3) Role Integration reuses and integrates a small portion of
domain-specific data to the general-domain data, which are trained under the
guidance of the central prompt. The central prompt is used for a streamlined
inference process, removing the necessity to switch prompts for different
domains. Empirical results demonstrate that REGA effectively alleviates
catastrophic forgetting and inter-domain confusion. This leads to improved
domain-specific performance compared to standard fine-tuned models, while still
preserving robust general capabilities.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02757" title="Abstract">arXiv:2403.02757</a> [<a href="/pdf/2403.02757" title="Download PDF">pdf</a>, <a href="/format/2403.02757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Memory Learning: A Declarative Learning Framework for Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Tianxiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siyin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Q">Qingyuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The exploration of whether agents can align with their environment without
relying on human-labeled data presents an intriguing research topic. Drawing
inspiration from the alignment process observed in intelligent organisms, where
declarative memory plays a pivotal role in summarizing past experiences, we
propose a novel learning framework. The agents adeptly distill insights from
past experiences, refining and updating existing notes to enhance their
performance in the environment. This entire process transpires within the
memory components and is implemented through natural language, so we character
this framework as In-memory Learning. We also delve into the key features of
benchmarks designed to evaluate the self-improvement process. Through
systematic experiments, we demonstrate the effectiveness of our framework and
provide insights into this problem.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02760" title="Abstract">arXiv:2403.02760</a> [<a href="/pdf/2403.02760" title="Download PDF">pdf</a>, <a href="/ps/2403.02760" title="Download PostScript">ps</a>, <a href="/format/2403.02760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emerging Synergies Between Large Language Models and Machine Learning in  Ecommerce Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaonan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+Z">Zhipeng Ling</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhengyu Jin</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S">ShuQian Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">With the boom of e-commerce and web applications, recommender systems have
become an important part of our daily lives, providing personalized
recommendations based on the user's preferences. Although deep neural networks
(DNNs) have made significant progress in improving recommendation systems by
simulating the interaction between users and items and incorporating their
textual information, these DNN-based approaches still have some limitations,
such as the difficulty of effectively understanding users' interests and
capturing textual information. It is not possible to generalize to different
seen/unseen recommendation scenarios and reason about their predictions. At the
same time, the emergence of large language models (LLMs), represented by
ChatGPT and GPT-4, has revolutionized the fields of natural language processing
(NLP) and artificial intelligence (AI) due to their superior capabilities in
the basic tasks of language understanding and generation, and their impressive
generalization and reasoning capabilities. As a result, recent research has
sought to harness the power of LLM to improve recommendation systems. Given the
rapid development of this research direction in the field of recommendation
systems, there is an urgent need for a systematic review of existing LLM-driven
recommendation systems for researchers and practitioners in related fields to
gain insight into. More specifically, we first introduced a representative
approach to learning user and item representations using LLM as a feature
encoder. We then reviewed the latest advances in LLMs techniques for
collaborative filtering enhanced recommendation systems from the three
paradigms of pre-training, fine-tuning, and prompting. Finally, we had a
comprehensive discussion on the future direction of this emerging field.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02765" title="Abstract">arXiv:2403.02765</a> [<a href="/pdf/2403.02765" title="Download PDF">pdf</a>, <a href="/format/2403.02765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> G4-Attention: Deep Learning Model with Attention for predicting DNA  G-Quadruplexes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+S">Shrimon Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Pramanik%2C+P">Pulakesh Pramanik</a>, 
<a href="/search/cs?searchtype=author&query=Basuchowdhuri%2C+P">Partha Basuchowdhuri</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+S">Santanu Bhattacharya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
<p class="mathjax">G-Quadruplexes are the four-stranded non-canonical nucleic acid secondary
structures, formed by the stacking arrangement of the guanine tetramers. They
are involved in a wide range of biological roles because of their exceptionally
unique and distinct structural characteristics. After the completion of the
human genome sequencing project, a lot of bioinformatic algorithms were
introduced to predict the active G4s regions \textit{in vitro} based on the
canonical G4 sequence elements, G-\textit{richness}, and G-\textit{skewness},
as well as the non-canonical sequence features. Recently, sequencing techniques
like G4-seq and G4-ChIP-seq were developed to map the G4s \textit{in vitro},
and \textit{in vivo} respectively at a few hundred base resolution.
Subsequently, several machine learning approaches were developed for predicting
the G4 regions using the existing databases. However, their prediction models
were simplistic, and the prediction accuracy was notably poor. In response,
here, we propose a novel convolutional neural network with Bi-LSTM and
attention layers, named G4-attention, to predict the G4 forming sequences with
improved accuracy. G4-attention achieves high accuracy and attains
state-of-the-art results in the G4 prediction task. Our model also predicts the
G4 regions accurately in the highly class-imbalanced datasets. In addition, the
developed model trained on the human genome dataset can be applied to any
non-human genome DNA sequences to predict the G4 formation propensities.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02767" title="Abstract">arXiv:2403.02767</a> [<a href="/pdf/2403.02767" title="Download PDF">pdf</a>, <a href="/format/2403.02767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeconfuseTrack:Dealing with Confusion for Multi-Object Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Cheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shoudong Han</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+M">Mengyu He</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wenbo Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yuhao Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurate data association is crucial in reducing confusion, such as ID
switches and assignment errors, in multi-object tracking (MOT). However,
existing advanced methods often overlook the diversity among trajectories and
the ambiguity and conflicts present in motion and appearance cues, leading to
confusion among detections, trajectories, and associations when performing
simple global data association. To address this issue, we propose a simple,
versatile, and highly interpretable data association approach called Decomposed
Data Association (DDA). DDA decomposes the traditional association problem into
multiple sub-problems using a series of non-learning-based modules and
selectively addresses the confusion in each sub-problem by incorporating
targeted exploitation of new cues. Additionally, we introduce Occlusion-aware
Non-Maximum Suppression (ONMS) to retain more occluded detections, thereby
increasing opportunities for association with trajectories and indirectly
reducing the confusion caused by missed detections. Finally, based on DDA and
ONMS, we design a powerful multi-object tracker named DeconfuseTrack,
specifically focused on resolving confusion in MOT. Extensive experiments
conducted on the MOT17 and MOT20 datasets demonstrate that our proposed DDA and
ONMS significantly enhance the performance of several popular trackers.
Moreover, DeconfuseTrack achieves state-of-the-art performance on the MOT17 and
MOT20 test sets, significantly outperforms the baseline tracker ByteTrack in
metrics such as HOTA, IDF1, AssA. This validates that our tracking design
effectively reduces confusion caused by simple global association.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02768" title="Abstract">arXiv:2403.02768</a> [<a href="/pdf/2403.02768" title="Download PDF">pdf</a>, <a href="/format/2403.02768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Analysis on the Use and Reporting of National Security  Letters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bellon%2C+A">Alex Bellon</a>, 
<a href="/search/cs?searchtype=author&query=Haller%2C+M">Miro Haller</a>, 
<a href="/search/cs?searchtype=author&query=Labunets%2C+A">Andrey Labunets</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+E">Enze Liu</a>, 
<a href="/search/cs?searchtype=author&query=Savage%2C+S">Stefan Savage</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as short presentation at CSLAW 2024 (not in proceeding): <a href="https://computersciencelaw.org/2024/accepted-papers/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">National Security Letters (NSLs) are similar to administrative subpoenas and
can be issued directly by elements of the executive branch without requiring
prior approval from a court or grand jury. Importantly, NSLs authorize the
imposition of nondisclosure orders (aka "gag orders") on the receiving party.
Controversy about potential abuses of this authority has driven a range of
legal and policy discussions. To address these concerns, both the public sector
and the private sector have sought to document the usage of NSLs in aggregated
form. However, each data source is limited in scope, time, and kind.
<br />In this paper, we consolidate the available data around NSLs and answer two
questions: (1) what can the public effectively learn from the reported data and
does this information suffice to assess the NSL usage? (2) how accessible is
this data collection? We show that longitudinal trends in the usage of NSLs can
be observed. For instance, we find a significant increase in NSL requests for
non-US persons and that the policy reforms to decrease the mandated
nondisclosure period appear to be effective. The observed trends suggest that
the current transparency mechanisms are viable safeguards against the excessive
use of NSLs. However, aggregating and normalizing the data requires manual
reviewing, parsing, and validating. We even find inconsistencies within and
across official data sources. Overall, the laborious data collection process
hinders external and internal auditing efforts and demonstrates the need for a
unified and more usable dataset for NSLs.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02769" title="Abstract">arXiv:2403.02769</a> [<a href="/pdf/2403.02769" title="Download PDF">pdf</a>, <a href="/format/2403.02769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HUNTER: Unsupervised Human-centric 3D Detection via Transferring  Knowledge from Synthetic Instances to Real Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yichen Yao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zimo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yujing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhencai Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinge Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Runnan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yuexin Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human-centric 3D scene understanding has recently drawn increasing attention,
driven by its critical impact on robotics. However, human-centric real-life
scenarios are extremely diverse and complicated, and humans have intricate
motions and interactions. With limited labeled data, supervised methods are
difficult to generalize to general scenarios, hindering real-life applications.
Mimicking human intelligence, we propose an unsupervised 3D detection method
for human-centric scenarios by transferring the knowledge from synthetic human
instances to real scenes. To bridge the gap between the distinct data
representations and feature distributions of synthetic models and real point
clouds, we introduce novel modules for effective instance-to-scene
representation transfer and synthetic-to-real feature alignment. Remarkably,
our method exhibits superior performance compared to current state-of-the-art
techniques, achieving a substantial 87.8\% improvement in mAP and closely
approaching the performance of fully supervised methods (62.15 mAP vs. 69.02
mAP) on HuCenLife.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02772" title="Abstract">arXiv:2403.02772</a> [<a href="/pdf/2403.02772" title="Download PDF">pdf</a>, <a href="/format/2403.02772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rehabilitation Exercise Quality Assessment through Supervised  Contrastive Learning with Hard and Soft Negatives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karlov%2C+M">Mark Karlov</a>, 
<a href="/search/cs?searchtype=author&query=Abedi%2C+A">Ali Abedi</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S+S">Shehroz S. Khan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY)

</div>
<p class="mathjax">Exercise-based rehabilitation programs have proven to be effective in
enhancing the quality of life and reducing mortality and rehospitalization
rates. AI-driven virtual rehabilitation, which allows patients to independently
complete exercises at home, utilizes AI algorithms to analyze exercise data,
providing feedback to patients and updating clinicians on their progress. These
programs commonly prescribe a variety of exercise types, leading to a distinct
challenge in rehabilitation exercise assessment datasets: while abundant in
overall training samples, these datasets often have a limited number of samples
for each individual exercise type. This disparity hampers the ability of
existing approaches to train generalizable models with such a small sample size
per exercise. Addressing this issue, our paper introduces a novel supervised
contrastive learning framework with hard and soft negative samples that
effectively utilizes the entire dataset to train a single model applicable to
all exercise types. This model, with a Spatial-Temporal Graph Convolutional
Network (ST-GCN) architecture, demonstrated enhanced generalizability across
exercises and a decrease in overall complexity. Through extensive experiments
on three publicly available rehabilitation exercise assessment datasets, the
University of Idaho-Physical Rehabilitation Movement Data (UI-PRMD),
IntelliRehabDS (IRDS), and KInematic assessment of MOvement and clinical scores
for remote monitoring of physical REhabilitation (KIMORE), our method has shown
to surpass existing methods, setting a new benchmark in rehabilitation exercise
assessment accuracy.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02773" title="Abstract">arXiv:2403.02773</a> [<a href="/pdf/2403.02773" title="Download PDF">pdf</a>, <a href="/format/2403.02773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LodeStar: Maritime Radar Descriptor for Semi-Direct Radar Odometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jang%2C+H">Hyesu Jang</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+M">Minwoo Jung</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+M">Myung-Hwan Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+A">Ayoung Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Robotics and Automation Letter
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letter, 9-2 (2024) 1684-1691
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Maritime radars are prevalently adopted to capture the vessel's
omnidirectional data as imagery. Nevertheless, inherent challenges persist with
marine radars, including limited frequency, suboptimal resolution, and
indeterminate detections. Additionally, the scarcity of discernible landmarks
in the vast marine expanses remains a challenge, resulting in consecutive
scenes that often lack matching feature points. In this context, we introduce a
resilient maritime radar scan representation LodeStar, and an enhanced feature
extraction technique tailored for marine radar applications. Moreover, we
embark on estimating marine radar odometry utilizing a semi-direct approach.
LodeStar-based approach markedly attenuates the errors in odometry estimation,
and our assertion is corroborated through meticulous experimental validation.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02775" title="Abstract">arXiv:2403.02775</a> [<a href="/pdf/2403.02775" title="Download PDF">pdf</a>, <a href="/format/2403.02775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EasyQuant: An Efficient Data-free Quantization Algorithm for LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hanlin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yifu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Decheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jianchen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Z">Zhanhui Kang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) have proven to be very superior to conventional
methods in various tasks. However, their expensive computations and high memory
requirements are prohibitive for deployment. Model quantization is an effective
method for reducing this overhead. The problem is that in most previous works,
the quantized model was calibrated using few samples from the training data,
which might affect the generalization of the quantized LLMs to unknown cases
and tasks. Hence in this work, we explore an important question: Can we design
a data-independent quantization method for LLMs to guarantee its generalization
performance? In this work, we propose EasyQuant, a training-free and
data-independent weight-only quantization algorithm for LLMs. Our observation
indicates that two factors: outliers in the weight and quantization ranges, are
essential for reducing the quantization error. Therefore, in EasyQuant, we
leave the outliers (less than 1%) unchanged and optimize the quantization range
to reduce the reconstruction error. With these methods, we surprisingly find
that EasyQuant achieves comparable performance to the original model. Since
EasyQuant does not depend on any training data, the generalization performance
of quantized LLMs is safely guaranteed. Moreover, EasyQuant can be implemented
in parallel so that the quantized model could be attained in a few minutes even
for LLMs over 100B. To our best knowledge, we are the first work that achieves
almost lossless quantization performance for LLMs under a data-independent
setting and our algorithm runs over 10 times faster than the data-dependent
methods.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02777" title="Abstract">arXiv:2403.02777</a> [<a href="/pdf/2403.02777" title="Download PDF">pdf</a>, <a href="/format/2403.02777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Zero-Shot Reinforcement Learning Strategy for Autonomous Guidewire  Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scarponi%2C+V">Valentina Scarponi</a> (MIMESIS, ICube), 
<a href="/search/cs?searchtype=author&query=Duprez%2C+M">Michel Duprez</a> (ICube, MIMESIS), 
<a href="/search/cs?searchtype=author&query=Nageotte%2C+F">Florent Nageotte</a> (ICube), 
<a href="/search/cs?searchtype=author&query=Cotin%2C+S">St&#xe9;phane Cotin</a> (ICube, MIMESIS)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Journal of Computer Assisted Radiology and Surgery, In press
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Purpose: The treatment of cardiovascular diseases requires complex and
challenging navigation of a guidewire and catheter. This often leads to lengthy
interventions during which the patient and clinician are exposed to X-ray
radiation. Deep Reinforcement Learning approaches have shown promise in
learning this task and may be the key to automating catheter navigation during
robotized interventions. Yet, existing training methods show limited
capabilities at generalizing to unseen vascular anatomies, requiring to be
retrained each time the geometry changes. Methods: In this paper, we propose a
zero-shot learning strategy for three-dimensional autonomous endovascular
navigation. Using a very small training set of branching patterns, our
reinforcement learning algorithm is able to learn a control that can then be
applied to unseen vascular anatomies without retraining. Results: We
demonstrate our method on 4 different vascular systems, with an average success
rate of 95% at reaching random targets on these anatomies. Our strategy is also
computationally efficient, allowing the training of our controller to be
performed in only 2 hours. Conclusion: Our training method proved its ability
to navigate unseen geometries with different characteristics, thanks to a
nearly shape-invariant observation space.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02778" title="Abstract">arXiv:2403.02778</a> [<a href="/pdf/2403.02778" title="Download PDF">pdf</a>, <a href="/format/2403.02778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Abstracting Denotational Interpreters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Graf%2C+S">Sebastian Graf</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+S+P">Simon Peyton Jones</a>, 
<a href="/search/cs?searchtype=author&query=Keidel%2C+S">Sven Keidel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint; submitted to ICFP'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">We explore denotational interpreters: denotational semantics that produce
coinductive traces of a corresponding small-step operational semantics. By
parameterising our denotational interpreter over the semantic domain and then
varying it, we recover dynamic semantics with different evaluation strategies
as well as summary-based static analyses such as type analysis, all from the
same generic interpreter. Among our contributions is the first provably
adequate denotational semantics for call-by-need. The generated traces lend
themselves well to describe operational properties such as evaluation
cardinality, and hence to static analyses abstracting these operational
properties. Since static analysis and dynamic semantics share the same generic
interpreter definition, soundness proofs via abstract interpretation decompose
into showing small abstraction laws about the abstract domain, thus obviating
complicated ad-hoc preservation-style proof frameworks.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02780" title="Abstract">arXiv:2403.02780</a> [<a href="/pdf/2403.02780" title="Download PDF">pdf</a>, <a href="/ps/2403.02780" title="Download PostScript">ps</a>, <a href="/format/2403.02780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Collaboration Analysis Over Matrix Manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nosaka%2C+K">Keiyu Nosaka</a>, 
<a href="/search/cs?searchtype=author&query=Yoshise%2C+A">Akiko Yoshise</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">The effectiveness of machine learning (ML) algorithms is deeply intertwined
with the quality and diversity of their training datasets. Improved datasets,
marked by superior quality, enhance the predictive accuracy and broaden the
applicability of models across varied scenarios. Researchers often integrate
data from multiple sources to mitigate biases and limitations of single-source
datasets. However, this extensive data amalgamation raises significant ethical
concerns, particularly regarding user privacy and the risk of unauthorized data
disclosure. Various global legislative frameworks have been established to
address these privacy issues. While crucial for safeguarding privacy, these
regulations can complicate the practical deployment of ML technologies.
Privacy-Preserving Machine Learning (PPML) addresses this challenge by
safeguarding sensitive information, from health records to geolocation data,
while enabling the secure use of this data in developing robust ML models.
Within this realm, the Non-Readily Identifiable Data Collaboration (NRI-DC)
framework emerges as an innovative approach, potentially resolving the 'data
island' issue among institutions through non-iterative communication and robust
privacy protections. However, in its current state, the NRI-DC framework faces
model performance instability due to theoretical unsteadiness in creating
collaboration functions. This study establishes a rigorous theoretical
foundation for these collaboration functions and introduces new formulations
through optimization problems on matrix manifolds and efficient solutions.
Empirical analyses demonstrate that the proposed approach, particularly the
formulation over orthogonal matrix manifolds, significantly enhances
performance, maintaining consistency and efficiency without compromising
communication efficiency or privacy protections.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02781" title="Abstract">arXiv:2403.02781</a> [<a href="/pdf/2403.02781" title="Download PDF">pdf</a>, <a href="/format/2403.02781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PromptKD: Unsupervised Prompt Distillation for Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xinyi Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024. Project Page: <a href="https://zhengli97.github.io/PromptKD/.">this https URL</a> Code: <a href="https://github.com/zhengli97/PromptKD">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Prompt learning has emerged as a valuable technique in enhancing
vision-language models (VLMs) such as CLIP for downstream tasks in specific
domains. Existing work mainly focuses on designing various learning forms of
prompts, neglecting the potential of prompts as effective distillers for
learning from larger teacher models. In this paper, we introduce an
unsupervised domain prompt distillation framework, which aims to transfer the
knowledge of a larger teacher model to a lightweight target model through
prompt-driven imitation using unlabeled domain images. Specifically, our
framework consists of two distinct stages. In the initial stage, we pre-train a
large CLIP teacher model using domain (few-shot) labels. After pre-training, we
leverage the unique decoupled-modality characteristics of CLIP by pre-computing
and storing the text features as class vectors only once through the teacher
text encoder. In the subsequent stage, the stored class vectors are shared
across teacher and student image encoders for calculating the predicted logits.
Further, we align the logits of both the teacher and student models via KL
divergence, encouraging the student image encoder to generate similar
probability distributions to the teacher through the learnable prompts. The
proposed prompt distillation process eliminates the reliance on labeled data,
enabling the algorithm to leverage a vast amount of unlabeled images within the
domain. Finally, the well-trained student image encoders and pre-stored text
features (class vectors) are utilized for inference. To our best knowledge, we
are the first to (1) perform unsupervised domain-specific prompt-driven
knowledge distillation for CLIP, and (2) establish a practical pre-storing
mechanism of text features as shared class vectors between teacher and student.
Extensive experiments on 11 datasets demonstrate the effectiveness of our
method.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02782" title="Abstract">arXiv:2403.02782</a> [<a href="/pdf/2403.02782" title="Download PDF">pdf</a>, <a href="/format/2403.02782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why Not Use Your Textbook? Knowledge-Enhanced Procedure Planning of  Instructional Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nagasinghe%2C+K+R+Y">Kumaranage Ravindu Yasas Nagasinghe</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Honglu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gunawardhana%2C+M">Malitha Gunawardhana</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+M+R">Martin Renqiang Min</a>, 
<a href="/search/cs?searchtype=author&query=Harari%2C+D">Daniel Harari</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+H">Muhammad Haris Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, (supplementary material: 8 pages, 5 figures), accepted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we explore the capability of an agent to construct a logical
sequence of action steps, thereby assembling a strategic procedural plan. This
plan is crucial for navigating from an initial visual observation to a target
visual outcome, as depicted in real-life instructional videos. Existing works
have attained partial success by extensively leveraging various sources of
information available in the datasets, such as heavy intermediate visual
observations, procedural names, or natural language step-by-step instructions,
for features or supervision signals. However, the task remains formidable due
to the implicit causal constraints in the sequencing of steps and the
variability inherent in multiple feasible plans. To tackle these intricacies
that previous efforts have overlooked, we propose to enhance the capabilities
of the agent by infusing it with procedural knowledge. This knowledge, sourced
from training procedure plans and structured as a directed weighted graph,
equips the agent to better navigate the complexities of step sequencing and its
potential variations. We coin our approach KEPP, a novel Knowledge-Enhanced
Procedure Planning system, which harnesses a probabilistic procedural knowledge
graph extracted from training data, effectively acting as a comprehensive
textbook for the training domain. Experimental evaluations across three
widely-used datasets under settings of varying complexity reveal that KEPP
attains superior, state-of-the-art results while requiring only minimal
supervision.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02783" title="Abstract">arXiv:2403.02783</a> [<a href="/pdf/2403.02783" title="Download PDF">pdf</a>, <a href="/format/2403.02783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Where the Really Hard Quadratic Assignment Problems Are: the QAP-SAT  instances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verel%2C+S">S&#xe9;bastien Verel</a> (LISIC), 
<a href="/search/cs?searchtype=author&query=Thomson%2C+S">Sarah Thomson</a>, 
<a href="/search/cs?searchtype=author&query=Rifki%2C+O">Omar Rifki</a> (LISIC)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Evolutionary Computation in Combinatorial Optimization Conference
  (evoCOP), Apr 2024, Aberystwyth, United Kingdom
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The Quadratic Assignment Problem (QAP) is one of the major domains in the
field of evolutionary computation, and more widely in combinatorial
optimization. This paper studies the phase transition of the QAP, which can be
described as a dramatic change in the problem's computational complexity and
satisfiability, within a narrow range of the problem parameters. To approach
this phenomenon, we introduce a new QAP-SAT design of the initial problem based
on submodularity to capture its difficulty with new features. This
decomposition is studied experimentally using branch-and-bound and tabu search
solvers. A phase transition parameter is then proposed. The critical parameter
of phase transition satisfaction and that of the solving effort are shown to be
highly correlated for tabu search, thus allowing the prediction of difficult
instances.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02784" title="Abstract">arXiv:2403.02784</a> [<a href="/pdf/2403.02784" title="Download PDF">pdf</a>, <a href="/format/2403.02784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DDF: A Novel Dual-Domain Image Fusion Strategy for Remote Sensing Image  Semantic Segmentation with Unsupervised Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ran%2C+L">Lingyan Ran</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lushuang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+T">Tao Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Y">Yinghui Xing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semantic segmentation of remote sensing images is a challenging and hot issue
due to the large amount of unlabeled data. Unsupervised domain adaptation (UDA)
has proven to be advantageous in incorporating unclassified information from
the target domain. However, independently fine-tuning UDA models on the source
and target domains has a limited effect on the outcome. This paper proposes a
hybrid training strategy as well as a novel dual-domain image fusion strategy
that effectively utilizes the original image, transformation image, and
intermediate domain information. Moreover, to enhance the precision of
pseudo-labels, we present a pseudo-label region-specific weight strategy. The
efficacy of our approach is substantiated by extensive benchmark experiments
and ablation studies conducted on the ISPRS Vaihingen and Potsdam datasets.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02785" title="Abstract">arXiv:2403.02785</a> [<a href="/pdf/2403.02785" title="Download PDF">pdf</a>, <a href="/format/2403.02785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Fully-discrete Semi-Lagrangian scheme for a price formation MFG model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ashrafyan%2C+Y">Yuri Ashrafyan</a>, 
<a href="/search/math?searchtype=author&query=Gomes%2C+D">Diogo Gomes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 4 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Here, we examine a fully-discrete Semi-Lagrangian scheme for a mean-field
game price formation model. We show that the discretization is monotone as a
multivalued operator and prove the uniqueness of the discretized solution.
Moreover, we show that the limit of the discretization converges to the weak
solution of the continuous price formation mean-field game using monotonicity
methods. This scheme performs substantially better than standard methods by
giving reliable results within a few iterations, as several numerical
simulations and comparisons at the end of the paper illustrate.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02786" title="Abstract">arXiv:2403.02786</a> [<a href="/pdf/2403.02786" title="Download PDF">pdf</a>, <a href="/format/2403.02786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Supervised Graph Representation Learning with Human-centric  Explanation for Predicting Fatty Liver Disease
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+Y">So Yeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sehee Wang</a>, 
<a href="/search/cs?searchtype=author&query=Choe%2C+E+K">Eun Kyung Choe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted in Human-Centric Representation Learning workshop at AAAI 2024 (<a href="https://hcrl-workshop.github.io/2024/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Addressing the challenge of limited labeled data in clinical settings,
particularly in the prediction of fatty liver disease, this study explores the
potential of graph representation learning within a semi-supervised learning
framework. Leveraging graph neural networks (GNNs), our approach constructs a
subject similarity graph to identify risk patterns from health checkup data.
The effectiveness of various GNN approaches in this context is demonstrated,
even with minimal labeled samples. Central to our methodology is the inclusion
of human-centric explanations through explainable GNNs, providing personalized
feature importance scores for enhanced interpretability and clinical relevance,
thereby underscoring the potential of our approach in advancing healthcare
practices with a keen focus on graph representation learning and human-centric
explanation.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02794" title="Abstract">arXiv:2403.02794</a> [<a href="/pdf/2403.02794" title="Download PDF">pdf</a>, <a href="/ps/2403.02794" title="Download PostScript">ps</a>, <a href="/format/2403.02794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Distance Metric Learning Model Based On Variational Information  Bottleneck
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">YaoDan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zidong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+R">Ru Jia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ru Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, personalized recommendation technology has flourished and
become one of the hot research directions. The matrix factorization model and
the metric learning model which proposed successively have been widely studied
and applied. The latter uses the Euclidean distance instead of the dot product
used by the former to measure the latent space vector. While avoiding the
shortcomings of the dot product, the assumption of Euclidean distance is
neglected, resulting in limited recommendation quality of the model. In order
to solve this problem, this paper combines the Variationl Information
Bottleneck with metric learning model for the first time, and proposes a new
metric learning model VIB-DML (Variational Information Bottleneck Distance
Metric Learning) for rating prediction, which limits the mutual information of
the latent space feature vector to improve the robustness of the model and
satisfiy the assumption of Euclidean distance by decoupling the latent space
feature vector. In this paper, the experimental results are compared with the
root mean square error (RMSE) on the three public datasets. The results show
that the generalization ability of VIB-DML is excellent. Compared with the
general metric learning model MetricF, the prediction error is reduced by
7.29%. Finally, the paper proves the strong robustness of VIBDML through
experiments.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02795" title="Abstract">arXiv:2403.02795</a> [<a href="/pdf/2403.02795" title="Download PDF">pdf</a>, <a href="/format/2403.02795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating and Optimizing Educational Content with Large Language Model  Judgments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He-Yueya%2C+J">Joy He-Yueya</a>, 
<a href="/search/cs?searchtype=author&query=Goodman%2C+N+D">Noah D. Goodman</a>, 
<a href="/search/cs?searchtype=author&query=Brunskill%2C+E">Emma Brunskill</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Creating effective educational materials generally requires expensive and
time-consuming studies of student learning outcomes. To overcome this barrier,
one idea is to build computational models of student learning and use them to
optimize instructional materials. However, it is difficult to model the
cognitive processes of learning dynamics. We propose an alternative approach
that uses Language Models (LMs) as educational experts to assess the impact of
various instructions on learning outcomes. Specifically, we use GPT-3.5 to
evaluate the overall effect of instructional materials on different student
groups and find that it can replicate well-established educational findings
such as the Expertise Reversal Effect and the Variability Effect. This
demonstrates the potential of LMs as reliable evaluators of educational
content. Building on this insight, we introduce an instruction optimization
approach in which one LM generates instructional materials using the judgments
of another LM as a reward function. We apply this approach to create math word
problem worksheets aimed at maximizing student learning gains. Human teachers'
evaluations of these LM-generated worksheets show a significant alignment
between the LM judgments and human teacher preferences. We conclude by
discussing potential divergences between human and LM opinions and the
resulting pitfalls of automating instructional design.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02799" title="Abstract">arXiv:2403.02799</a> [<a href="/pdf/2403.02799" title="Download PDF">pdf</a>, <a href="/format/2403.02799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DPPA: Pruning Method for Large Language Model to Model Merging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yaochen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+R">Rui Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiajun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Model merging is to combine fine-tuned models derived from multiple domains,
with the intent of enhancing the model's proficiency across various domains.
The principal concern is the resolution of parameter conflicts. A substantial
amount of existing research remedy this issue during the merging stage, with
the latest study focusing on resolving this issue throughout the pruning stage.
The DARE approach has exhibited promising outcomes when applied to a simplistic
fine-tuned model. However, the efficacy of this method tends to wane when
employed on complex fine-tuned models that show a significant parameter bias
relative to the baseline model. In this paper, we introduce a dual-stage method
termed Dynamic Pruning Partition Amplification (DPPA), devised to tackle the
challenge of merging complex fine-tuned models. Initially, we introduce
Dynamically Pruning (DP), an improved approach based on magnitude pruning,
which aim is to enhance performance at higher pruning rates. Subsequently, we
propose Dynamically Partition Amplification (DPA), a rescaling strategy, is
designed to dynamically amplify parameter partitions in relation to their
significance levels. The experimental results show that our method maintains a
mere 20% of domain-specific parameters and yet delivers a performance
comparable to other methodologies that preserve up to 90% of parameters.
Furthermore, our method displays outstanding performance post-pruning, leading
to a significant improvement of nearly 20% performance in model merging. We
make our code on Github.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02803" title="Abstract">arXiv:2403.02803</a> [<a href="/pdf/2403.02803" title="Download PDF">pdf</a>, <a href="/format/2403.02803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Robust Federated Learning via Logits Calibration on Non-IID Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Adhikary%2C+A">Apurba Adhikary</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+C+S">Choong Seon Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE NOMS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Federated learning (FL) is a privacy-preserving distributed management
framework based on collaborative model training of distributed devices in edge
networks. However, recent studies have shown that FL is vulnerable to
adversarial examples (AEs), leading to a significant drop in its performance.
Meanwhile, the non-independent and identically distributed (non-IID) challenge
of data distribution between edge devices can further degrade the performance
of models. Consequently, both AEs and non-IID pose challenges to deploying
robust learning models at the edge. In this work, we adopt the adversarial
training (AT) framework to improve the robustness of FL models against
adversarial example (AE) attacks, which can be termed as federated adversarial
training (FAT). Moreover, we address the non-IID challenge by implementing a
simple yet effective logits calibration strategy under the FAT framework, which
can enhance the robustness of models when subjected to adversarial attacks.
Specifically, we employ a direct strategy to adjust the logits output by
assigning higher weights to classes with small samples during training. This
approach effectively tackles the class imbalance in the training data, with the
goal of mitigating biases between local and global models. Experimental results
on three dataset benchmarks, MNIST, Fashion-MNIST, and CIFAR-10 show that our
strategy achieves competitive results in natural and robust accuracy compared
to several baselines.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02810" title="Abstract">arXiv:2403.02810</a> [<a href="/pdf/2403.02810" title="Download PDF">pdf</a>, <a href="/ps/2403.02810" title="Download PostScript">ps</a>, <a href="/format/2403.02810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Gaussian Graph Operator: Learning parametric partial  differential equations in arbitrary discrete mechanics problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jinhong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+Z">Zhijian Zha</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qi Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The number of figures is 13. The number of tables is 7. The number of words is 9854
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep learning methods have access to be employed for solving physical systems
governed by parametric partial differential equations (PDEs) due to massive
scientific data. It has been refined to operator learning that focuses on
learning non-linear mapping between infinite-dimensional function spaces,
offering interface from observations to solutions. However, state-of-the-art
neural operators are limited to constant and uniform discretization, thereby
leading to deficiency in generalization on arbitrary discretization schemes for
computational domain. In this work, we propose a novel operator learning
algorithm, referred to as Dynamic Gaussian Graph Operator (DGGO) that expands
neural operators to learning parametric PDEs in arbitrary discrete mechanics
problems. The Dynamic Gaussian Graph (DGG) kernel learns to map the observation
vectors defined in general Euclidean space to metric vectors defined in
high-dimensional uniform metric space. The DGG integral kernel is parameterized
by Gaussian kernel weighted Riemann sum approximating and using dynamic message
passing graph to depict the interrelation within the integral term. Fourier
Neural Operator is selected to localize the metric vectors on spatial and
frequency domains. Metric vectors are regarded as located on latent uniform
domain, wherein spatial and spectral transformation offer highly regular
constraints on solution space. The efficiency and robustness of DGGO are
validated by applying it to solve numerical arbitrary discrete mechanics
problems in comparison with mainstream neural operators. Ablation experiments
are implemented to demonstrate the effectiveness of spatial transformation in
the DGG kernel. The proposed method is utilized to forecast stress field of
hyper-elastic material with geometrically variable void as engineering
application.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02814" title="Abstract">arXiv:2403.02814</a> [<a href="/pdf/2403.02814" title="Download PDF">pdf</a>, <a href="/format/2403.02814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InjectTST: A Transformer Method of Injecting Global Information into  Independent Channels for Long Time Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chi%2C+C">Ce Chi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kexin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhiyan Song</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+D">Di Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Chao Deng</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Junlan Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Transformer has become one of the most popular architectures for multivariate
time series (MTS) forecasting. Recent Transformer-based MTS models generally
prefer channel-independent structures with the observation that channel
independence can alleviate noise and distribution drift issues, leading to more
robustness. Nevertheless, it is essential to note that channel dependency
remains an inherent characteristic of MTS, carrying valuable information.
Designing a model that incorporates merits of both channel-independent and
channel-mixing structures is a key to further improvement of MTS forecasting,
which poses a challenging conundrum. To address the problem, an injection
method for global information into channel-independent Transformer, InjectTST,
is proposed in this paper. Instead of designing a channel-mixing model
directly, we retain the channel-independent backbone and gradually inject
global information into individual channels in a selective way. A channel
identifier, a global mixing module and a self-contextual attention module are
devised in InjectTST. The channel identifier can help Transformer distinguish
channels for better representation. The global mixing module produces
cross-channel global information. Through the self-contextual attention module,
the independent channels can selectively concentrate on useful global
information without robustness degradation, and channel mixing is achieved
implicitly. Experiments indicate that InjectTST can achieve stable improvement
compared with state-of-the-art models.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02816" title="Abstract">arXiv:2403.02816</a> [<a href="/pdf/2403.02816" title="Download PDF">pdf</a>, <a href="/format/2403.02816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient simulation of complex Ginzburg--Landau equations using  high-order exponential-type methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Caliari%2C+M">Marco Caliari</a>, 
<a href="/search/math?searchtype=author&query=Cassini%2C+F">Fabio Cassini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we consider the task of efficiently computing the numerical
solution of evolutionary complex Ginzburg--Landau equations. To this aim, we
employ high-order exponential methods of splitting and Lawson type for the time
integration. These schemes enjoy favorable stability properties and, in
particular, do not show restrictions on the time step size due to the
underlying stiffness of the models. The needed actions of matrix exponentials
are efficiently realized with pointwise operations in Fourier space (when the
model is considered with periodic boundary conditions) or by using a
tensor-oriented approach that suitably employs the so-called $\mu$-mode
products (when the semidiscretization in space is performed with finite
differences). The overall effectiveness of the approach is demonstrated by
running simulations on a variety of two- and three-dimensional (systems of)
complex Ginzburg--Landau equations with cubic and cubic-quintic nonlinearities,
which are widely considered in literature to model relevant physical phenomena.
In fact, in all instances high-order exponential-type schemes can outperform
standard techniques to integrate in time the models under consideration, i.e.,
the well-known split-step method and the explicit fourth-order Runge--Kutta
integrator.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02817" title="Abstract">arXiv:2403.02817</a> [<a href="/pdf/2403.02817" title="Download PDF">pdf</a>, <a href="/format/2403.02817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Here Comes The AI Worm: Unleashing Zero-click Worms that Target  GenAI-Powered Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cohen%2C+S">Stav Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Bitton%2C+R">Ron Bitton</a>, 
<a href="/search/cs?searchtype=author&query=Nassi%2C+B">Ben Nassi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website: <a href="https://sites.google.com/view/compromptmized">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In the past year, numerous companies have incorporated Generative AI (GenAI)
capabilities into new and existing applications, forming interconnected
Generative AI (GenAI) ecosystems consisting of semi/fully autonomous agents
powered by GenAI services. While ongoing research highlighted risks associated
with the GenAI layer of agents (e.g., dialog poisoning, membership inference,
prompt leaking, jailbreaking), a critical question emerges: Can attackers
develop malware to exploit the GenAI component of an agent and launch
cyber-attacks on the entire GenAI ecosystem? This paper introduces Morris II,
the first worm designed to target GenAI ecosystems through the use of
adversarial self-replicating prompts. The study demonstrates that attackers can
insert such prompts into inputs that, when processed by GenAI models, prompt
the model to replicate the input as output (replication), engaging in malicious
activities (payload). Additionally, these inputs compel the agent to deliver
them (propagate) to new agents by exploiting the connectivity within the GenAI
ecosystem. We demonstrate the application of Morris II against GenAIpowered
email assistants in two use cases (spamming and exfiltrating personal data),
under two settings (black-box and white-box accesses), using two types of input
data (text and images). The worm is tested against three different GenAI models
(Gemini Pro, ChatGPT 4.0, and LLaVA), and various factors (e.g., propagation
rate, replication, malicious activity) influencing the performance of the worm
are evaluated.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02818" title="Abstract">arXiv:2403.02818</a> [<a href="/pdf/2403.02818" title="Download PDF">pdf</a>, <a href="/format/2403.02818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Dense Labels Always Necessary for 3D Object Detection from Point  Cloud?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chenqiang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chuandong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+J">Jun Shu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fangcen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Luyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+D">Deyu Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current state-of-the-art (SOTA) 3D object detection methods often require a
large amount of 3D bounding box annotations for training. However, collecting
such large-scale densely-supervised datasets is notoriously costly. To reduce
the cumbersome data annotation process, we propose a novel sparsely-annotated
framework, in which we just annotate one 3D object per scene. Such a sparse
annotation strategy could significantly reduce the heavy annotation burden,
while inexact and incomplete sparse supervision may severely deteriorate the
detection performance. To address this issue, we develop the SS3D++ method that
alternatively improves 3D detector training and confident fully-annotated scene
generation in a unified learning scheme. Using sparse annotations as seeds, we
progressively generate confident fully-annotated scenes based on designing a
missing-annotated instance mining module and reliable background mining module.
Our proposed method produces competitive results when compared with SOTA
weakly-supervised methods using the same or even more annotation costs.
Besides, compared with SOTA fully-supervised methods, we achieve on-par or even
better performance on the KITTI dataset with about 5x less annotation cost, and
90% of their performance on the Waymo dataset with about 15x less annotation
cost. The additional unlabeled training scenes could further boost the
performance. The code will be available at https://github.com/gaocq/SS3D2.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02820" title="Abstract">arXiv:2403.02820</a> [<a href="/pdf/2403.02820" title="Download PDF">pdf</a>, <a href="/format/2403.02820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstruction for Sparse View Tomography of Long Objects Applied to  Imaging in the Wood Industry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baji%C4%87%2C+B">Buda Baji&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Huber%2C+J+A+J">Johannes A. J. Huber</a>, 
<a href="/search/cs?searchtype=author&query=Neyses%2C+B">Benedikt Neyses</a>, 
<a href="/search/cs?searchtype=author&query=Olofsson%2C+L">Linus Olofsson</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96ktem%2C+O">Ozan &#xd6;ktem</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In the wood industry, logs are commonly quality screened by discrete X-ray
scans on a moving conveyor belt from a few source positions. Typically,
two-dimensional (2D) slice-wise measurements are obtained by a sequential
scanning geometry. Each 2D slice alone does not carry sufficient information
for a three-dimensional tomographic reconstruction in which biological features
of interest in the log are well preserved. In the present work, we propose a
learned iterative reconstruction method based on the Learned Primal-Dual neural
network, suited for sequential scanning geometries. Our method accumulates
information between neighbouring slices, instead of only accounting for single
slices during reconstruction. Our quantitative and qualitative evaluations with
as few as five source positions show that our method yields reconstructions of
logs that are sufficiently accurate to identify biological features like knots
(branches), heartwood and sapwood.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02821" title="Abstract">arXiv:2403.02821</a> [<a href="/pdf/2403.02821" title="Download PDF">pdf</a>, <a href="/format/2403.02821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Adaptive Hydropower Management Approach for Downstream Ecosystem  Preservation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coelho%2C+C">C. Coelho</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+M">M. Jing</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+M+F+P">M. Fernanda P. Costa</a>, 
<a href="/search/cs?searchtype=author&query=Ferr%C3%A1s%2C+L+L">L.L. Ferr&#xe1;s</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Optimization and Control (math.OC)

</div>
<p class="mathjax">Hydropower plants play a pivotal role in advancing clean and sustainable
energy production, contributing significantly to the global transition towards
renewable energy sources. However, hydropower plants are currently perceived
both positively as sources of renewable energy and negatively as disruptors of
ecosystems. In this work, we highlight the overlooked potential of using
hydropower plant as protectors of ecosystems by using adaptive ecological
discharges. To advocate for this perspective, we propose using a neural network
to predict the minimum ecological discharge value at each desired time.
Additionally, we present a novel framework that seamlessly integrates it into
hydropower management software, taking advantage of the well-established
approach of using traditional constrained optimisation algorithms. This novel
approach not only protects the ecosystems from climate change but also
contributes to potentially increase the electricity production.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02825" title="Abstract">arXiv:2403.02825</a> [<a href="/pdf/2403.02825" title="Download PDF">pdf</a>, <a href="/format/2403.02825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Pre-training for Deep Session Data Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zixuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+L">Lizi Liao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yunshan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Session data has been widely used for understanding user's behavior in
e-commerce. Researchers are trying to leverage session data for different
tasks, such as purchase intention prediction, remaining length prediction,
recommendation, etc., as it provides context clues about the user's dynamic
interests. However, online shopping session data is semi-structured and complex
in nature, which contains both unstructured textual data about the products,
search queries, and structured user action sequences. Most existing works focus
on leveraging the coarse-grained item sequences for specific tasks, while
largely ignore the fine-grained information from text and user action details.
In this work, we delve into deep session data understanding via scrutinizing
the various clues inside the rich information in user sessions. Specifically,
we propose to pre-train a general-purpose User Behavior Model (UBM) over
large-scale session data with rich details, such as product title, attributes
and various kinds of user actions. A two-stage pre-training scheme is
introduced to encourage the model to self-learn from various augmentations with
contrastive learning objectives, which spans different granularity levels of
session data. Then the well-trained session understanding model can be easily
fine-tuned for various downstream tasks. Extensive experiments show that UBM
better captures the complex intra-item semantic relations, inter-item
connections and inter-interaction dependencies, leading to large performance
gains as compared to the baselines on several downstream tasks. And it also
demonstrates strong robustness when data is sparse.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02827" title="Abstract">arXiv:2403.02827</a> [<a href="/pdf/2403.02827" title="Download PDF">pdf</a>, <a href="/format/2403.02827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tuning-Free Noise Rectification for High Fidelity Image-to-Video  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weijie Li</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+L">Litong Gong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yiran Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+F">Fanda Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Biao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+T">Tiezheng Ge</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Bo Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image-to-video (I2V) generation tasks always suffer from keeping high
fidelity in the open domains. Traditional image animation techniques primarily
focus on specific domains such as faces or human poses, making them difficult
to generalize to open domains. Several recent I2V frameworks based on diffusion
models can generate dynamic content for open domain images but fail to maintain
fidelity. We found that two main factors of low fidelity are the loss of image
details and the noise prediction biases during the denoising process. To this
end, we propose an effective method that can be applied to mainstream video
diffusion models. This method achieves high fidelity based on supplementing
more precise image information and noise rectification. Specifically, given a
specified image, our method first adds noise to the input image latent to keep
more details, then denoises the noisy latent with proper rectification to
alleviate the noise prediction biases. Our method is tuning-free and
plug-and-play. The experimental results demonstrate the effectiveness of our
approach in improving the fidelity of generated videos. For more image-to-video
generated results, please refer to the project website:
https://noise-rectification.github.io.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02831" title="Abstract">arXiv:2403.02831</a> [<a href="/pdf/2403.02831" title="Download PDF">pdf</a>, <a href="/format/2403.02831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpaceHopper: A Small-Scale Legged Robot for Exploring Low-Gravity  Celestial Bodies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spiridonov%2C+A">Alexander Spiridonov</a>, 
<a href="/search/cs?searchtype=author&query=Buehler%2C+F">Fabio Buehler</a>, 
<a href="/search/cs?searchtype=author&query=Berclaz%2C+M">Moriz Berclaz</a>, 
<a href="/search/cs?searchtype=author&query=Schelbert%2C+V">Valerio Schelbert</a>, 
<a href="/search/cs?searchtype=author&query=Geurts%2C+J">Jorit Geurts</a>, 
<a href="/search/cs?searchtype=author&query=Krasnova%2C+E">Elena Krasnova</a>, 
<a href="/search/cs?searchtype=author&query=Steinke%2C+E">Emma Steinke</a>, 
<a href="/search/cs?searchtype=author&query=Toma%2C+J">Jonas Toma</a>, 
<a href="/search/cs?searchtype=author&query=Wuethrich%2C+J">Joschua Wuethrich</a>, 
<a href="/search/cs?searchtype=author&query=Polat%2C+R">Recep Polat</a>, 
<a href="/search/cs?searchtype=author&query=Zimmermann%2C+W">Wim Zimmermann</a>, 
<a href="/search/cs?searchtype=author&query=Arm%2C+P">Philip Arm</a>, 
<a href="/search/cs?searchtype=author&query=Rudin%2C+N">Nikita Rudin</a>, 
<a href="/search/cs?searchtype=author&query=Kolvenbach%2C+H">Hendrik Kolvenbach</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+M">Marco Hutter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the 2024 IEEE International Conference on Robotics and Automation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present SpaceHopper, a three-legged, small-scale robot designed for future
mobile exploration of asteroids and moons. The robot weighs 5.2kg and has a
body size of 245mm while using space-qualifiable components. Furthermore,
SpaceHopper's design and controls make it well-adapted for investigating
dynamic locomotion modes with extended flight-phases. Instead of gyroscopes or
fly-wheels, the system uses its three legs to reorient the body during flight
in preparation for landing. We control the leg motion for reorientation using
Deep Reinforcement Learning policies. In a simulation of Ceres' gravity
(0.029g), the robot can reliably jump to commanded positions up to 6m away. Our
real-world experiments show that SpaceHopper can successfully reorient to a
safe landing orientation within 9.7 degree inside a rotational gimbal and jump
in a counterweight setup in Earth's gravity. Overall, we consider SpaceHopper
an important step towards controlled jumping locomotion in low-gravity
environments.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02833" title="Abstract">arXiv:2403.02833</a> [<a href="/pdf/2403.02833" title="Download PDF">pdf</a>, <a href="/format/2403.02833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SOFIM: Stochastic Optimization Using Regularized Fisher Information  Matrix
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=C%2C+G">Gayathri C</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+M">Mrinmay Sen</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+A+K">A. K. Qin</a>, 
<a href="/search/cs?searchtype=author&query=N%2C+R+K">Raghu Kishore N</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yen-Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Raman%2C+B">Balasubramanian Raman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">This paper introduces a new stochastic optimization method based on the
regularized Fisher information matrix (FIM), named SOFIM, which can efficiently
utilize the FIM to approximate the Hessian matrix for finding Newton's gradient
update in large-scale stochastic optimization of machine learning models. It
can be viewed as a variant of natural gradient descent (NGD), where the
challenge of storing and calculating the full FIM is addressed through making
use of the regularized FIM and directly finding the gradient update direction
via Sherman-Morrison matrix inversion. Additionally, like the popular Adam
method, SOFIM uses the first moment of the gradient to address the issue of
non-stationary objectives across mini-batches due to heterogeneous data. The
utilization of the regularized FIM and Sherman-Morrison matrix inversion leads
to the improved convergence rate with the same space and time complexities as
stochastic gradient descent (SGD) with momentum. The extensive experiments on
training deep learning models on several benchmark image classification
datasets demonstrate that the proposed SOFIM outperforms SGD with momentum and
several state-of-the-art Newton optimization methods, such as Nystrom-SGD,
L-BFGS, and AdaHessian, in term of the convergence speed for achieving the
pre-specified objectives of training and test losses as well as test accuracy.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02834" title="Abstract">arXiv:2403.02834</a> [<a href="/pdf/2403.02834" title="Download PDF">pdf</a>, <a href="/format/2403.02834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Second-order robust parallel integrators for dynamical low-rank  approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kusch%2C+J">Jonas Kusch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Due to its reduced memory and computational demands, dynamical low-rank
approximation (DLRA) has sparked significant interest in multiple research
communities. A central challenge in DLRA is the development of time integrators
that are robust to the curvature of the manifold of low-rank matrices.
Recently, a parallel robust time integrator that permits dynamic rank
adaptation and enables a fully parallel update of all low-rank factors was
introduced. Despite its favorable computational efficiency, the construction as
a first-order approximation to the augmented basis-update &amp; Galerkin integrator
restricts the parallel integrator's accuracy to order one. In this work, an
extension to higher order is proposed by a careful basis augmentation before
solving the matrix differential equations of the factorized solution. A robust
error bound with an improved dependence on normal components of the vector
field together with a norm preservation property up to small terms is derived.
These analytic results are complemented and demonstrated through a series of
numerical experiments.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02839" title="Abstract">arXiv:2403.02839</a> [<a href="/pdf/2403.02839" title="Download PDF">pdf</a>, <a href="/format/2403.02839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study of LLM-as-a-Judge for LLM Evaluation: Fine-tuned  Judge Models are Task-specific Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yingqi Qu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Muyun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tiejun Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recently, there has been a growing trend of utilizing Large Language Model
(LLM) to evaluate the quality of other LLMs. Many studies have employed
proprietary close-source models, especially GPT4, as the evaluator.
Alternatively, other works have fine-tuned judge models based on open-source
LLMs as the evaluator. In this study, we conduct an empirical study of
different judge models on their evaluation capability. Our findings indicate
that although the fine-tuned judge models achieve high accuracy on in-domain
test sets, even surpassing GPT4, they are inherently task-specific classifiers,
and their generalizability and fairness severely underperform GPT4.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02845" title="Abstract">arXiv:2403.02845</a> [<a href="/pdf/2403.02845" title="Download PDF">pdf</a>, <a href="/format/2403.02845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OORD: The Oxford Offroad Radar Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gadd%2C+M">Matthew Gadd</a>, 
<a href="/search/cs?searchtype=author&query=De+Martini%2C+D">Daniele De Martini</a>, 
<a href="/search/cs?searchtype=author&query=Bartlett%2C+O">Oliver Bartlett</a>, 
<a href="/search/cs?searchtype=author&query=Murcutt%2C+P">Paul Murcutt</a>, 
<a href="/search/cs?searchtype=author&query=Towlson%2C+M">Matt Towlson</a>, 
<a href="/search/cs?searchtype=author&query=Widojo%2C+M">Matthew Widojo</a>, 
<a href="/search/cs?searchtype=author&query=Mu%C5%9Fat%2C+V">Valentina Mu&#x15f;at</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+L">Luke Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Panagiotaki%2C+E">Efimia Panagiotaki</a>, 
<a href="/search/cs?searchtype=author&query=Pramatarov%2C+G">Georgi Pramatarov</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BChn%2C+M+A">Marc Alexander K&#xfc;hn</a>, 
<a href="/search/cs?searchtype=author&query=Marchegiani%2C+L">Letizia Marchegiani</a>, 
<a href="/search/cs?searchtype=author&query=Newman%2C+P">Paul Newman</a>, 
<a href="/search/cs?searchtype=author&query=Kunze%2C+L">Lars Kunze</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">There is a growing academic interest as well as commercial exploitation of
millimetre-wave scanning radar for autonomous vehicle localisation and scene
understanding. Although several datasets to support this research area have
been released, they are primarily focused on urban or semi-urban environments.
Nevertheless, rugged offroad deployments are important application areas which
also present unique challenges and opportunities for this sensor technology.
Therefore, the Oxford Offroad Radar Dataset (OORD) presents data collected in
the rugged Scottish highlands in extreme weather. The radar data we offer to
the community are accompanied by GPS/INS reference - to further stimulate
research in radar place recognition. In total we release over 90GiB of radar
scans as well as GPS and IMU readings by driving a diverse set of four routes
over 11 forays, totalling approximately 154km of rugged driving. This is an
area increasingly explored in literature, and we therefore present and release
examples of recent open-sourced radar place recognition systems and their
performance on our dataset. This includes a learned neural network, the weights
of which we also release. The data and tools are made freely available to the
community at https://oxford-robotics-institute.github.io/oord-dataset.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02846" title="Abstract">arXiv:2403.02846</a> [<a href="/pdf/2403.02846" title="Download PDF">pdf</a>, <a href="/format/2403.02846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FLGuard: Byzantine-Robust Federated Learning via Ensemble of Contrastive  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Younghan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+Y">Yungi Cho</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+W">Woorim Han</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+H">Ho Bae</a>, 
<a href="/search/cs?searchtype=author&query=Paek%2C+Y">Yunheung Paek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 28th European Symposium on Research in Computer Security (ESORICS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated Learning (FL) thrives in training a global model with numerous
clients by only sharing the parameters of their local models trained with their
private training datasets. Therefore, without revealing the private dataset,
the clients can obtain a deep learning (DL) model with high performance.
However, recent research proposed poisoning attacks that cause a catastrophic
loss in the accuracy of the global model when adversaries, posed as benign
clients, are present in a group of clients. Therefore, recent studies suggested
byzantine-robust FL methods that allow the server to train an accurate global
model even with the adversaries present in the system. However, many existing
methods require the knowledge of the number of malicious clients or the
auxiliary (clean) dataset or the effectiveness reportedly decreased hugely when
the private dataset was non-independently and identically distributed
(non-IID). In this work, we propose FLGuard, a novel byzantine-robust FL method
that detects malicious clients and discards malicious local updates by
utilizing the contrastive learning technique, which showed a tremendous
improvement as a self-supervised learning method. With contrastive models, we
design FLGuard as an ensemble scheme to maximize the defensive capability. We
evaluate FLGuard extensively under various poisoning attacks and compare the
accuracy of the global model with existing byzantine-robust FL methods. FLGuard
outperforms the state-of-the-art defense methods in most cases and shows
drastic improvement, especially in non-IID settings.
https://github.com/201younghanlee/FLGuard
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02847" title="Abstract">arXiv:2403.02847</a> [<a href="/pdf/2403.02847" title="Download PDF">pdf</a>, <a href="/ps/2403.02847" title="Download PostScript">ps</a>, <a href="/format/2403.02847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Numerical Approximation of Parabolic Problems Using Model Order  Reduction and the Laplace Transform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Henr%C3%ADquez%2C+F">Fernando Henr&#xed;quez</a>, 
<a href="/search/math?searchtype=author&query=Hesthaven%2C+J+S">Jan S. Hesthaven</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We introduce a novel, fast method for the numerical approximation of
parabolic partial differential equations (PDEs for short) based on model order
reduction techniques and the Laplace transform. We start by applying said
transform to the evolution problem, thus yielding a time-independent boundary
value problem solely depending on the complex Laplace parameter. In an offline
stage, we judiciously sample the Laplace parameter and numerically solve the
corresponding collection of high-fidelity or full-order problems. Next, we
apply a proper orthogonal decomposition (POD) to this collection of solutions
in order to obtain a reduced basis in the Laplace domain. We project the linear
parabolic problem onto this basis, and then using any suitable time-stepping
method, we solve the evolution problem. A key insight to justify the
implementation and analysis of the proposed method corresponds to resorting to
Hardy spaces of analytic functions and establishing, through the Paley-Wiener
theorem, an isometry between the solution of the time-dependent problem and its
Laplace transform. As a result, one may conclude that computing a POD with
samples taken in the Laplace domain produces an exponentially accurate reduced
basis for the time-dependent problem. Numerical experiments portray the
performance of the method in terms of accuracy and, in particular, speed-up
when compared to the solution obtained by solving the full-order model.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02850" title="Abstract">arXiv:2403.02850</a> [<a href="/pdf/2403.02850" title="Download PDF">pdf</a>, <a href="/ps/2403.02850" title="Download PostScript">ps</a>, <a href="/format/2403.02850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Syndrome-based Neural Decoders for Bit-Interleaved Coded  Modulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Boni+Rovella%2C+G">Gast&#xf3;n De Boni Rovella</a>, 
<a href="/search/cs?searchtype=author&query=Benammar%2C+M">Meryem Benammar</a>, 
<a href="/search/cs?searchtype=author&query=Benaddi%2C+T">Tarik Benaddi</a>, 
<a href="/search/cs?searchtype=author&query=Meric%2C+H">Hugo Meric</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 7 figures. To be published in Proc. IEEE International Conference on Machine Learning for Communication and Networking (ICMLCN 2024), Stockholm, Sweden, May 5-8, 2024. \copyright 2024 IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this work, we introduce a framework that enables the use of Syndrome-Based
Neural Decoders (SBND) for high-order Bit-Interleaved Coded Modulations (BICM).
To this end, we extend the previous results on SBND, for which the validity is
limited to Binary Phase-Shift Keying (BPSK), by means of a theoretical channel
modeling of the bit Log-Likelihood Ratio (bit-LLR) induced outputs. We
implement the proposed SBND system for two polar codes $(64,32)$ and
$(128,64)$, using a Recurrent Neural Network (RNN) and a Transformer-based
architecture. Both implementations are compared in Bit Error Rate (BER)
performance and computational complexity.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02856" title="Abstract">arXiv:2403.02856</a> [<a href="/pdf/2403.02856" title="Download PDF">pdf</a>, <a href="/format/2403.02856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Data Management: From Theory to Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hai%2C+R">Rihan Hai</a>, 
<a href="/search/cs?searchtype=author&query=Hung%2C+S">Shih-Han Hung</a>, 
<a href="/search/cs?searchtype=author&query=Feld%2C+S">Sebastian Feld</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 40th IEEE International Conference on Data Engineering (ICDE 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Quantum computing has emerged as a transformative tool for future data
management. Classical problems in database domains, including query
optimization, data integration, and transaction management, have recently been
addressed using quantum computing techniques. This tutorial aims to establish
the theoretical foundation essential for enhancing methodologies and practical
implementations in this line of research. Moreover, this tutorial takes a
forward-looking approach by delving into recent strides in quantum internet
technologies and the nonlocality theory. We aim to shed light on the uncharted
territory of future data systems tailored for the quantum internet.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02863" title="Abstract">arXiv:2403.02863</a> [<a href="/pdf/2403.02863" title="Download PDF">pdf</a>, <a href="/format/2403.02863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spintronic Implementation of UNet for Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vadde%2C+V">Venkatesh Vadde</a>, 
<a href="/search/cs?searchtype=author&query=Muralidharan%2C+B">Bhaskaran Muralidharan</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Abhishek Sharma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Image and Video Processing (eess.IV); Applied Physics (physics.app-ph)

</div>
<p class="mathjax">Image segmentation plays a crucial role in computer vision applications like
self-driving cars, satellite imagery analysis, and medical diagnosis.
Implementing these complex deep neural networks on conventional hardware is
highly inefficient. In this work, we propose hardware implementation of UNet
for segmentation tasks, using spintronic devices. Our approach involves
designing hardware for convolution, deconvolution, ReLU, and max pooling layers
of the UNet architecture. We demonstrate the synaptic behavior of the domain
wall MTJ, and design convolution and deconvolution layers using the domain
wall-based crossbar array. We utilize the orthogonal current injected MTJ with
its continuous resistance change and showcase the ReLU and max pooling
functions. We employ a hybrid simulation setup by coupling micromagnetic
simulation, non-equilibrium Green's function,
Landau-Lifshitz-Gilbert-Slonczewski equations, and circuit simulation with
Python programming to incorporate the diverse physics of spin-transport,
magnetization dynamics, and CMOS elements in our proposed designs. We evaluate
our UNet design on the CamVid dataset and achieve segmentation accuracies that
are comparable to software implementation. During training, our design consumes
43.59pJ of energy for synaptic weight updates.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02867" title="Abstract">arXiv:2403.02867</a> [<a href="/pdf/2403.02867" title="Download PDF">pdf</a>, <a href="/format/2403.02867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Continuous-time Diffusion Framework for Network Inference and  Influence Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Keke Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Ruize Gao</a>, 
<a href="/search/cs?searchtype=author&query=Cautis%2C+B">Bogdan Cautis</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xiaokui Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The study of continuous-time information diffusion has been an important area
of research for many applications in recent years. When only the diffusion
traces (cascades) are accessible, cascade-based network inference and influence
estimation are two essential problems to explore. Alas, existing methods
exhibit limited capability to infer and process networks with more than a few
thousand nodes, suffering from scalability issues. In this paper, we view the
diffusion process as a continuous-time dynamical system, based on which we
establish a continuous-time diffusion model. Subsequently, we instantiate the
model to a scalable and effective framework (FIM) to approximate the diffusion
propagation from available cascades, thereby inferring the underlying network
structure. Furthermore, we undertake an analysis of the approximation error of
FIM for network inference. To achieve the desired scalability for influence
estimation, we devise an advanced sampling technique and significantly boost
the efficiency. We also quantify the effect of the approximation error on
influence estimation theoretically. Experimental results showcase the
effectiveness and superior scalability of FIM on network inference and
influence estimation.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02870" title="Abstract">arXiv:2403.02870</a> [<a href="/pdf/2403.02870" title="Download PDF">pdf</a>, <a href="/format/2403.02870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Precise Extraction of Deep Learning Models via Side-Channel Attacks on  Edge/Endpoint Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Younghan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jun%2C+S">Sohee Jun</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+Y">Yungi Cho</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+W">Woorim Han</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+H">Hyungon Moon</a>, 
<a href="/search/cs?searchtype=author&query=Paek%2C+Y">Yunheung Paek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 27th European Symposium on Research in Computer Security (ESORICS 2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">With growing popularity, deep learning (DL) models are becoming larger-scale,
and only the companies with vast training datasets and immense computing power
can manage their business serving such large models. Most of those DL models
are proprietary to the companies who thus strive to keep their private models
safe from the model extraction attack (MEA), whose aim is to steal the model by
training surrogate models. Nowadays, companies are inclined to offload the
models from central servers to edge/endpoint devices. As revealed in the latest
studies, adversaries exploit this opportunity as new attack vectors to launch
side-channel attack (SCA) on the device running victim model and obtain various
pieces of the model information, such as the model architecture (MA) and image
dimension (ID). Our work provides a comprehensive understanding of such a
relationship for the first time and would benefit future MEA studies in both
offensive and defensive sides in that they may learn which pieces of
information exposed by SCA are more important than the others. Our analysis
additionally reveals that by grasping the victim model information from SCA,
MEA can get highly effective and successful even without any prior knowledge of
the model. Finally, to evince the practicality of our analysis results, we
empirically apply SCA, and subsequently, carry out MEA under realistic threat
assumptions. The results show up to 5.8 times better performance than when the
adversary has no model information about the victim model.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02873" title="Abstract">arXiv:2403.02873</a> [<a href="/pdf/2403.02873" title="Download PDF">pdf</a>, <a href="/format/2403.02873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Note on High-Probability Analysis of Algorithms with Exponential,  Sub-Gaussian, and General Light Tails
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Attia%2C+A">Amit Attia</a>, 
<a href="/search/cs?searchtype=author&query=Koren%2C+T">Tomer Koren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Probability (math.PR)

</div>
<p class="mathjax">This short note describes a simple technique for analyzing probabilistic
algorithms that rely on a light-tailed (but not necessarily bounded) source of
randomization. We show that the analysis of such an algorithm can be reduced,
in a black-box manner and with only a small loss in logarithmic factors, to an
analysis of a simpler variant of the same algorithm that uses bounded random
variables and often easier to analyze. This approach simultaneously applies to
any light-tailed randomization, including exponential, sub-Gaussian, and more
general fast-decaying distributions, without needing to appeal to specialized
concentration inequalities. Analyses of a generalized Azuma inequality and
stochastic optimization with general light-tailed noise are provided to
illustrate the technique.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02875" title="Abstract">arXiv:2403.02875</a> [<a href="/pdf/2403.02875" title="Download PDF">pdf</a>, <a href="/format/2403.02875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Conceptual Understanding in Multimodal Contrastive Learning  through Hard Negative Samples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=R%C3%B6sch%2C+P+J">Philipp J. R&#xf6;sch</a>, 
<a href="/search/cs?searchtype=author&query=Oswald%2C+N">Norbert Oswald</a>, 
<a href="/search/cs?searchtype=author&query=Geierhos%2C+M">Michaela Geierhos</a>, 
<a href="/search/cs?searchtype=author&query=Libovick%C3%BD%2C+J">Jind&#x159;ich Libovick&#xfd;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Current multimodal models leveraging contrastive learning often face
limitations in developing fine-grained conceptual understanding. This is due to
random negative samples during pretraining, causing almost exclusively very
dissimilar concepts to be compared in the loss function. Consequently, the
models struggle with fine-grained semantic differences. To address this
problem, we introduce a novel pretraining method incorporating synthetic hard
negative text examples. The hard negatives permute terms corresponding to
visual concepts, leading to a more fine-grained visual and textual concept
alignment. Further, we introduce InpaintCOCO, a new challenging dataset for
assessing the fine-grained alignment of colors, objects, and sizes in
vision-language models. We created the dataset using generative inpainting from
COCO images by changing the visual concepts so that the images no longer match
their original captions. Our results show significant improvements in
fine-grained concept understanding across a wide range of vision-language
datasets, including our InpaintCOCO dataset.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02877" title="Abstract">arXiv:2403.02877</a> [<a href="/pdf/2403.02877" title="Download PDF">pdf</a>, <a href="/format/2403.02877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ActiveAD: Planning-Oriented Active Learning for End-to-End Autonomous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Han Lu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiaosong Jia</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yichen Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+W">Wenlong Liao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaokang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">End-to-end differentiable learning for autonomous driving (AD) has recently
become a prominent paradigm. One main bottleneck lies in its voracious appetite
for high-quality labeled data e.g. 3D bounding boxes and semantic segmentation,
which are notoriously expensive to manually annotate. The difficulty is further
pronounced due to the prominent fact that the behaviors within samples in AD
often suffer from long tailed distribution. In other words, a large part of
collected data can be trivial (e.g. simply driving forward in a straight road)
and only a few cases are safety-critical. In this paper, we explore a
practically important yet under-explored problem about how to achieve sample
and label efficiency for end-to-end AD. Specifically, we design a
planning-oriented active learning method which progressively annotates part of
collected raw data according to the proposed diversity and usefulness criteria
for planning routes. Empirically, we show that our planning-oriented approach
could outperform general active learning methods by a large margin. Notably,
our method achieves comparable performance with state-of-the-art end-to-end AD
methods - by using only 30% nuScenes data. We hope our work could inspire
future works to explore end-to-end AD from a data-centric perspective in
addition to methodology efforts.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02879" title="Abstract">arXiv:2403.02879</a> [<a href="/pdf/2403.02879" title="Download PDF">pdf</a>, <a href="/format/2403.02879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-LED: Zero-Reference Lighting Estimation Diffusion Model for  Low-Light Image Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jinhong He</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+M">Minglong Xue</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhipu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Chengyun Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+S">Senming Zhong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion model-based low-light image enhancement methods rely heavily on
paired training data, leading to limited extensive application. Meanwhile,
existing unsupervised methods lack effective bridging capabilities for unknown
degradation. To address these limitations, we propose a novel zero-reference
lighting estimation diffusion model for low-light image enhancement called
Zero-LED. It utilizes the stable convergence ability of diffusion models to
bridge the gap between low-light domains and real normal-light domains and
successfully alleviates the dependence on pairwise training data via
zero-reference learning. Specifically, we first design the initial optimization
network to preprocess the input image and implement bidirectional constraints
between the diffusion model and the initial optimization network through
multiple objective functions. Subsequently, the degradation factors of the
real-world scene are optimized iteratively to achieve effective light
enhancement. In addition, we explore a frequency-domain based and semantically
guided appearance reconstruction module that encourages feature alignment of
the recovered image at a fine-grained level and satisfies subjective
expectations. Finally, extensive experiments demonstrate the superiority of our
approach to other state-of-the-art methods and more significant generalization
capabilities. We will open the source code upon acceptance of the paper.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02882" title="Abstract">arXiv:2403.02882</a> [<a href="/pdf/2403.02882" title="Download PDF">pdf</a>, <a href="/format/2403.02882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous vehicle decision and control through reinforcement learning  with traffic flow randomization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lin%2C+Y">Yuan Lin</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+A">Antai Xie</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+X">Xiao Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Most of the current studies on autonomous vehicle decision-making and control
tasks based on reinforcement learning are conducted in simulated environments.
The training and testing of these studies are carried out under rule-based
microscopic traffic flow, with little consideration of migrating them to real
or near-real environments to test their performance. It may lead to a
degradation in performance when the trained model is tested in more realistic
traffic scenes. In this study, we propose a method to randomize the driving
style and behavior of surrounding vehicles by randomizing certain parameters of
the car-following model and the lane-changing model of rule-based microscopic
traffic flow in SUMO. We trained policies with deep reinforcement learning
algorithms under the domain randomized rule-based microscopic traffic flow in
freeway and merging scenes, and then tested them separately in rule-based
microscopic traffic flow and high-fidelity microscopic traffic flow. Results
indicate that the policy trained under domain randomization traffic flow has
significantly better success rate and calculative reward compared to the models
trained under other microscopic traffic flows.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02884" title="Abstract">arXiv:2403.02884</a> [<a href="/pdf/2403.02884" title="Download PDF">pdf</a>, <a href="/format/2403.02884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MathScale: Scaling Instruction Tuning for Mathematical Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhengyang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingxing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+B">Benyou Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Furu Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated remarkable capabilities in
problem-solving. However, their proficiency in solving mathematical problems
remains inadequate. We propose MathScale, a simple and scalable method to
create high-quality mathematical reasoning data using frontier LLMs (e.g., {\tt
GPT-3.5}). Inspired by the cognitive mechanism in human mathematical learning,
it first extracts topics and knowledge points from seed math questions and then
build a concept graph, which is subsequently used to generate new math
questions. MathScale exhibits effective scalability along the size axis of the
math dataset that we generate. As a result, we create a mathematical reasoning
dataset (MathScaleQA) containing two million math question-answer pairs. To
evaluate mathematical reasoning abilities of LLMs comprehensively, we construct
{\sc MwpBench}, a benchmark of Math Word Problems, which is a collection of ten
datasets (including GSM8K and MATH) covering K-12, college, and competition
level math problems. We apply MathScaleQA to fine-tune open-source LLMs (e.g.,
LLaMA-2 and Mistral), resulting in significantly improved capabilities in
mathematical reasoning. Evaluated on {\sc MwpBench}, MathScale-7B achieves
state-of-the-art performance across all datasets, surpassing its best peers of
equivalent size by 42.9\% in micro average accuracy and 43.7\% in macro average
accuracy, respectively.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02886" title="Abstract">arXiv:2403.02886</a> [<a href="/pdf/2403.02886" title="Download PDF">pdf</a>, <a href="/format/2403.02886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Confidence Estimation: Towards Reliable Failure Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Fei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xu-Yao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhen Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cheng-Lin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE TPAMI. arXiv admin note: text overlap with <a href="/abs/2303.02970">arXiv:2303.02970</a>; text overlap with <a href="/abs/2007.01458">arXiv:2007.01458</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Reliable confidence estimation is a challenging yet fundamental requirement
in many risk-sensitive applications. However, modern deep neural networks are
often overconfident for their incorrect predictions, i.e., misclassified
samples from known classes, and out-of-distribution (OOD) samples from unknown
classes. In recent years, many confidence calibration and OOD detection methods
have been developed. In this paper, we find a general, widely existing but
actually-neglected phenomenon that most confidence estimation methods are
harmful for detecting misclassification errors. We investigate this problem and
reveal that popular calibration and OOD detection methods often lead to worse
confidence separation between correctly classified and misclassified examples,
making it difficult to decide whether to trust a prediction or not. Finally, we
propose to enlarge the confidence gap by finding flat minima, which yields
state-of-the-art failure prediction performance under various settings
including balanced, long-tailed, and covariate-shift classification scenarios.
Our study not only provides a strong baseline for reliable confidence
estimation but also acts as a bridge between understanding calibration, OOD
detection, and failure prediction. The code is available at
\url{https://github.com/Impression2805/FMFP}.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02887" title="Abstract">arXiv:2403.02887</a> [<a href="/pdf/2403.02887" title="Download PDF">pdf</a>, <a href="/format/2403.02887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing the Rate-Distortion-Perception Flexibility of Learned Image  Codecs with Conditional Diffusion Decoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mari%2C+D">Daniele Mari</a>, 
<a href="/search/cs?searchtype=author&query=Milani%2C+S">Simone Milani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Learned image compression codecs have recently achieved impressive
compression performances surpassing the most efficient image coding
architectures. However, most approaches are trained to minimize rate and
distortion which often leads to unsatisfactory visual results at low bitrates
since perceptual metrics are not taken into account. In this paper, we show
that conditional diffusion models can lead to promising results in the
generative compression task when used as a decoder, and that, given a
compressed representation, they allow creating new tradeoff points between
distortion and perception at the decoder side based on the sampling method.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02889" title="Abstract">arXiv:2403.02889</a> [<a href="/pdf/2403.02889" title="Download PDF">pdf</a>, <a href="/format/2403.02889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In Search of Truth: An Interrogation Approach to Hallucination Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yehuda%2C+Y">Yakir Yehuda</a>, 
<a href="/search/cs?searchtype=author&query=Malkiel%2C+I">Itzik Malkiel</a>, 
<a href="/search/cs?searchtype=author&query=Barkan%2C+O">Oren Barkan</a>, 
<a href="/search/cs?searchtype=author&query=Weill%2C+J">Jonathan Weill</a>, 
<a href="/search/cs?searchtype=author&query=Ronen%2C+R">Royi Ronen</a>, 
<a href="/search/cs?searchtype=author&query=Koenigstein%2C+N">Noam Koenigstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite the many advances of Large Language Models (LLMs) and their
unprecedented rapid evolution, their impact and integration into every facet of
our daily lives is limited due to various reasons. One critical factor
hindering their widespread adoption is the occurrence of hallucinations, where
LLMs invent answers that sound realistic, yet drift away from factual truth. In
this paper, we present a novel method for detecting hallucinations in large
language models, which tackles a critical issue in the adoption of these models
in various real-world scenarios. Through extensive evaluations across multiple
datasets and LLMs, including Llama-2, we study the hallucination levels of
various recent LLMs and demonstrate the effectiveness of our method to
automatically detect them. Notably, we observe up to 62% hallucinations for
Llama-2 in a specific experiment, where our method achieves a Balanced Accuracy
(B-ACC) of 87%, all without relying on external knowledge.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02892" title="Abstract">arXiv:2403.02892</a> [<a href="/pdf/2403.02892" title="Download PDF">pdf</a>, <a href="/format/2403.02892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Long-Term Person Re-Identification Using Global, Local Body  Part, and Head Streams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thanh%2C+D+T">Duy Tran Thanh</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yeejin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+B">Byeongkeun Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neurocomputing, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This work addresses the task of long-term person re-identification.
Typically, person re-identification assumes that people do not change their
clothes, which limits its applications to short-term scenarios. To overcome
this limitation, we investigate long-term person re-identification, which
considers both clothes-changing and clothes-consistent scenarios. In this
paper, we propose a novel framework that effectively learns and utilizes both
global and local information. The proposed framework consists of three streams:
global, local body part, and head streams. The global and head streams encode
identity-relevant information from an entire image and a cropped image of the
head region, respectively. Both streams encode the most distinct, less
distinct, and average features using the combinations of adversarial erasing,
max pooling, and average pooling. The local body part stream extracts
identity-related information for each body part, allowing it to be compared
with the same body part from another image. Since body part annotations are not
available in re-identification datasets, pseudo-labels are generated using
clustering. These labels are then utilized to train a body part segmentation
head in the local body part stream. The proposed framework is trained by
backpropagating the weighted summation of the identity classification loss, the
pair-based loss, and the pseudo body part segmentation loss. To demonstrate the
effectiveness of the proposed method, we conducted experiments on three
publicly available datasets (Celeb-reID, PRCC, and VC-Clothes). The
experimental results demonstrate that the proposed method outperforms the
previous state-of-the-art method.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02893" title="Abstract">arXiv:2403.02893</a> [<a href="/pdf/2403.02893" title="Download PDF">pdf</a>, <a href="/format/2403.02893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Cross-Lingual Document-Level Event Causality Identification  with Heterogeneous Graph Contrastive Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhitao He</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+P">Pengfei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yubo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiqiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mengshu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Event Causality Identification (ECI) refers to detect causal relations
between events in texts. However, most existing studies focus on sentence-level
ECI with high-resource language, leaving more challenging document-level ECI
(DECI) with low-resource languages under-explored. In this paper, we propose a
Heterogeneous Graph Interaction Model with Multi-granularity Contrastive
Transfer Learning (GIMC) for zero-shot cross-lingual document-level ECI.
Specifically, we introduce a heterogeneous graph interaction network to model
the long-distance dependencies between events that are scattered over document.
Then, to improve cross-lingual transferability of causal knowledge learned from
source language, we propose a multi-granularity contrastive transfer learning
module to align the causal representations across languages. Extensive
experiments show our framework outperforms previous state-of-the-art model by
9.4% and 8.2% of average F1 score on monolingual and multilingual scenarios
respectively. Notably, in multilingual scenario, our zero-shot framework even
exceeds GPT-3.5 with few-shot learning by 24.3% in overall performance.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02898" title="Abstract">arXiv:2403.02898</a> [<a href="/pdf/2403.02898" title="Download PDF">pdf</a>, <a href="/format/2403.02898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning Using Coupled Tensor Train Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangtao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kofidis%2C+E">Eleftherios Kofidis</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Ce Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Le Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yipeng Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Coupled tensor decomposition (CTD) can extract joint features from multimodal
data in various applications. It can be employed for federated learning
networks with data confidentiality. Federated CTD achieves data privacy
protection by sharing common features and keeping individual features. However,
traditional CTD schemes based on canonical polyadic decomposition (CPD) may
suffer from low computational efficiency and heavy communication costs.
Inspired by the efficient tensor train decomposition, we propose a coupled
tensor train (CTT) decomposition for federated learning. The distributed
coupled multi-way data are decomposed into a series of tensor trains with
shared factors. In this way, we can extract common features of coupled modes
while maintaining the different features of uncoupled modes. Thus the privacy
preservation of information across different network nodes can be ensured. The
proposed CTT approach is instantiated for two fundamental network structures,
namely master-slave and decentralized networks. Experimental results on
synthetic and real datasets demonstrate the superiority of the proposed schemes
over existing methods in terms of both computational efficiency and
communication rounds. In a classification task, experimental results show that
the CTT-based federated learning achieves almost the same accuracy performance
as that of the centralized counterpart.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02899" title="Abstract">arXiv:2403.02899</a> [<a href="/pdf/2403.02899" title="Download PDF">pdf</a>, <a href="/format/2403.02899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain-Agnostic Mutual Prompting for Unsupervised Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zhekai Du</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fengling Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+K">Ke Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingjing Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Conventional Unsupervised Domain Adaptation (UDA) strives to minimize
distribution discrepancy between domains, which neglects to harness rich
semantics from data and struggles to handle complex domain shifts. A promising
technique is to leverage the knowledge of large-scale pre-trained
vision-language models for more guided adaptation. Despite some endeavors,
current methods often learn textual prompts to embed domain semantics for
source and target domains separately and perform classification within each
domain, limiting cross-domain knowledge transfer. Moreover, prompting only the
language branch lacks flexibility to adapt both modalities dynamically. To
bridge this gap, we propose Domain-Agnostic Mutual Prompting (DAMP) to exploit
domain-invariant semantics by mutually aligning visual and textual embeddings.
Specifically, the image contextual information is utilized to prompt the
language branch in a domain-agnostic and instance-conditioned way. Meanwhile,
visual prompts are imposed based on the domain-agnostic textual prompt to
elicit domain-invariant visual embeddings. These two branches of prompts are
learned mutually with a cross-attention module and regularized with a
semantic-consistency loss and an instance-discrimination contrastive loss.
Experiments on three UDA benchmarks demonstrate the superiority of DAMP over
state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02901" title="Abstract">arXiv:2403.02901</a> [<a href="/pdf/2403.02901" title="Download PDF">pdf</a>, <a href="/format/2403.02901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Survey on Process-Oriented Automatic Text Summarization  with Exploration of LLM-Based Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hanlei Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+D">Dan Meng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+J">Jinghua Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Automatic Text Summarization (ATS), utilizing Natural Language Processing
(NLP) algorithms, aims to create concise and accurate summaries, thereby
significantly reducing the human effort required in processing large volumes of
text. ATS has drawn considerable interest in both academic and industrial
circles. Many studies have been conducted in the past to survey ATS methods;
however, they generally lack practicality for real-world implementations, as
they often categorize previous methods from a theoretical standpoint. Moreover,
the advent of Large Language Models (LLMs) has altered conventional ATS
methods. In this survey, we aim to 1) provide a comprehensive overview of ATS
from a ``Process-Oriented Schema'' perspective, which is best aligned with
real-world implementations; 2) comprehensively review the latest LLM-based ATS
works; and 3) deliver an up-to-date survey of ATS, bridging the two-year gap in
the literature. To the best of our knowledge, this is the first survey to
specifically investigate LLM-based ATS methods.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02902" title="Abstract">arXiv:2403.02902</a> [<a href="/pdf/2403.02902" title="Download PDF">pdf</a>, <a href="/format/2403.02902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demonstrating Mutual Reinforcement Effect through Information Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chengguang Gan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xuzheng He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qinghao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mori%2C+T">Tatsunori Mori</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 15 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The Mutual Reinforcement Effect (MRE) investigates the synergistic
relationship between word-level and text-level classifications in text
classification tasks. It posits that the performance of both classification
levels can be mutually enhanced. However, this mechanism has not been
adequately demonstrated or explained in prior research. To address this gap, we
employ information flow analysis to observe and substantiate the MRE theory.
Our experiments on six MRE hybrid datasets revealed the presence of MRE in the
model and its impact. Additionally, we conducted fine-tuning experiments, whose
results were consistent with those of the information flow experiments. The
convergence of findings from both experiments corroborates the existence of
MRE. Furthermore, we extended the application of MRE to prompt learning,
utilizing word-level information as a verbalizer to bolster the model's
prediction of text-level classification labels. In our final experiment, the
F1-score significantly surpassed the baseline in five out of six datasets,
further validating the notion that word-level information enhances the language
model's comprehension of the text as a whole.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02905" title="Abstract">arXiv:2403.02905</a> [<a href="/pdf/2403.02905" title="Download PDF">pdf</a>, <a href="/format/2403.02905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MMoFusion: Multi-modal Co-Speech Motion Generation with Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiangning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+W">Weijian Cao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaobin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Moran Li</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xiaozhong Ji</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengtian Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhifeng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lizhuang Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">The body movements accompanying speech aid speakers in expressing their
ideas. Co-speech motion generation is one of the important approaches for
synthesizing realistic avatars. Due to the intricate correspondence between
speech and motion, generating realistic and diverse motion is a challenging
task. In this paper, we propose MMoFusion, a Multi-modal co-speech Motion
generation framework based on the diffusion model to ensure both the
authenticity and diversity of generated motion. We propose a progressive fusion
strategy to enhance the interaction of inter-modal and intra-modal, efficiently
integrating multi-modal information. Specifically, we employ a masked style
matrix based on emotion and identity information to control the generation of
different motion styles. Temporal modeling of speech and motion is partitioned
into style-guided specific feature encoding and shared feature encoding, aiming
to learn both inter-modal and intra-modal features. Besides, we propose a
geometric loss to enforce the joints' velocity and acceleration coherence among
frames. Our framework generates vivid, diverse, and style-controllable motion
of arbitrary length through inputting speech and editing identity and emotion.
Extensive experiments demonstrate that our method outperforms current co-speech
motion generation methods including upper body and challenging full body.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02906" title="Abstract">arXiv:2403.02906</a> [<a href="/pdf/2403.02906" title="Download PDF">pdf</a>, <a href="/format/2403.02906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Citizen Science and Machine Learning for Research and Nature  Conservation: The Case of Eurasian Lynx, Free-ranging Rodents and Insects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Skorupska%2C+K">Kinga Skorupska</a>, 
<a href="/search/cs?searchtype=author&query=Stryjek%2C+R">Rafa&#x142; Stryjek</a>, 
<a href="/search/cs?searchtype=author&query=Wierzbowska%2C+I">Izabela Wierzbowska</a>, 
<a href="/search/cs?searchtype=author&query=Bebas%2C+P">Piotr Bebas</a>, 
<a href="/search/cs?searchtype=author&query=Grzeszczuk%2C+M">Maciej Grzeszczuk</a>, 
<a href="/search/cs?searchtype=author&query=Gago%2C+P">Piotr Gago</a>, 
<a href="/search/cs?searchtype=author&query=Kowalski%2C+J">Jaros&#x142;aw Kowalski</a>, 
<a href="/search/cs?searchtype=author&query=Krzywicki%2C+M">Maciej Krzywicki</a>, 
<a href="/search/cs?searchtype=author&query=Lazarek%2C+J">Jagoda Lazarek</a>, 
<a href="/search/cs?searchtype=author&query=Kope%C4%87%2C+W">Wies&#x142;aw Kope&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 11 figures, MIDI 2023 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Technology is increasingly used in Nature Reserves and National Parks around
the world to support conservation efforts. Endangered species, such as the
Eurasian Lynx (Lynx lynx), are monitored by a network of automatic photo traps.
Yet, this method produces vast amounts of data, which needs to be prepared,
analyzed and interpreted. Therefore, researchers working in this area
increasingly need support to process this incoming information. One opportunity
is to seek support from volunteer Citizen Scientists who can help label the
data, however, it is challenging to retain their interest. Another way is to
automate the process with image recognition using convolutional neural
networks. During the panel, we will discuss considerations related to nature
research and conservation as well as opportunities for the use of Citizen
Science and Machine Learning to expedite the process of data preparation,
labelling and analysis.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02908" title="Abstract">arXiv:2403.02908</a> [<a href="/pdf/2403.02908" title="Download PDF">pdf</a>, <a href="/format/2403.02908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preserving Tangible and Intangible Cultural Heritage: the Cases of  Volterra and Atari
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grzeszczuk%2C+M">Maciej Grzeszczuk</a>, 
<a href="/search/cs?searchtype=author&query=Skorupska%2C+K">Kinga Skorupska</a>, 
<a href="/search/cs?searchtype=author&query=Grabarczyk%2C+P">Pawe&#x142; Grabarczyk</a>, 
<a href="/search/cs?searchtype=author&query=Fuchs%2C+W">W&#x142;adys&#x142;aw Fuchs</a>, 
<a href="/search/cs?searchtype=author&query=Aubin%2C+P+F">Paul F. Aubin</a>, 
<a href="/search/cs?searchtype=author&query=Dietrick%2C+M+E">Mark E. Dietrick</a>, 
<a href="/search/cs?searchtype=author&query=Karpowicz%2C+B">Barbara Karpowicz</a>, 
<a href="/search/cs?searchtype=author&query=Mas%C5%82yk%2C+R">Rafa&#x142; Mas&#x142;yk</a>, 
<a href="/search/cs?searchtype=author&query=Zinevych%2C+P">Pavlo Zinevych</a>, 
<a href="/search/cs?searchtype=author&query=Stawski%2C+W">Wiktor Stawski</a>, 
<a href="/search/cs?searchtype=author&query=Knapi%C5%84ski%2C+S">Stanis&#x142;aw Knapi&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Kope%C4%87%2C+W">Wies&#x142;aw Kope&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, including 1 page of bibliography, 9 figures. Panel summary to be published in proceedings from 11th Machine Intelligence and Digital Interaction MIDI Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Digital Libraries (cs.DL); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">At first glance, the ruins of the Roman Theatre in the Italian town of
Volterra have little in common with cassette tapes containing Atari games. One
is certainly considered an important historical landmark, while the consensus
on the importance of the other is partial at best. Still, both are remnants of
times vastly different from the present and are at risk of oblivion. Unearthed
architectural structures are exposed to the elements just as the deteriorating
signals stored on magnetic tapes. However, the rate of deterioration is much
faster with the magnetic media, as their life expectancy is counted in decades,
whereas the Roman Theater, which is already in ruin, measures its lifespan in
centuries. Hence, both would benefit from some form of digital preservation and
reconstruction. In this panel, we discuss how to sustainably preserve tangible
and intangible cultural artifacts for future generations.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02909" title="Abstract">arXiv:2403.02909</a> [<a href="/pdf/2403.02909" title="Download PDF">pdf</a>, <a href="/format/2403.02909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaze-Vector Estimation in the Dark with Temporally Encoded Event-driven  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+A">Abeer Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+N+K">Naval K. Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Prasad%2C+S+S">Shyam S. Prasad</a>, 
<a href="/search/cs?searchtype=author&query=Himanshu">Himanshu</a>, 
<a href="/search/cs?searchtype=author&query=Saurav%2C+S">Sumeet Saurav</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Sanjay Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">In this paper, we address the intricate challenge of gaze vector prediction,
a pivotal task with applications ranging from human-computer interaction to
driver monitoring systems. Our innovative approach is designed for the
demanding setting of extremely low-light conditions, leveraging a novel
temporal event encoding scheme, and a dedicated neural network architecture.
The temporal encoding method seamlessly integrates Dynamic Vision Sensor (DVS)
events with grayscale guide frames, generating consecutively encoded images for
input into our neural network. This unique solution not only captures diverse
gaze responses from participants within the active age group but also
introduces a curated dataset tailored for low-light conditions. The encoded
temporal frames paired with our network showcase impressive spatial
localization and reliable gaze direction in their predictions. Achieving a
remarkable 100-pixel accuracy of 100%, our research underscores the potency of
our neural network to work with temporally consecutive encoded images for
precise gaze vector predictions in challenging low-light videos, contributing
to the advancement of gaze prediction technologies.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02910" title="Abstract">arXiv:2403.02910</a> [<a href="/pdf/2403.02910" title="Download PDF">pdf</a>, <a href="/format/2403.02910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ImgTrojan: Jailbreaking Vision-Language Models with ONE Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xijia Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+S">Shuai Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingpeng Kong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">There has been an increasing interest in the alignment of large language
models (LLMs) with human values. However, the safety issues of their
integration with a vision module, or vision language models (VLMs), remain
relatively underexplored. In this paper, we propose a novel jailbreaking attack
against VLMs, aiming to bypass their safety barrier when a user inputs harmful
instructions. A scenario where our poisoned (image, text) data pairs are
included in the training data is assumed. By replacing the original textual
captions with malicious jailbreak prompts, our method can perform jailbreak
attacks with the poisoned images. Moreover, we analyze the effect of poison
ratios and positions of trainable parameters on our attack's success rate. For
evaluation, we design two metrics to quantify the success rate and the
stealthiness of our attack. Together with a list of curated harmful
instructions, a benchmark for measuring attack efficacy is provided. We
demonstrate the efficacy of our attack by comparing it with baseline methods.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02913" title="Abstract">arXiv:2403.02913</a> [<a href="/pdf/2403.02913" title="Download PDF">pdf</a>, <a href="/format/2403.02913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scientific machine learning for closure models in multiscale problems: a  review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sanderse%2C+B">Benjamin Sanderse</a>, 
<a href="/search/math?searchtype=author&query=Stinis%2C+P">Panos Stinis</a>, 
<a href="/search/math?searchtype=author&query=Maulik%2C+R">Romit Maulik</a>, 
<a href="/search/math?searchtype=author&query=Ahmed%2C+S+E">Shady E. Ahmed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Closure problems are omnipresent when simulating multiscale systems, where
some quantities and processes cannot be fully prescribed despite their effects
on the simulation's accuracy. Recently, scientific machine learning approaches
have been proposed as a way to tackle the closure problem, combining
traditional (physics-based) modeling with data-driven (machine-learned)
techniques, typically through enriching differential equations with neural
networks. This paper reviews the different reduced model forms, distinguished
by the degree to which they include known physics, and the different objectives
of a priori and a posteriori learning. The importance of adhering to physical
laws (such as symmetries and conservation laws) in choosing the reduced model
form and choosing the learning method is discussed. The effect of spatial and
temporal discretization and recent trends toward discretization-invariant
models are reviewed. In addition, we make the connections between closure
problems and several other research disciplines: inverse problems, Mori-Zwanzig
theory, and multi-fidelity methods. In conclusion, much progress has been made
with scientific machine learning approaches for solving closure problems, but
many challenges remain. In particular, the generalizability and
interpretability of learned models is a major issue that needs to be addressed
further.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02914" title="Abstract">arXiv:2403.02914</a> [<a href="/pdf/2403.02914" title="Download PDF">pdf</a>, <a href="/ps/2403.02914" title="Download PostScript">ps</a>, <a href="/format/2403.02914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DynST: Dynamic Sparse Training for Resource-Constrained Spatio-Temporal  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Haomin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guibin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yutong Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuxuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The ever-increasing sensor service, though opening a precious path and
providing a deluge of earth system data for deep-learning-oriented earth
science, sadly introduce a daunting obstacle to their industrial level
deployment. Concretely, earth science systems rely heavily on the extensive
deployment of sensors, however, the data collection from sensors is constrained
by complex geographical and social factors, making it challenging to achieve
comprehensive coverage and uniform deployment. To alleviate the obstacle,
traditional approaches to sensor deployment utilize specific algorithms to
design and deploy sensors. These methods dynamically adjust the activation
times of sensors to optimize the detection process across each sub-region.
Regrettably, formulating an activation strategy generally based on historical
observations and geographic characteristics, which make the methods and
resultant models were neither simple nor practical. Worse still, the complex
technical design may ultimately lead to a model with weak generalizability. In
this paper, we introduce for the first time the concept of spatio-temporal data
dynamic sparse training and are committed to adaptively, dynamically filtering
important sensor distributions. To our knowledge, this is the first proposal
(termed DynST) of an industry-level deployment optimization concept at the data
level. However, due to the existence of the temporal dimension, pruning of
spatio-temporal data may lead to conflicts at different timestamps. To achieve
this goal, we employ dynamic merge technology, along with ingenious dimensional
mapping to mitigate potential impacts caused by the temporal aspect. During the
training process, DynST utilize iterative pruning and sparse training,
repeatedly identifying and dynamically removing sensor perception areas that
contribute the least to future predictions.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02917" title="Abstract">arXiv:2403.02917</a> [<a href="/pdf/2403.02917" title="Download PDF">pdf</a>, <a href="/ps/2403.02917" title="Download PostScript">ps</a>, <a href="/format/2403.02917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Miniaturized Device for Ultrafast On-demand Drug Release based on a  Gigahertz Ultrasonic Resonator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yangchao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+M">Moonkwang Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Meng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+X">Xuexin Duan</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+T">Tian Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figures, 1 table
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> \c{opyright} 2024 The Authors. Advanced Engineering Materials
  published by Wiley-VCH GmbH
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Biological Physics (physics.bio-ph)

</div>
<p class="mathjax">On-demand controlled drug delivery is essential for the treatment of a wide
range of chronic diseases. As the drug is released at the time when required,
its efficacy is boosted and the side effects are minimized. However, so far,
drug delivery devices often rely on the passive diffusion process for a
sustained release, which is slow and uncontrollable. Here, we present a
miniaturized microfluidic device for wirelessly controlled ultrafast active
drug delivery, driven by an oscillating solid-liquid interface. The oscillation
generates acoustic streaming in the drug reservoir, which opens an elastic
valve to deliver the drug. High-speed microscopy reveals the fast response of
the valve on the order of 1 ms, which is more than three orders of magnitude
faster than the start-of-the-art. The amount of the released drug exhibits a
linear relationship with the working time and the electric power applied to the
ultrasonic resonator. The trigger of the release is wirelessly controlled via a
magnetic field, and the system shows stable output in a continuous experiment
for two weeks. The integrated system shows great promise as a long-term
controlled drug delivery implant for chronic diseases.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02918" title="Abstract">arXiv:2403.02918</a> [<a href="/pdf/2403.02918" title="Download PDF">pdf</a>, <a href="/format/2403.02918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-Channel Robot Ego-Speech Filtering during Human-Robot Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yue Li</a>, 
<a href="/search/cs?searchtype=author&query=Hindriks%2C+K+V">Koen V Hindriks</a>, 
<a href="/search/cs?searchtype=author&query=Kunneman%2C+F">Florian Kunneman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM Technological Advances in Human-Robot Interaction. 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In this paper, we study how well human speech can automatically be filtered
when this overlaps with the voice and fan noise of a social robot, Pepper. We
ultimately aim for an HRI scenario where the microphone can remain open when
the robot is speaking, enabling a more natural turn-taking scheme where the
human can interrupt the robot. To respond appropriately, the robot would need
to understand what the interlocutor said in the overlapping part of the speech,
which can be accomplished by target speech extraction (TSE). To investigate how
well TSE can be accomplished in the context of the popular social robot Pepper,
we set out to manufacture a datase composed of a mixture of recorded speech of
Pepper itself, its fan noise (which is close to the microphones), and human
speech as recorded by the Pepper microphone, in a room with low reverberation
and high reverberation. Comparing a signal processing approach, with and
without post-filtering, and a convolutional recurrent neural network (CRNN)
approach to a state-of-the-art speaker identification-based TSE model, we found
that the signal processing approach without post-filtering yielded the best
performance in terms of Word Error Rate on the overlapping speech signals with
low reverberation, while the CRNN approach is more robust for reverberation.
These results show that estimating the human voice in overlapping speech with a
robot is possible in real-life application, provided that the room
reverberation is low and the human speech has a high volume or high pitch.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02919" title="Abstract">arXiv:2403.02919</a> [<a href="/pdf/2403.02919" title="Download PDF">pdf</a>, <a href="/format/2403.02919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Domain Image Conversion by CycleDM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shimotsumagari%2C+S">Sho Shimotsumagari</a>, 
<a href="/search/cs?searchtype=author&query=Takezaki%2C+S">Shumpei Takezaki</a>, 
<a href="/search/cs?searchtype=author&query=Haraguchi%2C+D">Daichi Haraguchi</a>, 
<a href="/search/cs?searchtype=author&query=Uchida%2C+S">Seiichi Uchida</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The purpose of this paper is to enable the conversion between machine-printed
character images (i.e., font images) and handwritten character images through
machine learning. For this purpose, we propose a novel unpaired image-to-image
domain conversion method, CycleDM, which incorporates the concept of CycleGAN
into the diffusion model. Specifically, CycleDM has two internal conversion
models that bridge the denoising processes of two image domains. These
conversion models are efficiently trained without explicit correspondence
between the domains. By applying machine-printed and handwritten character
images to the two modalities, CycleDM realizes the conversion between them. Our
experiments for evaluating the converted images quantitatively and
qualitatively found that ours performs better than other comparable approaches.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02920" title="Abstract">arXiv:2403.02920</a> [<a href="/pdf/2403.02920" title="Download PDF">pdf</a>, <a href="/format/2403.02920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TaylorShift: Shifting the Complexity of Self-Attention from Squared to  Linear (and Back) using Taylor-Softmax
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nauen%2C+T+C">Tobias Christian Nauen</a>, 
<a href="/search/cs?searchtype=author&query=Palacio%2C+S">Sebastian Palacio</a>, 
<a href="/search/cs?searchtype=author&query=Dengel%2C+A">Andreas Dengel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The quadratic complexity of the attention mechanism represents one of the
biggest hurdles for processing long sequences using Transformers. Current
methods, relying on sparse representations or stateful recurrence, sacrifice
token-to-token interactions, which ultimately leads to compromises in
performance. This paper introduces TaylorShift, a novel reformulation of the
Taylor softmax that enables computing full token-to-token interactions in
linear time and space. We analytically determine the crossover points where
employing TaylorShift becomes more efficient than traditional attention,
aligning closely with empirical measurements. Specifically, our findings
demonstrate that TaylorShift enhances memory efficiency for sequences as short
as 800 tokens and accelerates inference for inputs of approximately 1700 tokens
and beyond. For shorter sequences, TaylorShift scales comparably with the
vanilla attention. Furthermore, a classification benchmark across five tasks
involving long sequences reveals no degradation in accuracy when employing
Transformers equipped with TaylorShift. For reproducibility, we provide access
to our code under https://github.com/tobna/TaylorShift.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02922" title="Abstract">arXiv:2403.02922</a> [<a href="/pdf/2403.02922" title="Download PDF">pdf</a>, <a href="/format/2403.02922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Spectra to Biophysical Insights: End-to-End Learning with a Biased  Radiative Transfer Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=She%2C+Y">Yihang She</a>, 
<a href="/search/cs?searchtype=author&query=Atzberger%2C+C">Clement Atzberger</a>, 
<a href="/search/cs?searchtype=author&query=Blake%2C+A">Andrew Blake</a>, 
<a href="/search/cs?searchtype=author&query=Keshav%2C+S">Srinivasan Keshav</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Advances in machine learning have boosted the use of Earth observation data
for climate change research. Yet, the interpretability of machine-learned
representations remains a challenge, particularly in understanding forests'
biophysical reactions to climate change. Traditional methods in remote sensing
that invert radiative transfer models (RTMs) to retrieve biophysical variables
from spectral data often fail to account for biases inherent in the RTM,
especially for complex forests. We propose to integrate RTMs into an
auto-encoder architecture, creating an end-to-end learning approach. Our method
not only corrects biases in RTMs but also outperforms traditional techniques
for variable retrieval like neural network regression. Furthermore, our
framework has potential generally for inverting biased physical models. The
code is available on https://github.com/yihshe/ai-refined-rtm.git.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02928" title="Abstract">arXiv:2403.02928</a> [<a href="/pdf/2403.02928" title="Download PDF">pdf</a>, <a href="/format/2403.02928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User-Driven Adaptation: Tailoring Autonomous Driving Systems with  Dynamic Preferences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingyue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jialong Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Nianyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+E">Eunsuk Kang</a>, 
<a href="/search/cs?searchtype=author&query=Tei%2C+K">Kenji Tei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by CHI LBW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">In the realm of autonomous vehicles, dynamic user preferences are critical
yet challenging to accommodate. Existing methods often misrepresent these
preferences, either by overlooking their dynamism or overburdening users as
humans often find it challenging to express their objectives mathematically.
The previously introduced framework, which interprets dynamic preferences as
inherent uncertainty and includes a ``human-on-the-loop'' mechanism enabling
users to give feedback when dissatisfied with system behaviors, addresses this
gap. In this study, we further enhance the approach with a user study of 20
participants, focusing on aligning system behavior with user expectations
through feedback-driven adaptation. The findings affirm the approach's ability
to effectively merge algorithm-driven adjustments with user complaints, leading
to improved participants' subjective satisfaction in autonomous systems.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02930" title="Abstract">arXiv:2403.02930</a> [<a href="/pdf/2403.02930" title="Download PDF">pdf</a>, <a href="/format/2403.02930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Second Look on BASS -- Boosting Abstractive Summarization with Unified  Semantic Graphs -- A Replication Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kora%C5%9F%2C+O+A">Osman Alperen Kora&#x15f;</a>, 
<a href="/search/cs?searchtype=author&query=Schl%C3%B6tterer%2C+J">J&#xf6;rg Schl&#xf6;tterer</a>, 
<a href="/search/cs?searchtype=author&query=Seifert%2C+C">Christin Seifert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this contribution is published in Advances in Information Retrieval, 46th European Conference on Information Retrieval, ECIR 2024. 16 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a detailed replication study of the BASS framework, an abstractive
summarization system based on the notion of Unified Semantic Graphs. Our
investigation includes challenges in replicating key components and an ablation
study to systematically isolate error sources rooted in replicating novel
components. Our findings reveal discrepancies in performance compared to the
original work. We highlight the significance of paying careful attention even
to reasonably omitted details for replicating advanced frameworks like BASS,
and emphasize key practices for writing replicable papers.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02931" title="Abstract">arXiv:2403.02931</a> [<a href="/pdf/2403.02931" title="Download PDF">pdf</a>, <a href="/ps/2403.02931" title="Download PostScript">ps</a>, <a href="/format/2403.02931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the quality of individual-level online information tracking:  challenges of existing approaches and introduction of a new content- and  long-tail sensitive academic solution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adam%2C+S">Silke Adam</a>, 
<a href="/search/cs?searchtype=author&query=Makhortykh%2C+M">Mykola Makhortykh</a>, 
<a href="/search/cs?searchtype=author&query=Maier%2C+M">Michaela Maier</a>, 
<a href="/search/cs?searchtype=author&query=Aigenseer%2C+V">Viktor Aigenseer</a>, 
<a href="/search/cs?searchtype=author&query=Urman%2C+A">Aleksandra Urman</a>, 
<a href="/search/cs?searchtype=author&query=Lopez%2C+T+G">Teresa Gil Lopez</a>, 
<a href="/search/cs?searchtype=author&query=Christner%2C+C">Clara Christner</a>, 
<a href="/search/cs?searchtype=author&query=de+Le%C3%B3n%2C+E">Ernesto de Le&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Ulloa%2C+R">Roberto Ulloa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 73 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This article evaluates the quality of data collection in individual-level
desktop information tracking used in the social sciences and shows that the
existing approaches face sampling issues, validity issues due to the lack of
content-level data and their disregard of the variety of devices and long-tail
consumption patterns as well as transparency and privacy issues. To overcome
some of these problems, the article introduces a new academic tracking
solution, WebTrack, an open source tracking tool maintained by a major European
research institution. The design logic, the interfaces and the backend
requirements for WebTrack, followed by a detailed examination of strengths and
weaknesses of the tool, are discussed. Finally, using data from 1185
participants, the article empirically illustrates how an improvement in the
data collection through WebTrack leads to new innovative shifts in the
processing of tracking data. As WebTrack allows collecting the content people
are exposed to on more than classical news platforms, we can strongly improve
the detection of politics-related information consumption in tracking data with
the application of automated content analysis compared to traditional
approaches that rely on the list-based identification of news.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02932" title="Abstract">arXiv:2403.02932</a> [<a href="/pdf/2403.02932" title="Download PDF">pdf</a>, <a href="/format/2403.02932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RulePrompt: Weakly Supervised Text Classification with Prompting PLMs  and Self-Iterative Logical Rules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Miaomiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiaqi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yilin Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WWW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Weakly supervised text classification (WSTC), also called zero-shot or
dataless text classification, has attracted increasing attention due to its
applicability in classifying a mass of texts within the dynamic and open Web
environment, since it requires only a limited set of seed words (label names)
for each category instead of labeled data. With the help of recently popular
prompting Pre-trained Language Models (PLMs), many studies leveraged manually
crafted and/or automatically identified verbalizers to estimate the likelihood
of categories, but they failed to differentiate the effects of these
category-indicative words, let alone capture their correlations and realize
adaptive adjustments according to the unlabeled corpus. In this paper, in order
to let the PLM effectively understand each category, we at first propose a
novel form of rule-based knowledge using logical expressions to characterize
the meanings of categories. Then, we develop a prompting PLM-based approach
named RulePrompt for the WSTC task, consisting of a rule mining module and a
rule-enhanced pseudo label generation module, plus a self-supervised
fine-tuning module to make the PLM align with this task. Within this framework,
the inaccurate pseudo labels assigned to texts and the imprecise logical rules
associated with categories mutually enhance each other in an alternative
manner. That establishes a self-iterative closed loop of knowledge (rule)
acquisition and utilization, with seed words serving as the starting point.
Extensive experiments validate the effectiveness and robustness of our
approach, which markedly outperforms state-of-the-art weakly supervised
methods. What is more, our approach yields interpretable category rules,
proving its advantage in disambiguating easily-confused categories.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02933" title="Abstract">arXiv:2403.02933</a> [<a href="/pdf/2403.02933" title="Download PDF">pdf</a>, <a href="/format/2403.02933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fuzzy Datalog$^\exists$ over Arbitrary t-Norms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lanzinger%2C+M">Matthias Lanzinger</a>, 
<a href="/search/cs?searchtype=author&query=Sferrazza%2C+S">Stefano Sferrazza</a>, 
<a href="/search/cs?searchtype=author&query=Wa%C5%82%C4%99ga%2C+P+A">Przemys&#x142;aw A. Wa&#x142;&#x119;ga</a>, 
<a href="/search/cs?searchtype=author&query=Gottlob%2C+G">Georg Gottlob</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">One of the main challenges in the area of Neuro-Symbolic AI is to perform
logical reasoning in the presence of both neural and symbolic data. This
requires combining heterogeneous data sources such as knowledge graphs, neural
model predictions, structured databases, crowd-sourced data, and many more. To
allow for such reasoning, we generalise the standard rule-based language
Datalog with existential rules (commonly referred to as tuple-generating
dependencies) to the fuzzy setting, by allowing for arbitrary t-norms in the
place of classical conjunctions in rule bodies. The resulting formalism allows
us to perform reasoning about data associated with degrees of uncertainty while
preserving computational complexity results and the applicability of reasoning
techniques established for the standard Datalog setting. In particular, we
provide fuzzy extensions of Datalog chases which produce fuzzy universal models
and we exploit them to show that in important fragments of the language,
reasoning has the same complexity as in the classical setting.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02934" title="Abstract">arXiv:2403.02934</a> [<a href="/pdf/2403.02934" title="Download PDF">pdf</a>, <a href="/format/2403.02934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> iSummary: Workload-based, Personalized Summaries for Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vassiliou%2C+G">Giannis Vassiliou</a>, 
<a href="/search/cs?searchtype=author&query=Alevizakis%2C+F">Fanouris Alevizakis</a>, 
<a href="/search/cs?searchtype=author&query=Papadakis%2C+N">Nikolaos Papadakis</a>, 
<a href="/search/cs?searchtype=author&query=Kondylakis%2C+H">Haridimos Kondylakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">The explosion in the size and the complexity of the available Knowledge
Graphs on the web has led to the need for efficient and effective methods for
their understanding and exploration. Semantic summaries have recently emerged
as methods to quickly explore and understand the contents of various sources.
However in most cases they are static not incorporating user needs and
preferences and cannot scale. In this paper we present iSummary a novel
scalable approach for constructing personalized summaries. As the size and the
complexity of the Knowledge Graphs for constructing personalized summaries
prohibit efficient summary construction, in our approach we exploit query logs.
The main idea behind our approach is to exploit knowledge captured in existing
user queries for identifying the most interesting resources and linking them
constructing as such highquality personalized summaries. We present an
algorithm with theoretical guarantees on the summarys quality linear in the
number of queries available in the query log. We evaluate our approach using
three realworld datasets and several baselines showing that our approach
dominates other methods in terms of both quality and efficiency.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02936" title="Abstract">arXiv:2403.02936</a> [<a href="/pdf/2403.02936" title="Download PDF">pdf</a>, <a href="/format/2403.02936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdAM: Adaptive Fault-Tolerant Approximate Multiplier for Edge DNN  Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taheri%2C+M">Mahdi Taheri</a>, 
<a href="/search/cs?searchtype=author&query=Cherezova%2C+N">Natalia Cherezova</a>, 
<a href="/search/cs?searchtype=author&query=Nazari%2C+S">Samira Nazari</a>, 
<a href="/search/cs?searchtype=author&query=Rafiq%2C+A">Ahsan Rafiq</a>, 
<a href="/search/cs?searchtype=author&query=Azarpeyvand%2C+A">Ali Azarpeyvand</a>, 
<a href="/search/cs?searchtype=author&query=Ghasempouri%2C+T">Tara Ghasempouri</a>, 
<a href="/search/cs?searchtype=author&query=Daneshtalab%2C+M">Masoud Daneshtalab</a>, 
<a href="/search/cs?searchtype=author&query=Raik%2C+J">Jaan Raik</a>, 
<a href="/search/cs?searchtype=author&query=Jenihhin%2C+M">Maksim Jenihhin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Hardware Architecture (cs.AR); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we propose an architecture of a novel adaptive fault-tolerant
approximate multiplier tailored for ASIC-based DNN accelerators.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02938" title="Abstract">arXiv:2403.02938</a> [<a href="/pdf/2403.02938" title="Download PDF">pdf</a>, <a href="/format/2403.02938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AIx Speed: Playback Speed Optimization Using Listening Comprehension of  Speech Recognition Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kawamura%2C+K">Kazuki Kawamura</a>, 
<a href="/search/cs?searchtype=author&query=Rekimoto%2C+J">Jun Rekimoto</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AHs '23: Proceedings of the Augmented Humans International
  Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Since humans can listen to audio and watch videos at faster speeds than
actually observed, we often listen to or watch these pieces of content at
higher playback speeds to increase the time efficiency of content
comprehension. To further utilize this capability, systems that automatically
adjust the playback speed according to the user's condition and the type of
content to assist in more efficient comprehension of time-series content have
been developed. However, there is still room for these systems to further
extend human speed-listening ability by generating speech with playback speed
optimized for even finer time units and providing it to humans. In this study,
we determine whether humans can hear the optimized speech and propose a system
that automatically adjusts playback speed at units as small as phonemes while
ensuring speech intelligibility. The system uses the speech recognizer score as
a proxy for how well a human can hear a certain unit of speech and maximizes
the speech playback speed to the extent that a human can hear. This method can
be used to produce fast but intelligible speech. In the evaluation experiment,
we compared the speech played back at a constant fast speed and the flexibly
speed-up speech generated by the proposed method in a blind test and confirmed
that the proposed method produced speech that was easier to listen to.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02939" title="Abstract">arXiv:2403.02939</a> [<a href="/pdf/2403.02939" title="Download PDF">pdf</a>, <a href="/format/2403.02939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PaperWeaver: Enriching Topical Paper Alerts by Contextualizing  Recommended Papers with User-collected Papers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yoonjoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+H+B">Hyeonsu B. Kang</a>, 
<a href="/search/cs?searchtype=author&query=Latzke%2C+M">Matt Latzke</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Juho Kim</a>, 
<a href="/search/cs?searchtype=author&query=Bragg%2C+J">Jonathan Bragg</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+J+C">Joseph Chee Chang</a>, 
<a href="/search/cs?searchtype=author&query=Siangliulue%2C+P">Pao Siangliulue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">With the rapid growth of scholarly archives, researchers subscribe to "paper
alert" systems that periodically provide them with recommendations of recently
published papers that are similar to previously collected papers. However,
researchers sometimes struggle to make sense of nuanced connections between
recommended papers and their own research context, as existing systems only
present paper titles and abstracts. To help researchers spot these connections,
we present PaperWeaver, an enriched paper alerts system that provides
contextualized text descriptions of recommended papers based on user-collected
papers. PaperWeaver employs a computational method based on Large Language
Models (LLMs) to infer users' research interests from their collected papers,
extract context-specific aspects of papers, and compare recommended and
collected papers on these aspects. Our user study (N=15) showed that
participants using PaperWeaver were able to better understand the relevance of
recommended papers and triage them more confidently when compared to a baseline
that presented the related work sections from recommended papers.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02940" title="Abstract">arXiv:2403.02940</a> [<a href="/pdf/2403.02940" title="Download PDF">pdf</a>, <a href="/format/2403.02940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ISC: an RADI-type method for stochastic continuous-time algebraic  Riccati equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guo%2C+Z">Zhen-Chen Guo</a>, 
<a href="/search/math?searchtype=author&query=Liang%2C+X">Xin Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 2 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper, we propose an RADI-type method for large-scale stochastic
continuous-time algebraic Riccati equations with sparse and low-rank
structures. The so-called ISC method is developed by using the Incorporation
idea together with different Shifts to accelerate the convergence and
Compressions to reduce the storage and complexity. Numerical experiments are
given to show its efficiency.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02942" title="Abstract">arXiv:2403.02942</a> [<a href="/pdf/2403.02942" title="Download PDF">pdf</a>, <a href="/format/2403.02942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tensor Decomposition-based Time Varying Channel Estimation for mmWave  MIMO-OFDM Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruizhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Hong Ren</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Cunhua Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Gui Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiangzhou Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we consider the time-varying channel estimation in millimeter
wave (mmWave) multiple-input multiple-output MIMO systems with hybrid
beamforming architectures. Different from the existing contributions that
considered single-carrier mmWave systems with high mobility, the wideband
orthogonal frequency division multiplexing (OFDM) system is considered in this
work. To solve the channel estimation problem under channel double selectivity,
we propose a pilot transmission scheme based on 5G OFDM, and the received
signals are formed as a fourth-order tensor, which fits the low-rank
CANDECOMP/PARAFAC (CP) model. By further exploring the Vandermonde structure of
factor matrix, a tensor-subspace decomposition based channel estimation method
is proposed to solve the CP decomposition, where the uniqueness condition is
analyzed. Based on the decomposed factor matrices, the channel parameters,
including angles of arrival/departure, delays, channel gains and Doppler shifts
are estimated, and the Cram\'{e}r-Rao bound (CRB) results are derived as
performance metrics. Simulation results demonstrate the superior performance of
the proposed method over other benchmarks. Furthermore, the channel estimation
methods are tested based on the channel parameters generated by Wireless
InSites, and simulation results show the effectiveness of the proposed method
in practical scenarios.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02944" title="Abstract">arXiv:2403.02944</a> [<a href="/pdf/2403.02944" title="Download PDF">pdf</a>, <a href="/format/2403.02944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Image Compression with Text-guided Encoding for both Pixel-level  and Perceptual Fidelity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hagyeong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minkyu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jun-Hyuk Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+D">Dokwan Oh</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaeho Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advances in text-guided image compression have shown great potential
to enhance the perceptual quality of reconstructed images. These methods,
however, tend to have significantly degraded pixel-wise fidelity, limiting
their practicality. To fill this gap, we develop a new text-guided image
compression algorithm that achieves both high perceptual and pixel-wise
fidelity. In particular, we propose a compression framework that leverages text
information mainly by text-adaptive encoding and training with joint image-text
loss. By doing so, we avoid decoding based on text-guided generative models --
known for high generative diversity -- and effectively utilize the semantic
information of text at a global level. Experimental results on various datasets
show that our method can achieve high pixel-level and perceptual quality, with
either human- or machine-generated captions. In particular, our method
outperforms all baselines in terms of LPIPS, with some room for even more
improvements when we use more carefully generated captions.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02945" title="Abstract">arXiv:2403.02945</a> [<a href="/pdf/2403.02945" title="Download PDF">pdf</a>, <a href="/format/2403.02945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Learning Approaches for Identifying ICU Patient Subgroups:  Do Results Generalise?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mayne%2C+H">Harry Mayne</a>, 
<a href="/search/cs?searchtype=author&query=Parsons%2C+G">Guy Parsons</a>, 
<a href="/search/cs?searchtype=author&query=Mahdi%2C+A">Adam Mahdi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The use of unsupervised learning to identify patient subgroups has emerged as
a potentially promising direction to improve the efficiency of Intensive Care
Units (ICUs). By identifying subgroups of patients with similar levels of
medical resource need, ICUs could be restructured into a collection of smaller
subunits, each catering to a specific group. However, it is unclear whether
common patient subgroups exist across different ICUs, which would determine
whether ICU restructuring could be operationalised in a standardised manner. In
this paper, we tested the hypothesis that common ICU patient subgroups exist by
examining whether the results from one existing study generalise to a different
dataset. We extracted 16 features representing medical resource need and used
consensus clustering to derive patient subgroups, replicating the previous
study. We found limited similarities between our results and those of the
previous study, providing evidence against the hypothesis. Our findings imply
that there is significant variation between ICUs; thus, a standardised
restructuring approach is unlikely to be appropriate. Instead, potential
efficiency gains might be greater when the number and nature of the subunits
are tailored to each ICU individually.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02946" title="Abstract">arXiv:2403.02946</a> [<a href="/pdf/2403.02946" title="Download PDF">pdf</a>, <a href="/format/2403.02946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAFFIRA: a Framework for Assessing the Reliability of  Systolic-Array-Based DNN Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taheri%2C+M">Mahdi Taheri</a>, 
<a href="/search/cs?searchtype=author&query=Daneshtalab%2C+M">Masoud Daneshtalab</a>, 
<a href="/search/cs?searchtype=author&query=Raik%2C+J">Jaan Raik</a>, 
<a href="/search/cs?searchtype=author&query=Jenihhin%2C+M">Maksim Jenihhin</a>, 
<a href="/search/cs?searchtype=author&query=Pappalardo%2C+S">Salvatore Pappalardo</a>, 
<a href="/search/cs?searchtype=author&query=Jimenez%2C+P">Paul Jimenez</a>, 
<a href="/search/cs?searchtype=author&query=Deveautour%2C+B">Bastien Deveautour</a>, 
<a href="/search/cs?searchtype=author&query=Bosio%2C+A">Alberto Bosio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Hardware Architecture (cs.AR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Systolic array has emerged as a prominent architecture for Deep Neural
Network (DNN) hardware accelerators, providing high-throughput and low-latency
performance essential for deploying DNNs across diverse applications. However,
when used in safety-critical applications, reliability assessment is mandatory
to guarantee the correct behavior of DNN accelerators. While fault injection
stands out as a well-established practical and robust method for reliability
assessment, it is still a very time-consuming process. This paper addresses the
time efficiency issue by introducing a novel hierarchical software-based
hardware-aware fault injection strategy tailored for systolic array-based DNN
accelerators.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02950" title="Abstract">arXiv:2403.02950</a> [<a href="/pdf/2403.02950" title="Download PDF">pdf</a>, <a href="/format/2403.02950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A general approach to enhance the survivability of backdoor attacks by  decision path coupling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yufei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dingji Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bihuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ziqian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xin Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Backdoor attacks have been one of the emerging security threats to deep
neural networks (DNNs), leading to serious consequences. One of the mainstream
backdoor defenses is model reconstruction-based. Such defenses adopt model
unlearning or pruning to eliminate backdoors. However, little attention has
been paid to survive from such defenses. To bridge the gap, we propose Venom,
the first generic backdoor attack enhancer to improve the survivability of
existing backdoor attacks against model reconstruction-based defenses. We
formalize Venom as a binary-task optimization problem. The first is the
original backdoor attack task to preserve the original attack capability, while
the second is the attack enhancement task to improve the attack survivability.
To realize the second task, we propose attention imitation loss to force the
decision path of poisoned samples in backdoored models to couple with the
crucial decision path of benign samples, which makes backdoors difficult to
eliminate. Our extensive evaluation on two DNNs and three datasets has
demonstrated that Venom significantly improves the survivability of eight
state-of-the-art attacks against eight state-of-the-art defenses without
impacting the capability of the original attacks.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02951" title="Abstract">arXiv:2403.02951</a> [<a href="/pdf/2403.02951" title="Download PDF">pdf</a>, <a href="/format/2403.02951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking the Text-to-SQL Capability of Large Language Models: A  Comprehensive Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yuxiao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+G">Guoqing Du</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaoru Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhishuai Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C+H">Chi Harold Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+H">Hangyu Mao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) have emerged as a powerful tool in advancing the
Text-to-SQL task, significantly outperforming traditional methods.
Nevertheless, as a nascent research field, there is still no consensus on the
optimal prompt templates and design frameworks. Additionally, existing
benchmarks inadequately explore the performance of LLMs across the various
sub-tasks of the Text-to-SQL process, which hinders the assessment of LLMs'
cognitive capabilities and the optimization of LLM-based solutions.To address
the aforementioned issues, we firstly construct a new dataset designed to
mitigate the risk of overfitting in LLMs. Then we formulate five evaluation
tasks to comprehensively assess the performance of diverse methods across
various LLMs throughout the Text-to-SQL process.Our study highlights the
performance disparities among LLMs and proposes optimal in-context learning
solutions tailored to each task. These findings offer valuable insights for
enhancing the development of LLM-based Text-to-SQL systems.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02953" title="Abstract">arXiv:2403.02953</a> [<a href="/pdf/2403.02953" title="Download PDF">pdf</a>, <a href="/format/2403.02953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-level Robust Bidding of Renewable-only Virtual Power Plant in  Energy and Ancillary Service Markets for Worst-case Profit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nemati%2C+H">Hadi Nemati</a>, 
<a href="/search/eess?searchtype=author&query=S%C3%A1nchez-Mart%C3%ADn%2C+P">Pedro S&#xe1;nchez-Mart&#xed;n</a>, 
<a href="/search/eess?searchtype=author&query=Baringo%2C+A">Ana Baringo</a>, 
<a href="/search/eess?searchtype=author&query=Ortega%2C+%C3%81">&#xc1;lvaro Ortega</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper proposes a novel single-level robust mathematical approach to
model the RES-only Virtual Power Plant (RVPP) bidding problem in the
simultaneous Day Ahead Market (DAM) and Secondary Reserve Market (SRM). The
worst-case profit of RVPP due to uncertainties related to electricity prices,
Non-dispatchable Renewable Energy Sources (ND-RES) production, and flexible
demand is captured. In order to find the worst-case profit in a single-level
model, the relationship between price and energy uncertainties leads to some
non-linear constraints, which are appropriately linearized. The simulation
results show the superiority of the proposed robust model compared to those in
the literature, as well as its computational efficiency.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02955" title="Abstract">arXiv:2403.02955</a> [<a href="/pdf/2403.02955" title="Download PDF">pdf</a>, <a href="/format/2403.02955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XAI-Based Detection of Adversarial Attacks on Deepfake Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pinhasov%2C+B">Ben Pinhasov</a>, 
<a href="/search/cs?searchtype=author&query=Lapid%2C+R">Raz Lapid</a>, 
<a href="/search/cs?searchtype=author&query=Ohayon%2C+R">Rony Ohayon</a>, 
<a href="/search/cs?searchtype=author&query=Sipper%2C+M">Moshe Sipper</a>, 
<a href="/search/cs?searchtype=author&query=Aperstein%2C+Y">Yehudit Aperstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We introduce a novel methodology for identifying adversarial attacks on
deepfake detectors using eXplainable Artificial Intelligence (XAI). In an era
characterized by digital advancement, deepfakes have emerged as a potent tool,
creating a demand for efficient detection systems. However, these systems are
frequently targeted by adversarial attacks that inhibit their performance. We
address this gap, developing a defensible deepfake detector by leveraging the
power of XAI. The proposed methodology uses XAI to generate interpretability
maps for a given method, providing explicit visualizations of decision-making
factors within the AI models. We subsequently employ a pretrained feature
extractor that processes both the input image and its corresponding XAI image.
The feature embeddings extracted from this process are then used for training a
simple yet effective classifier. Our approach contributes not only to the
detection of deepfakes but also enhances the understanding of possible
adversarial attacks, pinpointing potential vulnerabilities. Furthermore, this
approach does not change the performance of the deepfake detector. The paper
demonstrates promising results suggesting a potential pathway for future
deepfake detection mechanisms. We believe this study will serve as a valuable
contribution to the community, sparking much-needed discourse on safeguarding
deepfake detectors.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02957" title="Abstract">arXiv:2403.02957</a> [<a href="/pdf/2403.02957" title="Download PDF">pdf</a>, <a href="/format/2403.02957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Asymptotic Mean Square Error Optimality of Diffusion  Probabilistic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fesl%2C+B">Benedikt Fesl</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%B6ck%2C+B">Benedikt B&#xf6;ck</a>, 
<a href="/search/cs?searchtype=author&query=Strasser%2C+F">Florian Strasser</a>, 
<a href="/search/cs?searchtype=author&query=Baur%2C+M">Michael Baur</a>, 
<a href="/search/cs?searchtype=author&query=Joham%2C+M">Michael Joham</a>, 
<a href="/search/cs?searchtype=author&query=Utschick%2C+W">Wolfgang Utschick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Diffusion probabilistic models (DPMs) have recently shown great potential for
denoising tasks. Despite their practical utility, there is a notable gap in
their theoretical understanding. This paper contributes novel theoretical
insights by rigorously proving the asymptotic convergence of a specific DPM
denoising strategy to the mean square error (MSE)-optimal conditional mean
estimator (CME) over a large number of diffusion steps. The studied DPM-based
denoiser shares the training procedure of DPMs but distinguishes itself by
forwarding only the conditional mean during the reverse inference process after
training. We highlight the unique perspective that DPMs are composed of an
asymptotically optimal denoiser while simultaneously inheriting a powerful
generator by switching re-sampling in the reverse process on and off. The
theoretical findings are validated by numerical results.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02959" title="Abstract">arXiv:2403.02959</a> [<a href="/pdf/2403.02959" title="Download PDF">pdf</a>, <a href="/format/2403.02959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SimuCourt: Building Judicial Decision-Making Agents with Real-world  Judgement Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhitao He</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+P">Pengfei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhuoran Jin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yubo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiexin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huaijun Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiaojian Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the development of deep learning, natural language processing technology
has effectively improved the efficiency of various aspects of the traditional
judicial industry. However, most current efforts focus solely on individual
judicial stage, overlooking cross-stage collaboration. As the autonomous agents
powered by large language models are becoming increasingly smart and able to
make complex decisions in real-world settings, offering new insights for
judicial intelligence. In this paper, (1) we introduce SimuCourt, a judicial
benchmark that encompasses 420 judgment documents from real-world, spanning the
three most common types of judicial cases, and a novel task Judicial
Decision-Making to evaluate the judicial analysis and decision-making power of
agents. To support this task, we construct a large-scale judicial knowledge
base, JudicialKB, with multiple legal knowledge. (2) we propose a novel
multi-agent framework, AgentsCourt. Our framework follows the real-world
classic court trial process, consisting of court debate simulation, legal
information retrieval and judgement refinement to simulate the decision-making
of judge. (3) we perform extensive experiments, the results demonstrate that,
our framework outperforms the existing advanced methods in various aspects,
especially in generating legal grounds, where our model achieves significant
improvements of 8.6% and 9.1% F1 score in the first and second instance
settings, respectively.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02962" title="Abstract">arXiv:2403.02962</a> [<a href="/pdf/2403.02962" title="Download PDF">pdf</a>, <a href="/format/2403.02962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WikiTableEdit: A Benchmark for Table Editing by Natural Language  Instruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xiaojun Wan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Tabular data, as a crucial form of data representation, exists in diverse
formats on the Web. When confronted with complex and irregular tables, manual
modification becomes a laborious task. This paper investigates the performance
of Large Language Models (LLMs) in the context of table editing tasks. Existing
research mainly focuses on regular-shaped tables, wherein instructions are used
to generate code in SQL, Python, or Excel Office-script for manipulating the
tables. Nevertheless, editing tables with irregular structures, particularly
those containing merged cells spanning multiple rows, poses a challenge when
using code. To address this, we introduce the WikiTableEdit dataset. Leveraging
26,531 tables from the WikiSQL dataset, we automatically generate natural
language instructions for six distinct basic operations and the corresponding
outcomes, resulting in over 200,000 instances. Subsequently, we evaluate
several representative large language models on the WikiTableEdit dataset to
demonstrate the challenge of this task. The dataset will be released to the
community to promote related researches.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02963" title="Abstract">arXiv:2403.02963</a> [<a href="/pdf/2403.02963" title="Download PDF">pdf</a>, <a href="/ps/2403.02963" title="Download PostScript">ps</a>, <a href="/format/2403.02963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Opportunistic User Scheduling for Secure RIS-aided Wireless  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wafai%2C+B">Burhan Wafai</a>, 
<a href="/search/cs?searchtype=author&query=Ghose%2C+S">Sarbani Ghose</a>, 
<a href="/search/cs?searchtype=author&query=Kundu%2C+C">Chinmoy Kundu</a>, 
<a href="/search/cs?searchtype=author&query=Dubey%2C+A">Ankit Dubey</a>, 
<a href="/search/cs?searchtype=author&query=Flanagan%2C+M+F">Mark F. Flanagan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we provide expressions for the secrecy outage probability
(SOP) for suboptimal and optimal opportunistic scheduling schemes in a
reconfigurable intelligent surface (RIS) aided system with multiple
eavesdroppers in approximate closed form. A suboptimal scheduling (SS) scheme
is analyzed, which is used when the channel state information (CSI) of the
eavesdropping links is unavailable, and the optimal scheduling (OS) scheme is
also analyzed, which is used when the global CSI is available. For each scheme,
we provide a simplified expression for the SOP in the high signal-to-noise
ratio (SNR) regime to demonstrate its behavior as a function of the key system
parameters. At high SNR, the SOP saturates to a constant level which decreases
exponentially with the number of RIS elements in the SS scheme and with the
product of the number of RIS elements and the number of users in the OS scheme.
We compare the performance of the opportunistic user scheduling schemes with
that of a non-orthogonal multiple access (NOMA) based scheduling scheme which
chooses a pair of users in each time slot for scheduling and we show that the
opportunistic schemes outperform the NOMA-based scheme. We also derive a
closed-form expression for the SOP of a decode-and-forward (DF) relay-aided
scheduling scheme in order to compare it with that of the RIS-aided system. It
is found that the RIS-aided system outperforms the relay-aided systems when the
number of RIS elements is sufficiently large. An increased number of RIS
elements is required to outperform the relay-aided system at higher operating
frequencies.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02965" title="Abstract">arXiv:2403.02965</a> [<a href="/pdf/2403.02965" title="Download PDF">pdf</a>, <a href="/format/2403.02965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT and biometrics: an assessment of face recognition, gender  detection, and age estimation capabilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hassanpour%2C+A">Ahmad Hassanpour</a>, 
<a href="/search/cs?searchtype=author&query=Kowsari%2C+Y">Yasamin Kowsari</a>, 
<a href="/search/cs?searchtype=author&query=Shahreza%2C+H+O">Hatef Otroshi Shahreza</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Marcel%2C+S">Sebastien Marcel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper explores the application of large language models (LLMs), like
ChatGPT, for biometric tasks. We specifically examine the capabilities of
ChatGPT in performing biometric-related tasks, with an emphasis on face
recognition, gender detection, and age estimation. Since biometrics are
considered as sensitive information, ChatGPT avoids answering direct prompts,
and thus we crafted a prompting strategy to bypass its safeguard and evaluate
the capabilities for biometrics tasks. Our study reveals that ChatGPT
recognizes facial identities and differentiates between two facial images with
considerable accuracy. Additionally, experimental results demonstrate
remarkable performance in gender detection and reasonable accuracy for the age
estimation tasks. Our findings shed light on the promising potentials in the
application of LLMs and foundation models for biometrics.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02966" title="Abstract">arXiv:2403.02966</a> [<a href="/pdf/2403.02966" title="Download PDF">pdf</a>, <a href="/format/2403.02966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evidence-Focused Fact Summarization for Knowledge-Augmented Zero-Shot  Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ko%2C+S">Sungho Ko</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+H">Hyunjin Cho</a>, 
<a href="/search/cs?searchtype=author&query=Chae%2C+H">Hyungjoo Chae</a>, 
<a href="/search/cs?searchtype=author&query=Yeo%2C+J">Jinyoung Yeo</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongha Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent studies have investigated utilizing Knowledge Graphs (KGs) to enhance
Quesetion Answering (QA) performance of Large Language Models (LLMs), yet
structured KG verbalization remains challengin. Existing methods, such as
triple-form or free-form textual conversion of triple-form facts, encounter
several issues. These include reduced evidence density due to duplicated
entities or relationships, and reduced evidence clarity due to an inability to
emphasize crucial evidence. To address these issues, we propose EFSum, an
Evidence-focused Fact Summarization framework for enhanced QA with
knowledge-augmented LLMs. We optimize an open-source LLM as a fact summarizer
through distillation and preference alignment. Our extensive experiments show
that EFSum improves LLM's zero-shot QA performance, and it is possible to
ensure both the helpfulness and faithfulness of the summary.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02969" title="Abstract">arXiv:2403.02969</a> [<a href="/pdf/2403.02969" title="Download PDF">pdf</a>, <a href="/format/2403.02969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-modal Instruction Tuned LLMs with Fine-grained Visual Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junwen He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lijun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Huchuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jun-Yan He</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+J">Jin-Peng Lan</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuansong Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multimodal Large Language Model (MLLMs) leverages Large Language Models as a
cognitive framework for diverse visual-language tasks. Recent efforts have been
made to equip MLLMs with visual perceiving and grounding capabilities. However,
there still remains a gap in providing fine-grained pixel-level perceptions and
extending interactions beyond text-specific inputs. In this work, we propose
{\bf{AnyRef}}, a general MLLM model that can generate pixel-wise object
perceptions and natural language descriptions from multi-modality references,
such as texts, boxes, images, or audio. This innovation empowers users with
greater flexibility to engage with the model beyond textual and regional
prompts, without modality-specific designs. Through our proposed refocusing
mechanism, the generated grounding output is guided to better focus on the
referenced object, implicitly incorporating additional pixel-level supervision.
This simple modification utilizes attention scores generated during the
inference of LLM, eliminating the need for extra computations while exhibiting
performance enhancements in both grounding masks and referring expressions.
With only publicly available training data, our model achieves state-of-the-art
results across multiple benchmarks, including diverse modality referring
segmentation and region-level referring expression generation.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02971" title="Abstract">arXiv:2403.02971</a> [<a href="/pdf/2403.02971" title="Download PDF">pdf</a>, <a href="/ps/2403.02971" title="Download PostScript">ps</a>, <a href="/format/2403.02971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Space Complexity of Euclidean Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaoyi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuxiang Tian</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lingxiao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zengfeng Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by SoCG2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">The $(k, z)$-Clustering problem in Euclidean space $\mathbb{R}^d$ has been
extensively studied. Given the scale of data involved, compression methods for
the Euclidean $(k, z)$-Clustering problem, such as data compression and
dimension reduction, have received significant attention in the literature.
However, the space complexity of the clustering problem, specifically, the
number of bits required to compress the cost function within a multiplicative
error $\varepsilon$, remains unclear in existing literature.
<br />This paper initiates the study of space complexity for Euclidean $(k,
z)$-Clustering and offers both upper and lower bounds. Our space bounds are
nearly tight when $k$ is constant, indicating that storing a coreset, a
well-known data compression approach, serves as the optimal compression scheme.
Furthermore, our lower bound result for $(k, z)$-Clustering establishes a tight
space bound of $\Theta( n d )$ for terminal embedding, where $n$ represents the
dataset size. Our technical approach leverages new geometric insights for
principal angles and discrepancy methods, which may hold independent interest.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02972" title="Abstract">arXiv:2403.02972</a> [<a href="/pdf/2403.02972" title="Download PDF">pdf</a>, <a href="/ps/2403.02972" title="Download PostScript">ps</a>, <a href="/format/2403.02972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bodioid: philosophical reflections on the hybrid of bodies and artefacts  towards post-human
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiang Xu</a> (1), 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Gang Sun</a> (1), 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jingyu Xu</a> (1), 
<a href="/search/cs?searchtype=author&query=Su%2C+P">Pujie Su</a> (1) ((1) Tongji University, College of Design and Innovation, Shanghai, China.)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The advent of the post-human era has blurred the boundary between the body
and artifacts. Further, external materials and information are more deeply
integrated into the body, making emerging technology a key driving force for
shaping post-human existence and promoting bodily evolution. Based on this,
this study analyses the transformation process of three technological forms,
namely tools, machines, and cyborgs, and reveals the construction of bodies and
artifacts. From the phenomenological perspective, the essences of body and
artifact existences are reflected upon, and the existence is construction
viewpoint is proposed. Furthermore, a technological design concept, bodioid, is
proposed to meticulously depict the characteristics of integrating similarities
and differences towards unity between the body and artifacts, based on the
theoretical foundation of technology mediation and the materialization of
morality. Finally, through analogizing the organizational form of language, the
two key forms and specific mechanisms of bodioid construction, namely extension
and mirroring, are indicated. With this in mind, the post-human existence
landscape is discussed with the objective of providing theoretical insights
into the study of the underlying philosophical principles of technological
design.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02974" title="Abstract">arXiv:2403.02974</a> [<a href="/pdf/2403.02974" title="Download PDF">pdf</a>, <a href="/format/2403.02974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Learning of Human Constraints from Feedback in Shared Autonomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shibei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T+N">Tran Nguyen Le</a>, 
<a href="/search/cs?searchtype=author&query=Kaski%2C+S">Samuel Kaski</a>, 
<a href="/search/cs?searchtype=author&query=Kyrki%2C+V">Ville Kyrki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI-24 Bridge Program on Collaborative AI and Modeling of Humans &amp; AAAI-24 Workshop on Ad Hoc Teamwork
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Real-time collaboration with humans poses challenges due to the different
behavior patterns of humans resulting from diverse physical constraints.
Existing works typically focus on learning safety constraints for
collaboration, or how to divide and distribute the subtasks between the
participating agents to carry out the main task. In contrast, we propose to
learn a human constraints model that, in addition, considers the diverse
behaviors of different human operators. We consider a type of collaboration in
a shared-autonomy fashion, where both a human operator and an assistive robot
act simultaneously in the same task space that affects each other's actions.
The task of the assistive agent is to augment the skill of humans to perform a
shared task by supporting humans as much as possible, both in terms of reducing
the workload and minimizing the discomfort for the human operator. Therefore,
we propose an augmentative assistant agent capable of learning and adapting to
human physical constraints, aligning its actions with the ergonomic preferences
and limitations of the human operator.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02975" title="Abstract">arXiv:2403.02975</a> [<a href="/pdf/2403.02975" title="Download PDF">pdf</a>, <a href="/format/2403.02975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A General and Flexible Multi-concept Parsing Framework for Multilingual  Semantic Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+D">Dong Yao</a>, 
<a href="/search/cs?searchtype=author&query=Alghamdi%2C+A">Asaad Alghamdi</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Q">Qingrong Xia</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+X">Xiaoye Qu</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+X">Xinyu Duan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhefeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Huai%2C+B">Baoxing Huai</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Peilun Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhou Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Sentence semantic matching is a research hotspot in natural language
processing, which is considerably significant in various key scenarios, such as
community question answering, searching, chatbot, and recommendation. Since
most of the advanced models directly model the semantic relevance among words
between two sentences while neglecting the \textit{keywords} and
\textit{intents} concepts of them, DC-Match is proposed to disentangle keywords
from intents and utilizes them to optimize the matching performance. Although
DC-Match is a simple yet effective method for semantic matching, it highly
depends on the external NER techniques to identify the keywords of sentences,
which limits the performance of semantic matching for minor languages since
satisfactory NER tools are usually hard to obtain. In this paper, we propose to
generally and flexibly resolve the text into multi concepts for multilingual
semantic matching to liberate the model from the reliance on NER models. To
this end, we devise a \underline{M}ulti-\underline{C}oncept \underline{P}arsed
\underline{S}emantic \underline{M}atching framework based on the pre-trained
language models, abbreviated as \textbf{MCP-SM}, to extract various concepts
and infuse them into the classification tokens. We conduct comprehensive
experiments on English datasets QQP and MRPC, and Chinese dataset Medical-SM.
Besides, we experiment on Arabic datasets MQ2Q and XNLI, the outstanding
performance further prove MCP-SM's applicability in low-resource languages.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02977" title="Abstract">arXiv:2403.02977</a> [<a href="/pdf/2403.02977" title="Download PDF">pdf</a>, <a href="/format/2403.02977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Iterative Region Inflation for Computing Large 2-D/3-D Convex  Regions of Obstacle-Free Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qianhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhepei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+F">Fei Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">1) Restrictive Inflation is designed to ensure the managibility of the
generated convex polytope. Based on its characteristic of few variables but
rich constraints, an efficient and numerically stable solver is designed. 2) A
novel method that formulates the MVIE problem into SOCP formulation is
proposed, which avoids directly confronting the positive definite constraints
and improves the computational efficiency. 3) Especially for 2-D MVIE, a
linear-time exact algorithm is introduced for the first time, filling a gap
that existed for several decades and further enabling ultra-fast computational
performance. 4) Building upon the above methods, a reliable convex polytope
generation algorithm FIRI is proposed. Extensive experiments verify its
superior comprehensive performance in terms of quality, efficiency, and
managibility. High-performance implementation of FIRI will be open-sourced for
the reference of the community.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02981" title="Abstract">arXiv:2403.02981</a> [<a href="/pdf/2403.02981" title="Download PDF">pdf</a>, <a href="/format/2403.02981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Doubly Abductive Counterfactual Inference for Text-based Image Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xue Song</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jiequan Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanwang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingjing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+R">Richang Hong</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu-Gang Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We study text-based image editing (TBIE) of a single image by counterfactual
inference because it is an elegant formulation to precisely address the
requirement: the edited image should retain the fidelity of the original one.
Through the lens of the formulation, we find that the crux of TBIE is that
existing techniques hardly achieve a good trade-off between editability and
fidelity, mainly due to the overfitting of the single-image fine-tuning. To
this end, we propose a Doubly Abductive Counterfactual inference framework
(DAC). We first parameterize an exogenous variable as a UNet LoRA, whose
abduction can encode all the image details. Second, we abduct another exogenous
variable parameterized by a text encoder LoRA, which recovers the lost
editability caused by the overfitted first abduction. Thanks to the second
abduction, which exclusively encodes the visual transition from post-edit to
pre-edit, its inversion -- subtracting the LoRA -- effectively reverts pre-edit
back to post-edit, thereby accomplishing the edit. Through extensive
experiments, our DAC achieves a good trade-off between editability and
fidelity. Thus, we can support a wide spectrum of user editing intents,
including addition, removal, manipulation, replacement, style transfer, and
facial change, which are extensively validated in both qualitative and
quantitative evaluations. Codes are in https://github.com/xuesong39/DAC.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02983" title="Abstract">arXiv:2403.02983</a> [<a href="/pdf/2403.02983" title="Download PDF">pdf</a>, <a href="/format/2403.02983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning Under Attack: Exposing Vulnerabilities through Data  Poisoning Attacks in Computer Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nowroozi%2C+E">Ehsan Nowroozi</a>, 
<a href="/search/cs?searchtype=author&query=Haider%2C+I">Imran Haider</a>, 
<a href="/search/cs?searchtype=author&query=Taheri%2C+R">Rahim Taheri</a>, 
<a href="/search/cs?searchtype=author&query=Conti%2C+M">Mauro Conti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Federated Learning (FL) is a machine learning (ML) approach that enables
multiple decentralized devices or edge servers to collaboratively train a
shared model without exchanging raw data. During the training and sharing of
model updates between clients and servers, data and models are susceptible to
different data-poisoning attacks.
<br />In this study, our motivation is to explore the severity of data poisoning
attacks in the computer network domain because they are easy to implement but
difficult to detect. We considered two types of data-poisoning attacks, label
flipping (LF) and feature poisoning (FP), and applied them with a novel
approach. In LF, we randomly flipped the labels of benign data and trained the
model on the manipulated data. For FP, we randomly manipulated the highly
contributing features determined using the Random Forest algorithm. The
datasets used in this experiment were CIC and UNSW related to computer
networks. We generated adversarial samples using the two attacks mentioned
above, which were applied to a small percentage of datasets. Subsequently, we
trained and tested the accuracy of the model on adversarial datasets. We
recorded the results for both benign and manipulated datasets and observed
significant differences between the accuracy of the models on different
datasets. From the experimental results, it is evident that the LF attack
failed, whereas the FP attack showed effective results, which proved its
significance in fooling a server. With a 1% LF attack on the CIC, the accuracy
was approximately 0.0428 and the ASR was 0.9564; hence, the attack is easily
detectable, while with a 1% FP attack, the accuracy and ASR were both
approximately 0.9600, hence, FP attacks are difficult to detect. We repeated
the experiment with different poisoning percentages.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02985" title="Abstract">arXiv:2403.02985</a> [<a href="/pdf/2403.02985" title="Download PDF">pdf</a>, <a href="/format/2403.02985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolution Transformer: In-Context Evolutionary Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lange%2C+R+T">Robert Tjarko Lange</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yingtao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yujin Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Evolutionary optimization algorithms are often derived from loose biological
analogies and struggle to leverage information obtained during the sequential
course of optimization. An alternative promising approach is to leverage data
and directly discover powerful optimization principles via meta-optimization.
In this work, we follow such a paradigm and introduce Evolution Transformer, a
causal Transformer architecture, which can flexibly characterize a family of
Evolution Strategies. Given a trajectory of evaluations and search distribution
statistics, Evolution Transformer outputs a performance-improving update to the
search distribution. The architecture imposes a set of suitable inductive
biases, i.e. the invariance of the distribution update to the order of
population members within a generation and equivariance to the order of the
search dimensions. We train the model weights using Evolutionary Algorithm
Distillation, a technique for supervised optimization of sequence models using
teacher algorithm trajectories. The resulting model exhibits strong in-context
optimization performance and shows strong generalization capabilities to
otherwise challenging neuroevolution tasks. We analyze the resulting properties
of the Evolution Transformer and propose a technique to fully
self-referentially train the Evolution Transformer, starting from a random
initialization and bootstrapping its own learning progress. We provide an open
source implementation under https://github.com/RobertTLange/evosax.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02990" title="Abstract">arXiv:2403.02990</a> [<a href="/pdf/2403.02990" title="Download PDF">pdf</a>, <a href="/format/2403.02990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Augmentation using LLMs: Data Perspectives, Learning Paradigms and  Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+B">Bosheng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+C">Chengwei Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Ruochen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+T">Tianze Luo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinze Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guizhen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+W">Wenhan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Junjie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+A+T">Anh Tuan Luu</a>, 
<a href="/search/cs?searchtype=author&query=Joty%2C+S">Shafiq Joty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the rapidly evolving field of machine learning (ML), data augmentation
(DA) has emerged as a pivotal technique for enhancing model performance by
diversifying training examples without the need for additional data collection.
This survey explores the transformative impact of Large Language Models (LLMs)
on DA, particularly addressing the unique challenges and opportunities they
present in the context of natural language processing (NLP) and beyond. From a
data perspective and a learning perspective, we examine various strategies that
utilize Large Language Models for data augmentation, including a novel
exploration of learning paradigms where LLM-generated data is used for further
training. Additionally, this paper delineates the primary challenges faced in
this domain, ranging from controllable data augmentation to multi modal data
augmentation. This survey highlights the paradigm shift introduced by LLMs in
DA, aims to serve as a foundational guide for researchers and practitioners in
this field.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02991" title="Abstract">arXiv:2403.02991</a> [<a href="/pdf/2403.02991" title="Download PDF">pdf</a>, <a href="/format/2403.02991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MADTP: Multimodal Alignment-Guided Dynamic Token Pruning for  Accelerating Vision-Language Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jianjian Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+P">Peng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shengze Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yansong Tang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiwen Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 9 figures, Published in CVPR2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proc. IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision-Language Transformers (VLTs) have shown great success recently, but
are meanwhile accompanied by heavy computation costs, where a major reason can
be attributed to the large number of visual and language tokens. Existing token
pruning research for compressing VLTs mainly follows a single-modality-based
scheme yet ignores the critical role of aligning different modalities for
guiding the token pruning process, causing the important tokens for one
modality to be falsely pruned in another modality branch. Meanwhile, existing
VLT pruning works also lack the flexibility to dynamically compress each layer
based on different input samples. To this end, we propose a novel framework
named Multimodal Alignment-Guided Dynamic Token Pruning (MADTP) for
accelerating various VLTs. Specifically, we first introduce a well-designed
Multi-modality Alignment Guidance (MAG) module that can align features of the
same semantic concept from different modalities, to ensure the pruned tokens
are less important for all modalities. We further design a novel Dynamic Token
Pruning (DTP) module, which can adaptively adjust the token compression ratio
in each layer based on different input instances. Extensive experiments on
various benchmarks demonstrate that MADTP significantly reduces the
computational complexity of kinds of multimodal models while preserving
competitive performance. Notably, when applied to the BLIP model in the NLVR2
dataset, MADTP can reduce the GFLOPs by 80% with less than 4% performance
degradation.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02993" title="Abstract">arXiv:2403.02993</a> [<a href="/pdf/2403.02993" title="Download PDF">pdf</a>, <a href="/format/2403.02993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Localized Zeroth-Order Prompt Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wenyang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+Y">Yao Shu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zongmin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhaoxuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiangqiang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Z">Zhongxiang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+S">See-Kiong Ng</a>, 
<a href="/search/cs?searchtype=author&query=Low%2C+B+K+H">Bryan Kian Hsiang Low</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The efficacy of large language models (LLMs) in understanding and generating
natural language has aroused a wide interest in developing prompt-based methods
to harness the power of black-box LLMs. Existing methodologies usually
prioritize a global optimization for finding the global optimum, which however
will perform poorly in certain tasks. This thus motivates us to re-think the
necessity of finding a global optimum in prompt optimization. To answer this,
we conduct a thorough empirical study on prompt optimization and draw two major
insights. Contrasting with the rarity of global optimum, local optima are
usually prevalent and well-performed, which can be more worthwhile for
efficient prompt optimization (Insight I). The choice of the input domain,
covering both the generation and the representation of prompts, affects the
identification of well-performing local optima (Insight II). Inspired by these
insights, we propose a novel algorithm, namely localized zeroth-order prompt
optimization (ZOPO), which incorporates a Neural Tangent Kernel-based derived
Gaussian process into standard zeroth-order optimization for an efficient
search of well-performing local optima in prompt optimization. Remarkably, ZOPO
outperforms existing baselines in terms of both the optimization performance
and the query efficiency, which we demonstrate through extensive experiments.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02995" title="Abstract">arXiv:2403.02995</a> [<a href="/pdf/2403.02995" title="Download PDF">pdf</a>, <a href="/format/2403.02995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Label Flipping Attacks in Malicious URL Detectors Using  Ensemble Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nowroozi%2C+E">Ehsan Nowroozi</a>, 
<a href="/search/cs?searchtype=author&query=Jadalla%2C+N">Nada Jadalla</a>, 
<a href="/search/cs?searchtype=author&query=Ghelichkhani%2C+S">Samaneh Ghelichkhani</a>, 
<a href="/search/cs?searchtype=author&query=Jolfaei%2C+A">Alireza Jolfaei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Malicious URLs provide adversarial opportunities across various industries,
including transportation, healthcare, energy, and banking which could be
detrimental to business operations. Consequently, the detection of these URLs
is of crucial importance; however, current Machine Learning (ML) models are
susceptible to backdoor attacks. These attacks involve manipulating a small
percentage of training data labels, such as Label Flipping (LF), which changes
benign labels to malicious ones and vice versa. This manipulation results in
misclassification and leads to incorrect model behavior. Therefore, integrating
defense mechanisms into the architecture of ML models becomes an imperative
consideration to fortify against potential attacks.
<br />The focus of this study is on backdoor attacks in the context of URL
detection using ensemble trees. By illuminating the motivations behind such
attacks, highlighting the roles of attackers, and emphasizing the critical
importance of effective defense strategies, this paper contributes to the
ongoing efforts to fortify ML models against adversarial threats within the ML
domain in network security. We propose an innovative alarm system that detects
the presence of poisoned labels and a defense mechanism designed to uncover the
original class labels with the aim of mitigating backdoor attacks on ensemble
tree classifiers. We conducted a case study using the Alexa and Phishing Site
URL datasets and showed that LF attacks can be addressed using our proposed
defense mechanism. Our experimental results prove that the LF attack achieved
an Attack Success Rate (ASR) between 50-65% within 2-5%, and the innovative
defense method successfully detected poisoned labels with an accuracy of up to
100%.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02996" title="Abstract">arXiv:2403.02996</a> [<a href="/pdf/2403.02996" title="Download PDF">pdf</a>, <a href="/ps/2403.02996" title="Download PostScript">ps</a>, <a href="/format/2403.02996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Convex Optimization Framework for Computing Robustness Margins of  Kalman Filters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Prabhat%2C+H">Himanshu Prabhat</a>, 
<a href="/search/eess?searchtype=author&query=Bhattacharya%2C+R">Raktim Bhattacharya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC); Applications (stat.AP)

</div>
<p class="mathjax">This paper proposes a novel convex optimization framework for designing
robust Kalman filters that guarantee a user-specified steady-state error while
maximizing process and sensor noise. The proposed framework simultaneously
determines the Kalman gain and the robustness margin in terms of the process
and sensor noise. This is the first paper to present such a joint formulation
for Kalman filtering. The proposed methodology is validated through two
distinct examples: the Clohessy-Wiltshire-Hill equations for a chaser
spacecraft in an elliptical orbit and the longitudinal motion model of an F-16
aircraft.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02997" title="Abstract">arXiv:2403.02997</a> [<a href="/pdf/2403.02997" title="Download PDF">pdf</a>, <a href="/format/2403.02997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cover Edge-Based Novel Triangle Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bader%2C+D+A">David A. Bader</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fuhuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zhihui Du</a>, 
<a href="/search/cs?searchtype=author&query=Pauliuchenka%2C+P">Palina Pauliuchenka</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+O+A">Oliver Alvarado Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Anant Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Minnal%2C+S+S+V">Sai Sri Vastav Minnal</a>, 
<a href="/search/cs?searchtype=author&query=Nahata%2C+V">Valmik Nahata</a>, 
<a href="/search/cs?searchtype=author&query=Ganeshan%2C+A">Anya Ganeshan</a>, 
<a href="/search/cs?searchtype=author&query=Gundogdu%2C+A">Ahmet Gundogdu</a>, 
<a href="/search/cs?searchtype=author&query=Lew%2C+J">Jason Lew</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Listing and counting triangles in graphs is a key algorithmic kernel for
network analyses, including community detection, clustering coefficients,
k-trusses, and triangle centrality. In this paper, we propose the novel concept
of a cover-edge set that can be used to find triangles more efficiently.
Leveraging the breadth-first search (BFS) method, we can quickly generate a
compact cover-edge set. Novel sequential and parallel triangle counting
algorithms that employ cover-edge sets are presented. The novel sequential
algorithm performs competitively with the fastest previous approaches on both
real and synthetic graphs, such as those from the Graph500 Benchmark and the
MIT/Amazon/IEEE Graph Challenge. We implement 22 sequential algorithms for
performance evaluation and comparison. At the same time, we employ OpenMP to
parallelize 11 sequential algorithms, presenting an in-depth analysis of their
parallel performance. Furthermore, we develop a distributed parallel algorithm
that can asymptotically reduce communication on massive graphs. In our estimate
from massive-scale Graph500 graphs, our distributed parallel algorithm can
reduce the communication on a scale~36 graph by 1156x and on a scale~42 graph
by 2368x. Comprehensive experiments are conducted on the recently launched
Intel Xeon 8480+ processor and shed light on how graph attributes, such as
topology, diameter, and degree distribution, can affect the performance of
these algorithms.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02998" title="Abstract">arXiv:2403.02998</a> [<a href="/pdf/2403.02998" title="Download PDF">pdf</a>, <a href="/format/2403.02998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Calibrated Deep Clustering Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yuheng Jia</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jianhong Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Junhui Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep clustering has exhibited remarkable performance; however, the
overconfidence problem, i.e., the estimated confidence for a sample belonging
to a particular cluster greatly exceeds its actual prediction accuracy, has
been overlooked in prior research. To tackle this critical issue, we pioneer
the development of a calibrated deep clustering framework. Specifically, we
propose a novel dual-head deep clustering pipeline that can effectively
calibrate the estimated confidence and the actual accuracy. The calibration
head adjusts the overconfident predictions of the clustering head using
regularization methods, generating prediction confidence and pseudo-labels that
match the model learning status. This calibration process also guides the
clustering head in dynamically selecting reliable high-confidence samples for
training. Additionally, we introduce an effective network initialization
strategy that enhances both training speed and network robustness. Extensive
experiments demonstrate the proposed calibrated deep clustering framework not
only surpasses state-of-the-art deep clustering methods by approximately 10
times in terms of expected calibration error but also significantly outperforms
them in terms of clustering accuracy.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03002" title="Abstract">arXiv:2403.03002</a> [<a href="/pdf/2403.03002" title="Download PDF">pdf</a>, <a href="/ps/2403.03002" title="Download PostScript">ps</a>, <a href="/format/2403.03002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mem-elements based Neuromorphic Hardware for Neural Network Application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Ankur Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Master's Thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)

</div>
<p class="mathjax">The thesis investigates the utilization of memristive and memcapacitive
crossbar arrays in low-power machine learning accelerators, offering a
comprehensive co-design framework for deep neural networks (DNN). The model,
implemented through a hybrid Python and PyTorch approach, accounts for various
non-idealities, achieving exceptional training accuracies of 90.02% and 91.03%
for the CIFAR-10 dataset with memristive and memcapacitive crossbar arrays on
an 8-layer VGG network. Additionally, the thesis introduces a novel approach to
emulate meminductor devices using Operational Transconductance Amplifiers (OTA)
and capacitors, showcasing adjustable behavior. Transistor-level simulations in
180 nm CMOS technology, operating at 60 MHz, demonstrate the proposed
meminductor emulator's viability with a power consumption of 0.337 mW. The
design is further validated in neuromorphic circuits and CNN accelerators,
achieving training and testing accuracies of 91.04% and 88.82%, respectively.
Notably, the exclusive use of MOS transistors ensures the feasibility of
monolithic IC fabrication. This research significantly contributes to the
exploration of advanced hardware solutions for efficient and high-performance
machine-learning applications.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03003" title="Abstract">arXiv:2403.03003</a> [<a href="/pdf/2403.03003" title="Download PDF">pdf</a>, <a href="/format/2403.03003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feast Your Eyes: Mixture-of-Resolution Adaptation for Multimodal Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+G">Gen Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yiyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiawu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaoshuai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+R">Rongrong Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite remarkable progress, existing multimodal large language models
(MLLMs) are still inferior in granular visual recognition. Contrary to previous
works, we study this problem from the perspective of image resolution, and
reveal that a combination of low- and high-resolution visual features can
effectively mitigate this shortcoming. Based on this observation, we propose a
novel and efficient method for MLLMs, termed Mixture-of-Resolution Adaptation
(MRA). In particular, MRA adopts two visual pathways for images with different
resolutions, where high-resolution visual information is embedded into the
low-resolution pathway via the novel mixture-of-resolution adapters
(MR-Adapters). This design also greatly reduces the input sequence length of
MLLMs. To validate MRA, we apply it to a recent MLLM called LLaVA, and term the
new model LLaVA-HR. We conduct extensive experiments on 11 vision-language (VL)
tasks, which show that LLaVA-HR outperforms existing MLLMs on 8 VL tasks, e.g.,
+9.4% on TextVQA. More importantly, both training and inference of LLaVA-HR
remain efficient with MRA, e.g., 20 training hours and 3$\times$ inference
speed than LLaVA-1.5. Source codes are released at:
https://github.com/luogen1996/LLaVA-HR.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03005" title="Abstract">arXiv:2403.03005</a> [<a href="/pdf/2403.03005" title="Download PDF">pdf</a>, <a href="/format/2403.03005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit-Explicit simulation of Mass-Spring-Charge Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhaocheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Papanicolopulos%2C+S">Stefanos Papanicolopulos</a>, 
<a href="/search/cs?searchtype=author&query=Subr%2C+K">Kartic Subr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">Point masses connected by springs, or mass-spring systems, are widely used in
computer animation to approximate the behavior of deformable objects. One of
the restrictions imposed by these models is that points that are not
topologically constrained (linked by a spring) are unable to interact with each
other explicitly. Such interactions would introduce a new dimension for
artistic control and animation within the computer graphics community. Beyond
graphics, such a model could be an effective proxy to use for model-based
learning of complex physical systems such as molecular biology. We propose to
imbue masses in a mass-spring system with electrostatic charge leading a system
with internal forces between all pairs of charged points -- regardless of
whether they are linked by a spring. We provide a practical and stable
algorithm to simulate charged mass-spring systems over long time horizons. We
demonstrate how these systems may be controlled via parameters such as guidance
electric fields or external charges, thus presenting fresh opportunities for
artistic authoring. Our method is especially appropriate for computer graphics
applications due to its robustness at larger simulation time steps.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03008" title="Abstract">arXiv:2403.03008</a> [<a href="/pdf/2403.03008" title="Download PDF">pdf</a>, <a href="/format/2403.03008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Graphs as Context Sources for LLM-Based Explanations of  Learning Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abu-Rasheed%2C+H">Hasan Abu-Rasheed</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+C">Christian Weber</a>, 
<a href="/search/cs?searchtype=author&query=Fathi%2C+M">Madjid Fathi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In the era of personalized education, the provision of comprehensible
explanations for learning recommendations is of a great value to enhance the
learner's understanding and engagement with the recommended learning content.
Large language models (LLMs) and generative AI in general have recently opened
new doors for generating human-like explanations, for and along learning
recommendations. However, their precision is still far away from acceptable in
a sensitive field like education. To harness the abilities of LLMs, while still
ensuring a high level of precision towards the intent of the learners, this
paper proposes an approach to utilize knowledge graphs (KG) as a source of
factual context, for LLM prompts, reducing the risk of model hallucinations,
and safeguarding against wrong or imprecise information, while maintaining an
application-intended learning context. We utilize the semantic relations in the
knowledge graph to offer curated knowledge about learning recommendations. With
domain-experts in the loop, we design the explanation as a textual template,
which is filled and completed by the LLM. Domain experts were integrated in the
prompt engineering phase as part of a study, to ensure that explanations
include information that is relevant to the learner. We evaluate our approach
quantitatively using Rouge-N and Rouge-L measures, as well as qualitatively
with experts and learners. Our results show an enhanced recall and precision of
the generated explanations compared to those generated solely by the GPT model,
with a greatly reduced risk of generating imprecise information in the final
learning explanation.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03014" title="Abstract">arXiv:2403.03014</a> [<a href="/pdf/2403.03014" title="Download PDF">pdf</a>, <a href="/format/2403.03014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Case for Evaluating Multimodal Translation Models on Text Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vijayan%2C+V">Vipin Vijayan</a>, 
<a href="/search/cs?searchtype=author&query=Bowen%2C+B">Braeden Bowen</a>, 
<a href="/search/cs?searchtype=author&query=Grigsby%2C+S">Scott Grigsby</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+T">Timothy Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Gwinnup%2C+J">Jeremy Gwinnup</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">A good evaluation framework should evaluate multimodal machine translation
(MMT) models by measuring 1) their use of visual information to aid in the
translation task and 2) their ability to translate complex sentences such as
done for text-only machine translation. However, most current work in MMT is
evaluated against the Multi30k testing sets, which do not measure these
properties. Namely, the use of visual information by the MMT model cannot be
shown directly from the Multi30k test set results and the sentences in Multi30k
are are image captions, i.e., short, descriptive sentences, as opposed to
complex sentences that typical text-only machine translation models are
evaluated against.
<br />Therefore, we propose that MMT models be evaluated using 1) the CoMMuTE
evaluation framework, which measures the use of visual information by MMT
models, 2) the text-only WMT news translation task test sets, which evaluates
translation performance against complex sentences, and 3) the Multi30k test
sets, for measuring MMT model performance against a real MMT dataset. Finally,
we evaluate recent MMT models trained solely against the Multi30k dataset
against our proposed evaluation framework and demonstrate the dramatic drop
performance against text-only testing sets compared to recent text-only MT
models.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03015" title="Abstract">arXiv:2403.03015</a> [<a href="/pdf/2403.03015" title="Download PDF">pdf</a>, <a href="/format/2403.03015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low Complexity Channel Estimation for RIS-Assisted THz Systems with Beam  Split
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+X">Xin Su</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ruisi He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+B">Bo Ai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">To support extremely high data rates, reconfigurable intelligent surface
(RIS)-assisted terahertz (THz) communication is considered to be a promising
technology for future sixth-generation networks. However, due to the typical
employment of hybrid beamforming architecture in THz systems, as well as the
passive nature of RIS which lacks the capability to process pilot signals,
obtaining channel state information (CSI) is facing significant challenges. To
accurately estimate the cascaded channel, we propose a novel low-complexity
channel estimation scheme, which includes three steps. Specifically, we first
estimate full CSI within a small subset of subcarriers (SCs). Then, we acquire
angular information at base station and RIS based on the full CSI. Finally, we
derive spatial directions and recover full-CSI for the remaining SCs.
Theoretical analysis and simulation results demonstrate that the proposed
scheme can achieve superior performance in terms of normalized
mean-square-error and exhibit a lower computational complexity compared with
the existing algorithms.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03017" title="Abstract">arXiv:2403.03017</a> [<a href="/pdf/2403.03017" title="Download PDF">pdf</a>, <a href="/format/2403.03017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied  Instruction Following
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Haochen Shi</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhiyuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xingdi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=C%C3%B4t%C3%A9%2C+M">Marc-Alexandre C&#xf4;t&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Embodied Instruction Following (EIF) is a crucial task in embodied learning,
requiring agents to interact with their environment through egocentric
observations to fulfill natural language instructions. Recent advancements have
seen a surge in employing large language models (LLMs) within a
framework-centric approach to enhance performance in embodied learning tasks,
including EIF. Despite these efforts, there exists a lack of a unified
understanding regarding the impact of various components-ranging from visual
perception to action execution-on task performance. To address this gap, we
introduce OPEx, a comprehensive framework that delineates the core components
essential for solving embodied learning tasks: Observer, Planner, and Executor.
Through extensive evaluations, we provide a deep analysis of how each component
influences EIF task performance. Furthermore, we innovate within this space by
deploying a multi-agent dialogue strategy on a TextWorld counterpart, further
enhancing task performance. Our findings reveal that LLM-centric design
markedly improves EIF outcomes, identify visual perception and low-level action
execution as critical bottlenecks, and demonstrate that augmenting LLMs with a
multi-agent framework further elevates performance.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03018" title="Abstract">arXiv:2403.03018</a> [<a href="/pdf/2403.03018" title="Download PDF">pdf</a>, <a href="/format/2403.03018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CRISPR: Ensemble Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rostami%2C+M">Mohammad Rostami</a>, 
<a href="/search/cs?searchtype=author&query=Ghariyazi%2C+A">Amin Ghariyazi</a>, 
<a href="/search/cs?searchtype=author&query=Dashti%2C+H">Hamed Dashti</a>, 
<a href="/search/cs?searchtype=author&query=Rohban%2C+M+H">Mohammad Hossein Rohban</a>, 
<a href="/search/cs?searchtype=author&query=Rabiee%2C+H+R">Hamid R. Rabiee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Genomics (q-bio.GN)

</div>
<p class="mathjax">Clustered Regularly Interspaced Short Palindromic Repeats (CRISPR) is a gene
editing technology that has revolutionized the fields of biology and medicine.
However, one of the challenges of using CRISPR is predicting the on-target
efficacy and off-target sensitivity of single-guide RNAs (sgRNAs). This is
because most existing methods are trained on separate datasets with different
genes and cells, which limits their generalizability. In this paper, we propose
a novel ensemble learning method for sgRNA design that is accurate and
generalizable. Our method combines the predictions of multiple machine learning
models to produce a single, more robust prediction. This approach allows us to
learn from a wider range of data, which improves the generalizability of our
model. We evaluated our method on a benchmark dataset of sgRNA designs and
found that it outperformed existing methods in terms of both accuracy and
generalizability. Our results suggest that our method can be used to design
sgRNAs with high sensitivity and specificity, even for new genes or cells. This
could have important implications for the clinical use of CRISPR, as it would
allow researchers to design more effective and safer treatments for a variety
of diseases.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03020" title="Abstract">arXiv:2403.03020</a> [<a href="/pdf/2403.03020" title="Download PDF">pdf</a>, <a href="/format/2403.03020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SplAgger: Split Aggregation for Meta-Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beck%2C+J">Jacob Beck</a>, 
<a href="/search/cs?searchtype=author&query=Jackson%2C+M">Matthew Jackson</a>, 
<a href="/search/cs?searchtype=author&query=Vuorio%2C+R">Risto Vuorio</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zheng Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Whiteson%2C+S">Shimon Whiteson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A core ambition of reinforcement learning (RL) is the creation of agents
capable of rapid learning in novel tasks. Meta-RL aims to achieve this by
directly learning such agents. One category of meta-RL methods, called black
box methods, does so by training off-the-shelf sequence models end-to-end. In
contrast, another category of methods have been developed that explicitly infer
a posterior distribution over the unknown task. These methods generally have
distinct objectives and sequence models designed to enable task inference, and
so are known as task inference methods. However, recent evidence suggests that
task inference objectives are unnecessary in practice. Nonetheless, it remains
unclear whether task inference sequence models are beneficial even when task
inference objectives are not. In this paper, we present strong evidence that
task inference sequence models are still beneficial. In particular, we
investigate sequence models with permutation invariant aggregation, which
exploit the fact that, due to the Markov property, the task posterior does not
depend on the order of data. We empirically confirm the advantage of
permutation invariant sequence models without the use of task inference
objectives. However, we also find, surprisingly, that there are multiple
conditions under which permutation variance remains useful. Therefore, we
propose SplAgger, which uses both permutation variant and invariant components
to achieve the best of both worlds, outperforming all baselines on continuous
control and memory environments.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03021" title="Abstract">arXiv:2403.03021</a> [<a href="/pdf/2403.03021" title="Download PDF">pdf</a>, <a href="/format/2403.03021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating the convergence of Newton&#x27;s method for nonlinear elliptic  PDEs using Fourier neural operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aghili%2C+J">Joubine Aghili</a>, 
<a href="/search/math?searchtype=author&query=Franck%2C+E">Emmanuel Franck</a>, 
<a href="/search/math?searchtype=author&query=Hild%2C+R">Romain Hild</a>, 
<a href="/search/math?searchtype=author&query=Michel-Dansac%2C+V">Victor Michel-Dansac</a>, 
<a href="/search/math?searchtype=author&query=Vigon%2C+V">Vincent Vigon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">It is well known that Newton's method, especially when applied to large
problems such as the discretization of nonlinear partial differential equations
(PDEs), can have trouble converging if the initial guess is too far from the
solution. This work focuses on accelerating this convergence, in the context of
the discretization of nonlinear elliptic PDEs. We first provide a quick review
of existing methods, and justify our choice of learning an initial guess with a
Fourier neural operator (FNO). This choice was motivated by the
mesh-independence of such operators, whose training and evaluation can be
performed on grids with different resolutions. The FNO is trained using a loss
minimization over generated data, loss functions based on the PDE
discretization. Numerical results, in one and two dimensions, show that the
proposed initial guess accelerates the convergence of Newton's method by a
large margin compared to a naive initial guess, especially for highly nonlinear
or anisotropic problems.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03024" title="Abstract">arXiv:2403.03024</a> [<a href="/pdf/2403.03024" title="Download PDF">pdf</a>, <a href="/format/2403.03024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Improved Deep Learning-based Vulnerability Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sejfia%2C+A">Adriana Sejfia</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Satyaki Das</a>, 
<a href="/search/cs?searchtype=author&query=Shafiq%2C+S">Saad Shafiq</a>, 
<a href="/search/cs?searchtype=author&query=Medvidovi%C4%87%2C+N">Nenad Medvidovi&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Deep learning (DL) has been a common thread across several recent techniques
for vulnerability detection. The rise of large, publicly available datasets of
vulnerabilities has fueled the learning process underpinning these techniques.
While these datasets help the DL-based vulnerability detectors, they also
constrain these detectors' predictive abilities. Vulnerabilities in these
datasets have to be represented in a certain way, e.g., code lines, functions,
or program slices within which the vulnerabilities exist. We refer to this
representation as a base unit. The detectors learn how base units can be
vulnerable and then predict whether other base units are vulnerable. We have
hypothesized that this focus on individual base units harms the ability of the
detectors to properly detect those vulnerabilities that span multiple base
units (or MBU vulnerabilities). For vulnerabilities such as these, a correct
detection occurs when all comprising base units are detected as vulnerable.
Verifying how existing techniques perform in detecting all parts of a
vulnerability is important to establish their effectiveness for other
downstream tasks. To evaluate our hypothesis, we conducted a study focusing on
three prominent DL-based detectors: ReVeal, DeepWukong, and LineVul. Our study
shows that all three detectors contain MBU vulnerabilities in their respective
datasets. Further, we observed significant accuracy drops when detecting these
types of vulnerabilities. We present our study and a framework that can be used
to help DL-based detectors toward the proper inclusion of MBU vulnerabilities.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03028" title="Abstract">arXiv:2403.03028</a> [<a href="/pdf/2403.03028" title="Download PDF">pdf</a>, <a href="/format/2403.03028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Word Importance Explains How Prompts Affect Language Model Outputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hackmann%2C+S">Stefan Hackmann</a>, 
<a href="/search/cs?searchtype=author&query=Mahmoudian%2C+H">Haniyeh Mahmoudian</a>, 
<a href="/search/cs?searchtype=author&query=Steadman%2C+M">Mark Steadman</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+M">Michael Schmidt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The emergence of large language models (LLMs) has revolutionized numerous
applications across industries. However, their "black box" nature often hinders
the understanding of how they make specific decisions, raising concerns about
their transparency, reliability, and ethical use. This study presents a method
to improve the explainability of LLMs by varying individual words in prompts to
uncover their statistical impact on the model outputs. This approach, inspired
by permutation importance for tabular data, masks each word in the system
prompt and evaluates its effect on the outputs based on the available text
scores aggregated over multiple user inputs. Unlike classical attention, word
importance measures the impact of prompt words on arbitrarily-defined text
scores, which enables decomposing the importance of words into the specific
measures of interest--including bias, reading level, verbosity, etc. This
procedure also enables measuring impact when attention weights are not
available. To test the fidelity of this approach, we explore the effect of
adding different suffixes to multiple different system prompts and comparing
subsequent generations with different large language models. Results show that
word importance scores are closely related to the expected suffix importances
for multiple scoring functions.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03029" title="Abstract">arXiv:2403.03029</a> [<a href="/pdf/2403.03029" title="Download PDF">pdf</a>, <a href="/format/2403.03029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Socratic Reasoning Improves Positive Text Rewriting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goel%2C+A">Anmol Goel</a>, 
<a href="/search/cs?searchtype=author&query=Daheim%2C+N">Nico Daheim</a>, 
<a href="/search/cs?searchtype=author&query=Gurevych%2C+I">Iryna Gurevych</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Reframing a negative into a positive thought is at the crux of several
cognitive approaches to mental health and psychotherapy that could be made more
accessible by large language model-based solutions. Such reframing is typically
non-trivial and requires multiple rationalization steps to uncover the
underlying issue of a negative thought and transform it to be more positive.
However, this rationalization process is currently neglected by both datasets
and models which reframe thoughts in one step. In this work, we address this
gap by augmenting open-source datasets for positive text rewriting with
synthetically-generated Socratic rationales using a novel framework called
\textsc{SocraticReframe}. \textsc{SocraticReframe} uses a sequence of
question-answer pairs to rationalize the thought rewriting process. We show
that such Socratic rationales significantly improve positive text rewriting for
different open-source LLMs according to both automatic and human evaluations
guided by criteria from psychotherapy research.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03030" title="Abstract">arXiv:2403.03030</a> [<a href="/pdf/2403.03030" title="Download PDF">pdf</a>, <a href="/format/2403.03030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unifying Controller Design for Stabilizing Nonlinear Systems with  Norm-Bounded Control Inputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+Z">Zhiyong Sun</a>, 
<a href="/search/eess?searchtype=author&query=Weiland%2C+S">Siep Weiland</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper revisits a classical challenge in the design of stabilizing
controllers for nonlinear systems with a norm-bounded input constraint. By
extending Lin-Sontag's universal formula and introducing a generic
(state-dependent) scaling term, a unifying controller design method is
proposed. The incorporation of this generic scaling term gives a unified
controller and enables the derivation of alternative universal formulas with
various favorable properties, which makes it suitable for tailored control
designs to meet specific requirements and provides versatility across different
control scenarios. Additionally, we present a constructive approach to
determine the optimal scaling term, leading to an explicit solution to an
optimization problem, named optimization-based universal formula. The resulting
controller ensures asymptotic stability, satisfies a norm-bounded input
constraint, and optimizes a predefined cost function. Finally, the essential
properties of the unified controllers are analyzed, including smoothness,
continuity at the origin, stability margin, and inverse optimality. Simulations
validate the approach, showcasing its effectiveness in addressing a challenging
stabilizing control problem of a nonlinear system.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03031" title="Abstract">arXiv:2403.03031</a> [<a href="/pdf/2403.03031" title="Download PDF">pdf</a>, <a href="/format/2403.03031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Use Tools via Cooperative and Interactive Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhengliang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiuyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Lingyong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Haibo Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Dawei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhumin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+P">Pengjie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Verberne%2C+S">Suzan Verberne</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhaochun Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Tool learning empowers large language models (LLMs) as agents to use external
tools to extend their capability. Existing methods employ one single LLM-based
agent to iteratively select and execute tools, thereafter incorporating the
result into the next action prediction. However, they still suffer from
potential performance degradation when addressing complex tasks due to: (1) the
limitation of the inherent capability of a single LLM to perform diverse
actions, and (2) the struggle to adaptively correct mistakes when the task
fails. To mitigate these problems, we propose the ConAgents, a Cooperative and
interactive Agents framework, which modularizes the workflow of tool learning
into Grounding, Execution, and Observing agents. We also introduce an iterative
calibration (IterCali) method, enabling the agents to adapt themselves based on
the feedback from the tool environment. Experiments conducted on three datasets
demonstrate the superiority of our ConAgents (e.g., 6 point improvement over
the SOTA baseline). We further provide fine-granularity analysis for the
efficiency and consistency of our framework.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03032" title="Abstract">arXiv:2403.03032</a> [<a href="/pdf/2403.03032" title="Download PDF">pdf</a>, <a href="/ps/2403.03032" title="Download PostScript">ps</a>, <a href="/format/2403.03032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Logic Programming with Multiplicative Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Acclavio%2C+M">Matteo Acclavio</a>, 
<a href="/search/cs?searchtype=author&query=Maieli%2C+R">Roberto Maieli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">In the logic programming paradigm, a program is defined by a set of methods,
each of which can be executed when specific conditions are met during the
current state of an execution. The semantics of these programs can be elegantly
represented using sequent calculi, in which each method is linked to an
inference rule. In this context, proof search mirrors the program's execution.
Previous works introduced a framework in which the process of constructing
proof nets is employed to model executions, as opposed to the traditional
approach of proof search in sequent calculus.
<br />This paper further extends this investigation by focussing on the pure
multiplicative fragment of this framework. We demonstrate, providing practical
examples, the capability to define logic programming methods with
context-sensitive behaviors solely through specific resource-preserving and
context-free operations, corresponding to certain generalized multiplicative
connectives explored in existing literature. We show how some of these methods,
although still multiplicative, escape the purely multiplicative fragment of
Linear Logic (MLL).
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03035" title="Abstract">arXiv:2403.03035</a> [<a href="/pdf/2403.03035" title="Download PDF">pdf</a>, <a href="/format/2403.03035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mars 2.0: A Toolchain for Modeling, Analysis, Verification and Code  Generation of Cyber-Physical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+B">Bohua Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Q">Qiang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Z">Zekun Ji</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xiangyu Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+N">Naijun Zhan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">We introduce Mars 2.0 for modeling, analysis, verification and code
generation of Cyber-Physical Systems. Mars 2.0 integrates Mars 1.0 with several
important extensions and improvements, allowing the design of cyber-physical
systems using the combination of AADL and Simulink/Stateflow, which provide a
unified graphical framework for modeling the functionality, physicality and
architecture of the system to be developed. For a safety-critical system,
formal analysis and verification of its combined AADL and Simulink/Stateflow
model can be conducted via the following steps. First, the toolchain
automatically translates AADL and Simulink/Stateflow models into Hybrid CSP
(HCSP), an extension of CSP for formally modeling hybrid systems. Second, the
HCSP processes can be simulated using the HCSP simulator, and to complement
incomplete simulation, they can be verified using the Hybrid Hoare Logic prover
in Isabelle/HOL, as well as the more automated HHLPy prover. Finally,
implementations in SystemC or C can be automatically generated from the
verified HCSP processes. The transformation from AADL and Simulink/Stateflow to
HCSP, and the one from HCSP to SystemC or C, are both guaranteed to be correct
with formal proofs. This approach allows model-driven design of safety-critical
cyber-physical systems based on graphical and formal models and proven-correct
translation procedures. We demonstrate the use of the toolchain on several
benchmarks of varying complexity, including several industrial-sized examples.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03037" title="Abstract">arXiv:2403.03037</a> [<a href="/pdf/2403.03037" title="Download PDF">pdf</a>, <a href="/format/2403.03037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Backpack Full of Skills: Egocentric Video Understanding with Diverse  Task Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peirone%2C+S+A">Simone Alberto Peirone</a>, 
<a href="/search/cs?searchtype=author&query=Pistilli%2C+F">Francesca Pistilli</a>, 
<a href="/search/cs?searchtype=author&query=Alliegro%2C+A">Antonio Alliegro</a>, 
<a href="/search/cs?searchtype=author&query=Averta%2C+G">Giuseppe Averta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE/CVF Conference on Computer Vision and Pattern Recognition 2024. Project webpage at <a href="https://sapeirone.github.io/EgoPack">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Human comprehension of a video stream is naturally broad: in a few instants,
we are able to understand what is happening, the relevance and relationship of
objects, and forecast what will follow in the near future, everything all at
once. We believe that - to effectively transfer such an holistic perception to
intelligent machines - an important role is played by learning to correlate
concepts and to abstract knowledge coming from different tasks, to
synergistically exploit them when learning novel skills. To accomplish this, we
seek for a unified approach to video understanding which combines shared
temporal modelling of human actions with minimal overhead, to support multiple
downstream tasks and enable cooperation when learning novel skills. We then
propose EgoPack, a solution that creates a collection of task perspectives that
can be carried across downstream tasks and used as a potential source of
additional insights, as a backpack of skills that a robot can carry around and
use when needed. We demonstrate the effectiveness and efficiency of our
approach on four Ego4D benchmarks, outperforming current state-of-the-art
methods.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03045" title="Abstract">arXiv:2403.03045</a> [<a href="/pdf/2403.03045" title="Download PDF">pdf</a>, <a href="/format/2403.03045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adding Multimodal Capabilities to a Text-only Translation Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vijayan%2C+V">Vipin Vijayan</a>, 
<a href="/search/cs?searchtype=author&query=Bowen%2C+B">Braeden Bowen</a>, 
<a href="/search/cs?searchtype=author&query=Grigsby%2C+S">Scott Grigsby</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+T">Timothy Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Gwinnup%2C+J">Jeremy Gwinnup</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">While most current work in multimodal machine translation (MMT) uses the
Multi30k dataset for training and evaluation, we find that the resulting models
overfit to the Multi30k dataset to an extreme degree. Consequently, these
models perform very badly when evaluated against typical text-only testing sets
such as the WMT newstest datasets. In order to perform well on both Multi30k
and typical text-only datasets, we use a performant text-only machine
translation (MT) model as the starting point of our MMT model. We add
vision-text adapter layers connected via gating mechanisms to the MT model, and
incrementally transform the MT model into an MMT model by 1) pre-training using
vision-based masking of the source text and 2) fine-tuning on Multi30k.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03046" title="Abstract">arXiv:2403.03046</a> [<a href="/pdf/2403.03046" title="Download PDF">pdf</a>, <a href="/ps/2403.03046" title="Download PostScript">ps</a>, <a href="/format/2403.03046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Exchange Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garg%2C+M">Mohit Garg</a>, 
<a href="/search/cs?searchtype=author&query=Sarswat%2C+S">Suneel Sarswat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Auctions are widely used in exchanges to match buy and sell requests. Once
the buyers and sellers place their requests, the exchange determines how these
requests are to be matched. The two most popular objectives used while
determining the matching are maximizing volume at a uniform price and
maximizing volume with dynamic pricing. In this work, we study the algorithmic
complexity of the problems arising from these matching tasks.
<br />We present a linear time algorithm for uniform price matching which is an
improvement over the previous algorithms that take $O(n\log n)$ time to match
$n$ requests. For dynamic price matching, we establish a lower bound of
$\Omega(n \log n)$ on the running time, thereby proving that the currently
known best algorithm is time-optimal.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03048" title="Abstract">arXiv:2403.03048</a> [<a href="/pdf/2403.03048" title="Download PDF">pdf</a>, <a href="/format/2403.03048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design of Stochastic Quantizers for Privacy Preservation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+L">Le Liu</a>, 
<a href="/search/eess?searchtype=author&query=Kawano%2C+Y">Yu Kawano</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+M">Ming Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">In this paper, we examine the role of stochastic quantizers for privacy
preservation. We first employ a static stochastic quantizer and investigate its
corresponding privacy-preserving properties. Specifically, we demonstrate that
a sufficiently large quantization step guarantees $(0, \delta)$ differential
privacy. Additionally, the degradation of control performance caused by
quantization is evaluated as the tracking error of output regulation. These two
analyses characterize the trade-off between privacy and control performance,
determined by the quantization step. This insight enables us to use
quantization intentionally as a means to achieve the seemingly conflicting two
goals of maintaining control performance and preserving privacy at the same
time; towards this end, we further investigate a dynamic stochastic quantizer.
Under a stability assumption, the dynamic stochastic quantizer can enhance
privacy, more than the static one, while achieving the same control
performance. We further handle the unstable case by additionally applying input
Gaussian noise.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03055" title="Abstract">arXiv:2403.03055</a> [<a href="/pdf/2403.03055" title="Download PDF">pdf</a>, <a href="/format/2403.03055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Policy Gradient for Linear Quadratic Networked Control with  Limited Communication Range
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yuzi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yuan Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Machine Learning (cs.LG); Robotics (cs.RO); Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper proposes a scalable distributed policy gradient method and proves
its convergence to near-optimal solution in multi-agent linear quadratic
networked systems. The agents engage within a specified network under local
communication constraints, implying that each agent can only exchange
information with a limited number of neighboring agents. On the underlying
graph of the network, each agent implements its control input depending on its
nearby neighbors' states in the linear quadratic control setting. We show that
it is possible to approximate the exact gradient only using local information.
Compared with the centralized optimal controller, the performance gap decreases
to zero exponentially as the communication and control ranges increase. We also
demonstrate how increasing the communication range enhances system stability in
the gradient descent process, thereby elucidating a critical trade-off. The
simulation results verify our theoretical findings.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03057" title="Abstract">arXiv:2403.03057</a> [<a href="/pdf/2403.03057" title="Download PDF">pdf</a>, <a href="/format/2403.03057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Interaction-Based Offline Runtime Verification of Distributed  Systems with Lifeline Removal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahe%2C+E">Erwan Mahe</a>, 
<a href="/search/cs?searchtype=author&query=Bannour%2C+B">Boutheina Bannour</a>, 
<a href="/search/cs?searchtype=author&query=Gaston%2C+C">Christophe Gaston</a>, 
<a href="/search/cs?searchtype=author&query=Gall%2C+P+L">Pascale Le Gall</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages (31 in the article proper, 1 page of references, 6 pages in appendices), 18 figures, submitted to Science of Computer Programming journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">Runtime Verification (RV) refers to a family of techniques in which system
executions are observed and confronted to formal specifications, with the aim
of identifying faults. In Offline RV, observation is done in a first step and
verification in a second, on a static artifact collected during observation. In
this paper, we define an approach to offline RV of Distributed Systems (DS)
against interactions. Interactions are formal models describing communications
within a DS. DS are composed of subsystems deployed on different machines and
interacting via message passing. Therefore, observing executions of a DS
entails logging a collection of local execution traces, one for each subsystem,
that we call a multi-trace. A major challenge in analyzing multi-traces is that
there are no practical means to synchronize the ends of observations of all
local traces. We address this via an operation, called lifeline removal, which
we apply on-the-fly on the specification during verification once a local trace
has been entirely analyzed. This operation removes from the interaction the
specification of actions occurring on the subsystem that is no-longer observed.
This may allow further execution of the specification via removing deadlocks
due to the partial orders of actions. We prove the correctness of the resulting
RV algorithm and introduce two optimization techniques which we also prove
correct. We implement a Partial Order Reduction (POR) technique via the
selection of a one-unambiguous action (as a unique first step to a
linearization) which existence is determined via another use of the lifeline
removal operator. Additionally, Local Analyses (LOC) i.e., the verification of
local traces, can be leveraged during the global multi-trace analysis to prove
failure more quickly. Experiments illustrate the application of our RV approach
and the benefits of our optimizations.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03061" title="Abstract">arXiv:2403.03061</a> [<a href="/pdf/2403.03061" title="Download PDF">pdf</a>, <a href="/format/2403.03061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Industry meets Trustworthy AI: A Systematic Review of AI for  Industry 5.0
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vyhmeister%2C+E">Eduardo Vyhmeister</a>, 
<a href="/search/cs?searchtype=author&query=Castane%2C+G+G">Gabriel G. Castane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Review Manuscript
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Industry is at the forefront of adopting new technologies, and the process
followed by the adoption has a significant impact on the economy and society.
In this work, we focus on analysing the current paradigm in which industry
evolves, making it more sustainable and Trustworthy. In Industry 5.0,
Artificial Intelligence (AI), among other technology enablers, is used to build
services from a sustainable, human-centric and resilient perspective. It is
crucial to understand those aspects that can bring AI to industry, respecting
Trustworthy principles by collecting information to define how it is
incorporated in the early stages, its impact, and the trends observed in the
field. In addition, to understand the challenges and gaps in the transition
from Industry 4.0 to Industry 5.0, a general perspective on the industry's
readiness for new technologies is described. This provides practitioners with
novel opportunities to be explored in pursuit of the adoption of Trustworthy AI
in the sector.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03063" title="Abstract">arXiv:2403.03063</a> [<a href="/pdf/2403.03063" title="Download PDF">pdf</a>, <a href="/format/2403.03063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CrackNex: a Few-shot Low-light Crack Segmentation Model Based on Retinex  Theory for UAV Inspections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zhen Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiawei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+S">Shuhang Hou</a>, 
<a href="/search/cs?searchtype=author&query=Chuah%2C+M+C">Mooi Choo Chuah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, IEEE International Conference on Robotics and Automation (ICRA) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Routine visual inspections of concrete structures are imperative for
upholding the safety and integrity of critical infrastructure. Such visual
inspections sometimes happen under low-light conditions, e.g., checking for
bridge health. Crack segmentation under such conditions is challenging due to
the poor contrast between cracks and their surroundings. However, most deep
learning methods are designed for well-illuminated crack images and hence their
performance drops dramatically in low-light scenes. In addition, conventional
approaches require many annotated low-light crack images which is
time-consuming. In this paper, we address these challenges by proposing
CrackNex, a framework that utilizes reflectance information based on Retinex
Theory to help the model learn a unified illumination-invariant representation.
Furthermore, we utilize few-shot segmentation to solve the inefficient training
data problem. In CrackNex, both a support prototype and a reflectance prototype
are extracted from the support set. Then, a prototype fusion module is designed
to integrate the features from both prototypes. CrackNex outperforms the SOTA
methods on multiple datasets. Additionally, we present the first benchmark
dataset, LCSD, for low-light crack segmentation. LCSD consists of 102
well-illuminated crack images and 41 low-light crack images. The dataset and
code are available at https://github.com/zy1296/CrackNex.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03066" title="Abstract">arXiv:2403.03066</a> [<a href="/pdf/2403.03066" title="Download PDF">pdf</a>, <a href="/ps/2403.03066" title="Download PostScript">ps</a>, <a href="/format/2403.03066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tracking-in-range Formulations for Numerical Optimal Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ramesh%2C+N">Nikilesh Ramesh</a>, 
<a href="/search/eess?searchtype=author&query=Kerrigan%2C+E+C">Eric C. Kerrigan</a>, 
<a href="/search/eess?searchtype=author&query=Nie%2C+Y">Yuanbo Nie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In contrast to set-point tracking which aims to reduce the tracking error
between the tracker and the reference, tracking-in-range problems only focus on
whether the tracker is within a given range around the reference, making it
more suitable for the mission specifications of many practical applications. In
this work, we present novel optimal control formulations to solve
tracking-in-range problems, for both problems requiring the tracker to be
always in range, and problems allowing the tracker to go out of range to yield
overall better outcomes. As the problem naturally involves discontinuous
functions, we present alternative formulations and regularisation strategies to
improve the performance of numerical solvers. The extension to in-range
tracking with multiple trackers and in-range tracking in high dimensional space
are also discussed and illustrated with numerical examples, demonstrating
substantial increases in mission duration in comparison to traditional
set-point tracking.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03067" title="Abstract">arXiv:2403.03067</a> [<a href="/pdf/2403.03067" title="Download PDF">pdf</a>, <a href="/format/2403.03067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enumeration for MSO-Queries on Compressed Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lohrey%2C+M">Markus Lohrey</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+M+L">Markus L. Schmid</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Databases (cs.DB)

</div>
<p class="mathjax">We present a linear preprocessing and output-linear delay enumeration
algorithm for MSO-queries over trees that are compressed in the
well-established grammar-based framework. Time bounds are measured with respect
to the size of the compressed representation of the tree. Our result extends
previous work on the enumeration of MSO-queries over uncompressed trees and on
the enumeration of document spanners over compressed text documents.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03069" title="Abstract">arXiv:2403.03069</a> [<a href="/pdf/2403.03069" title="Download PDF">pdf</a>, <a href="/format/2403.03069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Variational Autoencoder Estimation from Incomplete Data with  Mixture Variational Families
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Simkus%2C+V">Vaidotas Simkus</a>, 
<a href="/search/cs?searchtype=author&query=Gutmann%2C+M+U">Michael U. Gutmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We consider the task of estimating variational autoencoders (VAEs) when the
training data is incomplete. We show that missing data increases the complexity
of the model's posterior distribution over the latent variables compared to the
fully-observed case. The increased complexity may adversely affect the fit of
the model due to a mismatch between the variational and model posterior
distributions. We introduce two strategies based on (i) finite
variational-mixture and (ii) imputation-based variational-mixture distributions
to address the increased posterior complexity. Through a comprehensive
evaluation of the proposed approaches, we show that variational mixtures are
effective at improving the accuracy of VAE estimation from incomplete data.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03075" title="Abstract">arXiv:2403.03075</a> [<a href="/pdf/2403.03075" title="Download PDF">pdf</a>, <a href="/format/2403.03075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Concrete Visual Tokens for Multimodal Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bowen%2C+B">Braeden Bowen</a>, 
<a href="/search/cs?searchtype=author&query=Vijayan%2C+V">Vipin Vijayan</a>, 
<a href="/search/cs?searchtype=author&query=Grigsby%2C+S">Scott Grigsby</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+T">Timothy Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Gwinnup%2C+J">Jeremy Gwinnup</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The challenge of visual grounding and masking in multimodal machine
translation (MMT) systems has encouraged varying approaches to the detection
and selection of visually-grounded text tokens for masking. We introduce new
methods for detection of visually and contextually relevant (concrete) tokens
from source sentences, including detection with natural language processing
(NLP), detection with object detection, and a joint detection-verification
technique. We also introduce new methods for selection of detected tokens,
including shortest $n$ tokens, longest $n$ tokens, and all detected concrete
tokens. We utilize the GRAM MMT architecture to train models against
synthetically collated multimodal datasets of source images with masked
sentences, showing performance improvements and improved usage of visual
context during translation tasks over the baseline model.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03076" title="Abstract">arXiv:2403.03076</a> [<a href="/pdf/2403.03076" title="Download PDF">pdf</a>, <a href="/format/2403.03076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and robust method for screened Poisson lattice Green&#x27;s function  using asymptotic expansion and Fast Fourier Transform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hou%2C+W">Wei Hou</a>, 
<a href="/search/math?searchtype=author&query=Colonius%2C+T">Tim Colonius</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">We study the lattice Green's function (LGF) of the screened Poisson equation
on a two-dimensional rectangular lattice. This LGF arises in numerical
analysis, random walks, solid-state physics, and other fields. Its defining
characteristic is the screening term, which defines different regimes. When its
coefficient is large, we can accurately approximate the LGF with an
exponentially converging asymptotic expansion, and its convergence rate
monotonically increases with the coefficient of the screening term. To tabulate
the LGF when the coefficient is not large, we derive a one-dimensional integral
representation of the LGF. We show that the trapezoidal rule can approximate
this integral with exponential convergence, and we propose an efficient
algorithm for its evaluation via the Fast Fourier Transform. We discuss
applications including computing the LGF of the three-dimensional Poisson
equation with one periodic direction and the return probability of a
two-dimensional random walk with killing.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03077" title="Abstract">arXiv:2403.03077</a> [<a href="/pdf/2403.03077" title="Download PDF">pdf</a>, <a href="/format/2403.03077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MiKASA: Multi-Key-Anchor &amp; Scene-Aware Transformer for 3D Visual  Grounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Chun-Peng Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shaoxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pagani%2C+A">Alain Pagani</a>, 
<a href="/search/cs?searchtype=author&query=Stricker%2C+D">Didier Stricker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D visual grounding involves matching natural language descriptions with
their corresponding objects in 3D spaces. Existing methods often face
challenges with accuracy in object recognition and struggle in interpreting
complex linguistic queries, particularly with descriptions that involve
multiple anchors or are view-dependent. In response, we present the MiKASA
(Multi-Key-Anchor Scene-Aware) Transformer. Our novel end-to-end trained model
integrates a self-attention-based scene-aware object encoder and an original
multi-key-anchor technique, enhancing object recognition accuracy and the
understanding of spatial relationships. Furthermore, MiKASA improves the
explainability of decision-making, facilitating error diagnosis. Our model
achieves the highest overall accuracy in the Referit3D challenge for both the
Sr3D and Nr3D datasets, particularly excelling by a large margin in categories
that require viewpoint-dependent descriptions.
<br />The source code and additional resources for this project are available on
GitHub: https://github.com/birdy666/MiKASA-3DVG
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03082" title="Abstract">arXiv:2403.03082</a> [<a href="/pdf/2403.03082" title="Download PDF">pdf</a>, <a href="/format/2403.03082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recall-Oriented Continual Learning with Generative Adversarial  Meta-Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+H">Haneol Kang</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+D">Dong-Wan Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AAAI-2024 (Oral presentation)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The stability-plasticity dilemma is a major challenge in continual learning,
as it involves balancing the conflicting objectives of maintaining performance
on previous tasks while learning new tasks. In this paper, we propose the
recall-oriented continual learning framework to address this challenge.
Inspired by the human brain's ability to separate the mechanisms responsible
for stability and plasticity, our framework consists of a two-level
architecture where an inference network effectively acquires new knowledge and
a generative network recalls past knowledge when necessary. In particular, to
maximize the stability of past knowledge, we investigate the complexity of
knowledge depending on different representations, and thereby introducing
generative adversarial meta-model (GAMM) that incrementally learns
task-specific parameters instead of input data samples of the task. Through our
experiments, we show that our framework not only effectively learns new
knowledge without any disruption but also achieves high stability of previous
knowledge in both task-aware and task-agnostic learning scenarios. Our code is
available at: https://github.com/bigdata-inha/recall-oriented-cl-framework.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03083" title="Abstract">arXiv:2403.03083</a> [<a href="/pdf/2403.03083" title="Download PDF">pdf</a>, <a href="/format/2403.03083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tooling Offline Runtime Verification against Interaction Models :  recognizing sliced behaviors using parameterized simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahe%2C+E">Erwan Mahe</a>, 
<a href="/search/cs?searchtype=author&query=Bannour%2C+B">Boutheina Bannour</a>, 
<a href="/search/cs?searchtype=author&query=Gaston%2C+C">Christophe Gaston</a>, 
<a href="/search/cs?searchtype=author&query=Lapitre%2C+A">Arnault Lapitre</a>, 
<a href="/search/cs?searchtype=author&query=Gall%2C+P+L">Pascale Le Gall</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 double-column pages (25 in the paper proper, 3 additional pages for references and appendices), 19 figures (1 in the appendices), submitted to the Journal of Object Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Offline runtime verification involves the static analysis of executions of a
system against a specification. For distributed systems, it is generally not
possible to characterize executions in the form of global traces, given the
absence of a global clock. To account for this, we model executions as
collections of local traces called multi-traces, with one local trace per group
of co-localized actors that share a common clock. Due to the difficulty of
synchronizing the start and end of the recordings of local traces, events may
be missing at their beginning or end. Considering such partially observed
multi-traces is challenging for runtime verification. To that end, we propose
an algorithm that verifies the conformity of such traces against formal
specifications called Interactions (akin to Message Sequence Charts). It relies
on parameterized simulation to reconstitute unobserved behaviors.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03095" title="Abstract">arXiv:2403.03095</a> [<a href="/pdf/2403.03095" title="Download PDF">pdf</a>, <a href="/format/2403.03095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross Pseudo-Labeling for Semi-Supervised Audio-Visual Source  Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuxin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shijie Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuhao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hu Su</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+W">Wei Zou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted To ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Audio-Visual Source Localization (AVSL) is the task of identifying specific
sounding objects in the scene given audio cues. In our work, we focus on
semi-supervised AVSL with pseudo-labeling. To address the issues with vanilla
hard pseudo-labels including bias accumulation, noise sensitivity, and
instability, we propose a novel method named Cross Pseudo-Labeling (XPL),
wherein two models learn from each other with the cross-refine mechanism to
avoid bias accumulation. We equip XPL with two effective components. Firstly,
the soft pseudo-labels with sharpening and pseudo-label exponential moving
average mechanisms enable models to achieve gradual self-improvement and ensure
stable training. Secondly, the curriculum data selection module adaptively
selects pseudo-labels with high quality during training to mitigate potential
bias. Experimental results demonstrate that XPL significantly outperforms
existing methods, achieving state-of-the-art performance while effectively
mitigating confirmation bias and ensuring training stability.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03097" title="Abstract">arXiv:2403.03097</a> [<a href="/pdf/2403.03097" title="Download PDF">pdf</a>, <a href="/format/2403.03097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tappy: Predicting Tap Accuracy of User-Interface Elements by  Reverse-Engineering Webpage Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Usuba%2C+H">Hiroki Usuba</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+J">Junichi Sato</a>, 
<a href="/search/cs?searchtype=author&query=Sasaya%2C+N">Naomi Sasaya</a>, 
<a href="/search/cs?searchtype=author&query=Yamanaka%2C+S">Shota Yamanaka</a>, 
<a href="/search/cs?searchtype=author&query=Yamashit%2C+F">Fumiya Yamashit</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Selecting a UI element is a fundamental operation on webpages, and the ease
of tapping a target object has a significant impact on usability. It is thus
important to analyze existing UIs in order to design better ones. However,
tools proposed in previous studies cannot identify whether an element is
tappable on modern webpages. In this study, we developed Tappy that can
identify tappable UI elements on webpages and estimate the tap-success rate
based on the element size. Our interviews of professional designers and
engineers showed that Tappy helped discussions of UI design on the basis of its
quantitative metric. Furthermore, we have launched this tool to be freely
available to external users, so readers can access Tappy by visiting the
website (https://tappy.yahoo.co.jp).
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03101" title="Abstract">arXiv:2403.03101</a> [<a href="/pdf/2403.03101" title="Download PDF">pdf</a>, <a href="/format/2403.03101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuqi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+S">Shuofei Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Ou%2C+Y">Yixin Ou</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Shumin Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ningyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+S">Shiwei Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yue Shen</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+L">Lei Liang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjie Gu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huajun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress. Project page: <a href="https://zjunlp.github.io/project/KnowAgent/">this https URL</a> Code: <a href="https://github.com/zjunlp/KnowAgent">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Large Language Models (LLMs) have demonstrated great potential in complex
reasoning tasks, yet they fall short when tackling more sophisticated
challenges, especially when interacting with environments through generating
executable actions. This inadequacy primarily stems from the lack of built-in
action knowledge in language agents, which fails to effectively guide the
planning trajectories during task solving and results in planning
hallucination. To address this issue, we introduce KnowAgent, a novel approach
designed to enhance the planning capabilities of LLMs by incorporating explicit
action knowledge. Specifically, KnowAgent employs an action knowledge base and
a knowledgeable self-learning strategy to constrain the action path during
planning, enabling more reasonable trajectory synthesis, and thereby enhancing
the planning performance of language agents. Experimental results on HotpotQA
and ALFWorld based on various backbone models demonstrate that KnowAgent can
achieve comparable or superior performance to existing baselines. Further
analysis indicates the effectiveness of KnowAgent in terms of planning
hallucinations mitigation. Code is available in
https://github.com/zjunlp/KnowAgent.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03102" title="Abstract">arXiv:2403.03102</a> [<a href="/pdf/2403.03102" title="Download PDF">pdf</a>, <a href="/format/2403.03102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;In Dialogues We Learn&quot;: Towards Personalized Dialogue Without  Pre-defined Profiles through In-Dialogue Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C">Chuanqi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Q">Quan Tu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+S">Shuo Shang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+C">Cunli Mao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhengtao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rui Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Personalized dialogue systems have gained significant attention in recent
years for their ability to generate responses in alignment with different
personas. However, most existing approaches rely on pre-defined personal
profiles, which are not only time-consuming and labor-intensive to create but
also lack flexibility. We propose In-Dialogue Learning (IDL), a fine-tuning
framework that enhances the ability of pre-trained large language models to
leverage dialogue history to characterize persona for completing personalized
dialogue generation tasks without pre-defined profiles. Our experiments on
three datasets demonstrate that IDL brings substantial improvements, with BLEU
and ROUGE scores increasing by up to 200% and 247%, respectively. Additionally,
the results of human evaluations further validate the efficacy of our proposed
method.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03103" title="Abstract">arXiv:2403.03103</a> [<a href="/pdf/2403.03103" title="Download PDF">pdf</a>, <a href="/format/2403.03103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergent Equivariance in Deep Ensembles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gerken%2C+J+E">Jan E. Gerken</a>, 
<a href="/search/cs?searchtype=author&query=Kessel%2C+P">Pan Kessel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages + 15 pages appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We demonstrate that deep ensembles are secretly equivariant models. More
precisely, we show that deep ensembles become equivariant for all inputs and at
all training times by simply using data augmentation. Crucially, equivariance
holds off-manifold and for any architecture in the infinite width limit. The
equivariance is emergent in the sense that predictions of individual ensemble
members are not equivariant but their collective prediction is. Neural tangent
kernel theory is used to derive this result and we verify our theoretical
insights using detailed numerical experiments.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03105" title="Abstract">arXiv:2403.03105</a> [<a href="/pdf/2403.03105" title="Download PDF">pdf</a>, <a href="/ps/2403.03105" title="Download PostScript">ps</a>, <a href="/format/2403.03105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Biomechanical Comparison of Human Walking Locomotion on Solid Ground and  Sand
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chunchu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xunjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jingang Yi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 10 figures, submitted to Journal of Biomechanics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Current studies on human locomotion focus mainly on solid ground walking
conditions. In this paper, we present a biomechanic comparison of human walking
locomotion on solid ground and sand. A novel dataset containing 3-dimensional
motion and biomechanical data from 20 able-bodied adults for locomotion on
solid ground and sand is collected. We present the data collection methods and
report the sensor data along with the kinematic and kinetic profiles of joint
biomechanics. A comprehensive analysis of human gait and joint stiffness
profiles is presented. The kinematic and kinetic analysis reveals that human
walking locomotion on sand shows different ground reaction forces and joint
torque profiles, compared with those patterns from walking on solid ground.
These gait differences reflect that humans adopt motion control strategies for
yielding terrain conditions such as sand. The dataset also provides a source of
locomotion data for researchers to study human activity recognition and
assistive devices for walking on different terrains.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03107" title="Abstract">arXiv:2403.03107</a> [<a href="/pdf/2403.03107" title="Download PDF">pdf</a>, <a href="/ps/2403.03107" title="Download PostScript">ps</a>, <a href="/format/2403.03107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On-demand Mobility Services for Urban Resilience: A Review Towards  Human-Machine Collaborative Future
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiangbo Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Mobility-on-demand (MOD) services have the potential to significantly improve
the adaptiveness and recovery of urban logistics and transportation
infrastructure, in the wake of disruptive events. This paper presents a survey
on the usage of MOD services for resilience improvement (MOD-R) and finds a
noticeable increase within recent years on this topic across four main areas:
resilient MOD services, novel usage of MOD-R services for improving supply
chain resilience, empirical impact evaluation, and supporting technologies.
MOD-R services have been utilized for anomaly detection, essential supply
delivery, evacuation and rescue, on-site medical care, power grid
stabilization, transit service substitution during downtime, and infrastructure
and equipment repair. The review reveals integrating electrification,
automation, and advanced communication technologies offers significant
synergistic benefits. The review also suggests the importance of harnessing the
collective capabilities of humans and intelligent machines to effectively
implement versatile, multi-functional MOD-R services during crises.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03111" title="Abstract">arXiv:2403.03111</a> [<a href="/pdf/2403.03111" title="Download PDF">pdf</a>, <a href="/format/2403.03111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved LiDAR Odometry and Mapping using Deep Semantic Segmentation and  Novel Outliers Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Afifi%2C+M">Mohamed Afifi</a>, 
<a href="/search/cs?searchtype=author&query=ElHelw%2C+M">Mohamed ElHelw</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Perception is a key element for enabling intelligent autonomous navigation.
Understanding the semantics of the surrounding environment and accurate vehicle
pose estimation are essential capabilities for autonomous vehicles, including
self-driving cars and mobile robots that perform complex tasks. Fast moving
platforms like self-driving cars impose a hard challenge for localization and
mapping algorithms. In this work, we propose a novel framework for real-time
LiDAR odometry and mapping based on LOAM architecture for fast moving
platforms. Our framework utilizes semantic information produced by a deep
learning model to improve point-to-line and point-to-plane matching between
LiDAR scans and build a semantic map of the environment, leading to more
accurate motion estimation using LiDAR data. We observe that including semantic
information in the matching process introduces a new type of outlier matches to
the process, where matching occur between different objects of the same
semantic class. To this end, we propose a novel algorithm that explicitly
identifies and discards potential outliers in the matching process. In our
experiments, we study the effect of improving the matching process on the
robustness of LiDAR odometry against high speed motion. Our experimental
evaluations on KITTI dataset demonstrate that utilizing semantic information
and rejecting outliers significantly enhance the robustness of LiDAR odometry
and mapping when there are large gaps between scan acquisition poses, which is
typical for fast moving platforms.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03114" title="Abstract">arXiv:2403.03114</a> [<a href="/pdf/2403.03114" title="Download PDF">pdf</a>, <a href="/format/2403.03114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equilibria in Two-Stage Facility Location with Atomic Clients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krogmann%2C+S">Simon Krogmann</a>, 
<a href="/search/cs?searchtype=author&query=Lenzner%2C+P">Pascal Lenzner</a>, 
<a href="/search/cs?searchtype=author&query=Skopalik%2C+A">Alexander Skopalik</a>, 
<a href="/search/cs?searchtype=author&query=Uetz%2C+M">Marc Uetz</a>, 
<a href="/search/cs?searchtype=author&query=Vos%2C+M+C">Marnix C. Vos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We consider competitive facility location as a two-stage multi-agent system
with two types of clients. For a given host graph with weighted clients on the
vertices, first facility agents strategically select vertices for opening their
facilities. Then, the clients strategically select which of the opened
facilities in their neighborhood to patronize. Facilities want to attract as
much client weight as possible, clients want to minimize congestion on the
chosen facility.
<br />All recently studied versions of this model assume that clients can split
their weight strategically. We consider clients with unsplittable weights, but
allow mixed strategies. So clients may randomize over which facility to
patronize. Besides modeling a natural client behavior, this subtle change
yields drastic changes, e.g., for a given facility placement, qualitatively
different client equilibria are possible.
<br />As our main result, we show that pure subgame perfect equilibria always exist
if all client weights are identical. For this, we use a novel potential
function argument, employing a hierarchical classification of the clients and
sophisticated rounding in each step. In contrast, for non-identical clients, we
show that deciding the existence of even approximately stable states is
computationally intractable. On the positive side, we give a tight bound of 2
on the price of anarchy which implies high social welfare of equilibria, if
they exist.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03117" title="Abstract">arXiv:2403.03117</a> [<a href="/pdf/2403.03117" title="Download PDF">pdf</a>, <a href="/format/2403.03117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Necessary and Sufficient Conditions to the Problem of Input-Output  Extension of Internally Controlled Underactuated Nonlinear Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mizzoni%2C+M">Mirko Mizzoni</a>, 
<a href="/search/eess?searchtype=author&query=Afifi%2C+A">Amr Afifi</a>, 
<a href="/search/eess?searchtype=author&query=Franchi%2C+A">Antonio Franchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this letter, we address the problem of re-targeting a commercial
under-actuated robotic system to a higher dimensional output task. Commercial
platforms are equipped with an on-board low-level internal controller that
provides the user some virtual references inputs and cannot be replaced. Such
controller may control in practice only a subset of the total
degrees-of-freedom of the system. Our primary objective is to augment these
systems by introducing supplementary inputs, attaining increased output
capability. Integrating such additional inputs into the control framework
introduces a layer of complexity, raising questions about the compatibility and
cohesiveness of the overall system. We derive necessary and sufficient
conditions under which it is possible to extend the controlled outputs by
adding extra inputs when one is forced to keep the internal controller
unmodified. We underscore the efficacy and universality of our proposed
methodology through the presentation of two relevant examples.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03120" title="Abstract">arXiv:2403.03120</a> [<a href="/pdf/2403.03120" title="Download PDF">pdf</a>, <a href="/format/2403.03120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion-Corrected Moving Average: Including Post-Hoc Temporal Information  for Improved Video Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mendel%2C+R">Robert Mendel</a> (1), 
<a href="/search/cs?searchtype=author&query=Rueckert%2C+T">Tobias Rueckert</a> (1), 
<a href="/search/cs?searchtype=author&query=Wilhelm%2C+D">Dirk Wilhelm</a> (2), 
<a href="/search/cs?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a> (3, 4), 
<a href="/search/cs?searchtype=author&query=Palm%2C+C">Christoph Palm</a> (1, 5) ((1) Regensburg Medical Image Computing (ReMIC), Ostbayerische Technische Hochschule Regensburg (OTH Regensburg), Regensburg, Germany, (2) Department of Surgery, Faculty of Medicine, Klinikum rechts der Isar, Technical University of Munich, Munich, Germany, (3) Artificial Intelligence in Healthcare and Medicine, Klinikum rechts der Isar, Technical University of Munich, Munich, Germany, (4) Department of Computing, Imperial College London, London, UK, (5) Regensburg Center of Health Sciences and Technology (RCHST), OTH Regensburg, Regensburg, Germany)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Real-time computational speed and a high degree of precision are requirements
for computer-assisted interventions. Applying a segmentation network to a
medical video processing task can introduce significant inter-frame prediction
noise. Existing approaches can reduce inconsistencies by including temporal
information but often impose requirements on the architecture or dataset. This
paper proposes a method to include temporal information in any segmentation
model and, thus, a technique to improve video segmentation performance without
alterations during training or additional labeling. With Motion-Corrected
Moving Average, we refine the exponential moving average between the current
and previous predictions. Using optical flow to estimate the movement between
consecutive frames, we can shift the prior term in the moving-average
calculation to align with the geometry of the current frame. The optical flow
calculation does not require the output of the model and can therefore be
performed in parallel, leading to no significant runtime penalty for our
approach. We evaluate our approach on two publicly available segmentation
datasets and two proprietary endoscopic datasets and show improvements over a
baseline approach.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03121" title="Abstract">arXiv:2403.03121</a> [<a href="/pdf/2403.03121" title="Download PDF">pdf</a>, <a href="/format/2403.03121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Angry Men, Sad Women: Large Language Models Reflect Gendered Stereotypes  in Emotion Attribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Plaza-del-Arco%2C+F+M">Flor Miriam Plaza-del-Arco</a>, 
<a href="/search/cs?searchtype=author&query=Curry%2C+A+C">Amanda Cercas Curry</a>, 
<a href="/search/cs?searchtype=author&query=Curry%2C+A">Alba Curry</a>, 
<a href="/search/cs?searchtype=author&query=Abercrombie%2C+G">Gavin Abercrombie</a>, 
<a href="/search/cs?searchtype=author&query=Hovy%2C+D">Dirk Hovy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) reflect societal norms and biases, especially
about gender. While societal biases and stereotypes have been extensively
researched in various NLP applications, there is a surprising gap for emotion
analysis. However, emotion and gender are closely linked in societal discourse.
E.g., women are often thought of as more empathetic, while men's anger is more
socially accepted. To fill this gap, we present the first comprehensive study
of gendered emotion attribution in five state-of-the-art LLMs (open- and
closed-source). We investigate whether emotions are gendered, and whether these
variations are based on societal stereotypes. We prompt the models to adopt a
gendered persona and attribute emotions to an event like 'When I had a serious
argument with a dear person'. We then analyze the emotions generated by the
models in relation to the gender-event pairs. We find that all models
consistently exhibit gendered emotions, influenced by gender stereotypes. These
findings are in line with established research in psychology and gender
studies. Our study sheds light on the complex societal interplay between
language, gender, and emotion. The reproduction of emotion stereotypes in LLMs
allows us to use those models to study the topic in detail, but raises
questions about the predictive use of those same LLMs for emotion applications.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03122" title="Abstract">arXiv:2403.03122</a> [<a href="/pdf/2403.03122" title="Download PDF">pdf</a>, <a href="/format/2403.03122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NRDF: Neural Riemannian Distance Fields for Learning Articulated Pose  Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yannan He</a>, 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+G">Garvita Tiwari</a>, 
<a href="/search/cs?searchtype=author&query=Birdal%2C+T">Tolga Birdal</a>, 
<a href="/search/cs?searchtype=author&query=Lenssen%2C+J+E">Jan Eric Lenssen</a>, 
<a href="/search/cs?searchtype=author&query=Pons-Moll%2C+G">Gerard Pons-Moll</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024. Project page: <a href="https://virtualhumans.mpi-inf.mpg.de/nrdf">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Faithfully modeling the space of articulations is a crucial task that allows
recovery and generation of realistic poses, and remains a notorious challenge.
To this end, we introduce Neural Riemannian Distance Fields (NRDFs),
data-driven priors modeling the space of plausible articulations, represented
as the zero-level-set of a neural field in a high-dimensional
product-quaternion space. To train NRDFs only on positive examples, we
introduce a new sampling algorithm, ensuring that the geodesic distances follow
a desired distribution, yielding a principled distance field learning paradigm.
We then devise a projection algorithm to map any random pose onto the level-set
by an adaptive-step Riemannian optimizer, adhering to the product manifold of
joint rotations at all times. NRDFs can compute the Riemannian gradient via
backpropagation and by mathematical analogy, are related to Riemannian flow
matching, a recent generative model. We conduct a comprehensive evaluation of
NRDF against other pose priors in various downstream tasks, i.e., pose
generation, image-based pose estimation, and solving inverse kinematics,
highlighting NRDF's superior performance. Besides humans, NRDF's versatility
extends to hand and animal poses, as it can effectively represent any
articulation.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03126" title="Abstract">arXiv:2403.03126</a> [<a href="/pdf/2403.03126" title="Download PDF">pdf</a>, <a href="/format/2403.03126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Federated Deep Learning Approach for Privacy-Preserving Real-Time  Transient Stability Predictions in Power Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hijazi%2C+M">Maeshal Hijazi</a>, 
<a href="/search/eess?searchtype=author&query=Dehghanian%2C+P">Payman Dehghanian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024 International Conference on Smart Grid Synchronized Measurements &amp; Analytics (SGSMA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Maintaining the privacy of power system data is essential for protecting
sensitive information and ensuring the operation security of critical
infrastructure. Therefore, the adoption of centralized deep learning (DL)
transient stability assessment (TSA) frameworks can introduce risks to electric
utilities. This is because these frameworks make utility data susceptible to
cyber threats and communication issues when transmitting data to a central
server for training a single TSA model. Additionally, the centralized approach
demands significant computational resources, which may not always be readily
available. In light of these challenges, this paper introduces a federated
DL-based TSA framework designed to identify the operating states of the power
system. Instead of local utilities transmitting their data to a central server
for centralized model training, they independently train their own TSA models
using their respective datasets. Subsequently, the parameters of each local TSA
model are sent to a central server for model aggregation, and the resulting
model is shared back with the local clients. This approach not only preserves
the integrity of local utility data, making it resilient against cyber threats
but also reduces the computational demands for local TSA model training. The
proposed approach is tested on four local clients each having the IEEE 39-bus
test system.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03129" title="Abstract">arXiv:2403.03129</a> [<a href="/pdf/2403.03129" title="Download PDF">pdf</a>, <a href="/format/2403.03129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoGenesis: A Framework Collaborating Large and Small Language Models for  Secure Context-Aware Instruction Following
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaiyan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+E">Ermo Hua</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+B">Biqing Qi</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+N">Ning Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bowen Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the advancement of language models (LMs), their exposure to private data
is increasingly inevitable, and their deployment (especially for smaller ones)
on personal devices, such as PCs and smartphones, has become a prevailing
trend. In contexts laden with user information, enabling models to both
safeguard user privacy and execute commands efficiently emerges as an essential
research imperative. In this paper, we propose CoGenesis, a collaborative
generation framework integrating large (hosted on cloud infrastructure) and
small models (deployed on local devices) to address privacy concerns logically.
Initially, we design a pipeline to create personalized writing instruction
datasets enriched with extensive context details as the testbed of this
research issue. Subsequently, we introduce two variants of CoGenesis based on
sketch and logits respectively. Our experimental findings, based on our
synthesized dataset and two additional open-source datasets, indicate that: 1)
Large-scale models perform well when provided with user context but struggle in
the absence of such context. 2) While specialized smaller models fine-tuned on
the synthetic dataset show promise, they still lag behind their larger
counterparts. 3) Our CoGenesis framework, utilizing mixed-scale models,
showcases competitive performance, providing a feasible solution to privacy
issues.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03134" title="Abstract">arXiv:2403.03134</a> [<a href="/pdf/2403.03134" title="Download PDF">pdf</a>, <a href="/format/2403.03134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simplicity in Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+K">Kevin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Nath%2C+S+S">Surabhi S Nath</a>, 
<a href="/search/cs?searchtype=author&query=Brielmann%2C+A">Aenne Brielmann</a>, 
<a href="/search/cs?searchtype=author&query=Dayan%2C+P">Peter Dayan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">The complexity of visual stimuli plays an important role in many cognitive
phenomena, including attention, engagement, memorability, time perception and
aesthetic evaluation. Despite its importance, complexity is poorly understood
and ironically, previous models of image complexity have been quite
\textit{complex}. There have been many attempts to find handcrafted features
that explain complexity, but these features are usually dataset specific, and
hence fail to generalise. On the other hand, more recent work has employed deep
neural networks to predict complexity, but these models remain difficult to
interpret, and do not guide a theoretical understanding of the problem. Here we
propose to model complexity using segment-based representations of images. We
use state-of-the-art segmentation models, SAM and FC-CLIP, to quantify the
number of segments at multiple granularities, and the number of classes in an
image respectively. We find that complexity is well-explained by a simple
linear model with these two features across six diverse image-sets of
naturalistic scene and art images. This suggests that the complexity of images
can be surprisingly simple.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03141" title="Abstract">arXiv:2403.03141</a> [<a href="/pdf/2403.03141" title="Download PDF">pdf</a>, <a href="/format/2403.03141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Guided Exploration for RL Agents in Text Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Golchha%2C+H">Hitesh Golchha</a>, 
<a href="/search/cs?searchtype=author&query=Yerawar%2C+S">Sahil Yerawar</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+D">Dhruvesh Patel</a>, 
<a href="/search/cs?searchtype=author&query=Dan%2C+S">Soham Dan</a>, 
<a href="/search/cs?searchtype=author&query=Murugesan%2C+K">Keerthiram Murugesan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Real-world sequential decision making is characterized by sparse rewards and
large decision spaces, posing significant difficulty for experiential learning
systems like $\textit{tabula rasa}$ reinforcement learning (RL) agents. Large
Language Models (LLMs), with a wealth of world knowledge, can help RL agents
learn quickly and adapt to distribution shifts. In this work, we introduce
Language Guided Exploration (LGE) framework, which uses a pre-trained language
model (called GUIDE ) to provide decision-level guidance to an RL agent (called
EXPLORER). We observe that on ScienceWorld (Wang et al.,2022), a challenging
text environment, LGE outperforms vanilla RL agents significantly and also
outperforms other sophisticated methods like Behaviour Cloning and Text
Decision Transformer.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03145" title="Abstract">arXiv:2403.03145</a> [<a href="/pdf/2403.03145" title="Download PDF">pdf</a>, <a href="/format/2403.03145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual Mean-Teacher: An Unbiased Semi-Supervised Framework for  Audio-Visual Source Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuxin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shijie Ma</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hu Su</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuhao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+W">Wei Zou</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Siyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yun Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Audio-Visual Source Localization (AVSL) aims to locate sounding objects
within video frames given the paired audio clips. Existing methods
predominantly rely on self-supervised contrastive learning of audio-visual
correspondence. Without any bounding-box annotations, they struggle to achieve
precise localization, especially for small objects, and suffer from blurry
boundaries and false positives. Moreover, the naive semi-supervised method is
poor in fully leveraging the information of abundant unlabeled data. In this
paper, we propose a novel semi-supervised learning framework for AVSL, namely
Dual Mean-Teacher (DMT), comprising two teacher-student structures to
circumvent the confirmation bias issue. Specifically, two teachers, pre-trained
on limited labeled data, are employed to filter out noisy samples via the
consensus between their predictions, and then generate high-quality
pseudo-labels by intersecting their confidence maps. The sufficient utilization
of both labeled and unlabeled data and the proposed unbiased framework enable
DMT to outperform current state-of-the-art methods by a large margin, with CIoU
of 90.4% and 48.8% on Flickr-SoundNet and VGG-Sound Source, obtaining 8.9%,
9.6% and 4.6%, 6.4% improvements over self- and semi-supervised methods
respectively, given only 3% positional-annotations. We also extend our
framework to some existing AVSL methods and consistently boost their
performance.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03149" title="Abstract">arXiv:2403.03149</a> [<a href="/pdf/2403.03149" title="Download PDF">pdf</a>, <a href="/format/2403.03149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Federated Learning Mitigates Client-side Training Data  Distribution Inference Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yichang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+M">Ming Yin</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+M">Minghong Fang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+N+Z">Neil Zhenqiang Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in The Web Conference 2024 (WWW '24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent studies have revealed that federated learning (FL), once considered
secure due to clients not sharing their private data with the server, is
vulnerable to attacks such as client-side training data distribution inference,
where a malicious client can recreate the victim's data. While various
countermeasures exist, they are not practical, often assuming server access to
some training data or knowledge of label distribution before the attack.
<br />In this work, we bridge the gap by proposing InferGuard, a novel
Byzantine-robust aggregation rule aimed at defending against client-side
training data distribution inference attacks. In our proposed InferGuard, the
server first calculates the coordinate-wise median of all the model updates it
receives. A client's model update is considered malicious if it significantly
deviates from the computed median update. We conduct a thorough evaluation of
our proposed InferGuard on five benchmark datasets and perform a comparison
with ten baseline methods. The results of our experiments indicate that our
defense mechanism is highly effective in protecting against client-side
training data distribution inference attacks, even against strong adaptive
attacks. Furthermore, our method substantially outperforms the baseline methods
in various practical FL scenarios.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03150" title="Abstract">arXiv:2403.03150</a> [<a href="/pdf/2403.03150" title="Download PDF">pdf</a>, <a href="/format/2403.03150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep-Learned Compression for Radio-Frequency Signal Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+A">Armani Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Kaasaragadda%2C+Y">Yagna Kaasaragadda</a>, 
<a href="/search/cs?searchtype=author&query=Kokalj-Filipovic%2C+S">Silvija Kokalj-Filipovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Next-generation cellular concepts rely on the processing of large quantities
of radio-frequency (RF) samples. This includes Radio Access Networks (RAN)
connecting the cellular front-end based on software defined radios (SDRs) and a
framework for the AI processing of spectrum-related data. The RF data collected
by the dense RAN radio units and spectrum sensors may need to be jointly
processed for intelligent decision making. Moving large amounts of data to AI
agents may result in significant bandwidth and latency costs. We propose a deep
learned compression (DLC) model, HQARF, based on learned vector quantization
(VQ), to compress the complex-valued samples of RF signals comprised of 6
modulation classes. We are assessing the effects of HQARF on the performance of
an AI model trained to infer the modulation class of the RF signal. Compression
of narrow-band RF samples for the training and off-the-site inference will
allow for an efficient use of the bandwidth and storage for non-real-time
analytics, and for a decreased delay in real-time applications. While exploring
the effectiveness of the HQARF signal reconstructions in modulation
classification tasks, we highlight the DLC optimization space and some open
problems related to the training of the VQ embedded in HQARF.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03157" title="Abstract">arXiv:2403.03157</a> [<a href="/pdf/2403.03157" title="Download PDF">pdf</a>, <a href="/format/2403.03157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Clustered Federated Learning in NOMA Enhanced Wireless  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yushen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kaidi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zhiguo Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">This study explores the benefits of integrating the novel clustered federated
learning (CFL) approach with non-orthogonal multiple access (NOMA) under
non-independent and identically distributed (non-IID) datasets, where multiple
devices participate in the aggregation with time limitations and a finite
number of sub-channels. A detailed theoretical analysis of the generalization
gap that measures the degree of non-IID in the data distribution is presented.
Following that, solutions to address the challenges posed by non-IID conditions
are proposed with the analysis of the properties. Specifically, users' data
distributions are parameterized as concentration parameters and grouped using
spectral clustering, with Dirichlet distribution serving as the prior. The
investigation into the generalization gap and convergence rate guides the
design of sub-channel assignments through the matching-based algorithm, and the
power allocation is achieved by Karush-Kuhn-Tucker (KKT) conditions with the
derived closed-form solution. The extensive simulation results show that the
proposed cluster-based FL framework can outperform FL baselines in terms of
both test accuracy and convergence rate. Moreover, jointly optimizing
sub-channel and power allocation in NOMA-enhanced networks can lead to a
significant improvement.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03161" title="Abstract">arXiv:2403.03161</a> [<a href="/pdf/2403.03161" title="Download PDF">pdf</a>, <a href="/format/2403.03161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PalmProbNet: A Probabilistic Approach to Understanding Palm  Distributions in Ecuadorian Tropical Forest via Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+K">Kangning Cui</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Zishan Shao</a>, 
<a href="/search/cs?searchtype=author&query=Larsen%2C+G">Gregory Larsen</a>, 
<a href="/search/cs?searchtype=author&query=Pauca%2C+V">Victor Pauca</a>, 
<a href="/search/cs?searchtype=author&query=Alqahtani%2C+S">Sarra Alqahtani</a>, 
<a href="/search/cs?searchtype=author&query=Segurado%2C+D">David Segurado</a>, 
<a href="/search/cs?searchtype=author&query=Pinheiro%2C+J">Jo&#xe3;o Pinheiro</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Manqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lutz%2C+D">David Lutz</a>, 
<a href="/search/cs?searchtype=author&query=Plemmons%2C+R">Robert Plemmons</a>, 
<a href="/search/cs?searchtype=author&query=Silman%2C+M">Miles Silman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures, and 1 table, to appear in ACMSE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Palms play an outsized role in tropical forests and are important resources
for humans and wildlife. A central question in tropical ecosystems is
understanding palm distribution and abundance. However, accurately identifying
and localizing palms in geospatial imagery presents significant challenges due
to dense vegetation, overlapping canopies, and variable lighting conditions in
mixed-forest landscapes. Addressing this, we introduce PalmProbNet, a
probabilistic approach utilizing transfer learning to analyze high-resolution
UAV-derived orthomosaic imagery, enabling the detection of palm trees within
the dense canopy of the Ecuadorian Rainforest. This approach represents a
substantial advancement in automated palm detection, effectively pinpointing
palm presence and locality in mixed tropical rainforests. Our process begins by
generating an orthomosaic image from UAV images, from which we extract and
label palm and non-palm image patches in two distinct sizes. These patches are
then used to train models with an identical architecture, consisting of an
unaltered pre-trained ResNet-18 and a Multilayer Perceptron (MLP) with
specifically trained parameters. Subsequently, PalmProbNet employs a sliding
window technique on the landscape orthomosaic, using both small and large
window sizes to generate a probability heatmap. This heatmap effectively
visualizes the distribution of palms, showcasing the scalability and
adaptability of our approach in various forest densities. Despite the
challenging terrain, our method demonstrated remarkable performance, achieving
an accuracy of 97.32% and a Cohen's kappa of 94.59% in testing.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03163" title="Abstract">arXiv:2403.03163</a> [<a href="/pdf/2403.03163" title="Download PDF">pdf</a>, <a href="/format/2403.03163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design2Code: How Far Are We From Automating Front-End Engineering?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Si%2C+C">Chenglei Si</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanzhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhengyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruibo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Diyi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report; The first two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY)

</div>
<p class="mathjax">Generative AI has made rapid advancements in recent years, achieving
unprecedented capabilities in multimodal understanding and code generation.
This can enable a new paradigm of front-end development, in which multimodal
LLMs might directly convert visual designs into code implementations. In this
work, we formalize this as a Design2Code task and conduct comprehensive
benchmarking. Specifically, we manually curate a benchmark of 484 diverse
real-world webpages as test cases and develop a set of automatic evaluation
metrics to assess how well current multimodal LLMs can generate the code
implementations that directly render into the given reference webpages, given
the screenshots as input. We also complement automatic metrics with
comprehensive human evaluations. We develop a suite of multimodal prompting
methods and show their effectiveness on GPT-4V and Gemini Pro Vision. We
further finetune an open-source Design2Code-18B model that successfully matches
the performance of Gemini Pro Vision. Both human evaluation and automatic
metrics show that GPT-4V performs the best on this task compared to other
models. Moreover, annotators think GPT-4V generated webpages can replace the
original reference webpages in 49% of cases in terms of visual appearance and
content; and perhaps surprisingly, in 64% of cases GPT-4V generated webpages
are considered better than the original reference webpages. Our fine-grained
break-down metrics indicate that open-source models mostly lag in recalling
visual elements from the input webpages and in generating correct layout
designs, while aspects like text content and coloring can be drastically
improved with proper finetuning.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03165" title="Abstract">arXiv:2403.03165</a> [<a href="/pdf/2403.03165" title="Download PDF">pdf</a>, <a href="/ps/2403.03165" title="Download PostScript">ps</a>, <a href="/format/2403.03165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Federated Learning and Edge Computing for Recommendation  Systems within Cloud Computing Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yaqian Qi</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yaqian Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiangxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hanzhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jingxiao Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">To enable large-scale and efficient deployment of artificial intelligence
(AI), the combination of AI and edge computing has spawned Edge Intelligence,
which leverages the computing and communication capabilities of end devices and
edge servers to process data closer to where it is generated. A key technology
for edge intelligence is the privacy-protecting machine learning paradigm known
as Federated Learning (FL), which enables data owners to train models without
having to transfer raw data to third-party servers. However, FL networks are
expected to involve thousands of heterogeneous distributed devices. As a
result, communication efficiency remains a key bottleneck. To reduce node
failures and device exits, a Hierarchical Federated Learning (HFL) framework is
proposed, where a designated cluster leader supports the data owner through
intermediate model aggregation. Therefore, based on the improvement of edge
server resource utilization, this paper can effectively make up for the
limitation of cache capacity. In order to mitigate the impact of soft clicks on
the quality of user experience (QoE), the authors model the user QoE as a
comprehensive system cost. To solve the formulaic problem, the authors propose
a decentralized caching algorithm with federated deep reinforcement learning
(DRL) and federated learning (FL), where multiple agents learn and make
decisions independently
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03167" title="Abstract">arXiv:2403.03167</a> [<a href="/pdf/2403.03167" title="Download PDF">pdf</a>, <a href="/format/2403.03167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PARADISE: Evaluating Implicit Planning Skills of Language Models with  Procedural Warnings and Tips Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uzuno%C4%9Flu%2C+A">Arda Uzuno&#x11f;lu</a>, 
<a href="/search/cs?searchtype=author&query=Safa%2C+A+R">Abdalfatah Rashid Safa</a>, 
<a href="/search/cs?searchtype=author&query=%C5%9Eahin%2C+G+G">G&#xf6;zde G&#xfc;l &#x15e;ahin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recently, there has been growing interest within the community regarding
whether large language models are capable of planning or executing plans.
However, most prior studies use LLMs to generate high-level plans for
simplified scenarios lacking linguistic complexity and domain diversity,
limiting analysis of their planning abilities. These setups constrain
evaluation methods (e.g., predefined action space), architectural choices
(e.g., only generative models), and overlook the linguistic nuances essential
for realistic analysis. To tackle this, we present PARADISE, an abductive
reasoning task using Q\&amp;A format on practical procedural text sourced from
wikiHow. It involves warning and tip inference tasks directly associated with
goals, excluding intermediary steps, with the aim of testing the ability of the
models to infer implicit knowledge of the plan solely from the given goal. Our
experiments, utilizing fine-tuned language models and zero-shot prompting,
reveal the effectiveness of task-specific small models over large language
models in most scenarios. Despite advancements, all models fall short of human
performance. Notably, our analysis uncovers intriguing insights, such as
variations in model behavior with dropped keywords, struggles of BERT-family
and GPT-4 with physical and abstract goals, and the proposed tasks offering
valuable prior knowledge for other unseen procedural tasks. The PARADISE
dataset and associated resources are publicly available for further research
exploration with https://github.com/GGLAB-KU/paradise.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03168" title="Abstract">arXiv:2403.03168</a> [<a href="/pdf/2403.03168" title="Download PDF">pdf</a>, <a href="/format/2403.03168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Explicitly Conditioned Sparsifying Transforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=P%C4%83tra%C5%9Fcu%2C+A">Andrei P&#x103;tra&#x15f;cu</a>, 
<a href="/search/math?searchtype=author&query=Rusu%2C+C">Cristian Rusu</a>, 
<a href="/search/math?searchtype=author&query=Irofti%2C+P">Paul Irofti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">Sparsifying transforms became in the last decades widely known tools for
finding structured sparse representations of signals in certain transform
domains. Despite the popularity of classical transforms such as DCT and
Wavelet, learning optimal transforms that guarantee good representations of
data into the sparse domain has been recently analyzed in a series of papers.
Typically, the conditioning number and representation ability are complementary
key features of learning square transforms that may not be explicitly
controlled in a given optimization model. Unlike the existing approaches from
the literature, in our paper, we consider a new sparsifying transform model
that enforces explicit control over the data representation quality and the
condition number of the learned transforms. We confirm through numerical
experiments that our model presents better numerical behavior than the
state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03170" title="Abstract">arXiv:2403.03170</a> [<a href="/pdf/2403.03170" title="Download PDF">pdf</a>, <a href="/format/2403.03170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context  Misinformation Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+P">Peng Qi</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zehong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+W">Wynne Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M+L">Mong Li Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY)

</div>
<p class="mathjax">Misinformation is a prevalent societal issue due to its potential high risks.
Out-of-context (OOC) misinformation, where authentic images are repurposed with
false text, is one of the easiest and most effective ways to mislead audiences.
Current methods focus on assessing image-text consistency but lack convincing
explanations for their judgments, which is essential for debunking
misinformation. While Multimodal Large Language Models (MLLMs) have rich
knowledge and innate capability for visual reasoning and explanation
generation, they still lack sophistication in understanding and discovering the
subtle crossmodal differences. In this paper, we introduce SNIFFER, a novel
multimodal large language model specifically engineered for OOC misinformation
detection and explanation. SNIFFER employs two-stage instruction tuning on
InstructBLIP. The first stage refines the model's concept alignment of generic
objects with news-domain entities and the second stage leverages language-only
GPT-4 generated OOC-specific instruction data to fine-tune the model's
discriminatory powers. Enhanced by external tools and retrieval, SNIFFER not
only detects inconsistencies between text and image but also utilizes external
knowledge for contextual verification. Our experiments show that SNIFFER
surpasses the original MLLM by over 40% and outperforms state-of-the-art
methods in detection accuracy. SNIFFER also provides accurate and persuasive
explanations as validated by quantitative and human evaluations.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03172" title="Abstract">arXiv:2403.03172</a> [<a href="/pdf/2403.03172" title="Download PDF">pdf</a>, <a href="/format/2403.03172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reaching Consensus in Cooperative Multi-Agent Reinforcement Learning  with Goal Imagination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liangzhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Kaiwen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Fengming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xinghu Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shujie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+D">Deheng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Haobo Fu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Q">Qiang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wei Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Reaching consensus is key to multi-agent coordination. To accomplish a
cooperative task, agents need to coherently select optimal joint actions to
maximize the team reward. However, current cooperative multi-agent
reinforcement learning (MARL) methods usually do not explicitly take consensus
into consideration, which may cause miscoordination problem. In this paper, we
propose a model-based consensus mechanism to explicitly coordinate multiple
agents. The proposed Multi-agent Goal Imagination (MAGI) framework guides
agents to reach consensus with an Imagined common goal. The common goal is an
achievable state with high value, which is obtained by sampling from the
distribution of future states. We directly model this distribution with a
self-supervised generative model, thus alleviating the "curse of dimensinality"
problem induced by multi-agent multi-step policy rollout commonly used in
model-based methods. We show that such efficient consensus mechanism can guide
all agents cooperatively reaching valuable future states. Results on
Multi-agent Particle-Environments and Google Research Football environment
demonstrate the superiority of MAGI in both sample efficiency and performance.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03173" title="Abstract">arXiv:2403.03173</a> [<a href="/pdf/2403.03173" title="Download PDF">pdf</a>, <a href="/format/2403.03173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving the bongard-logo problem by modeling a probabilistic model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+R">Ruizhuo Song</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+B">Beiming Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 11 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Abstract reasoning problems challenge the perceptual and cognitive abilities
of AI algorithms, demanding deeper pattern discernment and inductive reasoning
beyond explicit image features. This study introduces PMoC, a tailored
probability model for the Bongard-Logo problem, achieving high reasoning
accuracy by constructing independent probability models. Additionally, we
present Pose-Transformer, an enhanced Transformer-Encoder designed for complex
abstract reasoning tasks, including Bongard-Logo, RAVEN, I-RAVEN, and PGM.
Pose-Transformer incorporates positional information learning, inspired by
capsule networks' pose matrices, enhancing its focus on local positional
relationships in image data processing. When integrated with PMoC, it further
improves reasoning accuracy. Our approach effectively addresses reasoning
difficulties associated with abstract entities' positional changes,
outperforming previous models on the OIG, D3$\times$3 subsets of RAVEN, and PGM
databases. This research contributes to advancing AI's capabilities in abstract
reasoning and cognitive pattern recognition.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03174" title="Abstract">arXiv:2403.03174</a> [<a href="/pdf/2403.03174" title="Download PDF">pdf</a>, <a href="/format/2403.03174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MOKA: Open-Vocabulary Robotic Manipulation through Mark-Based Visual  Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fangchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+K">Kuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Open-vocabulary generalization requires robotic systems to perform tasks
involving complex and diverse environments and task goals. While the recent
advances in vision language models (VLMs) present unprecedented opportunities
to solve unseen problems, how to utilize their emergent capabilities to control
robots in the physical world remains an open question. In this paper, we
present MOKA (Marking Open-vocabulary Keypoint Affordances), an approach that
employs VLMs to solve robotic manipulation tasks specified by free-form
language descriptions. At the heart of our approach is a compact point-based
representation of affordance and motion that bridges the VLM's predictions on
RGB images and the robot's motions in the physical world. By prompting a VLM
pre-trained on Internet-scale data, our approach predicts the affordances and
generates the corresponding motions by leveraging the concept understanding and
commonsense knowledge from broad sources. To scaffold the VLM's reasoning in
zero-shot, we propose a visual prompting technique that annotates marks on the
images, converting the prediction of keypoints and waypoints into a series of
visual question answering problems that are feasible for the VLM to solve.
Using the robot experiences collected in this way, we further investigate ways
to bootstrap the performance through in-context learning and policy
distillation. We evaluate and analyze MOKA's performance on a variety of
manipulation tasks specified by free-form language descriptions, such as tool
use, deformable body manipulation, and object rearrangement.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03176" title="Abstract">arXiv:2403.03176</a> [<a href="/pdf/2403.03176" title="Download PDF">pdf</a>, <a href="/ps/2403.03176" title="Download PostScript">ps</a>, <a href="/format/2403.03176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unifying and Certifying Top-Quality Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Katz%2C+M">Michael Katz</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Junkyu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Sohrabi%2C+S">Shirin Sohrabi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at ICAPS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The growing utilization of planning tools in practical scenarios has sparked
an interest in generating multiple high-quality plans. Consequently, a range of
computational problems under the general umbrella of top-quality planning were
introduced over a short time period, each with its own definition. In this
work, we show that the existing definitions can be unified into one, based on a
dominance relation. The different computational problems, therefore, simply
correspond to different dominance relations. Given the unified definition, we
can now certify the top-quality of the solutions, leveraging existing
certification of unsolvability and optimality. We show that task
transformations found in the existing literature can be employed for the
efficient certification of various top-quality planning problems and propose a
novel transformation to efficiently certify loopless top-quality planning.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03181" title="Abstract">arXiv:2403.03181</a> [<a href="/pdf/2403.03181" title="Download PDF">pdf</a>, <a href="/format/2403.03181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Behavior Generation with Latent Actions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seungjae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yibin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Etukuru%2C+H">Haritheja Etukuru</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H+J">H. Jin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Shafiullah%2C+N+M+M">Nur Muhammad Mahi Shafiullah</a>, 
<a href="/search/cs?searchtype=author&query=Pinto%2C+L">Lerrel Pinto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Github repo: <a href="https://github.com/jayLEE0301/vq_bet_official">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Generative modeling of complex behaviors from labeled datasets has been a
longstanding problem in decision making. Unlike language or image generation,
decision making requires modeling actions - continuous-valued vectors that are
multimodal in their distribution, potentially drawn from uncurated sources,
where generation errors can compound in sequential prediction. A recent class
of models called Behavior Transformers (BeT) addresses this by discretizing
actions using k-means clustering to capture different modes. However, k-means
struggles to scale for high-dimensional action spaces or long sequences, and
lacks gradient information, and thus BeT suffers in modeling long-range
actions. In this work, we present Vector-Quantized Behavior Transformer
(VQ-BeT), a versatile model for behavior generation that handles multimodal
action prediction, conditional generation, and partial observations. VQ-BeT
augments BeT by tokenizing continuous actions with a hierarchical vector
quantization module. Across seven environments including simulated
manipulation, autonomous driving, and robotics, VQ-BeT improves on
state-of-the-art models such as BeT and Diffusion Policies. Importantly, we
demonstrate VQ-BeT's improved ability to capture behavior modes while
accelerating inference speed 5x over Diffusion Policies. Videos and code can be
found https://sjlee.cc/vq-bet
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03182" title="Abstract">arXiv:2403.03182</a> [<a href="/pdf/2403.03182" title="Download PDF">pdf</a>, <a href="/format/2403.03182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the computation of stable coupled state-space models for dynamic  substructuring applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dias%2C+R+S+O">R.S.O. Dias</a>, 
<a href="/search/eess?searchtype=author&query=Martarelli%2C+M">M. Martarelli</a>, 
<a href="/search/eess?searchtype=author&query=Chiariotti%2C+P">P. Chiariotti</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Mechanical Systems and Signal Processing, Volume 205, 15 December
  2023, 110807
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Dynamical Systems (math.DS)

</div>
<p class="mathjax">This paper aims at introducing a methodology to compute stable coupled
state-space models for dynamic substructuring applications by introducing two
novel approaches targeted to accomplish this task: a) a procedure to impose
Newtons's second law without relying on the use of undamped RCMs (residual
compensation modes) and b) a novel approach to impose stability on unstable
coupled state-space models. The enforcement of stability is performed by
dividing the unstable model into two different models, one composed by the
stable poles (stable model) and the other composed by the unstable ones
(unstable model). Then, the poles of the unstable state-space model are forced
to be stable, leading to the computation of a stabilized state-space model.
Afterwards, to make sure that the Frequency Response Functions (FRFs) of the
stabilized model well match the FRFs of the unstable model, the Least-Squares
Frequency Domain (LSFD) method is exploited to update the modal parameters of
the stabilized model composed by the pairs of complex conjugate poles. The
validity of the proposed methodologies is presented and discussed by exploiting
experimental data. Indeed, by exploiting the FRFs of a real system, accurate
state-space models respecting Newton's second law are computed. Then,
decoupling and coupling operations are performed with the identified
state-space models, no matter the models resultant from the decoupling/coupling
operations are unstable. Stability is then imposed on the computed unstable
coupled model by following the approach proposed in this paper. The methodology
proved to work well on these data. Moreover, the paper also shows that the
coupled state-space models obtained using this methodology are suitable to be
exploited in time-domain analyses and simulations.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03183" title="Abstract">arXiv:2403.03183</a> [<a href="/pdf/2403.03183" title="Download PDF">pdf</a>, <a href="/format/2403.03183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Well Can Transformers Emulate In-context Newton&#x27;s Method?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giannou%2C+A">Angeliki Giannou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Papailiopoulos%2C+D">Dimitris Papailiopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+D">Jason D. Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Transformer-based models have demonstrated remarkable in-context learning
capabilities, prompting extensive research into its underlying mechanisms.
Recent studies have suggested that Transformers can implement first-order
optimization algorithms for in-context learning and even second order ones for
the case of linear regression. In this work, we study whether Transformers can
perform higher order optimization methods, beyond the case of linear
regression. We establish that linear attention Transformers with ReLU layers
can approximate second order optimization algorithms for the task of logistic
regression and achieve $\epsilon$ error with only a logarithmic to the error
more layers. As a by-product we demonstrate the ability of even linear
attention-only Transformers in implementing a single step of Newton's iteration
for matrix inversion with merely two layers. These results suggest the ability
of the Transformer architecture to implement complex algorithms, beyond
gradient descent.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03185" title="Abstract">arXiv:2403.03185</a> [<a href="/pdf/2403.03185" title="Download PDF">pdf</a>, <a href="/format/2403.03185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preventing Reward Hacking with Occupancy Measure Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laidlaw%2C+C">Cassidy Laidlaw</a>, 
<a href="/search/cs?searchtype=author&query=Singhal%2C+S">Shivam Singhal</a>, 
<a href="/search/cs?searchtype=author&query=Dragan%2C+A">Anca Dragan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Reward hacking occurs when an agent performs very well with respect to a
"proxy" reward function (which may be hand-specified or learned), but poorly
with respect to the unknown true reward. Since ensuring good alignment between
the proxy and true reward is extremely difficult, one approach to prevent
reward hacking is optimizing the proxy conservatively. Prior work has
particularly focused on enforcing the learned policy to behave similarly to a
"safe" policy by penalizing the KL divergence between their action
distributions (AD). However, AD regularization doesn't always work well since a
small change in action distribution at a single state can lead to potentially
calamitous outcomes, while large changes might not be indicative of any
dangerous activity. Our insight is that when reward hacking, the agent visits
drastically different states from those reached by the safe policy, causing
large deviations in state occupancy measure (OM). Thus, we propose regularizing
based on the OM divergence between policies instead of AD divergence to prevent
reward hacking. We theoretically establish that OM regularization can more
effectively avoid large drops in true reward. Then, we empirically demonstrate
in a variety of realistic environments that OM divergence is superior to AD
divergence for preventing reward hacking by regularizing towards a safe policy.
Furthermore, we show that occupancy measure divergence can also regularize
learned policies away from reward hacking behavior. Our code and data are
available at https://github.com/cassidylaidlaw/orpo
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03186" title="Abstract">arXiv:2403.03186</a> [<a href="/pdf/2403.03186" title="Download PDF">pdf</a>, <a href="/format/2403.03186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards General Computer Control: A Multimodal Agent for Red Dead  Redemption II as a Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Weihao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Ziluo Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wentao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bohan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+J">Junpeng Yue</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+H">Haochong Xia</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jiechuan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Longtao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xinrun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+Y">Yifei Bi</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+P">Pengjie Gu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinrun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Karlsson%2C+B+F">B&#xf6;rje F. Karlsson</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+B">Bo An</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zongqing Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Recent studies have demonstrated the success of foundation agents in specific
tasks or scenarios. However, existing agents cannot generalize across different
scenarios, mainly due to their diverse observation and action spaces and
semantic gaps, or reliance on task-specific resources. In this work, we propose
the General Computer Control (GCC) setting: building foundation agents that can
master any computer task by taking only screen images (and possibly audio) of
the computer as input, and producing keyboard and mouse operations as output,
similar to human-computer interaction. To target GCC, we propose Cradle, an
agent framework with strong reasoning abilities, including self-reflection,
task inference, and skill curation, to ensure generalizability and
self-improvement across various tasks. To demonstrate the capabilities of
Cradle, we deploy it in the complex AAA game Red Dead Redemption II, serving as
a preliminary attempt towards GCC with a challenging target. Our agent can
follow the main storyline and finish real missions in this complex AAA game,
with minimal reliance on prior knowledge and application-specific resources.
The project website is at https://baai-agents.github.io/Cradle/.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03187" title="Abstract">arXiv:2403.03187</a> [<a href="/pdf/2403.03187" title="Download PDF">pdf</a>, <a href="/format/2403.03187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reliable, Adaptable, and Attributable Language Models with Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Asai%2C+A">Akari Asai</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zexuan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Danqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Koh%2C+P+W">Pang Wei Koh</a>, 
<a href="/search/cs?searchtype=author&query=Zettlemoyer%2C+L">Luke Zettlemoyer</a>, 
<a href="/search/cs?searchtype=author&query=Hajishirzi%2C+H">Hannaneh Hajishirzi</a>, 
<a href="/search/cs?searchtype=author&query=Yih%2C+W">Wen-tau Yih</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Parametric language models (LMs), which are trained on vast amounts of web
data, exhibit remarkable flexibility and capability. However, they still face
practical challenges such as hallucinations, difficulty in adapting to new data
distributions, and a lack of verifiability. In this position paper, we advocate
for retrieval-augmented LMs to replace parametric LMs as the next generation of
LMs. By incorporating large-scale datastores during inference,
retrieval-augmented LMs can be more reliable, adaptable, and attributable.
Despite their potential, retrieval-augmented LMs have yet to be widely adopted
due to several obstacles: specifically, current retrieval-augmented LMs
struggle to leverage helpful text beyond knowledge-intensive tasks such as
question answering, have limited interaction between retrieval and LM
components, and lack the infrastructure for scaling. To address these, we
propose a roadmap for developing general-purpose retrieval-augmented LMs. This
involves a reconsideration of datastores and retrievers, the exploration of
pipelines with improved retriever-LM interaction, and significant investment in
infrastructure for efficient training and inference.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03188" title="Abstract">arXiv:2403.03188</a> [<a href="/pdf/2403.03188" title="Download PDF">pdf</a>, <a href="/ps/2403.03188" title="Download PostScript">ps</a>, <a href="/format/2403.03188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Democratized Flood Risk Management: An Advanced AI Assistant  Enabled by GPT-4 for Enhanced Interpretability and Public Engagement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martelo%2C+R">Rafaela Martelo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruo-Qian Wang</a> (Rutgers University)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, 3 figures and an appendix with 2 supplementary tables detailing experimental results and observations. Supported by Rutgers's Research Incubator in Climate and Health, Seed Funding Initiative and Research Council Award - "Engaged Climate Action". Source code and data available at <a href="https://github.com/RafaelaMartelo/FloodGPT-4_Prototype">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Real-time flood forecasting plays a crucial role in enabling timely and
effective emergency responses. However, a significant challenge lies in
bridging the gap between complex numerical flood models and practical
decision-making. Decision-makers often rely on experts to interpret these
models for optimizing flood mitigation strategies. And the public requires
complex techniques to inquiry and understand socio-cultural and institutional
factors, often hinders the public's understanding of flood risks. To overcome
these challenges, our study introduces an innovative solution: a customized AI
Assistant powered by the GPT-4 Large Language Model. This AI Assistant is
designed to facilitate effective communication between decision-makers, the
general public, and flood forecasters, without the requirement of specialized
knowledge. The new framework utilizes GPT-4's advanced natural language
understanding and function calling capabilities to provide immediate flood
alerts and respond to various flood-related inquiries. Our developed prototype
integrates real-time flood warnings with flood maps and social vulnerability
data. It also effectively translates complex flood zone information into
actionable risk management advice. To assess its performance, we evaluated the
prototype using six criteria within three main categories: relevance, error
resilience, and understanding of context. Our research marks a significant step
towards a more accessible and user-friendly approach in flood risk management.
This study highlights the potential of advanced AI tools like GPT-4 in
democratizing information and enhancing public engagement in critical social
and environmental issues.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03190" title="Abstract">arXiv:2403.03190</a> [<a href="/pdf/2403.03190" title="Download PDF">pdf</a>, <a href="/format/2403.03190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Triple-CFN: Restructuring Conceptual Spaces for Enhancing Abstract  Reasoning process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+R">Ruizhuo Song</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+B">Beiming Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Abstract reasoning problems pose significant challenges to artificial
intelligence algorithms, demanding cognitive capabilities beyond those required
for perception tasks. This study introduces the Triple-CFN approach to tackle
the Bongard-Logo problem, achieving notable reasoning accuracy by implicitly
reorganizing the concept space of conflicting instances. Additionally, the
Triple-CFN paradigm proves effective for the RPM problem with necessary
modifications, yielding competitive results. To further enhance performance on
the RPM issue, we develop the Meta Triple-CFN network, which explicitly
structures the problem space while maintaining interpretability on progressive
patterns. The success of Meta Triple-CFN is attributed to its paradigm of
modeling the conceptual space, equivalent to normalizing reasoning information.
Based on this ideology, we introduce the Re-space layer, enhancing the
performance of both Meta Triple-CFN and Triple-CFN. This paper aims to
contribute to advancements in machine intelligence by exploring innovative
network designs for addressing abstract reasoning problems, paving the way for
further breakthroughs in this domain.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03193" title="Abstract">arXiv:2403.03193</a> [<a href="/pdf/2403.03193" title="Download PDF">pdf</a>, <a href="/format/2403.03193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VeriEQL: Bounded Equivalence Verification for Complex SQL Queries with  Integrity Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yang He</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Pinhan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuepeng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> OOPSLA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Databases (cs.DB)

</div>
<p class="mathjax">The task of SQL query equivalence checking is important in various real-world
applications (including query rewriting and automated grading) that involve
complex queries with integrity constraints; yet, state-of-the-art techniques
are very limited in their capability of reasoning about complex features (e.g.,
those that involve sorting, case statement, rich integrity constraints, etc.)
in real-life queries. To the best of our knowledge, we propose the first
SMT-based approach and its implementation, VeriEQL, capable of proving and
disproving bounded equivalence of complex SQL queries. VeriEQL is based on a
new logical encoding that models query semantics over symbolic tuples using the
theory of integers with uninterpreted functions. It is simple yet highly
practical -- our comprehensive evaluation on over 20,000 benchmarks shows that
VeriEQL outperforms all state-of-the-art techniques by more than one order of
magnitude in terms of the number of benchmarks that can be proved or disproved.
VeriEQL can also generate counterexamples that facilitate many downstream tasks
(such as finding serious bugs in systems like MySQL and Apache Calcite).
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03194" title="Abstract">arXiv:2403.03194</a> [<a href="/pdf/2403.03194" title="Download PDF">pdf</a>, <a href="/format/2403.03194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAGID: An Automated Pipeline for Generating Synthetic Multi-modal  Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aboutalebi%2C+H">Hossein Aboutalebi</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hwanjun Song</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yusheng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Arshit Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Justin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hang Su</a>, 
<a href="/search/cs?searchtype=author&query=Shalyminov%2C+I">Igor Shalyminov</a>, 
<a href="/search/cs?searchtype=author&query=Pappas%2C+N">Nikolaos Pappas</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Siffi Singh</a>, 
<a href="/search/cs?searchtype=author&query=Mansour%2C+S">Saab Mansour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Development of multimodal interactive systems is hindered by the lack of
rich, multimodal (text, images) conversational data, which is needed in large
quantities for LLMs. Previous approaches augment textual dialogues with
retrieved images, posing privacy, diversity, and quality constraints. In this
work, we introduce \textbf{M}ultimodal \textbf{A}ugmented \textbf{G}enerative
\textbf{I}mages \textbf{D}ialogues (MAGID), a framework to augment text-only
dialogues with diverse and high-quality images. Subsequently, a diffusion model
is applied to craft corresponding images, ensuring alignment with the
identified text. Finally, MAGID incorporates an innovative feedback loop
between an image description generation module (textual LLM) and image quality
modules (addressing aesthetics, image-text matching, and safety), that work in
tandem to generate high-quality and multi-modal dialogues. We compare MAGID to
other SOTA baselines on three dialogue datasets, using automated and human
evaluation. Our results show that MAGID is comparable to or better than
baselines, with significant improvements in human evaluation, especially
against retrieval baselines where the image database is small.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03196" title="Abstract">arXiv:2403.03196</a> [<a href="/pdf/2403.03196" title="Download PDF">pdf</a>, <a href="/ps/2403.03196" title="Download PostScript">ps</a>, <a href="/format/2403.03196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SmartSantander: IoT Experimentation over a Smart City Testbed
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanchez%2C+L">Luis Sanchez</a>, 
<a href="/search/cs?searchtype=author&query=Mu%C3%B1oz%2C+L">Luis Mu&#xf1;oz</a>, 
<a href="/search/cs?searchtype=author&query=Galache%2C+J+A">Jose Antonio Galache</a>, 
<a href="/search/cs?searchtype=author&query=Sotres%2C+P">Pablo Sotres</a>, 
<a href="/search/cs?searchtype=author&query=Santana%2C+J+R">Juan R. Santana</a>, 
<a href="/search/cs?searchtype=author&query=Gutierrez%2C+V">Veronica Gutierrez</a>, 
<a href="/search/cs?searchtype=author&query=Ramdhany%2C+R">Rajiv Ramdhany</a>, 
<a href="/search/cs?searchtype=author&query=Gluhak%2C+A">Alex Gluhak</a>, 
<a href="/search/cs?searchtype=author&query=Krco%2C+S">Srdjan Krco</a>, 
<a href="/search/cs?searchtype=author&query=Theodoridis%2C+E">Evangelos Theodoridis</a>, 
<a href="/search/cs?searchtype=author&query=Pfisterer%2C+D">Dennis Pfisterer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is published in Elsevier Computer Networks. This work has been funded by research project SmartSantander, under FP7-ICT-2009-5 of the 7th Framework Programme of the European Community
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Networks, Volume 61, 14 March 2014, Pages 217-238
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper describes the deployment and experimentation architecture of the
Internet of Things experimentation facility being deployed at Santander city.
The facility is implemented within the SmartSantander project, one of the
projects of the Future Internet Research and Experimentation initiative of the
European Commission and represents a unique in the world city-scale
experimental research facility. Additionally, this facility supports typical
applications and services of a smart city. Tangible results are expected to
influence the definition and specification of Future Internet architecture
design from viewpoints of Internet of Things and Internet of Services. The
facility comprises a large number of Internet of Things devices deployed in
several urban scenarios which will be federated into a single testbed. In this
paper the deployment being carried out at the main location, namely Santander
city, is described. Besides presenting the current deployment, in this article
the main insights in terms of the architectural design of a large-scale IoT
testbed are presented as well. Furthermore, solutions adopted for
implementation of the different components addressing the required testbed
functionalities are also sketched out. The IoT experimentation facility
described in this paper is conceived to provide a suitable platform for large
scale experimentation and evaluation of IoT concepts under real-life
conditions.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03203" title="Abstract">arXiv:2403.03203</a> [<a href="/pdf/2403.03203" title="Download PDF">pdf</a>, <a href="/format/2403.03203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLEVR-POC: Reasoning-Intensive Visual Question Answering in Partially  Observable Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abraham%2C+S+S">Savitha Sam Abraham</a>, 
<a href="/search/cs?searchtype=author&query=Alirezaie%2C+M">Marjan Alirezaie</a>, 
<a href="/search/cs?searchtype=author&query=De+Raedt%2C+L">Luc De Raedt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 10 images, Accepted at LREC-COLING 2024 - The 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The integration of learning and reasoning is high on the research agenda in
AI. Nevertheless, there is only a little attention to use existing background
knowledge for reasoning about partially observed scenes to answer questions
about the scene. Yet, we as humans use such knowledge frequently to infer
plausible answers to visual questions (by eliminating all inconsistent ones).
Such knowledge often comes in the form of constraints about objects and it
tends to be highly domain or environment-specific. We contribute a novel
benchmark called CLEVR-POC for reasoning-intensive visual question answering
(VQA) in partially observable environments under constraints. In CLEVR-POC,
knowledge in the form of logical constraints needs to be leveraged to generate
plausible answers to questions about a hidden object in a given partial scene.
For instance, if one has the knowledge that all cups are colored either red,
green or blue and that there is only one green cup, it becomes possible to
deduce the color of an occluded cup as either red or blue, provided that all
other cups, including the green one, are observed. Through experiments, we
observe that the low performance of pre-trained vision language models like
CLIP (~ 22%) and a large language model (LLM) like GPT-4 (~ 46%) on CLEVR-POC
ascertains the necessity for frameworks that can handle reasoning-intensive
tasks where environment-specific background knowledge is available and crucial.
Furthermore, our demonstration illustrates that a neuro-symbolic model, which
integrates an LLM like GPT-4 with a visual perception network and a formal
logical reasoner, exhibits exceptional performance on CLEVR-POC.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03206" title="Abstract">arXiv:2403.03206</a> [<a href="/pdf/2403.03206" title="Download PDF">pdf</a>, <a href="/format/2403.03206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Rectified Flow Transformers for High-Resolution Image Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esser%2C+P">Patrick Esser</a>, 
<a href="/search/cs?searchtype=author&query=Kulal%2C+S">Sumith Kulal</a>, 
<a href="/search/cs?searchtype=author&query=Blattmann%2C+A">Andreas Blattmann</a>, 
<a href="/search/cs?searchtype=author&query=Entezari%2C+R">Rahim Entezari</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+J">Jonas M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Saini%2C+H">Harry Saini</a>, 
<a href="/search/cs?searchtype=author&query=Levi%2C+Y">Yam Levi</a>, 
<a href="/search/cs?searchtype=author&query=Lorenz%2C+D">Dominik Lorenz</a>, 
<a href="/search/cs?searchtype=author&query=Sauer%2C+A">Axel Sauer</a>, 
<a href="/search/cs?searchtype=author&query=Boesel%2C+F">Frederic Boesel</a>, 
<a href="/search/cs?searchtype=author&query=Podell%2C+D">Dustin Podell</a>, 
<a href="/search/cs?searchtype=author&query=Dockhorn%2C+T">Tim Dockhorn</a>, 
<a href="/search/cs?searchtype=author&query=English%2C+Z">Zion English</a>, 
<a href="/search/cs?searchtype=author&query=Lacey%2C+K">Kyle Lacey</a>, 
<a href="/search/cs?searchtype=author&query=Goodwin%2C+A">Alex Goodwin</a>, 
<a href="/search/cs?searchtype=author&query=Marek%2C+Y">Yannik Marek</a>, 
<a href="/search/cs?searchtype=author&query=Rombach%2C+R">Robin Rombach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion models create data from noise by inverting the forward paths of
data towards noise and have emerged as a powerful generative modeling technique
for high-dimensional, perceptual data such as images and videos. Rectified flow
is a recent generative model formulation that connects data and noise in a
straight line. Despite its better theoretical properties and conceptual
simplicity, it is not yet decisively established as standard practice. In this
work, we improve existing noise sampling techniques for training rectified flow
models by biasing them towards perceptually relevant scales. Through a
large-scale study, we demonstrate the superior performance of this approach
compared to established diffusion formulations for high-resolution
text-to-image synthesis. Additionally, we present a novel transformer-based
architecture for text-to-image generation that uses separate weights for the
two modalities and enables a bidirectional flow of information between image
and text tokens, improving text comprehension, typography, and human preference
ratings. We demonstrate that this architecture follows predictable scaling
trends and correlates lower validation loss to improved text-to-image synthesis
as measured by various metrics and human evaluations. Our largest models
outperform state-of-the-art models, and we will make our experimental data,
code, and model weights publicly available.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03213" title="Abstract">arXiv:2403.03213</a> [<a href="/pdf/2403.03213" title="Download PDF">pdf</a>, <a href="/format/2403.03213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the computation of lattice sums without translational invariance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Buchheit%2C+A+A">Andreas A. Buchheit</a>, 
<a href="/search/math?searchtype=author&query=Ke%C3%9Fler%2C+T">Torsten Ke&#xdf;ler</a>, 
<a href="/search/math?searchtype=author&query=Serkh%2C+K">Kirill Serkh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Strongly Correlated Electrons (cond-mat.str-el); High Energy Physics - Lattice (hep-lat)

</div>
<p class="mathjax">This work introduces a framework for the efficient computation of oscillatory
multidimensional lattice sums in geometries with boundaries, a problem
intersecting pure and applied mathematics with immediate applications in
condensed matter physics and topological quantum physics. The challenge in
evaluating the arising sums results from the combination of singular long-range
interactions with the loss of translational invariance caused by the
boundaries, rendering standard tools ineffective. Our work shows that these
lattice sums can be generated from a generalization of the Riemann zeta
function to multidimensional non-periodic lattice sums. We put forth a new
representation of this zeta function together with a numerical algorithm that
ensures super-exponential convergence across an extensive range of geometries.
Notably, our method's runtime is influenced only by the complexity of the
considered geometries and not by the sheer number of particles, providing the
foundation for efficient simulations of macroscopic condensed matter systems.
We showcase the practical utility of our method by computing interaction
energies in a three-dimensional crystal structure with $3\times 10^{23}$
particles. Our method's accuracy is thoroughly assessed through a detailed
error analysis that both uses analytical results and numerical experiments. A
reference implementation is provided online along with the article
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03215" title="Abstract">arXiv:2403.03215</a> [<a href="/pdf/2403.03215" title="Download PDF">pdf</a>, <a href="/format/2403.03215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Safety-Critical Framework for UGVs in Complex Environments: A  Data-Driven Discrepancy-Aware Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+S+X">Skylar X. Wei</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+L">Lu Gan</a>, 
<a href="/search/cs?searchtype=author&query=Burdick%2C+J+W">Joel W. Burdick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This work presents a novel data-driven multi-layered planning and control
framework for the safe navigation of a class of unmanned ground vehicles (UGVs)
in the presence of unknown stationary obstacles and additive modeling
uncertainties. The foundation of this framework is a novel robust model
predictive planner, designed to generate optimal collision-free trajectories
given an occupancy grid map, and a paired ancillary controller, augmented to
provide robustness against model uncertainties extracted from learning data.
<br />To tackle modeling discrepancies, we identify both matched (input
discrepancies) and unmatched model residuals between the true and the nominal
reduced-order models using closed-loop tracking errors as training data.
Utilizing conformal prediction, we extract probabilistic upper bounds for the
unknown model residuals, which serve to construct a robustifying ancillary
controller. Further, we also determine maximum tracking discrepancies, also
known as the robust control invariance tube, under the augmented policy,
formulating them as collision buffers. Employing a LiDAR-based occupancy map to
characterize the environment, we construct a discrepancy-aware cost map that
incorporates these collision buffers. This map is then integrated into a
sampling-based model predictive path planner that generates optimal and safe
trajectories that can be robustly tracked by the augmented ancillary controller
in the presence of model mismatches.
<br />The effectiveness of the framework is experimentally validated for autonomous
high-speed trajectory tracking in a cluttered environment with four different
vehicle-terrain configurations. We also showcase the framework's versatility by
reformulating it as a driver-assist program, providing collision avoidance
corrections based on user joystick commands.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03217" title="Abstract">arXiv:2403.03217</a> [<a href="/pdf/2403.03217" title="Download PDF">pdf</a>, <a href="/format/2403.03217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised 3D Patient Modeling with Multi-modal Attentive Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Meng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Planche%2C+B">Benjamin Planche</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+X">Xuan Gong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Terrence Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Ziyan Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MICCAI 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D patient body modeling is critical to the success of automated patient
positioning for smart medical scanning and operating rooms. Existing CNN-based
end-to-end patient modeling solutions typically require a) customized network
designs demanding large amount of relevant training data, covering extensive
realistic clinical scenarios (e.g., patient covered by sheets), which leads to
suboptimal generalizability in practical deployment, b) expensive 3D human
model annotations, i.e., requiring huge amount of manual effort, resulting in
systems that scale poorly. To address these issues, we propose a generic
modularized 3D patient modeling method consists of (a) a multi-modal keypoint
detection module with attentive fusion for 2D patient joint localization, to
learn complementary cross-modality patient body information, leading to
improved keypoint localization robustness and generalizability in a wide
variety of imaging (e.g., CT, MRI etc.) and clinical scenarios (e.g., heavy
occlusions); and (b) a self-supervised 3D mesh regression module which does not
require expensive 3D mesh parameter annotations to train, bringing immediate
cost benefits for clinical deployment. We demonstrate the efficacy of the
proposed method by extensive patient positioning experiments on both public and
clinical data. Our evaluation results achieve superior patient positioning
performance across various imaging modalities in real clinical scenarios.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03218" title="Abstract">arXiv:2403.03218</a> [<a href="/pdf/2403.03218" title="Download PDF">pdf</a>, <a href="/format/2403.03218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Nathaniel Li</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+A">Alexander Pan</a>, 
<a href="/search/cs?searchtype=author&query=Gopal%2C+A">Anjali Gopal</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+S">Summer Yue</a>, 
<a href="/search/cs?searchtype=author&query=Berrios%2C+D">Daniel Berrios</a>, 
<a href="/search/cs?searchtype=author&query=Gatti%2C+A">Alice Gatti</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J+D">Justin D. Li</a>, 
<a href="/search/cs?searchtype=author&query=Dombrowski%2C+A">Ann-Kathrin Dombrowski</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+S">Shashwat Goel</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+L">Long Phan</a>, 
<a href="/search/cs?searchtype=author&query=Mukobi%2C+G">Gabriel Mukobi</a>, 
<a href="/search/cs?searchtype=author&query=Helm-Burger%2C+N">Nathan Helm-Burger</a>, 
<a href="/search/cs?searchtype=author&query=Lababidi%2C+R">Rassin Lababidi</a>, 
<a href="/search/cs?searchtype=author&query=Justen%2C+L">Lennart Justen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A+B">Andrew B. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Michael Chen</a>, 
<a href="/search/cs?searchtype=author&query=Barrass%2C+I">Isabelle Barrass</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+O">Oliver Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaoyuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tamirisa%2C+R">Rishub Tamirisa</a>, 
<a href="/search/cs?searchtype=author&query=Bharathi%2C+B">Bhrugu Bharathi</a>, 
<a href="/search/cs?searchtype=author&query=Khoja%2C+A">Adam Khoja</a>, 
<a href="/search/cs?searchtype=author&query=Herbert-Voss%2C+A">Ariel Herbert-Voss</a>, 
<a href="/search/cs?searchtype=author&query=Breuer%2C+C+B">Cort B. Breuer</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+A">Andy Zou</a>, 
<a href="/search/cs?searchtype=author&query=Mazeika%2C+M">Mantas Mazeika</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Oswal%2C+P">Palash Oswal</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiran Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hunt%2C+A+A">Adam A. Hunt</a>, 
<a href="/search/cs?searchtype=author&query=Tienken-Harder%2C+J">Justin Tienken-Harder</a>, 
<a href="/search/cs?searchtype=author&query=Shih%2C+K+Y">Kevin Y. Shih</a>, 
<a href="/search/cs?searchtype=author&query=Talley%2C+K">Kemper Talley</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+J">John Guan</a>, 
<a href="/search/cs?searchtype=author&query=Kaplan%2C+R">Russell Kaplan</a>, 
<a href="/search/cs?searchtype=author&query=Steneker%2C+I">Ian Steneker</a>, 
<a href="/search/cs?searchtype=author&query=Campbell%2C+D">David Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Jokubaitis%2C+B">Brad Jokubaitis</a>, 
<a href="/search/cs?searchtype=author&query=Levinson%2C+A">Alex Levinson</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jean Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+W">William Qian</a>, 
<a href="/search/cs?searchtype=author&query=Karmakar%2C+K+K">Kallol Krishna Karmakar</a>, 
<a href="/search/cs?searchtype=author&query=Basart%2C+S">Steven Basart</a>, 
<a href="/search/cs?searchtype=author&query=Fitz%2C+S">Stephen Fitz</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+M">Mindy Levine</a>, 
<a href="/search/cs?searchtype=author&query=Kumaraguru%2C+P">Ponnurangam Kumaraguru</a>, 
<a href="/search/cs?searchtype=author&query=Tupakula%2C+U">Uday Tupakula</a>, 
<a href="/search/cs?searchtype=author&query=Varadharajan%2C+V">Vijay Varadharajan</a>, 
<a href="/search/cs?searchtype=author&query=Shoshitaishvili%2C+Y">Yan Shoshitaishvili</a>, 
<a href="/search/cs?searchtype=author&query=Ba%2C+J">Jimmy Ba</a>, 
<a href="/search/cs?searchtype=author&query=Esvelt%2C+K+M">Kevin M. Esvelt</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Alexandr Wang</a>,  et al. (1 additional author not shown)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> See the project page at <a href="https://wmdp.ai">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY)

</div>
<p class="mathjax">The White House Executive Order on Artificial Intelligence highlights the
risks of large language models (LLMs) empowering malicious actors in developing
biological, cyber, and chemical weapons. To measure these risks of malicious
use, government institutions and major AI labs are developing evaluations for
hazardous capabilities in LLMs. However, current evaluations are private,
preventing further research into mitigating risk. Furthermore, they focus on
only a few, highly specific pathways for malicious use. To fill these gaps, we
publicly release the Weapons of Mass Destruction Proxy (WMDP) benchmark, a
dataset of 4,157 multiple-choice questions that serve as a proxy measurement of
hazardous knowledge in biosecurity, cybersecurity, and chemical security. WMDP
was developed by a consortium of academics and technical consultants, and was
stringently filtered to eliminate sensitive information prior to public
release. WMDP serves two roles: first, as an evaluation for hazardous knowledge
in LLMs, and second, as a benchmark for unlearning methods to remove such
hazardous knowledge. To guide progress on unlearning, we develop CUT, a
state-of-the-art unlearning method based on controlling model representations.
CUT reduces model performance on WMDP while maintaining general capabilities in
areas such as biology and computer science, suggesting that unlearning may be a
concrete path towards reducing malicious use from LLMs. We release our
benchmark and code publicly at https://wmdp.ai
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03219" title="Abstract">arXiv:2403.03219</a> [<a href="/pdf/2403.03219" title="Download PDF">pdf</a>, <a href="/ps/2403.03219" title="Download PostScript">ps</a>, <a href="/format/2403.03219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LC-Tsalis-INF: Generalized Best-of-Both-Worlds Linear Contextual Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kato%2C+M">Masahiro Kato</a>, 
<a href="/search/cs?searchtype=author&query=Ito%2C+S">Shinji Ito</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">This study considers the linear contextual bandit problem with independent
and identically distributed (i.i.d.) contexts. In this problem, existing
studies have proposed Best-of-Both-Worlds (BoBW) algorithms whose regrets
satisfy $O(\log^2(T))$ for the number of rounds $T$ in a stochastic regime with
a suboptimality gap lower-bounded by a positive constant, while satisfying
$O(\sqrt{T})$ in an adversarial regime. However, the dependency on $T$ has room
for improvement, and the suboptimality-gap assumption can be relaxed. For this
issue, this study proposes an algorithm whose regret satisfies $O(\log(T))$ in
the setting when the suboptimality gap is lower-bounded. Furthermore, we
introduce a margin condition, a milder assumption on the suboptimality gap.
That condition characterizes the problem difficulty linked to the suboptimality
gap using a parameter $\beta \in (0, \infty]$. We then show that the
algorithm's regret satisfies
$O\left(\left\{\log(T)\right\}^{\frac{1+\beta}{2+\beta}}T^{\frac{1}{2+\beta}}\right)$.
Here, $\beta= \infty$ corresponds to the case in the existing studies where a
lower bound exists in the suboptimality gap, and our regret satisfies
$O(\log(T))$ in that case. Our proposed algorithm is based on the
Follow-The-Regularized-Leader with the Tsallis entropy and referred to as the
$\alpha$-Linear-Contextual (LC)-Tsallis-INF.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03221" title="Abstract">arXiv:2403.03221</a> [<a href="/pdf/2403.03221" title="Download PDF">pdf</a>, <a href="/format/2403.03221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAR: Flexible, Accurate and Robust 6DoF Relative Camera Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rockwell%2C+C">Chris Rockwell</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+N">Nilesh Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Linyi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J+J">Jeong Joon Park</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+J">Justin Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Fouhey%2C+D+F">David F. Fouhey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024. Project Page: <a href="https://crockwell.github.io/far/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Estimating relative camera poses between images has been a central problem in
computer vision. Methods that find correspondences and solve for the
fundamental matrix offer high precision in most cases. Conversely, methods
predicting pose directly using neural networks are more robust to limited
overlap and can infer absolute translation scale, but at the expense of reduced
precision. We show how to combine the best of both methods; our approach yields
results that are both precise and robust, while also accurately inferring
translation scales. At the heart of our model lies a Transformer that (1)
learns to balance between solved and learned pose estimations, and (2) provides
a prior to guide a solver. A comprehensive analysis supports our design choices
and demonstrates that our method adapts flexibly to various feature extractors
and correspondence estimators, showing state-of-the-art performance in 6DoF
pose estimation on Matterport3D, InteriorNet, StreetLearn, and Map-free
Relocalization.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Wed,  6 Mar 24</h3>
<dl>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00957" title="Abstract">arXiv:2403.00957</a> (cross-list from stat.ME) [<a href="/pdf/2403.00957" title="Download PDF">pdf</a>, <a href="/format/2403.00957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resolution of Simpson&#x27;s paradox via the common cause principle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hovhannisyan%2C+A">A. Hovhannisyan</a>, 
<a href="/search/stat?searchtype=author&query=Allahverdyan%2C+A+E">A. E. Allahverdyan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Artificial Intelligence (cs.AI); Probability (math.PR); Data Analysis, Statistics and Probability (physics.data-an); Applications (stat.AP)

</div>
<p class="mathjax">Simpson's paradox is an obstacle to establishing a probabilistic association
between two events $a_1$ and $a_2$, given the third (lurking) random variable
$B$. We focus on scenarios when the random variables $A$ (which combines $a_1$,
$a_2$, and their complements) and $B$ have a common cause $C$ that need not be
observed. Alternatively, we can assume that $C$ screens out $A$ from $B$. For
such cases, the correct association between $a_1$ and $a_2$ is to be defined
via conditioning over $C$. This set-up generalizes the original Simpson's
paradox. Now its two contradicting options simply refer to two particular and
different causes $C$. We show that if $B$ and $C$ are binary and $A$ is
quaternary (the minimal and the most widespread situation for valid Simpson's
paradox), the conditioning over any binary common cause $C$ establishes the
same direction of the association between $a_1$ and $a_2$ as the conditioning
over $B$ in the original formulation of the paradox. Thus, for the minimal
common cause, one should choose the option of Simpson's paradox that assumes
conditioning over $B$ and not its marginalization. For tertiary (unobserved)
common causes $C$ all three options of Simpson's paradox become possible (i.e.
marginalized, conditional, and none of them), and one needs prior information
on $C$ to choose the right option.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02342" title="Abstract">arXiv:2403.02342</a> (cross-list from physics.soc-ph) [<a href="/pdf/2403.02342" title="Download PDF">pdf</a>, <a href="/ps/2403.02342" title="Download PostScript">ps</a>, <a href="/format/2403.02342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entanglement: Balancing Punishment and Compensation, Repeated Dilemma  Game-Theoretic Analysis of Maximum Compensation Problem for Bypass and Least  Cost Paths in Fact-Checking, Case of Fake News with Weak Wallace&#x27;s Law
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kawahata%2C+Y">Yasuko Kawahata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Recurring Dilemma, Wallace's Law, Entanglement, Detour Path, Least Cost Path, Metzler Function, Metzler Matrix, Fake News, Fact-Checking, Punitive Dominance Problem, Maximum Compensation Problem, Informational health
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Artificial Intelligence (cs.AI); Theoretical Economics (econ.TH)

</div>
<p class="mathjax">This research note is organized with respect to a novel approach to solving
problems related to the spread of fake news and effective fact-checking.
Focusing on the least-cost routing problem, the discussion is organized with
respect to the use of Metzler functions and Metzler matrices to model the
dynamics of information propagation among news providers. With this approach,
we designed a strategy to minimize the spread of fake news, which is
detrimental to informational health, while at the same time maximizing the
spread of credible information. In particular, through the punitive dominance
problem and the maximum compensation problem, we developed and examined a path
to reassess the incentives of news providers to act and to analyze their impact
on the equilibrium of the information market. By applying the concept of
entanglement to the context of information propagation, we shed light on the
complexity of interactions among news providers and contribute to the
formulation of more effective information management strategies. This study
provides new theoretical and practical insights into issues related to fake
news and fact-checking, and will be examined against improving informational
health and public digital health.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02371" title="Abstract">arXiv:2403.02371</a> (cross-list from eess.AS) [<a href="/pdf/2403.02371" title="Download PDF">pdf</a>, <a href="/format/2403.02371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuroVoz: a Castillian Spanish corpus of parkinsonian speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mendes-Laureano%2C+J">Jana&#xed;na Mendes-Laureano</a>, 
<a href="/search/eess?searchtype=author&query=G%C3%B3mez-Garc%C3%ADa%2C+J+A">Jorge A. G&#xf3;mez-Garc&#xed;a</a>, 
<a href="/search/eess?searchtype=author&query=Guerrero-L%C3%B3pez%2C+A">Alejandro Guerrero-L&#xf3;pez</a>, 
<a href="/search/eess?searchtype=author&query=Luque-Buzo%2C+E">Elisa Luque-Buzo</a>, 
<a href="/search/eess?searchtype=author&query=Arias-Londo%C3%B1o%2C+J+D">Juli&#xe1;n D. Arias-Londo&#xf1;o</a>, 
<a href="/search/eess?searchtype=author&query=Grandas-P%C3%A9rez%2C+F+J">Francisco J. Grandas-P&#xe9;rez</a>, 
<a href="/search/eess?searchtype=author&query=Godino-Llorente%2C+J+I">Juan I. Godino-Llorente</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Sound (cs.SD)

</div>
<p class="mathjax">The advancement of Parkinson's Disease (PD) diagnosis through speech analysis
is hindered by a notable lack of publicly available, diverse language datasets,
limiting the reproducibility and further exploration of existing research.
<br />In response to this gap, we introduce a comprehensive corpus from 108 native
Castilian Spanish speakers, comprising 55 healthy controls and 53 individuals
diagnosed with PD, all of whom were under pharmacological treatment and
recorded in their medication-optimized state. This unique dataset features a
wide array of speech tasks, including sustained phonation of the five Spanish
vowels, diadochokinetic tests, 16 listen-and-repeat utterances, and free
monologues. The dataset emphasizes accuracy and reliability through specialist
manual transcriptions of the listen-and-repeat tasks and utilizes Whisper for
automated monologue transcriptions, making it the most complete public corpus
of Parkinsonian speech, and the first in Castillian Spanish.
<br />NeuroVoz is composed by 2,903 audio recordings averaging $26.88 \pm 3.35$
recordings per participant, offering a substantial resource for the scientific
exploration of PD's impact on speech. This dataset has already underpinned
several studies, achieving a benchmark accuracy of 89% in PD speech pattern
identification, indicating marked speech alterations attributable to PD.
Despite these advances, the broader challenge of conducting a
language-agnostic, cross-corpora analysis of Parkinsonian speech patterns
remains an open area for future research. This contribution not only fills a
critical void in PD speech analysis resources but also sets a new standard for
the global research community in leveraging speech as a diagnostic tool for
neurodegenerative diseases.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02405" title="Abstract">arXiv:2403.02405</a> (cross-list from quant-ph) [<a href="/pdf/2403.02405" title="Download PDF">pdf</a>, <a href="/format/2403.02405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification of the Fashion-MNIST Dataset on a Quantum Computer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Shen%2C+K">Kevin Shen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jobst%2C+B">Bernhard Jobst</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shishenina%2C+E">Elvira Shishenina</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pollmann%2C+F">Frank Pollmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> (15 pages, 11 figures)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The potential impact of quantum machine learning algorithms on industrial
applications remains an exciting open question. Conventional methods for
encoding classical data into quantum computers are not only too costly for a
potential quantum advantage in the algorithms but also severely limit the scale
of feasible experiments on current hardware. Therefore, recent works, despite
claiming the near-term suitability of their algorithms, do not provide
experimental benchmarking on standard machine learning datasets. We attempt to
solve the data encoding problem by improving a recently proposed variational
algorithm [1] that approximately prepares the encoded data, using
asymptotically shallow circuits that fit the native gate set and topology of
currently available quantum computers. We apply the improved algorithm to
encode the Fashion-MNIST dataset [2], which can be directly used in future
empirical studies of quantum machine learning algorithms. We deploy simple
quantum variational classifiers trained on the encoded dataset on a current
quantum computer ibmq-kolkata [3] and achieve moderate accuracies, providing a
proof of concept for the near-term usability of our data encoding method.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02408" title="Abstract">arXiv:2403.02408</a> (cross-list from eess.IV) [<a href="/pdf/2403.02408" title="Download PDF">pdf</a>, <a href="/format/2403.02408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Spatio-temporal Aligned SUNet Model for Low-light Video Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lin%2C+R">Ruirui Lin</a>, 
<a href="/search/eess?searchtype=author&query=Anantrasirichai%2C+N">Nantheera Anantrasirichai</a>, 
<a href="/search/eess?searchtype=author&query=Malyugina%2C+A">Alexandra Malyugina</a>, 
<a href="/search/eess?searchtype=author&query=Bull%2C+D">David Bull</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Distortions caused by low-light conditions are not only visually unpleasant
but also degrade the performance of computer vision tasks. The restoration and
enhancement have proven to be highly beneficial. However, there are only a
limited number of enhancement methods explicitly designed for videos acquired
in low-light conditions. We propose a Spatio-Temporal Aligned SUNet (STA-SUNet)
model using a Swin Transformer as a backbone to capture low light video
features and exploit their spatio-temporal correlations. The STA-SUNet model is
trained on a novel, fully registered dataset (BVI), which comprises dynamic
scenes captured under varying light conditions. It is further analysed
comparatively against various other models over three test datasets. The model
demonstrates superior adaptivity across all datasets, obtaining the highest
PSNR and SSIM values. It is particularly effective in extreme low-light
conditions, yielding fairly good visualisation results.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02432" title="Abstract">arXiv:2403.02432</a> (cross-list from stat.ML) [<a href="/pdf/2403.02432" title="Download PDF">pdf</a>, <a href="/format/2403.02432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the impact of measure pre-conditionings on general parametric ML  models and transfer learning via domain adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Garc%C3%ADa%2C+J+S">Joaqu&#xed;n S&#xe1;nchez Garc&#xed;a</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">We study a new technique for understanding convergence of learning agents
under small modifications of data. We show that such convergence can be
understood via an analogue of Fatou's lemma which yields gamma-convergence. We
show it's relevance and applications in general machine learning tasks and
domain adaptation transfer learning.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02467" title="Abstract">arXiv:2403.02467</a> (cross-list from econ.EM) [<a href="/pdf/2403.02467" title="Download PDF">pdf</a>, <a href="/ps/2403.02467" title="Download PostScript">ps</a>, <a href="/format/2403.02467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applied Causal Inference Powered by ML and AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Chernozhukov%2C+V">Victor Chernozhukov</a>, 
<a href="/search/econ?searchtype=author&query=Hansen%2C+C">Christian Hansen</a>, 
<a href="/search/econ?searchtype=author&query=Kallus%2C+N">Nathan Kallus</a>, 
<a href="/search/econ?searchtype=author&query=Spindler%2C+M">Martin Spindler</a>, 
<a href="/search/econ?searchtype=author&query=Syrgkanis%2C+V">Vasilis Syrgkanis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Machine Learning (cs.LG); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">An introduction to the emerging fusion of machine learning and causal
inference. The book presents ideas from classical structural equation models
(SEMs) and their modern AI equivalent, directed acyclical graphs (DAGs) and
structural causal models (SCMs), and covers Double/Debiased Machine Learning
methods to do inference in such models using modern predictive tools.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02468" title="Abstract">arXiv:2403.02468</a> (cross-list from math.OC) [<a href="/pdf/2403.02468" title="Download PDF">pdf</a>, <a href="/format/2403.02468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Primal-dual hybrid gradient method for solving optimal control  problems and the corresponding Hamilton-Jacobi PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Meng%2C+T">Tingwei Meng</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+S">Siting Liu</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+W">Wuchen Li</a>, 
<a href="/search/math?searchtype=author&query=Osher%2C+S">Stanley Osher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Optimal control problems are crucial in various domains, including path
planning, robotics, and humanoid control, demonstrating their broad
applicability. The connection between optimal control and Hamilton-Jacobi (HJ)
partial differential equations (PDEs) underscores the need for solving HJ PDEs
to address these control problems effectively. While numerous numerical methods
exist for tackling HJ PDEs across different dimensions, this paper introduces
an innovative optimization-based approach that reformulates optimal control
problems and HJ PDEs into a saddle point problem using a Lagrange multiplier.
Our method, based on the preconditioned primal-dual hybrid gradient (PDHG)
method, offers a solution to HJ PDEs with first-order accuracy and numerical
unconditional stability, enabling larger time steps and avoiding the
limitations of explicit time discretization methods. Our approach has ability
to handle a wide variety of Hamiltonian functions, including those that are
non-smooth and dependent on time and space, through a simplified saddle point
formulation that facilitates easy and parallelizable updates. Furthermore, our
framework extends to viscous HJ PDEs and stochastic optimal control problems,
showcasing its versatility. Through a series of numerical examples, we
demonstrate the method's effectiveness in managing diverse Hamiltonians and
achieving efficient parallel computation, highlighting its potential for
wide-ranging applications in optimal control and beyond.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02500" title="Abstract">arXiv:2403.02500</a> (cross-list from q-fin.PM) [<a href="/pdf/2403.02500" title="Download PDF">pdf</a>, <a href="/ps/2403.02500" title="Download PostScript">ps</a>, <a href="/format/2403.02500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RVRAE: A Dynamic Factor Model Based on Variational Recurrent Autoencoder  for Stock Returns Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Wang%2C+Y">Yilun Wang</a>, 
<a href="/search/q-fin?searchtype=author&query=Guo%2C+S">Shengjie Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Portfolio Management (q-fin.PM)</span>; Machine Learning (cs.LG); Pricing of Securities (q-fin.PR)

</div>
<p class="mathjax">In recent years, the dynamic factor model has emerged as a dominant tool in
economics and finance, particularly for investment strategies. This model
offers improved handling of complex, nonlinear, and noisy market conditions
compared to traditional static factor models. The advancement of machine
learning, especially in dealing with nonlinear data, has further enhanced asset
pricing methodologies. This paper introduces a groundbreaking dynamic factor
model named RVRAE. This model is a probabilistic approach that addresses the
temporal dependencies and noise in market data. RVRAE ingeniously combines the
principles of dynamic factor modeling with the variational recurrent
autoencoder (VRAE) from deep learning. A key feature of RVRAE is its use of a
prior-posterior learning method. This method fine-tunes the model's learning
process by seeking an optimal posterior factor model informed by future data.
Notably, RVRAE is adept at risk modeling in volatile stock markets, estimating
variances from latent space distributions while also predicting returns. Our
empirical tests with real stock market data underscore RVRAE's superior
performance compared to various established baseline methods.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02512" title="Abstract">arXiv:2403.02512</a> (cross-list from quant-ph) [<a href="/pdf/2403.02512" title="Download PDF">pdf</a>, <a href="/format/2403.02512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid quantum programming with PennyLane Lightning on HPC platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Asadi%2C+A">Ali Asadi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dusko%2C+A">Amintor Dusko</a>, 
<a href="/search/quant-ph?searchtype=author&query=Park%2C+C">Chae-Yeun Park</a>, 
<a href="/search/quant-ph?searchtype=author&query=Michaud-Rioux%2C+V">Vincent Michaud-Rioux</a>, 
<a href="/search/quant-ph?searchtype=author&query=Schoch%2C+I">Isidor Schoch</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shu%2C+S">Shuli Shu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Vincent%2C+T">Trevor Vincent</a>, 
<a href="/search/quant-ph?searchtype=author&query=O%27Riordan%2C+L+J">Lee James O&#x27;Riordan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For all data and workloads, see <a href="https://github.com/PennyLaneAI/lightning-on-hpc">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Emerging Technologies (cs.ET); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">We introduce PennyLane's Lightning suite, a collection of high-performance
state-vector simulators targeting CPU, GPU, and HPC-native architectures and
workloads. Quantum applications such as QAOA, VQE, and synthetic workloads are
implemented to demonstrate the supported classical computing architectures and
showcase the scale of problems that can be simulated using our tooling. We
benchmark the performance of Lightning with backends supporting CPUs, as well
as NVidia and AMD GPUs, and compare the results to other commonly used
high-performance simulator packages, demonstrating where Lightning's
implementations give performance leads. We show improved CPU performance by
employing explicit SIMD intrinsics and multi-threading, batched task-based
execution across multiple GPUs, and distributed forward and gradient-based
quantum circuit executions across multiple nodes. Our data shows we can
comfortably simulate a variety of circuits, giving examples with up to 30
qubits on a single device or node, and up to 41 qubits using multiple nodes.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02524" title="Abstract">arXiv:2403.02524</a> (cross-list from math.DS) [<a href="/pdf/2403.02524" title="Download PDF">pdf</a>, <a href="/format/2403.02524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Koopman operators with intrinsic observables in rigged reproducing  kernel Hilbert spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ishikawa%2C+I">Isao Ishikawa</a>, 
<a href="/search/math?searchtype=author&query=Hashimoto%2C+Y">Yuka Hashimoto</a>, 
<a href="/search/math?searchtype=author&query=Ikeda%2C+M">Masahiro Ikeda</a>, 
<a href="/search/math?searchtype=author&query=Kawahara%2C+Y">Yoshinobu Kawahara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Machine Learning (cs.LG); Functional Analysis (math.FA); Spectral Theory (math.SP); Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper presents a novel approach for estimating the Koopman operator
defined on a reproducing kernel Hilbert space (RKHS) and its spectra. We
propose an estimation method, what we call Jet Dynamic Mode Decomposition
(JetDMD), leveraging the intrinsic structure of RKHS and the geometric notion
known as jets to enhance the estimation of the Koopman operator. This method
refines the traditional Extended Dynamic Mode Decomposition (EDMD) in accuracy,
especially in the numerical estimation of eigenvalues. This paper proves
JetDMD's superiority through explicit error bounds and convergence rate for
special positive definite kernels, offering a solid theoretical foundation for
its performance. We also delve into the spectral analysis of the Koopman
operator, proposing the notion of extended Koopman operator within a framework
of rigged Hilbert space. This notion leads to a deeper understanding of
estimated Koopman eigenfunctions and capturing them outside the original
function space. Through the theory of rigged Hilbert space, our study provides
a principled methodology to analyze the estimated spectrum and eigenfunctions
of Koopman operators, and enables eigendecomposition within a rigged RKHS. We
also propose a new effective method for reconstructing the dynamical system
from temporally-sampled trajectory data of the dynamical system with solid
theoretical guarantee. We conduct several numerical simulations using the van
der Pol oscillator, the Duffing oscillator, the H\'enon map, and the Lorenz
attractor, and illustrate the performance of JetDMD with clear numerical
computations of eigenvalues and accurate predictions of the dynamical systems.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02530" title="Abstract">arXiv:2403.02530</a> (cross-list from math.OC) [<a href="/pdf/2403.02530" title="Download PDF">pdf</a>, <a href="/ps/2403.02530" title="Download PostScript">ps</a>, <a href="/format/2403.02530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Projected gradient descent accumulates at Bouligand stationary points
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Olikier%2C+G">Guillaume Olikier</a>, 
<a href="/search/math?searchtype=author&query=Waldspurger%2C+I">Ir&#xe8;ne Waldspurger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">This paper concerns the projected gradient descent (PGD) algorithm for the
problem of minimizing a continuously differentiable function on a nonempty
closed subset of a Euclidean vector space. Without further assumptions, this
problem is intractable and devoted algorithms are only expected to find a
stationary point. PGD is known to generate a sequence whose accumulation points
are Mordukhovich stationary. In this paper, these accumulation points are
proven to be Bouligand stationary, and even proximally stationary if the
gradient is locally Lipschitz continuous. These are the strongest stationarity
properties that can be expected for the considered problem.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02532" title="Abstract">arXiv:2403.02532</a> (cross-list from quant-ph) [<a href="/pdf/2403.02532" title="Download PDF">pdf</a>, <a href="/format/2403.02532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Superposition detection and QMA with non-collapsing measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Bassirian%2C+R">Roozbeh Bassirian</a>, 
<a href="/search/quant-ph?searchtype=author&query=Marwaha%2C+K">Kunal Marwaha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">We prove that QMA where the verifier may also make a single non-collapsing
measurement is equal to NEXP, resolving an open question of Aaronson. We show
this is a corollary to a modified proof of QMA+ = NEXP [<a href="/abs/2306.13247">arXiv:2306.13247</a>]. At
the core of many results inspired by Blier and Tapp [<a href="/abs/0709.0738">arXiv:0709.0738</a>] is an
unphysical property testing problem deciding whether a quantum state is close
to an element of a fixed basis.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02536" title="Abstract">arXiv:2403.02536</a> (cross-list from astro-ph.SR) [<a href="/pdf/2403.02536" title="Download PDF">pdf</a>, <a href="/format/2403.02536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forecasting SEP Events During Solar Cycles 23 and 24 Using Interpretable  Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Kasapis%2C+S">Spiridon Kasapis</a>, 
<a href="/search/astro-ph?searchtype=author&query=Kitiashvili%2C+I+N">Irina N. Kitiashvili</a>, 
<a href="/search/astro-ph?searchtype=author&query=Kosovich%2C+P">Paul Kosovich</a>, 
<a href="/search/astro-ph?searchtype=author&query=Kosovichev%2C+A+G">Alexander G. Kosovichev</a>, 
<a href="/search/astro-ph?searchtype=author&query=Sadykov%2C+V+M">Viacheslav M. Sadykov</a>, 
<a href="/search/astro-ph?searchtype=author&query=O%27Keefe%2C+P">Patrick O&#x27;Keefe</a>, 
<a href="/search/astro-ph?searchtype=author&query=Wang%2C+V">Vincent Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Article submitted and is under revision to the AAS Astrophysical Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Solar and Stellar Astrophysics (astro-ph.SR)</span>; Machine Learning (cs.LG); Space Physics (physics.space-ph)

</div>
<p class="mathjax">Prediction of the Solar Energetic Particle (SEP) events garner increasing
interest as space missions extend beyond Earth's protective magnetosphere.
These events, which are, in most cases, products of magnetic
reconnection-driven processes during solar flares or fast
coronal-mass-ejection-driven shock waves, pose significant radiation hazards to
aviation, space-based electronics, and particularly, space exploration. In this
work, we utilize the recently developed dataset that combines the Solar
Dynamics Observatory/Helioseismic and Magnetic Imager's (SDO/HMI) Space weather
HMI Active Region Patches (SHARP) and the Solar and Heliospheric
Observatory/Michelson Doppler Imager's (SoHO/MDI) Space Weather MDI Active
Region Patches (SMARP). We employ a suite of machine learning strategies,
including Support Vector Machines (SVM) and regression models, to evaluate the
predictive potential of this new data product for a forecast of post-solar
flare SEP events. Our study indicates that despite the augmented volume of
data, the prediction accuracy reaches 0.7 +- 0.1, which aligns with but does
not exceed these published benchmarks. A linear SVM model with training and
testing configurations that mimic an operational setting (positive-negative
imbalance) reveals a slight increase (+ 0.04 +- 0.05) in the accuracy of a
14-hour SEP forecast compared to previous studies. This outcome emphasizes the
imperative for more sophisticated, physics-informed models to better understand
the underlying processes leading to SEP events.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02543" title="Abstract">arXiv:2403.02543</a> (cross-list from quant-ph) [<a href="/pdf/2403.02543" title="Download PDF">pdf</a>, <a href="/ps/2403.02543" title="Download PostScript">ps</a>, <a href="/format/2403.02543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PDQMA = DQMA = NEXP: QMA With Hidden Variables and Non-collapsing  Measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Aaronson%2C+S">Scott Aaronson</a>, 
<a href="/search/quant-ph?searchtype=author&query=Grewal%2C+S">Sabee Grewal</a>, 
<a href="/search/quant-ph?searchtype=author&query=Iyer%2C+V">Vishnu Iyer</a>, 
<a href="/search/quant-ph?searchtype=author&query=Marshall%2C+S+C">Simon C. Marshall</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ramachandran%2C+R">Ronak Ramachandran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">We define and study a variant of QMA (Quantum Merlin Arthur) in which Arthur
can make multiple non-collapsing measurements to Merlin's witness state, in
addition to ordinary collapsing measurements. By analogy to the class PDQP
defined by Aaronson, Bouland, Fitzsimons, and Lee (2014), we call this class
PDQMA. Our main result is that PDQMA = NEXP; this result builds on the MIP =
NEXP Theorem and complements the result of Aaronson (2018) that PDQP/qpoly =
ALL. While the result has little to do with quantum mechanics, we also show a
more "quantum" result: namely, that QMA with the ability to inspect the entire
history of a hidden variable is equal to NEXP, under mild assumptions on the
hidden-variable theory. We also observe that a quantum computer, augmented with
quantum advice and the ability to inspect the history of a hidden variable, can
solve any decision problem in polynomial time.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02544" title="Abstract">arXiv:2403.02544</a> (cross-list from eess.IV) [<a href="/pdf/2403.02544" title="Download PDF">pdf</a>, <a href="/format/2403.02544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coronary artery segmentation in non-contrast calcium scoring CT images  using deep learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bujny%2C+M">Mariusz Bujny</a>, 
<a href="/search/eess?searchtype=author&query=Jesionek%2C+K">Katarzyna Jesionek</a>, 
<a href="/search/eess?searchtype=author&query=Nalepa%2C+J">Jakub Nalepa</a>, 
<a href="/search/eess?searchtype=author&query=Miszalski-Jamka%2C+K">Karol Miszalski-Jamka</a>, 
<a href="/search/eess?searchtype=author&query=Widawka-%C5%BBak%2C+K">Katarzyna Widawka-&#x17b;ak</a>, 
<a href="/search/eess?searchtype=author&query=Wolny%2C+S">Sabina Wolny</a>, 
<a href="/search/eess?searchtype=author&query=Kostur%2C+M">Marcin Kostur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Precise localization of coronary arteries in Computed Tomography (CT) scans
is critical from the perspective of medical assessment of coronary artery
disease. Although various methods exist that offer high-quality segmentation of
coronary arteries in cardiac contrast-enhanced CT scans, the potential of less
invasive, non-contrast CT in this area is still not fully exploited. Since such
fine anatomical structures are hardly visible in this type of medical images,
the existing methods are characterized by high recall and low precision, and
are used mainly for filtering of atherosclerotic plaques in the context of
calcium scoring. In this paper, we address this research gap and introduce a
deep learning algorithm for segmenting coronary arteries in multi-vendor
ECG-gated non-contrast cardiac CT images which benefits from a novel framework
for semi-automatic generation of Ground Truth (GT) via image registration. We
hypothesize that the proposed GT generation process is much more efficient in
this case than manual segmentation, since it allows for a fast generation of
large volumes of diverse data, which leads to well-generalizing models. To
investigate and thoroughly evaluate the segmentation quality based on such an
approach, we propose a novel method for manual mesh-to-image registration,
which is used to create our test-GT. The experimental study shows that the
trained model has significantly higher accuracy than the GT used for training,
and leads to the Dice and clDice metrics close to the interrater variability.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02566" title="Abstract">arXiv:2403.02566</a> (cross-list from eess.IV) [<a href="/pdf/2403.02566" title="Download PDF">pdf</a>, <a href="/format/2403.02566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Weakly Supervised 3D Medical Image Segmentation through  Probabilistic-aware Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fan%2C+Z">Zhaoxin Fan</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+R">Runmin Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+J">Junhao Wu</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+X">Xin Huang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+T">Tianyang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+H">Heng Huang</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+M">Min Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">3D medical image segmentation is a challenging task with crucial implications
for disease diagnosis and treatment planning. Recent advances in deep learning
have significantly enhanced fully supervised medical image segmentation.
However, this approach heavily relies on labor-intensive and time-consuming
fully annotated ground-truth labels, particularly for 3D volumes. To overcome
this limitation, we propose a novel probabilistic-aware weakly supervised
learning pipeline, specifically designed for 3D medical imaging. Our pipeline
integrates three innovative components: a probability-based pseudo-label
generation technique for synthesizing dense segmentation masks from sparse
annotations, a Probabilistic Multi-head Self-Attention network for robust
feature extraction within our Probabilistic Transformer Network, and a
Probability-informed Segmentation Loss Function to enhance training with
annotation confidence. Demonstrating significant advances, our approach not
only rivals the performance of fully supervised methods but also surpasses
existing weakly supervised methods in CT and MRI datasets, achieving up to
18.1% improvement in Dice scores for certain organs. The code is available at
https://github.com/runminjiang/PW4MedSeg.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02579" title="Abstract">arXiv:2403.02579</a> (cross-list from cond-mat.dis-nn) [<a href="/pdf/2403.02579" title="Download PDF">pdf</a>, <a href="/format/2403.02579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric Dynamics of Signal Propagation Predict Trainability of  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Cowsik%2C+A">Aditya Cowsik</a>, 
<a href="/search/cond-mat?searchtype=author&query=Nebabu%2C+T">Tamra Nebabu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Qi%2C+X">Xiao-Liang Qi</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ganguli%2C+S">Surya Ganguli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We investigate forward signal propagation and gradient back propagation in
deep, randomly initialized transformers, yielding simple necessary and
sufficient conditions on initialization hyperparameters that ensure
trainability of deep transformers. Our approach treats the evolution of the
representations of $n$ tokens as they propagate through the transformer layers
in terms of a discrete time dynamical system of $n$ interacting particles. We
derive simple update equations for the evolving geometry of this particle
system, starting from a permutation symmetric simplex. Our update equations
show that without MLP layers, this system will collapse to a line, consistent
with prior work on rank collapse in transformers. However, unlike prior work,
our evolution equations can quantitatively track particle geometry in the
additional presence of nonlinear MLP layers, and it reveals an order-chaos
phase transition as a function of initialization hyperparameters, like the
strength of attentional and MLP residual connections and weight variances. In
the ordered phase the particles are attractive and collapse to a line, while in
the chaotic phase the particles are repulsive and converge to a regular
$n$-simplex. We analytically derive two Lyapunov exponents: an angle exponent
that governs departures from the edge of chaos in this particle system, and a
gradient exponent that governs the rate of exponential growth or decay of
backpropagated gradients. We show through experiments that, remarkably, the
final test loss at the end of training is well predicted just by these two
exponents at the beginning of training, and that the simultaneous vanishing of
these two exponents yields a simple necessary and sufficient condition to
achieve minimal test loss.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02589" title="Abstract">arXiv:2403.02589</a> (cross-list from math.OC) [<a href="/pdf/2403.02589" title="Download PDF">pdf</a>, <a href="/ps/2403.02589" title="Download PostScript">ps</a>, <a href="/format/2403.02589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MUSIC: Accelerated Convergence for Distributed Optimization With Inexact  and Exact Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wu%2C+M">Mou Wu</a>, 
<a href="/search/math?searchtype=author&query=Liao%2C+H">Haibin Liao</a>, 
<a href="/search/math?searchtype=author&query=Ding%2C+Z">Zhengtao Ding</a>, 
<a href="/search/math?searchtype=author&query=Xiao%2C+Y">Yonggang Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Gradient-type distributed optimization methods have blossomed into one of the
most important tools for solving a minimization learning task over a networked
agent system. However, only one gradient update per iteration is difficult to
achieve a substantive acceleration of convergence. In this paper, we propose an
accelerated framework named as MUSIC allowing each agent to perform multiple
local updates and a single combination in each iteration. More importantly, we
equip inexact and exact distributed optimization methods into this framework,
thereby developing two new algorithms that exhibit accelerated linear
convergence and high communication efficiency. Our rigorous convergence
analysis reveals the sources of steady-state errors arising from inexact
policies and offers effective solutions. Numerical results based on synthetic
and real datasets demonstrate both our theoretical motivations and analysis, as
well as performance advantages.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02601" title="Abstract">arXiv:2403.02601</a> (cross-list from eess.IV) [<a href="/pdf/2403.02601" title="Download PDF">pdf</a>, <a href="/format/2403.02601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Res Leads the Way: Improving Generalization for Super-Resolution by  Self-Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Haoyu Chen</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+W">Wenbo Li</a>, 
<a href="/search/eess?searchtype=author&query=Gu%2C+J">Jinjin Gu</a>, 
<a href="/search/eess?searchtype=author&query=Ren%2C+J">Jingjing Ren</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+H">Haoze Sun</a>, 
<a href="/search/eess?searchtype=author&query=Zou%2C+X">Xueyi Zou</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zhensong Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+Y">Youliang Yan</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+L">Lei Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">For image super-resolution (SR), bridging the gap between the performance on
synthetic datasets and real-world degradation scenarios remains a challenge.
This work introduces a novel "Low-Res Leads the Way" (LWay) training framework,
merging Supervised Pre-training with Self-supervised Learning to enhance the
adaptability of SR models to real-world images. Our approach utilizes a
low-resolution (LR) reconstruction network to extract degradation embeddings
from LR images, merging them with super-resolved outputs for LR reconstruction.
Leveraging unseen LR images for self-supervised learning guides the model to
adapt its modeling space to the target domain, facilitating fine-tuning of SR
models without requiring paired high-resolution (HR) images. The integration of
Discrete Wavelet Transform (DWT) further refines the focus on high-frequency
details. Extensive evaluations show that our method significantly improves the
generalization and detail restoration capabilities of SR models on unseen
real-world datasets, outperforming existing methods. Our training regime is
universally compatible, requiring no network architecture modifications, making
it a practical solution for real-world SR applications.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02645" title="Abstract">arXiv:2403.02645</a> (cross-list from eess.SP) [<a href="/pdf/2403.02645" title="Download PDF">pdf</a>, <a href="/format/2403.02645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Over-The-Air Double-Threshold Deep Learner for Jamming Detection in 5G  RF domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Asemian%2C+G">Ghazal Asemian</a>, 
<a href="/search/eess?searchtype=author&query=Amini%2C+M">Mohammadreza Amini</a>, 
<a href="/search/eess?searchtype=author&query=Kantarci%2C+B">Burak Kantarci</a>, 
<a href="/search/eess?searchtype=author&query=Erol-Kantarci%2C+M">Melike Erol-Kantarci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">With the evolution of 5G wireless communications, the Synchronization Signal
Block (SSB) plays a critical role in the synchronization of devices and
accessibility of services. However, due to the predictable nature of SSB
transmission, including the Primary and Secondary Synchronization Signals (PSS
and SSS), jamming attacks are critical threats. By leveraging RF domain
knowledge, this work presents a novel deep learning-based technique for
detecting jammers in 5G networks. Unlike the existing jamming detection
algorithms that mostly rely on network parameters, we introduce a double
threshold deep learning jamming detector by focusing on the SSB. The detection
method is focused on RF domain features and improves the robustness of the
network without requiring integration with the pre-existing network
infrastructure. By integrating a preprocessing block that extracts PSS
correlation and energy per null resource elements (EPNRE) characteristics, our
method distinguishes between normal and jammed received signals with high
precision. Additionally, by incorporation of Discrete Wavelet Transform (DWT),
the efficacy of training and detection are optimized. A double threshold double
Deep Neural Network (DT-DDNN) is also introduced to the architecture
complemented by a deep cascade learning model to increase the sensitivity of
the model to variations of signal to jamming noise ratio (SJNR). Results show
that the proposed method achieves 96.4% detection rate in extra low jamming
power, i.e., SJNR between 15 to 30 dB which outperforms the single threshold
DNN design with 86.0% detection rate and unprocessed IQ sample DNN design with
83.2% detection rate. Ultimately, performance of DT-DDNN is validated through
the analysis of real 5G signals obtained from a practical testbed,
demonstrating a strong alignment with the simulation results.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02651" title="Abstract">arXiv:2403.02651</a> (cross-list from eess.SP) [<a href="/pdf/2403.02651" title="Download PDF">pdf</a>, <a href="/format/2403.02651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning at the Speed of Wireless: Online Real-Time Learning for  AI-Enabled MIMO in NextG
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+J">Jiarui Xu</a>, 
<a href="/search/eess?searchtype=author&query=Jere%2C+S">Shashank Jere</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+Y">Yifei Song</a>, 
<a href="/search/eess?searchtype=author&query=Kao%2C+Y">Yi-Hung Kao</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+L">Lizhong Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+L">Lingjia Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, 1 table, magazine paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Integration of artificial intelligence (AI) and machine learning (ML) into
the air interface has been envisioned as a key technology for next-generation
(NextG) cellular networks. At the air interface, multiple-input multiple-output
(MIMO) and its variants such as multi-user MIMO (MU-MIMO) and
massive/full-dimension MIMO have been key enablers across successive
generations of cellular networks with evolving complexity and design
challenges. Initiating active investigation into leveraging AI/ML tools to
address these challenges for MIMO becomes a critical step towards an AI-enabled
NextG air interface. At the NextG air interface, the underlying wireless
environment will be extremely dynamic with operation adaptations performed on a
sub-millisecond basis by MIMO operations such as MU-MIMO scheduling and
rank/link adaptation. Given the enormously large number of operation adaptation
possibilities, we contend that online real-time AI/ML-based approaches
constitute a promising paradigm. To this end, we outline the inherent
challenges and offer insights into the design of such online real-time
AI/ML-based solutions for MIMO operations. An online real-time AI/ML-based
method for MIMO-OFDM channel estimation is then presented, serving as a
potential roadmap for developing similar techniques across various MIMO
operations in NextG.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02697" title="Abstract">arXiv:2403.02697</a> (cross-list from stat.ML) [<a href="/pdf/2403.02697" title="Download PDF">pdf</a>, <a href="/format/2403.02697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise misleads rotation invariant algorithms on sparse targets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Warmuth%2C+M+K">Manfred K. Warmuth</a> (1), 
<a href="/search/stat?searchtype=author&query=Kot%C5%82owski%2C+W">Wojciech Kot&#x142;owski</a> (2), 
<a href="/search/stat?searchtype=author&query=Jones%2C+M">Matt Jones</a> (3), 
<a href="/search/stat?searchtype=author&query=Amid%2C+E">Ehsan Amid</a> (1) ((1) Google Inc., (2) Institute of Computing Science, Poznan University of Technology, Poznan, Poland, (3) University of Colorado Boulder, Colorado, USA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">It is well known that the class of rotation invariant algorithms are
suboptimal even for learning sparse linear problems when the number of examples
is below the "dimension" of the problem. This class includes any gradient
descent trained neural net with a fully-connected input layer (initialized with
a rotationally symmetric distribution). The simplest sparse problem is learning
a single feature out of $d$ features. In that case the classification error or
regression loss grows with $1-k/n$ where $k$ is the number of examples seen.
These lower bounds become vacuous when the number of examples $k$ reaches the
dimension $d$.
<br />We show that when noise is added to this sparse linear problem, rotation
invariant algorithms are still suboptimal after seeing $d$ or more examples. We
prove this via a lower bound for the Bayes optimal algorithm on a rotationally
symmetrized problem. We then prove much lower upper bounds on the same problem
for simple non-rotation invariant algorithms. Finally we analyze the gradient
flow trajectories of many standard optimization algorithms in some simple cases
and show how they veer toward or away from the sparse targets.
<br />We believe that our trajectory categorization will be useful in designing
algorithms that can exploit sparse targets and our method for proving lower
bounds will be crucial for analyzing other families of algorithms that admit
different classes of invariances.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02726" title="Abstract">arXiv:2403.02726</a> (cross-list from econ.GN) [<a href="/pdf/2403.02726" title="Download PDF">pdf</a>, <a href="/ps/2403.02726" title="Download PostScript">ps</a>, <a href="/format/2403.02726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bias in Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Zhou%2C+M">Mi Zhou</a>, 
<a href="/search/econ?searchtype=author&query=Abhishek%2C+V">Vibhanshu Abhishek</a>, 
<a href="/search/econ?searchtype=author&query=Derdenger%2C+T">Timothy Derdenger</a>, 
<a href="/search/econ?searchtype=author&query=Kim%2C+J">Jaymo Kim</a>, 
<a href="/search/econ?searchtype=author&query=Srinivasan%2C+K">Kannan Srinivasan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">This study analyzed images generated by three popular generative artificial
intelligence (AI) tools - Midjourney, Stable Diffusion, and DALLE 2 -
representing various occupations to investigate potential bias in AI
generators. Our analysis revealed two overarching areas of concern in these AI
generators, including (1) systematic gender and racial biases, and (2) subtle
biases in facial expressions and appearances. Firstly, we found that all three
AI generators exhibited bias against women and African Americans. Moreover, we
found that the evident gender and racial biases uncovered in our analysis were
even more pronounced than the status quo when compared to labor force
statistics or Google images, intensifying the harmful biases we are actively
striving to rectify in our society. Secondly, our study uncovered more nuanced
prejudices in the portrayal of emotions and appearances. For example, women
were depicted as younger with more smiles and happiness, while men were
depicted as older with more neutral expressions and anger, posing a risk that
generative AI models may unintentionally depict women as more submissive and
less competent than men. Such nuanced biases, by their less overt nature, might
be more problematic as they can permeate perceptions unconsciously and may be
more difficult to rectify. Although the extent of bias varied depending on the
model, the direction of bias remained consistent in both commercial and
open-source AI generators. As these tools become commonplace, our study
highlights the urgency to identify and mitigate various biases in generative
AI, reinforcing the commitment to ensuring that AI technologies benefit all of
humanity for a more inclusive future.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02750" title="Abstract">arXiv:2403.02750</a> (cross-list from eess.IV) [<a href="/pdf/2403.02750" title="Download PDF">pdf</a>, <a href="/format/2403.02750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speckle Noise Reduction in Ultrasound Images using Denoising  Auto-encoder with Skip Connection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bhute%2C+S">Suraj Bhute</a>, 
<a href="/search/eess?searchtype=author&query=Mandal%2C+S">Subhamoy Mandal</a>, 
<a href="/search/eess?searchtype=author&query=Guha%2C+D">Debashree Guha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Selected for presentation at 2024 IEEE South Asian Ultrasonics Symposium
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Ultrasound is a widely used medical tool for non-invasive diagnosis, but its
images often contain speckle noise which can lower their resolution and
contrast-to-noise ratio. This can make it more difficult to extract, recognize,
and analyze features in the images, as well as impair the accuracy of
computer-assisted diagnostic techniques and the ability of doctors to interpret
the images. Reducing speckle noise, therefore, is a crucial step in the
preprocessing of ultrasound images. Researchers have proposed several speckle
reduction methods, but no single method takes all relevant factors into
account. In this paper, we compare seven such methods: Median, Gaussian,
Bilateral, Average, Weiner, Anisotropic and Denoising auto-encoder without and
with skip connections in terms of their ability to preserve features and edges
while effectively reducing noise. In an experimental study, a convolutional
noise-removing auto-encoder with skip connection, a deep learning method, was
used to improve ultrasound images of breast cancer. This method involved adding
speckle noise at various levels. The results of the deep learning method were
compared to those of traditional image enhancement methods, and it was found
that the proposed method was more effective. To assess the performance of these
algorithms, we use three established evaluation metrics and present both
filtered images and statistical data.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02774" title="Abstract">arXiv:2403.02774</a> (cross-list from physics.ao-ph) [<a href="/pdf/2403.02774" title="Download PDF">pdf</a>, <a href="/format/2403.02774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast, Scale-Adaptive, and Uncertainty-Aware Downscaling of Earth System  Model Fields with Generative Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Hess%2C+P">Philipp Hess</a>, 
<a href="/search/physics?searchtype=author&query=Aich%2C+M">Michael Aich</a>, 
<a href="/search/physics?searchtype=author&query=Pan%2C+B">Baoxiang Pan</a>, 
<a href="/search/physics?searchtype=author&query=Boers%2C+N">Niklas Boers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Geophysics (physics.geo-ph)

</div>
<p class="mathjax">Accurate and high-resolution Earth system model (ESM) simulations are
essential to assess the ecological and socio-economic impacts of anthropogenic
climate change, but are computationally too expensive. Recent machine learning
approaches have shown promising results in downscaling ESM simulations,
outperforming state-of-the-art statistical approaches. However, existing
methods require computationally costly retraining for each ESM and extrapolate
poorly to climates unseen during training. We address these shortcomings by
learning a consistency model (CM) that efficiently and accurately downscales
arbitrary ESM simulations without retraining in a zero-shot manner. Our
foundation model approach yields probabilistic downscaled fields at resolution
only limited by the observational reference data. We show that the CM
outperforms state-of-the-art diffusion models at a fraction of computational
cost while maintaining high controllability on the downscaling task. Further,
our method generalizes to climate states unseen during training without
explicitly formulated physical constraints.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02808" title="Abstract">arXiv:2403.02808</a> (cross-list from math.CO) [<a href="/pdf/2403.02808" title="Download PDF">pdf</a>, <a href="/ps/2403.02808" title="Download PostScript">ps</a>, <a href="/format/2403.02808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Face-hitting Dominating Sets in Planar Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Francis%2C+P">P. Francis</a>, 
<a href="/search/math?searchtype=author&query=Illickan%2C+A+M">Abraham M. Illickan</a>, 
<a href="/search/math?searchtype=author&query=Jose%2C+L+M">Lijo M. Jose</a>, 
<a href="/search/math?searchtype=author&query=Rajendraprasad%2C+D">Deepak Rajendraprasad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">A dominating set of a graph $G$ is a subset $S$ of its vertices such that
each vertex of $G$ not in $S$ has a neighbor in $S$. A face-hitting set of a
plane graph $G$ is a set $T$ of vertices in $G$ such that every face of $G$
contains at least one vertex of $T$. We show that the vertex-set of every plane
(multi-)graph without isolated vertices, self-loops or $2$-faces can be
partitioned into two disjoint sets so that both the sets are dominating and
face-hitting. We also show that all the three assumptions above are necessary
for the conclusion.
<br />As a corollary, we show that every $n$-vertex simple plane triangulation has
a dominating set of size at most $(1 - \alpha)n/2$, where $\alpha n$ is the
maximum size of an independent set in the triangulation. Matheson and Tarjan
[European J. Combin., 1996] conjectured that every plane triangulation with a
sufficiently large number of vertices $n$ has a dominating set of size at most
$n / 4$. Currently, the best known general bound for this is by Christiansen,
Rotenberg and Rutschmann [SODA, 2024] who showed that every plane triangulation
on $n &gt; 10$ vertices has a dominating set of size at most $2n/7$. Our corollary
improves their bound for $n$-vertex plane triangulations which contain a
maximal independent set of size either less than $2n/7$ or more than $3n/7$.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02811" title="Abstract">arXiv:2403.02811</a> (cross-list from math.OC) [<a href="/pdf/2403.02811" title="Download PDF">pdf</a>, <a href="/format/2403.02811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear quadratic control of nonlinear systems with Koopman operator  learning and the Nystr&#xf6;m method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Caldarelli%2C+E">Edoardo Caldarelli</a>, 
<a href="/search/math?searchtype=author&query=Chatalic%2C+A">Antoine Chatalic</a>, 
<a href="/search/math?searchtype=author&query=Colom%C3%A9%2C+A">Adri&#xe0; Colom&#xe9;</a>, 
<a href="/search/math?searchtype=author&query=Molinari%2C+C">Cesare Molinari</a>, 
<a href="/search/math?searchtype=author&query=Ocampo-Martinez%2C+C">Carlos Ocampo-Martinez</a>, 
<a href="/search/math?searchtype=author&query=Torras%2C+C">Carme Torras</a>, 
<a href="/search/math?searchtype=author&query=Rosasco%2C+L">Lorenzo Rosasco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY); Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we study how the Koopman operator framework can be combined
with kernel methods to effectively control nonlinear dynamical systems. While
kernel methods have typically large computational requirements, we show how
random subspaces (Nystr\"om approximation) can be used to achieve huge
computational savings while preserving accuracy. Our main technical
contribution is deriving theoretical guarantees on the effect of the Nystr\"om
approximation. More precisely, we study the linear quadratic regulator problem,
showing that both the approximated Riccati operator and the regulator
objective, for the associated solution of the optimal control problem, converge
at the rate $m^{-1/2}$, where $m$ is the random subspace size. Theoretical
findings are complemented by numerical experiments corroborating our results.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02822" title="Abstract">arXiv:2403.02822</a> (cross-list from physics.app-ph) [<a href="/pdf/2403.02822" title="Download PDF">pdf</a>, <a href="/ps/2403.02822" title="Download PostScript">ps</a>, <a href="/format/2403.02822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Highly Reproducible and CMOS-compatible VO2-based Oscillators for  Brain-inspired Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Maher%2C+O">Olivier Maher</a>, 
<a href="/search/physics?searchtype=author&query=Bernini%2C+R">Roy Bernini</a>, 
<a href="/search/physics?searchtype=author&query=Harnack%2C+N">Nele Harnack</a>, 
<a href="/search/physics?searchtype=author&query=Gotsmann%2C+B">Bernd Gotsmann</a>, 
<a href="/search/physics?searchtype=author&query=Sousa%2C+M">Marilyne Sousa</a>, 
<a href="/search/physics?searchtype=author&query=Bragaglia%2C+V">Valeria Bragaglia</a>, 
<a href="/search/physics?searchtype=author&query=Karg%2C+S">Siegfried Karg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applied Physics (physics.app-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">With remarkable electrical and optical switching properties induced at low
power and near room temperature (68C), vanadium dioxide (VO2) has sparked
rising interest in unconventional computing among the phase-change materials
research community. The scalability and the potential to compute beyond the von
Neumann model make VO2 especially appealing for implementation in oscillating
neural networks for artificial intelligence (AI) applications, to solve
constraint satisfaction problems, and for pattern recognition. Its integration
into large networks of oscillators on a Silicon platform still poses challenges
associated with the stabilization in the correct oxidation state and the
ability to fabricate a structure with predictable electrical behavior showing
very low variability. In this work, the role played by the different annealing
parameters applied by three methods (slow thermal annealing, flash annealing,
and rapid thermal annealing), following the vanadium oxide atomic layer
deposition (ALD), on the formation of VO2 grains is studied and an optimal
substrate stack configuration that minimizes variability between devices is
proposed. Material and electrical characterizations are performed on the
different films and a step-by-step recipe to build reproducible VO2-based
oscillators is presented, which is argued to be made possible thanks to the
introduction of a hafnium oxide (HfO2) layer between the silicon substrate and
the vanadium oxide layer. Up to seven nearly identical VO2-based devices are
contacted simultaneously to create a network of oscillators, paving the way for
large-scale implementation of VO2 oscillating neural networks.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02832" title="Abstract">arXiv:2403.02832</a> (cross-list from q-fin.CP) [<a href="/pdf/2403.02832" title="Download PDF">pdf</a>, <a href="/ps/2403.02832" title="Download PostScript">ps</a>, <a href="/format/2403.02832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quasi-Monte Carlo for Efficient Fourier Pricing of Multi-Asset Options
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Bayer%2C+C">Christian Bayer</a>, 
<a href="/search/q-fin?searchtype=author&query=Hammouda%2C+C+B">Chiheb Ben Hammouda</a>, 
<a href="/search/q-fin?searchtype=author&query=Papapantoleon%2C+A">Antonis Papapantoleon</a>, 
<a href="/search/q-fin?searchtype=author&query=Samet%2C+M">Michael Samet</a>, 
<a href="/search/q-fin?searchtype=author&query=Tempone%2C+R">Ra&#xfa;l Tempone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance (q-fin.CP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Efficiently pricing multi-asset options poses a significant challenge in
quantitative finance. The Monte Carlo (MC) method remains the prevalent choice
for pricing engines; however, its slow convergence rate impedes its practical
application. Fourier methods leverage the knowledge of the characteristic
function to accurately and rapidly value options with up to two assets.
Nevertheless, they face hurdles in the high-dimensional settings due to the
tensor product (TP) structure of commonly employed quadrature techniques. This
work advocates using the randomized quasi-MC (RQMC) quadrature to improve the
scalability of Fourier methods with high dimensions. The RQMC technique
benefits from the smoothness of the integrand and alleviates the curse of
dimensionality while providing practical error estimates. Nonetheless, the
applicability of RQMC on the unbounded domain, $\mathbb{R}^d$, requires a
domain transformation to $[0,1]^d$, which may result in singularities of the
transformed integrand at the corners of the hypercube, and deteriorate the rate
of convergence of RQMC. To circumvent this difficulty, we design an efficient
domain transformation procedure based on the derived boundary growth conditions
of the integrand. This transformation preserves the sufficient regularity of
the integrand and hence improves the rate of convergence of RQMC. To validate
this analysis, we demonstrate the efficiency of employing RQMC with an
appropriate transformation to evaluate options in the Fourier space for various
pricing models, payoffs, and dimensions. Finally, we highlight the
computational advantage of applying RQMC over MC or TP in the Fourier domain,
and over MC in the physical domain for options with up to 15 assets.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02862" title="Abstract">arXiv:2403.02862</a> (cross-list from math.AP) [<a href="/pdf/2403.02862" title="Download PDF">pdf</a>, <a href="/format/2403.02862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical investigation of stabilization in the Hybridizable  Discontinuous Galerkin method for linear anisotropic elastic equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pham%2C+H">Ha Pham</a>, 
<a href="/search/math?searchtype=author&query=Faucher%2C+F">Florian Faucher</a>, 
<a href="/search/math?searchtype=author&query=Barucq%2C+H">H&#xe9;l&#xe8;ne Barucq</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">This work concerns the implementation of the hybridizable discontinuous
Galerkin (HDG) method to solve the linear anisotropic elastic equation in the
frequency domain. First-order formulation with the compliance tensor and Voigt
notation are employed to provide a compact description of the discretized
problem and flexibility with highly heterogeneous media. We further focus on
the question of optimal choice of stabilization in the definition of HDG
numerical traces. For this purpose, we construct a hybridized Godunov-upwind
flux for anisotropic elasticity possessing three distinct wavespeeds. This
stabilization removes the need to choose scaling factors, contrary to identity
and Kelvin-Christoffel based stabilizations which are popular choices in
literature. We carry out comparisons among these families for isotropic and
anisotropic material, with constant background and highly heterogeneous ones,
in two and three dimensions. They establish the optimality of the Godunov
stabilization which can be used as a reference choice for generic material and
different types of waves.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02866" title="Abstract">arXiv:2403.02866</a> (cross-list from physics.optics) [<a href="/pdf/2403.02866" title="Download PDF">pdf</a>, <a href="/ps/2403.02866" title="Download PostScript">ps</a>, <a href="/format/2403.02866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlocking Electro-optic Resonant Phase Shifting for Multi-dimensional,  Ultra-dynamic Photonic Switches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Luo%2C+L">Lingzhi Luo</a>, 
<a href="/search/physics?searchtype=author&query=Ma%2C+R">Rui Ma</a>, 
<a href="/search/physics?searchtype=author&query=Penty%2C+R+V">Richard V. Penty</a>, 
<a href="/search/physics?searchtype=author&query=Cheng%2C+Q">Qixiang Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Optical circuit switching is connection-oriented, being deterministic through
the reservation of a complete wavelength channel or spatial path for a certain
period. However, this comes at a trade-off against link dynamics, and overall
capacity can thus be constrained by the time slot reservations, especially for
switches with microsecond- to millisecond-scale reconfiguration times. For
data-intensive applications, the communication patterns associated with random
data sets typically yield short-lived flows. This situation calls for a new
multi-dimensional switching paradigm that fully exploits not only the space and
wavelength domains but also with nanosecond-scale reconfigurable capability in
the time domain to enable ultra-dynamic links. In this work, we focus on the
exploitation of micro-ring resonant phase shifters (RPSs) that are wavelength
selective for optical switching in a single plane. By proposing an innovative
analytical method with transmission circle chart, we fully unlock the power of
RPS with nanosecond-scale reconfigurability and the capability to arbitrarily
manipulate its phase and amplitude. Such a compact model offers fresh insights
into designs with under and critically coupled RPSs beyond the commonly
explored over-coupling condition. This creates not only versatile switch
elements but also perfect absorbers for robust multi-wavelength operations. The
proposed device can bring about a breakthrough in the optical switching
capacity that potentially addresses the challenges faced by modern data center
networks, as well as other photonic circuits for high-throughput signal
processing.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02871" title="Abstract">arXiv:2403.02871</a> (cross-list from quant-ph) [<a href="/pdf/2403.02871" title="Download PDF">pdf</a>, <a href="/format/2403.02871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Mixed-State Self-Attention Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+F">Fu Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhao%2C+Q">Qinglin Zhao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Feng%2C+L">Li Feng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+C">Chuangtao Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lin%2C+Y">Yangbin Lin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lin%2C+J">Jianhong Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The rapid advancement of quantum computing has increasingly highlighted its
potential in the realm of machine learning, particularly in the context of
natural language processing (NLP) tasks. Quantum machine learning (QML)
leverages the unique capabilities of quantum computing to offer novel
perspectives and methodologies for complex data processing and pattern
recognition challenges. This paper introduces a novel Quantum Mixed-State
Attention Network (QMSAN), which integrates the principles of quantum computing
with classical machine learning algorithms, especially self-attention networks,
to enhance the efficiency and effectiveness in handling NLP tasks. QMSAN model
employs a quantum attention mechanism based on mixed states, enabling efficient
direct estimation of similarity between queries and keys within the quantum
domain, leading to more effective attention weight acquisition. Additionally,
we propose an innovative quantum positional encoding scheme, implemented
through fixed quantum gates within the quantum circuit, to enhance the model's
accuracy. Experimental validation on various datasets demonstrates that QMSAN
model outperforms existing quantum and classical models in text classification,
achieving significant performance improvements. QMSAN model not only
significantly reduces the number of parameters but also exceeds classical
self-attention networks in performance, showcasing its strong capability in
data representation and information extraction. Furthermore, our study
investigates the model's robustness in different quantum noise environments,
showing that QMSAN possesses commendable robustness to low noise.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02912" title="Abstract">arXiv:2403.02912</a> (cross-list from math.OC) [<a href="/pdf/2403.02912" title="Download PDF">pdf</a>, <a href="/ps/2403.02912" title="Download PostScript">ps</a>, <a href="/format/2403.02912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mirror Descent Algorithms with Nearly Dimension-Independent Rates for  Differentially-Private Stochastic Saddle-Point Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gonz%C3%A1lez%2C+T">Tom&#xe1;s Gonz&#xe1;lez</a>, 
<a href="/search/math?searchtype=author&query=Guzm%C3%A1n%2C+C">Crist&#xf3;bal Guzm&#xe1;n</a>, 
<a href="/search/math?searchtype=author&query=Paquette%2C+C">Courtney Paquette</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">We study the problem of differentially-private (DP) stochastic
(convex-concave) saddle-points in the polyhedral setting. We propose
$(\varepsilon, \delta)$-DP algorithms based on stochastic mirror descent that
attain nearly dimension-independent convergence rates for the expected duality
gap, a type of guarantee that was known before only for bilinear objectives.
For convex-concave and first-order-smooth stochastic objectives, our algorithms
attain a rate of $\sqrt{\log(d)/n} + (\log(d)^{3/2}/[n\varepsilon])^{1/3}$,
where $d$ is the dimension of the problem and $n$ the dataset size. Under an
additional second-order-smoothness assumption, we improve the rate on the
expected gap to $\sqrt{\log(d)/n} + (\log(d)^{3/2}/[n\varepsilon])^{2/5}$.
Under this additional assumption, we also show, by using bias-reduced gradient
estimators, that the duality gap is bounded by $\log(d)/\sqrt{n} +
\log(d)/[n\varepsilon]^{1/2}$ with constant success probability. This result
provides evidence of the near-optimality of the approach. Finally, we show that
combining our methods with acceleration techniques from online learning leads
to the first algorithm for DP Stochastic Convex Optimization in the polyhedral
setting that is not based on Frank-Wolfe methods. For convex and
first-order-smooth stochastic objectives, our algorithms attain an excess risk
of $\sqrt{\log(d)/n} + \log(d)^{7/10}/[n\varepsilon]^{2/5}$, and when
additionally assuming second-order-smoothness, we improve the rate to
$\sqrt{\log(d)/n} + \log(d)/\sqrt{n\varepsilon}$. Instrumental to all of these
results are various extensions of the classical Maurey Sparsification Lemma,
which may be of independent interest.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02921" title="Abstract">arXiv:2403.02921</a> (cross-list from physics.soc-ph) [<a href="/pdf/2403.02921" title="Download PDF">pdf</a>, <a href="/ps/2403.02921" title="Download PostScript">ps</a>, <a href="/format/2403.02921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum for Good and the Societal Impact of Quantum Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Troyer%2C+M">Matthias Troyer</a>, 
<a href="/search/physics?searchtype=author&query=Benjamin%2C+E+V">Emily Violi Benjamin</a>, 
<a href="/search/physics?searchtype=author&query=Gevorkian%2C+A">Ani Gevorkian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to be published in Pontificiae Academiae Scientiarvm Scripta Varia
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Computers and Society (cs.CY); Quantum Physics (quant-ph)

</div>
<p class="mathjax">Quantum computing promises to help humanity solve problems that would
otherwise be intractable on classical computers. Unlike today's machines,
quantum computers use a novel computing process that leverages the foundational
quantum mechanical laws of nature. This unlocks unparalleled compute power for
certain applications and promises to help solve some of our generation's
gravest challenges, including the climate crisis, food insecurity, and
widespread disease. No one entity will be able to realize this end state alone.
Developing a fault-tolerant quantum supercomputer and a vibrant ecosystem
around it will require deep partnerships between industry, governments, and
academia. It will also require collective action to enable and promote positive
applications of quantum computing and ensure that the safe and responsible use
of the technology is at the center of its development and deployment. Achieving
these objectives will require focusing on three priorities:
<br />1. Impact. Ensure quantum computing benefits all of humankind by developing
quantum solutions to solve critical, global problems.
<br />2. Use. Protect against malicious use by accelerating the deployment of
quantum-safe cryptography and developing governance processes and controls for
the responsible use of quantum machines.
<br />3. Access. Democratize the potential for economic growth across all of
society through skilling, workforce and ecosystem development, and digital
infrastructure.
<br />This paper discusses each in turn.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02937" title="Abstract">arXiv:2403.02937</a> (cross-list from quant-ph) [<a href="/pdf/2403.02937" title="Download PDF">pdf</a>, <a href="/ps/2403.02937" title="Download PostScript">ps</a>, <a href="/format/2403.02937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Algorithms in a Superposition of Spacetimes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Shmueli%2C+O">Omri Shmueli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">Quantum computers are expected to revolutionize our ability to process
information. The advancement from classical to quantum computing is a product
of our advancement from classical to quantum physics -- the more our
understanding of the universe grows, so does our ability to use it for
computation. A natural question that arises is, what will physics allow in the
future? Can more advanced theories of physics increase our computational power,
beyond quantum computing?
<br />An active field of research in physics studies theoretical phenomena outside
the scope of explainable quantum mechanics, that form when attempting to
combine Quantum Mechanics (QM) with General Relativity (GR) into a unified
theory of Quantum Gravity (QG). QG is known to present the possibility of a
quantum superposition of causal structure and event orderings. In the
literature of quantum information theory, this translates to a superposition of
unitary evolution orders.
<br />In this work we show a first example of a natural computational model based
on QG, that provides an exponential speedup over standard quantum computation
(under standard hardness assumptions). We define a model and complexity measure
for a quantum computer that has the ability to generate a superposition of
unitary evolution orders, and show that such computer is able to solve in
polynomial time two of the fundamental problems in computer science: The Graph
Isomorphism Problem ($\mathsf{GI}$) and the Gap Closest Vector Problem
($\mathsf{GapCVP}$), with gap $O\left( n^{2} \right)$. These problems are
believed by experts to be hard to solve for a regular quantum computer.
Interestingly, our model does not seem overpowered, and we found no obvious way
to solve entire complexity classes that are considered hard in computer
science, like the classes $\mathbf{NP}$ and $\mathbf{SZK}$.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02967" title="Abstract">arXiv:2403.02967</a> (cross-list from math.OC) [<a href="/pdf/2403.02967" title="Download PDF">pdf</a>, <a href="/format/2403.02967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Convex Stochastic Composite Optimization with Polyak Momentum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gao%2C+Y">Yuan Gao</a>, 
<a href="/search/math?searchtype=author&query=Rodomanov%2C+A">Anton Rodomanov</a>, 
<a href="/search/math?searchtype=author&query=Stich%2C+S+U">Sebastian U. Stich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The stochastic proximal gradient method is a powerful generalization of the
widely used stochastic gradient descent (SGD) method and has found numerous
applications in Machine Learning. However, it is notoriously known that this
method fails to converge in non-convex settings where the stochastic noise is
significant (i.e. when only small or bounded batch sizes are used). In this
paper, we focus on the stochastic proximal gradient method with Polyak
momentum. We prove this method attains an optimal convergence rate for
non-convex composite optimization problems, regardless of batch size.
Additionally, we rigorously analyze the variance reduction effect of the Polyak
momentum in the composite optimization setting and we show the method also
converges when the proximal step can only be solved inexactly. Finally, we
provide numerical experiments to validate our theoretical results.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02968" title="Abstract">arXiv:2403.02968</a> (cross-list from quant-ph) [<a href="/pdf/2403.02968" title="Download PDF">pdf</a>, <a href="/format/2403.02968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hamiltonian Property Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Bluhm%2C+A">Andreas Bluhm</a>, 
<a href="/search/quant-ph?searchtype=author&query=Caro%2C+M+C">Matthias C. Caro</a>, 
<a href="/search/quant-ph?searchtype=author&query=Oufkir%2C+A">Aadil Oufkir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39+18 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS); Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">Locality is a fundamental feature of many physical time evolutions.
Assumptions on locality and related structural properties also underlie
recently proposed procedures for learning an unknown Hamiltonian from access to
the induced time evolution. However, no protocols to rigorously test whether an
unknown Hamiltonian is local were known. We investigate Hamiltonian locality
testing as a property testing problem, where the task is to determine whether
an unknown $n$-qubit Hamiltonian $H$ is $k$-local or $\varepsilon$-far from all
$k$-local Hamiltonians, given access to the time evolution along $H$. First, we
emphasize the importance of the chosen distance measure: With respect to the
operator norm, a worst-case distance measure, incoherent quantum locality
testers require $\tilde{\Omega}(2^n)$ many time evolution queries and an
expected total evolution time of $\tilde{\Omega}(2^n / \varepsilon)$, and even
coherent testers need $\Omega(2^{n/2})$ many queries and
$\Omega(2^{n/2}/\varepsilon)$ total evolution time. In contrast, when distances
are measured according to the normalized Frobenius norm, corresponding to an
average-case distance, we give a sample-, time-, and computationally efficient
incoherent Hamiltonian locality testing algorithm based on randomized
measurements. In fact, our procedure can be used to simultaneously test a wide
class of Hamiltonian properties beyond locality. Finally, we prove that
learning a general Hamiltonian remains exponentially hard with this
average-case distance, thereby establishing an exponential separation between
Hamiltonian testing and learning. Our work initiates the study of property
testing for quantum Hamiltonians, demonstrating that a broad class of
Hamiltonian properties is efficiently testable even with limited quantum
capabilities, and positioning Hamiltonian testing as an independent area of
research alongside Hamiltonian learning.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02973" title="Abstract">arXiv:2403.02973</a> (cross-list from math.OC) [<a href="/pdf/2403.02973" title="Download PDF">pdf</a>, <a href="/ps/2403.02973" title="Download PostScript">ps</a>, <a href="/format/2403.02973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Predictive Control for setpoint tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Limon%2C+D">Daniel Limon</a>, 
<a href="/search/math?searchtype=author&query=Ferramosca%2C+A">Antonio Ferramosca</a>, 
<a href="/search/math?searchtype=author&query=Alvarado%2C+I">Ignacio Alvarado</a>, 
<a href="/search/math?searchtype=author&query=Alamo%2C+T">Teodoro Alamo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The main objective of tracking control is to steer the tracking error, that
is the difference between the reference and the output, to zero while the
plant's operation limits are satisfied. This requires that some assumptions on
the evolution of the future values of the reference must be taken into account.
Typically a simple evolution of the reference is considered, such as step,
ramp, or parabolic reference signals. It is important to notice that the
tracking problem considers possible variations in the reference to be tracked,
such as steps or slope variations of the ramps. Then the tracking control
problem is inherently uncertain, since the reference may differ from what is
expected. If the value of the reference is changed, then there is no guarantee
that the feasibility and stability properties of the resulting control law
hold. This report presents the MPC for tracking (MPCT) approach, which ensures
recursive feasibility and asymptotic stability of the setpoint when the value
of the reference is changed.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03013" title="Abstract">arXiv:2403.03013</a> (cross-list from math.CO) [<a href="/pdf/2403.03013" title="Download PDF">pdf</a>, <a href="/format/2403.03013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The clique chromatic number of sparse random graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=V%2C+M+F">Manuel Fernandez V</a>, 
<a href="/search/math?searchtype=author&query=Warnke%2C+L">Lutz Warnke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Probability (math.PR)

</div>
<p class="mathjax">The clique chromatic number of a graph is the smallest number of colors in a
vertex coloring so that no maximal clique is monochromatic. In this paper, we
determine the order of magnitude of the clique chromatic number of the random
graph G_{n,p} for most edge-probabilities p in the range n^{-2/5} \ll p \ll 1.
This resolves open problems and questions of Lichev, Mitsche and Warnke as well
as Alon and Krievelevich.
<br />One major proof difficulty stems from high-degree vertices, which prevent
maximal cliques in their neighborhoods: we deal with these vertices by an
intricate union bound argument, that combines the probabilistic method with new
degree counting arguments in order to enable Janson's inequality. This way we
determine the asymptotics of the clique chromatic number of G_{n,p} in some
ranges, and discover a surprising new phenomenon that contradicts earlier
predictions for edge-probabilities p close to n^{-2/5}.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03053" title="Abstract">arXiv:2403.03053</a> (cross-list from eess.SP) [<a href="/pdf/2403.03053" title="Download PDF">pdf</a>, <a href="/format/2403.03053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Codebook Design for Network Beam Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dreifuerst%2C+R+M">Ryan M. Dreifuerst</a>, 
<a href="/search/eess?searchtype=author&query=Heath%2C+R+W">Robert W. Heath Jr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be submitted to IEEE Transactions on Wireless Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Networking and Internet Architecture (cs.NI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Obtaining accurate and timely channel state information (CSI) is a
fundamental challenge for large antenna systems. Mobile systems like 5G use a
beam management framework that joins the initial access, beamforming, CSI
acquisition, and data transmission. The design of codebooks for these stages,
however, is challenging due to their interrelationships, varying array sizes,
and site-specific channel and user distributions. Furthermore, beam management
is often focused on single-sector operations while ignoring the overarching
network- and system-level optimization. In this paper, we proposed an
end-to-end learned codebook design algorithm, network beamspace learning (NBL),
that captures and optimizes codebooks to mitigate interference while maximizing
the achievable performance with extremely large hybrid arrays. The proposed
algorithm requires limited shared information yet designs codebooks that
outperform traditional codebooks by over 10dB in beam alignment and achieve
more than 25% improvements in network spectral efficiency.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03071" title="Abstract">arXiv:2403.03071</a> (cross-list from stat.ML) [<a href="/pdf/2403.03071" title="Download PDF">pdf</a>, <a href="/format/2403.03071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On a Neural Implementation of Brenier&#x27;s Polar Factorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Vesseron%2C+N">Nina Vesseron</a>, 
<a href="/search/stat?searchtype=author&query=Cuturi%2C+M">Marco Cuturi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In 1991, Brenier proved a theorem that generalizes the $QR$ decomposition for
square matrices -- factored as PSD $\times$ unitary -- to any vector field
$F:\mathbb{R}^d\rightarrow \mathbb{R}^d$. The theorem, known as the polar
factorization theorem, states that any field $F$ can be recovered as the
composition of the gradient of a convex function $u$ with a measure-preserving
map $M$, namely $F=\nabla u \circ M$. We propose a practical implementation of
this far-reaching theoretical result, and explore possible uses within machine
learning. The theorem is closely related to optimal transport (OT) theory, and
we borrow from recent advances in the field of neural optimal transport to
parameterize the potential $u$ as an input convex neural network. The map $M$
can be either evaluated pointwise using $u^*$, the convex conjugate of $u$,
through the identity $M=\nabla u^* \circ F$, or learned as an auxiliary
network. Because $M$ is, in general, not injective, we consider the additional
task of estimating the ill-posed inverse map that can approximate the pre-image
measure $M^{-1}$ using a stochastic generator. We illustrate possible
applications of \citeauthor{Brenier1991PolarFA}'s polar factorization to
non-convex optimization problems, as well as sampling of densities that are not
log-concave.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03085" title="Abstract">arXiv:2403.03085</a> (cross-list from math.CT) [<a href="/pdf/2403.03085" title="Download PDF">pdf</a>, <a href="/ps/2403.03085" title="Download PostScript">ps</a>, <a href="/format/2403.03085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A 2-categorical analysis of context comprehension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Coraglia%2C+G">Greta Coraglia</a>, 
<a href="/search/math?searchtype=author&query=Emmenegger%2C+J">Jacopo Emmenegger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Logic in Computer Science (cs.LO); Logic (math.LO)

</div>
<p class="mathjax">We consider the equivalence between the two main categorical models for the
type-theoretical operation of context comprehension, namely P. Dybjer's
categories with families and B. Jacobs' comprehension categories, and
generalise it to the non-discrete case. The classical equivalence can be
summarised in the slogan: "terms as sections". By recognising "terms as
coalgebras", we show how to use the structure-semantics adjunction to prove
that a 2-category of comprehension categories is biequivalent to a 2-category
of (non-discrete) categories with families. The biequivalence restricts to the
classical one proved by Hofmann in the discrete case. It also provides a
framework where to compare different morphisms of these structures that have
appeared in the literature, varying on the degree of preservation of the
relevant structure. We consider in particular morphisms defined by
Claraimbault-Dybjer, Jacobs, Larrea, and Uemura.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03089" title="Abstract">arXiv:2403.03089</a> (cross-list from q-bio.QM) [<a href="/pdf/2403.03089" title="Download PDF">pdf</a>, <a href="/format/2403.03089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VQSynery: Robust Drug Synergy Prediction With Vector Quantization  Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Wu%2C+J">Jiawei Wu</a>, 
<a href="/search/q-bio?searchtype=author&query=Yan%2C+M">Mingyuan Yan</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+D">Dianbo Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The pursuit of optimizing cancer therapies is significantly advanced by the
accurate prediction of drug synergy. Traditional methods, such as clinical
trials, are reliable yet encumbered by extensive time and financial demands.
The emergence of high-throughput screening and computational innovations has
heralded a shift towards more efficient methodologies for exploring drug
interactions. In this study, we present VQSynergy, a novel framework that
employs the Vector Quantization (VQ) mechanism, integrated with gated residuals
and a tailored attention mechanism, to enhance the precision and
generalizability of drug synergy predictions. Our findings demonstrate that
VQSynergy surpasses existing models in terms of robustness, particularly under
Gaussian noise conditions, highlighting its superior performance and utility in
the complex and often noisy domain of drug synergy research. This study
underscores the potential of VQSynergy in revolutionizing the field through its
advanced predictive capabilities, thereby contributing to the optimization of
cancer treatment strategies.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03100" title="Abstract">arXiv:2403.03100</a> (cross-list from eess.AS) [<a href="/pdf/2403.03100" title="Download PDF">pdf</a>, <a href="/format/2403.03100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ju%2C+Z">Zeqian Ju</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yuancheng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+K">Kai Shen</a>, 
<a href="/search/eess?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/eess?searchtype=author&query=Xin%2C+D">Detai Xin</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+D">Dongchao Yang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yanqing Liu</a>, 
<a href="/search/eess?searchtype=author&query=Leng%2C+Y">Yichong Leng</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+K">Kaitao Song</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+S">Siliang Tang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Z">Zhizheng Wu</a>, 
<a href="/search/eess?searchtype=author&query=Qin%2C+T">Tao Qin</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiang-Yang Li</a>, 
<a href="/search/eess?searchtype=author&query=Ye%2C+W">Wei Ye</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+S">Shikun Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Bian%2C+J">Jiang Bian</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+L">Lei He</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jinyu Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+S">Sheng Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 15 tables, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">While recent large-scale text-to-speech (TTS) models have achieved
significant progress, they still fall short in speech quality, similarity, and
prosody. Considering speech intricately encompasses various attributes (e.g.,
content, prosody, timbre, and acoustic details) that pose significant
challenges for generation, a natural idea is to factorize speech into
individual subspaces representing different attributes and generate them
individually. Motivated by it, we propose NaturalSpeech 3, a TTS system with
novel factorized diffusion models to generate natural speech in a zero-shot
way. Specifically, 1) we design a neural codec with factorized vector
quantization (FVQ) to disentangle speech waveform into subspaces of content,
prosody, timbre, and acoustic details; 2) we propose a factorized diffusion
model to generate attributes in each subspace following its corresponding
prompt. With this factorization design, NaturalSpeech 3 can effectively and
efficiently model the intricate speech with disentangled subspaces in a
divide-and-conquer way. Experiments show that NaturalSpeech 3 outperforms the
state-of-the-art TTS systems on quality, similarity, prosody, and
intelligibility. Furthermore, we achieve better performance by scaling to 1B
parameters and 200K hours of training data.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03104" title="Abstract">arXiv:2403.03104</a> (cross-list from math.OC) [<a href="/pdf/2403.03104" title="Download PDF">pdf</a>, <a href="/ps/2403.03104" title="Download PostScript">ps</a>, <a href="/format/2403.03104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-rank approximated Kalman-Bucy filters using Oja&#x27;s principal  component flow for linear time-invariant systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tsuzuki%2C+D">Daiki Tsuzuki</a>, 
<a href="/search/math?searchtype=author&query=Ohki%2C+K">Kentaro Ohki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The Kalman-Bucy filter is widely used in various applications. However, the
filter becomes computationally complex under large-scale systems. To address
this problem, a low-rank approximated Kalman-Bucy filter consisting of Oja's
principal component flow and a low-dimensional Riccati differential equation
was proposed. However, the estimation error was established only for linear
time-invariant systems with a symmetric system matrix. This study removes
restrictions on the symmetricity of the system matrix and reveals the
equilibrium points of the Oja flow and their stability for general real square
matrices. In addition, the attraction domain for a set of stable equilibrium
points is estimated. Based on these results, we demonstrate that the low-rank
approximated Kalman-Bucy filter has a bounded estimation error covariance
matrix when the system is controllable and observable.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03143" title="Abstract">arXiv:2403.03143</a> (cross-list from physics.soc-ph) [<a href="/pdf/2403.03143" title="Download PDF">pdf</a>, <a href="/format/2403.03143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Smartphones to Study Vaccination Decisions in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Girardini%2C+N+A">Nicol&#xf2; Alessandro Girardini</a>, 
<a href="/search/physics?searchtype=author&query=Stopczynski%2C+A">Arkadiusz Stopczynski</a>, 
<a href="/search/physics?searchtype=author&query=Baranov%2C+O">Olga Baranov</a>, 
<a href="/search/physics?searchtype=author&query=Betsch%2C+C">Cornelia Betsch</a>, 
<a href="/search/physics?searchtype=author&query=Brockmann%2C+D">Dirk Brockmann</a>, 
<a href="/search/physics?searchtype=author&query=Lehmann%2C+S">Sune Lehmann</a>, 
<a href="/search/physics?searchtype=author&query=B%C3%B6hm%2C+R">Robert B&#xf6;hm</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">One of the most important tools available to limit the spread and impact of
infectious diseases is vaccination. It is therefore important to understand
what factors determine people's vaccination decisions. To this end, previous
behavioural research made use of, (i) controlled but often abstract or
hypothetical studies (e.g., vignettes) or, (ii) realistic but typically less
flexible studies that make it difficult to understand individual decision
processes (e.g., clinical trials). Combining the best of these approaches, we
propose integrating real-world Bluetooth contacts via smartphones in several
rounds of a game scenario, as a novel methodology to study vaccination
decisions and disease spread. In our 12-week proof-of-concept study conducted
with $N$ = 494 students, we found that participants strongly responded to some
of the information provided to them during or after each decision round,
particularly those related to their individual health outcomes. In contrast,
information related to others' decisions and outcomes (e.g., the number of
vaccinated or infected individuals) appeared to be less important. We discuss
the potential of this novel method and point to fruitful areas for future
research.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03154" title="Abstract">arXiv:2403.03154</a> (cross-list from physics.comp-ph) [<a href="/pdf/2403.03154" title="Download PDF">pdf</a>, <a href="/format/2403.03154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Many-Body Physics Calculations with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Pan%2C+H">Haining Pan</a>, 
<a href="/search/physics?searchtype=author&query=Mudur%2C+N">Nayantara Mudur</a>, 
<a href="/search/physics?searchtype=author&query=Taranto%2C+W">Will Taranto</a>, 
<a href="/search/physics?searchtype=author&query=Tikhanovskaya%2C+M">Maria Tikhanovskaya</a>, 
<a href="/search/physics?searchtype=author&query=Venugopalan%2C+S">Subhashini Venugopalan</a>, 
<a href="/search/physics?searchtype=author&query=Bahri%2C+Y">Yasaman Bahri</a>, 
<a href="/search/physics?searchtype=author&query=Brenner%2C+M+P">Michael P. Brenner</a>, 
<a href="/search/physics?searchtype=author&query=Kim%2C+E">Eun-Ah Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures. Supplemental material in the source file
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Other Condensed Matter (cond-mat.other); Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated an unprecedented ability to
perform complex tasks in multiple domains, including mathematical and
scientific reasoning. We demonstrate that with carefully designed prompts, LLMs
can accurately carry out key calculations in research papers in theoretical
physics. We focus on a broadly used approximation method in quantum physics:
the Hartree-Fock method, requiring an analytic multi-step calculation deriving
approximate Hamiltonian and corresponding self-consistency equations. To carry
out the calculations using LLMs, we design multi-step prompt templates that
break down the analytic calculation into standardized steps with placeholders
for problem-specific information. We evaluate GPT-4's performance in executing
the calculation for 15 research papers from the past decade, demonstrating
that, with correction of intermediate steps, it can correctly derive the final
Hartree-Fock Hamiltonian in 13 cases and makes minor errors in 2 cases.
Aggregating across all research papers, we find an average score of 87.5 (out
of 100) on the execution of individual calculation steps. Overall, the
requisite skill for doing these calculations is at the graduate level in
quantum condensed matter theory. We further use LLMs to mitigate the two
primary bottlenecks in this evaluation process: (i) extracting information from
papers to fill in templates and (ii) automatic scoring of the calculation
steps, demonstrating good results in both cases. The strong performance is the
first step for developing algorithms that automatically explore theoretical
hypotheses at an unprecedented scale.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03180" title="Abstract">arXiv:2403.03180</a> (cross-list from math.OC) [<a href="/pdf/2403.03180" title="Download PDF">pdf</a>, <a href="/format/2403.03180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shuffling Momentum Gradient Algorithm for Convex Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tran%2C+T+H">Trang H. Tran</a>, 
<a href="/search/math?searchtype=author&query=Tran-Dinh%2C+Q">Quoc Tran-Dinh</a>, 
<a href="/search/math?searchtype=author&query=Nguyen%2C+L+M">Lam M. Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Vietnam Journal of Mathematics (VJOM), Special issue dedicated to Dr. Tam\'as Terlaky on the occasion of his 70th birthday, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The Stochastic Gradient Descent method (SGD) and its stochastic variants have
become methods of choice for solving finite-sum optimization problems arising
from machine learning and data science thanks to their ability to handle
large-scale applications and big datasets. In the last decades, researchers
have made substantial effort to study the theoretical performance of SGD and
its shuffling variants. However, only limited work has investigated its
shuffling momentum variants, including shuffling heavy-ball momentum schemes
for non-convex problems and Nesterov's momentum for convex settings. In this
work, we extend the analysis of the shuffling momentum gradient method
developed in [Tran et al (2021)] to both finite-sum convex and strongly convex
optimization problems. We provide the first analysis of shuffling
momentum-based methods for the strongly convex setting, attaining a convergence
rate of $O(1/nT^2)$, where $n$ is the number of samples and $T$ is the number
of training epochs. Our analysis is a state-of-the-art, matching the best rates
of existing shuffling stochastic gradient algorithms in the literature.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03205" title="Abstract">arXiv:2403.03205</a> (cross-list from math.ST) [<a href="/pdf/2403.03205" title="Download PDF">pdf</a>, <a href="/format/2403.03205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Super-spreaders in Network Cascades
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mossel%2C+E">Elchanan Mossel</a>, 
<a href="/search/math?searchtype=author&query=Sridhar%2C+A">Anirudh Sridhar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Information Theory (cs.IT); Social and Information Networks (cs.SI); Probability (math.PR)

</div>
<p class="mathjax">Suppose that a cascade (e.g., an epidemic) spreads on an unknown graph, and
only the infection times of vertices are observed. What can be learned about
the graph from the infection times caused by multiple distinct cascades? Most
of the literature on this topic focuses on the task of recovering the entire
graph, which requires $\Omega ( \log n)$ cascades for an $n$-vertex bounded
degree graph. Here we ask a different question: can the important parts of the
graph be estimated from just a few (i.e., constant number) of cascades, even as
$n$ grows large?
<br />In this work, we focus on identifying super-spreaders (i.e., high-degree
vertices) from infection times caused by a Susceptible-Infected process on a
graph. Our first main result shows that vertices of degree greater than
$n^{3/4}$ can indeed be estimated from a constant number of cascades. Our
algorithm for doing so leverages a novel connection between vertex degrees and
the second derivative of the cumulative infection curve. Conversely, we show
that estimating vertices of degree smaller than $n^{1/2}$ requires at least
$\log(n) / \log \log (n)$ cascades. Surprisingly, this matches (up to $\log
\log n$ factors) the number of cascades needed to learn the \emph{entire} graph
if it is a tree.
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03208" title="Abstract">arXiv:2403.03208</a> (cross-list from stat.ML) [<a href="/pdf/2403.03208" title="Download PDF">pdf</a>, <a href="/format/2403.03208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Statistical Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zrnic%2C+T">Tijana Zrnic</a>, 
<a href="/search/stat?searchtype=author&query=Cand%C3%A8s%2C+E+J">Emmanuel J. Cand&#xe8;s</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Inspired by the concept of active learning, we propose active
inference$\unicode{x2013}$a methodology for statistical inference with
machine-learning-assisted data collection. Assuming a budget on the number of
labels that can be collected, the methodology uses a machine learning model to
identify which data points would be most beneficial to label, thus effectively
utilizing the budget. It operates on a simple yet powerful intuition:
prioritize the collection of labels for data points where the model exhibits
uncertainty, and rely on the model's predictions where it is confident. Active
inference constructs provably valid confidence intervals and hypothesis tests
while leveraging any black-box machine learning model and handling any data
distribution. The key point is that it achieves the same level of accuracy with
far fewer samples than existing baselines relying on non-adaptively-collected
data. This means that for the same number of collected samples, active
inference enables smaller confidence intervals and more powerful p-values. We
evaluate active inference on datasets from public opinion research, census
analysis, and proteomics.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Wed,  6 Mar 24</h3>
<dl>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1711.01183" title="Abstract">arXiv:1711.01183</a> (replaced) [<a href="/pdf/1711.01183" title="Download PDF">pdf</a>, <a href="/format/1711.01183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal actuator design based on shape calculus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kalise%2C+D">Dante Kalise</a>, 
<a href="/search/math?searchtype=author&query=Kunisch%2C+K">Karl Kunisch</a>, 
<a href="/search/math?searchtype=author&query=Sturm%2C+K">Kevin Sturm</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, differs from previous version as proof of Theorem 4.2 has been fixed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1905.07342" title="Abstract">arXiv:1905.07342</a> (replaced) [<a href="/pdf/1905.07342" title="Download PDF">pdf</a>, <a href="/format/1905.07342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pair-Matching: Links Prediction with Adaptive Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Giraud%2C+C">Christophe Giraud</a>, 
<a href="/search/stat?searchtype=author&query=Issartel%2C+Y">Yann Issartel</a>, 
<a href="/search/stat?searchtype=author&query=Leh%C3%A9ricy%2C+L">Luc Leh&#xe9;ricy</a>, 
<a href="/search/stat?searchtype=author&query=Lerasle%2C+M">Matthieu Lerasle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 78 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1910.14080" title="Abstract">arXiv:1910.14080</a> (replaced) [<a href="/pdf/1910.14080" title="Download PDF">pdf</a>, <a href="/ps/1910.14080" title="Download PostScript">ps</a>, <a href="/format/1910.14080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextual Text Denoising with Masked Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yifu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haoming Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2001.05371" title="Abstract">arXiv:2001.05371</a> (replaced) [<a href="/pdf/2001.05371" title="Download PDF">pdf</a>, <a href="/format/2001.05371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making deep neural networks right for the right scientific reasons by  interacting with their explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schramowski%2C+P">Patrick Schramowski</a>, 
<a href="/search/cs?searchtype=author&query=Stammer%2C+W">Wolfgang Stammer</a>, 
<a href="/search/cs?searchtype=author&query=Teso%2C+S">Stefano Teso</a>, 
<a href="/search/cs?searchtype=author&query=Brugger%2C+A">Anna Brugger</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+X">Xiaoting Shao</a>, 
<a href="/search/cs?searchtype=author&query=Luigs%2C+H">Hans-Georg Luigs</a>, 
<a href="/search/cs?searchtype=author&query=Mahlein%2C+A">Anne-Katrin Mahlein</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/1805.08578">arXiv:1805.08578</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.08207" title="Abstract">arXiv:2102.08207</a> (replaced) [<a href="/pdf/2102.08207" title="Download PDF">pdf</a>, <a href="/format/2102.08207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decidability for Sturmian words
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hieronymi%2C+P">Philipp Hieronymi</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+D">Dun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Oei%2C+R">Reed Oei</a>, 
<a href="/search/cs?searchtype=author&query=Schaeffer%2C+L">Luke Schaeffer</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+C">Christian Schulz</a>, 
<a href="/search/cs?searchtype=author&query=Shallit%2C+J">Jeffrey Shallit</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Combinatorics (math.CO); Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.12920" title="Abstract">arXiv:2102.12920</a> (replaced) [<a href="/pdf/2102.12920" title="Download PDF">pdf</a>, <a href="/ps/2102.12920" title="Download PostScript">ps</a>, <a href="/format/2102.12920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emerging Trends in Federated Learning: From Model Fusion to Federated X  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shaoxiong Ji</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yue Tan</a>, 
<a href="/search/cs?searchtype=author&query=Saravirta%2C+T">Teemu Saravirta</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhiqin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yixin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Vasankari%2C+L">Lauri Vasankari</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+G">Guodong Long</a>, 
<a href="/search/cs?searchtype=author&query=Walid%2C+A">Anwar Walid</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.04987" title="Abstract">arXiv:2104.04987</a> (replaced) [<a href="/pdf/2104.04987" title="Download PDF">pdf</a>, <a href="/format/2104.04987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoGL: A Library for Automated Graph Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yijian Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+C">Chaoyu Guan</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+J">Jie Cai</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Heng Chang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jiyan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zixin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+B">Beini Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yipeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenwu Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version; initial version published at ICLR 2021 Workshop on Geometrical and Topological Representation Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.04274" title="Abstract">arXiv:2106.04274</a> (replaced) [<a href="/pdf/2106.04274" title="Download PDF">pdf</a>, <a href="/format/2106.04274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Human Pose Estimation Based on 2D-3D Consistency with Synchronized  Adversarial Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yicheng Deng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Cheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yongqi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiahui Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.01633" title="Abstract">arXiv:2108.01633</a> (replaced) [<a href="/pdf/2108.01633" title="Download PDF">pdf</a>, <a href="/ps/2108.01633" title="Download PostScript">ps</a>, <a href="/format/2108.01633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing Linear Hadwiger&#x27;s Conjecture to Coloring Small Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Delcourt%2C+M">Michelle Delcourt</a>, 
<a href="/search/math?searchtype=author&query=Postle%2C+L">Luke Postle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages. In this version, some minor typos fixed. Previously updated in response to referee comments. This and the three previous versions add the necessary results from <a href="/abs/2006.11798">arXiv:2006.11798</a> in order to create a self-contained standalone paper. arXiv admin note: text overlap with <a href="/abs/2006.11798">arXiv:2006.11798</a>, <a href="/abs/2010.05999">arXiv:2010.05999</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.04376" title="Abstract">arXiv:2108.04376</a> (replaced) [<a href="/pdf/2108.04376" title="Download PDF">pdf</a>, <a href="/format/2108.04376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counterfactual Effect Generalization: A Combinatorial Definition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ribeiro%2C+A+F">Andre F. Ribeiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.10795" title="Abstract">arXiv:2109.10795</a> (replaced) [<a href="/pdf/2109.10795" title="Download PDF">pdf</a>, <a href="/format/2109.10795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural network relief: a pruning algorithm based on neural activity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dekhovich%2C+A">Aleksandr Dekhovich</a>, 
<a href="/search/cs?searchtype=author&query=Tax%2C+D+M+J">David M.J. Tax</a>, 
<a href="/search/cs?searchtype=author&query=Sluiter%2C+M+H+F">Marcel H.F. Sluiter</a>, 
<a href="/search/cs?searchtype=author&query=Bessa%2C+M+A">Miguel A. Bessa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.00557" title="Abstract">arXiv:2111.00557</a> (replaced) [<a href="/pdf/2111.00557" title="Download PDF">pdf</a>, <a href="/format/2111.00557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On The Absolute Constant in Hanson-Wright Inequality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Moshksar%2C+K">Kamyar Moshksar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.10657" title="Abstract">arXiv:2111.10657</a> (replaced) [<a href="/pdf/2111.10657" title="Download PDF">pdf</a>, <a href="/format/2111.10657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizing Graph Neural Networks on Out-Of-Distribution Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Shaohua Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+P">Peng Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bai Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.10985" title="Abstract">arXiv:2202.10985</a> (replaced) [<a href="/pdf/2202.10985" title="Download PDF">pdf</a>, <a href="/format/2202.10985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Laboratory Experiment on Using Different Financial-Incentivization  Schemes in Software-Engineering Experimentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bershadskyy%2C+D">Dmitri Bershadskyy</a> (1), 
<a href="/search/cs?searchtype=author&query=Kr%C3%BCger%2C+J">Jacob Kr&#xfc;ger</a> (2), 
<a href="/search/cs?searchtype=author&query=%C3%87al%C4%B1kl%C4%B1%2C+G">G&#xfc;l &#xc7;al&#x131;kl&#x131;</a> (3), 
<a href="/search/cs?searchtype=author&query=Otto%2C+S">Siegmar Otto</a> (4), 
<a href="/search/cs?searchtype=author&query=Zabel%2C+S">Sarah Zabel</a> (1 and 4), 
<a href="/search/cs?searchtype=author&query=Greif%2C+J">Jannik Greif</a> (1), 
<a href="/search/cs?searchtype=author&query=Heyer%2C+R">Robert Heyer</a> (5) ((1) Otto-von-Guericke University Magdeburg, Germany (2) Eindhoven University of Technology, The Netherlands (3) University of Glasgow, UK (4) University of Hohenheim, Germany (5) Leibniz Institute for Analytical Sciences Dortmund and Bielefeld University, Germany)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Laboratory experiment for our registered report (previous preprints) with tracked changes, submitted for peer review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.04392" title="Abstract">arXiv:2205.04392</a> (replaced) [<a href="/pdf/2205.04392" title="Download PDF">pdf</a>, <a href="/ps/2205.04392" title="Download PostScript">ps</a>, <a href="/format/2205.04392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &#x3c9;-Regular Energy Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dziadek%2C+S">Sven Dziadek</a>, 
<a href="/search/cs?searchtype=author&query=Fahrenberg%2C+U">Uli Fahrenberg</a>, 
<a href="/search/cs?searchtype=author&query=Schlehuber-Caissier%2C+P">Philipp Schlehuber-Caissier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.10089" title="Abstract">arXiv:2205.10089</a> (replaced) [<a href="/pdf/2205.10089" title="Download PDF">pdf</a>, <a href="/format/2205.10089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kernel Normalized Convolutional Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nasirigerdeh%2C+R">Reza Nasirigerdeh</a>, 
<a href="/search/cs?searchtype=author&query=Torkzadehmahani%2C+R">Reihaneh Torkzadehmahani</a>, 
<a href="/search/cs?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a>, 
<a href="/search/cs?searchtype=author&query=Kaissis%2C+G">Georgios Kaissis</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transactions on Machine Learning Research (TMLR), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.05880" title="Abstract">arXiv:2206.05880</a> (replaced) [<a href="/pdf/2206.05880" title="Download PDF">pdf</a>, <a href="/format/2206.05880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Confident Sinkhorn Allocation for Pseudo-Labeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Vu Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Husain%2C+H">Hisham Husain</a>, 
<a href="/search/cs?searchtype=author&query=Farfade%2C+S">Sachin Farfade</a>, 
<a href="/search/cs?searchtype=author&query=van+den+Hengel%2C+A">Anton van den Hengel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code <a href="https://github.com/amzn/confident-sinkhorn-allocation">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.10540" title="Abstract">arXiv:2206.10540</a> (replaced) [<a href="/pdf/2206.10540" title="Download PDF">pdf</a>, <a href="/format/2206.10540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Symbolic Regression Datasets and Benchmarks for Scientific  Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Matsubara%2C+Y">Yoshitomo Matsubara</a>, 
<a href="/search/cs?searchtype=author&query=Chiba%2C+N">Naoya Chiba</a>, 
<a href="/search/cs?searchtype=author&query=Igarashi%2C+R">Ryo Igarashi</a>, 
<a href="/search/cs?searchtype=author&query=Ushiku%2C+Y">Yoshitaka Ushiku</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at DMLR. Code and datasets are available at <a href="https://github.com/omron-sinicx/srsd-benchmark">this https URL</a> <a href="https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_easy">this https URL</a> <a href="https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_medium">this https URL</a> <a href="https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_hard">this https URL</a> and another three sets of SRSD datasets with dummy variables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Symbolic Computation (cs.SC)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.11456" title="Abstract">arXiv:2206.11456</a> (replaced) [<a href="/pdf/2206.11456" title="Download PDF">pdf</a>, <a href="/format/2206.11456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metric Optimization in Penner Coordinates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Capouellez%2C+R">Ryan Capouellez</a>, 
<a href="/search/cs?searchtype=author&query=Zorin%2C+D">Denis Zorin</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Trans. Graph. 42, 6, Article 234 (December 2023), 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.00300" title="Abstract">arXiv:2208.00300</a> (replaced) [<a href="/pdf/2208.00300" title="Download PDF">pdf</a>, <a href="/ps/2208.00300" title="Download PostScript">ps</a>, <a href="/format/2208.00300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the bottleneck stability of rank decompositions of multi-parameter  persistence modules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Botnan%2C+M+B">Magnus Bakke Botnan</a>, 
<a href="/search/math?searchtype=author&query=Oppermann%2C+S">Steffen Oppermann</a>, 
<a href="/search/math?searchtype=author&query=Oudot%2C+S">Steve Oudot</a>, 
<a href="/search/math?searchtype=author&query=Scoccola%2C+L">Luis Scoccola</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 4 figures; v2: add details, fix typos and minor issues, improve exposition, add conjecture 5.30
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Topology (math.AT)</span>; Computational Geometry (cs.CG); Representation Theory (math.RT)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.01375" title="Abstract">arXiv:2209.01375</a> (replaced) [<a href="/pdf/2209.01375" title="Download PDF">pdf</a>, <a href="/format/2209.01375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Variational Approach for Joint Image Recovery and Feature Extraction  Based on Spatially-Varying Generalised Gaussian Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chouzenoux%2C+E">Emilie Chouzenoux</a>, 
<a href="/search/cs?searchtype=author&query=Corbineau%2C+M">Marie-Caroline Corbineau</a>, 
<a href="/search/cs?searchtype=author&query=Pesquet%2C+J">Jean-Christophe Pesquet</a>, 
<a href="/search/cs?searchtype=author&query=Scrivanti%2C+G">Gabriele Scrivanti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.13797" title="Abstract">arXiv:2209.13797</a> (replaced) [<a href="/pdf/2209.13797" title="Download PDF">pdf</a>, <a href="/format/2209.13797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PCB-RandNet: Rethinking Random Sampling for LIDAR Semantic Segmentation  in Autonomous Driving Scene
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Huixian Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">XianFeng Han</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+D">Dehong He</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+G">Guoqiang Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICRA 2024. Code: <a href="https://github.com/huixiancheng/PCB-RandNet">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10209" title="Abstract">arXiv:2211.10209</a> (replaced) [<a href="/pdf/2211.10209" title="Download PDF">pdf</a>, <a href="/format/2211.10209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Alignment of Group Fairness with Attribute Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aalmoes%2C+J">Jan Aalmoes</a>, 
<a href="/search/cs?searchtype=author&query=Duddu%2C+V">Vasisht Duddu</a>, 
<a href="/search/cs?searchtype=author&query=Boutet%2C+A">Antoine Boutet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2202.02242">arXiv:2202.02242</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13715" title="Abstract">arXiv:2211.13715</a> (replaced) [<a href="/pdf/2211.13715" title="Download PDF">pdf</a>, <a href="/format/2211.13715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trust Your $\nabla$: Gradient-based Intervention Targeting for Causal  Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Olko%2C+M">Mateusz Olko</a>, 
<a href="/search/stat?searchtype=author&query=Zaj%C4%85c%2C+M">Micha&#x142; Zaj&#x105;c</a>, 
<a href="/search/stat?searchtype=author&query=Nowak%2C+A">Aleksandra Nowak</a>, 
<a href="/search/stat?searchtype=author&query=Scherrer%2C+N">Nino Scherrer</a>, 
<a href="/search/stat?searchtype=author&query=Annadani%2C+Y">Yashas Annadani</a>, 
<a href="/search/stat?searchtype=author&query=Bauer%2C+S">Stefan Bauer</a>, 
<a href="/search/stat?searchtype=author&query=Kuci%C5%84ski%2C+%C5%81">&#x141;ukasz Kuci&#x144;ski</a>, 
<a href="/search/stat?searchtype=author&query=Mi%C5%82o%C5%9B%2C+P">Piotr Mi&#x142;o&#x15b;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.15188" title="Abstract">arXiv:2211.15188</a> (replaced) [<a href="/pdf/2211.15188" title="Download PDF">pdf</a>, <a href="/format/2211.15188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incremental Spatial and Spectral Learning of Neural Operators for  Solving Large-Scale PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=George%2C+R+J">Robert Joseph George</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiawei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Kossaifi%2C+J">Jean Kossaifi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.16860" title="Abstract">arXiv:2211.16860</a> (replaced) [<a href="/pdf/2211.16860" title="Download PDF">pdf</a>, <a href="/format/2211.16860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gapped String Indexing in Subquadratic Space and Sublinear Query Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bille%2C+P">Philip Bille</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B8rtz%2C+I+L">Inge Li G&#xf8;rtz</a>, 
<a href="/search/cs?searchtype=author&query=Lewenstein%2C+M">Moshe Lewenstein</a>, 
<a href="/search/cs?searchtype=author&query=Pissis%2C+S+P">Solon P. Pissis</a>, 
<a href="/search/cs?searchtype=author&query=Rotenberg%2C+E">Eva Rotenberg</a>, 
<a href="/search/cs?searchtype=author&query=Steiner%2C+T+A">Teresa Anna Steiner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 2 figures. To appear at STACS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.17029" title="Abstract">arXiv:2211.17029</a> (replaced) [<a href="/pdf/2211.17029" title="Download PDF">pdf</a>, <a href="/format/2211.17029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Directed Acyclic Graph Structure Learning from Dynamic Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Shaohua Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chuan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.05005" title="Abstract">arXiv:2212.05005</a> (replaced) [<a href="/pdf/2212.05005" title="Download PDF">pdf</a>, <a href="/format/2212.05005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memories are One-to-Many Mapping Alleviators in Talking Face Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+A">Anni Tang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tianyu He</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+J">Jun Ling</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Li Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: see <a href="https://memoryface.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.11337" title="Abstract">arXiv:2212.11337</a> (replaced) [<a href="/pdf/2212.11337" title="Download PDF">pdf</a>, <a href="/format/2212.11337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unscrambling Quantum Information with Clifford decoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Oliviero%2C+S+F+E">Salvatore F.E. Oliviero</a>, 
<a href="/search/quant-ph?searchtype=author&query=Leone%2C+L">Lorenzo Leone</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lloyd%2C+S">Seth Lloyd</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hamma%2C+A">Alioscia Hamma</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Phys. Rev. Lett. 132, 080402 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); General Relativity and Quantum Cosmology (gr-qc); High Energy Physics - Theory (hep-th)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.12760" title="Abstract">arXiv:2212.12760</a> (replaced) [<a href="/pdf/2212.12760" title="Download PDF">pdf</a>, <a href="/ps/2212.12760" title="Download PostScript">ps</a>, <a href="/format/2212.12760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agent-based Modeling and Simulation of Human Muscle For Development of  Human Gait Analyzer Application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saadati%2C+S">Sina Saadati</a>, 
<a href="/search/cs?searchtype=author&query=Razzazi%2C+M">Mohammadreza Razzazi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 15 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02148" title="Abstract">arXiv:2301.02148</a> (replaced) [<a href="/pdf/2301.02148" title="Download PDF">pdf</a>, <a href="/format/2301.02148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An electromechanics-driven fluid dynamics model for the simulation of  the whole human heart
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zingaro%2C+A">Alberto Zingaro</a>, 
<a href="/search/math?searchtype=author&query=Bucelli%2C+M">Michele Bucelli</a>, 
<a href="/search/math?searchtype=author&query=Piersanti%2C+R">Roberto Piersanti</a>, 
<a href="/search/math?searchtype=author&query=Regazzoni%2C+F">Francesco Regazzoni</a>, 
<a href="/search/math?searchtype=author&query=Dede%27%2C+L">Luca Dede&#x27;</a>, 
<a href="/search/math?searchtype=author&query=Quarteroni%2C+A">Alfio Quarteroni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Engineering, Finance, and Science (cs.CE); Biological Physics (physics.bio-ph); Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.05849" title="Abstract">arXiv:2301.05849</a> (replaced) [<a href="/pdf/2301.05849" title="Download PDF">pdf</a>, <a href="/format/2301.05849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Distillation in Federated Edge Learning: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Sheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Min Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xuefeng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Runhan Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+B">Bo Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 1 figure, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09522" title="Abstract">arXiv:2301.09522</a> (replaced) [<a href="/pdf/2301.09522" title="Download PDF">pdf</a>, <a href="/format/2301.09522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimising Event-Driven Spiking Neural Network with Regularisation and  Cutoff
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Dengyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+G">Gaojie Jin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Han Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xinping Yi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaowei Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10327" title="Abstract">arXiv:2301.10327</a> (replaced) [<a href="/pdf/2301.10327" title="Download PDF">pdf</a>, <a href="/format/2301.10327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Multidimensional Clusters With Support Lines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fachada%2C+N">Nuno Fachada</a>, 
<a href="/search/cs?searchtype=author&query=de+Andrade%2C+D">Diogo de Andrade</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The peer-reviewed version of this paper is published in Knowledge-Based Systems at <a href="https://doi.org/10.1016/j.knosys.2023.110836.">this https URL</a> This version is typeset by the author and differs only in pagination and typographical detail
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Knowledge-Based Systems, 277, 110836, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12130" title="Abstract">arXiv:2301.12130</a> (replaced) [<a href="/pdf/2301.12130" title="Download PDF">pdf</a>, <a href="/format/2301.12130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained Policy Optimization with Explicit Behavior Density for  Offline Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+B">Bing-Yi Jing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12515" title="Abstract">arXiv:2301.12515</a> (replaced) [<a href="/pdf/2301.12515" title="Download PDF">pdf</a>, <a href="/format/2301.12515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiDAR-CS Dataset: LiDAR Point Cloud Dataset with Cross-Sensors for 3D  Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Dingfu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jingjing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chulin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Cheng-Zhong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liangjun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13413" title="Abstract">arXiv:2301.13413</a> (replaced) [<a href="/pdf/2301.13413" title="Download PDF">pdf</a>, <a href="/format/2301.13413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine Robotic Manipulation without Force/Torque Sensor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shan%2C+S">Shilin Shan</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+Q">Quang-Cuong Pham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Robotics and Automation Letters (RA-L), 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02803" title="Abstract">arXiv:2302.02803</a> (replaced) [<a href="/pdf/2302.02803" title="Download PDF">pdf</a>, <a href="/format/2302.02803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Never Skip Leg Day Again: Training the Lower Body with Vertical Jumps in  a Virtual Reality Exergame
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cmentowski%2C+S">Sebastian Cmentowski</a>, 
<a href="/search/cs?searchtype=author&query=Karaosmanoglu%2C+S">Sukran Karaosmanoglu</a>, 
<a href="/search/cs?searchtype=author&query=Nacke%2C+L">Lennart Nacke</a>, 
<a href="/search/cs?searchtype=author&query=Steinicke%2C+F">Frank Steinicke</a>, 
<a href="/search/cs?searchtype=author&query=Kr%C3%BCger%2C+J">Jens Kr&#xfc;ger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10244" title="Abstract">arXiv:2302.10244</a> (replaced) [<a href="/pdf/2302.10244" title="Download PDF">pdf</a>, <a href="/format/2302.10244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Basic quantum subroutines: finding multiple marked elements and summing  numbers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=van+Apeldoorn%2C+J">Joran van Apeldoorn</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gribling%2C+S">Sander Gribling</a>, 
<a href="/search/quant-ph?searchtype=author&query=Nieuwboer%2C+H">Harold Nieuwboer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, accepted in Quantum
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13056" title="Abstract">arXiv:2302.13056</a> (replaced) [<a href="/pdf/2302.13056" title="Download PDF">pdf</a>, <a href="/format/2302.13056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SATBA: An Invisible Backdoor Attack Based On Spatial Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Huasong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaowei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaodong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bullock%2C+L+B">Leon Bevan Bullock</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05620" title="Abstract">arXiv:2303.05620</a> (replaced) [<a href="/pdf/2303.05620" title="Download PDF">pdf</a>, <a href="/format/2303.05620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CFR-ICL: Cascade-Forward Refinement with Iterative Click Loss for  Interactive Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shoukun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+M">Min Xian</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Fei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Capriotti%2C+L">Luca Capriotti</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+T">Tiankai Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07902" title="Abstract">arXiv:2303.07902</a> (replaced) [<a href="/pdf/2303.07902" title="Download PDF">pdf</a>, <a href="/format/2303.07902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BLAT: Bootstrapping Language-Audio Pre-training based on AudioSet  Tag-guided Synthetic Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xuenan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiling Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zelin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pingyue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zeyu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Mengyue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K+Q">Kenny Q. Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12654" title="Abstract">arXiv:2303.12654</a> (replaced) [<a href="/pdf/2303.12654" title="Download PDF">pdf</a>, <a href="/format/2303.12654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Informational Rescaling of PCA Maps with Application to Genetic Distance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taleb%2C+N+N">Nassim Nicholas Taleb</a>, 
<a href="/search/cs?searchtype=author&query=Zalloua%2C+P">Pierre Zalloua</a>, 
<a href="/search/cs?searchtype=author&query=Elbassioni%2C+K">Khaled Elbassioni</a>, 
<a href="/search/cs?searchtype=author&query=Henschel%2C+A">Andreas Henschel</a>, 
<a href="/search/cs?searchtype=author&query=Platt%2C+D+E">Daniel E. Platt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Populations and Evolution (q-bio.PE)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15734" title="Abstract">arXiv:2303.15734</a> (replaced) [<a href="/pdf/2303.15734" title="Download PDF">pdf</a>, <a href="/format/2303.15734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Background Music for a Fighting Game: A Multi-Instrument Volume  Modulation Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+I">Ibrahim Khan</a>, 
<a href="/search/cs?searchtype=author&query=Van+Nguyen%2C+T">Thai Van Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nimpattanavong%2C+C">Chollakorn Nimpattanavong</a>, 
<a href="/search/cs?searchtype=author&query=Thawonmas%2C+R">Ruck Thawonmas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In the updated version, the description of the association between the distance between the two players (PD) and the instrument's volume on page 3 has been revised
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16618" title="Abstract">arXiv:2303.16618</a> (replaced) [<a href="/pdf/2303.16618" title="Download PDF">pdf</a>, <a href="/format/2303.16618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reference-less Analysis of Context Specificity in Translation with  Personalised Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vincent%2C+S">Sebastian Vincent</a>, 
<a href="/search/cs?searchtype=author&query=Dowek%2C+A">Alice Dowek</a>, 
<a href="/search/cs?searchtype=author&query=Sumner%2C+R">Rowanne Sumner</a>, 
<a href="/search/cs?searchtype=author&query=Blundell%2C+C">Charlotte Blundell</a>, 
<a href="/search/cs?searchtype=author&query=Preston%2C+E">Emily Preston</a>, 
<a href="/search/cs?searchtype=author&query=Bayliss%2C+C">Chris Bayliss</a>, 
<a href="/search/cs?searchtype=author&query=Oakley%2C+C">Chris Oakley</a>, 
<a href="/search/cs?searchtype=author&query=Scarton%2C+C">Carolina Scarton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00346" title="Abstract">arXiv:2304.00346</a> (replaced) [<a href="/pdf/2304.00346" title="Download PDF">pdf</a>, <a href="/ps/2304.00346" title="Download PostScript">ps</a>, <a href="/format/2304.00346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergent iLQR for Safe Trajectory Planning and Control of Legged  Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">James Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Payne%2C+J+J">J. Joe Payne</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+A+M">Aaron M. Johnson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04497" title="Abstract">arXiv:2304.04497</a> (replaced) [<a href="/pdf/2304.04497" title="Download PDF">pdf</a>, <a href="/format/2304.04497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Framework for Exploratory Learning-Aided Community Detection  Under Topological Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yu Hou</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+C">Cong Tran</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+W">Won-Yong Shin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 9 figures, 6 tables; its conference version was presented at the ACM International Conference on Information and Knowledge Management (CIKM 2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07143" title="Abstract">arXiv:2304.07143</a> (replaced) [<a href="/pdf/2304.07143" title="Download PDF">pdf</a>, <a href="/format/2304.07143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Car-Following Models: A Multidisciplinary Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+T+T">Tianya Terry Zhang</a>, 
<a href="/search/eess?searchtype=author&query=D.%2C+P">Ph.D.</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+P+J">Peter J. Jin</a>, 
<a href="/search/eess?searchtype=author&query=D.%2C+P">Ph.D.</a>, 
<a href="/search/eess?searchtype=author&query=McQuade%2C+S+T">Sean T. McQuade</a>, 
<a href="/search/eess?searchtype=author&query=D.%2C+P">Ph.D.</a>, 
<a href="/search/eess?searchtype=author&query=Bayen%2C+A">Alexandre Bayen</a>, 
<a href="/search/eess?searchtype=author&query=D.%2C+P">Ph.D.</a>, 
<a href="/search/eess?searchtype=author&query=Piccoli%2C+B">Benedetto Piccoli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11860" title="Abstract">arXiv:2304.11860</a> (replaced) [<a href="/pdf/2304.11860" title="Download PDF">pdf</a>, <a href="/format/2304.11860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the lifting and reconstruction of nonlinear systems with multiple  invariant sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pan%2C+S">Shaowu Pan</a>, 
<a href="/search/math?searchtype=author&query=Duraisamy%2C+K">Karthik Duraisamy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12228" title="Abstract">arXiv:2304.12228</a> (replaced) [<a href="/pdf/2304.12228" title="Download PDF">pdf</a>, <a href="/format/2304.12228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Contrastive Learning Enhanced Heterogeneous Graph Neural  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Nian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+H">Hui Han</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chuan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by TKDE as a regular paper. arXiv admin note: substantial text overlap with <a href="/abs/2105.09111">arXiv:2105.09111</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12653" title="Abstract">arXiv:2304.12653</a> (replaced) [<a href="/pdf/2304.12653" title="Download PDF">pdf</a>, <a href="/format/2304.12653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partially Observable Mean Field Multi-Agent Reinforcement Learning Based  on Graph-Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Min Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guanjun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Ziyuan Zhou</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Drones 2023, 7(7), 476
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13119" title="Abstract">arXiv:2304.13119</a> (replaced) [<a href="/pdf/2304.13119" title="Download PDF">pdf</a>, <a href="/format/2304.13119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Application of Transformers for Nonlinear Channel Compensation in  Optical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamgini%2C+B+B">Behnam Behinaein Hamgini</a>, 
<a href="/search/cs?searchtype=author&query=Najafi%2C+H">Hossein Najafi</a>, 
<a href="/search/cs?searchtype=author&query=Bakhshali%2C+A">Ali Bakhshali</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhuhong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13269" title="Abstract">arXiv:2304.13269</a> (replaced) [<a href="/pdf/2304.13269" title="Download PDF">pdf</a>, <a href="/ps/2304.13269" title="Download PostScript">ps</a>, <a href="/format/2304.13269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Game-based Platforms for Artificial Intelligence Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chengpeng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yunlong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Haocheng Du</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jialin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03235" title="Abstract">arXiv:2305.03235</a> (replaced) [<a href="/pdf/2305.03235" title="Download PDF">pdf</a>, <a href="/ps/2305.03235" title="Download PostScript">ps</a>, <a href="/format/2305.03235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hardware in Loop Learning with Spin Stochastic Neurons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+A+N+M+N">A N M Nafiul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kezhou Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shukla%2C+A+K">Amit K. Shukla</a>, 
<a href="/search/cs?searchtype=author&query=Khanal%2C+P">Pravin Khanal</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bowei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei-Gang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+A">Abhronil Sengupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06176" title="Abstract">arXiv:2305.06176</a> (replaced) [<a href="/pdf/2305.06176" title="Download PDF">pdf</a>, <a href="/ps/2305.06176" title="Download PostScript">ps</a>, <a href="/format/2305.06176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-tuning Language Models with Generative Adversarial Reward Modelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z+Z">Zhang Ze Yu</a>, 
<a href="/search/cs?searchtype=author&query=Jaw%2C+L+J">Lau Jia Jaw</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+Z">Zhang Hui</a>, 
<a href="/search/cs?searchtype=author&query=Low%2C+B+K+H">Bryan Kian Hsiang Low</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 9 figures, 12 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08391" title="Abstract">arXiv:2305.08391</a> (replaced) [<a href="/pdf/2305.08391" title="Download PDF">pdf</a>, <a href="/format/2305.08391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncovering the Potential of ChatGPT for Discourse Analysis in Dialogue:  An Empirical Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yaxin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+F">Feng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peifeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haizhou Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by LREC-COLING'2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14342" title="Abstract">arXiv:2305.14342</a> (replaced) [<a href="/pdf/2305.14342" title="Download PDF">pdf</a>, <a href="/format/2305.14342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sophia: A Scalable Stochastic Second-order Optimizer for Language Model  Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Hall%2C+D">David Hall</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Percy Liang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tengyu Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14824" title="Abstract">arXiv:2305.14824</a> (replaced) [<a href="/pdf/2305.14824" title="Download PDF">pdf</a>, <a href="/format/2305.14824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Temporal Misalignment by Discarding Outdated Facts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M+J+Q">Michael J.Q. Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+E">Eunsol Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted into EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17519" title="Abstract">arXiv:2305.17519</a> (replaced) [<a href="/pdf/2305.17519" title="Download PDF">pdf</a>, <a href="/ps/2305.17519" title="Download PostScript">ps</a>, <a href="/format/2305.17519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Closure Certificates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murali%2C+V">Vishnu Murali</a>, 
<a href="/search/cs?searchtype=author&query=Trivedi%2C+A">Ashutosh Trivedi</a>, 
<a href="/search/cs?searchtype=author&query=Zamani%2C+M">Majid Zamani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures. To appear in 27th ACM International Conference on Hybrid Systems: Computation and Control Hong-Kong, 13-16 May 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18149" title="Abstract">arXiv:2305.18149</a> (replaced) [<a href="/pdf/2305.18149" title="Download PDF">pdf</a>, <a href="/format/2305.18149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiscale Positive-Unlabeled Detection of AI-Generated Texts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuchuan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hanting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xutao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Z">Zheyuan Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qinghua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruifeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhe Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR2024 (Spotlight)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19394" title="Abstract">arXiv:2305.19394</a> (replaced) [<a href="/pdf/2305.19394" title="Download PDF">pdf</a>, <a href="/format/2305.19394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synaptic Weight Distributions Depend on the Geometry of Plasticity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Pogodin%2C+R">Roman Pogodin</a>, 
<a href="/search/q-bio?searchtype=author&query=Cornford%2C+J">Jonathan Cornford</a>, 
<a href="/search/q-bio?searchtype=author&query=Ghosh%2C+A">Arna Ghosh</a>, 
<a href="/search/q-bio?searchtype=author&query=Gidel%2C+G">Gauthier Gidel</a>, 
<a href="/search/q-bio?searchtype=author&query=Lajoie%2C+G">Guillaume Lajoie</a>, 
<a href="/search/q-bio?searchtype=author&query=Richards%2C+B">Blake Richards</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The Twelfth International Conference on Learning Representations,
  2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02775" title="Abstract">arXiv:2306.02775</a> (replaced) [<a href="/pdf/2306.02775" title="Download PDF">pdf</a>, <a href="/format/2306.02775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Input-gradient space particle inference for neural network ensembles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Trinh%2C+T">Trung Trinh</a>, 
<a href="/search/stat?searchtype=author&query=Heinonen%2C+M">Markus Heinonen</a>, 
<a href="/search/stat?searchtype=author&query=Acerbi%2C+L">Luigi Acerbi</a>, 
<a href="/search/stat?searchtype=author&query=Kaski%2C+S">Samuel Kaski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ICLR 2024 (spotlight presentation). Code is available at <a href="https://github.com/AaltoPML/FoRDE">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04735" title="Abstract">arXiv:2306.04735</a> (replaced) [<a href="/pdf/2306.04735" title="Download PDF">pdf</a>, <a href="/format/2306.04735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Soft-prompt Tuning for Large Language Models to Evaluate Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jacob-Junqi Tian</a>, 
<a href="/search/cs?searchtype=author&query=Emerson%2C+D">David Emerson</a>, 
<a href="/search/cs?searchtype=author&query=Miyandoab%2C+S+Z">Sevil Zanjani Miyandoab</a>, 
<a href="/search/cs?searchtype=author&query=Pandya%2C+D">Deval Pandya</a>, 
<a href="/search/cs?searchtype=author&query=Seyyed-Kalantari%2C+L">Laleh Seyyed-Kalantari</a>, 
<a href="/search/cs?searchtype=author&query=Khattak%2C+F+K">Faiza Khan Khattak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07948" title="Abstract">arXiv:2306.07948</a> (replaced) [<a href="/pdf/2306.07948" title="Download PDF">pdf</a>, <a href="/format/2306.07948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Inference in Contextual Stochastic Block Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duranthon%2C+O">O. Duranthon</a>, 
<a href="/search/cs?searchtype=author&query=Zdeborov%C3%A1%2C+L">L. Zdeborov&#xe1;</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> TMLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09281" title="Abstract">arXiv:2306.09281</a> (replaced) [<a href="/pdf/2306.09281" title="Download PDF">pdf</a>, <a href="/format/2306.09281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Motion Forecasting with Real-World Perception Inputs: Are  End-to-End Approaches Competitive?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yihong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chambon%2C+L">Lo&#xef;ck Chambon</a>, 
<a href="/search/cs?searchtype=author&query=Zablocki%2C+%C3%89">&#xc9;loi Zablocki</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Micka&#xeb;l Chen</a>, 
<a href="/search/cs?searchtype=author&query=Alahi%2C+A">Alexandre Alahi</a>, 
<a href="/search/cs?searchtype=author&query=Cord%2C+M">Matthieu Cord</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+P">Patrick P&#xe9;rez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09305" title="Abstract">arXiv:2306.09305</a> (replaced) [<a href="/pdf/2306.09305" title="Download PDF">pdf</a>, <a href="/format/2306.09305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Training of Diffusion Models with Masked Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hongkai Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+W">Weili Nie</a>, 
<a href="/search/cs?searchtype=author&query=Vahdat%2C+A">Arash Vahdat</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11034" title="Abstract">arXiv:2306.11034</a> (replaced) [<a href="/pdf/2306.11034" title="Download PDF">pdf</a>, <a href="/ps/2306.11034" title="Download PostScript">ps</a>, <a href="/format/2306.11034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning-based sound speed estimation and aberration correction in  linear-array photoacoustic imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shi%2C+M">Mengjie Shi</a>, 
<a href="/search/eess?searchtype=author&query=Vercauteren%2C+T">Tom Vercauteren</a>, 
<a href="/search/eess?searchtype=author&query=Xia%2C+W">Wenfeng Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11677" title="Abstract">arXiv:2306.11677</a> (replaced) [<a href="/pdf/2306.11677" title="Download PDF">pdf</a>, <a href="/format/2306.11677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseudorandom unitaries are neither real nor sparse nor noise-robust
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Haug%2C+T">Tobias Haug</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bharti%2C+K">Kishor Bharti</a>, 
<a href="/search/quant-ph?searchtype=author&query=Koh%2C+D+E">Dax Enshan Koh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11980" title="Abstract">arXiv:2306.11980</a> (replaced) [<a href="/pdf/2306.11980" title="Download PDF">pdf</a>, <a href="/format/2306.11980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-based Smart Reply (LSR): Enhancing Collaborative Performance with  ChatGPT-mediated Smart Reply System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bastola%2C+A">Ashish Bastola</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hembree%2C+J">Judsen Hembree</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+P">Pooja Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Z">Zihao Gong</a>, 
<a href="/search/cs?searchtype=author&query=Dixon%2C+E">Emma Dixon</a>, 
<a href="/search/cs?searchtype=author&query=Razi%2C+A">Abolfazl Razi</a>, 
<a href="/search/cs?searchtype=author&query=McNeese%2C+N">Nathan McNeese</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12105" title="Abstract">arXiv:2306.12105</a> (replaced) [<a href="/pdf/2306.12105" title="Download PDF">pdf</a>, <a href="/format/2306.12105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mass-Producing Failures of Multimodal Systems with Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tong%2C+S">Shengbang Tong</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+E">Erik Jones</a>, 
<a href="/search/cs?searchtype=author&query=Steinhardt%2C+J">Jacob Steinhardt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12217" title="Abstract">arXiv:2306.12217</a> (replaced) [<a href="/pdf/2306.12217" title="Download PDF">pdf</a>, <a href="/ps/2306.12217" title="Download PostScript">ps</a>, <a href="/format/2306.12217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lumbar spine segmentation in MR images: a dataset and a public benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=van+der+Graaf%2C+J+W">Jasper W. van der Graaf</a>, 
<a href="/search/eess?searchtype=author&query=van+Hooff%2C+M+L">Miranda L. van Hooff</a>, 
<a href="/search/eess?searchtype=author&query=Buckens%2C+C+F+M">Constantinus F. M. Buckens</a>, 
<a href="/search/eess?searchtype=author&query=Rutten%2C+M">Matthieu Rutten</a>, 
<a href="/search/eess?searchtype=author&query=van+Susante%2C+J+L+C">Job L. C. van Susante</a>, 
<a href="/search/eess?searchtype=author&query=Kroeze%2C+R+J">Robert Jan Kroeze</a>, 
<a href="/search/eess?searchtype=author&query=de+Kleuver%2C+M">Marinus de Kleuver</a>, 
<a href="/search/eess?searchtype=author&query=van+Ginneken%2C+B">Bram van Ginneken</a>, 
<a href="/search/eess?searchtype=author&query=Lessmann%2C+N">Nikolas Lessmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Scientific Data
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Scientific Data 11.1 (2024): 264
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12497" title="Abstract">arXiv:2306.12497</a> (replaced) [<a href="/pdf/2306.12497" title="Download PDF">pdf</a>, <a href="/format/2306.12497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Density Uncertainty Layers for Reliable Uncertainty Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+Y">Yookoon Park</a>, 
<a href="/search/cs?searchtype=author&query=Blei%2C+D+M">David M. Blei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16504" title="Abstract">arXiv:2306.16504</a> (replaced) [<a href="/pdf/2306.16504" title="Download PDF">pdf</a>, <a href="/format/2306.16504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Momentum Benefits Non-IID Federated Learning Simply and Provably
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Ziheng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xinmeng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Pengfei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+K">Kun Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17256" title="Abstract">arXiv:2306.17256</a> (replaced) [<a href="/pdf/2306.17256" title="Download PDF">pdf</a>, <a href="/format/2306.17256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Could Small Language Models Serve as Recommenders? Towards Data-centric  Cold-start Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xuansheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Huachi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yucheng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Wenlin Yao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ninghao Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06924" title="Abstract">arXiv:2307.06924</a> (replaced) [<a href="/pdf/2307.06924" title="Download PDF">pdf</a>, <a href="/format/2307.06924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DRAGON: A Dialogue-Based Robot for Assistive Navigation with Visual  Language Grounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuijing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+A">Aamir Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+K">Kaiwen Hong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Runxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+P">Peixin Chang</a>, 
<a href="/search/cs?searchtype=author&query=Mizrachi%2C+Z">Zachary Mizrachi</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Justin Lin</a>, 
<a href="/search/cs?searchtype=author&query=McPherson%2C+D+L">D. Livingston McPherson</a>, 
<a href="/search/cs?searchtype=author&query=Rogers%2C+W+A">Wendy A. Rogers</a>, 
<a href="/search/cs?searchtype=author&query=Driggs-Campbell%2C+K">Katherine Driggs-Campbell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in IEEE Robotics and Automation Letters (RA-L)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07314" title="Abstract">arXiv:2307.07314</a> (replaced) [<a href="/pdf/2307.07314" title="Download PDF">pdf</a>, <a href="/format/2307.07314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact Bayesian Inference for Loopy Probabilistic Programs using  Generating Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klinkenberg%2C+L">Lutz Klinkenberg</a>, 
<a href="/search/cs?searchtype=author&query=Blumenthal%2C+C">Christian Blumenthal</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingshuai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Haase%2C+D">Darion Haase</a>, 
<a href="/search/cs?searchtype=author&query=Katoen%2C+J">Joost-Pieter Katoen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11333" title="Abstract">arXiv:2307.11333</a> (replaced) [<a href="/pdf/2307.11333" title="Download PDF">pdf</a>, <a href="/format/2307.11333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demystifying Local and Global Fairness Trade-offs in Federated Learning  Using Partial Information Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamman%2C+F">Faisal Hamman</a>, 
<a href="/search/cs?searchtype=author&query=Dutta%2C+S">Sanghamitra Dutta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at the International Conference on Learning Representations (ICLR) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12754" title="Abstract">arXiv:2307.12754</a> (replaced) [<a href="/pdf/2307.12754" title="Download PDF">pdf</a>, <a href="/format/2307.12754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonparametric Linear Feature Learning in Regression Through  Regularisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Follain%2C+B">Bertille Follain</a>, 
<a href="/search/stat?searchtype=author&query=Bach%2C+F">Francis Bach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13991" title="Abstract">arXiv:2307.13991</a> (replaced) [<a href="/pdf/2307.13991" title="Download PDF">pdf</a>, <a href="/format/2307.13991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> METAVerse: Meta-Learning Traversability Cost Map for Off-Road Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">Junwon Seo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taekyung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+S">Seongyong Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Kwak%2C+K">Kiho Kwak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our video can be found at <a href="https://youtu.be/4rIAMM1ZKMo">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14036" title="Abstract">arXiv:2307.14036</a> (replaced) [<a href="/pdf/2307.14036" title="Download PDF">pdf</a>, <a href="/format/2307.14036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hydra Battles and AC Termination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hirokawa%2C+N">Nao Hirokawa</a>, 
<a href="/search/cs?searchtype=author&query=Middeldorp%2C+A">Aart Middeldorp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 1 figure, submitted to LMCS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14940" title="Abstract">arXiv:2307.14940</a> (replaced) [<a href="/pdf/2307.14940" title="Download PDF">pdf</a>, <a href="/format/2307.14940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Self-Adaptive Penalty Method for Integrating Prior Knowledge  Constraints into Neural ODEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coelho%2C+C">C. Coelho</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+M+F+P">M. Fernanda P. Costa</a>, 
<a href="/search/cs?searchtype=author&query=Ferr%C3%A1s%2C+L+L">L. L. Ferr&#xe1;s</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16807" title="Abstract">arXiv:2307.16807</a> (replaced) [<a href="/pdf/2307.16807" title="Download PDF">pdf</a>, <a href="/format/2307.16807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the use of associative memory in Hopfield networks designed to solve  propositional satisfiability problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/nlin?searchtype=author&query=Weber%2C+N">Natalya Weber</a>, 
<a href="/search/nlin?searchtype=author&query=Koch%2C+W">Werner Koch</a>, 
<a href="/search/nlin?searchtype=author&query=Erdem%2C+O">Ozan Erdem</a>, 
<a href="/search/nlin?searchtype=author&query=Froese%2C+T">Tom Froese</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE Symposium Series on Computational Intelligence (SSCI)
  1352-1358
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Adaptation and Self-Organizing Systems (nlin.AO)</span>; Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00846" title="Abstract">arXiv:2308.00846</a> (replaced) [<a href="/pdf/2308.00846" title="Download PDF">pdf</a>, <a href="/format/2308.00846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pathfinding Future PIM Architectures by Demystifying a Commercial PIM  Technology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hyun%2C+B">Bongjoon Hyun</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taehun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongjae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Rhu%2C+M">Minsoo Rhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at the 30th IEEE International Symposium on High-Performance Computer Architecture (HPCA-30), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01264" title="Abstract">arXiv:2308.01264</a> (replaced) [<a href="/pdf/2308.01264" title="Download PDF">pdf</a>, <a href="/ps/2308.01264" title="Download PostScript">ps</a>, <a href="/format/2308.01264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the psychology of LLMs&#x27; Moral and Legal Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almeida%2C+G+F+C+F">Guilherme F. C. F. Almeida</a>, 
<a href="/search/cs?searchtype=author&query=Nunes%2C+J+L">Jos&#xe9; Luiz Nunes</a>, 
<a href="/search/cs?searchtype=author&query=Engelmann%2C+N">Neele Engelmann</a>, 
<a href="/search/cs?searchtype=author&query=Wiegmann%2C+A">Alex Wiegmann</a>, 
<a href="/search/cs?searchtype=author&query=de+Ara%C3%BAjo%2C+M">Marcelo de Ara&#xfa;jo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06354" title="Abstract">arXiv:2308.06354</a> (replaced) [<a href="/pdf/2308.06354" title="Download PDF">pdf</a>, <a href="/ps/2308.06354" title="Download PostScript">ps</a>, <a href="/format/2308.06354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models to Identify Social Determinants of Health in  Electronic Health Records
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guevara%2C+M">Marco Guevara</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+S">Spencer Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Chaunzwa%2C+T+L">Tafadzwa L. Chaunzwa</a>, 
<a href="/search/cs?searchtype=author&query=Franco%2C+I">Idalid Franco</a>, 
<a href="/search/cs?searchtype=author&query=Kann%2C+B">Benjamin Kann</a>, 
<a href="/search/cs?searchtype=author&query=Moningi%2C+S">Shalini Moningi</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+J">Jack Qian</a>, 
<a href="/search/cs?searchtype=author&query=Goldstein%2C+M">Madeleine Goldstein</a>, 
<a href="/search/cs?searchtype=author&query=Harper%2C+S">Susan Harper</a>, 
<a href="/search/cs?searchtype=author&query=Aerts%2C+H+J">Hugo JWL Aerts</a>, 
<a href="/search/cs?searchtype=author&query=Savova%2C+G+K">Guergana K. Savova</a>, 
<a href="/search/cs?searchtype=author&query=Mak%2C+R+H">Raymond H. Mak</a>, 
<a href="/search/cs?searchtype=author&query=Bitterman%2C+D+S">Danielle S. Bitterman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Peer-reviewed version published at NPJ Digital Medicine: <a href="https://www.nature.com/articles/s41746-023-00970-0">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NPJ Digit Med. 2024 Jan 11;7(1):6
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07061" title="Abstract">arXiv:2308.07061</a> (replaced) [<a href="/pdf/2308.07061" title="Download PDF">pdf</a>, <a href="/format/2308.07061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Unlearning: Solutions and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zihan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiaohua Jia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09766" title="Abstract">arXiv:2308.09766</a> (replaced) [<a href="/pdf/2308.09766" title="Download PDF">pdf</a>, <a href="/format/2308.09766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time Series Predictions in Unmonitored Sites: A Survey of Machine  Learning Techniques in Water Resources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Willard%2C+J+D">Jared D. Willard</a>, 
<a href="/search/cs?searchtype=author&query=Varadharajan%2C+C">Charuleka Varadharajan</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiaowei Jia</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vipin Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 4 figures, 1 table, submitted to Environmental Data Science
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10664" title="Abstract">arXiv:2308.10664</a> (replaced) [<a href="/pdf/2308.10664" title="Download PDF">pdf</a>, <a href="/format/2308.10664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Safe Deep Reinforcement Learning Approach for Energy Efficient  Federated Learning in Wireless Communication Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koursioumpas%2C+N">Nikolaos Koursioumpas</a>, 
<a href="/search/cs?searchtype=author&query=Magoula%2C+L">Lina Magoula</a>, 
<a href="/search/cs?searchtype=author&query=Petropouleas%2C+N">Nikolaos Petropouleas</a>, 
<a href="/search/cs?searchtype=author&query=Thanopoulos%2C+A">Alexandros-Ioannis Thanopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Panagea%2C+T">Theodora Panagea</a>, 
<a href="/search/cs?searchtype=author&query=Alonistioti%2C+N">Nancy Alonistioti</a>, 
<a href="/search/cs?searchtype=author&query=Gutierrez-Estevez%2C+M+A">M. A. Gutierrez-Estevez</a>, 
<a href="/search/cs?searchtype=author&query=Khalili%2C+R">Ramin Khalili</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 Pages Double Column, 6 Figures, Accepted for publication in the IEEE Transactions on Green Communications and Networking (TGCN). arXiv admin note: text overlap with <a href="/abs/2306.14237">arXiv:2306.14237</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13249" title="Abstract">arXiv:2308.13249</a> (replaced) [<a href="/pdf/2308.13249" title="Download PDF">pdf</a>, <a href="/format/2308.13249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning and Optimization of Implicit Negative Feedback for Industrial  Short-video Recommender System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yunzhu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Nian Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+J">Jianxin Chang</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yanan Niu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yang Song</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+D">Depeng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CIKM'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15465" title="Abstract">arXiv:2308.15465</a> (replaced) [<a href="/pdf/2308.15465" title="Download PDF">pdf</a>, <a href="/format/2308.15465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sharing proofs with predicative theories through universe polymorphic  elaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Felicissimo%2C+T">Thiago Felicissimo</a>, 
<a href="/search/cs?searchtype=author&query=Blanqui%2C+F">Fr&#xe9;d&#xe9;ric Blanqui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Journal version of <a href="https://doi.org/10.4230/LIPIcs.CSL.2023.19">this https URL</a> to be submitted to LMCS, also supersedes <a href="/abs/2211.05700">arXiv:2211.05700</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16910" title="Abstract">arXiv:2308.16910</a> (replaced) [<a href="/pdf/2308.16910" title="Download PDF">pdf</a>, <a href="/format/2308.16910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Variational Physics-Informed Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Rojas%2C+S">Sergio Rojas</a>, 
<a href="/search/math?searchtype=author&query=Maczuga%2C+P">Pawe&#x142; Maczuga</a>, 
<a href="/search/math?searchtype=author&query=Mu%C3%B1oz-Matute%2C+J">Judit Mu&#xf1;oz-Matute</a>, 
<a href="/search/math?searchtype=author&query=Pardo%2C+D">David Pardo</a>, 
<a href="/search/math?searchtype=author&query=Paszynski%2C+M">Maciej Paszynski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04386" title="Abstract">arXiv:2309.04386</a> (replaced) [<a href="/pdf/2309.04386" title="Download PDF">pdf</a>, <a href="/format/2309.04386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ARRTOC: Adversarially Robust Real-Time Optimization and Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ahmed%2C+A">Akhil Ahmed</a>, 
<a href="/search/eess?searchtype=author&query=del+Rio-Chanona%2C+E+A">Ehecatl Antonio del Rio-Chanona</a>, 
<a href="/search/eess?searchtype=author&query=Mercangoz%2C+M">Mehmet Mercangoz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04766" title="Abstract">arXiv:2309.04766</a> (replaced) [<a href="/pdf/2309.04766" title="Download PDF">pdf</a>, <a href="/format/2309.04766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment  to Cultural Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+F">Fangkai Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Aw%2C+A+T">Ai Ti Aw</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N+F">Nancy F. Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages. More datasets (2 on Cross-Lingual Consistency and 4 on Cultural Understanding) and more supported languages. Code: <a href="https://seaeval.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05035" title="Abstract">arXiv:2309.05035</a> (replaced) [<a href="/pdf/2309.05035" title="Download PDF">pdf</a>, <a href="/format/2309.05035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Duplicate Question Retrieval and Confirmation Time Prediction in  Software Communities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hazra%2C+R">Rima Hazra</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+D">Debanjan Saha</a>, 
<a href="/search/cs?searchtype=author&query=Sahoo%2C+A">Amruit Sahoo</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Somnath Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+A">Animesh Mukherjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full paper accepted at ASONAM 2023: The 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Software Engineering (cs.SE); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05203" title="Abstract">arXiv:2309.05203</a> (replaced) [<a href="/pdf/2309.05203" title="Download PDF">pdf</a>, <a href="/format/2309.05203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Artificially Real to Real: Leveraging Pseudo Data from Large  Language Models for Low-Resource Molecule Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+N">Nuwa Xi</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yanrui Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haochun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sendong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Bing Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07964" title="Abstract">arXiv:2309.07964</a> (replaced) [<a href="/pdf/2309.07964" title="Download PDF">pdf</a>, <a href="/format/2309.07964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Shortest Path Restoration Lemmas for Multiple Edge Failures:  Trade-offs Between Fault-tolerance and Subpaths
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bodwin%2C+G">Greg Bodwin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lily Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08322" title="Abstract">arXiv:2309.08322</a> (replaced) [<a href="/pdf/2309.08322" title="Download PDF">pdf</a>, <a href="/format/2309.08322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-bounded Active Monitoring of Unknown Dynamic Targets in  Road-networks with Minimum Fleet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuaikang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kantaros%2C+Y">Yiannis Kantaros</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Meng Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08849" title="Abstract">arXiv:2309.08849</a> (replaced) [<a href="/pdf/2309.08849" title="Download PDF">pdf</a>, <a href="/ps/2309.08849" title="Download PostScript">ps</a>, <a href="/format/2309.08849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning a Stable Dynamic System with a Lyapunov Energy Function for  Demonstratives Using Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Y">Yongxiang Zou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xiuze Xia</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Long Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10331" title="Abstract">arXiv:2309.10331</a> (replaced) [<a href="/pdf/2309.10331" title="Download PDF">pdf</a>, <a href="/format/2309.10331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hardness results for decoding the surface code with Pauli noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Fischer%2C+A">Alex Fischer</a>, 
<a href="/search/quant-ph?searchtype=author&query=Miyake%2C+A">Akimasa Miyake</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 21 figures. 29 pages, 13 figures in main text. This version includes minor improvements to explanations, more standardized terminology, and minor extensions of the results in Appendices C and D
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10402" title="Abstract">arXiv:2309.10402</a> (replaced) [<a href="/pdf/2309.10402" title="Download PDF">pdf</a>, <a href="/format/2309.10402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimum width for universal approximation using ReLU networks on compact  domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+N">Namjun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+C">Chanho Min</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sejun Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13944" title="Abstract">arXiv:2309.13944</a> (replaced) [<a href="/pdf/2309.13944" title="Download PDF">pdf</a>, <a href="/format/2309.13944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provable Training for Graph Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengmei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Nian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chuan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 spotlight. Camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13948" title="Abstract">arXiv:2309.13948</a> (replaced) [<a href="/pdf/2309.13948" title="Download PDF">pdf</a>, <a href="/format/2309.13948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Co-Design Optimisation of Morphing Topology and Control of Winged Drones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bergonti%2C+F">Fabio Bergonti</a>, 
<a href="/search/cs?searchtype=author&query=Nava%2C+G">Gabriele Nava</a>, 
<a href="/search/cs?searchtype=author&query=W%C3%BCest%2C+V">Valentin W&#xfc;est</a>, 
<a href="/search/cs?searchtype=author&query=Paolino%2C+A">Antonello Paolino</a>, 
<a href="/search/cs?searchtype=author&query=L%27Erario%2C+G">Giuseppe L&#x27;Erario</a>, 
<a href="/search/cs?searchtype=author&query=Pucci%2C+D">Daniele Pucci</a>, 
<a href="/search/cs?searchtype=author&query=Floreano%2C+D">Dario Floreano</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2024 International Conference on Robotics and Automation (ICRA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14178" title="Abstract">arXiv:2309.14178</a> (replaced) [<a href="/pdf/2309.14178" title="Download PDF">pdf</a>, <a href="/format/2309.14178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chebyshev HOPGD with sparse grid sampling for parameterized linear  systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Correnty%2C+S">Siobh&#xe1;n Correnty</a>, 
<a href="/search/math?searchtype=author&query=Freitag%2C+M+A">Melina A. Freitag</a>, 
<a href="/search/math?searchtype=author&query=Soodhalter%2C+K+M">Kirk M. Soodhalter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14225" title="Abstract">arXiv:2309.14225</a> (replaced) [<a href="/pdf/2309.14225" title="Download PDF">pdf</a>, <a href="/format/2309.14225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HumanMimic: Learning Natural Locomotion and Transitions for Humanoid  Robot via Wasserstein Adversarial Imitation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+A">Annan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Hiraoka%2C+T">Takuma Hiraoka</a>, 
<a href="/search/cs?searchtype=author&query=Hiraoka%2C+N">Naoki Hiraoka</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+F">Fan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Kawaharazuka%2C+K">Kento Kawaharazuka</a>, 
<a href="/search/cs?searchtype=author&query=Kojima%2C+K">Kunio Kojima</a>, 
<a href="/search/cs?searchtype=author&query=Okada%2C+K">Kei Okada</a>, 
<a href="/search/cs?searchtype=author&query=Inaba%2C+M">Masayuki Inaba</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14737" title="Abstract">arXiv:2309.14737</a> (replaced) [<a href="/pdf/2309.14737" title="Download PDF">pdf</a>, <a href="/format/2309.14737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Volumetric Semantically Consistent 3D Panoptic Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miao%2C+Y">Yang Miao</a>, 
<a href="/search/cs?searchtype=author&query=Armeni%2C+I">Iro Armeni</a>, 
<a href="/search/cs?searchtype=author&query=Pollefeys%2C+M">Marc Pollefeys</a>, 
<a href="/search/cs?searchtype=author&query=Barath%2C+D">Daniel Barath</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15065" title="Abstract">arXiv:2309.15065</a> (replaced) [<a href="/pdf/2309.15065" title="Download PDF">pdf</a>, <a href="/format/2309.15065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language-EXtended Indoor SLAM (LEXIS): A Versatile System for Real-time  Visual Scene Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kassab%2C+C">Christina Kassab</a>, 
<a href="/search/cs?searchtype=author&query=Mattamala%2C+M">Matias Mattamala</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lintong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fallon%2C+M">Maurice Fallon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16445" title="Abstract">arXiv:2309.16445</a> (replaced) [<a href="/pdf/2309.16445" title="Download PDF">pdf</a>, <a href="/format/2309.16445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> db-CBS: Discontinuity-Bounded Conflict-Based Search for Multi-Robot  Kinodynamic Motion Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moldagalieva%2C+A">Akmaral Moldagalieva</a>, 
<a href="/search/cs?searchtype=author&query=Ortiz-Haro%2C+J">Joaquim Ortiz-Haro</a>, 
<a href="/search/cs?searchtype=author&query=Toussaint%2C+M">Marc Toussaint</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B6nig%2C+W">Wolfgang H&#xf6;nig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16487" title="Abstract">arXiv:2309.16487</a> (replaced) [<a href="/pdf/2309.16487" title="Download PDF">pdf</a>, <a href="/format/2309.16487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Poisoning Fair Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianci Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Feijie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hengtong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pan Li</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+L">Lu Su</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jing Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00194" title="Abstract">arXiv:2310.00194</a> (replaced) [<a href="/pdf/2310.00194" title="Download PDF">pdf</a>, <a href="/format/2310.00194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Prefrontal Cortex-inspired Architecture for Planning in Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Webb%2C+T">Taylor Webb</a>, 
<a href="/search/cs?searchtype=author&query=Mondal%2C+S+S">Shanka Subhra Mondal</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Krabach%2C+B">Brian Krabach</a>, 
<a href="/search/cs?searchtype=author&query=Momennejad%2C+I">Ida Momennejad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00648" title="Abstract">arXiv:2310.00648</a> (replaced) [<a href="/pdf/2310.00648" title="Download PDF">pdf</a>, <a href="/format/2310.00648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PETA: Parameter-Efficient Trojan Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Lauren Hong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Ting Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01690" title="Abstract">arXiv:2310.01690</a> (replaced) [<a href="/pdf/2310.01690" title="Download PDF">pdf</a>, <a href="/format/2310.01690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forecasting Tropical Cyclones with Cascaded Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Nath%2C+P">Pritthijit Nath</a>, 
<a href="/search/physics?searchtype=author&query=Shukla%2C+P">Pancham Shukla</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/physics?searchtype=author&query=Quilodr%C3%A1n-Casas%2C+C">C&#xe9;sar Quilodr&#xe1;n-Casas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for poster presentation at the ICLR 2024 workshop on Tackling Climate Change with Machine Learning. 7 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02424" title="Abstract">arXiv:2310.02424</a> (replaced) [<a href="/pdf/2310.02424" title="Download PDF">pdf</a>, <a href="/format/2310.02424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AXNav: Replaying Accessibility Tests from Natural Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taeb%2C+M">Maryam Taeb</a>, 
<a href="/search/cs?searchtype=author&query=Swearngin%2C+A">Amanda Swearngin</a>, 
<a href="/search/cs?searchtype=author&query=Schoop%2C+E">Eldon Schoop</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+R">Ruijia Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yue Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Nichols%2C+J">Jeffrey Nichols</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted into Conference on Human Factors in Computing Systems (CHI) 2024, 22 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02791" title="Abstract">arXiv:2310.02791</a> (replaced) [<a href="/pdf/2310.02791" title="Download PDF">pdf</a>, <a href="/format/2310.02791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> R-LGP: A Reachability-guided Logic-geometric Programming Framework for  Optimal Task and Motion Planning on Mobile Manipulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ly%2C+K+T">Kim Tien Ly</a>, 
<a href="/search/cs?searchtype=author&query=Semenov%2C+V">Valeriy Semenov</a>, 
<a href="/search/cs?searchtype=author&query=Risiglione%2C+M">Mattia Risiglione</a>, 
<a href="/search/cs?searchtype=author&query=Merkt%2C+W">Wolfgang Merkt</a>, 
<a href="/search/cs?searchtype=author&query=Havoutis%2C+I">Ioannis Havoutis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04295" title="Abstract">arXiv:2310.04295</a> (replaced) [<a href="/pdf/2310.04295" title="Download PDF">pdf</a>, <a href="/format/2310.04295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Representations for Intervention Extrapolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saengkyongam%2C+S">Sorawit Saengkyongam</a>, 
<a href="/search/cs?searchtype=author&query=Rosenfeld%2C+E">Elan Rosenfeld</a>, 
<a href="/search/cs?searchtype=author&query=Ravikumar%2C+P">Pradeep Ravikumar</a>, 
<a href="/search/cs?searchtype=author&query=Pfister%2C+N">Niklas Pfister</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jonas Peters</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the International Conference on Learning Representations (ICLR) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08047" title="Abstract">arXiv:2310.08047</a> (replaced) [<a href="/pdf/2310.08047" title="Download PDF">pdf</a>, <a href="/format/2310.08047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Three Paths to Rational Curves with Rational Arc Length
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schr%C3%B6cker%2C+H">Hans-Peter Schr&#xf6;cker</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0%C3%ACr%2C+Z">Zbyn&#x11b;k &#x160;&#xec;r</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Differential Geometry (math.DG); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08935" title="Abstract">arXiv:2310.08935</a> (replaced) [<a href="/pdf/2310.08935" title="Download PDF">pdf</a>, <a href="/ps/2310.08935" title="Download PostScript">ps</a>, <a href="/format/2310.08935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proof of a conjecture about Parrondo&#x27;s paradox for two-armed slot  machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liang%2C+H">Huaijin Liang</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+Z">Zengjing Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09527" title="Abstract">arXiv:2310.09527</a> (replaced) [<a href="/pdf/2310.09527" title="Download PDF">pdf</a>, <a href="/ps/2310.09527" title="Download PostScript">ps</a>, <a href="/format/2310.09527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A discontinuous plane wave neural network method for Helmholtz equation  and time-harmonic Maxwell&#x27;s equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yuan%2C+L">Long Yuan</a>, 
<a href="/search/math?searchtype=author&query=Hu%2C+Q">Qiya Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09793" title="Abstract">arXiv:2310.09793</a> (replaced) [<a href="/pdf/2310.09793" title="Download PDF">pdf</a>, <a href="/ps/2310.09793" title="Download PostScript">ps</a>, <a href="/format/2310.09793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Detection of Cat Facial Landmarks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martvel%2C+G">George Martvel</a>, 
<a href="/search/cs?searchtype=author&query=Shimshoni%2C+I">Ilan Shimshoni</a>, 
<a href="/search/cs?searchtype=author&query=Zamansky%2C+A">Anna Zamansky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2305.04232">arXiv:2305.04232</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Int J Comput Vis (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09847" title="Abstract">arXiv:2310.09847</a> (replaced) [<a href="/pdf/2310.09847" title="Download PDF">pdf</a>, <a href="/format/2310.09847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XRMDN: An Extended Recurrent Mixture Density Network for Short-Term  Probabilistic Rider Demand Forecasting with High Volatility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoming Li</a>, 
<a href="/search/cs?searchtype=author&query=Normandin-Taillon%2C+H">Hubert Normandin-Taillon</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 14 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10023" title="Abstract">arXiv:2310.10023</a> (replaced) [<a href="/pdf/2310.10023" title="Download PDF">pdf</a>, <a href="/format/2310.10023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D-BBS: Global Localization for 3D Point Cloud Scan Matching Using  Branch-and-Bound Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aoki%2C+K">Koki Aoki</a>, 
<a href="/search/cs?searchtype=author&query=Koide%2C+K">Kenji Koide</a>, 
<a href="/search/cs?searchtype=author&query=Oishi%2C+S">Shuji Oishi</a>, 
<a href="/search/cs?searchtype=author&query=Yokozuka%2C+M">Masashi Yokozuka</a>, 
<a href="/search/cs?searchtype=author&query=Banno%2C+A">Atsuhiko Banno</a>, 
<a href="/search/cs?searchtype=author&query=Meguro%2C+J">Junichi Meguro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE International Conference on Robotics and Automation (ICRA2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10096" title="Abstract">arXiv:2310.10096</a> (replaced) [<a href="/pdf/2310.10096" title="Download PDF">pdf</a>, <a href="/format/2310.10096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLP-Bench: A Large Scale Tabular Benchmark for Learning from Label  Proportions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brahmbhatt%2C+A">Anand Brahmbhatt</a>, 
<a href="/search/cs?searchtype=author&query=Pokala%2C+M">Mohith Pokala</a>, 
<a href="/search/cs?searchtype=author&query=Saket%2C+R">Rishi Saket</a>, 
<a href="/search/cs?searchtype=author&query=Raghuveer%2C+A">Aravindan Raghuveer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11230" title="Abstract">arXiv:2310.11230</a> (replaced) [<a href="/pdf/2310.11230" title="Download PDF">pdf</a>, <a href="/format/2310.11230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zipformer: A faster and better encoder for automatic speech recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yao%2C+Z">Zengwei Yao</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+L">Liyong Guo</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+X">Xiaoyu Yang</a>, 
<a href="/search/eess?searchtype=author&query=Kang%2C+W">Wei Kang</a>, 
<a href="/search/eess?searchtype=author&query=Kuang%2C+F">Fangjun Kuang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Y">Yifan Yang</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+Z">Zengrui Jin</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+L">Long Lin</a>, 
<a href="/search/eess?searchtype=author&query=Povey%2C+D">Daniel Povey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13061" title="Abstract">arXiv:2310.13061</a> (replaced) [<a href="/pdf/2310.13061" title="Download PDF">pdf</a>, <a href="/format/2310.13061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To grok or not to grok: Disentangling generalization and memorization on  corrupted algorithmic datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doshi%2C+D">Darshil Doshi</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Aritra Das</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tianyu He</a>, 
<a href="/search/cs?searchtype=author&query=Gromov%2C+A">Andrey Gromov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9+20 pages, 7+25 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13841" title="Abstract">arXiv:2310.13841</a> (replaced) [<a href="/pdf/2310.13841" title="Download PDF">pdf</a>, <a href="/format/2310.13841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast hyperboloid decision tree algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chlenski%2C+P">Philippe Chlenski</a>, 
<a href="/search/cs?searchtype=author&query=Turok%2C+E">Ethan Turok</a>, 
<a href="/search/cs?searchtype=author&query=Moretti%2C+A">Antonio Moretti</a>, 
<a href="/search/cs?searchtype=author&query=Pe%27er%2C+I">Itsik Pe&#x27;er</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on Learning Representations (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14540" title="Abstract">arXiv:2310.14540</a> (replaced) [<a href="/pdf/2310.14540" title="Download PDF">pdf</a>, <a href="/format/2310.14540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Spatial Understanding of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yamada%2C+Y">Yutaro Yamada</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+Y">Yihan Bao</a>, 
<a href="/search/cs?searchtype=author&query=Lampinen%2C+A+K">Andrew K. Lampinen</a>, 
<a href="/search/cs?searchtype=author&query=Kasai%2C+J">Jungo Kasai</a>, 
<a href="/search/cs?searchtype=author&query=Yildirim%2C+I">Ilker Yildirim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to TMLR 2024. Our code and data are available at <a href="https://github.com/runopti/SpatialEvalLLM">this https URL</a>, <a href="https://huggingface.co/datasets/yyamada/SpatialEvalLLM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17603" title="Abstract">arXiv:2310.17603</a> (replaced) [<a href="/pdf/2310.17603" title="Download PDF">pdf</a>, <a href="/format/2310.17603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An efficient frequency-independent numerical method for computing the  far-field pattern induced by polygonal obstacles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gibbs%2C+A">A. Gibbs</a>, 
<a href="/search/math?searchtype=author&query=Langdon%2C+S">S. Langdon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17748" title="Abstract">arXiv:2310.17748</a> (replaced) [<a href="/pdf/2310.17748" title="Download PDF">pdf</a>, <a href="/format/2310.17748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making the End-User a Priority in Benchmarking: OrionBench for  Unsupervised Time Series Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alnegheimish%2C+S">Sarah Alnegheimish</a>, 
<a href="/search/cs?searchtype=author&query=Berti-Equille%2C+L">Laure Berti-Equille</a>, 
<a href="/search/cs?searchtype=author&query=Veeramachaneni%2C+K">Kalyan Veeramachaneni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18794" title="Abstract">arXiv:2310.18794</a> (replaced) [<a href="/pdf/2310.18794" title="Download PDF">pdf</a>, <a href="/format/2310.18794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sequence-Level Certainty Reduces Hallucination In Knowledge-Grounded  Dialogue Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yixin Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fanyou Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weijie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sengamedu%2C+S+H">Srinivasan H. Sengamedu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19794" title="Abstract">arXiv:2310.19794</a> (replaced) [<a href="/pdf/2310.19794" title="Download PDF">pdf</a>, <a href="/format/2310.19794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Causal Bandits for Linear Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Yan%2C+Z">Zirui Yan</a>, 
<a href="/search/stat?searchtype=author&query=Mukherjee%2C+A">Arpan Mukherjee</a>, 
<a href="/search/stat?searchtype=author&query=Var%C4%B1c%C4%B1%2C+B">Burak Var&#x131;c&#x131;</a>, 
<a href="/search/stat?searchtype=author&query=Tajer%2C+A">Ali Tajer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00390" title="Abstract">arXiv:2311.00390</a> (replaced) [<a href="/pdf/2311.00390" title="Download PDF">pdf</a>, <a href="/format/2311.00390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Modular Pneumatic Soft Gripper Design for Aerial Grasping and Landing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheung%2C+H+C">Hiu Ching Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Ching-Wei Chang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bailun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+C">Chih-Yung Wen</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+H+K">Henry K. Chu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 13 figures, accepted by IEEE RoboSoft 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01054" title="Abstract">arXiv:2311.01054</a> (replaced) [<a href="/pdf/2311.01054" title="Download PDF">pdf</a>, <a href="/ps/2311.01054" title="Download PostScript">ps</a>, <a href="/format/2311.01054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A feasible and unitary quantum programming language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Caro%2C+A">Alejandro D&#xed;az-Caro</a> (CONICET, UBA, UNQ), 
<a href="/search/cs?searchtype=author&query=Hainry%2C+E">Emmanuel Hainry</a> (MOCQUA), 
<a href="/search/cs?searchtype=author&query=P%C3%A9choux%2C+R">Romain P&#xe9;choux</a> (MOCQUA), 
<a href="/search/cs?searchtype=author&query=Silva%2C+M">M&#xe1;rio Silva</a> (MOCQUA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03002" title="Abstract">arXiv:2311.03002</a> (replaced) [<a href="/pdf/2311.03002" title="Download PDF">pdf</a>, <a href="/format/2311.03002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating treatment effects from single-arm trials via latent-variable  modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haussmann%2C+M">Manuel Haussmann</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T+M+S">Tran Minh Son Le</a>, 
<a href="/search/cs?searchtype=author&query=Halla-aho%2C+V">Viivi Halla-aho</a>, 
<a href="/search/cs?searchtype=author&query=Kurki%2C+S">Samu Kurki</a>, 
<a href="/search/cs?searchtype=author&query=Leinonen%2C+J+V">Jussi V. Leinonen</a>, 
<a href="/search/cs?searchtype=author&query=Koskinen%2C+M">Miika Koskinen</a>, 
<a href="/search/cs?searchtype=author&query=Kaski%2C+S">Samuel Kaski</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%A4hdesm%C3%A4ki%2C+H">Harri L&#xe4;hdesm&#xe4;ki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at the 27th International Conference on Artificial Intelligence and Statistics (AISTATS) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03131" title="Abstract">arXiv:2311.03131</a> (replaced) [<a href="/pdf/2311.03131" title="Download PDF">pdf</a>, <a href="/format/2311.03131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoding Neuronal Networks: A Reservoir Computing Approach for  Predicting Connectivity and Functionality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Auslender%2C+I">Ilya Auslender</a>, 
<a href="/search/q-bio?searchtype=author&query=Letti%2C+G">Giorgio Letti</a>, 
<a href="/search/q-bio?searchtype=author&query=Heydari%2C+Y">Yasaman Heydari</a>, 
<a href="/search/q-bio?searchtype=author&query=Zaccaria%2C+C">Clara Zaccaria</a>, 
<a href="/search/q-bio?searchtype=author&query=Pavesi%2C+L">Lorenzo Pavesi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Biological Physics (physics.bio-ph)

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04179" title="Abstract">arXiv:2311.04179</a> (replaced) [<a href="/pdf/2311.04179" title="Download PDF">pdf</a>, <a href="/ps/2311.04179" title="Download PostScript">ps</a>, <a href="/format/2311.04179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Leakage in Machine Learning Pipelines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sasse%2C+L">Leonard Sasse</a>, 
<a href="/search/cs?searchtype=author&query=Nicolaisen-Sobesky%2C+E">Eliana Nicolaisen-Sobesky</a>, 
<a href="/search/cs?searchtype=author&query=Dukart%2C+J">Juergen Dukart</a>, 
<a href="/search/cs?searchtype=author&query=Eickhoff%2C+S+B">Simon B. Eickhoff</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B6tz%2C+M">Michael G&#xf6;tz</a>, 
<a href="/search/cs?searchtype=author&query=Hamdan%2C+S">Sami Hamdan</a>, 
<a href="/search/cs?searchtype=author&query=Komeyer%2C+V">Vera Komeyer</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+A">Abhijit Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Lahnakoski%2C+J">Juha Lahnakoski</a>, 
<a href="/search/cs?searchtype=author&query=Love%2C+B+C">Bradley C. Love</a>, 
<a href="/search/cs?searchtype=author&query=Raimondo%2C+F">Federico Raimondo</a>, 
<a href="/search/cs?searchtype=author&query=Patil%2C+K+R">Kaustubh R. Patil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> second draft
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05624" title="Abstract">arXiv:2311.05624</a> (replaced) [<a href="/pdf/2311.05624" title="Download PDF">pdf</a>, <a href="/ps/2311.05624" title="Download PostScript">ps</a>, <a href="/format/2311.05624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NP-hard problems are not in BQP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Czerwinski%2C+R">Reiner Czerwinski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09354" title="Abstract">arXiv:2311.09354</a> (replaced) [<a href="/pdf/2311.09354" title="Download PDF">pdf</a>, <a href="/ps/2311.09354" title="Download PostScript">ps</a>, <a href="/format/2311.09354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nondestructive, quantitative viability analysis of 3D tissue cultures  using machine learning image segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Trettner%2C+K+J">Kylie J. Trettner</a>, 
<a href="/search/q-bio?searchtype=author&query=Hsieh%2C+J">Jeremy Hsieh</a>, 
<a href="/search/q-bio?searchtype=author&query=Xiao%2C+W">Weikun Xiao</a>, 
<a href="/search/q-bio?searchtype=author&query=Lee%2C+J+S+H">Jerry S.H. Lee</a>, 
<a href="/search/q-bio?searchtype=author&query=Armani%2C+A+M">Andrea M. Armani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 total pages, Main text and SI included, 35 figures (5 main text, 30 supplemental), 9 tables, 6 datasets (provided on linked GitHub), linked image files on Zenodo
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11255" title="Abstract">arXiv:2311.11255</a> (replaced) [<a href="/pdf/2311.11255" title="Download PDF">pdf</a>, <a href="/format/2311.11255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M$^{2}$UGen: Multi-modal Music Understanding and Generation with the  Power of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shansong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hussain%2C+A+S">Atin Sakkeer Hussain</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chenshuo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11772" title="Abstract">arXiv:2311.11772</a> (replaced) [<a href="/pdf/2311.11772" title="Download PDF">pdf</a>, <a href="/format/2311.11772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Good Feature Extractor Is All You Need for Weakly Supervised Pathology  Slide Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=W%C3%B6lflein%2C+G">Georg W&#xf6;lflein</a>, 
<a href="/search/cs?searchtype=author&query=Ferber%2C+D">Dyke Ferber</a>, 
<a href="/search/cs?searchtype=author&query=Meneghetti%2C+A+R">Asier Rabasco Meneghetti</a>, 
<a href="/search/cs?searchtype=author&query=Nahhas%2C+O+S+M+E">Omar S. M. El Nahhas</a>, 
<a href="/search/cs?searchtype=author&query=Truhn%2C+D">Daniel Truhn</a>, 
<a href="/search/cs?searchtype=author&query=Carrero%2C+Z+I">Zunamys I. Carrero</a>, 
<a href="/search/cs?searchtype=author&query=Harrison%2C+D+J">David J. Harrison</a>, 
<a href="/search/cs?searchtype=author&query=Arandjelovi%C4%87%2C+O">Ognjen Arandjelovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Kather%2C+J+N">Jakob N. Kather</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13720" title="Abstract">arXiv:2311.13720</a> (replaced) [<a href="/pdf/2311.13720" title="Download PDF">pdf</a>, <a href="/format/2311.13720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can LLMs Fix Issues with Reasoning Models? Towards More Likely Models  for AI Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caglar%2C+T">Turgay Caglar</a>, 
<a href="/search/cs?searchtype=author&query=Belhaj%2C+S">Sirine Belhaj</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborti%2C+T">Tathagata Chakraborti</a>, 
<a href="/search/cs?searchtype=author&query=Katz%2C+M">Michael Katz</a>, 
<a href="/search/cs?searchtype=author&query=Sreedharan%2C+S">Sarath Sreedharan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14058" title="Abstract">arXiv:2311.14058</a> (replaced) [<a href="/pdf/2311.14058" title="Download PDF">pdf</a>, <a href="/ps/2311.14058" title="Download PostScript">ps</a>, <a href="/format/2311.14058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identification for Tree-shaped Structural Causal Models in Polynomial  Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Aaryan Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Bl%C3%A4ser%2C+M">Markus Bl&#xe4;ser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15453" title="Abstract">arXiv:2311.15453</a> (replaced) [<a href="/pdf/2311.15453" title="Download PDF">pdf</a>, <a href="/format/2311.15453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DISYRE: Diffusion-Inspired SYnthetic REstoration for Unsupervised  Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marimont%2C+S+N">Sergio Naval Marimont</a>, 
<a href="/search/cs?searchtype=author&query=Baugh%2C+M">Matthew Baugh</a>, 
<a href="/search/cs?searchtype=author&query=Siomos%2C+V">Vasilis Siomos</a>, 
<a href="/search/cs?searchtype=author&query=Tzelepis%2C+C">Christos Tzelepis</a>, 
<a href="/search/cs?searchtype=author&query=Kainz%2C+B">Bernhard Kainz</a>, 
<a href="/search/cs?searchtype=author&query=Tarroni%2C+G">Giacomo Tarroni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures. Accepted for publication in ISBI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16176" title="Abstract">arXiv:2311.16176</a> (replaced) [<a href="/pdf/2311.16176" title="Download PDF">pdf</a>, <a href="/format/2311.16176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Biases with Diverse Ensembles and Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scimeca%2C+L">Luca Scimeca</a>, 
<a href="/search/cs?searchtype=author&query=Rubinstein%2C+A">Alexander Rubinstein</a>, 
<a href="/search/cs?searchtype=author&query=Teney%2C+D">Damien Teney</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+S+J">Seong Joon Oh</a>, 
<a href="/search/cs?searchtype=author&query=Nicolicioiu%2C+A+M">Armand Mihai Nicolicioiu</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2310.02230">arXiv:2310.02230</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16417" title="Abstract">arXiv:2311.16417</a> (replaced) [<a href="/pdf/2311.16417" title="Download PDF">pdf</a>, <a href="/format/2311.16417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges and Opportunities to Enable Large-Scale Computing via  Heterogeneous Chiplets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhuoping Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shixin Ji</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xingzhen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+J">Jinming Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weifeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jani%2C+D">Dharmesh Jani</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Peipei Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18061" title="Abstract">arXiv:2311.18061</a> (replaced) [<a href="/pdf/2311.18061" title="Download PDF">pdf</a>, <a href="/format/2311.18061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TransNAS-TSAD: Harnessing Transformers for Multi-Objective Neural  Architecture Search in Time Series Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haq%2C+I+U">Ijaz Ul Haq</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B+S">Byung Suk Lee</a>, 
<a href="/search/cs?searchtype=author&query=Rizzo%2C+D+M">Donna M. Rizzo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages , 4 figures, It will submitted to a journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18177" title="Abstract">arXiv:2311.18177</a> (replaced) [<a href="/pdf/2311.18177" title="Download PDF">pdf</a>, <a href="/format/2311.18177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Effective Universal Polynomial Basis for Spectral Graph Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Keke Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18377" title="Abstract">arXiv:2311.18377</a> (replaced) [<a href="/pdf/2311.18377" title="Download PDF">pdf</a>, <a href="/ps/2311.18377" title="Download PostScript">ps</a>, <a href="/format/2311.18377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer Learning across Different Chemical Domains: Virtual Screening  of Organic Materials with Deep Learning Models Pretrained on Small Molecule  and Chemical Reaction Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Zhang%2C+C">Chengwei Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Zhai%2C+Y">Yushuang Zhai</a>, 
<a href="/search/physics?searchtype=author&query=Gong%2C+Z">Ziyang Gong</a>, 
<a href="/search/physics?searchtype=author&query=Duan%2C+H">Hongliang Duan</a>, 
<a href="/search/physics?searchtype=author&query=She%2C+Y">Yuan-Bin She</a>, 
<a href="/search/physics?searchtype=author&query=Yang%2C+Y">Yun-Fang Yang</a>, 
<a href="/search/physics?searchtype=author&query=Su%2C+A">An Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG); Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00463" title="Abstract">arXiv:2312.00463</a> (replaced) [<a href="/pdf/2312.00463" title="Download PDF">pdf</a>, <a href="/ps/2312.00463" title="Download PostScript">ps</a>, <a href="/format/2312.00463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-rank-modified Galerkin methods for the Lyapunov equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lund%2C+K">Kathryn Lund</a>, 
<a href="/search/math?searchtype=author&query=Palitta%2C+D">Davide Palitta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01659" title="Abstract">arXiv:2312.01659</a> (replaced) [<a href="/pdf/2312.01659" title="Download PDF">pdf</a>, <a href="/format/2312.01659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RiskBench: A Scenario-based Benchmark for Risk Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kung%2C+C">Chi-Hsi Kung</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chieh-Chi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Pao%2C+P">Pang-Yuan Pao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shu-Wei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pin-Lun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hsin-Cheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yi-Ting Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03085" title="Abstract">arXiv:2312.03085</a> (replaced) [<a href="/pdf/2312.03085" title="Download PDF">pdf</a>, <a href="/format/2312.03085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ScAR: Scaling Adversarial Robustness for LiDAR Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiaohu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Radha%2C+H">Hayder Radha</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05235" title="Abstract">arXiv:2312.05235</a> (replaced) [<a href="/pdf/2312.05235" title="Download PDF">pdf</a>, <a href="/format/2312.05235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative AI in Higher Education: Seeing ChatGPT Through Universities&#x27;  Policies, Resources, and Guidelines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+A">Anh Dang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zihao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Mac%2C+S">Son Mac</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05772" title="Abstract">arXiv:2312.05772</a> (replaced) [<a href="/pdf/2312.05772" title="Download PDF">pdf</a>, <a href="/format/2312.05772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A^3-CodGen: A Repository-Level Code Generation Framework for Code Reuse  with Local-Aware, Global-Aware, and Third-Party-Library-Aware
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+D">Dianshu Liao</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shidong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaoyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiaoxue Ren</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhenchang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Huan Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qinying Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07533" title="Abstract">arXiv:2312.07533</a> (replaced) [<a href="/pdf/2312.07533" title="Download PDF">pdf</a>, <a href="/format/2312.07533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VILA: On Pre-training for Visual Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Ji Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongxu Yin</a>, 
<a href="/search/cs?searchtype=author&query=Ping%2C+W">Wei Ping</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Molchanov%2C+P">Pavlo Molchanov</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+A">Andrew Tao</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+H">Huizi Mao</a>, 
<a href="/search/cs?searchtype=author&query=Kautz%2C+J">Jan Kautz</a>, 
<a href="/search/cs?searchtype=author&query=Shoeybi%2C+M">Mohammad Shoeybi</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Song Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08616" title="Abstract">arXiv:2312.08616</a> (replaced) [<a href="/pdf/2312.08616" title="Download PDF">pdf</a>, <a href="/format/2312.08616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generalized Neural Diffusion Framework on Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yibo Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongrui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chuan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09932" title="Abstract">arXiv:2312.09932</a> (replaced) [<a href="/pdf/2312.09932" title="Download PDF">pdf</a>, <a href="/format/2312.09932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RDR: the Recap, Deliberate, and Respond Method for Enhanced Language  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zi%2C+Y">Yuxin Zi</a>, 
<a href="/search/cs?searchtype=author&query=Veeramani%2C+H">Hariram Veeramani</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+K">Kaushik Roy</a>, 
<a href="/search/cs?searchtype=author&query=Sheth%2C+A">Amit Sheth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09979" title="Abstract">arXiv:2312.09979</a> (replaced) [<a href="/pdf/2312.09979" title="Download PDF">pdf</a>, <a href="/format/2312.09979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LoRAMoE: Alleviate World Knowledge Forgetting in Large Language Models  via MoE-Style Plugin
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dou%2C+S">Shihan Dou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+E">Enyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Songyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Wei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuhao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+Z">Zhiheng Xi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiaoran Fan</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+S">Shiliang Pu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Rui Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12450" title="Abstract">arXiv:2312.12450</a> (replaced) [<a href="/pdf/2312.12450" title="Download PDF">pdf</a>, <a href="/format/2312.12450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can It Edit? Evaluating the Ability of Large Language Models to Follow  Code Editing Instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cassano%2C+F">Federico Cassano</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Luisa Li</a>, 
<a href="/search/cs?searchtype=author&query=Sethi%2C+A">Akul Sethi</a>, 
<a href="/search/cs?searchtype=author&query=Shinn%2C+N">Noah Shinn</a>, 
<a href="/search/cs?searchtype=author&query=Brennan-Jones%2C+A">Abby Brennan-Jones</a>, 
<a href="/search/cs?searchtype=author&query=Lozhkov%2C+A">Anton Lozhkov</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+C+J">Carolyn Jane Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Guha%2C+A">Arjun Guha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2312.06024">arXiv:2312.06024</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15504" title="Abstract">arXiv:2312.15504</a> (replaced) [<a href="/pdf/2312.15504" title="Download PDF">pdf</a>, <a href="/ps/2312.15504" title="Download PostScript">ps</a>, <a href="/format/2312.15504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Power Allocation and Beamforming Design for IRS-aided Secure Directional  Modulation Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+R">Rongen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+F">Feng Shu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Fuhui Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yongpeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiangzhou Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15516" title="Abstract">arXiv:2312.15516</a> (replaced) [<a href="/pdf/2312.15516" title="Download PDF">pdf</a>, <a href="/format/2312.15516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A-SDM: Accelerating Stable Diffusion through Redundancy Removal and  Performance Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jinchao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+X">Xiaobing Tu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Siyuan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+P">Pengfei Wan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Since the experimental part has not been added, we wish to withdraw the manuscript, and we hope to submit it after the experiment has been verified
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16044" title="Abstract">arXiv:2312.16044</a> (replaced) [<a href="/pdf/2312.16044" title="Download PDF">pdf</a>, <a href="/format/2312.16044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMLight: Large Language Models as Traffic Signal Control Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+S">Siqi Lai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weijia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02014" title="Abstract">arXiv:2401.02014</a> (replaced) [<a href="/pdf/2401.02014" title="Download PDF">pdf</a>, <a href="/format/2401.02014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Zero-Shot Multi-Speaker TTS with Negated Speaker  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeon%2C+Y">Yejin Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yunsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G+G">Gary Geunbae Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03968" title="Abstract">arXiv:2401.03968</a> (replaced) [<a href="/pdf/2401.03968" title="Download PDF">pdf</a>, <a href="/format/2401.03968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> scDiffusion: conditional generation of high-quality single-cell data  using diffusion model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Luo%2C+E">Erpai Luo</a>, 
<a href="/search/q-bio?searchtype=author&query=Hao%2C+M">Minsheng Hao</a>, 
<a href="/search/q-bio?searchtype=author&query=Wei%2C+L">Lei Wei</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+X">Xuegong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Genomics (q-bio.GN)

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04577" title="Abstract">arXiv:2401.04577</a> (replaced) [<a href="/pdf/2401.04577" title="Download PDF">pdf</a>, <a href="/format/2401.04577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Audio Generation using a Single Non-Autoregressive Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ziv%2C+A">Alon Ziv</a>, 
<a href="/search/cs?searchtype=author&query=Gat%2C+I">Itai Gat</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+G+L">Gael Le Lan</a>, 
<a href="/search/cs?searchtype=author&query=Remez%2C+T">Tal Remez</a>, 
<a href="/search/cs?searchtype=author&query=Kreuk%2C+F">Felix Kreuk</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%A9fossez%2C+A">Alexandre D&#xe9;fossez</a>, 
<a href="/search/cs?searchtype=author&query=Copet%2C+J">Jade Copet</a>, 
<a href="/search/cs?searchtype=author&query=Synnaeve%2C+G">Gabriel Synnaeve</a>, 
<a href="/search/cs?searchtype=author&query=Adi%2C+Y">Yossi Adi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05765" title="Abstract">arXiv:2401.05765</a> (replaced) [<a href="/pdf/2401.05765" title="Download PDF">pdf</a>, <a href="/format/2401.05765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new computationally efficient algorithm to solve Feature Selection for  Functional Data Classification in high-dimensional spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Boschi%2C+T">Tobia Boschi</a>, 
<a href="/search/stat?searchtype=author&query=Bonin%2C+F">Francesca Bonin</a>, 
<a href="/search/stat?searchtype=author&query=Ordonez-Hurtado%2C+R">Rodrigo Ordonez-Hurtado</a>, 
<a href="/search/stat?searchtype=author&query=Pascale%2C+A">Alessandra Pascale</a>, 
<a href="/search/stat?searchtype=author&query=Epperlein%2C+J">Jonathan Epperlein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05932" title="Abstract">arXiv:2401.05932</a> (replaced) [<a href="/pdf/2401.05932" title="Download PDF">pdf</a>, <a href="/format/2401.05932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffDA: a Diffusion model for weather-scale Data Assimilation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Langwen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gianinazzi%2C+L">Lukas Gianinazzi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yuejiang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Dueben%2C+P+D">Peter D. Dueben</a>, 
<a href="/search/cs?searchtype=author&query=Hoefler%2C+T">Torsten Hoefler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06071" title="Abstract">arXiv:2401.06071</a> (replaced) [<a href="/pdf/2401.06071" title="Download PDF">pdf</a>, <a href="/format/2401.06071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GroundingGPT:Language Enhanced Multi-modal Grounding Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaowei Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hang Song</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yiqing Cai</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Q">Qi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Ran Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Junting Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zefeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+V+T">Van Tu Vu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhida Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06401" title="Abstract">arXiv:2401.06401</a> (replaced) [<a href="/e-print/2401.06401" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DevEval: Evaluating Code Generation in Practical Software Projects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Ge Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yunfei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongmin Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huanyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kaibo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lecheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zheng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lanshen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jiazheng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuanming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yihong Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuqi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+B">Bin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mengfei Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> There are mistakes in the dataset. We need to re-check the dataset and repeat our experiments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06509" title="Abstract">arXiv:2401.06509</a> (replaced) [<a href="/pdf/2401.06509" title="Download PDF">pdf</a>, <a href="/format/2401.06509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AntEval: Evaluation of Social Interaction Competencies in LLM-Driven  Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuanzhi Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Linchao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preliminary version of an ongoing work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08814" title="Abstract">arXiv:2401.08814</a> (replaced) [<a href="/pdf/2401.08814" title="Download PDF">pdf</a>, <a href="/format/2401.08814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inviscid Burgers as a degenerate elliptic problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kouskiya%2C+U">Uditnarayan Kouskiya</a>, 
<a href="/search/math?searchtype=author&query=Acharya%2C+A">Amit Acharya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph); Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09356" title="Abstract">arXiv:2401.09356</a> (replaced) [<a href="/pdf/2401.09356" title="Download PDF">pdf</a>, <a href="/format/2401.09356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Swing: Short-cutting Rings for Higher Bandwidth Allreduce
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Sensi%2C+D">Daniele De Sensi</a>, 
<a href="/search/cs?searchtype=author&query=Bonato%2C+T">Tommaso Bonato</a>, 
<a href="/search/cs?searchtype=author&query=Saam%2C+D">David Saam</a>, 
<a href="/search/cs?searchtype=author&query=Hoefler%2C+T">Torsten Hoefler</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NSDI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI); Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10553" title="Abstract">arXiv:2401.10553</a> (replaced) [<a href="/pdf/2401.10553" title="Download PDF">pdf</a>, <a href="/ps/2401.10553" title="Download PostScript">ps</a>, <a href="/format/2401.10553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-set cubical categories and their formalisation with a proof  assistant
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malbos%2C+P">Philippe Malbos</a>, 
<a href="/search/cs?searchtype=author&query=Massacrier%2C+T">Tanguy Massacrier</a>, 
<a href="/search/cs?searchtype=author&query=Struth%2C+G">Georg Struth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Category Theory (math.CT)

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10647" title="Abstract">arXiv:2401.10647</a> (replaced) [<a href="/pdf/2401.10647" title="Download PDF">pdf</a>, <a href="/format/2401.10647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sowing the Wind, Reaping the Whirlwind: The Impact of Editing Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hazra%2C+R">Rima Hazra</a>, 
<a href="/search/cs?searchtype=author&query=Layek%2C+S">Sayan Layek</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Somnath Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Poria%2C+S">Soujanya Poria</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review. {<a href="https://huggingface.co/datasets/SoftMINER-Group/NicheHazardQA">this https URL</a>}
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12671" title="Abstract">arXiv:2401.12671</a> (replaced) [<a href="/pdf/2401.12671" title="Download PDF">pdf</a>, <a href="/format/2401.12671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context Matters: Pushing the Boundaries of Open-Ended Answer Generation  with Graph-Structured Knowledge Context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Somnath Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Sahoo%2C+A">Amruit Sahoo</a>, 
<a href="/search/cs?searchtype=author&query=Layek%2C+S">Sayan Layek</a>, 
<a href="/search/cs?searchtype=author&query=Dutta%2C+A">Avik Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Hazra%2C+R">Rima Hazra</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+A">Animesh Mukherjee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14074" title="Abstract">arXiv:2401.14074</a> (replaced) [<a href="/pdf/2401.14074" title="Download PDF">pdf</a>, <a href="/format/2401.14074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProCNS: Progressive Prototype Calibration and Noise Suppression for  Weakly-Supervised Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Y. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">L. Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K+K+Y">K. K. Y. Wong</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">X. Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14624" title="Abstract">arXiv:2401.14624</a> (replaced) [<a href="/pdf/2401.14624" title="Download PDF">pdf</a>, <a href="/format/2401.14624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Query of CC: Unearthing Large Scale Domain-Specific Knowledge from  Public Corpora
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fei%2C+Z">Zhaoye Fei</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yunfan Shao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhiyuan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We have released the full data (total of 735GB) in <a href="https://huggingface.co/datasets/Query-of-CC/knowledge_pile_full">this https URL</a> and partial data (about 40GB) in <a href="https://huggingface.co/datasets/Query-of-CC/knowledge_pile">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15906" title="Abstract">arXiv:2401.15906</a> (replaced) [<a href="/pdf/2401.15906" title="Download PDF">pdf</a>, <a href="/format/2401.15906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mean Estimation with User-Level Privacy for Spatio-Temporal IoT Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rameshwar%2C+V+A">V. Arvind Rameshwar</a>, 
<a href="/search/cs?searchtype=author&query=Tandon%2C+A">Anshoo Tandon</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+P">Prajjwal Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A+V">Aditya Vikram Singh</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+N">Novoneel Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Abhay Sharma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Information Theory (cs.IT); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16461" title="Abstract">arXiv:2401.16461</a> (replaced) [<a href="/pdf/2401.16461" title="Download PDF">pdf</a>, <a href="/format/2401.16461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Norm Enforcement with a Soft Touch: Faster Emergence, Happier Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tzeng%2C+S">Sz-Ting Tzeng</a>, 
<a href="/search/cs?searchtype=author&query=Ajmeri%2C+N">Nirav Ajmeri</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+M+P">Munindar P. Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 figures, 5 tables (and supplementary material with code availability and additional results), accepted at AAMAS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16650" title="Abstract">arXiv:2401.16650</a> (replaced) [<a href="/pdf/2401.16650" title="Download PDF">pdf</a>, <a href="/format/2401.16650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmenting Replay in World Models for Continual Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Luke Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kuhlmann%2C+L">Levin Kuhlmann</a>, 
<a href="/search/cs?searchtype=author&query=Kowadlo%2C+G">Gideon Kowadlo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00421" title="Abstract">arXiv:2402.00421</a> (replaced) [<a href="/pdf/2402.00421" title="Download PDF">pdf</a>, <a href="/format/2402.00421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From PARIS to LE-PARIS: Toward Patent Response Automation with  Recommender Systems and Collaborative Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+J">Jung-Mei Chu</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+H">Hao-Cheng Lo</a>, 
<a href="/search/cs?searchtype=author&query=Hsiang%2C+J">Jieh Hsiang</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+C">Chun-Chieh Cho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 5 figures, typos corrected, references added, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.01549" title="Abstract">arXiv:2402.01549</a> (replaced) [<a href="/e-print/2402.01549" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum advantage in zero-error function computation with side  information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+R">Ruoyu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Ramamoorthy%2C+A">Aditya Ramamoorthy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We have realized an error in Claim 3
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Combinatorics (math.CO); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.01831" title="Abstract">arXiv:2402.01831</a> (replaced) [<a href="/pdf/2402.01831" title="Download PDF">pdf</a>, <a href="/format/2402.01831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio Flamingo: A Novel Audio Language Model with Few-Shot Learning and  Dialogue Abilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+Z">Zhifeng Kong</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+A">Arushi Goel</a>, 
<a href="/search/cs?searchtype=author&query=Badlani%2C+R">Rohan Badlani</a>, 
<a href="/search/cs?searchtype=author&query=Ping%2C+W">Wei Ping</a>, 
<a href="/search/cs?searchtype=author&query=Valle%2C+R">Rafael Valle</a>, 
<a href="/search/cs?searchtype=author&query=Catanzaro%2C+B">Bryan Catanzaro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02141" title="Abstract">arXiv:2402.02141</a> (replaced) [<a href="/pdf/2402.02141" title="Download PDF">pdf</a>, <a href="/ps/2402.02141" title="Download PostScript">ps</a>, <a href="/format/2402.02141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot sketch-based remote sensing image retrieval based on  multi-level and attention-guided tokenization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaoshuang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+B">Beiping Song</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhuang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02192" title="Abstract">arXiv:2402.02192</a> (replaced) [<a href="/pdf/2402.02192" title="Download PDF">pdf</a>, <a href="/format/2402.02192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RecNet: An Invertible Point Cloud Encoding through Range Image  Embeddings for Multi-Robot Map Sharing and Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stathoulopoulos%2C+N">Nikolaos Stathoulopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Saucedo%2C+M+A+V">Mario A.V. Saucedo</a>, 
<a href="/search/cs?searchtype=author&query=Koval%2C+A">Anton Koval</a>, 
<a href="/search/cs?searchtype=author&query=Nikolakopoulos%2C+G">George Nikolakopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the 2024 IEEE International Conference on Robotics and Automation in Yokohama, (ICRA24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02649" title="Abstract">arXiv:2402.02649</a> (replaced) [<a href="/pdf/2402.02649" title="Download PDF">pdf</a>, <a href="/format/2402.02649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Densely Decoded Networks with Adaptive Deep Supervision for Medical  Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Suraj Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D+Z">Danny Z. Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04412" title="Abstract">arXiv:2402.04412</a> (replaced) [<a href="/pdf/2402.04412" title="Download PDF">pdf</a>, <a href="/format/2402.04412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The VampPrior Mixture Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stirn%2C+A">Andrew Stirn</a>, 
<a href="/search/cs?searchtype=author&query=Knowles%2C+D+A">David A. Knowles</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06700" title="Abstract">arXiv:2402.06700</a> (replaced) [<a href="/pdf/2402.06700" title="Download PDF">pdf</a>, <a href="/format/2402.06700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entropy-Regularized Token-Level Policy Optimization for Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+M">Muning Wen</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Cheng Deng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Ying Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06809" title="Abstract">arXiv:2402.06809</a> (replaced) [<a href="/pdf/2402.06809" title="Download PDF">pdf</a>, <a href="/format/2402.06809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Adaptation Using Pseudo Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chhabra%2C+S">Sachin Chhabra</a>, 
<a href="/search/cs?searchtype=author&query=Venkateswara%2C+H">Hemanth Venkateswara</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baoxin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages + 3 pages of references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07232" title="Abstract">arXiv:2402.07232</a> (replaced) [<a href="/pdf/2402.07232" title="Download PDF">pdf</a>, <a href="/format/2402.07232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GTM: General Trajectory Modeling with Auto-regressive Generation of  Feature Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jilin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Shengnan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jensen%2C+C+S">Christian S. Jensen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Youfang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+H">Huaiyu Wan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07383" title="Abstract">arXiv:2402.07383</a> (replaced) [<a href="/pdf/2402.07383" title="Download PDF">pdf</a>, <a href="/format/2402.07383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making Flow-Matching-Based Zero-Shot Text-to-Speech Laugh as You Like
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kanda%2C+N">Naoyuki Kanda</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xiaofei Wang</a>, 
<a href="/search/eess?searchtype=author&query=Eskimez%2C+S+E">Sefik Emre Eskimez</a>, 
<a href="/search/eess?searchtype=author&query=Thakker%2C+M">Manthan Thakker</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+H">Hemin Yang</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+Z">Zirun Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+M">Min Tang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+C">Canrun Li</a>, 
<a href="/search/eess?searchtype=author&query=Tsai%2C+C">Chung-Hsien Tsai</a>, 
<a href="/search/eess?searchtype=author&query=Xiao%2C+Z">Zhen Xiao</a>, 
<a href="/search/eess?searchtype=author&query=Xia%2C+Y">Yufei Xia</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jinzhu Li</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yanqing Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+S">Sheng Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Zeng%2C+M">Michael Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> See <a href="https://aka.ms/elate/">this https URL</a> for demo samples, v2: subjective evaluation has been added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.09099" title="Abstract">arXiv:2402.09099</a> (replaced) [<a href="/pdf/2402.09099" title="Download PDF">pdf</a>, <a href="/format/2402.09099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Neuron Interactions and Emergence in LLMs: From the  Multifractal Analysis Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xiongye Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chenyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ping%2C+H">Heng Ping</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+D">Defu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaxing Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yizhuo Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shixuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Bogdan%2C+P">Paul Bogdan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.09353" title="Abstract">arXiv:2402.09353</a> (replaced) [<a href="/pdf/2402.09353" title="Download PDF">pdf</a>, <a href="/format/2402.09353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DoRA: Weight-Decomposed Low-Rank Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shih-Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chien-Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongxu Yin</a>, 
<a href="/search/cs?searchtype=author&query=Molchanov%2C+P">Pavlo Molchanov</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y+F">Yu-Chiang Frank Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+K">Kwang-Ting Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Min-Hung Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code available at <a href="https://github.com/nbasyl/DoRA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11000" title="Abstract">arXiv:2402.11000</a> (replaced) [<a href="/pdf/2402.11000" title="Download PDF">pdf</a>, <a href="/format/2402.11000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASGEA: Exploiting Logic Rules from Align-Subgraphs for Entity Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yangyifei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Lingbing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qian Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wenxuan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhixin Cai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianxin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Ongoing work; 16 pages, 9 Tables, 8 Figures; Code: <a href="https://github.com/lyyf2002/ASGEA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11105" title="Abstract">arXiv:2402.11105</a> (replaced) [<a href="/pdf/2402.11105" title="Download PDF">pdf</a>, <a href="/format/2402.11105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Magic Mirror on the Wall, How to Benchmark Quantum Error Correction  Codes, Overall ?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chatterjee%2C+A">Avimita Chatterjee</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ghosh%2C+S">Swaroop Ghosh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 14 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11425" title="Abstract">arXiv:2402.11425</a> (replaced) [<a href="/pdf/2402.11425" title="Download PDF">pdf</a>, <a href="/ps/2402.11425" title="Download PostScript">ps</a>, <a href="/format/2402.11425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Local False Discovery Rate Control: A Resource Allocation  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ao%2C+R">Ruicheng Ao</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+H">Hongyu Chen</a>, 
<a href="/search/stat?searchtype=author&query=Simchi-Levi%2C+D">David Simchi-Levi</a>, 
<a href="/search/stat?searchtype=author&query=Zhu%2C+F">Feng Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11445" title="Abstract">arXiv:2402.11445</a> (replaced) [<a href="/pdf/2402.11445" title="Download PDF">pdf</a>, <a href="/format/2402.11445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balanced Truncation of Linear Systems with Quadratic Outputs in Limited  Time and Frequency Intervals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Song%2C+Q">Qiu-Yan Song</a>, 
<a href="/search/eess?searchtype=author&query=Zulfiqar%2C+U">Umair Zulfiqar</a>, 
<a href="/search/eess?searchtype=author&query=Xiao%2C+Z">Zhi-Hua Xiao</a>, 
<a href="/search/eess?searchtype=author&query=Uddin%2C+M+M">Mohammad Monir Uddin</a>, 
<a href="/search/eess?searchtype=author&query=Sreeram%2C+V">Victor Sreeram</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.12177" title="Abstract">arXiv:2402.12177</a> (replaced) [<a href="/pdf/2402.12177" title="Download PDF">pdf</a>, <a href="/ps/2402.12177" title="Download PostScript">ps</a>, <a href="/format/2402.12177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mafin: Enhancing Black-Box Embeddings with Model Augmented Fine-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingtian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+S">Shawn Lan</a>, 
<a href="/search/cs?searchtype=author&query=Hayes%2C+P">Peter Hayes</a>, 
<a href="/search/cs?searchtype=author&query=Barber%2C+D">David Barber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.12426" title="Abstract">arXiv:2402.12426</a> (replaced) [<a href="/pdf/2402.12426" title="Download PDF">pdf</a>, <a href="/ps/2402.12426" title="Download PostScript">ps</a>, <a href="/format/2402.12426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attacks on Node Attributes in Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Ying Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lanier%2C+M">Michael Lanier</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+A">Anindya Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Vorobeychik%2C+Y">Yevgeniy Vorobeychik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024 AICS workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.12647" title="Abstract">arXiv:2402.12647</a> (replaced) [<a href="/pdf/2402.12647" title="Download PDF">pdf</a>, <a href="/format/2402.12647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffusionNOCS: Managing Symmetry and Uncertainty in Sim2Real Multi-Modal  Category-level Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ikeda%2C+T">Takuya Ikeda</a>, 
<a href="/search/cs?searchtype=author&query=Zakharov%2C+S">Sergey Zakharov</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+T">Tianyi Ko</a>, 
<a href="/search/cs?searchtype=author&query=Irshad%2C+M+Z">Muhammad Zubair Irshad</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+R">Robert Lee</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Katherine Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ambrus%2C+R">Rares Ambrus</a>, 
<a href="/search/cs?searchtype=author&query=Nishiwaki%2C+K">Koichi Nishiwaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages. 9 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.12721" title="Abstract">arXiv:2402.12721</a> (replaced) [<a href="/pdf/2402.12721" title="Download PDF">pdf</a>, <a href="/format/2402.12721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for  Recognizing Low-Quality Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeon%2C+J">Jinsung Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hyundong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jonghyun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Sanghyun Hong</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongeun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kookjin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+N">Noseong Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.12936" title="Abstract">arXiv:2402.12936</a> (replaced) [<a href="/pdf/2402.12936" title="Download PDF">pdf</a>, <a href="/format/2402.12936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring Impacts of Poisoning on Model Parameters and Neuron  Activations: A Case Study of Poisoning CodeBERT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hussain%2C+A">Aftab Hussain</a>, 
<a href="/search/cs?searchtype=author&query=Rabin%2C+M+R+I">Md Rafiqul Islam Rabin</a>, 
<a href="/search/cs?searchtype=author&query=Ayoobi%2C+N">Navid Ayoobi</a>, 
<a href="/search/cs?searchtype=author&query=Alipour%2C+M+A">Mohammad Amin Alipour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13172" title="Abstract">arXiv:2402.13172</a> (replaced) [<a href="/pdf/2402.13172" title="Download PDF">pdf</a>, <a href="/format/2402.13172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Kinematics Estimation from Video with a Biomechanical Model and  Synthetic Training Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhi-Yi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+B">Bofan Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Fernandez%2C+J+C">Judith Cueto Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Kruk%2C+E">Eline van der Kruk</a>, 
<a href="/search/cs?searchtype=author&query=Seth%2C+A">Ajay Seth</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xucong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13613" title="Abstract">arXiv:2402.13613</a> (replaced) [<a href="/pdf/2402.13613" title="Download PDF">pdf</a>, <a href="/format/2402.13613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overview of the VLSP 2023 -- ComOM Shared Task: A Data Challenge for  Comparative Opinion Mining from Vietnamese Product Reviews
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+H">Hoang-Quynh Le</a>, 
<a href="/search/cs?searchtype=author&query=Can%2C+D">Duy-Cat Can</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+K">Khanh-Vinh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+M">Mai-Vu Tran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of VLSP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13852" title="Abstract">arXiv:2402.13852</a> (replaced) [<a href="/pdf/2402.13852" title="Download PDF">pdf</a>, <a href="/format/2402.13852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Control System for Continuous Glucose Monitoring and Maintenance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wasi%2C+A+T">Azmine Toushik Wasi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 Pages, 4 figures, ICLR 2024 Tiny Papers Track <a href="https://openreview.net/forum?id=Te4P3Cn54g">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The Second Tiny Papers Track at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Systems and Control (eess.SY); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13948" title="Abstract">arXiv:2402.13948</a> (replaced) [<a href="/pdf/2402.13948" title="Download PDF">pdf</a>, <a href="/ps/2402.13948" title="Download PostScript">ps</a>, <a href="/format/2402.13948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Syndrome-based Neural Decoder for Linear Block Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Boni+Rovella%2C+G">Gast&#xf3;n De Boni Rovella</a>, 
<a href="/search/cs?searchtype=author&query=Benammar%2C+M">Meryem Benammar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 7 figures. Published in Proc. IEEE Global Communications Conference (GLOBECOM 2023), Kuala Lumpur, Malaysia, December 4-8, 2023. \c{opyright} 2023 IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14160" title="Abstract">arXiv:2402.14160</a> (replaced) [<a href="/pdf/2402.14160" title="Download PDF">pdf</a>, <a href="/format/2402.14160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursive Speculative Decoding: Accelerating LLM Inference via Sampling  Without Replacement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeon%2C+W">Wonseok Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Gagrani%2C+M">Mukul Gagrani</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+R">Raghavv Goel</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Junyoung Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Mingu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lott%2C+C">Christopher Lott</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 82 pages, 9 figures, 54 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14396" title="Abstract">arXiv:2402.14396</a> (replaced) [<a href="/pdf/2402.14396" title="Download PDF">pdf</a>, <a href="/format/2402.14396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Circuit Optimization with AlphaTensor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ruiz%2C+F+J+R">Francisco J. R. Ruiz</a>, 
<a href="/search/quant-ph?searchtype=author&query=Laakkonen%2C+T">Tuomas Laakkonen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bausch%2C+J">Johannes Bausch</a>, 
<a href="/search/quant-ph?searchtype=author&query=Balog%2C+M">Matej Balog</a>, 
<a href="/search/quant-ph?searchtype=author&query=Barekatain%2C+M">Mohammadamin Barekatain</a>, 
<a href="/search/quant-ph?searchtype=author&query=Heras%2C+F+J+H">Francisco J. H. Heras</a>, 
<a href="/search/quant-ph?searchtype=author&query=Novikov%2C+A">Alexander Novikov</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fitzpatrick%2C+N">Nathan Fitzpatrick</a>, 
<a href="/search/quant-ph?searchtype=author&query=Romera-Paredes%2C+B">Bernardino Romera-Paredes</a>, 
<a href="/search/quant-ph?searchtype=author&query=van+de+Wetering%2C+J">John van de Wetering</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fawzi%2C+A">Alhussein Fawzi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Meichanetzidis%2C+K">Konstantinos Meichanetzidis</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kohli%2C+P">Pushmeet Kohli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages main paper + 19 pages appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14482" title="Abstract">arXiv:2402.14482</a> (replaced) [<a href="/pdf/2402.14482" title="Download PDF">pdf</a>, <a href="/format/2402.14482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpanSeq: Similarity-based sequence data splitting method for improved  development and assessment of deep learning projects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Florensa%2C+A+F">Alfred Ferrer Florensa</a>, 
<a href="/search/cs?searchtype=author&query=Armenteros%2C+J+J+A">Jose Juan Almagro Armenteros</a>, 
<a href="/search/cs?searchtype=author&query=Nielsen%2C+H">Henrik Nielsen</a>, 
<a href="/search/cs?searchtype=author&query=Aarestrup%2C+F+M">Frank M&#xf8;ller Aarestrup</a>, 
<a href="/search/cs?searchtype=author&query=Clausen%2C+P+T+L+C">Philip Thomas Lanken Conradsen Clausen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14818" title="Abstract">arXiv:2402.14818</a> (replaced) [<a href="/pdf/2402.14818" title="Download PDF">pdf</a>, <a href="/format/2402.14818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PALO: A Polyglot Large Multimodal Model for 5B People
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maaz%2C+M">Muhammad Maaz</a>, 
<a href="/search/cs?searchtype=author&query=Rasheed%2C+H">Hanoona Rasheed</a>, 
<a href="/search/cs?searchtype=author&query=Shaker%2C+A">Abdelrahman Shaker</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Salman Khan</a>, 
<a href="/search/cs?searchtype=author&query=Cholakal%2C+H">Hisham Cholakal</a>, 
<a href="/search/cs?searchtype=author&query=Anwer%2C+R+M">Rao M. Anwer</a>, 
<a href="/search/cs?searchtype=author&query=Baldwin%2C+T">Tim Baldwin</a>, 
<a href="/search/cs?searchtype=author&query=Felsberg%2C+M">Michael Felsberg</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+F+S">Fahad S. Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report of PALO
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15183" title="Abstract">arXiv:2402.15183</a> (replaced) [<a href="/pdf/2402.15183" title="Download PDF">pdf</a>, <a href="/format/2402.15183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphEdit: Large Language Models for Graph Structure Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zirui Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Lianghao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yanhua Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zixuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+L">Liang Pang</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15322" title="Abstract">arXiv:2402.15322</a> (replaced) [<a href="/pdf/2402.15322" title="Download PDF">pdf</a>, <a href="/format/2402.15322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Transport on the Lie Group of Roto-translations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bon%2C+D">Daan Bon</a>, 
<a href="/search/cs?searchtype=author&query=Pai%2C+G">Gautam Pai</a>, 
<a href="/search/cs?searchtype=author&query=Bellaard%2C+G">Gijs Bellaard</a>, 
<a href="/search/cs?searchtype=author&query=Mula%2C+O">Olga Mula</a>, 
<a href="/search/cs?searchtype=author&query=Duits%2C+R">Remco Duits</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Differential Geometry (math.DG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15919" title="Abstract">arXiv:2402.15919</a> (replaced) [<a href="/pdf/2402.15919" title="Download PDF">pdf</a>, <a href="/format/2402.15919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to See Through Dazzle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xiaopeng Peng</a>, 
<a href="/search/cs?searchtype=author&query=Fleet%2C+E+F">Erin F. Fleet</a>, 
<a href="/search/cs?searchtype=author&query=Watnik%2C+A+T">Abbie T. Watnik</a>, 
<a href="/search/cs?searchtype=author&query=Swartzlander%2C+G+A">Grover A. Swartzlander</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15993" title="Abstract">arXiv:2402.15993</a> (replaced) [<a href="/pdf/2402.15993" title="Download PDF">pdf</a>, <a href="/format/2402.15993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Method for S4 with Diagonal State Space Layers using Balanced  Truncation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ezoe%2C+H">Haruka Ezoe</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+K">Kazuhiro Sato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16868" title="Abstract">arXiv:2402.16868</a> (replaced) [<a href="/pdf/2402.16868" title="Download PDF">pdf</a>, <a href="/format/2402.16868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Codebook-enabled Generative End-to-end Semantic Communication Powered by  Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+P">Peigen Ye</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yaping Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Shumin Yao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaodong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuguang Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE INFOCOM PerAI6G 2024(accepted)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17334" title="Abstract">arXiv:2402.17334</a> (replaced) [<a href="/pdf/2402.17334" title="Download PDF">pdf</a>, <a href="/format/2402.17334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BiVRec: Bidirectional View-based Multimodal Sequential Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jiaxi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jingtong Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yuehong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuxuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+M">Ming He</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zitao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18068" title="Abstract">arXiv:2402.18068</a> (replaced) [<a href="/pdf/2402.18068" title="Download PDF">pdf</a>, <a href="/format/2402.18068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SynArtifact: Classifying and Alleviating Artifacts in Synthetic Images  via Vision-Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+B">Bin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jianhao Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yexin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jian Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shuyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bo Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18180" title="Abstract">arXiv:2402.18180</a> (replaced) [<a href="/pdf/2402.18180" title="Download PDF">pdf</a>, <a href="/format/2402.18180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Simulacra: A Step toward the Personification of Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Qiuejie Xie</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Q">Qiming Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qingqiu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuejie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+R">Rui Feng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shang Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18240" title="Abstract">arXiv:2402.18240</a> (replaced) [<a href="/pdf/2402.18240" title="Download PDF">pdf</a>, <a href="/format/2402.18240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prospect Personalized Recommendation on Large Language Model-based Agent  Platform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jizhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+K">Keqin Bao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wentao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wanhong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fuli Feng</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18372" title="Abstract">arXiv:2402.18372</a> (replaced) [<a href="/pdf/2402.18372" title="Download PDF">pdf</a>, <a href="/format/2402.18372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedUV: Uniformity and Variance for Heterogeneous Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Son%2C+H+M">Ha Min Son</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Moon-Hyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+T">Tai-Myoung Chung</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures, 5 tables, to appear at CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18420" title="Abstract">arXiv:2402.18420</a> (replaced) [<a href="/pdf/2402.18420" title="Download PDF">pdf</a>, <a href="/format/2402.18420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CafkNet: GNN-Empowered Forward Kinematic Modeling for Cable-Driven  Parallel Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Linhan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Cong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+W">Weiwei Shang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jia Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To the best of authors' knowledge, it is the first study to employ the GNN for the FK problem of CDPRs. First two authors have equal contribution. Videos and codes are available at <a href="https://sites.google.com/view/cafknet/site">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18766" title="Abstract">arXiv:2402.18766</a> (replaced) [<a href="/pdf/2402.18766" title="Download PDF">pdf</a>, <a href="/format/2402.18766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Generative AI for Portuguese with Open Decoder Gerv&#xe1;sio PT*
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santos%2C+R">Rodrigo Santos</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+J">Jo&#xe3;o Silva</a>, 
<a href="/search/cs?searchtype=author&query=Gomes%2C+L">Lu&#xed;s Gomes</a>, 
<a href="/search/cs?searchtype=author&query=Rodrigues%2C+J">Jo&#xe3;o Rodrigues</a>, 
<a href="/search/cs?searchtype=author&query=Branco%2C+A">Ant&#xf3;nio Branco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18774" title="Abstract">arXiv:2402.18774</a> (replaced) [<a href="/pdf/2402.18774" title="Download PDF">pdf</a>, <a href="/format/2402.18774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Situate AI Guidebook: Co-Designing a Toolkit to Support  Multi-Stakeholder Early-stage Deliberations Around Public Sector AI Proposals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kawakami%2C+A">Anna Kawakami</a>, 
<a href="/search/cs?searchtype=author&query=Coston%2C+A">Amanda Coston</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haiyi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Heidari%2C+H">Hoda Heidari</a>, 
<a href="/search/cs?searchtype=author&query=Holstein%2C+K">Kenneth Holstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18830" title="Abstract">arXiv:2402.18830</a> (replaced) [<a href="/pdf/2402.18830" title="Download PDF">pdf</a>, <a href="/format/2402.18830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training-set-free two-stage deep learning for spectroscopic data  de-noising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Huang%2C+D">Dongchen Huang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Liu%2C+J">Junde Liu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Qian%2C+T">Tian Qian</a>, 
<a href="/search/cond-mat?searchtype=author&query=Weng%2C+H">Hongming Weng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18946" title="Abstract">arXiv:2402.18946</a> (replaced) [<a href="/pdf/2402.18946" title="Download PDF">pdf</a>, <a href="/format/2402.18946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Adaptive Safety-Critical Control with Gaussian Processes in  High-Order Uncertain Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+L">Long Wen</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xiangtong Yao</a>, 
<a href="/search/cs?searchtype=author&query=Bing%2C+Z">Zhenshan Bing</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Linghuan Kong</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wei He</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+A">Alois Knoll</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19001" title="Abstract">arXiv:2402.19001</a> (replaced) [<a href="/pdf/2402.19001" title="Download PDF">pdf</a>, <a href="/format/2402.19001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of the Two-Step Heterogeneous Transfer Learning for Laryngeal  Blood Vessel Classification: Issue and Improvement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+X">Xinyi Fang</a>, 
<a href="/search/cs?searchtype=author&query=Chong%2C+C+F">Chak Fong Chong</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K+L">Kei Long Wong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yapeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+W">Wei Ke</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tiankui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Im%2C+S">Sio-Kei Im</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19059" title="Abstract">arXiv:2402.19059</a> (replaced) [<a href="/pdf/2402.19059" title="Download PDF">pdf</a>, <a href="/format/2402.19059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VEnvision3D: A Synthetic Perception Dataset for 3D Multi-Task Model  Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiahao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+C">Chen Long</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yue Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jialiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haiping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhen Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19170" title="Abstract">arXiv:2402.19170</a> (replaced) [<a href="/pdf/2402.19170" title="Download PDF">pdf</a>, <a href="/ps/2402.19170" title="Download PostScript">ps</a>, <a href="/format/2402.19170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Legal Judgement Prediction in Romanian with Long Text Encoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Masala%2C+M">Mihai Masala</a>, 
<a href="/search/cs?searchtype=author&query=Rebedea%2C+T">Traian Rebedea</a>, 
<a href="/search/cs?searchtype=author&query=Velicu%2C+H">Horia Velicu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Rejected at LREC-COLING with 4/4/3
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19276" title="Abstract">arXiv:2402.19276</a> (replaced) [<a href="/pdf/2402.19276" title="Download PDF">pdf</a>, <a href="/format/2402.19276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modular Blind Video Quality Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wen%2C+W">Wen Wen</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+M">Mu Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yabin Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Liao%2C+Y">Yiting Liao</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Junlin Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+K">Kede Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024; It is not the camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19280" title="Abstract">arXiv:2402.19280</a> (replaced) [<a href="/pdf/2402.19280" title="Download PDF">pdf</a>, <a href="/ps/2402.19280" title="Download PostScript">ps</a>, <a href="/format/2402.19280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mobile Health Text Misinformation Identification Using Mobile Data  Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wen-Chen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Pillai%2C+S+E+V+S">Sanjaikanth E Vadakkethil Somanathan Pillai</a>, 
<a href="/search/cs?searchtype=author&query=ElSaid%2C+A+A">Abdelrahman Ahmed ElSaid</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19282" title="Abstract">arXiv:2402.19282</a> (replaced) [<a href="/pdf/2402.19282" title="Download PDF">pdf</a>, <a href="/format/2402.19282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WanJuan-CC: A Safe and High-Quality Open-sourced English Webtext Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jiantao Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+H">Haijun Lv</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhenjiang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+W">Wenchang Ning</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jia Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">ChaoBin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+P">Pei Chu</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yuan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lindong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+R">Runyu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhiyuan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Huanze Tang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Z">Zhikai Lei</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Jiawei Hong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Keyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+Z">Zhaoye Fei</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruiliang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhongying Tu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hang Yan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19298" title="Abstract">arXiv:2402.19298</a> (replaced) [<a href="/pdf/2402.19298" title="Download PDF">pdf</a>, <a href="/format/2402.19298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Suppress and Rebalance: Towards Generalized Multi-Modal Face  Anti-Spoofing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+R">Rizhao Cai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yizhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Ying Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zitong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wenzhong Tang</a>, 
<a href="/search/cs?searchtype=author&query=Kot%2C+A">Alex Kot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepeted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19350" title="Abstract">arXiv:2402.19350</a> (replaced) [<a href="/pdf/2402.19350" title="Download PDF">pdf</a>, <a href="/format/2402.19350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompting Explicit and Implicit Knowledge for Multi-hop Question  Answering Based on Human Reading Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Guangming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+Y">Yunfei Long</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Cunjin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jiaxing Shen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xia Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted at LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00030" title="Abstract">arXiv:2403.00030</a> (replaced) [<a href="/pdf/2403.00030" title="Download PDF">pdf</a>, <a href="/format/2403.00030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphPub: Generation of Differential Privacy Graph with High  Availability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wanghan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Bin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Ao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiqiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+B">Bo Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00111" title="Abstract">arXiv:2403.00111</a> (replaced) [<a href="/pdf/2403.00111" title="Download PDF">pdf</a>, <a href="/format/2403.00111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A compendium and evaluation of taxonomy quality attributes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Unterkalmsteiner%2C+M">Michael Unterkalmsteiner</a>, 
<a href="/search/cs?searchtype=author&query=Abdeen%2C+W">Waleed Abdeen</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Expert Syst. J. Knowl. Eng. 40(1) (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00225" title="Abstract">arXiv:2403.00225</a> (replaced) [<a href="/pdf/2403.00225" title="Download PDF">pdf</a>, <a href="/format/2403.00225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Policy Learning via Offline Skill Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+W+K">Woo Kyung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+M">Minjong Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+H">Honguk Woo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00579" title="Abstract">arXiv:2403.00579</a> (replaced) [<a href="/pdf/2403.00579" title="Download PDF">pdf</a>, <a href="/format/2403.00579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuPIMs: NPU-PIM Heterogeneous Acceleration for Batched LLM Inferencing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heo%2C+G">Guseul Heo</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sangyeop Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+J">Jaehong Cho</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+H">Hyunmin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sanghyeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ham%2C+H">Hyungkyu Ham</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+G">Gwangsun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Mahajan%2C+D">Divya Mahajan</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jongse Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00685" title="Abstract">arXiv:2403.00685</a> (replaced) [<a href="/pdf/2403.00685" title="Download PDF">pdf</a>, <a href="/ps/2403.00685" title="Download PostScript">ps</a>, <a href="/format/2403.00685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Know your exceptions: Towards an Ontology of Exceptions in Knowledge  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sacco%2C+G">Gabriele Sacco</a>, 
<a href="/search/cs?searchtype=author&query=Bozzato%2C+L">Loris Bozzato</a>, 
<a href="/search/cs?searchtype=author&query=Kutz%2C+O">Oliver Kutz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 4 pages are appendix. (v2 updates: minor revisions on discussions, terminology and text editing)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00748" title="Abstract">arXiv:2403.00748</a> (replaced) [<a href="/pdf/2403.00748" title="Download PDF">pdf</a>, <a href="/format/2403.00748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Primal-Dual iLQR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sousa-Pinto%2C+J">Jo&#xe3;o Sousa-Pinto</a>, 
<a href="/search/math?searchtype=author&query=Orban%2C+D">Dominique Orban</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00818" title="Abstract">arXiv:2403.00818</a> (replaced) [<a href="/pdf/2403.00818" title="Download PDF">pdf</a>, <a href="/format/2403.00818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DenseMamba: State Space Models with Dense Hidden Connection for  Efficient Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wei He</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kai Han</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yehui Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengcheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Tianyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhe Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00835" title="Abstract">arXiv:2403.00835</a> (replaced) [<a href="/pdf/2403.00835" title="Download PDF">pdf</a>, <a href="/format/2403.00835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLLMs: Consistency Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kou%2C+S">Siqi Kou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Lanxiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhezhi He</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhijie Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00867" title="Abstract">arXiv:2403.00867</a> (replaced) [<a href="/pdf/2403.00867" title="Download PDF">pdf</a>, <a href="/format/2403.00867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by  Exploring Refusal Loss Landscapes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaomeng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pin-Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+T">Tsung-Yi Ho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://huggingface.co/spaces/TrustSafeAI/GradientCuff-Jailbreak-Defense">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00884" title="Abstract">arXiv:2403.00884</a> (replaced) [<a href="/pdf/2403.00884" title="Download PDF">pdf</a>, <a href="/format/2403.00884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text classification of column headers with a controlled vocabulary:  leveraging LLMs for metadata enrichment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martorana%2C+M">Margherita Martorana</a>, 
<a href="/search/cs?searchtype=author&query=Kuhn%2C+T">Tobias Kuhn</a>, 
<a href="/search/cs?searchtype=author&query=Stork%2C+L">Lise Stork</a>, 
<a href="/search/cs?searchtype=author&query=van+Ossenbruggen%2C+J">Jacco van Ossenbruggen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00890" title="Abstract">arXiv:2403.00890</a> (replaced) [<a href="/pdf/2403.00890" title="Download PDF">pdf</a>, <a href="/ps/2403.00890" title="Download PostScript">ps</a>, <a href="/format/2403.00890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Android Malware Detection Through Data Augmentation Using  Wasserstein Generative Adversarial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stalin%2C+K">Kawana Stalin</a>, 
<a href="/search/cs?searchtype=author&query=Mekoya%2C+M+B">Mikias Berhanu Mekoya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01053" title="Abstract">arXiv:2403.01053</a> (replaced) [<a href="/pdf/2403.01053" title="Download PDF">pdf</a>, <a href="/format/2403.01053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seeing Unseen: Discover Novel Biomedical Concepts via  Geometry-Constrained Probabilistic Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jianan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dongnan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Hang Chang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Heng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Weidong Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01085" title="Abstract">arXiv:2403.01085</a> (replaced) [<a href="/e-print/2403.01085" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Strongly Subcubic Combinatorial Algorithm for Triangle Detection with  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dumitrescu%2C+A">Adrian Dumitrescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The triangle detection algorithm may fail. The analysis of Case 2.1 (in Subsection 2.1) is invalid. Thanks to Zach Hunter for pointing this out
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01128" title="Abstract">arXiv:2403.01128</a> (replaced) [<a href="/pdf/2403.01128" title="Download PDF">pdf</a>, <a href="/format/2403.01128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sensitivity Analysis On Loss Landscape
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faroz%2C+S">Salman Faroz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01131" title="Abstract">arXiv:2403.01131</a> (replaced) [<a href="/pdf/2403.01131" title="Download PDF">pdf</a>, <a href="/format/2403.01131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLaMoCo: Instruction Tuning of Large Language Models for Optimization  Code Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ma%2C+Z">Zeyuan Ma</a>, 
<a href="/search/math?searchtype=author&query=Guo%2C+H">Hongshu Guo</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+J">Jiacheng Chen</a>, 
<a href="/search/math?searchtype=author&query=Peng%2C+G">Guojun Peng</a>, 
<a href="/search/math?searchtype=author&query=Cao%2C+Z">Zhiguang Cao</a>, 
<a href="/search/math?searchtype=author&query=Ma%2C+Y">Yining Ma</a>, 
<a href="/search/math?searchtype=author&query=Gong%2C+Y">Yue-Jiao Gong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01444" title="Abstract">arXiv:2403.01444</a> (replaced) [<a href="/pdf/2403.01444" title="Download PDF">pdf</a>, <a href="/format/2403.01444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3DGStream: On-the-Fly Training of 3D Gaussians for Efficient Streaming  of Photo-Realistic Free-Viewpoint Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiakai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+H">Han Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guangyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhanjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+W">Wei Xing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024 Accepted. Project Page: <a href="https://sjojok.github.io/3dgstream">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01469" title="Abstract">arXiv:2403.01469</a> (replaced) [<a href="/pdf/2403.01469" title="Download PDF">pdf</a>, <a href="/format/2403.01469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KorMedMCQA: Multi-Choice Question Answering Benchmark for Korean  Healthcare Professional Licensing Examinations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kweon%2C+S">Sunjun Kweon</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+B">Byungjin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minkyu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+R+W">Rae Woong Park</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+E">Edward Choi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01491" title="Abstract">arXiv:2403.01491</a> (replaced) [<a href="/pdf/2403.01491" title="Download PDF">pdf</a>, <a href="/format/2403.01491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultimate codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hurley%2C+T">Ted Hurley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Rings and Algebras (math.RA)

</div>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01528" title="Abstract">arXiv:2403.01528</a> (replaced) [<a href="/pdf/2403.01528" title="Download PDF">pdf</a>, <a href="/format/2403.01528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Biomolecule and Natural Language through Multi-Modal  Learning: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+Q">Qizhi Pei</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lijun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+K">Kaiyuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jinhua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+T">Tao Qin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rui Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Survey Paper. 25 pages, 9 figures, and 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01537" title="Abstract">arXiv:2403.01537</a> (replaced) [<a href="/pdf/2403.01537" title="Download PDF">pdf</a>, <a href="/format/2403.01537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed-Strategy Nash Equilibrium for Crowd Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Muchen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Baldini%2C+F">Francesca Baldini</a>, 
<a href="/search/cs?searchtype=author&query=Trautman%2C+P">Peter Trautman</a>, 
<a href="/search/cs?searchtype=author&query=Murphey%2C+T">Todd Murphey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01543" title="Abstract">arXiv:2403.01543</a> (replaced) [<a href="/pdf/2403.01543" title="Download PDF">pdf</a>, <a href="/format/2403.01543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Action Counting with Dynamic Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zishi Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaoxuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+Q">Qiuyan Shang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wentao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ci%2C+H">Hai Ci</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yizhou Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> code: <a href="https://github.com/lizishi/DeTRC">this https URL</a>, proj page: <a href="https://shirleymaxx.github.io/DeTRC/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01548" title="Abstract">arXiv:2403.01548</a> (replaced) [<a href="/pdf/2403.01548" title="Download PDF">pdf</a>, <a href="/format/2403.01548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Context Sharpness as Alerts: An Inner Representation Perspective for  Hallucination Mitigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shiqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+M">Miao Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junteng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhengxuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Teng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Siyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junxian He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> code repo is available at: <a href="https://github.com/hkust-nlp/Activation_decoding.git">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01616" title="Abstract">arXiv:2403.01616</a> (replaced) [<a href="/pdf/2403.01616" title="Download PDF">pdf</a>, <a href="/format/2403.01616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Comprehensive Vietnamese Retrieval-Augmented Generation and  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duc%2C+N+Q">Nguyen Quang Duc</a>, 
<a href="/search/cs?searchtype=author&query=Son%2C+L+H">Le Hai Son</a>, 
<a href="/search/cs?searchtype=author&query=Nhan%2C+N+D">Nguyen Duc Nhan</a>, 
<a href="/search/cs?searchtype=author&query=Minh%2C+N+D+N">Nguyen Dich Nhat Minh</a>, 
<a href="/search/cs?searchtype=author&query=Huong%2C+L+T">Le Thanh Huong</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+D+V">Dinh Viet Sang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01756" title="Abstract">arXiv:2403.01756</a> (replaced) [<a href="/pdf/2403.01756" title="Download PDF">pdf</a>, <a href="/format/2403.01756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention Guidance Mechanism for Handwritten Mathematical Expression  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yutian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+W">Wenjun Ke</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jianguo Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01777" title="Abstract">arXiv:2403.01777</a> (replaced) [<a href="/pdf/2403.01777" title="Download PDF">pdf</a>, <a href="/format/2403.01777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NPHardEval4V: A Dynamic Reasoning Benchmark of Multimodal Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lizhou Fan</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+W">Wenyue Hua</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Kaijie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Mingyu Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lingyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+H">Haoyang Ling</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+J">Jinkui Chi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jindong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongfeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01800" title="Abstract">arXiv:2403.01800</a> (replaced) [<a href="/pdf/2403.01800" title="Download PDF">pdf</a>, <a href="/format/2403.01800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AtomoVideo: High Fidelity Image-to-Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+L">Litong Gong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yiran Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weijie Li</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+X">Xiaoyang Kang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Biao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+T">Tiezheng Ge</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Bo Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report. Page: <a href="https://atomo-video.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01802" title="Abstract">arXiv:2403.01802</a> (replaced) [<a href="/pdf/2403.01802" title="Download PDF">pdf</a>, <a href="/format/2403.01802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TNF: Tri-branch Neural Fusion for Multimodal Medical Data Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Sone%2C+S">Shusaku Sone</a>, 
<a href="/search/cs?searchtype=author&query=Ushiku%2C+Y">Yoshitaka Ushiku</a>, 
<a href="/search/cs?searchtype=author&query=Oba%2C+Y">Yuki Oba</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jiaxin Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01879" title="Abstract">arXiv:2403.01879</a> (replaced) [<a href="/pdf/2403.01879" title="Download PDF">pdf</a>, <a href="/format/2403.01879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High curvature means low-rank: On the sectional curvature of Grassmann  and Stiefel manifolds and the underlying matrix trace inequalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zimmermann%2C+R">Ralf Zimmermann</a>, 
<a href="/search/math?searchtype=author&query=Stoye%2C+J">Jakob Stoye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01890" title="Abstract">arXiv:2403.01890</a> (replaced) [<a href="/pdf/2403.01890" title="Download PDF">pdf</a>, <a href="/format/2403.01890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aerial Tensile Perching and Disentangling Mechanism for Long-Term  Environmental Monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lan%2C+T">Tian Lan</a>, 
<a href="/search/cs?searchtype=author&query=Romanello%2C+L">Luca Romanello</a>, 
<a href="/search/cs?searchtype=author&query=Kovac%2C+M">Mirko Kovac</a>, 
<a href="/search/cs?searchtype=author&query=Armanini%2C+S+F">Sophie F. Armanini</a>, 
<a href="/search/cs?searchtype=author&query=Kocer%2C+B+B">Basaran Bahadir Kocer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures, Accepted in IEEE International Conference on Robotics and Automation (ICRA) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01897" title="Abstract">arXiv:2403.01897</a> (replaced) [<a href="/pdf/2403.01897" title="Download PDF">pdf</a>, <a href="/format/2403.01897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fostering the Ecosystem of Open Neural Encoders for Portuguese with  Albertina PT* Family
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santos%2C+R">Rodrigo Santos</a>, 
<a href="/search/cs?searchtype=author&query=Rodrigues%2C+J">Jo&#xe3;o Rodrigues</a>, 
<a href="/search/cs?searchtype=author&query=Gomes%2C+L">Lu&#xed;s Gomes</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+J">Jo&#xe3;o Silva</a>, 
<a href="/search/cs?searchtype=author&query=Branco%2C+A">Ant&#xf3;nio Branco</a>, 
<a href="/search/cs?searchtype=author&query=Cardoso%2C+H+L">Henrique Lopes Cardoso</a>, 
<a href="/search/cs?searchtype=author&query=Os%C3%B3rio%2C+T+F">Tom&#xe1;s Freitas Os&#xf3;rio</a>, 
<a href="/search/cs?searchtype=author&query=Leite%2C+B">Bernardo Leite</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01919" title="Abstract">arXiv:2403.01919</a> (replaced) [<a href="/pdf/2403.01919" title="Download PDF">pdf</a>, <a href="/format/2403.01919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matrix Completion with Convex Optimization and Column Subset Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krajewska%2C+A">Antonina Krajewska</a>, 
<a href="/search/cs?searchtype=author&query=Niewiadomska-Szynkiewicz%2C+E">Ewa Niewiadomska-Szynkiewicz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01932" title="Abstract">arXiv:2403.01932</a> (replaced) [<a href="/pdf/2403.01932" title="Download PDF">pdf</a>, <a href="/format/2403.01932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tree Counting by Bridging 3D Point Clouds with Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianfang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhongyu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheng-Yen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jenq-Neng Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Oehmcke%2C+S">Stefan Oehmcke</a>, 
<a href="/search/cs?searchtype=author&query=Gominski%2C+D+P+J">Dimitri Pierre Johannes Gominski</a>, 
<a href="/search/cs?searchtype=author&query=Gieseke%2C+F">Fabian Gieseke</a>, 
<a href="/search/cs?searchtype=author&query=Igel%2C+C">Christian Igel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01944" title="Abstract">arXiv:2403.01944</a> (replaced) [<a href="/pdf/2403.01944" title="Download PDF">pdf</a>, <a href="/format/2403.01944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fourier-basis Functions to Bridge Augmentation Gap: Rethinking Frequency  Augmentation in Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vaish%2C+P">Puru Vaish</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shunxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Strisciuglio%2C+N">Nicola Strisciuglio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02093" title="Abstract">arXiv:2403.02093</a> (replaced) [<a href="/pdf/2403.02093" title="Download PDF">pdf</a>, <a href="/format/2403.02093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Daedalus: Self-Adaptive Horizontal Autoscaling for Resource Efficiency  of Distributed Stream Processing Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pfister%2C+B+J+J">Benjamin J. J. Pfister</a>, 
<a href="/search/cs?searchtype=author&query=Scheinert%2C+D">Dominik Scheinert</a>, 
<a href="/search/cs?searchtype=author&query=Geldenhuys%2C+M+K">Morgan K. Geldenhuys</a>, 
<a href="/search/cs?searchtype=author&query=Kao%2C+O">Odej Kao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02130" title="Abstract">arXiv:2403.02130</a> (replaced) [<a href="/pdf/2403.02130" title="Download PDF">pdf</a>, <a href="/format/2403.02130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using LLMs for the Extraction and Normalization of Product Attribute  Values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baumann%2C+N">Nick Baumann</a>, 
<a href="/search/cs?searchtype=author&query=Brinkmann%2C+A">Alexander Brinkmann</a>, 
<a href="/search/cs?searchtype=author&query=Bizer%2C+C">Christian Bizer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02164" title="Abstract">arXiv:2403.02164</a> (replaced) [<a href="/pdf/2403.02164" title="Download PDF">pdf</a>, <a href="/ps/2403.02164" title="Download PostScript">ps</a>, <a href="/format/2403.02164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cognition is All You Need -- The Next Layer of AI Above Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spivack%2C+N">Nova Spivack</a>, 
<a href="/search/cs?searchtype=author&query=Douglas%2C+S">Sam Douglas</a>, 
<a href="/search/cs?searchtype=author&query=Crames%2C+M">Michelle Crames</a>, 
<a href="/search/cs?searchtype=author&query=Connors%2C+T">Tim Connors</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 63 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item681">[681]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02175" title="Abstract">arXiv:2403.02175</a> (replaced) [<a href="/pdf/2403.02175" title="Download PDF">pdf</a>, <a href="/format/2403.02175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiSTA: Geometric Object-Based Change Detection in Cluttered Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rowell%2C+J">Joseph Rowell</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lintong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fallon%2C+M">Maurice Fallon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6+n page limit for (accepted) ICRA 2024 submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item682">[682]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02187" title="Abstract">arXiv:2403.02187</a> (replaced) [<a href="/pdf/2403.02187" title="Download PDF">pdf</a>, <a href="/format/2403.02187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mutual Information Estimation via Normalizing Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Butakov%2C+I">Ivan Butakov</a>, 
<a href="/search/cs?searchtype=author&query=Tolmachev%2C+A">Alexander Tolmachev</a>, 
<a href="/search/cs?searchtype=author&query=Malanchuk%2C+S">Sofia Malanchuk</a>, 
<a href="/search/cs?searchtype=author&query=Neopryatnaya%2C+A">Anna Neopryatnaya</a>, 
<a href="/search/cs?searchtype=author&query=Frolov%2C+A">Alexey Frolov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item683">[683]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02241" title="Abstract">arXiv:2403.02241</a> (replaced) [<a href="/pdf/2403.02241" title="Download PDF">pdf</a>, <a href="/format/2403.02241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Redshift: Random Networks are not Random Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teney%2C+D">Damien Teney</a>, 
<a href="/search/cs?searchtype=author&query=Nicolicioiu%2C+A">Armand Nicolicioiu</a>, 
<a href="/search/cs?searchtype=author&query=Hartmann%2C+V">Valentin Hartmann</a>, 
<a href="/search/cs?searchtype=author&query=Abbasnejad%2C+E">Ehsan Abbasnejad</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
  2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item684">[684]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02332" title="Abstract">arXiv:2403.02332</a> (replaced) [<a href="/pdf/2403.02332" title="Download PDF">pdf</a>, <a href="/format/2403.02332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniCtrl: Improving the Spatiotemporal Consistency of Text-to-Video  Diffusion Models via Training-Free Unified Attention Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuweiyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+T">Tian Xia</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Sihan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Github: <a href="https://github.com/XuweiyiChen/UniCtrl">this https URL</a> Website: <a href="https://unified-attention-control.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item364">Cross-lists</a></li>
<li><a href="#item415">Replacements</a></li>
</ul>
<small>[ total of 684 entries:  <b>1-684</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2403">2403</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
